===============================================================================

This patch turns the standard Quagga implementation into one that supports the
MPLS framework implemented by James Leu, Ramon Casellas, and David S. Miller.

TECHNICAL INFORMATION:

quagga-mpls version 0.99.10, checked out from the MPLS project's P4 repository
on Oct 25th, 2008.

Applies to Quagga 0.99.10, available from:
http://www.quagga.net/download/quagga-0.99.10.tar.gz

This patch has been obtained using the following procedure:
 1) First of all, Redhat-specific files have been removed from the package.
 2) Then, the following files have been copied from the ldp-portable package of
 the MPLS Linux project (checked out on Oct 29th, 2008) to the ldpd directory:
   ldp/ldp_addr.c
   ldp/ldp_addr.h
   ldp/ldp_adj.c
   ldp/ldp_adj.h
   ldp/ldp_attr.c
   ldp/ldp_attr.h
   ldp/ldp_buf.c
   ldp/ldp_buf.h
   ldp/ldp_cfg.c
   ldp/ldp_cfg.h
   ldp/ldp_defaults.h
   ldp/ldp_entity.c
   ldp/ldp_entity.h
   ldp/ldp_fec.c
   ldp/ldp_fec.h
   ldp/ldp_global.c
   ldp/ldp_global.h
   ldp/ldp_hello.c
   ldp/ldp_hello.h
   ldp/ldp_hop.c
   ldp/ldp_hop.h
   ldp/ldp_hop_list.c
   ldp/ldp_hop_list.h
   ldp/ldp_if.c
   ldp/ldp_if.h
   ldp/ldp_inet_addr.c
   ldp/ldp_inet_addr.h
   ldp/ldp_init.c
   ldp/ldp_init.h
   ldp/ldp_inlabel.c
   ldp/ldp_inlabel.h
   ldp/ldp_keepalive.c
   ldp/ldp_keepalive.h
   ldp/ldp_label_abort.c
   ldp/ldp_label_abort.h
   ldp/ldp_label_mapping.c
   ldp/ldp_label_mapping.h
   ldp/ldp_label_rel_with.c
   ldp/ldp_label_rel_with.h
   ldp/ldp_label_request.c
   ldp/ldp_label_request.h
   ldp/ldp_mesg.c
   ldp/ldp_mesg.h
   ldp/ldp_nexthop.c
   ldp/ldp_nexthop.h
   ldp/ldp_nortel.c
   ldp/ldp_nortel.h
   ldp/ldp_notif.c
   ldp/ldp_notif.h
   ldp/ldp_outlabel.c
   ldp/ldp_outlabel.h
   ldp/ldp_pdu.h
   ldp/ldp_pdu_setup.c
   ldp/ldp_pdu_setup.h
   ldp/ldp_peer.c
   ldp/ldp_peer.h
   ldp/ldp_resource.c
   ldp/ldp_resource.h
   ldp/ldp_session.c
   ldp/ldp_session.h
   ldp/ldp_state_funcs.c
   ldp/ldp_state_machine.c
   ldp/ldp_state_machine.h
   ldp/ldp_struct.h
   ldp/ldp_tunnel.c
   ldp/ldp_tunnel.h
   common/mpls_struct.h
   common/mpls_assert.h
   common/mpls_bitfield.h
   common/mpls_fib_impl.h
   common/mpls_ifmgr_impl.h
   common/mpls_mm_impl.h
   common/mpls_mpls_impl.h
   common/mpls_policy_impl.h
   common/mpls_refcnt.h
   common/mpls_socket_impl.h
   common/mpls_timer_impl.h
   common/mpls_trace_impl.h
   common/mpls_tree_impl.h
   common/mpls_list.h
   common/mpls_lock_impl.h
   common/mpls_compare.h
   common/mpls_compare.c
 3) Some documentation files have been copied from the plain Quagga package to
 the MPLS-enabled package, in order to prevent them from appearing in the patch.
 4) Some files created by automake/autoconf have been removed from the plain
 Quagga package.
 5) The following files have been copied from a 2.6.26.5 Linux kernel tree,
 patched with MPLS Linux 1.962, to the include/linux directory of the package:
   genetlink.h
   mpls.h
   rtnetlink.h
   shim.h
 6) The file lib/memtypes.h has been modified to include the definition of two
 macros: MTYPE_TE and MTYPE_RSVP.
 7) The template for the configure script has been modified to support the
 specification of a custom path where the SNMP library can be retrieved.
 8) The resulting package has been diff'ed against a clean Quagga 0.99.10.

===============================================================================


diff -Naur quagga-0.99.10/bgpd/bgp_nexthop.c quagga-mpls/bgpd/bgp_nexthop.c
--- quagga-0.99.10/bgpd/bgp_nexthop.c	2007-05-04 22:15:47.000000000 +0200
+++ quagga-mpls/bgpd/bgp_nexthop.c	2008-11-25 12:30:18.000000000 +0100
@@ -118,33 +118,31 @@
   if (next1->type != next2->type)
     return 0;
 
-  switch (next1->type)
+  if (CHECK_FLAG (next1->type, ZEBRA_NEXTHOP_IPV4))
     {
-    case ZEBRA_NEXTHOP_IPV4:
       if (! IPV4_ADDR_SAME (&next1->gate.ipv4, &next2->gate.ipv4))
 	return 0;
-      break;
-    case ZEBRA_NEXTHOP_IFINDEX:
-    case ZEBRA_NEXTHOP_IFNAME:
-      if (next1->ifindex != next2->ifindex)
-	return 0;
-      break;
+    }
 #ifdef HAVE_IPV6
-    case ZEBRA_NEXTHOP_IPV6:
-      if (! IPV6_ADDR_SAME (&next1->gate.ipv6, &next2->gate.ipv6))
-	return 0;
-      break;
-    case ZEBRA_NEXTHOP_IPV6_IFINDEX:
-    case ZEBRA_NEXTHOP_IPV6_IFNAME:
-      if (! IPV6_ADDR_SAME (&next1->gate.ipv6, &next2->gate.ipv6))
+  else if (CHECK_FLAG (next1->type, ZEBRA_NEXTHOP_IPV6))
+    {
+      if (!IPV6_ADDR_SAME (&next1->gate.ipv6, &next2->gate.ipv6))
 	return 0;
+    }
+#endif /* HAVE_IPV6 */
+
+  if (CHECK_FLAG (next1->type, ZEBRA_NEXTHOP_IFINDEX))
+    {
       if (next1->ifindex != next2->ifindex)
 	return 0;
-      break;
-#endif /* HAVE_IPV6 */
-    default:
-      /* do nothing */
-      break;
+    }
+  else if (CHECK_FLAG (next1->type, ZEBRA_NEXTHOP_IFNAME))
+    {
+      if (!(next1->ifname && next2->ifname))
+        return 0;
+
+      if (strncmp(next1->ifname, next2->ifname, INTERFACE_NAMSIZ))
+        return 0;
     }
   return 1;
 }
@@ -714,6 +712,7 @@
   int i;
   u_char nexthop_num;
   struct nexthop *nexthop;
+  struct zapi_nexthop znh;
   struct bgp_nexthop_cache *bnc;
 
   s = zlookup->ibuf;
@@ -750,20 +749,27 @@
 	{
 	  nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
 	  memset (nexthop, 0, sizeof (struct nexthop));
-	  nexthop->type = stream_getc (s);
-	  switch (nexthop->type)
+	  zapi_nexthop_read(s, &znh);
+
+	  nexthop->type = znh.type;
+	  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
+	    {
+	      nexthop->gate.ipv4.s_addr = znh.gw.ipv4.s_addr;
+	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
+	    {
+	      assert (0);
+	    }
+
+	  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+	    {
+	      nexthop->ifindex = znh.intf.index;
+	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
 	    {
-	    case ZEBRA_NEXTHOP_IPV4:
-	      nexthop->gate.ipv4.s_addr = stream_get_ipv4 (s);
-	      break;
-	    case ZEBRA_NEXTHOP_IFINDEX:
-	    case ZEBRA_NEXTHOP_IFNAME:
-	      nexthop->ifindex = stream_getl (s);
-	      break;
-            default:
-              /* do nothing */
-              break;
+	      assert (0);
 	    }
+
 	  bnc_nexthop_add (bnc, nexthop);
 	}
     }
@@ -823,6 +829,7 @@
   int i;
   u_char nexthop_num;
   struct nexthop *nexthop;
+  struct zapi_nexthop znh;
   struct bgp_nexthop_cache *bnc;
 
   s = zlookup->ibuf;
@@ -858,27 +865,29 @@
 
       for (i = 0; i < nexthop_num; i++)
 	{
+	  zapi_nexthop_read(s, &znh);
 	  nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
 	  memset (nexthop, 0, sizeof (struct nexthop));
-	  nexthop->type = stream_getc (s);
-	  switch (nexthop->type)
+	  nexthop->type = znh.type;
+
+	  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
+	    {
+	      assert (0);
+	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
+	    {
+	      nexthop->gate.ipv6 = znh.gw.ipv6;
+	    }
+
+	  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+	    {
+	      nexthop->ifindex = znh.intf.index;
+	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
 	    {
-	    case ZEBRA_NEXTHOP_IPV6:
-	      stream_get (&nexthop->gate.ipv6, s, 16);
-	      break;
-	    case ZEBRA_NEXTHOP_IPV6_IFINDEX:
-	    case ZEBRA_NEXTHOP_IPV6_IFNAME:
-	      stream_get (&nexthop->gate.ipv6, s, 16);
-	      nexthop->ifindex = stream_getl (s);
-	      break;
-	    case ZEBRA_NEXTHOP_IFINDEX:
-	    case ZEBRA_NEXTHOP_IFNAME:
-	      nexthop->ifindex = stream_getl (s);
-	      break;
-	    default:
-	      /* do nothing */
-	      break;
+	      assert (0);
 	    }
+
 	  bnc_nexthop_add (bnc, nexthop);
 	}
     }
@@ -938,6 +947,8 @@
   u_int32_t metric = 0;
   u_char nexthop_num;
   u_char nexthop_type;
+  struct zapi_nexthop znh;
+  int i;
 
   /* If lookup connection is not available return valid. */
   if (zlookup->sock < 0)
@@ -1007,17 +1018,22 @@
   /* If there is nexthop then this is active route. */
   if (nexthop_num)
     {
-      nexthop.s_addr = 0;
-      nexthop_type = stream_getc (s);
-      if (nexthop_type == ZEBRA_NEXTHOP_IPV4)
+      for (i = 0; i < nexthop_num; i++)
 	{
-	  nexthop.s_addr = stream_get_ipv4 (s);
-	  if (igpnexthop)
-	    *igpnexthop = nexthop;
+	  zapi_nexthop_read(s, &znh);
+	  nexthop_type = znh.type;
+	  if (CHECK_FLAG (nexthop_type, ZEBRA_NEXTHOP_IPV4))
+	    {
+	      nexthop.s_addr = znh.gw.ipv4.s_addr;
+	    }
+	  else if (CHECK_FLAG (nexthop_type, ZEBRA_NEXTHOP_IPV6))
+	    {
+	      assert (0);
+	    }
 	}
-      else
-	*igpnexthop = nexthop;
 
+      if (igpnexthop)
+	*igpnexthop = nexthop;
       return 1;
     }
   else
diff -Naur quagga-0.99.10/bgpd/bgp_route.c quagga-mpls/bgpd/bgp_route.c
--- quagga-0.99.10/bgpd/bgp_route.c	2008-04-10 13:47:45.000000000 +0200
+++ quagga-mpls/bgpd/bgp_route.c	2008-11-25 12:30:18.000000000 +0100
@@ -1893,7 +1893,10 @@
 
       /* Update MPLS tag.  */
       if (safi == SAFI_MPLS_VPN)
-        memcpy ((bgp_info_extra_get (ri))->tag, tag, 3);
+        {
+          bgp_info_set_flag (rn, ri, BGP_INFO_MPLS);
+          memcpy ((bgp_info_extra_get (ri))->tag, tag, 3);
+        }
 
       bgp_info_set_flag (rn, ri, BGP_INFO_VALID);
 
@@ -1923,7 +1926,10 @@
 
   /* Update MPLS tag. */
   if (safi == SAFI_MPLS_VPN)
-    memcpy ((bgp_info_extra_get (new))->tag, tag, 3);
+    {
+      bgp_info_set_flag (rn, new, BGP_INFO_MPLS);
+      memcpy ((bgp_info_extra_get (new))->tag, tag, 3);
+    }
 
   bgp_info_set_flag (rn, new, BGP_INFO_VALID);
 
diff -Naur quagga-0.99.10/bgpd/bgp_route.h quagga-mpls/bgpd/bgp_route.h
--- quagga-0.99.10/bgpd/bgp_route.h	2007-08-06 17:24:51.000000000 +0200
+++ quagga-mpls/bgpd/bgp_route.h	2008-11-25 12:30:18.000000000 +0100
@@ -76,6 +76,7 @@
 #define BGP_INFO_STALE          (1 << 8)
 #define BGP_INFO_REMOVED        (1 << 9)
 #define BGP_INFO_COUNTED	(1 << 10)
+#define BGP_INFO_MPLS		(1 << 11)
 
   /* BGP route type.  This can be static, RIP, OSPF, BGP etc.  */
   u_char type;
diff -Naur quagga-0.99.10/bgpd/bgp_zebra.c quagga-mpls/bgpd/bgp_zebra.c
--- quagga-0.99.10/bgpd/bgp_zebra.c	2007-05-04 22:15:47.000000000 +0200
+++ quagga-mpls/bgpd/bgp_zebra.c	2008-11-25 12:30:18.000000000 +0100
@@ -36,6 +36,7 @@
 #include "bgpd/bgp_nexthop.h"
 #include "bgpd/bgp_zebra.h"
 #include "bgpd/bgp_fsm.h"
+#include "bgpd/bgp_mplsvpn.h"
 #include "bgpd/bgp_debug.h"
 
 /* All information about zebra. */
@@ -230,73 +231,52 @@
 static int
 zebra_read_ipv4 (int command, struct zclient *zclient, zebra_size_t length)
 {
-  struct stream *s;
   struct zapi_ipv4 api;
   unsigned long ifindex;
   struct in_addr nexthop;
   struct prefix_ipv4 p;
+  int i;
 
-  s = zclient->ibuf;
-  ifindex = 0;
-  nexthop.s_addr = 0;
-
-  /* Type, flags, message. */
-  api.type = stream_getc (s);
-  api.flags = stream_getc (s);
-  api.message = stream_getc (s);
-
-  /* IPv4 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv4));
-  p.family = AF_INET;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
-
-  /* Nexthop, ifindex, distance, metric. */
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
-    {
-      api.nexthop_num = stream_getc (s);
-      nexthop.s_addr = stream_get_ipv4 (s);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_IFINDEX))
-    {
-      api.ifindex_num = stream_getc (s);
-      ifindex = stream_getl (s);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (s);
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (s);
-  else
-    api.metric = 0;
-
-  if (command == ZEBRA_IPV4_ROUTE_ADD)
-    {
-      if (BGP_DEBUG(zebra, ZEBRA))
-	{
-	  char buf[2][INET_ADDRSTRLEN];
-	  zlog_debug("Zebra rcvd: IPv4 route add %s %s/%d nexthop %s metric %u",
-		     zebra_route_string(api.type),
-		     inet_ntop(AF_INET, &p.prefix, buf[0], sizeof(buf[0])),
-		     p.prefixlen,
-		     inet_ntop(AF_INET, &nexthop, buf[1], sizeof(buf[1])),
-		     api.metric);
-	}
-      bgp_redistribute_add((struct prefix *)&p, &nexthop, api.metric, api.type);
-    }
-  else
+  zapi_ipv4_route_read (zclient, length, &api, &p);
+  for (i = 0; i < api.nexthop_num; i++)
     {
-      if (BGP_DEBUG(zebra, ZEBRA))
-	{
-	  char buf[2][INET_ADDRSTRLEN];
-	  zlog_debug("Zebra rcvd: IPv4 route delete %s %s/%d "
-		     "nexthop %s metric %u",
-		     zebra_route_string(api.type),
-		     inet_ntop(AF_INET, &p.prefix, buf[0], sizeof(buf[0])),
-		     p.prefixlen,
-		     inet_ntop(AF_INET, &nexthop, buf[1], sizeof(buf[1])),
-		     api.metric);
-	}
-      bgp_redistribute_delete((struct prefix *)&p, api.type);
+      ifindex = 0;
+      nexthop.s_addr = 0;
+      if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IPV4))
+        nexthop.s_addr = api.nexthop[i].gw.ipv4.s_addr;
+
+      if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IFINDEX))
+        ifindex = api.nexthop[i].intf.index;
+
+      if (command == ZEBRA_IPV4_ROUTE_ADD)
+        {
+          if (BGP_DEBUG(zebra, ZEBRA))
+	    {
+	      char buf[2][INET_ADDRSTRLEN];
+	      zlog_debug("Zebra rcvd: IPv4 route add %s %s/%d nexthop %s metric %u",
+		         zebra_route_string(api.type),
+		         inet_ntop(AF_INET, &p.prefix, buf[0], sizeof(buf[0])),
+		         p.prefixlen,
+		         inet_ntop(AF_INET, &nexthop, buf[1], sizeof(buf[1])),
+		         api.metric);
+	    }
+          bgp_redistribute_add((struct prefix *)&p, &nexthop, api.metric, api.type);
+        }
+      else
+        {
+          if (BGP_DEBUG(zebra, ZEBRA))
+	    {
+	      char buf[2][INET_ADDRSTRLEN];
+	      zlog_debug("Zebra rcvd: IPv4 route delete %s %s/%d "
+		         "nexthop %s metric %u",
+		         zebra_route_string(api.type),
+		         inet_ntop(AF_INET, &p.prefix, buf[0], sizeof(buf[0])),
+		         p.prefixlen,
+		         inet_ntop(AF_INET, &nexthop, buf[1], sizeof(buf[1])),
+		         api.metric);
+	    }
+          bgp_redistribute_delete((struct prefix *)&p, api.type);
+        }
     }
 
   return 0;
@@ -307,80 +287,61 @@
 static int
 zebra_read_ipv6 (int command, struct zclient *zclient, zebra_size_t length)
 {
-  struct stream *s;
   struct zapi_ipv6 api;
   unsigned long ifindex;
   struct in6_addr nexthop;
   struct prefix_ipv6 p;
+  int i;
 
-  s = zclient->ibuf;
-  ifindex = 0;
-  memset (&nexthop, 0, sizeof (struct in6_addr));
-
-  /* Type, flags, message. */
-  api.type = stream_getc (s);
-  api.flags = stream_getc (s);
-  api.message = stream_getc (s);
-
-  /* IPv6 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv6));
-  p.family = AF_INET6;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
-
-  /* Nexthop, ifindex, distance, metric. */
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
-    {
-      api.nexthop_num = stream_getc (s);
-      stream_get (&nexthop, s, 16);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_IFINDEX))
-    {
-      api.ifindex_num = stream_getc (s);
-      ifindex = stream_getl (s);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (s);
-  else
-    api.distance = 0;
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (s);
-  else
-    api.metric = 0;
+  zapi_ipv6_route_read (zclient, length, &api, &p);
 
   /* Simply ignore link-local address. */
   if (IN6_IS_ADDR_LINKLOCAL (&p.prefix))
     return 0;
 
-  if (command == ZEBRA_IPV6_ROUTE_ADD)
+  for (i = 0; i < api.nexthop_num; i++)
     {
-      if (BGP_DEBUG(zebra, ZEBRA))
-	{
-	  char buf[INET6_ADDRSTRLEN];
-	  zlog_debug("Zebra rcvd: IPv6 route add %s %s/%d metric %u",
-		     zebra_route_string(api.type),
-		     inet_ntop(AF_INET6, &p.prefix, buf, sizeof(buf)),
-		     p.prefixlen, api.metric);
-	}
-      bgp_redistribute_add ((struct prefix *)&p, NULL, api.metric, api.type);
-    }
-  else
-    {
-      if (BGP_DEBUG(zebra, ZEBRA))
-	{
-	  char buf[INET6_ADDRSTRLEN];
-	  zlog_debug("Zebra rcvd: IPv6 route delete %s %s/%d metric %u",
-		     zebra_route_string(api.type),
-		     inet_ntop(AF_INET6, &p.prefix, buf, sizeof(buf)),
-		     p.prefixlen, api.metric);
-	}
-      bgp_redistribute_delete ((struct prefix *) &p, api.type);
+
+      ifindex = 0;
+      memset (&nexthop, 0, sizeof (struct in6_addr));
+
+      if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IPV6))
+        memcpy(&nexthop, &api.nexthop[i].gw.ipv6, 16);
+
+      if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IFINDEX))
+        ifindex = api.nexthop[i].intf.index;
+
+      if (command == ZEBRA_IPV6_ROUTE_ADD)
+        {
+          if (BGP_DEBUG(zebra, ZEBRA))
+	    {
+	      char buf[INET6_ADDRSTRLEN];
+	      zlog_debug("Zebra rcvd: IPv6 route add %s %s/%d metric %u",
+		         zebra_route_string(api.type),
+		         inet_ntop(AF_INET6, &p.prefix, buf, sizeof(buf)),
+		         p.prefixlen, api.metric);
+	    }
+          bgp_redistribute_add ((struct prefix *)&p, NULL, api.metric, api.type);
+        }
+      else
+        {
+          if (BGP_DEBUG(zebra, ZEBRA))
+	    {
+	      char buf[INET6_ADDRSTRLEN];
+	      zlog_debug("Zebra rcvd: IPv6 route delete %s %s/%d metric %u",
+		         zebra_route_string(api.type),
+		         inet_ntop(AF_INET6, &p.prefix, buf, sizeof(buf)),
+		         p.prefixlen, api.metric);
+	    }
+          bgp_redistribute_delete ((struct prefix *) &p, api.type);
+        }
     }
   
   return 0;
 }
 #endif /* HAVE_IPV6 */
 
+
 struct interface *
 if_lookup_by_ipv4 (struct in_addr *addr)
 {
@@ -708,10 +669,19 @@
 
       api.type = ZEBRA_ROUTE_BGP;
       api.message = 0;
+
       SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
       api.nexthop_num = 1;
-      api.nexthop = &nexthop;
-      api.ifindex_num = 0;
+      api.nexthop[0].type = ZEBRA_NEXTHOP_IPV4;
+      api.nexthop[0].gw.ipv4 = info->attr->nexthop;
+#ifdef HAVE_MPLS
+      if (CHECK_FLAG (info->flags, BGP_INFO_MPLS))
+        {
+          SET_FLAG (api.nexthop[0].type, ZEBRA_NEXTHOP_MPLS);
+          api.nexthop[0].mpls.type = ZEBRA_MPLS_LABEL_GEN;
+          api.nexthop[0].mpls.u.gen = decode_label(info->extra->tag);
+        }
+#endif
       SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
       api.metric = info->attr->med;
 
@@ -782,12 +752,20 @@
       api.flags = flags;
       api.type = ZEBRA_ROUTE_BGP;
       api.message = 0;
+
       SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
       api.nexthop_num = 1;
-      api.nexthop = &nexthop;
-      SET_FLAG (api.message, ZAPI_MESSAGE_IFINDEX);
-      api.ifindex_num = 1;
-      api.ifindex = &ifindex;
+      api.nexthop[0].type = ZEBRA_NEXTHOP_IPV6|ZEBRA_NEXTHOP_IFINDEX;
+      memcpy(&api.nexthop[0].gw.ipv6, nexthop, sizeof(*nexthop));
+      api.nexthop[0].intf.index = ifindex;
+#ifdef HAVE_MPLS
+      if (CHECK_FLAG (info->flags, BGP_INFO_MPLS))
+        {
+          SET_FLAG (api.nexthop[0].type, ZEBRA_NEXTHOP_MPLS);
+          api.nexthop[0].mpls.type = ZEBRA_MPLS_LABEL_GEN;
+          api.nexthop[0].mpls.u.gen = decode_label(info->extra->tag);
+        }
+#endif
       SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
       api.metric = info->attr->med;
 
@@ -842,10 +820,19 @@
 
       api.type = ZEBRA_ROUTE_BGP;
       api.message = 0;
+
       SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
       api.nexthop_num = 1;
-      api.nexthop = &nexthop;
-      api.ifindex_num = 0;
+      api.nexthop[0].type = ZEBRA_NEXTHOP_IPV4;
+      api.nexthop[0].gw.ipv4 = info->attr->nexthop;
+#ifdef HAVE_MPLS
+      if (CHECK_FLAG (info->flags, BGP_INFO_MPLS))
+        {
+          SET_FLAG (api.nexthop[0].type, ZEBRA_NEXTHOP_MPLS);
+          api.nexthop[0].mpls.type = ZEBRA_MPLS_LABEL_GEN;
+          api.nexthop[0].mpls.u.gen = decode_label(info->extra->tag);
+        }
+#endif
       SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
       api.metric = info->attr->med;
 
@@ -897,12 +884,20 @@
       api.flags = flags;
       api.type = ZEBRA_ROUTE_BGP;
       api.message = 0;
+
       SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
       api.nexthop_num = 1;
-      api.nexthop = &nexthop;
-      SET_FLAG (api.message, ZAPI_MESSAGE_IFINDEX);
-      api.ifindex_num = 1;
-      api.ifindex = &ifindex;
+      api.nexthop[0].type = ZEBRA_NEXTHOP_IPV6|ZEBRA_NEXTHOP_IFINDEX;
+      memcpy(&api.nexthop[0].gw.ipv6, nexthop, sizeof(*nexthop));
+      api.nexthop[0].intf.index = ifindex;
+#ifdef HAVE_MPLS
+      if (CHECK_FLAG (info->flags, BGP_INFO_MPLS))
+        {
+          SET_FLAG (api.nexthop[0].type, ZEBRA_NEXTHOP_MPLS);
+          api.nexthop[0].mpls.type = ZEBRA_MPLS_LABEL_GEN;
+          api.nexthop[0].mpls.u.gen = decode_label(info->extra->tag);
+        }
+#endif
       SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
       api.metric = info->attr->med;
 
diff -Naur quagga-0.99.10/config.h.in quagga-mpls/config.h.in
--- quagga-0.99.10/config.h.in	2008-06-10 22:54:56.000000000 +0200
+++ quagga-mpls/config.h.in	2008-11-25 12:30:18.000000000 +0100
@@ -187,6 +187,9 @@
 /* Define to 1 if you have the `memset' function. */
 #undef HAVE_MEMSET
 
+/* Enable MPLS */
+#undef HAVE_MPLS
+
 /* Define to 1 if you have the <netdb.h> header file. */
 #undef HAVE_NETDB_H
 
@@ -538,9 +541,15 @@
 /* KAME IPv6 stack */
 #undef KAME
 
+/* ldpd vty socket */
+#undef LDP_VTYSH_PATH
+
 /* Linux IPv6 stack */
 #undef LINUX_IPV6
 
+/* Linux MPLS */
+#undef LINUX_MPLS
+
 /* Mask for log files */
 #undef LOGFILE_MASK
 
@@ -590,6 +599,9 @@
 /* isisd PID */
 #undef PATH_ISISD_PID
 
+/* ldpd PID */
+#undef PATH_LDPD_PID
+
 /* ospf6d PID */
 #undef PATH_OSPF6D_PID
 
diff -Naur quagga-0.99.10/configure.ac quagga-mpls/configure.ac
--- quagga-0.99.10/configure.ac	2008-06-10 22:54:23.000000000 +0200
+++ quagga-mpls/configure.ac	2008-11-25 12:33:39.000000000 +0100
@@ -179,10 +179,16 @@
 dnl ----------------------
 AC_ARG_ENABLE(vtysh,
 [  --enable-vtysh          include integrated vty shell for Quagga])
+AC_ARG_ENABLE(mpls,
+[  --enable-mpls           turn on MPLS related features and daemons])
 AC_ARG_ENABLE(ipv6,
 [  --disable-ipv6          turn off IPv6 related features and daemons])
 AC_ARG_ENABLE(zebra,
 [  --disable-zebra         do not build zebra daemon])
+AC_ARG_ENABLE(ldpd,
+[  --disable-ldpd          do not build ldpd])
+AC_ARG_ENABLE(rsvpd,
+[  --disable-rsvpd         do not build rsvpd])
 AC_ARG_ENABLE(bgpd,
 [  --disable-bgpd          do not build bgpd])
 AC_ARG_ENABLE(ripd,
@@ -700,7 +706,7 @@
 if test x"$opsys" = x"gnu-linux"; then
   if test "${enable_netlink}" = "yes";then
     AC_MSG_RESULT(netlink)
-    RT_METHOD=rt_netlink.o
+    RT_METHOD="netlink.o rt_netlink.o"
     AC_DEFINE(HAVE_NETLINK,,netlink)
     netlink=yes
   elif test "${enable_netlink}" = "no"; then
@@ -709,7 +715,7 @@
     netlink=no
   else
     AC_MSG_RESULT(netlink)
-    RT_METHOD=rt_netlink.o
+    RT_METHOD="netlink.o rt_netlink.o"
     AC_DEFINE(HAVE_NETLINK,,netlink)
     netlink=yes
   fi
@@ -1115,6 +1121,39 @@
 #endif
 ])dnl
 
+dnl ----------
+dnl MPLS check
+dnl ----------
+MPLS_METHOD=""
+AC_MSG_CHECKING(whether this OS has MPLS stack)
+AM_CONDITIONAL(MPLS_ENABLED, test "x${enable_mpls}" != "xno")
+if test "${enable_mpls}" = "no"; then
+  enable_ldpd="no"
+  enable_rsvpd="no"
+  AC_MSG_RESULT(disabled)
+else
+  if test "x${enable_mpls}" = "xnull"; then
+    AC_DEFINE(HAVE_MPLS,1,Enable MPLS)
+    MPLS_METHOD="mpls_null.o"
+    AC_MSG_RESULT(MPLS Null)
+  else
+    AC_EGREP_CPP(yes, [
+	#include <linux/mpls.h>
+	#if MPLS_LINUX_VERSION
+	yes
+	#endif],
+	[AC_DEFINE(HAVE_MPLS,1,Enable MPLS)
+	 AC_DEFINE(LINUX_MPLS,1,Linux MPLS)
+	 MPLS_METHOD="mpls_netlink.o"
+	 AC_MSG_RESULT(MPLS Linux)],
+	[enable_ldpd="no"
+	 enable_rsvpd="no"
+	 AC_MSG_RESULT(no)]
+    )
+  fi
+fi
+AC_SUBST(MPLS_METHOD)
+
 dnl --------------------
 dnl Daemon disable check
 dnl --------------------
@@ -1142,6 +1181,18 @@
   OSPFD="ospfd"
 fi
 
+if test "${enable_ldpd}" = "no";then
+  LDPD=""
+else
+  LDPD="ldpd"
+fi
+
+if test "${enable_rsvpd}" = "no";then
+  RSVPD=""
+else
+  RSVPD="rsvpd"
+fi
+
 if test "${enable_watchquagga}" = "no";then
   WATCHQUAGGA=""
 else
@@ -1157,7 +1208,6 @@
       OSPFCLIENT="ospfclient"
     fi
   fi
-
 fi
 
 case "${enable_ripngd}" in
@@ -1191,6 +1241,8 @@
 
 AC_SUBST(ZEBRA)
 AC_SUBST(BGPD)
+AC_SUBST(LDPD)
+AC_SUBST(RSVPD)
 AC_SUBST(RIPD)
 AC_SUBST(RIPNGD)
 AC_SUBST(OSPFD)
@@ -1234,7 +1286,15 @@
     	[AC_DEFINE(HAVE_NETSNMP,,Net SNMP) 
     	 AC_DEFINE(HAVE_SNMP,,SNMP)
     	 LIBS="${LIBS} -lnetsnmp"],
-    	[AC_MSG_ERROR([--enable-snmp given, but cannot find support for SNMP])])
+    	[AC_CHECK_FILE(${SNMP_LIBDIR}/libnetsnmp.so,
+         [AC_DEFINE(HAVE_NETSNMP,,Net SNMP)
+         AC_DEFINE(HAVE_SNMP,,SNMP)
+         LIBS="${LIBS} ${SNMP_LIBDIR}/libnetsnmp.so"],
+         [AC_CHECK_FILE(${SNMP_LIBFILE},
+            [AC_DEFINE(HAVE_NETSNMP,,Net SNMP)
+            AC_DEFINE(HAVE_SNMP,,SNMP)
+            LIBS="${LIBS} ${SNMP_LIBFILE}"],
+            [AC_MSG_ERROR([--enable-snmp given, but cannot find support for SNMP])])])])
     
     for ac_snmp in /usr/include \
     		/usr/local/include \
@@ -1406,6 +1466,8 @@
 AC_DEFINE_UNQUOTED(PATH_ZEBRA_PID, "$quagga_statedir/zebra.pid",zebra PID)
 AC_DEFINE_UNQUOTED(PATH_RIPD_PID, "$quagga_statedir/ripd.pid",ripd PID)
 AC_DEFINE_UNQUOTED(PATH_RIPNGD_PID, "$quagga_statedir/ripngd.pid",ripngd PID)
+AC_DEFINE_UNQUOTED(PATH_LDPD_PID, "$quagga_statedir/ldpd.pid",ldpd PID)
+AC_DEFINE_UNQUOTED(PATH_RSVPD_PID, "$quagga_statedir/rsvpd.pid",rsvpd PID)
 AC_DEFINE_UNQUOTED(PATH_BGPD_PID, "$quagga_statedir/bgpd.pid",bgpd PID)
 AC_DEFINE_UNQUOTED(PATH_OSPFD_PID, "$quagga_statedir/ospfd.pid",ospfd PID)
 AC_DEFINE_UNQUOTED(PATH_OSPF6D_PID, "$quagga_statedir/ospf6d.pid",ospf6d PID)
@@ -1415,6 +1477,8 @@
 AC_DEFINE_UNQUOTED(ZEBRA_VTYSH_PATH, "$quagga_statedir/zebra.vty",zebra vty socket)
 AC_DEFINE_UNQUOTED(RIP_VTYSH_PATH, "$quagga_statedir/ripd.vty",rip vty socket)
 AC_DEFINE_UNQUOTED(RIPNG_VTYSH_PATH, "$quagga_statedir/ripngd.vty",ripng vty socket)
+AC_DEFINE_UNQUOTED(LDP_VTYSH_PATH, "$quagga_statedir/ldpd.vty",ldpd vty socket)
+AC_DEFINE_UNQUOTED(RSVP_VTYSH_PATH, "$quagga_statedir/rsvpd.vty",rsvpd vty socket)
 AC_DEFINE_UNQUOTED(BGP_VTYSH_PATH, "$quagga_statedir/bgpd.vty",bgpd vty socket)
 AC_DEFINE_UNQUOTED(OSPF_VTYSH_PATH, "$quagga_statedir/ospfd.vty",ospfd vty socket)
 AC_DEFINE_UNQUOTED(OSPF6_VTYSH_PATH, "$quagga_statedir/ospf6d.vty",ospf6d vty socket)
@@ -1442,6 +1506,8 @@
 
 AC_CONFIG_FILES([Makefile lib/Makefile zebra/Makefile ripd/Makefile 
 	  ripngd/Makefile bgpd/Makefile ospfd/Makefile watchquagga/Makefile
+	  ldpd/Makefile
+	  rsvpd/Makefile
 	  ospf6d/Makefile isisd/Makefile vtysh/Makefile doc/Makefile 
 	  ospfclient/Makefile tests/Makefile m4/Makefile redhat/Makefile
 	  pkgsrc/Makefile
diff -Naur quagga-0.99.10/include/linux/genetlink.h quagga-mpls/include/linux/genetlink.h
--- quagga-0.99.10/include/linux/genetlink.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/include/linux/genetlink.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,113 @@
+#ifndef __LINUX_GENERIC_NETLINK_H
+#define __LINUX_GENERIC_NETLINK_H
+
+#include <linux/netlink.h>
+
+#define GENL_NAMSIZ	16	/* length of family name */
+
+#define GENL_MIN_ID	NLMSG_MIN_TYPE
+#define GENL_MAX_ID	1023
+
+struct genlmsghdr {
+	__u8	cmd;
+	__u8	version;
+	__u16	reserved;
+};
+
+#define GENL_HDRLEN	NLMSG_ALIGN(sizeof(struct genlmsghdr))
+
+#define GENL_ADMIN_PERM		0x01
+#define GENL_CMD_CAP_DO		0x02
+#define GENL_CMD_CAP_DUMP	0x04
+#define GENL_CMD_CAP_HASPOL	0x08
+
+/*
+ * List of reserved static generic netlink identifiers:
+ */
+#define GENL_ID_GENERATE	0
+#define GENL_ID_CTRL		NLMSG_MIN_TYPE
+
+/**************************************************************************
+ * Controller
+ **************************************************************************/
+
+enum {
+	CTRL_CMD_UNSPEC,
+	CTRL_CMD_NEWFAMILY,
+	CTRL_CMD_DELFAMILY,
+	CTRL_CMD_GETFAMILY,
+	CTRL_CMD_NEWOPS,
+	CTRL_CMD_DELOPS,
+	CTRL_CMD_GETOPS,
+	CTRL_CMD_NEWMCAST_GRP,
+	CTRL_CMD_DELMCAST_GRP,
+	CTRL_CMD_GETMCAST_GRP, /* unused */
+	__CTRL_CMD_MAX,
+};
+
+#define CTRL_CMD_MAX (__CTRL_CMD_MAX - 1)
+
+enum {
+	CTRL_ATTR_UNSPEC,
+	CTRL_ATTR_FAMILY_ID,
+	CTRL_ATTR_FAMILY_NAME,
+	CTRL_ATTR_VERSION,
+	CTRL_ATTR_HDRSIZE,
+	CTRL_ATTR_MAXATTR,
+	CTRL_ATTR_OPS,
+	CTRL_ATTR_MCAST_GROUPS,
+	__CTRL_ATTR_MAX,
+};
+
+#define CTRL_ATTR_MAX (__CTRL_ATTR_MAX - 1)
+
+enum {
+	CTRL_ATTR_OP_UNSPEC,
+	CTRL_ATTR_OP_ID,
+	CTRL_ATTR_OP_FLAGS,
+	__CTRL_ATTR_OP_MAX,
+};
+
+#define CTRL_ATTR_OP_MAX (__CTRL_ATTR_OP_MAX - 1)
+
+enum {
+	CTRL_ATTR_MCAST_GRP_UNSPEC,
+	CTRL_ATTR_MCAST_GRP_NAME,
+	CTRL_ATTR_MCAST_GRP_ID,
+	__CTRL_ATTR_MCAST_GRP_MAX,
+};
+
+#define CTRL_ATTR_MCAST_GRP_MAX (__CTRL_ATTR_MCAST_GRP_MAX - 1)
+
+enum {
+	MPLS_CMD_UNSPEC,
+	MPLS_CMD_NEWILM,
+	MPLS_CMD_DELILM,
+	MPLS_CMD_GETILM,
+	MPLS_CMD_NEWNHLFE,
+	MPLS_CMD_DELNHLFE,
+	MPLS_CMD_GETNHLFE,
+	MPLS_CMD_NEWXC,
+	MPLS_CMD_DELXC,
+	MPLS_CMD_GETXC,
+	MPLS_CMD_SETLABELSPACE,
+	MPLS_CMD_GETLABELSPACE,
+	__MPLS_CMD_MAX,
+};
+
+#define MPLS_CMD_MAX (__MPLS_CMD_MAX - 1)
+
+enum {
+	MPLS_ATTR_UNSPEC,
+	MPLS_ATTR_ILM,
+	MPLS_ATTR_NHLFE,
+	MPLS_ATTR_XC,
+	MPLS_ATTR_LABELSPACE,
+	MPLS_ATTR_INSTR,
+	MPLS_ATTR_STATS,
+	__MPLS_ATTR_MAX,
+};
+
+#define MPLS_ATTR_MAX (__MPLS_ATTR_MAX - 1)
+
+#endif	/* __LINUX_GENERIC_NETLINK_H */
diff -Naur quagga-0.99.10/include/linux/mpls.h quagga-mpls/include/linux/mpls.h
--- quagga-0.99.10/include/linux/mpls.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/include/linux/mpls.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,248 @@
+/*****************************************************************************
+ * MPLS
+ *      An implementation of the MPLS (MultiProtocol Label
+ *      Switching Architecture) for Linux.
+ *
+ * Authors:
+ *          James Leu        <jleu@mindspring.com>
+ *          Ramon Casellas   <casellas@infres.enst.fr>
+ *
+ *   (c) 1999-2004   James Leu        <jleu@mindspring.com>
+ *   (c) 2003-2004   Ramon Casellas   <casellas@infres.enst.fr>
+ *
+ * include/linux/mpls.h
+ *      Data types and structs used by userspace programs to access MPLS
+ *      forwarding. Most interface with the MPLS subsystem is IOCTL based
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ ****************************************************************************/
+
+#ifndef _LINUX_MPLS_H_
+#define _LINUX_MPLS_H_
+
+#ifdef __KERNEL__
+#include <linux/socket.h>
+#include <linux/if.h>
+#else
+#include <sys/socket.h>
+#include <linux/types.h>
+#include <net/if.h>
+#endif
+
+#define MPLS_NUM_OPS		8
+
+#define MPLS_LINUX_VERSION	0x01090602
+
+#define	MPLS_GRP_ILM	1
+#define	MPLS_GRP_NHLFE	2
+#define	MPLS_GRP_XC	4
+#define	MPLS_GRP_LABELSPACE 8
+
+#define MPLS_IPV4_EXPLICIT_NULL	0       /* only valid as sole label stack entry
+					   Pop label and send to IPv4 stack */
+#define MPLS_ROUTER_ALERT	1       /* anywhere except bottom, packet it is
+					   forwared to a software module
+					   determined by the next label,
+					   if the packet is forwarded, push this
+					   label back on */
+#define MPLS_IPV6_EXPLICIT_NULL	2       /* only valid as sole label stack entry
+					   Pop label and send to IPv6 stack */
+#define MPLS_IMPLICIT_NULL	3       /* a LIB with this, signifies to pop
+					   the next label and use that */
+
+#define MPLS_CHANGE_MTU		0x01
+#define MPLS_CHANGE_PROP_TTL	0x02
+#define MPLS_CHANGE_INSTR	0x04
+#define MPLS_CHANGE_PROTO	0x10
+
+enum mpls_dir {
+	MPLS_IN = 0x10,
+	MPLS_OUT = 0x20
+};
+
+enum mpls_opcode_enum {
+	MPLS_OP_NOP = 0x00,
+	MPLS_OP_POP,
+	MPLS_OP_PEEK,
+	MPLS_OP_PUSH,
+	MPLS_OP_DLV,
+	MPLS_OP_FWD,
+	MPLS_OP_NF_FWD,
+	MPLS_OP_DS_FWD,
+	MPLS_OP_EXP_FWD,
+	MPLS_OP_SET,
+	MPLS_OP_SET_RX,
+	MPLS_OP_SET_TC,
+	MPLS_OP_SET_DS,
+	MPLS_OP_SET_EXP,
+	MPLS_OP_EXP2TC,
+	MPLS_OP_EXP2DS,
+	MPLS_OP_TC2EXP,
+	MPLS_OP_DS2EXP,
+	MPLS_OP_NF2EXP,
+	MPLS_OP_SET_NF,
+	MPLS_OP_MAX
+};
+
+enum mpls_label_type_enum {
+	MPLS_LABEL_GEN = 1,
+	MPLS_LABEL_ATM,
+	MPLS_LABEL_FR,
+	MPLS_LABEL_KEY
+};
+
+struct mpls_label_atm {
+	u_int16_t  mla_vpi;
+	u_int16_t  mla_vci;
+};
+
+struct mpls_label {
+	enum mpls_label_type_enum ml_type;
+	union {
+		u_int32_t ml_key;
+		u_int32_t ml_gen;
+		u_int32_t ml_fr;
+		struct mpls_label_atm ml_atm;
+	} u;
+	int ml_index;
+};
+
+struct mpls_in_label_req {
+	unsigned int      mil_proto;
+	struct mpls_label mil_label;
+	unsigned char     mil_change_flag;
+};
+
+#define MPLS_LABELSPACE_MAX	255
+
+struct mpls_labelspace_req {
+	int mls_ifindex;                  /* Index to the MPLS-enab. interface*/
+	int mls_labelspace;               /* Labelspace IN/SET -- OUT/GET     */
+};
+
+struct mpls_nexthop_info {
+	unsigned int    mni_if;
+	struct sockaddr mni_addr;
+};
+
+struct mpls_out_label_req {
+	struct mpls_label mol_label;
+	u_int32_t         mol_mtu;
+	int8_t            mol_propagate_ttl;
+	unsigned char     mol_change_flag;
+};
+
+struct mpls_xconnect_req {
+	struct mpls_label mx_in;
+	struct mpls_label mx_out;
+};
+
+struct mpls_tunnel_req {
+	char mt_ifname[IFNAMSIZ];
+	unsigned int mt_nhlfe_key;
+};
+
+#define MPLS_NFMARK_NUM 64
+
+struct mpls_nfmark_fwd {
+	unsigned int nf_key[MPLS_NFMARK_NUM];
+	unsigned short nf_mask;
+};
+
+#define MPLS_DSMARK_NUM 64
+
+struct mpls_dsmark_fwd {
+	unsigned int df_key[MPLS_DSMARK_NUM];
+	unsigned char df_mask;
+};
+
+#define MPLS_TCINDEX_NUM 64
+
+struct mpls_tcindex_fwd {
+	unsigned int tc_key[MPLS_TCINDEX_NUM];
+	unsigned short tc_mask;
+};
+
+#define MPLS_EXP_NUM 8
+
+struct mpls_exp_fwd {
+	unsigned int ef_key[MPLS_EXP_NUM];
+};
+
+struct mpls_exp2tcindex {
+	unsigned short e2t[MPLS_EXP_NUM];
+};
+
+struct mpls_exp2dsmark {
+	unsigned char e2d[MPLS_EXP_NUM];
+};
+
+struct mpls_tcindex2exp {
+	unsigned char t2e_mask;
+	unsigned char t2e[MPLS_TCINDEX_NUM];
+};
+
+struct mpls_dsmark2exp {
+	unsigned char d2e_mask;
+	unsigned char d2e[MPLS_DSMARK_NUM];
+};
+
+struct mpls_nfmark2exp {
+	unsigned char n2e_mask;
+	unsigned char n2e[MPLS_NFMARK_NUM];
+};
+
+struct mpls_instr_elem {
+	unsigned short mir_opcode;
+	unsigned char mir_direction;
+	union {
+		struct mpls_label        push;
+		struct mpls_label        fwd;
+		struct mpls_nfmark_fwd   nf_fwd;
+		struct mpls_dsmark_fwd   ds_fwd;
+		struct mpls_exp_fwd      exp_fwd;
+		struct mpls_nexthop_info set;
+		unsigned int             set_rx;
+		unsigned short           set_tc;
+		unsigned short           set_ds;
+		unsigned char            set_exp;
+		struct mpls_exp2tcindex  exp2tc;
+		struct mpls_exp2dsmark   exp2ds;
+		struct mpls_tcindex2exp  tc2exp;
+		struct mpls_dsmark2exp   ds2exp;
+		struct mpls_nfmark2exp   nf2exp;
+		unsigned long            set_nf;
+	} mir_data;
+};
+
+/* Standard shortcuts */
+#define mir_push       mir_data.push
+#define mir_fwd        mir_data.fwd
+#define mir_nf_fwd     mir_data.nf_fwd
+#define mir_ds_fwd     mir_data.ds_fwd
+#define mir_exp_fwd    mir_data.exp_fwd
+#define mir_set        mir_data.set
+#define mir_set_rx     mir_data.set_rx
+#define mir_set_tc     mir_data.set_tc
+#define mir_set_tx     mir_data.set_tx
+#define mir_set_ds     mir_data.set_ds
+#define mir_set_exp    mir_data.set_exp
+#define mir_set_nf     mir_data.set_nf
+#define mir_exp2tc     mir_data.exp2tc
+#define mir_exp2ds     mir_data.exp2ds
+#define mir_tc2exp     mir_data.tc2exp
+#define mir_ds2exp     mir_data.ds2exp
+#define mir_nf2exp     mir_data.nf2exp
+
+struct mpls_instr_req {
+	struct mpls_instr_elem       mir_instr[MPLS_NUM_OPS];
+	unsigned char                mir_instr_length;
+	unsigned char                mir_direction;
+	int                          mir_index;
+	struct mpls_label            mir_label;
+};
+
+#endif
diff -Naur quagga-0.99.10/include/linux/rtnetlink.h quagga-mpls/include/linux/rtnetlink.h
--- quagga-0.99.10/include/linux/rtnetlink.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/include/linux/rtnetlink.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,775 @@
+#ifndef __LINUX_RTNETLINK_H
+#define __LINUX_RTNETLINK_H
+
+#include <linux/netlink.h>
+#include <linux/if_link.h>
+#include <linux/if_addr.h>
+#include <linux/neighbour.h>
+
+/****
+ *		Routing/neighbour discovery messages.
+ ****/
+
+/* Types of messages */
+
+enum {
+	RTM_BASE	= 16,
+#define RTM_BASE	RTM_BASE
+
+	RTM_NEWLINK	= 16,
+#define RTM_NEWLINK	RTM_NEWLINK
+	RTM_DELLINK,
+#define RTM_DELLINK	RTM_DELLINK
+	RTM_GETLINK,
+#define RTM_GETLINK	RTM_GETLINK
+	RTM_SETLINK,
+#define RTM_SETLINK	RTM_SETLINK
+
+	RTM_NEWADDR	= 20,
+#define RTM_NEWADDR	RTM_NEWADDR
+	RTM_DELADDR,
+#define RTM_DELADDR	RTM_DELADDR
+	RTM_GETADDR,
+#define RTM_GETADDR	RTM_GETADDR
+
+	RTM_NEWROUTE	= 24,
+#define RTM_NEWROUTE	RTM_NEWROUTE
+	RTM_DELROUTE,
+#define RTM_DELROUTE	RTM_DELROUTE
+	RTM_GETROUTE,
+#define RTM_GETROUTE	RTM_GETROUTE
+
+	RTM_NEWNEIGH	= 28,
+#define RTM_NEWNEIGH	RTM_NEWNEIGH
+	RTM_DELNEIGH,
+#define RTM_DELNEIGH	RTM_DELNEIGH
+	RTM_GETNEIGH,
+#define RTM_GETNEIGH	RTM_GETNEIGH
+
+	RTM_NEWRULE	= 32,
+#define RTM_NEWRULE	RTM_NEWRULE
+	RTM_DELRULE,
+#define RTM_DELRULE	RTM_DELRULE
+	RTM_GETRULE,
+#define RTM_GETRULE	RTM_GETRULE
+
+	RTM_NEWQDISC	= 36,
+#define RTM_NEWQDISC	RTM_NEWQDISC
+	RTM_DELQDISC,
+#define RTM_DELQDISC	RTM_DELQDISC
+	RTM_GETQDISC,
+#define RTM_GETQDISC	RTM_GETQDISC
+
+	RTM_NEWTCLASS	= 40,
+#define RTM_NEWTCLASS	RTM_NEWTCLASS
+	RTM_DELTCLASS,
+#define RTM_DELTCLASS	RTM_DELTCLASS
+	RTM_GETTCLASS,
+#define RTM_GETTCLASS	RTM_GETTCLASS
+
+	RTM_NEWTFILTER	= 44,
+#define RTM_NEWTFILTER	RTM_NEWTFILTER
+	RTM_DELTFILTER,
+#define RTM_DELTFILTER	RTM_DELTFILTER
+	RTM_GETTFILTER,
+#define RTM_GETTFILTER	RTM_GETTFILTER
+
+	RTM_NEWACTION	= 48,
+#define RTM_NEWACTION   RTM_NEWACTION
+	RTM_DELACTION,
+#define RTM_DELACTION   RTM_DELACTION
+	RTM_GETACTION,
+#define RTM_GETACTION   RTM_GETACTION
+
+	RTM_NEWPREFIX	= 52,
+#define RTM_NEWPREFIX	RTM_NEWPREFIX
+
+	RTM_GETMULTICAST = 58,
+#define RTM_GETMULTICAST RTM_GETMULTICAST
+
+	RTM_GETANYCAST	= 62,
+#define RTM_GETANYCAST	RTM_GETANYCAST
+
+	RTM_NEWNEIGHTBL	= 64,
+#define RTM_NEWNEIGHTBL	RTM_NEWNEIGHTBL
+	RTM_GETNEIGHTBL	= 66,
+#define RTM_GETNEIGHTBL	RTM_GETNEIGHTBL
+	RTM_SETNEIGHTBL,
+#define RTM_SETNEIGHTBL	RTM_SETNEIGHTBL
+
+	RTM_NEWNDUSEROPT = 68,
+#define RTM_NEWNDUSEROPT RTM_NEWNDUSEROPT
+
+	RTM_NEWADDRLABEL = 72,
+#define RTM_NEWADDRLABEL RTM_NEWADDRLABEL
+	RTM_DELADDRLABEL,
+#define RTM_NEWADDRLABEL RTM_NEWADDRLABEL
+	RTM_GETADDRLABEL,
+#define RTM_GETADDRLABEL RTM_GETADDRLABEL
+
+	__RTM_MAX,
+#define RTM_MAX		(((__RTM_MAX + 3) & ~3) - 1)
+};
+
+#define RTM_NR_MSGTYPES	(RTM_MAX + 1 - RTM_BASE)
+#define RTM_NR_FAMILIES	(RTM_NR_MSGTYPES >> 2)
+#define RTM_FAM(cmd)	(((cmd) - RTM_BASE) >> 2)
+
+/* 
+   Generic structure for encapsulation of optional route information.
+   It is reminiscent of sockaddr, but with sa_family replaced
+   with attribute type.
+ */
+
+struct rtattr
+{
+	unsigned short	rta_len;
+	unsigned short	rta_type;
+};
+
+/* Macros to handle rtattributes */
+
+#define RTA_ALIGNTO	4
+#define RTA_ALIGN(len) ( ((len)+RTA_ALIGNTO-1) & ~(RTA_ALIGNTO-1) )
+#define RTA_OK(rta,len) ((len) >= (int)sizeof(struct rtattr) && \
+			 (rta)->rta_len >= sizeof(struct rtattr) && \
+			 (rta)->rta_len <= (len))
+#define RTA_NEXT(rta,attrlen)	((attrlen) -= RTA_ALIGN((rta)->rta_len), \
+				 (struct rtattr*)(((char*)(rta)) + RTA_ALIGN((rta)->rta_len)))
+#define RTA_LENGTH(len)	(RTA_ALIGN(sizeof(struct rtattr)) + (len))
+#define RTA_SPACE(len)	RTA_ALIGN(RTA_LENGTH(len))
+#define RTA_DATA(rta)   ((void*)(((char*)(rta)) + RTA_LENGTH(0)))
+#define RTA_PAYLOAD(rta) ((int)((rta)->rta_len) - RTA_LENGTH(0))
+
+
+
+
+/******************************************************************************
+ *		Definitions used in routing table administration.
+ ****/
+
+struct rtmsg
+{
+	unsigned char		rtm_family;
+	unsigned char		rtm_dst_len;
+	unsigned char		rtm_src_len;
+	unsigned char		rtm_tos;
+
+	unsigned char		rtm_table;	/* Routing table id */
+	unsigned char		rtm_protocol;	/* Routing protocol; see below	*/
+	unsigned char		rtm_scope;	/* See below */	
+	unsigned char		rtm_type;	/* See below	*/
+
+	unsigned		rtm_flags;
+};
+
+/* rtm_type */
+
+enum
+{
+	RTN_UNSPEC,
+	RTN_UNICAST,		/* Gateway or direct route	*/
+	RTN_LOCAL,		/* Accept locally		*/
+	RTN_BROADCAST,		/* Accept locally as broadcast,
+				   send as broadcast */
+	RTN_ANYCAST,		/* Accept locally as broadcast,
+				   but send as unicast */
+	RTN_MULTICAST,		/* Multicast route		*/
+	RTN_BLACKHOLE,		/* Drop				*/
+	RTN_UNREACHABLE,	/* Destination is unreachable   */
+	RTN_PROHIBIT,		/* Administratively prohibited	*/
+	RTN_THROW,		/* Not in this table		*/
+	RTN_NAT,		/* Translate this address	*/
+	RTN_XRESOLVE,		/* Use external resolver	*/
+	__RTN_MAX
+};
+
+#define RTN_MAX (__RTN_MAX - 1)
+
+
+/* rtm_protocol */
+
+#define RTPROT_UNSPEC	0
+#define RTPROT_REDIRECT	1	/* Route installed by ICMP redirects;
+				   not used by current IPv4 */
+#define RTPROT_KERNEL	2	/* Route installed by kernel		*/
+#define RTPROT_BOOT	3	/* Route installed during boot		*/
+#define RTPROT_STATIC	4	/* Route installed by administrator	*/
+
+/* Values of protocol >= RTPROT_STATIC are not interpreted by kernel;
+   they are just passed from user and back as is.
+   It will be used by hypothetical multiple routing daemons.
+   Note that protocol values should be standardized in order to
+   avoid conflicts.
+ */
+
+#define RTPROT_GATED	8	/* Apparently, GateD */
+#define RTPROT_RA	9	/* RDISC/ND router advertisements */
+#define RTPROT_MRT	10	/* Merit MRT */
+#define RTPROT_ZEBRA	11	/* Zebra */
+#define RTPROT_BIRD	12	/* BIRD */
+#define RTPROT_DNROUTED	13	/* DECnet routing daemon */
+#define RTPROT_XORP	14	/* XORP */
+#define RTPROT_NTK	15	/* Netsukuku */
+
+/* rtm_scope
+
+   Really it is not scope, but sort of distance to the destination.
+   NOWHERE are reserved for not existing destinations, HOST is our
+   local addresses, LINK are destinations, located on directly attached
+   link and UNIVERSE is everywhere in the Universe.
+
+   Intermediate values are also possible f.e. interior routes
+   could be assigned a value between UNIVERSE and LINK.
+*/
+
+enum rt_scope_t
+{
+	RT_SCOPE_UNIVERSE=0,
+/* User defined values  */
+	RT_SCOPE_SITE=200,
+	RT_SCOPE_LINK=253,
+	RT_SCOPE_HOST=254,
+	RT_SCOPE_NOWHERE=255
+};
+
+/* rtm_flags */
+
+#define RTM_F_NOTIFY		0x100	/* Notify user of route change	*/
+#define RTM_F_CLONED		0x200	/* This route is cloned		*/
+#define RTM_F_EQUALIZE		0x400	/* Multipath equalizer: NI	*/
+#define RTM_F_PREFIX		0x800	/* Prefix addresses		*/
+
+/* Reserved table identifiers */
+
+enum rt_class_t
+{
+	RT_TABLE_UNSPEC=0,
+/* User defined values */
+	RT_TABLE_COMPAT=252,
+	RT_TABLE_DEFAULT=253,
+	RT_TABLE_MAIN=254,
+	RT_TABLE_LOCAL=255,
+	RT_TABLE_MAX=0xFFFFFFFF
+};
+
+
+/* Routing message attributes */
+
+enum rtattr_type_t
+{
+	RTA_UNSPEC,
+	RTA_DST,
+	RTA_SRC,
+	RTA_IIF,
+	RTA_OIF,
+	RTA_GATEWAY,
+	RTA_PRIORITY,
+	RTA_PREFSRC,
+	RTA_METRICS,
+	RTA_MULTIPATH,
+	RTA_PROTOINFO, /* no longer used */
+	RTA_FLOW,
+	RTA_CACHEINFO,
+	RTA_SESSION, /* no longer used */
+	RTA_MP_ALGO, /* no longer used */
+	RTA_TABLE,
+	RTA_SHIM = 30,
+	__RTA_MAX
+};
+
+#define RTA_MAX (__RTA_MAX - 1)
+
+#define RTM_RTA(r)  ((struct rtattr*)(((char*)(r)) + NLMSG_ALIGN(sizeof(struct rtmsg))))
+#define RTM_PAYLOAD(n) NLMSG_PAYLOAD(n,sizeof(struct rtmsg))
+
+/* RTM_MULTIPATH --- array of struct rtnexthop.
+ *
+ * "struct rtnexthop" describes all necessary nexthop information,
+ * i.e. parameters of path to a destination via this nexthop.
+ *
+ * At the moment it is impossible to set different prefsrc, mtu, window
+ * and rtt for different paths from multipath.
+ */
+
+struct rtnexthop
+{
+	unsigned short		rtnh_len;
+	unsigned char		rtnh_flags;
+	unsigned char		rtnh_hops;
+	int			rtnh_ifindex;
+};
+
+/* rtnh_flags */
+
+#define RTNH_F_DEAD		1	/* Nexthop is dead (used by multipath)	*/
+#define RTNH_F_PERVASIVE	2	/* Do recursive gateway lookup	*/
+#define RTNH_F_ONLINK		4	/* Gateway is forced on link	*/
+
+/* Macros to handle hexthops */
+
+#define RTNH_ALIGNTO	4
+#define RTNH_ALIGN(len) ( ((len)+RTNH_ALIGNTO-1) & ~(RTNH_ALIGNTO-1) )
+#define RTNH_OK(rtnh,len) ((rtnh)->rtnh_len >= sizeof(struct rtnexthop) && \
+			   ((int)(rtnh)->rtnh_len) <= (len))
+#define RTNH_NEXT(rtnh)	((struct rtnexthop*)(((char*)(rtnh)) + RTNH_ALIGN((rtnh)->rtnh_len)))
+#define RTNH_LENGTH(len) (RTNH_ALIGN(sizeof(struct rtnexthop)) + (len))
+#define RTNH_SPACE(len)	RTNH_ALIGN(RTNH_LENGTH(len))
+#define RTNH_DATA(rtnh)   ((struct rtattr*)(((char*)(rtnh)) + RTNH_LENGTH(0)))
+
+/* RTM_CACHEINFO */
+
+struct rta_cacheinfo
+{
+	__u32	rta_clntref;
+	__u32	rta_lastuse;
+	__s32	rta_expires;
+	__u32	rta_error;
+	__u32	rta_used;
+
+#define RTNETLINK_HAVE_PEERINFO 1
+	__u32	rta_id;
+	__u32	rta_ts;
+	__u32	rta_tsage;
+};
+
+/* RTM_METRICS --- array of struct rtattr with types of RTAX_* */
+
+enum
+{
+	RTAX_UNSPEC,
+#define RTAX_UNSPEC RTAX_UNSPEC
+	RTAX_LOCK,
+#define RTAX_LOCK RTAX_LOCK
+	RTAX_MTU,
+#define RTAX_MTU RTAX_MTU
+	RTAX_WINDOW,
+#define RTAX_WINDOW RTAX_WINDOW
+	RTAX_RTT,
+#define RTAX_RTT RTAX_RTT
+	RTAX_RTTVAR,
+#define RTAX_RTTVAR RTAX_RTTVAR
+	RTAX_SSTHRESH,
+#define RTAX_SSTHRESH RTAX_SSTHRESH
+	RTAX_CWND,
+#define RTAX_CWND RTAX_CWND
+	RTAX_ADVMSS,
+#define RTAX_ADVMSS RTAX_ADVMSS
+	RTAX_REORDERING,
+#define RTAX_REORDERING RTAX_REORDERING
+	RTAX_HOPLIMIT,
+#define RTAX_HOPLIMIT RTAX_HOPLIMIT
+	RTAX_INITCWND,
+#define RTAX_INITCWND RTAX_INITCWND
+	RTAX_FEATURES,
+#define RTAX_FEATURES RTAX_FEATURES
+	RTAX_RTO_MIN,
+#define RTAX_RTO_MIN RTAX_RTO_MIN
+	__RTAX_MAX
+};
+
+#define RTAX_MAX (__RTAX_MAX - 1)
+
+#define RTAX_FEATURE_ECN	0x00000001
+#define RTAX_FEATURE_SACK	0x00000002
+#define RTAX_FEATURE_TIMESTAMP	0x00000004
+#define RTAX_FEATURE_ALLFRAG	0x00000008
+
+struct rta_session
+{
+	__u8	proto;
+	__u8	pad1;
+	__u16	pad2;
+
+	union {
+		struct {
+			__u16	sport;
+			__u16	dport;
+		} ports;
+
+		struct {
+			__u8	type;
+			__u8	code;
+			__u16	ident;
+		} icmpt;
+
+		__u32		spi;
+	} u;
+};
+
+/****
+ *		General form of address family dependent message.
+ ****/
+
+struct rtgenmsg
+{
+	unsigned char		rtgen_family;
+};
+
+/*****************************************************************
+ *		Link layer specific messages.
+ ****/
+
+/* struct ifinfomsg
+ * passes link level specific information, not dependent
+ * on network protocol.
+ */
+
+struct ifinfomsg
+{
+	unsigned char	ifi_family;
+	unsigned char	__ifi_pad;
+	unsigned short	ifi_type;		/* ARPHRD_* */
+	int		ifi_index;		/* Link index	*/
+	unsigned	ifi_flags;		/* IFF_* flags	*/
+	unsigned	ifi_change;		/* IFF_* change mask */
+};
+
+/********************************************************************
+ *		prefix information 
+ ****/
+
+struct prefixmsg
+{
+	unsigned char	prefix_family;
+	unsigned char	prefix_pad1;
+	unsigned short	prefix_pad2;
+	int		prefix_ifindex;
+	unsigned char	prefix_type;
+	unsigned char	prefix_len;
+	unsigned char	prefix_flags;
+	unsigned char	prefix_pad3;
+};
+
+enum 
+{
+	PREFIX_UNSPEC,
+	PREFIX_ADDRESS,
+	PREFIX_CACHEINFO,
+	__PREFIX_MAX
+};
+
+#define PREFIX_MAX	(__PREFIX_MAX - 1)
+
+struct prefix_cacheinfo
+{
+	__u32	preferred_time;
+	__u32	valid_time;
+};
+
+
+/*****************************************************************
+ *		Traffic control messages.
+ ****/
+
+struct tcmsg
+{
+	unsigned char	tcm_family;
+	unsigned char	tcm__pad1;
+	unsigned short	tcm__pad2;
+	int		tcm_ifindex;
+	__u32		tcm_handle;
+	__u32		tcm_parent;
+	__u32		tcm_info;
+};
+
+enum
+{
+	TCA_UNSPEC,
+	TCA_KIND,
+	TCA_OPTIONS,
+	TCA_STATS,
+	TCA_XSTATS,
+	TCA_RATE,
+	TCA_FCNT,
+	TCA_STATS2,
+	__TCA_MAX
+};
+
+#define TCA_MAX (__TCA_MAX - 1)
+
+#define TCA_RTA(r)  ((struct rtattr*)(((char*)(r)) + NLMSG_ALIGN(sizeof(struct tcmsg))))
+#define TCA_PAYLOAD(n) NLMSG_PAYLOAD(n,sizeof(struct tcmsg))
+
+/********************************************************************
+ *		Neighbor Discovery userland options
+ ****/
+
+struct nduseroptmsg
+{
+	unsigned char	nduseropt_family;
+	unsigned char	nduseropt_pad1;
+	unsigned short	nduseropt_opts_len;	/* Total length of options */
+	int		nduseropt_ifindex;
+	__u8		nduseropt_icmp_type;
+	__u8		nduseropt_icmp_code;
+	unsigned short	nduseropt_pad2;
+	unsigned int	nduseropt_pad3;
+	/* Followed by one or more ND options */
+};
+
+enum
+{
+	NDUSEROPT_UNSPEC,
+	NDUSEROPT_SRCADDR,
+	__NDUSEROPT_MAX
+};
+
+#define NDUSEROPT_MAX	(__NDUSEROPT_MAX - 1)
+
+#ifndef __KERNEL__
+/* RTnetlink multicast groups - backwards compatibility for userspace */
+#define RTMGRP_LINK		1
+#define RTMGRP_NOTIFY		2
+#define RTMGRP_NEIGH		4
+#define RTMGRP_TC		8
+
+#define RTMGRP_IPV4_IFADDR	0x10
+#define RTMGRP_IPV4_MROUTE	0x20
+#define RTMGRP_IPV4_ROUTE	0x40
+#define RTMGRP_IPV4_RULE	0x80
+
+#define RTMGRP_IPV6_IFADDR	0x100
+#define RTMGRP_IPV6_MROUTE	0x200
+#define RTMGRP_IPV6_ROUTE	0x400
+#define RTMGRP_IPV6_IFINFO	0x800
+
+#define RTMGRP_DECnet_IFADDR    0x1000
+#define RTMGRP_DECnet_ROUTE     0x4000
+
+#define RTMGRP_IPV6_PREFIX	0x20000
+#endif
+
+/* RTnetlink multicast groups */
+enum rtnetlink_groups {
+	RTNLGRP_NONE,
+#define RTNLGRP_NONE		RTNLGRP_NONE
+	RTNLGRP_LINK,
+#define RTNLGRP_LINK		RTNLGRP_LINK
+	RTNLGRP_NOTIFY,
+#define RTNLGRP_NOTIFY		RTNLGRP_NOTIFY
+	RTNLGRP_NEIGH,
+#define RTNLGRP_NEIGH		RTNLGRP_NEIGH
+	RTNLGRP_TC,
+#define RTNLGRP_TC		RTNLGRP_TC
+	RTNLGRP_IPV4_IFADDR,
+#define RTNLGRP_IPV4_IFADDR	RTNLGRP_IPV4_IFADDR
+	RTNLGRP_IPV4_MROUTE,
+#define	RTNLGRP_IPV4_MROUTE	RTNLGRP_IPV4_MROUTE
+	RTNLGRP_IPV4_ROUTE,
+#define RTNLGRP_IPV4_ROUTE	RTNLGRP_IPV4_ROUTE
+	RTNLGRP_IPV4_RULE,
+#define RTNLGRP_IPV4_RULE	RTNLGRP_IPV4_RULE
+	RTNLGRP_IPV6_IFADDR,
+#define RTNLGRP_IPV6_IFADDR	RTNLGRP_IPV6_IFADDR
+	RTNLGRP_IPV6_MROUTE,
+#define RTNLGRP_IPV6_MROUTE	RTNLGRP_IPV6_MROUTE
+	RTNLGRP_IPV6_ROUTE,
+#define RTNLGRP_IPV6_ROUTE	RTNLGRP_IPV6_ROUTE
+	RTNLGRP_IPV6_IFINFO,
+#define RTNLGRP_IPV6_IFINFO	RTNLGRP_IPV6_IFINFO
+	RTNLGRP_DECnet_IFADDR,
+#define RTNLGRP_DECnet_IFADDR	RTNLGRP_DECnet_IFADDR
+	RTNLGRP_NOP2,
+	RTNLGRP_DECnet_ROUTE,
+#define RTNLGRP_DECnet_ROUTE	RTNLGRP_DECnet_ROUTE
+	RTNLGRP_DECnet_RULE,
+#define RTNLGRP_DECnet_RULE	RTNLGRP_DECnet_RULE
+	RTNLGRP_NOP4,
+	RTNLGRP_IPV6_PREFIX,
+#define RTNLGRP_IPV6_PREFIX	RTNLGRP_IPV6_PREFIX
+	RTNLGRP_IPV6_RULE,
+#define RTNLGRP_IPV6_RULE	RTNLGRP_IPV6_RULE
+	RTNLGRP_ND_USEROPT,
+#define RTNLGRP_ND_USEROPT	RTNLGRP_ND_USEROPT
+	__RTNLGRP_MAX
+};
+#define RTNLGRP_MAX	(__RTNLGRP_MAX - 1)
+
+/* TC action piece */
+struct tcamsg
+{
+	unsigned char	tca_family;
+	unsigned char	tca__pad1;
+	unsigned short	tca__pad2;
+};
+#define TA_RTA(r)  ((struct rtattr*)(((char*)(r)) + NLMSG_ALIGN(sizeof(struct tcamsg))))
+#define TA_PAYLOAD(n) NLMSG_PAYLOAD(n,sizeof(struct tcamsg))
+#define TCA_ACT_TAB 1 /* attr type must be >=1 */	
+#define TCAA_MAX 1
+
+/* End of information exported to user level */
+
+#ifdef __KERNEL__
+
+#include <linux/mutex.h>
+
+static __inline__ int rtattr_strcmp(const struct rtattr *rta, const char *str)
+{
+	int len = strlen(str) + 1;
+	return len > rta->rta_len || memcmp(RTA_DATA(rta), str, len);
+}
+
+extern int rtnetlink_send(struct sk_buff *skb, struct net *net, u32 pid, u32 group, int echo);
+extern int rtnl_unicast(struct sk_buff *skb, struct net *net, u32 pid);
+extern int rtnl_notify(struct sk_buff *skb, struct net *net, u32 pid, u32 group,
+		       struct nlmsghdr *nlh, gfp_t flags);
+extern void rtnl_set_sk_err(struct net *net, u32 group, int error);
+extern int rtnetlink_put_metrics(struct sk_buff *skb, u32 *metrics);
+extern int rtnl_put_cacheinfo(struct sk_buff *skb, struct dst_entry *dst,
+			      u32 id, u32 ts, u32 tsage, long expires,
+			      u32 error);
+
+extern void __rta_fill(struct sk_buff *skb, int attrtype, int attrlen, const void *data);
+
+#define RTA_PUT(skb, attrtype, attrlen, data) \
+({	if (unlikely(skb_tailroom(skb) < (int)RTA_SPACE(attrlen))) \
+		 goto rtattr_failure; \
+   	__rta_fill(skb, attrtype, attrlen, data); }) 
+
+#define RTA_APPEND(skb, attrlen, data) \
+({	if (unlikely(skb_tailroom(skb) < (int)(attrlen))) \
+		goto rtattr_failure; \
+	memcpy(skb_put(skb, attrlen), data, attrlen); })
+
+#define RTA_PUT_NOHDR(skb, attrlen, data) \
+({	RTA_APPEND(skb, RTA_ALIGN(attrlen), data); \
+	memset(skb_tail_pointer(skb) - (RTA_ALIGN(attrlen) - attrlen), 0, \
+	       RTA_ALIGN(attrlen) - attrlen); })
+
+#define RTA_PUT_U8(skb, attrtype, value) \
+({	u8 _tmp = (value); \
+	RTA_PUT(skb, attrtype, sizeof(u8), &_tmp); })
+
+#define RTA_PUT_U16(skb, attrtype, value) \
+({	u16 _tmp = (value); \
+	RTA_PUT(skb, attrtype, sizeof(u16), &_tmp); })
+
+#define RTA_PUT_U32(skb, attrtype, value) \
+({	u32 _tmp = (value); \
+	RTA_PUT(skb, attrtype, sizeof(u32), &_tmp); })
+
+#define RTA_PUT_U64(skb, attrtype, value) \
+({	u64 _tmp = (value); \
+	RTA_PUT(skb, attrtype, sizeof(u64), &_tmp); })
+
+#define RTA_PUT_SECS(skb, attrtype, value) \
+	RTA_PUT_U64(skb, attrtype, (value) / HZ)
+
+#define RTA_PUT_MSECS(skb, attrtype, value) \
+	RTA_PUT_U64(skb, attrtype, jiffies_to_msecs(value))
+
+#define RTA_PUT_STRING(skb, attrtype, value) \
+	RTA_PUT(skb, attrtype, strlen(value) + 1, value)
+
+#define RTA_PUT_FLAG(skb, attrtype) \
+	RTA_PUT(skb, attrtype, 0, NULL);
+
+#define RTA_NEST(skb, type) \
+({	struct rtattr *__start = (struct rtattr *)skb_tail_pointer(skb); \
+	RTA_PUT(skb, type, 0, NULL); \
+	__start;  })
+
+#define RTA_NEST_END(skb, start) \
+({	(start)->rta_len = skb_tail_pointer(skb) - (unsigned char *)(start); \
+	(skb)->len; })
+
+#define RTA_NEST_COMPAT(skb, type, attrlen, data) \
+({	struct rtattr *__start = (struct rtattr *)skb_tail_pointer(skb); \
+	RTA_PUT(skb, type, attrlen, data); \
+	RTA_NEST(skb, type); \
+	__start; })
+
+#define RTA_NEST_COMPAT_END(skb, start) \
+({	struct rtattr *__nest = (void *)(start) + NLMSG_ALIGN((start)->rta_len); \
+	(start)->rta_len = skb_tail_pointer(skb) - (unsigned char *)(start); \
+	RTA_NEST_END(skb, __nest); \
+	(skb)->len; })
+
+#define RTA_NEST_CANCEL(skb, start) \
+({	if (start) \
+		skb_trim(skb, (unsigned char *) (start) - (skb)->data); \
+	-1; })
+
+#define RTA_GET_U8(rta) \
+({	if (!rta || RTA_PAYLOAD(rta) < sizeof(u8)) \
+		goto rtattr_failure; \
+	*(u8 *) RTA_DATA(rta); })
+
+#define RTA_GET_U16(rta) \
+({	if (!rta || RTA_PAYLOAD(rta) < sizeof(u16)) \
+		goto rtattr_failure; \
+	*(u16 *) RTA_DATA(rta); })
+
+#define RTA_GET_U32(rta) \
+({	if (!rta || RTA_PAYLOAD(rta) < sizeof(u32)) \
+		goto rtattr_failure; \
+	*(u32 *) RTA_DATA(rta); })
+
+#define RTA_GET_U64(rta) \
+({	u64 _tmp; \
+	if (!rta || RTA_PAYLOAD(rta) < sizeof(u64)) \
+		goto rtattr_failure; \
+	memcpy(&_tmp, RTA_DATA(rta), sizeof(_tmp)); \
+	_tmp; })
+
+#define RTA_GET_FLAG(rta) (!!(rta))
+
+#define RTA_GET_SECS(rta) ((unsigned long) RTA_GET_U64(rta) * HZ)
+#define RTA_GET_MSECS(rta) (msecs_to_jiffies((unsigned long) RTA_GET_U64(rta)))
+		
+static inline struct rtattr *
+__rta_reserve(struct sk_buff *skb, int attrtype, int attrlen)
+{
+	struct rtattr *rta;
+	int size = RTA_LENGTH(attrlen);
+
+	rta = (struct rtattr*)skb_put(skb, RTA_ALIGN(size));
+	rta->rta_type = attrtype;
+	rta->rta_len = size;
+	memset(RTA_DATA(rta) + attrlen, 0, RTA_ALIGN(size) - size);
+	return rta;
+}
+
+#define __RTA_PUT(skb, attrtype, attrlen) \
+({ 	if (unlikely(skb_tailroom(skb) < (int)RTA_SPACE(attrlen))) \
+		goto rtattr_failure; \
+   	__rta_reserve(skb, attrtype, attrlen); })
+
+extern void rtmsg_ifinfo(int type, struct net_device *dev, unsigned change);
+
+/* RTNL is used as a global lock for all changes to network configuration  */
+extern void rtnl_lock(void);
+extern void rtnl_unlock(void);
+extern int rtnl_trylock(void);
+extern int rtnl_is_locked(void);
+
+extern void rtnetlink_init(void);
+extern void __rtnl_unlock(void);
+
+#define ASSERT_RTNL() do { \
+	if (unlikely(!rtnl_is_locked())) { \
+		printk(KERN_ERR "RTNL: assertion failed at %s (%d)\n", \
+		       __FILE__,  __LINE__); \
+		dump_stack(); \
+	} \
+} while(0)
+
+#define BUG_TRAP(x) do { \
+	if (unlikely(!(x))) { \
+		printk(KERN_ERR "KERNEL: assertion (%s) failed at %s (%d)\n", \
+			#x,  __FILE__ , __LINE__); \
+	} \
+} while(0)
+
+static inline u32 rtm_get_table(struct rtattr **rta, u8 table)
+{
+	return RTA_GET_U32(rta[RTA_TABLE-1]);
+rtattr_failure:
+	return table;
+}
+
+#endif /* __KERNEL__ */
+
+
+#endif	/* __LINUX_RTNETLINK_H */
diff -Naur quagga-0.99.10/include/linux/shim.h quagga-mpls/include/linux/shim.h
--- quagga-0.99.10/include/linux/shim.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/include/linux/shim.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,12 @@
+#ifndef LINUX_SHIM_H
+#define LINUX_SHIM_H
+
+#define SHIMNAMSIZ 16
+struct rtshim
+{
+	char name[SHIMNAMSIZ+1];
+	short datalen;
+	char data[0];
+};
+
+#endif
diff -Naur quagga-0.99.10/isisd/isis_zebra.c quagga-mpls/isisd/isis_zebra.c
--- quagga-0.99.10/isisd/isis_zebra.c	2006-12-08 02:09:50.000000000 +0100
+++ quagga-mpls/isisd/isis_zebra.c	2008-11-25 12:30:18.000000000 +0100
@@ -337,12 +337,10 @@
 			   struct isis_route_info *route_info)
 {
   struct zapi_ipv6 api;
-  struct in6_addr **nexthop_list;
-  unsigned int *ifindex_list;
   struct isis_nexthop6 *nexthop6;
-  int i, size;
   struct listnode *node;
   struct prefix_ipv6 prefix6;
+  int i;
 
   if (CHECK_FLAG (route_info->flag, ISIS_ROUTE_FLAG_ZEBRA_SYNC))
     return;
@@ -350,35 +348,13 @@
   api.type = ZEBRA_ROUTE_ISIS;
   api.flags = 0;
   api.message = 0;
-  SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
-  SET_FLAG (api.message, ZAPI_MESSAGE_IFINDEX);
+
   SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
   api.metric = route_info->cost;
 #if 0
   SET_FLAG (api.message, ZAPI_MESSAGE_DISTANCE);
   api.distance = route_info->depth;
 #endif
-  api.nexthop_num = listcount (route_info->nexthops6);
-  api.ifindex_num = listcount (route_info->nexthops6);
-
-  /* allocate memory for nexthop_list */
-  size = sizeof (struct isis_nexthop6 *) * listcount (route_info->nexthops6);
-  nexthop_list = (struct in6_addr **) XMALLOC (MTYPE_ISIS_TMP, size);
-  if (!nexthop_list)
-    {
-      zlog_err ("isis_zebra_add_route_ipv6: out of memory!");
-      return;
-    }
-
-  /* allocate memory for ifindex_list */
-  size = sizeof (unsigned int) * listcount (route_info->nexthops6);
-  ifindex_list = (unsigned int *) XMALLOC (MTYPE_ISIS_TMP, size);
-  if (!ifindex_list)
-    {
-      zlog_err ("isis_zebra_add_route_ipv6: out of memory!");
-      XFREE (MTYPE_ISIS_TMP, nexthop_list);
-      return;
-    }
 
   /* for each nexthop */
   i = 0;
@@ -386,21 +362,18 @@
     {
       if (!IN6_IS_ADDR_LINKLOCAL (&nexthop6->ip6) &&
 	  !IN6_IS_ADDR_UNSPECIFIED (&nexthop6->ip6))
-	{
-	  api.nexthop_num--;
-	  api.ifindex_num--;
-	  continue;
-	}
+        continue;
 
-      nexthop_list[i] = &nexthop6->ip6;
-      ifindex_list[i] = nexthop6->ifindex;
+      SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
+      api.nexthop[i].type = ZEBRA_NEXTHOP_IPV6|ZEBRA_NEXTHOP_IFINDEX;
+      memcpy (&api.nexthop[i].gw.ipv6, &nexthop6->ip6, 16);
+      api.nexthop[i].intf.index = nexthop6->ifindex;
       i++;
     }
 
-  api.nexthop = nexthop_list;
-  api.ifindex = ifindex_list;
+  api.nexthop_num = i;
 
-  if (api.nexthop_num && api.ifindex_num)
+  if (api.nexthop_num)
     {
       prefix6.family = AF_INET6;
       prefix6.prefixlen = prefix->prefixlen;
@@ -409,9 +382,6 @@
       SET_FLAG (route_info->flag, ISIS_ROUTE_FLAG_ZEBRA_SYNC);
     }
 
-  XFREE (MTYPE_ISIS_TMP, nexthop_list);
-  XFREE (MTYPE_ISIS_TMP, ifindex_list);
-
   return;
 }
 
@@ -420,12 +390,10 @@
 			   struct isis_route_info *route_info)
 {
   struct zapi_ipv6 api;
-  struct in6_addr **nexthop_list;
-  unsigned int *ifindex_list;
   struct isis_nexthop6 *nexthop6;
-  int i, size;
   struct listnode *node;
   struct prefix_ipv6 prefix6;
+  int i;
 
   if (CHECK_FLAG (route_info->flag, ISIS_ROUTE_FLAG_ZEBRA_SYNC))
     return;
@@ -433,29 +401,6 @@
   api.type = ZEBRA_ROUTE_ISIS;
   api.flags = 0;
   api.message = 0;
-  SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
-  SET_FLAG (api.message, ZAPI_MESSAGE_IFINDEX);
-  api.nexthop_num = listcount (route_info->nexthops6);
-  api.ifindex_num = listcount (route_info->nexthops6);
-
-  /* allocate memory for nexthop_list */
-  size = sizeof (struct isis_nexthop6 *) * listcount (route_info->nexthops6);
-  nexthop_list = (struct in6_addr **) XMALLOC (MTYPE_ISIS_TMP, size);
-  if (!nexthop_list)
-    {
-      zlog_err ("isis_zebra_route_del_ipv6: out of memory!");
-      return;
-    }
-
-  /* allocate memory for ifindex_list */
-  size = sizeof (unsigned int) * listcount (route_info->nexthops6);
-  ifindex_list = (unsigned int *) XMALLOC (MTYPE_ISIS_TMP, size);
-  if (!ifindex_list)
-    {
-      zlog_err ("isis_zebra_route_del_ipv6: out of memory!");
-      XFREE (MTYPE_ISIS_TMP, nexthop_list);
-      return;
-    }
 
   /* for each nexthop */
   i = 0;
@@ -463,21 +408,16 @@
     {
       if (!IN6_IS_ADDR_LINKLOCAL (&nexthop6->ip6) &&
 	  !IN6_IS_ADDR_UNSPECIFIED (&nexthop6->ip6))
-	{
-	  api.nexthop_num--;
-	  api.ifindex_num--;
-	  continue;
-	}
+	continue;
 
-      nexthop_list[i] = &nexthop6->ip6;
-      ifindex_list[i] = nexthop6->ifindex;
+      SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
+      api.nexthop[i].type = ZEBRA_NEXTHOP_IPV6|ZEBRA_NEXTHOP_IFINDEX;
+      memcpy (&api.nexthop[i].gw.ipv6, &nexthop6->ip6, 16);
+      api.nexthop[i].intf.index = nexthop6->ifindex;
       i++;
     }
 
-  api.nexthop = nexthop_list;
-  api.ifindex = ifindex_list;
-
-  if (api.nexthop_num && api.ifindex_num)
+  if (api.nexthop_num)
     {
       prefix6.family = AF_INET6;
       prefix6.prefixlen = prefix->prefixlen;
@@ -485,9 +425,6 @@
       zapi_ipv6_route (ZEBRA_IPV6_ROUTE_DELETE, zclient, &prefix6, &api);
       UNSET_FLAG (route_info->flag, ISIS_ROUTE_FLAG_ZEBRA_SYNC);
     }
-
-  XFREE (MTYPE_ISIS_TMP, nexthop_list);
-  XFREE (MTYPE_ISIS_TMP, ifindex_list);
 }
 
 #endif /* HAVE_IPV6 */
@@ -527,45 +464,29 @@
 isis_zebra_read_ipv4 (int command, struct zclient *zclient,
 		      zebra_size_t length)
 {
-  struct stream *stream;
   struct zapi_ipv4 api;
   struct prefix_ipv4 p;
   unsigned long ifindex;
   struct in_addr nexthop;
+  int i;
 
-  stream = zclient->ibuf;
-  memset (&p, 0, sizeof (struct prefix_ipv4));
-  ifindex = 0;
-
-  api.type = stream_getc (stream);
-  api.flags = stream_getc (stream);
-  api.message = stream_getc (stream);
-
-  p.family = AF_INET;
-  p.prefixlen = stream_getc (stream);
-  stream_get (&p.prefix, stream, PSIZE (p.prefixlen));
+  zapi_ipv4_route(command, zclient, &p, &api);
 
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
-    {
-      api.nexthop_num = stream_getc (stream);
-      nexthop.s_addr = stream_get_ipv4 (stream);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_IFINDEX))
+  for (i = 0; i < api.nexthop_num; i++)
     {
-      api.ifindex_num = stream_getc (stream);
-      ifindex = stream_getl (stream);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (stream);
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (stream);
-  else
-    api.metric = 0;
+      ifindex = 0;
+      nexthop.s_addr = 0;
+      if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IPV4))
+        nexthop.s_addr = api.nexthop[i].gw.ipv4.s_addr;
 
-  if (command == ZEBRA_IPV4_ROUTE_ADD)
-    {
-      if (isis->debugs & DEBUG_ZEBRA)
-	zlog_debug ("IPv4 Route add from Z");
+      if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IFINDEX))
+        ifindex = api.nexthop[i].intf.index;
+
+      if (command == ZEBRA_IPV4_ROUTE_ADD)
+        {
+          if (isis->debugs & DEBUG_ZEBRA)
+	    zlog_debug ("IPv4 Route add from Z");
+        }
     }
 
   return 0;
@@ -576,6 +497,36 @@
 isis_zebra_read_ipv6 (int command, struct zclient *zclient,
 		      zebra_size_t length)
 {
+  struct zapi_ipv6 api;
+  struct prefix_ipv6 p;
+  unsigned long ifindex;
+  struct in_addr nexthop;
+  int i;
+
+  zapi_ipv6_route(command, zclient, &p, &api);
+
+  /* Simply ignore link-local address. */
+  if (IN6_IS_ADDR_LINKLOCAL (&p.prefix))
+    return 0;
+
+  for (i = 0; i < api.nexthop_num; i++)
+    {
+      ifindex = 0;
+      memset (&nexthop, 0, sizeof (struct in6_addr));
+
+      if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IPV6))
+        memcpy(&nexthop, &api.nexthop[i].gw.ipv6, 16);
+
+      if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IFINDEX))
+        ifindex = api.nexthop[i].intf.index;
+
+      if (command == ZEBRA_IPV6_ROUTE_ADD)
+        {
+          if (isis->debugs & DEBUG_ZEBRA)
+            zlog_debug ("IPv6 Route add from Z");
+        }
+    }
+
   return 0;
 }
 #endif
diff -Naur quagga-0.99.10/ldpd/impl_fib.c quagga-mpls/ldpd/impl_fib.c
--- quagga-0.99.10/ldpd/impl_fib.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_fib.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,26 @@
+#include <zebra.h>
+#include "prefix.h"
+#include "table.h"
+#include "if.h"
+#include "memory.h"
+#include "vty.h"
+
+#include "mpls_compare.h"
+
+#include "ldp.h"
+#include "ldp_struct.h"
+#include "ldp_cfg.h"
+
+#include "ldp_zebra.h"
+#include "mpls_fib_impl.h"
+
+void mpls_fib_close(mpls_fib_handle handle)
+{
+}
+
+mpls_fib_handle mpls_fib_open(const mpls_instance_handle handle,
+  const mpls_cfg_handle cfg)
+{
+  struct ldp *ldp = ldp_get();
+  return ldp;
+}
diff -Naur quagga-0.99.10/ldpd/impl_fib.h quagga-mpls/ldpd/impl_fib.h
--- quagga-0.99.10/ldpd/impl_fib.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_fib.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,9 @@
+#ifndef LDP_IMPL_FIB_H
+#define LDP_IMPL_FIB_H
+
+#include <zebra.h>
+
+#include "ldp_struct.h"
+#include "ldp.h"
+
+#endif
diff -Naur quagga-0.99.10/ldpd/impl_ifmgr.c quagga-mpls/ldpd/impl_ifmgr.c
--- quagga-0.99.10/ldpd/impl_ifmgr.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_ifmgr.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,34 @@
+#include <zebra.h>
+#include "if.h"
+
+#include "ldp.h"
+#include "ldp_struct.h"
+#include "mpls_ifmgr_impl.h"
+
+static int opened = 0;
+
+mpls_ifmgr_handle mpls_ifmgr_open(mpls_instance_handle handle,
+  mpls_cfg_handle cfg)
+{
+  opened = 1;
+  return 0xdeadbeef;
+}
+
+void mpls_ifmgr_close(mpls_ifmgr_handle ifmgr_handle)
+{
+  opened = 0;
+}
+
+mpls_return_enum mpls_ifmgr_get_mtu(mpls_ifmgr_handle ifmgr_handle,
+  mpls_if_handle if_handle, int *mtu)
+{
+  *mtu = if_handle->mtu;
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum mpls_ifmgr_get_name(const mpls_ifmgr_handle handle,
+  const mpls_if_handle if_handle, char *name, int len)
+{
+  strncpy(name, if_handle->name, len);
+  return MPLS_SUCCESS;
+}
diff -Naur quagga-0.99.10/ldpd/impl_ifmgr.h quagga-mpls/ldpd/impl_ifmgr.h
--- quagga-0.99.10/ldpd/impl_ifmgr.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_ifmgr.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,7 @@
+#ifndef LDP_IMPL_IFMGR_H
+#define LDP_IMPL_IFMGR_H
+
+#include <zebra.h>
+#include "ldp_struct.h"
+
+#endif
diff -Naur quagga-0.99.10/ldpd/impl_lock.c quagga-mpls/ldpd/impl_lock.c
--- quagga-0.99.10/ldpd/impl_lock.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_lock.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,29 @@
+#include "ldp_struct.h"
+#include "mpls_assert.h"
+#include "mpls_mm_impl.h"
+#include "mpls_lock_impl.h"
+
+mpls_lock_handle mpls_lock_create(mpls_lock_key_type key)
+{
+  int *i = mpls_malloc(sizeof(int));
+
+  *i = 0;
+  return i;
+}
+
+void mpls_lock_get(mpls_lock_handle handle)
+{
+  MPLS_ASSERT(*handle == 0);
+  (*handle)++;
+}
+
+void mpls_lock_release(mpls_lock_handle handle)
+{
+  MPLS_ASSERT(*handle == 1);
+  (*handle)--;
+}
+
+void mpls_lock_delete(mpls_lock_handle handle)
+{
+  mpls_free(handle);
+}
diff -Naur quagga-0.99.10/ldpd/impl_mm.c quagga-mpls/ldpd/impl_mm.c
--- quagga-0.99.10/ldpd/impl_mm.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_mm.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,28 @@
+#include "ldp_struct.h"
+#include "mpls_mm_impl.h"
+#include <stdio.h>
+#include <stdlib.h>
+
+#include "memory.h"
+
+static int _mm_count = 0;
+
+void *mpls_malloc(mpls_size_type size)
+{
+  void *mem = XMALLOC(MTYPE_LDP, size);
+  if (mem) {
+    _mm_count++;
+  }
+  return mem;
+}
+
+void mpls_free(void *mem)
+{
+  _mm_count--;
+  XFREE(MTYPE_LDP,mem);
+}
+
+void mpls_mm_results()
+{
+  zlog_info("LDP MM RESULTS: %d\n", _mm_count);
+}
diff -Naur quagga-0.99.10/ldpd/impl_mpls.c quagga-mpls/ldpd/impl_mpls.c
--- quagga-0.99.10/ldpd/impl_mpls.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_mpls.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,282 @@
+#include <zebra.h>
+
+#include "stream.h"
+#include "prefix.h"
+#include "memory.h"
+#include "log.h"
+#include "zclient.h"
+#include "if.h"
+
+#include "ldp.h"
+#include "ldp_struct.h"
+#include "ldp_entity.h"
+#include "mpls_mpls_impl.h"
+#include "mpls_socket_impl.h"
+
+#include "ldp_interface.h"
+#include "impl_mpls.h"
+#include "impl_fib.h"
+
+#include "ldp_zebra.h"
+#include "zclient.h"
+
+static int label = 10000;
+static int request = -2;
+extern struct zclient *zclient;
+extern struct list *pending_out_segment;
+extern struct list *pending_ftn;
+extern struct list *pending_xc;
+
+static int new_request()
+{
+  request--;
+  if (request > -2) {
+    request = -2;
+  }
+  return request;
+}
+
+mpls_mpls_handle mpls_mpls_open(mpls_instance_handle user_data)
+{
+  return MPLS_SUCCESS;
+}
+
+void mpls_mpls_close(mpls_mpls_handle handle)
+{
+}
+
+mpls_return_enum mpls_mpls_outsegment_add(mpls_mpls_handle handle, mpls_outsegment * o)
+{
+  struct zapi_mpls_out_segment out;
+  struct interface *ifp;
+
+  memset(&out, 0, sizeof(out));
+
+  out.index = 0;
+  out.req = new_request();
+  out.owner = ZEBRA_ROUTE_LDP;
+  out.nh.mpls.type = ZEBRA_MPLS_LABEL_GEN;
+  out.nh.mpls.u.gen = o->label.u.gen;
+  SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_MPLS);
+
+  if (o->nexthop.type & MPLS_NH_IP) {
+    SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_IPV4);
+    out.nh.gw.ipv4.s_addr = htonl(o->nexthop.ip.u.ipv4);
+  }
+
+  if (o->nexthop.type & MPLS_NH_IF) {
+    strcpy(out.nh.intf.name, o->nexthop.if_handle->name);
+    SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_IFNAME);
+  } else {
+    MPLS_ASSERT(o->nexthop.type & MPLS_NH_IP);
+
+    ifp = if_lookup_address(out.nh.gw.ipv4);
+    if (ifp) {
+      strcpy(out.nh.intf.name, ifp->name);
+      SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_IFNAME);
+    } else {
+      return MPLS_FAILURE;
+    }
+  }
+
+  /* store the request number as the handle, we'll need it when the
+   * response from zebra arrives */
+  o->handle = out.req;
+
+  listnode_add(pending_out_segment, o);
+
+  zapi_mpls_out_segment_add(zclient, &out);
+  return MPLS_SUCCESS;
+}
+
+void mpls_mpls_outsegment_del(mpls_mpls_handle handle, mpls_outsegment * o)
+{
+  struct zapi_mpls_out_segment out;
+  struct interface *ifp;
+  struct listnode *n;
+
+  memset(&out, 0, sizeof(out));
+
+  out.index = 0;
+  out.owner = ZEBRA_ROUTE_LDP;
+  out.nh.mpls.type = ZEBRA_MPLS_LABEL_GEN;
+  out.nh.mpls.u.gen = o->label.u.gen;
+  SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_MPLS);
+
+  if (o->nexthop.type & MPLS_NH_IP) {
+    SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_IPV4);
+    out.nh.gw.ipv4.s_addr = htonl(o->nexthop.ip.u.ipv4);
+  }
+
+  if (o->nexthop.type & MPLS_NH_IF) {
+    strncpy(out.nh.intf.name, o->nexthop.if_handle->name, INTERFACE_NAMSIZ);
+    SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_IFNAME);
+  } else {
+    MPLS_ASSERT(o->nexthop.type & MPLS_NH_IP);
+
+    ifp = if_lookup_address(out.nh.gw.ipv4);
+    if (ifp) {
+      strcpy(out.nh.intf.name, ifp->name);
+      SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_IFNAME);
+    } else {
+      return;
+    }
+  }
+
+  /* the out segment might still be in the pending list, remove it */
+  n = listnode_lookup(pending_out_segment, o);
+  if (n) {
+    list_delete_node(pending_out_segment, n);
+  }
+
+  out.index = o->handle;
+  zapi_mpls_out_segment_delete(zclient, &out);
+}
+
+mpls_return_enum mpls_mpls_insegment_add(mpls_mpls_handle handle,
+  mpls_insegment * i)
+{
+  struct zapi_mpls_in_segment api;
+
+  if (i->label.type == MPLS_LABEL_TYPE_NONE) {
+    i->label.type = MPLS_LABEL_TYPE_GENERIC;
+    i->label.u.gen = label++;
+  }
+
+  api.owner = ZEBRA_ROUTE_LDP;
+  api.labelspace = i->labelspace;
+  api.protocol = i->family;
+  api.pop = i->npop;
+  api.label.type = ZEBRA_MPLS_LABEL_GEN;
+  api.label.u.gen = i->label.u.gen;
+
+  zapi_mpls_in_segment_add(zclient, &api);
+  return MPLS_SUCCESS;
+}
+
+void mpls_mpls_insegment_del(mpls_mpls_handle handle, mpls_insegment * i)
+{
+  struct zapi_mpls_in_segment api;
+
+  api.owner = ZEBRA_ROUTE_LDP;
+  api.labelspace = i->labelspace;
+  api.protocol = i->family;
+  api.pop = i->npop;
+  api.label.type = ZEBRA_MPLS_LABEL_GEN;
+  api.label.u.gen = i->label.u.gen;
+
+  zapi_mpls_in_segment_delete(zclient, &api);
+}
+
+mpls_return_enum mpls_mpls_xconnect_add(mpls_mpls_handle handle, mpls_insegment * i, mpls_outsegment * o)
+{
+  struct zapi_mpls_xc api;
+  struct listnode *n;
+
+  n = listnode_lookup(pending_out_segment, o);
+  if (n) {
+    struct pending_xc_data *x = XMALLOC(MTYPE_TMP,
+	sizeof(struct pending_xc_data));
+    x->o = o;
+    x->i = i;
+    x->h = handle;
+    listnode_add(pending_xc, x);
+    return MPLS_SUCCESS;
+  }
+
+  api.owner = ZEBRA_ROUTE_LDP;
+  api.in_labelspace = i->labelspace;
+  api.in_label.type = ZEBRA_MPLS_LABEL_GEN;
+  api.in_label.u.gen = i->label.u.gen;
+  api.out_index = o->handle;
+
+  zapi_mpls_xc_add(zclient, &api);
+  return MPLS_SUCCESS;
+}
+
+void mpls_mpls_xconnect_del(mpls_mpls_handle handle, mpls_insegment * i,
+  mpls_outsegment * o)
+{
+  struct zapi_mpls_xc api;
+  struct listnode *n;
+
+  /* if its in the pending XC list, no need to send the delete because
+   * the add was never sent
+   */
+  n = listnode_lookup(pending_xc, o);
+  if (n) {
+    list_delete_node(pending_xc, n);
+    return;
+  }
+
+  api.owner = ZEBRA_ROUTE_LDP;
+  api.in_labelspace = i->labelspace;
+  api.in_label.type = ZEBRA_MPLS_LABEL_GEN;
+  api.in_label.u.gen = i->label.u.gen;
+  api.out_index = o->handle;
+
+  zapi_mpls_xc_delete(zclient, &api);
+}
+
+mpls_return_enum mpls_mpls_fec2out_add(mpls_mpls_handle handle, mpls_fec * f,
+  mpls_outsegment * o)
+{
+  struct zapi_mpls_ftn api;
+  struct listnode *n;
+  int retval;
+
+  n = listnode_lookup(pending_out_segment, o);
+  if (n) {
+    struct pending_ftn_data *fn = XMALLOC(MTYPE_TMP,
+	sizeof(struct pending_ftn_data));
+    fn->o = o;
+    fn->f = f;
+    fn->h = handle;
+    listnode_add(pending_ftn, fn);
+    return MPLS_SUCCESS;
+  }
+
+  api.fec.type = ZEBRA_MPLS_FEC_IPV4;
+  mpls_fec2zebra_prefix(f,&api.fec.u.p);
+  api.out_index = o->handle;
+  api.fec.owner = -1;
+  api.owner = ZEBRA_ROUTE_LDP;
+
+  retval = zapi_mpls_ftn_add(zclient, &api);
+  return MPLS_SUCCESS;
+}
+
+void mpls_mpls_fec2out_del(mpls_mpls_handle handle, mpls_fec * f,
+  mpls_outsegment * o)
+{
+  struct zapi_mpls_ftn api;
+  struct listnode *n;
+  int retval;
+
+  /* if its in the pending FTN list, no need to send the delete because
+   * the add was never sent
+   */
+  n = listnode_lookup(pending_ftn, o);
+  if (n) {
+    list_delete_node(pending_ftn, n);
+    return;
+  }
+
+  api.fec.type = ZEBRA_MPLS_FEC_IPV4;
+  mpls_fec2zebra_prefix(f,&api.fec.u.p);
+  api.out_index = o->handle;
+  api.fec.owner = -1;
+  api.owner = ZEBRA_ROUTE_LDP;
+
+  retval = zapi_mpls_ftn_delete(zclient, &api);
+}
+
+mpls_return_enum mpls_mpls_get_label_space_range(mpls_mpls_handle handle,
+  mpls_range * r)
+{
+  r->type = MPLS_LABEL_RANGE_GENERIC;
+  r->min.u.gen = 16;
+  r->max.u.gen = 0xFFFFF;
+
+  return MPLS_SUCCESS;
+}
diff -Naur quagga-0.99.10/ldpd/impl_mpls.h quagga-mpls/ldpd/impl_mpls.h
--- quagga-0.99.10/ldpd/impl_mpls.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_mpls.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,22 @@
+#ifndef IMPL_MPLS_H
+#define IMPL_MPLS_H
+
+#include "ldp_interface.h"
+
+struct pending_ftn_data
+{
+    mpls_mpls_handle h;
+    mpls_outsegment *o;
+    mpls_fec *f;
+};
+
+struct pending_xc_data
+{
+    mpls_mpls_handle h;
+    mpls_outsegment *o;
+    mpls_insegment *i;
+};
+
+int do_mpls_labelspace(struct ldp_interface *li);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/impl_policy.c quagga-mpls/ldpd/impl_policy.c
--- quagga-0.99.10/ldpd/impl_policy.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_policy.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,85 @@
+#include <zebra.h>
+
+#include "ldp_struct.h"
+#include "ldp_interface.h"
+#include "ldp_zebra.h"
+#include "mpls_policy_impl.h"
+#include "ldp.h"
+
+mpls_bool mpls_policy_import_check(mpls_instance_handle handle, mpls_fec * f,
+  mpls_nexthop * nh)
+{
+  return MPLS_BOOL_TRUE;
+}
+
+mpls_bool mpls_policy_ingress_check(mpls_instance_handle handle, mpls_fec * f, mpls_nexthop * nh)
+{
+  return MPLS_BOOL_TRUE;
+}
+
+mpls_bool mpls_policy_egress_check(mpls_instance_handle handle, mpls_fec * fec,
+  mpls_nexthop *nexthop)
+{
+  struct ldp *ldp = handle;
+  int result = MPLS_BOOL_FALSE;
+  struct prefix p;
+
+  switch(ldp->egress) {
+    case LDP_EGRESS_ALL:
+    {
+      result = MPLS_BOOL_TRUE;
+      break;
+    }
+    case LDP_EGRESS_LSRID:
+    {
+      mpls_fec2zebra_prefix(fec,&p);
+      if (prefix_same(&router_id, &p)) {
+         result = MPLS_BOOL_TRUE;
+      }
+      break;
+    }
+    case LDP_EGRESS_CONNECTED:
+    {
+      if (nexthop->attached == MPLS_BOOL_TRUE) {
+	result = MPLS_BOOL_TRUE;
+      }
+      break;
+    }
+    default:
+      break;
+  }
+  return result;
+}
+
+mpls_bool mpls_policy_export_check(mpls_instance_handle handle, mpls_fec  * f, mpls_nexthop * nh)
+{
+  return MPLS_BOOL_TRUE;
+}
+
+mpls_bool mpls_policy_address_export_check(mpls_instance_handle handle,
+  mpls_inet_addr *addr) {
+  struct ldp *ldp = handle;
+  mpls_bool flag = MPLS_BOOL_FALSE; 
+  struct interface *ifp;
+  struct in_addr in;
+
+  in.s_addr = htonl(addr->u.ipv4);
+
+  switch (ldp->address) {
+    case LDP_ADDRESS_LDP:
+      if ((ifp = if_lookup_exact_address(in)) && 
+         (struct ldp_interface*)(ifp->info)) {
+        flag = MPLS_BOOL_TRUE;
+      }
+      /* fall through */
+    case LDP_ADDRESS_LSRID:
+      if (in.s_addr == router_id.u.prefix4.s_addr) {
+        flag = MPLS_BOOL_TRUE;
+      }
+      break;
+    case LDP_ADDRESS_ALL:
+      flag = MPLS_BOOL_TRUE;
+      break;
+  }
+  return flag;
+}
diff -Naur quagga-0.99.10/ldpd/impl_socket.c quagga-mpls/ldpd/impl_socket.c
--- quagga-0.99.10/ldpd/impl_socket.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_socket.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,659 @@
+#include <stdio.h>
+#include <unistd.h>
+
+#include <zebra.h>
+#include "thread.h"
+#include "sockopt.h"
+#include "privs.h"
+#include "log.h"
+
+#include "ldp.h"
+
+#include "ldp_struct.h"
+#include "ldp_state_machine.h"
+#include "mpls_mm_impl.h"
+#include "mpls_socket_impl.h"
+
+
+extern struct thread_master *master;
+extern struct zebra_privs_t ldpd_privs;
+
+struct mpls_socket {
+    int fd;
+    int type;
+    struct thread *read;
+    struct thread *write;
+    void *extra;
+};
+
+static void _sockaddr2mpls_dest(const struct sockaddr *addr, mpls_dest * dest)
+{
+  dest->addr.type = MPLS_FAMILY_IPV4;
+  switch (dest->addr.type) {
+    case MPLS_FAMILY_IPV4:
+      dest->port = ntohs(((const struct sockaddr_in *)addr)->sin_port);
+      dest->addr.u.ipv4 = ntohl(((const struct sockaddr_in *)addr)->sin_addr.s_addr);
+      break;
+    default:
+      assert(0);
+  }
+}
+
+static void _mpls_dest2sockaddr(const mpls_dest * dest, struct sockaddr *addr)
+{
+  memset(addr, 0, sizeof(struct sockaddr));
+
+  switch (dest->addr.type) {
+    case MPLS_FAMILY_IPV4:
+      {
+        addr->sa_family = AF_INET;
+        ((struct sockaddr_in *)addr)->sin_port = htons(dest->port);
+        ((struct sockaddr_in *)addr)->sin_addr.s_addr = htonl(dest->addr.u.ipv4);
+        break;
+      }
+    default:
+      {
+        assert(0);
+      }
+  }
+}
+
+static int mplsd_read(struct thread *thread) {
+  int retval;
+  struct ldp *ldp = ldp_get();
+  mpls_socket_handle socket;
+
+  MPLS_ASSERT(thread); 
+
+  socket = THREAD_ARG(thread);
+  socket->read = thread_add_read(master,mplsd_read,socket,socket->fd);
+
+  if (!ldp) {
+    return 0;
+  }
+
+  switch (socket->type) {
+    case MPLS_SOCKET_TCP_DATA:
+    {
+      retval = ldp_event(ldp->h, socket, socket->extra,
+        LDP_EVENT_TCP_DATA);
+      break;
+    }
+    case MPLS_SOCKET_TCP_LISTEN:
+    {
+      retval = ldp_event(ldp->h, socket, socket->extra,
+        LDP_EVENT_TCP_LISTEN);
+      break;
+    }
+    case MPLS_SOCKET_UDP_DATA:
+    {
+      retval = ldp_event(ldp->h, socket, socket->extra,
+        LDP_EVENT_UDP_DATA);
+      break;
+    }
+    default:
+    {
+      assert(0);
+    }
+  }
+  return 0;
+}
+
+static int mplsd_write(struct thread *thread) {
+  struct ldp *ldp = ldp_get();
+  int retval;
+  mpls_socket_handle socket;
+
+  MPLS_ASSERT(thread); 
+
+  socket = THREAD_ARG(thread);
+  socket->write = thread_add_write(master,mplsd_write,socket,socket->fd);
+  if (socket->type != MPLS_SOCKET_TCP_CONNECT) {
+    assert(0);
+  }
+  retval = ldp_event(ldp->h, socket, socket->extra,
+    LDP_EVENT_TCP_CONNECT);
+
+  return 0;
+}
+
+mpls_socket_mgr_handle mpls_socket_mgr_open(mpls_instance_handle user_data)
+{
+  return 0xdeadbeef;
+}
+
+void mpls_socket_mgr_close(mpls_socket_mgr_handle handle)
+{
+}
+
+void mpls_socket_close(mpls_socket_mgr_handle handle, mpls_socket_handle socket)
+{
+  if (socket) {
+    close(socket->fd);
+    mpls_free(socket);
+  }
+}
+
+mpls_socket_handle mpls_socket_create_tcp(mpls_socket_mgr_handle handle)
+{
+  struct mpls_socket *sock;
+  sock = mpls_malloc(sizeof(struct mpls_socket));
+  memset(sock,0,sizeof(struct mpls_socket));
+  sock->fd = socket(AF_INET, SOCK_STREAM, 0);
+  MPLS_ASSERT(sock->fd > -1);
+  return sock;
+}
+
+mpls_socket_handle mpls_socket_create_udp(mpls_socket_mgr_handle handle)
+{
+  struct mpls_socket *sock;
+  u_char one = 1;
+
+  sock = mpls_malloc(sizeof(struct mpls_socket));
+  memset(sock,0,sizeof(struct mpls_socket));
+  sock->fd = socket(AF_INET, SOCK_DGRAM, 0);
+  MPLS_ASSERT(sock->fd > -1);
+  if (setsockopt(sock->fd,SOL_IP,IP_PKTINFO,&one,sizeof(one)) < 0) {
+    perror("PKTINFO");
+    mpls_free(sock);
+    return NULL;
+  }
+  return sock;
+}
+
+mpls_socket_handle mpls_socket_create_raw(mpls_socket_mgr_handle handle,
+  int proto)
+{
+  struct mpls_socket *sock;
+  u_char one = 1;
+
+  sock = mpls_malloc(sizeof(struct mpls_socket));
+  memset(sock,0,sizeof(struct mpls_socket));
+
+  if (ldpd_privs.change(ZPRIVS_RAISE))
+    zlog (NULL, LOG_ERR, "Can't raise privileges");
+
+  sock->fd = socket(AF_INET, SOCK_RAW, proto);
+  MPLS_ASSERT(sock->fd > -1);
+  if (setsockopt(sock->fd,SOL_IP,IP_PKTINFO,&one,sizeof(one)) < 0) {
+    perror("PKTINFO");
+    mpls_free(sock);
+    sock = NULL;
+  }
+
+  if (ldpd_privs.change(ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  return sock;
+}
+
+mpls_socket_handle mpls_socket_tcp_accept(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, mpls_dest * from)
+{
+  struct mpls_socket *sock = mpls_malloc(sizeof(struct mpls_socket));
+  struct sockaddr addr;
+  unsigned int size = sizeof(addr);
+
+  if ((sock->fd = accept(socket->fd,&addr,&size)) < 0) {
+    return NULL;
+  }
+
+  _sockaddr2mpls_dest(&addr, from);
+  return sock;
+}
+
+mpls_return_enum mpls_socket_bind(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, const mpls_dest * local)
+{
+  struct sockaddr addr;
+  int result = MPLS_SUCCESS;
+
+  _mpls_dest2sockaddr(local, &addr);
+
+  if (ldpd_privs.change(ZPRIVS_RAISE))
+    zlog (NULL, LOG_ERR, "Can't raise privileges");
+
+  if (bind(socket->fd, &addr, sizeof(struct sockaddr_in)) < 0) {
+    perror("bind");
+    result = MPLS_FAILURE;
+  }
+
+  if (ldpd_privs.change(ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  return result;
+}
+
+mpls_return_enum mpls_socket_tcp_listen(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, int depth)
+{
+  if (listen(socket->fd, depth) < 0) {
+    return MPLS_FAILURE;
+  }
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum mpls_socket_tcp_connect(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, const mpls_dest * to)
+{
+  struct sockaddr addr, *iaddr = NULL;
+
+  if (to != NULL) {
+    _mpls_dest2sockaddr(to, &addr);
+    iaddr = &addr;
+  } else {
+    iaddr = NULL;
+  }
+
+  if (connect(socket->fd, iaddr, sizeof(struct sockaddr)) < 0) {
+    if (errno == EINPROGRESS) {
+      return MPLS_NON_BLOCKING;
+    }
+
+    if (errno == EALREADY) {
+      return MPLS_SUCCESS;
+    }
+    perror("connect");
+    return MPLS_FAILURE;
+  }
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum mpls_socket_connect_status(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket)
+{
+  unsigned int size = sizeof(int);
+  int num = 1;
+
+  if (getsockopt(socket->fd, SOL_SOCKET, SO_ERROR, &num, &size) < 0) {
+    perror("getsockopt");
+    return MPLS_FAILURE;
+  }
+  if (!num) {
+    return MPLS_SUCCESS;
+  }
+  perror("getsockopt");
+  return MPLS_NON_BLOCKING;
+}
+
+int mpls_socket_get_errno(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket)
+{
+  return errno;
+}
+
+mpls_return_enum mpls_socket_options(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, uint32_t flag)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+  int one = 1;
+
+  if (ldpd_privs.change(ZPRIVS_RAISE))
+    zlog (NULL, LOG_ERR, "Can't raise privileges");
+
+  if (flag & MPLS_SOCKOP_REUSE) {
+    if (setsockopt(socket->fd, SOL_SOCKET, SO_REUSEADDR, (char *)&one,
+        sizeof(one)) < 0) {
+      retval = MPLS_FAILURE;
+      goto mpls_socket_options_exit;
+    }
+  }
+  if (flag & MPLS_SOCKOP_NONBLOCK) {
+    if (fcntl(socket->fd, F_SETFL, O_NONBLOCK) < 0) {
+      retval = MPLS_FAILURE;
+      goto mpls_socket_options_exit;
+    }
+  }
+  if (flag & MPLS_SOCKOP_ROUTERALERT) {
+    if (setsockopt(socket->fd, SOL_IP, IP_ROUTER_ALERT, (char *)&one,
+      sizeof(one)) < 0) {
+      retval = MPLS_FAILURE;
+      goto mpls_socket_options_exit;
+    }
+  }
+  if (flag & MPLS_SOCKOP_HDRINCL) {
+    if (setsockopt(socket->fd, SOL_IP, IP_HDRINCL, (char *)&one,
+      sizeof(one)) < 0) {
+      retval = MPLS_FAILURE;
+    }
+  }
+
+mpls_socket_options_exit:
+
+  if (ldpd_privs.change(ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  return retval;
+}
+
+mpls_return_enum mpls_socket_multicast_options(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, int ttl, int loop)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+  int zero = loop;
+  int one = ttl;
+
+  if (ldpd_privs.change(ZPRIVS_RAISE))
+    zlog (NULL, LOG_ERR, "Can't raise privileges");
+
+  if (setsockopt(socket->fd,SOL_IP,IP_MULTICAST_TTL,&one,sizeof(one))<0) {
+    retval = MPLS_FAILURE;
+    goto mpls_socket_multicast_options_exit;
+  }
+
+  if (setsockopt(socket->fd,SOL_IP,IP_MULTICAST_LOOP,&zero,sizeof(zero))<0) {
+    retval = MPLS_FAILURE;
+  }
+
+mpls_socket_multicast_options_exit:
+  if (ldpd_privs.change(ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  return retval;
+}
+
+mpls_return_enum mpls_socket_multicast_if_tx(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, const ldp_if * iff)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+  struct in_addr addr;
+  unsigned int ifindex = 0;
+  addr.s_addr = 0;
+
+  if (ldpd_privs.change(ZPRIVS_RAISE))
+    zlog (NULL, LOG_ERR, "Can't raise privileges");
+
+  if (iff == NULL) {
+    addr.s_addr = ntohl(INADDR_ANY);
+  } else {
+    ifindex = iff->handle->ifindex;
+  }
+
+  if (setsockopt_multicast_ipv4(socket->fd,IP_MULTICAST_IF,addr,0,ifindex)<0) {
+    retval = MPLS_FAILURE;
+  }
+
+  if (ldpd_privs.change(ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  return retval;
+}
+
+mpls_return_enum mpls_socket_multicast_if_join(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, const ldp_if * iff, const mpls_inet_addr * mult)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+  struct in_addr addr;
+  unsigned int ifindex = 0;
+  addr.s_addr = 0;
+
+  if (ldpd_privs.change(ZPRIVS_RAISE))
+    zlog (NULL, LOG_ERR, "Can't raise privileges");
+
+  if (iff == NULL) {
+    addr.s_addr = ntohl(INADDR_ANY);
+  } else {
+    ifindex = iff->handle->ifindex;
+  }
+
+  if (setsockopt_multicast_ipv4(socket->fd,IP_ADD_MEMBERSHIP,addr,
+    htonl(mult->u.ipv4),ifindex)<0) {
+    retval = MPLS_FAILURE;
+  }
+
+  if (ldpd_privs.change(ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  return retval;
+}
+
+void mpls_socket_multicast_if_drop(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, const ldp_if * iff, const mpls_inet_addr * mult)
+{
+  struct in_addr addr;
+  unsigned int ifindex = 0;
+  addr.s_addr = 0;
+
+  if (ldpd_privs.change(ZPRIVS_RAISE))
+    zlog (NULL, LOG_ERR, "Can't raise privileges");
+
+  if (iff == NULL) {
+    addr.s_addr = ntohl(INADDR_ANY);
+  } else {
+    ifindex = iff->handle->ifindex;
+  }
+
+  if (setsockopt_multicast_ipv4(socket->fd,IP_DROP_MEMBERSHIP,addr,
+    htonl(mult->u.ipv4),ifindex)<0) {
+    perror("multicast drop membership");
+  }
+
+  if (ldpd_privs.change(ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  return;
+}
+
+mpls_return_enum mpls_socket_readlist_add(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, void *extra, mpls_socket_enum type)
+{
+  socket->type = type;
+  socket->extra = extra;
+  MPLS_ASSERT(socket && (socket->fd > -1));
+  socket->read = thread_add_read(master,mplsd_read,socket,socket->fd);
+  MPLS_ASSERT(socket->read);
+  return MPLS_SUCCESS;
+}
+
+void mpls_socket_readlist_del(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket)
+{
+  if (socket && socket->read) {
+    thread_cancel(socket->read);
+    socket->read = NULL;
+  }
+}
+
+mpls_return_enum mpls_socket_writelist_add(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, void *extra, mpls_socket_enum type)
+{
+  socket->type = type;
+  socket->extra = extra;
+  MPLS_ASSERT(socket && (socket->fd > -1));
+  socket->write = thread_add_write(master,mplsd_write,socket,socket->fd);
+  MPLS_ASSERT(socket->write);
+  return MPLS_SUCCESS;
+}
+
+void mpls_socket_writelist_del(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket)
+{
+  if (socket) {
+    thread_cancel(socket->write);
+    socket->write = NULL;
+  }
+}
+  
+int mpls_socket_tcp_read(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket,
+  uint8_t * buffer, int size)
+{
+  int ret = read(socket->fd,buffer,size);
+  if (ret < 0 && errno != EAGAIN) {
+    perror("mpls_socket_tcp_read");
+    return 0;
+  }
+  return ret;
+}
+
+int mpls_socket_tcp_write(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket,
+  uint8_t * buffer, int size)
+{
+  return write(socket->fd,buffer,size);
+}
+
+int mpls_socket_udp_sendto(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, uint8_t * buffer, int size, const mpls_dest * to)
+{
+  struct sockaddr addr;
+  int retval;
+
+  _mpls_dest2sockaddr(to, &addr);
+
+  retval = sendto(socket->fd,buffer,size,0,&addr,sizeof(struct sockaddr));
+
+  return retval;
+}
+
+int mpls_socket_udp_recvfrom(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, uint8_t * buffer, int size, mpls_dest * from)
+{
+  int ret;
+  unsigned int ifindex = 0;
+  struct iovec iov;
+  struct cmsghdr *cmsg;
+  struct in_pktinfo *pktinfo;
+  struct sockaddr addr;
+  char buff [sizeof (*cmsg) + sizeof (*pktinfo)];
+  struct msghdr msgh = {&addr, sizeof(struct sockaddr), &iov, 1, buff,
+                        sizeof (*cmsg) + sizeof (*pktinfo), 0};
+
+  iov.iov_base = buffer;
+  iov.iov_len = size;
+  ret = recvmsg(socket->fd,&msgh,0);
+
+  if (ret < 0 && errno != EAGAIN) {
+    return 0;
+  }
+
+  cmsg = CMSG_FIRSTHDR(&msgh);
+
+  if (cmsg != NULL &&
+      cmsg->cmsg_level == IPPROTO_IP &&
+      cmsg->cmsg_type == IP_PKTINFO) {
+      pktinfo = (struct in_pktinfo *)CMSG_DATA(cmsg);
+      ifindex = pktinfo->ipi_ifindex;
+      from->if_handle = if_lookup_by_index(ifindex);
+      _sockaddr2mpls_dest((const struct sockaddr*)&addr, from);
+  }
+
+  return ret;
+}
+
+mpls_return_enum mpls_socket_get_local_name(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, mpls_dest *name) {
+  struct sockaddr_in address;
+  char inode_str[32];
+  char fd_str[20];
+  int inode_num;
+  FILE *file = NULL;
+  char line[256];
+  int ret = 1;
+  int uid;
+  int euid;
+
+  /* the only way on linux to get the source address used for a TCP session
+   * is to find the 'inode of the socket' by looking at what
+   * /proc/self/fd/<socket fd> points to (symlink).  Using readlink() we
+   * can get the 'path' of the inode (something like 'socket:[<inode>]').
+   * We can then use that inode to find the TCP session info for the socket
+   * in /proc/net/tcp
+   *
+   * The local address of the socket is the 2nd column, the inode number is
+   * in the 14th column
+   *
+   * Since the sockets we create are done under 'CAP_NET_ADMIN' their
+   * entries in /proc/self/fd/ are all chmod 700, chown root.root.  So we
+   * cannot see what they point to without elevating our permissions.
+   * By using CAP_SETID we can issue a setuid(0) and seteuid(0) which
+   * allows us to read the files owned by root.
+   */
+
+  memset(inode_str, 0, sizeof(inode_str));
+  sprintf(fd_str, "/proc/self/fd/%d", socket->fd);
+
+  uid = getuid();
+  euid = geteuid();
+
+  if (ldpd_privs.change(ZPRIVS_RAISE))
+    zlog (NULL, LOG_ERR, "Can't raise privileges");
+
+  setuid(0);
+  seteuid(0);
+
+  ret = readlink(fd_str, inode_str, sizeof(inode_str));
+
+  setuid(uid);
+  seteuid(euid);
+
+  if (ldpd_privs.change(ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  if (ret <= 0)
+    goto mpls_socket_get_local_name_exit;
+
+  ret = sscanf(inode_str,"socket:[%d]", &inode_num);
+  if (ret != 1) {
+    ret = 1;
+    goto mpls_socket_get_local_name_exit;
+  }
+
+  file = fopen("/proc/net/tcp","r");
+  if (file == NULL)
+    goto mpls_socket_get_local_name_exit;
+
+  /* skip header */
+  fgets(line, sizeof(line), file);
+
+  while(!feof(file)) {
+    if (fgets(line, sizeof(line), file)) {
+      unsigned long rxq, txq, time_len, retr, inode;
+      int num, local_port, rem_port, d, state, uid, timer_run, timeout;
+      char rem_addr[128], local_addr[128], timers[64], buffer[1024], more[512];
+    
+      num = sscanf(line,
+      "%d: %64[0-9A-Fa-f]:%X %64[0-9A-Fa-f]:%X %X %lX:%lX %X:%lX %lX %d %d %ld %512s\n",
+        &d, local_addr, &local_port, rem_addr, &rem_port, &state,
+        &txq, &rxq, &timer_run, &time_len, &retr, &uid, &timeout, &inode, more);
+
+      if (num < 13)
+	break;
+
+      if (inode == inode_num) {
+        sscanf(local_addr, "%X", &address.sin_addr.s_addr);
+        address.sin_family = AF_INET;
+	address.sin_port = local_port;
+        ret = 0;
+	break;
+      }
+    }
+  }
+
+mpls_socket_get_local_name_exit:
+
+  if (file)
+    fclose(file);
+
+  if (ret) {
+    memset(name, 0, sizeof(mpls_dest));
+    return MPLS_FAILURE;
+  }
+  _sockaddr2mpls_dest((struct sockaddr*)&address, name);
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum mpls_socket_get_remote_name(mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, mpls_dest *name) {
+  struct sockaddr address;
+  int size = sizeof(address);
+  int ret;
+
+  ret = getpeername(socket->fd, &address, &size);
+  if (ret) {
+    memset(name, 0, sizeof(mpls_dest));
+    return MPLS_FAILURE;
+  }
+  _sockaddr2mpls_dest(&address, name);
+  return MPLS_SUCCESS;
+}
diff -Naur quagga-0.99.10/ldpd/impl_timer.c quagga-mpls/ldpd/impl_timer.c
--- quagga-0.99.10/ldpd/impl_timer.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_timer.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,93 @@
+#include "ldp_struct.h"
+#include "mpls_timer_impl.h"
+#include "mpls_mm_impl.h"
+
+#include "thread.h"
+
+struct mpls_timer {
+    struct thread *timer;
+    mpls_time_unit_enum unit;
+    int duration;
+    int type;
+    void *extra;
+    mpls_cfg_handle g;
+    void (*callback) (mpls_timer_handle timer, void *extra, mpls_cfg_handle g);
+    int active;
+};
+
+extern struct thread_master *master;
+
+int mpls_timer(struct thread* thread) {
+  mpls_timer_handle timer = THREAD_ARG(thread);
+
+  timer->active = 0;
+  if (timer->type == MPLS_TIMER_REOCCURRING) {
+    timer->timer = thread_add_timer(master,mpls_timer,timer,timer->duration);
+    timer->active = 1;
+  }
+  timer->callback(timer,timer->extra,timer->g);
+
+  return 0;
+}
+
+mpls_timer_mgr_handle mpls_timer_open(mpls_instance_handle user_data)
+{
+  return 0xdeadbeef;
+}
+
+void mpls_timer_close(mpls_timer_mgr_handle handle)
+{
+}
+
+mpls_timer_handle mpls_timer_create(mpls_timer_mgr_handle handle,
+  mpls_time_unit_enum unit, int duration, void *extra, mpls_cfg_handle g,
+  void (*callback) (mpls_timer_handle timer, void *extra, mpls_cfg_handle g))
+{
+  struct mpls_timer *timer;
+  timer = mpls_malloc(sizeof(struct mpls_timer));
+  timer->unit = unit;
+  timer->duration = duration;
+  timer->extra = extra;
+  timer->g = g;
+  timer->callback = callback;
+  timer->active = 0;
+
+  return timer;
+}
+
+mpls_return_enum mpls_timer_modify(mpls_timer_mgr_handle handle,
+  mpls_timer_handle timer, int duration)
+{
+  if (!timer) {
+    return MPLS_FAILURE;
+  }
+  timer->duration = duration;
+  return MPLS_SUCCESS;
+}
+
+void mpls_timer_delete(mpls_timer_mgr_handle handle, mpls_timer_handle timer)
+{
+  if (timer) {
+    mpls_free(timer);
+  }
+}
+
+mpls_return_enum mpls_timer_start(mpls_timer_mgr_handle handle,
+  mpls_timer_handle timer, mpls_timer_type_enum type)
+{
+  if (!timer) {
+    return MPLS_FAILURE;
+  }
+  timer->type = type;
+  timer->timer = thread_add_timer(master,mpls_timer,timer,timer->duration);
+  timer->active = 1;
+  return MPLS_SUCCESS;
+}
+
+void mpls_timer_stop(mpls_timer_mgr_handle handle, mpls_timer_handle timer)
+{
+  if (timer && timer->active) {
+    thread_cancel(timer->timer);
+    timer->timer = NULL;
+  }
+}
diff -Naur quagga-0.99.10/ldpd/impl_tree.c quagga-mpls/ldpd/impl_tree.c
--- quagga-0.99.10/ldpd/impl_tree.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/impl_tree.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,159 @@
+#include <zebra.h>
+#include "prefix.h"
+#include "table.h"
+
+#include "ldp_struct.h"
+#include "mpls_mm_impl.h"
+#include "mpls_tree_impl.h"
+
+mpls_tree_handle mpls_tree_create(int depth)
+{
+  return route_table_init();
+}
+
+mpls_return_enum mpls_tree_insert(mpls_tree_handle tree, uint32_t key, int length,
+  void *info)
+{
+  struct route_node *node;
+  struct prefix p;
+
+  p.family = AF_INET;
+  p.prefixlen = length;
+  p.u.prefix4.s_addr = key;
+
+  if ((node = route_node_get(tree,&p))) {
+    /* result is that the node is 'held', it will be held */
+    /* until it is deleted from the tree */
+    node->info = info;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum mpls_tree_remove(mpls_tree_handle tree, uint32_t key,
+  int length, void **info)
+{
+  struct route_node *node;
+  struct prefix p;
+
+  p.family = AF_INET;
+  p.prefixlen = length;
+  p.u.prefix4.s_addr = key;
+
+  if ((node = route_node_lookup(tree,&p))) {
+    *info = node->info;
+    node->info = NULL;
+    route_unlock_node(node);
+    route_unlock_node(node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum mpls_tree_replace(mpls_tree_handle tree, uint32_t key, int length,
+  void *new, void **old)
+{
+  struct route_node *node;
+  struct prefix p;
+
+  p.family = AF_INET;
+  p.prefixlen = length;
+  p.u.prefix4.s_addr = key;
+
+  if ((node = route_node_lookup(tree,&p))) {
+    *old = node->info;
+    node->info = new;
+    route_unlock_node(node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum mpls_tree_get(mpls_tree_handle tree, uint32_t key, int length,
+  void **info)
+{
+  struct route_node *node;
+  struct prefix p;
+
+  p.family = AF_INET;
+  p.prefixlen = length;
+  p.u.prefix4.s_addr = key;
+
+  if ((node = route_node_lookup(tree,&p))) {
+    *info = node->info;
+    route_unlock_node(node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum mpls_tree_get_longest(mpls_tree_handle tree, uint32_t key,
+  void **info)
+{
+  struct route_node *node;
+  struct prefix p;
+
+  p.family = AF_INET;
+  p.prefixlen = 0;
+  p.u.prefix4.s_addr = key;
+
+  if ((node = route_node_match(tree,&p))) {
+    *info = node->info;
+    route_unlock_node(node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+void mpls_tree_dump(const mpls_tree_handle tree, ldp_tree_callback callback)
+{
+}
+
+void mpls_tree_delete(mpls_tree_handle tree)
+{
+  route_table_finish(tree);
+}
+
+mpls_return_enum mpls_tree_getfirst(mpls_tree_handle tree, uint32_t * key,
+  int *length, void **info)
+{
+  struct route_node *node;
+  struct prefix p;
+
+  p.family = AF_INET;
+  p.prefixlen = 0;
+  p.u.prefix4.s_addr = 0;
+
+  if ((node = route_node_match(tree,&p))) {
+    *info = node->info;
+    *length = node->p.prefixlen;
+    *key = node->p.u.prefix4.s_addr;
+    route_unlock_node(node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum mpls_tree_getnext(mpls_tree_handle tree, uint32_t * key,
+  int *length, void **info)
+{
+  struct route_node *node;
+  struct prefix p;
+
+  p.family = AF_INET;
+  p.prefixlen = *length;
+  p.u.prefix4.s_addr = *key;
+
+  if (!(node = route_node_match(tree,&p))) {
+    return MPLS_FAILURE;
+  }
+
+  if ((node = route_next(node))) {
+    *info = node->info;
+    *length = node->p.prefixlen;
+    *key = node->p.u.prefix4.s_addr;
+    route_unlock_node(node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
diff -Naur quagga-0.99.10/ldpd/l2cc_interface.c quagga-mpls/ldpd/l2cc_interface.c
--- quagga-0.99.10/ldpd/l2cc_interface.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/l2cc_interface.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,98 @@
+#include <zebra.h>
+#include "memory.h"
+
+#include "ldp.h"
+#include "ldp_cfg.h"
+#include "ldp_struct.h"
+
+#include "ldp_interface.h"
+
+struct l2cc_interface *l2cc_if_new(struct ldp_interface *mi) {
+    struct l2cc_interface *li;
+
+    li = XMALLOC(MTYPE_LDP, sizeof(struct l2cc_interface));
+    memset(li, 0, sizeof(struct l2cc_interface));
+    li->mi = mi;
+
+    li->admin_up = MPLS_BOOL_TRUE;
+    li->create_on_hold = MPLS_BOOL_FALSE;
+
+    return li;
+}
+
+void l2cc_if_free(struct l2cc_interface *li) {
+    XFREE(MTYPE_LDP, li);
+}
+
+void l2cc_interface_create(struct ldp_interface *mi) {
+    struct ldp *ldp = ldp_get();
+
+    mi->l2cc->create_on_hold = MPLS_BOOL_FALSE;
+
+    ldp_cfg_fec_set(ldp->h, &mi->l2cc->l2cc, LDP_CFG_ADD);
+    ldp_cfg_fec_get(ldp->h, &mi->l2cc->l2cc, 0xFFFFFFFF);
+
+    l2cc_interface_admin_state_finish(mi);
+}
+
+void l2cc_interface_delete(struct ldp_interface *mi) {
+    struct ldp *ldp = ldp_get();
+
+    mi->l2cc->create_on_hold = MPLS_BOOL_TRUE;
+
+    if (ldp) {
+	l2cc_interface_admin_state_start(mi);
+	ldp_cfg_fec_set(ldp->h, &mi->l2cc->l2cc, LDP_CFG_DEL);
+    }
+    mi->l2cc->l2cc.index = 0;
+}
+
+int l2cc_interface_startup(struct ldp_interface *mi) {
+    struct ldp *ldp = ldp_get();
+
+    if (!mi->l2cc->l2cc.index) {
+	return MPLS_FAILURE;
+    }
+
+    ldp_cfg_fec_set(ldp->h, &mi->l2cc->l2cc, LDP_CFG_ADD);
+
+    return MPLS_SUCCESS;
+}
+
+int l2cc_interface_shutdown(struct ldp_interface *mi) {
+    struct ldp *ldp = ldp_get();
+
+    if (!mi->l2cc->l2cc.index) {
+	return MPLS_FAILURE;
+    }
+
+    ldp_cfg_fec_set(ldp->h, &mi->l2cc->l2cc, LDP_CFG_DEL);
+
+    return MPLS_SUCCESS;
+}
+
+int l2cc_interface_admin_state_start(struct ldp_interface *mi) {
+  if (mi->l2cc->admin_up == MPLS_BOOL_TRUE && ldp_interface_is_up(mi)) {
+    return l2cc_interface_shutdown(mi);
+  }
+  return MPLS_SUCCESS;
+}
+
+int l2cc_interface_admin_state_finish(struct ldp_interface *mi) {
+  if (mi->l2cc->admin_up == MPLS_BOOL_TRUE && ldp_interface_is_up(mi)) {
+    return l2cc_interface_startup(mi);
+  }
+  return MPLS_SUCCESS;
+}
+
+void l2cc_if_up(struct ldp_interface *mi) {
+    if (mi->l2cc && mi->l2cc->admin_up == MPLS_BOOL_TRUE) {
+	l2cc_interface_startup(mi);
+    }
+}
+
+void l2cc_if_down(struct ldp_interface *mi) {
+    if (mi->l2cc && mi->l2cc->admin_up == MPLS_BOOL_TRUE) {
+	l2cc_interface_shutdown(mi);
+    }
+}
diff -Naur quagga-0.99.10/ldpd/l2cc_interface.h quagga-mpls/ldpd/l2cc_interface.h
--- quagga-0.99.10/ldpd/l2cc_interface.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/l2cc_interface.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,29 @@
+#ifndef L2CC_IF_H
+#define L2CC_IF_H
+
+#include "ldp_struct.h"
+
+struct ldp_interface;
+
+struct l2cc_interface {
+    struct ldp_interface *mi;
+    mpls_fec l2cc;
+    mpls_bool admin_up;
+    mpls_bool create_on_hold;
+};
+
+struct l2cc_interface *l2cc_if_new(struct ldp_interface *mi);
+void l2cc_if_free(struct l2cc_interface *li);
+
+void l2cc_if_up(struct ldp_interface *mi);
+void l2cc_if_down(struct ldp_interface *mi);
+
+int l2cc_interface_startup(struct ldp_interface *mi);
+int l2cc_interface_shutdown(struct ldp_interface *mi);
+
+void l2cc_interface_create(struct ldp_interface *mi);
+void l2cc_interface_delete(struct ldp_interface *mi);
+int l2cc_interface_admin_state_start(struct ldp_interface *mi);
+int l2cc_interface_admin_state_finish(struct ldp_interface *mi);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_addr.c quagga-mpls/ldpd/ldp_addr.c
--- quagga-0.99.10/ldpd/ldp_addr.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_addr.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,377 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdlib.h>
+#include <string.h>
+#include <sys/socket.h>
+#include "ldp_struct.h"
+#include "ldp_global.h"
+#include "ldp_session.h"
+#include "ldp_entity.h"
+#include "ldp_pdu_setup.h"
+#include "ldp_addr.h"
+#include "ldp_nexthop.h"
+#include "ldp_if.h"
+#include "ldp_buf.h"
+#include "ldp_mesg.h"
+#include "mpls_list.h"
+#include "mpls_ifmgr_impl.h"
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+#include "mpls_tree_impl.h"
+
+static uint32_t _ldp_addr_next_index = 1;
+
+ldp_addr *ldp_addr_create(ldp_global *g, mpls_inet_addr * address)
+{
+  ldp_addr *a = (ldp_addr *) mpls_malloc(sizeof(ldp_addr));
+
+  LDP_ENTER(g->user_data, "ldp_addr_create: 0x%08x", address->u.ipv4);
+  if (a) {
+   /*
+    * note: this is init to 1 for a reason!
+    * We're placing it in the global list, so this is our refcnt
+    * when this refcnt gets to zero, it will be removed from the
+    * global list and deleted
+    */
+    /*
+     * TESTING: jleu 6/7/2004, since I want the addr to be cleaned up
+     * when it no longer has a nexthop, fec, or label, the only things that
+     * should increment the ref are those (nh, fec, label etc), not global
+     * nor inserting into the tree.
+    MPLS_REFCNT_INIT(a, 1);
+     */
+    MPLS_REFCNT_INIT(a, 0);
+    MPLS_LIST_INIT(&a->nh_root, ldp_nexthop);
+    MPLS_LIST_ELEM_INIT(a, _global);
+    MPLS_LIST_ELEM_INIT(a, _if);
+    memcpy(&a->address, address, sizeof(mpls_inet_addr));
+    a->index = _ldp_addr_get_next_index();
+    a->session = NULL;
+    _ldp_global_add_addr(g, a);
+    ldp_addr_insert2(g, a);
+  }
+  LDP_EXIT(g->user_data, "ldp_addr_create: %p", a);
+  return a;
+}
+
+void ldp_addr_delete(ldp_global *g, ldp_addr * a)
+{
+  LDP_PRINT(g->user_data, "addr delete: %p", a);
+  MPLS_REFCNT_ASSERT(a, 0);
+  ldp_addr_remove(g, &a->address);
+  _ldp_global_del_addr(g, a);
+  mpls_free(a);
+}
+
+ldp_addr *ldp_addr_find(ldp_global *g, mpls_inet_addr * address)
+{
+  ldp_addr *addr = NULL;
+
+  LDP_ENTER(g->user_data, "ldp_addr_find: 0x%08x", address->u.ipv4);
+  if (mpls_tree_get(g->addr_tree, address->u.ipv4, 32, (void **)&addr) !=
+    MPLS_SUCCESS) {
+    LDP_EXIT(g->user_data, "ldp_addr_find: NULL");
+    return NULL;
+  }
+  LDP_EXIT(g->user_data, "ldp_addr_find: %p", addr);
+  return addr;
+}
+
+ldp_addr *ldp_addr_insert(ldp_global *g, mpls_inet_addr * address)
+{
+  ldp_addr *addr = NULL;
+
+  if ((addr = ldp_addr_create(g, address)) == NULL) {
+    LDP_PRINT(g->user_data, "ldp_addr_insert: error creating address\n");
+    return NULL;
+  }
+  return addr;
+}
+
+mpls_return_enum ldp_addr_insert2(ldp_global *g, ldp_addr *addr)
+{
+  LDP_ENTER(g->user_data, "ldp_addr_insert2: 0x%08x", addr->address.u.ipv4);
+  if (mpls_tree_insert(g->addr_tree, addr->address.u.ipv4, 32, (void *)addr) !=
+    MPLS_SUCCESS) {
+    LDP_EXIT(g->user_data, "ldp_addr_insert2-error");
+    MPLS_REFCNT_RELEASE2(g, addr, ldp_addr_delete);
+    return MPLS_FATAL;
+  }
+  LDP_EXIT(g->user_data, "ldp_addr_insert2");
+  return MPLS_SUCCESS;
+}
+
+void ldp_addr_remove(ldp_global *g, mpls_inet_addr * address)
+{
+  ldp_addr *addr = NULL;
+  mpls_tree_remove(g->addr_tree, address->u.ipv4, 32, (void **)&addr);
+}
+
+void ldp_addr_add_if(ldp_addr * a, ldp_if * i)
+{
+  MPLS_ASSERT(a && i);
+  MPLS_REFCNT_HOLD(i);
+  a->iff = i;
+}
+
+void ldp_addr_del_if(ldp_global *g, ldp_addr * a)
+{
+  MPLS_ASSERT(a);
+  MPLS_REFCNT_RELEASE2(g, a->iff, ldp_if_delete);
+  a->iff = NULL;
+}
+
+mpls_bool ldp_addr_is_empty(ldp_addr *a)
+{
+    if ((a->iff == NULL) && MPLS_LIST_EMPTY(&a->nh_root) &&
+      (a->session == NULL)) {
+      return MPLS_BOOL_TRUE;
+    }
+    return MPLS_BOOL_FALSE;
+}
+
+mpls_return_enum _ldp_addr_add_session(ldp_addr * a, ldp_session * s)
+{
+  MPLS_ASSERT(a && s);
+  MPLS_REFCNT_HOLD(s);
+  a->session = s;
+  return MPLS_SUCCESS;
+}
+
+void _ldp_addr_del_session(ldp_addr * a, ldp_session * s)
+{
+  MPLS_ASSERT(a && s);
+  a->session = NULL;
+  MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+}
+
+/*
+ * We do not hold a ref to the nexthop.  The nexthop holds a ref to the
+ * addr.  Nexthop creation calls ldp_addr_add_nexthop, nexthop deletion
+ * calls ldp_addr_del_nexthop.  There is no way a nexthop can be deleted
+ * without removing the addrs ref to the nexthop.
+ */
+void ldp_addr_add_nexthop(ldp_addr * a, ldp_nexthop * nh)
+{
+  ldp_nexthop *np = NULL;
+
+  MPLS_ASSERT(a && nh);
+
+  ldp_nexthop_add_addr(nh,a);
+
+  np = MPLS_LIST_HEAD(&a->nh_root);
+  while (np != NULL) {
+    if (np->index > nh->index) {
+       MPLS_LIST_INSERT_BEFORE(&a->nh_root, np, nh, _addr);
+       return;
+    }
+    np = MPLS_LIST_NEXT(&a->nh_root, np, _addr);
+  }
+  MPLS_LIST_ADD_TAIL(&a->nh_root, nh, _addr, ldp_nexthop);
+}
+
+void ldp_addr_del_nexthop(ldp_global *g, ldp_addr * a, ldp_nexthop * nh)
+{
+  MPLS_ASSERT(a && nh);
+  MPLS_LIST_REMOVE(&a->nh_root, nh, _addr);
+  ldp_nexthop_del_addr(g, nh);
+}
+
+uint32_t _ldp_addr_get_next_index()
+{
+  uint32_t retval = _ldp_addr_next_index;
+
+  _ldp_addr_next_index++;
+  if (retval > _ldp_addr_next_index) {
+    _ldp_addr_next_index = 1;
+  }
+  return retval;
+}
+
+void ldp_addr_mesg_prepare(ldp_mesg * msg, ldp_global * g, uint32_t msgid,
+  mpls_inet_addr * addr)
+{
+  MPLS_MSGPTR(Adr);
+
+  LDP_ENTER(g->user_data, "ldp_addr_mesg_prepare");
+
+  ldp_mesg_prepare(msg, MPLS_ADDR_MSGTYPE, msgid);
+  MPLS_MSGPARAM(Adr) = &msg->u.addr;
+
+  MPLS_MSGPARAM(Adr)->adrListTlvExists = 1;
+  MPLS_MSGPARAM(Adr)->baseMsg.msgLength +=
+    setupAddrTlv(&(MPLS_MSGPARAM(Adr)->addressList));
+
+  MPLS_MSGPARAM(Adr)->baseMsg.msgLength +=
+    addAddrElem2AddrTlv(&(MPLS_MSGPARAM(Adr)->addressList), addr->u.ipv4);
+
+  LDP_EXIT(g->user_data, "ldp_addr_mesg_prepare");
+}
+
+void ldp_waddr_mesg_prepare(ldp_mesg * msg, ldp_global * g, uint32_t msgid,
+  mpls_inet_addr * addr)
+{
+  MPLS_MSGPTR(Adr);
+
+  LDP_ENTER(g->user_data, "ldp_waddr_mesg_prepare");
+
+  ldp_mesg_prepare(msg, MPLS_ADDRWITH_MSGTYPE, msgid);
+  MPLS_MSGPARAM(Adr) = &msg->u.addr;
+
+  MPLS_MSGPARAM(Adr)->adrListTlvExists = 1;
+  MPLS_MSGPARAM(Adr)->baseMsg.msgLength +=
+    setupAddrTlv(&(MPLS_MSGPARAM(Adr)->addressList));
+
+  MPLS_MSGPARAM(Adr)->baseMsg.msgLength +=
+    addAddrElem2AddrTlv(&(MPLS_MSGPARAM(Adr)->addressList), addr->u.ipv4);
+
+  LDP_EXIT(g->user_data, "ldp_waddr_mesg_prepare");
+}
+
+mpls_return_enum ldp_addr_send(ldp_global * g, ldp_session * s,
+  mpls_inet_addr * a)
+{
+  mpls_return_enum result = MPLS_FAILURE;
+
+  MPLS_ASSERT(s && a);
+
+  LDP_ENTER(g->user_data, "ldp_addr_send");
+
+  ldp_addr_mesg_prepare(s->tx_message, g, g->message_identifier++, a);
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_ADDRESS,
+    "Addr Send: session(%d)\n", s->index);
+
+  result = ldp_mesg_send_tcp(g, s, s->tx_message);
+
+  LDP_EXIT(g->user_data, "ldp_addr_send");
+
+  return result;
+}
+
+mpls_return_enum ldp_waddr_send(ldp_global * g, ldp_session * s,
+  mpls_inet_addr * a)
+{
+  mpls_return_enum result = MPLS_FAILURE;
+
+  MPLS_ASSERT(s && a);
+
+  LDP_ENTER(g->user_data, "ldp_waddr_send");
+
+  ldp_waddr_mesg_prepare(s->tx_message, g, g->message_identifier++, a);
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_ADDRESS,
+    "Addr Withdraw Send: session(%d)\n", s->index);
+
+  result = ldp_mesg_send_tcp(g, s, s->tx_message);
+
+  LDP_EXIT(g->user_data, "ldp_waddr_send");
+
+  return result;
+}
+
+mpls_return_enum ldp_addr_process(ldp_global * g, ldp_session * s,
+  ldp_entity * e, ldp_mesg * msg)
+{
+  mplsLdpAdrMsg_t *body = &msg->u.addr;
+  mpls_inet_addr inet;
+  ldp_addr *addr = NULL;
+  ldp_nexthop *nh = NULL;
+  ldp_fec *fec = NULL;
+  int len = (body->addressList.baseTlv.length - MPLS_ADDFAMFIXLEN) /
+    MPLS_IPv4LEN;
+  int i;
+
+  LDP_ENTER(g->user_data, "ldp_addr_process");
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_ADDRESS,
+    "Addr Recv: session(%d)\n", s->index);
+
+  for (i = 0; i < len; i++) {
+    inet.type = MPLS_FAMILY_IPV4;
+    inet.u.ipv4 = body->addressList.address[i];
+
+    if (msg->u.generic.flags.flags.msgType == MPLS_ADDR_MSGTYPE) {
+      if (!(addr = ldp_addr_find(g, &inet))) {
+        /* it's not in the tree, put it there! */
+	if ((addr = ldp_addr_insert(g, &inet)) == NULL) {
+          LDP_PRINT(g->user_data, "ldp_addr_process: error adding addr\n");
+          goto ldp_addr_process_end;
+        }
+      }
+
+      /* the addr is in the tree */
+      if (addr->session) {
+        LDP_PRINT(g->user_data,
+          "ldp_addr_process: session (%d) already advertised this address\n",
+          addr->session->index);
+        return MPLS_FAILURE;
+      }
+
+      if (ldp_session_add_addr(g, s, addr) == MPLS_FAILURE) {
+        LDP_PRINT(g->user_data,
+          "ldp_addr_process: error adding address to session\n");
+        return MPLS_FAILURE;
+      }
+
+      nh = MPLS_LIST_HEAD(&addr->nh_root);
+      while (nh != NULL) {
+        fec = nh->fec;
+	/* create cross connect */
+	/* send label mapping */
+        nh = MPLS_LIST_NEXT(&addr->nh_root, nh, _addr);
+      }
+    } else {
+      /* addr withdrawl */
+      if ((addr = ldp_addr_find(g, &inet))) {
+        nh = MPLS_LIST_HEAD(&addr->nh_root);
+        while (fec != NULL) {
+          /* send label withdrawl */
+          /* delete cross connect */
+          nh = MPLS_LIST_NEXT(&addr->nh_root, nh, _addr);
+        }
+
+        ldp_session_del_addr(g, s, addr);
+      }
+    }
+  }
+
+  LDP_EXIT(g->user_data, "ldp_addr_process");
+
+  return MPLS_SUCCESS;
+
+ldp_addr_process_end:
+
+  LDP_EXIT(g->user_data, "ldp_addr_process-error");
+
+  return MPLS_FAILURE;
+}
+
+void ldp_addr_process_add(ldp_global *g, struct ldp_addr *a)
+{
+  ldp_session* sp = MPLS_LIST_HEAD(&g->session);
+  while (sp != NULL) {
+    if (sp->state == LDP_STATE_OPERATIONAL) {
+      ldp_addr_send(g, sp, &a->address);
+    }
+    sp = MPLS_LIST_NEXT(&g->session, sp, _global);
+  }
+}
+
+void ldp_addr_process_remove(ldp_global *g, struct ldp_addr *a)
+{
+  ldp_session* sp = MPLS_LIST_HEAD(&g->session);
+  while (sp != NULL) {
+    if (sp->state == LDP_STATE_OPERATIONAL) {
+      ldp_waddr_send(g, sp, &a->address);
+    }
+    sp = MPLS_LIST_NEXT(&g->session, sp, _global);
+  }
+}
diff -Naur quagga-0.99.10/ldpd/ldp_addr.h quagga-mpls/ldpd/ldp_addr.h
--- quagga-0.99.10/ldpd/ldp_addr.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_addr.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,42 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_ADDR_H_
+#define _LDP_ADDR_H_
+
+#include "ldp_struct.h"
+
+extern ldp_addr *ldp_addr_find(ldp_global *g, mpls_inet_addr * address);
+extern mpls_return_enum ldp_addr_insert2(ldp_global *g, ldp_addr *addr);
+extern ldp_addr *ldp_addr_insert(ldp_global *g, mpls_inet_addr * address);
+extern void ldp_addr_remove(ldp_global *g, mpls_inet_addr * address);
+extern ldp_addr *ldp_addr_create(ldp_global *g, mpls_inet_addr * inet);
+extern void ldp_addr_delete(ldp_global *g, ldp_addr * a);
+extern void ldp_addr_add_if(ldp_addr * a, ldp_if * i);
+extern void ldp_addr_del_if(ldp_global *g, ldp_addr * a);
+extern mpls_bool ldp_addr_is_empty(ldp_addr *a);
+extern mpls_return_enum _ldp_addr_add_session(ldp_addr * a, ldp_session * s);
+extern void _ldp_addr_del_session(ldp_addr * a, ldp_session * s);
+extern void ldp_addr_add_nexthop(ldp_addr * a, ldp_nexthop * nh);
+extern void ldp_addr_del_nexthop(ldp_global *g, ldp_addr * a, ldp_nexthop * nh);
+extern uint32_t _ldp_addr_get_next_index();
+
+extern void ldp_addr_mesg_prepare(ldp_mesg * msg, ldp_global * g,
+  uint32_t msgid, mpls_inet_addr * a);
+
+extern mpls_return_enum ldp_addr_send(ldp_global * g, ldp_session * s,
+  mpls_inet_addr * a);
+extern mpls_return_enum ldp_waddr_send(ldp_global * g, ldp_session * s,
+  mpls_inet_addr * a);
+extern mpls_return_enum ldp_addr_process(ldp_global * g, ldp_session * s,
+  ldp_entity * e, ldp_mesg * msg);
+extern void ldp_addr_process_add(ldp_global *g, struct ldp_addr *a);
+extern void ldp_addr_process_remove(ldp_global *g, struct ldp_addr *a);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_adj.c quagga-mpls/ldpd/ldp_adj.c
--- quagga-0.99.10/ldpd/ldp_adj.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_adj.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,286 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdlib.h>
+#include <sys/socket.h>
+#include "ldp_struct.h"
+#include "ldp_global.h"
+#include "ldp_session.h"
+#include "ldp_hello.h"
+#include "ldp_global.h"
+#include "ldp_entity.h"
+#include "ldp_adj.h"
+#include "ldp_peer.h"
+#include "mpls_mm_impl.h"
+#include "mpls_assert.h"
+#include "mpls_timer_impl.h"
+#include "mpls_lock_impl.h"
+#include "mpls_trace_impl.h"
+
+static uint32_t _ldp_adj_next_index = 1;
+
+ldp_adj *ldp_adj_create(mpls_inet_addr * source, mpls_inet_addr * lsraddr,
+  int labelspace, int remote_hellotime,
+  mpls_inet_addr * remote_transport_address, uint32_t remote_csn)
+{
+  ldp_adj *a = (ldp_adj *) mpls_malloc(sizeof(ldp_adj));
+  struct in_addr addr;
+
+  if (lsraddr == NULL || source == NULL)
+    return NULL;
+
+  if (a) {
+    memset(a, 0, sizeof(ldp_adj));
+    MPLS_REFCNT_INIT(a, 0);
+    MPLS_LIST_ELEM_INIT(a, _global);
+    MPLS_LIST_ELEM_INIT(a, _session);
+    MPLS_LIST_ELEM_INIT(a, _entity);
+
+    a->index = _ldp_adj_get_next_index();
+
+    /* these are operational values */
+    /* JLEU: where do I grab these values from */
+
+    /* these values are learned form the remote peer */
+    memcpy(&a->remote_source_address, source, sizeof(mpls_inet_addr));
+    memcpy(&a->remote_lsr_address, lsraddr, sizeof(mpls_inet_addr));
+
+    addr.s_addr = htonl(lsraddr->u.ipv4);
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_PERIODIC,
+	"Adj(%d) created for %s/",a->index, inet_ntoa(addr));
+    addr.s_addr = htonl(source->u.ipv4);
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_PERIODIC,
+	"%s\n",inet_ntoa(addr));
+
+    if (remote_transport_address) {
+      memcpy(&a->remote_transport_address, remote_transport_address,
+        sizeof(mpls_inet_addr));
+    } else {
+      memset(&a->remote_transport_address, 0, sizeof(mpls_inet_addr));
+    }
+
+    a->remote_hellotime = remote_hellotime;
+    a->remote_csn = remote_csn;
+    a->state = MPLS_OPER_DOWN;
+    a->role = LDP_NONE;
+  }
+  return a;
+}
+
+void ldp_adj_delete(ldp_adj * a)
+{
+  LDP_PRINT(NULL,"adj delete %p", a);
+  MPLS_REFCNT_ASSERT(a, 0);
+  mpls_free(a);
+}
+
+mpls_return_enum ldp_adj_startup(ldp_global * g, ldp_adj * a, int request)
+{
+  ldp_entity *e;
+
+  MPLS_ASSERT(a && (e = a->entity));
+  /* with recent changes to when the session gets created I think this
+   * assert is not longer valid - jleu 2003-02-20
+  MPLS_ASSERT(!a->session);
+   */
+  MPLS_ASSERT(a->state != LDP_NONE);
+
+  LDP_ENTER(g->user_data, "ldp_adj_startup");
+
+  /* ldp-11 3.5.2. Hello Message */
+  if (e->hellotime_timer != 0xFFFF) {
+    MPLS_REFCNT_HOLD(a);
+    a->hellotime_recv_timer = mpls_timer_create(g->timer_handle, MPLS_UNIT_SEC,
+      e->hellotime_timer, (void *)a, g, ldp_hello_timeout_callback);
+
+    if (mpls_timer_handle_verify(g->timer_handle, a->hellotime_recv_timer) ==
+      MPLS_BOOL_FALSE) {
+      MPLS_REFCNT_RELEASE(a, ldp_adj_delete);
+      goto ldp_adj_startup_error;
+    }
+  }
+
+  if (request && mpls_timer_handle_verify(g->timer_handle,
+      e->p.peer->hellotime_send_timer) == MPLS_BOOL_FALSE) {
+    /* request is ONLY specific with indirect adj */
+    ldp_hello_send(g, e);
+  }
+
+  a->state = MPLS_OPER_UP;
+
+  if (e->hellotime_timer != 0xFFFF) {
+    mpls_timer_start(g->timer_handle, a->hellotime_recv_timer,
+      MPLS_TIMER_ONESHOT);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_adj_startup");
+
+  return MPLS_SUCCESS;
+
+ldp_adj_startup_error:
+
+  LDP_EXIT(g->user_data, "ldp_adj_startup: error");
+
+  return MPLS_FAILURE;
+}
+
+#if 0                           /* no one used this? */
+mpls_return_enum ldp_adj_restart(ldp_global * g, ldp_adj * a)
+{
+
+  LDP_ENTER(g->user_data, "ldp_adj_restart");
+
+  if (a->session != NULL) {
+    ldp_session_shutdown(g, a->session);
+    /* session_shutdown does this already ldp_adj_del_session(a); */
+  }
+  mpls_timer_stop(g->timer_handle, a->hellotime_recv_timer);
+  mpls_timer_start(g->timer_handle, a->hellotime_recv_timer, MPLS_TIMER_ONESHOT);
+
+  LDP_EXIT(g->user_data, "ldp_adj_restart");
+
+  return MPLS_SUCCESS;
+}
+#endif
+
+mpls_return_enum ldp_adj_shutdown(ldp_global * g, ldp_adj * a)
+{
+  ldp_entity *e;
+
+  MPLS_ASSERT(g && a && (e = a->entity));
+
+  LDP_ENTER(g->user_data, "ldp_adj_shutdown");
+
+  MPLS_REFCNT_HOLD(a);
+
+  if (a->session) {
+    ldp_session_shutdown(g, a->session, MPLS_BOOL_TRUE);
+    /* session_shutdown does ldp_adj_del_session(a); */
+  }
+
+  ldp_adj_recv_stop(g, a);
+
+  if (e->entity_type == LDP_INDIRECT &&
+    e->p.peer->target_role == LDP_PASSIVE) {
+    /* we started sending due to a targeted hello with "request"
+     * now that the adj is down we can stop
+     */
+    ldp_peer_send_stop(g, e->p.peer);
+  }
+
+  ldp_entity_del_adj(e, a);
+  if (a->state == MPLS_OPER_UP) {
+    _ldp_global_del_adj(g, a);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_adj_shutdown");
+
+  MPLS_REFCNT_RELEASE(a, ldp_adj_delete);
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_adj_maintain_timer(ldp_global * g, ldp_adj * a)
+{
+  mpls_return_enum retval;
+
+  LDP_ENTER(g->user_data, "ldp_adj_maintain_timer");
+
+  mpls_timer_stop(g->timer_handle, a->hellotime_recv_timer);
+  retval =
+    mpls_timer_start(g->timer_handle, a->hellotime_recv_timer, MPLS_TIMER_ONESHOT);
+
+  LDP_EXIT(g->user_data, "ldp_adj_maintain_timer");
+
+  return retval;
+}
+
+mpls_return_enum ldp_adj_recv_start(ldp_global * g, ldp_adj * a)
+{
+  mpls_return_enum result = MPLS_SUCCESS;
+
+  LDP_ENTER(g->user_data, "ldp_adj_recv_start");
+
+  MPLS_REFCNT_HOLD(a);
+  a->hellotime_recv_timer = mpls_timer_create(g->timer_handle, MPLS_UNIT_SEC,
+    a->entity->hellotime_timer, (void *)a, g, ldp_hello_timeout_callback);
+
+  if (mpls_timer_handle_verify(g->timer_handle, a->hellotime_recv_timer) ==
+    MPLS_BOOL_FALSE) {
+    MPLS_REFCNT_RELEASE(a, ldp_adj_delete);
+    result = MPLS_FAILURE;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_adj_recv_start");
+
+  return result;
+}
+
+mpls_return_enum ldp_adj_recv_stop(ldp_global * g, ldp_adj * a)
+{
+
+  LDP_ENTER(g->user_data, "ldp_adj_recv_stop");
+
+  if (mpls_timer_handle_verify(g->timer_handle, a->hellotime_recv_timer) ==
+    MPLS_BOOL_TRUE) {
+    mpls_timer_stop(g->timer_handle, a->hellotime_recv_timer);
+    mpls_timer_delete(g->timer_handle, a->hellotime_recv_timer);
+    a->hellotime_recv_timer = (mpls_timer_handle) 0;
+    MPLS_REFCNT_RELEASE(a, ldp_adj_delete);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_adj_recv_stop");
+
+  return MPLS_SUCCESS;
+}
+
+void _ldp_adj_add_entity(ldp_adj * a, ldp_entity * e)
+{
+  MPLS_ASSERT(a && e);
+  MPLS_REFCNT_HOLD(e);
+  a->entity = e;
+}
+
+void _ldp_adj_del_entity(ldp_adj * a, ldp_entity *e)
+{
+  MPLS_ASSERT(a && e);
+  MPLS_REFCNT_RELEASE(e, ldp_entity_delete);
+  a->entity = NULL;
+}
+
+void ldp_adj_add_session(ldp_adj * a, ldp_session * s)
+{
+  MPLS_ASSERT(a && s);
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_PERIODIC,
+	"Adj(%d) bound to sesssion(%d)\n",a->index,s->index);
+
+  MPLS_REFCNT_HOLD(s);
+  a->session = s;
+  _ldp_session_add_adj(s, a);
+}
+
+void ldp_adj_del_session(ldp_adj * a, ldp_session * s)
+{
+  MPLS_ASSERT(a && s);
+  _ldp_session_del_adj(s, a);
+  MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+  a->session = NULL;
+}
+
+uint32_t _ldp_adj_get_next_index()
+{
+  uint32_t retval = _ldp_adj_next_index;
+
+  _ldp_adj_next_index++;
+  if (retval > _ldp_adj_next_index) {
+    _ldp_adj_next_index = 1;
+  }
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_adj.h quagga-mpls/ldpd/ldp_adj.h
--- quagga-0.99.10/ldpd/ldp_adj.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_adj.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,33 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_ADJ_H_
+#define _LDP_ADJ_H_
+
+#include "ldp_struct.h"
+
+extern ldp_adj *ldp_adj_create(mpls_inet_addr * source,
+  mpls_inet_addr * lsraddr, int labelspace, int remote_hellotime,
+  mpls_inet_addr * remote_transport_address, uint32_t remote_csn);
+
+extern void ldp_adj_delete(ldp_adj * a);
+extern mpls_return_enum ldp_adj_startup(ldp_global * g, ldp_adj * a,
+  int request);
+extern mpls_return_enum ldp_adj_restart(ldp_global * g, ldp_adj * a);
+extern mpls_return_enum ldp_adj_shutdown(ldp_global * g, ldp_adj * a);
+extern mpls_return_enum ldp_adj_maintain_timer(ldp_global * g, ldp_adj * a);
+extern mpls_return_enum ldp_adj_recv_stop(ldp_global * g, ldp_adj * a);
+
+extern void _ldp_adj_add_entity(ldp_adj * a, ldp_entity * e);
+extern void _ldp_adj_del_entity(ldp_adj * a, ldp_entity * e);
+extern void ldp_adj_add_session(ldp_adj * a, ldp_session * s);
+extern void ldp_adj_del_session(ldp_adj * a, ldp_session * s);
+extern uint32_t _ldp_adj_get_next_index();
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_attr.c quagga-mpls/ldpd/ldp_attr.c
--- quagga-0.99.10/ldpd/ldp_attr.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_attr.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,1050 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_label_mapping.h"
+#include "ldp_attr.h"
+#include "ldp_if.h"
+#include "ldp_addr.h"
+#include "ldp_fec.h"
+#include "ldp_global.h"
+#include "ldp_inlabel.h"
+#include "ldp_outlabel.h"
+#include "ldp_session.h"
+#include "mpls_refcnt.h"
+#include "mpls_mm_impl.h"
+#include "mpls_tree_impl.h"
+#include "mpls_trace_impl.h"
+
+#if MPLS_USE_LSR
+#include "lsr_cfg.h"
+#else
+#include "mpls_mpls_impl.h"
+#endif
+
+static ldp_fec *_ldp_attr_get_fec2(ldp_global * g, mpls_fec * f, mpls_bool flag);
+static ldp_fec *_ldp_attr_get_fec(ldp_global * g, ldp_attr * a, mpls_bool flag);
+static ldp_fs *_ldp_fec_add_fs_ds(ldp_fec * fec, ldp_session * s);
+static ldp_fs *_ldp_fec_add_fs_us(ldp_fec * fec, ldp_session * s);
+static ldp_fs *_ldp_fec_find_fs_us(ldp_fec * fec, ldp_session * s,
+  mpls_bool flag);
+static ldp_fs *_ldp_fec_find_fs_ds(ldp_fec * fec, ldp_session * s,
+  mpls_bool flag);
+static void _ldp_fec_del_fs_us(ldp_fec * fec, ldp_fs * fs);
+static void _ldp_fec_del_fs_ds(ldp_fec * fec, ldp_fs * fs);
+static ldp_fs *_ldp_fs_create(ldp_session * s);
+static void _ldp_fs_delete(ldp_fs * fs);
+static ldp_attr *_ldp_fs_find_attr(ldp_fs * fs, ldp_attr * a);
+static mpls_return_enum _ldp_fs_add_attr(ldp_fs * fs, ldp_attr * a);
+static mpls_bool _ldp_fs_del_attr(ldp_global *g, ldp_fs * fs, ldp_attr * a);
+static uint32_t _ldp_attr_get_next_index();
+
+static uint32_t _ldp_attr_next_index = 1;
+
+int ldp_attr_num_us2ds(ldp_attr * ds)
+{
+  ldp_attr *attr = NULL;
+  int count = 0;
+
+  attr = MPLS_LIST_HEAD(&ds->us_attr_root);
+  while (attr) {
+    count++;
+    attr = MPLS_LIST_NEXT(&ds->us_attr_root, attr, _ds_attr);
+  }
+  return count;
+}
+
+mpls_bool ldp_attr_us_partof_ds(ldp_attr * us, ldp_attr * ds)
+{
+  if (us->ds_attr == ds) {
+    return MPLS_BOOL_TRUE;
+  }
+  return MPLS_BOOL_FALSE;
+}
+
+void ldp_attr_del_us2ds(ldp_global *g, ldp_attr * us, ldp_attr * ds)
+{
+  if (!us || !ds) {
+    return;
+  }
+  if (ldp_attr_us_partof_ds(us, ds) == MPLS_BOOL_TRUE) {
+    us->ds_attr = NULL;
+    MPLS_REFCNT_RELEASE2(g, ds, ldp_attr_delete);
+    MPLS_LIST_REMOVE(&ds->us_attr_root, us, _ds_attr);
+    MPLS_REFCNT_RELEASE2(g, us, ldp_attr_delete);
+  } else {
+    MPLS_ASSERT(0);
+  }
+}
+
+void ldp_attr_add_fec(ldp_attr *a, ldp_fec *fec) {
+  MPLS_ASSERT(a && fec);
+  MPLS_REFCNT_HOLD(fec);
+  a->fec = fec;
+}
+
+void ldp_attr_del_fec(ldp_global *g, ldp_attr *a) {
+  MPLS_ASSERT(a);
+  if (a->fec) {
+    MPLS_REFCNT_RELEASE2(g, a->fec, ldp_fec_delete);
+    a->fec = NULL;
+  }
+}
+
+void ldp_attr_add_us2ds(ldp_attr * us, ldp_attr * ds)
+{
+
+  if (!us || !ds) {
+    return;
+  }
+  if (ldp_attr_us_partof_ds(us, ds) == MPLS_BOOL_TRUE) {
+    return;
+  }
+  MPLS_REFCNT_HOLD(us);
+  MPLS_LIST_ADD_TAIL(&ds->us_attr_root, us, _ds_attr, ldp_attr);
+  MPLS_REFCNT_HOLD(ds);
+  us->ds_attr = ds;
+}
+
+void ldp_attr_action_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle g)
+{
+}
+
+ldp_attr *ldp_attr_find_downstream_state_any2(ldp_global * g, ldp_fec * f,
+  ldp_lsp_state state)
+{
+  ldp_attr *attr = NULL;
+  ldp_fs *fs = NULL;
+
+  fs = MPLS_LIST_HEAD(&f->fs_root_ds);
+  while (fs != NULL) {
+    attr = MPLS_LIST_HEAD(&fs->attr_root);
+    while (attr != NULL) {
+      if (attr->state == state) {
+        return attr;
+      }
+      attr = MPLS_LIST_NEXT(&fs->attr_root, attr, _fs);
+    }
+    fs = MPLS_LIST_NEXT(&f->fs_root_ds, fs, _fec);
+  }
+  return NULL;
+}
+
+ldp_attr *ldp_attr_find_downstream_state_any(ldp_global * g, mpls_fec * f,
+  ldp_lsp_state state)
+{
+  ldp_fec *fnode = _ldp_attr_get_fec2(g, f, MPLS_BOOL_FALSE);
+
+  if (!fnode) {
+    return NULL;
+  }
+
+  return ldp_attr_find_downstream_state_any2(g, fnode, state);
+}
+
+ldp_attr *ldp_attr_find_upstream_state_any2(ldp_global * g, ldp_fec * f,
+  ldp_lsp_state state)
+{
+  ldp_attr *attr = NULL;
+  ldp_fs *fs = NULL;
+
+  fs = MPLS_LIST_HEAD(&f->fs_root_us);
+  while (fs != NULL) {
+    attr = MPLS_LIST_HEAD(&fs->attr_root);
+    while (attr != NULL) {
+      if (attr->state == state) {
+        return attr;
+      }
+      attr = MPLS_LIST_NEXT(&fs->attr_root, attr, _fs);
+    }
+    fs = MPLS_LIST_NEXT(&f->fs_root_us, fs, _fec);
+  }
+  return NULL;
+}
+
+ldp_attr *ldp_attr_find_upstream_state_any(ldp_global * g, mpls_fec * f,
+  ldp_lsp_state state)
+{
+  ldp_fec *fnode = _ldp_attr_get_fec2(g, f, MPLS_BOOL_FALSE);
+
+  if (!fnode) {
+    return NULL;
+  }
+
+  return ldp_attr_find_upstream_state_any2(g, fnode, state);
+}
+
+static ldp_attr *_ldp_attr_find_downstream_state(ldp_attr_list *ds_list,
+  ldp_lsp_state state)
+{
+  if (ds_list != NULL) {
+    ldp_attr *ds_attr = MPLS_LIST_HEAD(ds_list);
+
+    while (ds_attr != NULL) {
+      if (ds_attr->state == state) {
+        return ds_attr;
+      }
+      ds_attr = MPLS_LIST_NEXT(ds_list, ds_attr, _fs);
+    }
+  }
+  return NULL;
+}
+
+ldp_attr *ldp_attr_find_downstream_state2(ldp_global * g, ldp_session * s,
+  ldp_fec * f, ldp_lsp_state state)
+{
+  ldp_attr_list *ds_list = ldp_attr_find_downstream_all2(g, s, f);
+  return _ldp_attr_find_downstream_state(ds_list, state);
+}
+
+ldp_attr *ldp_attr_find_downstream_state(ldp_global * g, ldp_session * s,
+  mpls_fec * f, ldp_lsp_state state)
+{
+  ldp_attr_list *ds_list = ldp_attr_find_downstream_all(g, s, f);
+  return _ldp_attr_find_downstream_state(ds_list, state);
+}
+
+static ldp_attr *_ldp_attr_find_upstream_state(ldp_attr_list *us_list,
+    ldp_lsp_state state)
+{
+  if (us_list != NULL) {
+    ldp_attr *us_attr = MPLS_LIST_HEAD(us_list);
+
+    while (us_attr != NULL) {
+      if (us_attr->state == state) {
+        return us_attr;
+      }
+      us_attr = MPLS_LIST_NEXT(us_list, us_attr, _fs);
+    }
+  }
+  return NULL;
+}
+
+ldp_attr *ldp_attr_find_upstream_state2(ldp_global * g, ldp_session * s,
+  ldp_fec * f, ldp_lsp_state state)
+{
+  ldp_attr_list *us_list = ldp_attr_find_upstream_all2(g, s, f);
+  return _ldp_attr_find_upstream_state(us_list, state);
+}
+
+ldp_attr *ldp_attr_find_upstream_state(ldp_global * g, ldp_session * s,
+  mpls_fec * f, ldp_lsp_state state)
+{
+  ldp_attr_list *us_list = ldp_attr_find_upstream_all(g, s, f);
+  return _ldp_attr_find_upstream_state(us_list, state);
+}
+
+void ldp_attr_remove_complete(ldp_global * g, ldp_attr * attr,
+		mpls_bool complete)
+{
+  ldp_session *session = attr->session;
+  ldp_outlabel *out = NULL;
+  ldp_inlabel *in = NULL;
+  ldp_attr *us_temp = NULL;
+  mpls_fec fec;
+  int i;
+
+  switch (attr->state) {
+    case LDP_LSP_STATE_MAP_RECV:
+      if (attr->ingress == MPLS_BOOL_TRUE) {
+        out = attr->outlabel;
+        MPLS_ASSERT(out != NULL);
+        while ((in = MPLS_LIST_HEAD(&out->inlabel_root)) != NULL) {
+          ldp_inlabel_del_outlabel(g, in);
+        }
+
+        if (out->merge_count > 0) {
+          for (i = 0; i < attr->fecTlv.numberFecElements; i++) {
+            fec_tlv2mpls_fec(&attr->fecTlv, i, &fec);
+            out->merge_count--;
+#if MPLS_USE_LSR
+            {
+              lsr_ftn ftn;
+              memcpy(&ftn.fec, &fec, sizeof(mpls_fec));
+              ftn.outsegment_index = out->info.handle;
+              lsr_cfg_ftn_set2(g->lsr_handle, &ftn, LSR_CFG_DEL);
+            }
+#else
+            mpls_mpls_fec2out_del(g->mpls_handle, &fec, &out->info);
+#endif
+          }
+        }
+        MPLS_ASSERT(out->merge_count == 0);
+        ldp_attr_del_outlabel(g, attr);
+        ldp_session_del_outlabel(g, session, out);
+      }
+      while ((us_temp = MPLS_LIST_HEAD(&attr->us_attr_root)) != NULL) {
+        ldp_attr_del_us2ds(g, us_temp, attr);
+      }
+      ldp_attr_delete_downstream(g, session, attr);
+      break;
+    case LDP_LSP_STATE_MAP_SENT:
+      in = attr->inlabel;
+      out = in->outlabel;
+
+      if (in->reuse_count == 1 && out) {
+        ldp_inlabel_del_outlabel(g, in);
+      }
+      ldp_attr_del_inlabel(g, attr);
+      ldp_attr_delete_upstream(g, session, attr);
+      ldp_attr_del_us2ds(g, attr, attr->ds_attr);
+      ldp_session_del_inlabel(g, session, in);
+      break;
+    case LDP_LSP_STATE_ABORT_SENT:
+    case LDP_LSP_STATE_NOTIF_SENT:
+    case LDP_LSP_STATE_REQ_RECV:
+    case LDP_LSP_STATE_WITH_SENT:
+    case LDP_LSP_STATE_NO_LABEL_RESOURCE_SENT:
+      {
+        ldp_attr_del_us2ds(g, attr, attr->ds_attr);
+        ldp_attr_delete_upstream(g, session, attr);
+        break;
+      }
+    case LDP_LSP_STATE_ABORT_RECV:
+    case LDP_LSP_STATE_NOTIF_RECV:
+    case LDP_LSP_STATE_REQ_SENT:
+    case LDP_LSP_STATE_WITH_RECV:
+    case LDP_LSP_STATE_NO_LABEL_RESOURCE_RECV:
+      {
+        while ((us_temp = MPLS_LIST_HEAD(&attr->us_attr_root)) != NULL) {
+          ldp_attr_del_us2ds(g, us_temp, attr);
+        }
+        ldp_attr_delete_downstream(g, session, attr);
+        break;
+      }
+  }
+}
+
+ldp_attr *ldp_attr_create(ldp_global *g, mpls_fec * fec)
+{
+  ldp_attr *a = (ldp_attr *) mpls_malloc(sizeof(ldp_attr));
+
+  if (a != NULL) {
+    memset(a, 0, sizeof(ldp_attr));
+    MPLS_LIST_ELEM_INIT(a, _session);
+    MPLS_LIST_ELEM_INIT(a, _global);
+    MPLS_LIST_ELEM_INIT(a, _fs);
+    MPLS_LIST_INIT(&a->us_attr_root, ldp_attr);
+    MPLS_REFCNT_INIT(a, 0);
+    a->index = _ldp_attr_get_next_index();
+    a->in_tree = MPLS_BOOL_FALSE;
+    a->ingress = MPLS_BOOL_FALSE;
+    a->filtered = MPLS_BOOL_FALSE;
+
+    if (fec != NULL) {
+      mpls_fec2fec_tlv(fec, &a->fecTlv, 0);
+      a->fecTlv.numberFecElements = 1;
+      a->fecTlvExists = 1;
+    }
+    _ldp_global_add_attr(g, a);
+  }
+  return a;
+}
+
+void ldp_attr_delete(ldp_global *g, ldp_attr * a)
+{
+  LDP_PRINT(g->user_data, "attr delete: %p", a);
+  MPLS_REFCNT_ASSERT(a, 0);
+  MPLS_ASSERT(a->in_tree == MPLS_BOOL_FALSE);
+  _ldp_global_del_attr(g, a);
+  mpls_free(a);
+}
+
+void ldp_attr2ldp_attr(ldp_attr * a, ldp_attr * b, uint32_t flag)
+{
+  if (a->fecTlvExists && flag & LDP_ATTR_FEC) {
+    memcpy(&b->fecTlv, &a->fecTlv, sizeof(mplsLdpFecTlv_t));
+    b->fecTlvExists = 1;
+  }
+  if (a->genLblTlvExists && flag & LDP_ATTR_LABEL) {
+    memcpy(&b->genLblTlv, &a->genLblTlv, sizeof(mplsLdpGenLblTlv_t));
+    b->genLblTlvExists = 1;
+  } else if (a->atmLblTlvExists && flag & LDP_ATTR_LABEL) {
+    memcpy(&b->atmLblTlv, &a->atmLblTlv, sizeof(mplsLdpAtmLblTlv_t));
+    b->atmLblTlvExists = 1;
+  } else if (a->frLblTlvExists && flag & LDP_ATTR_LABEL) {
+    memcpy(&b->frLblTlv, &a->frLblTlv, sizeof(mplsLdpFrLblTlv_t));
+    b->frLblTlvExists = 1;
+  }
+  if (a->hopCountTlvExists && flag & LDP_ATTR_HOPCOUNT) {
+    memcpy(&b->hopCountTlv, &a->hopCountTlv, sizeof(mplsLdpHopTlv_t));
+    b->hopCountTlvExists = 1;
+  }
+  if (a->pathVecTlvExists && flag & LDP_ATTR_PATH) {
+    memcpy(&b->pathVecTlv, &a->pathVecTlv, sizeof(mplsLdpPathTlv_t));
+    b->pathVecTlvExists = 1;
+  }
+  if (a->lblMsgIdTlvExists && flag & LDP_ATTR_MSGID) {
+    memcpy(&b->lblMsgIdTlv, &a->lblMsgIdTlv, sizeof(mplsLdpLblMsgIdTlv_t));
+    b->lblMsgIdTlvExists = 1;
+  }
+  if (a->lspidTlvExists && flag & LDP_ATTR_LSPID) {
+    memcpy(&b->lspidTlv, &a->lspidTlv, sizeof(mplsLdpLspIdTlv_t));
+    b->lspidTlvExists = 1;
+  }
+  if (a->trafficTlvExists && flag & LDP_ATTR_TRAFFIC) {
+    memcpy(&b->trafficTlv, &a->trafficTlv, sizeof(mplsLdpTrafficTlv_t));
+    b->trafficTlvExists = 1;
+  }
+}
+
+mpls_return_enum ldp_attr_add_inlabel(ldp_global *g, ldp_attr * a, ldp_inlabel * i)
+{
+  if (a && i) {
+    MPLS_REFCNT_HOLD(i);
+    a->inlabel = i;
+    _ldp_inlabel_add_attr(g, i, a);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_attr_del_inlabel(ldp_global *g, ldp_attr * a)
+{
+  if (a && a->inlabel) {
+    _ldp_inlabel_del_attr(g, a->inlabel, a);
+    MPLS_REFCNT_RELEASE2(g, a->inlabel, ldp_inlabel_delete);
+    a->inlabel = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_attr_add_outlabel(ldp_attr * a, ldp_outlabel * o)
+{
+  if (a && o) {
+    MPLS_REFCNT_HOLD(o);
+    a->outlabel = o;
+    _ldp_outlabel_add_attr(o, a);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_attr_del_outlabel(ldp_global * g, ldp_attr * a)
+{
+  if (a && a->outlabel) {
+    _ldp_outlabel_del_attr(g, a->outlabel);
+    MPLS_REFCNT_RELEASE2(g, a->outlabel, ldp_outlabel_delete);
+    a->outlabel = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_attr_add_session(ldp_attr * a, ldp_session * s)
+{
+  if (a && s) {
+    MPLS_REFCNT_HOLD(s);
+    a->session = s;
+    _ldp_session_add_attr(s, a);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_attr_del_session(ldp_global *g, ldp_attr * a)
+{
+  if (a && a->session) {
+    _ldp_session_del_attr(g, a->session, a);
+    MPLS_REFCNT_RELEASE(a->session, ldp_session_delete);
+    a->session = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_bool ldp_attr_is_equal(ldp_attr * a, ldp_attr * b, uint32_t flag)
+{
+  if (flag & LDP_ATTR_LABEL) {
+    if (a->genLblTlvExists && b->genLblTlvExists) {
+      if (a->genLblTlv.label != b->genLblTlv.label) {
+        return MPLS_BOOL_FALSE;
+      }
+    } else if (a->atmLblTlvExists && b->atmLblTlvExists) {
+      if (a->atmLblTlv.flags.flags.vpi != b->atmLblTlv.flags.flags.vpi ||
+        a->atmLblTlv.vci != b->atmLblTlv.vci) {
+        return MPLS_BOOL_FALSE;
+      }
+    } else if (a->frLblTlvExists && b->frLblTlvExists) {
+      if (a->frLblTlv.flags.flags.len != b->frLblTlv.flags.flags.len ||
+        a->frLblTlv.flags.flags.dlci != b->frLblTlv.flags.flags.dlci) {
+        return MPLS_BOOL_FALSE;
+      }
+    } else {
+      return MPLS_BOOL_FALSE;
+    }
+  }
+  if (flag & LDP_ATTR_HOPCOUNT) {
+    if (a->hopCountTlvExists && b->hopCountTlvExists) {
+      if (a->hopCountTlv.hcValue != b->hopCountTlv.hcValue) {
+        return MPLS_BOOL_FALSE;
+      }
+    } else {
+      if (a->hopCountTlvExists != b->hopCountTlvExists) {
+        return MPLS_BOOL_FALSE;
+      }
+    }
+  }
+  if (flag & LDP_ATTR_PATH) {
+    int i;
+
+    if (a->pathVecTlvExists && b->pathVecTlvExists) {
+      for (i = 0; i < MPLS_MAXHOPSNUMBER; i++) {
+        if (a->pathVecTlv.lsrId[i] != b->pathVecTlv.lsrId[i]) {
+          return MPLS_BOOL_FALSE;
+        }
+      }
+    } else {
+      if (a->hopCountTlvExists != b->hopCountTlvExists) {
+        return MPLS_BOOL_FALSE;
+      }
+    }
+  }
+  if (flag & LDP_ATTR_FEC) {
+    int i;
+
+    if (a->fecTlvExists && b->fecTlvExists) {
+      if (a->fecTlv.numberFecElements != b->fecTlv.numberFecElements) {
+        return MPLS_BOOL_FALSE;
+      }
+      for (i = 0; i < a->fecTlv.numberFecElements; i++) {
+        if (a->fecTlv.fecElemTypes[i] != b->fecTlv.fecElemTypes[i]) {
+          return MPLS_BOOL_FALSE;
+        }
+        switch (a->fecTlv.fecElemTypes[i]) {
+          case MPLS_CRLSP_FEC:
+          case MPLS_WC_FEC:
+            /* nothing of interest to compare */
+            break;
+          case MPLS_PREFIX_FEC:
+          case MPLS_HOSTADR_FEC:
+            if (a->fecTlv.fecElArray[i].addressEl.addressFam !=
+              b->fecTlv.fecElArray[i].addressEl.addressFam ||
+              a->fecTlv.fecElArray[i].addressEl.preLen !=
+              b->fecTlv.fecElArray[i].addressEl.preLen ||
+              a->fecTlv.fecElArray[i].addressEl.address !=
+              b->fecTlv.fecElArray[i].addressEl.address) {
+              return MPLS_BOOL_FALSE;
+            }
+            break;
+          default:
+            MPLS_ASSERT(0);
+        }
+      }
+    } else {
+      return MPLS_BOOL_FALSE;
+    }
+  }
+  if (flag & LDP_ATTR_MSGID) {
+    if (a->lblMsgIdTlvExists && b->lblMsgIdTlvExists) {
+      if (a->lblMsgIdTlv.msgId != b->lblMsgIdTlv.msgId) {
+        return MPLS_BOOL_FALSE;
+      }
+    } else {
+      return MPLS_BOOL_FALSE;
+    }
+  }
+  if (flag & LDP_ATTR_LSPID) {
+    if (a->lspidTlvExists && b->lspidTlvExists) {
+      if (a->lspidTlv.localCrlspId != b->lspidTlv.localCrlspId ||
+        a->lspidTlv.routerId != b->lspidTlv.routerId) {
+        return MPLS_BOOL_FALSE;
+      }
+    } else {
+      return MPLS_BOOL_FALSE;
+    }
+  }
+  if (flag & LDP_ATTR_TRAFFIC) {
+  }
+  return MPLS_BOOL_TRUE;
+}
+
+mpls_return_enum ldp_attr_insert_upstream2(ldp_global * g, ldp_session * s,
+  ldp_attr * a, ldp_fec *f)
+{
+  ldp_fs *fs = NULL;
+  mpls_return_enum retval;
+
+  MPLS_ASSERT(g && s && a && (a->in_tree == MPLS_BOOL_FALSE) && f);
+
+  /* find the upstream fs for this session */
+  if ((fs = _ldp_fec_find_fs_us(f, s, MPLS_BOOL_TRUE)) == NULL) {
+    /* this session isn't in the list and cannot be added */
+    return MPLS_FAILURE;
+  }
+
+  ldp_attr_add_session(a, s);
+  ldp_attr_add_fec(a, f);
+
+  retval = _ldp_fs_add_attr(fs, a);
+  a->in_tree = MPLS_BOOL_TRUE;
+  return retval;
+}
+
+mpls_return_enum ldp_attr_insert_upstream(ldp_global * g, ldp_session * s,
+  ldp_attr * a)
+{
+  ldp_fec *fnode = NULL;
+
+  MPLS_ASSERT(g && s && a && (a->in_tree == MPLS_BOOL_FALSE));
+
+  if ((fnode = _ldp_attr_get_fec(g, a, MPLS_BOOL_TRUE)) == NULL) {
+    /* we couldn't get/add a node from/to the tree! */
+    return MPLS_FAILURE;
+  }
+
+  return ldp_attr_insert_upstream2(g, s, a, fnode);
+}
+
+mpls_return_enum ldp_attr_insert_downstream2(ldp_global * g, ldp_session * s,
+  ldp_attr * a, ldp_fec *f)
+{
+  ldp_fs *fs = NULL;
+  mpls_return_enum retval;
+
+  MPLS_ASSERT(g && s && a && (a->in_tree == MPLS_BOOL_FALSE) && f);
+
+  /* find the downstream fs for this session */
+  if ((fs = _ldp_fec_find_fs_ds(f, s, MPLS_BOOL_TRUE)) == NULL) {
+    /* this session isn't in the list and cannot be added */
+    return MPLS_FAILURE;
+  }
+
+  ldp_attr_add_session(a, s);
+  ldp_attr_add_fec(a, f);
+
+  retval = _ldp_fs_add_attr(fs, a);
+  a->in_tree = MPLS_BOOL_TRUE;
+  return retval;
+}
+
+mpls_return_enum ldp_attr_insert_downstream(ldp_global * g, ldp_session * s,
+  ldp_attr * a)
+{
+  ldp_fec *fnode = NULL;
+
+  MPLS_ASSERT(g && s && a && (a->in_tree == MPLS_BOOL_FALSE));
+
+  if ((fnode = _ldp_attr_get_fec(g, a, MPLS_BOOL_TRUE)) == NULL) {
+    /* we couldn't get/add a node from/to the tree! */
+    return MPLS_FAILURE;
+  }
+
+  return ldp_attr_insert_downstream2(g, s, a, fnode);
+}
+
+ldp_attr_list *ldp_attr_find_upstream_all2(ldp_global * g, ldp_session * s,
+  ldp_fec * f)
+{
+  ldp_fs *fs = NULL;
+
+  MPLS_ASSERT(f && g);
+
+  if (!s) {
+    return NULL;
+  }
+
+  /* find the upstream fs for this session */
+  if ((fs = _ldp_fec_find_fs_us(f, s, MPLS_BOOL_FALSE)) == NULL) {
+    /* this session isn't in the list */
+    return NULL;
+  }
+  return &fs->attr_root;
+}
+
+ldp_attr_list *ldp_attr_find_upstream_all(ldp_global * g, ldp_session * s,
+  mpls_fec * f)
+{
+  ldp_fec *fnode = NULL;
+
+  MPLS_ASSERT(f && g);
+
+  if (!s) {
+    return NULL;
+  }
+
+  if ((fnode = _ldp_attr_get_fec2(g, f, MPLS_BOOL_FALSE)) == NULL) {
+    /* we couldn't get the node from the tree! */
+    return NULL;
+  }
+
+  return ldp_attr_find_upstream_all2(g, s, fnode);
+}
+
+ldp_attr_list *ldp_attr_find_downstream_all2(ldp_global * g, ldp_session * s,
+  ldp_fec * f)
+{
+  ldp_fs *fs = NULL;
+
+  MPLS_ASSERT(f && g);
+
+  if (!s) {
+    return NULL;
+  }
+
+  /* find the downstream fs for this session */
+  if ((fs = _ldp_fec_find_fs_ds(f, s, MPLS_BOOL_FALSE)) == NULL) {
+    /* this session isn't in the list */
+    return NULL;
+  }
+  return &fs->attr_root;
+}
+
+ldp_attr_list *ldp_attr_find_downstream_all(ldp_global * g, ldp_session * s,
+  mpls_fec * f)
+{
+  ldp_fec *fnode = NULL;
+
+  MPLS_ASSERT(f && g);
+
+  if (!s) {
+    return NULL;
+  }
+
+  if ((fnode = _ldp_attr_get_fec2(g, f, MPLS_BOOL_FALSE)) == NULL) {
+    /* we couldn't get the node from the tree! */
+    return NULL;
+  }
+
+  return ldp_attr_find_downstream_all2(g, s, fnode);
+}
+
+void ldp_attr_delete_upstream(ldp_global * g, ldp_session * s, ldp_attr * a)
+{
+  ldp_fec *fnode = NULL;
+  ldp_fs *fs = NULL;
+
+  MPLS_ASSERT(a->in_tree == MPLS_BOOL_TRUE);
+
+  MPLS_REFCNT_HOLD(a);
+
+  /* find the fec node in the tree */
+  if ((fnode = _ldp_attr_get_fec(g, a, MPLS_BOOL_FALSE))) {
+    /* find the upstream fs for this session, on the fec */
+    if ((fs = _ldp_fec_find_fs_us(fnode, s, MPLS_BOOL_FALSE))) {
+      /* remove this attr from the fs, if this was the last
+       * attr on the fs, then remove the fs from the fec node
+       */
+      if (_ldp_fs_del_attr(g, fs, a) == MPLS_BOOL_TRUE) {
+        _ldp_fec_del_fs_us(fnode, fs);
+      }
+    }
+  }
+
+  ldp_attr_del_session(g, a);
+  ldp_attr_del_fec(g, a);
+
+  a->in_tree = MPLS_BOOL_FALSE;
+  MPLS_REFCNT_RELEASE2(g, a, ldp_attr_delete);
+}
+
+void ldp_attr_delete_downstream(ldp_global * g, ldp_session * s, ldp_attr * a)
+{
+  ldp_fec *fnode = NULL;
+  ldp_fs *fs = NULL;
+
+  MPLS_ASSERT(a->in_tree == MPLS_BOOL_TRUE);
+
+  MPLS_REFCNT_HOLD(a);
+  /* see ldp_attr_delete_upstream for more info */
+  if ((fnode = _ldp_attr_get_fec(g, a, MPLS_BOOL_FALSE))) {
+    if ((fs = _ldp_fec_find_fs_ds(fnode, s, MPLS_BOOL_FALSE))) {
+      if (_ldp_fs_del_attr(g, fs, a) == MPLS_BOOL_TRUE) {
+        _ldp_fec_del_fs_ds(fnode, fs);
+      }
+    }
+  }
+
+  ldp_attr_del_session(g, a);
+  ldp_attr_del_fec(g, a);
+
+  a->in_tree = MPLS_BOOL_FALSE;
+  MPLS_REFCNT_RELEASE2(g, a, ldp_attr_delete);
+}
+
+void ldp_attr2mpls_label_struct(ldp_attr * a, mpls_label_struct * l)
+{
+  if (a->genLblTlvExists) {
+    l->type = MPLS_LABEL_TYPE_GENERIC;
+    l->u.gen = a->genLblTlv.label;
+  } else if (a->atmLblTlvExists) {
+    l->type = MPLS_LABEL_TYPE_ATM;
+    l->u.atm.vpi = a->atmLblTlv.flags.flags.vpi;
+    l->u.atm.vci = a->atmLblTlv.vci;
+  } else if (a->frLblTlvExists) {
+    l->type = MPLS_LABEL_TYPE_FR;
+    l->u.fr.len = a->frLblTlv.flags.flags.len;
+    l->u.fr.dlci = a->frLblTlv.flags.flags.dlci;
+  } else {
+    MPLS_ASSERT(0);
+  }
+}
+
+void mpls_label_struct2ldp_attr(mpls_label_struct * l, ldp_attr * a)
+{
+  switch (l->type) {
+    case MPLS_LABEL_TYPE_GENERIC:
+      a->genLblTlvExists = 1;
+      a->atmLblTlvExists = 0;
+      a->frLblTlvExists = 0;
+      a->genLblTlv.label = l->u.gen;
+      break;
+    case MPLS_LABEL_TYPE_ATM:
+      a->genLblTlvExists = 0;
+      a->atmLblTlvExists = 1;
+      a->frLblTlvExists = 0;
+      a->atmLblTlv.flags.flags.vpi = l->u.atm.vpi;
+      a->atmLblTlv.vci = l->u.atm.vci;
+    case MPLS_LABEL_TYPE_FR:
+      a->genLblTlvExists = 0;
+      a->atmLblTlvExists = 0;
+      a->frLblTlvExists = 1;
+      a->frLblTlv.flags.flags.len = l->u.fr.len;
+      a->frLblTlv.flags.flags.dlci = l->u.fr.dlci;
+    default:
+      MPLS_ASSERT(0);
+  }
+}
+
+#if 0
+void ldp_attr2ldp_attr(ldp_attr * src, ldp_attr * dst, u_int32 flag)
+{
+  if (flag & LDP_ATTR_FEC) {
+    memcpy(&dst->fecTlv, &src->fecTlv, sizeof(mplsLdpFecTlv_t));
+    dst->fecTlvExists = src->fecTlvExists;
+  }
+  if (flag & LDP_ATTR_LABEL) {
+    memcpy(&dst->genLblTlv, &src->genLblTlv, sizeof(mplsLdpGenLblTlv_t));
+    memcpy(&dst->atmLblTlv, &src->atmLblTlv, sizeof(mplsLdpAtmLblTlv_t));
+    memcpy(&dst->frLblTlv, &src->frLblTlv, sizeof(mplsLdpFrLblTlv_t));
+    dst->genLblTlvExists = src->genLblTlvExists
+      dst->atmLblTlvExists = src->atmLblTlvExists
+      dst->frLblTlvExists = src->frLblTlvExists}
+  if (flag & LDP_ATTR_HOPCOUNT) {
+    memcpy(&dst->hopCountTlv, &src->hopCountTlv, sizeof(mplsLdpHopTlv_t));
+    dst->hopCountTlvExists = src->hopCountTlvExists;
+  }
+  if (flag & LDP_ATTR_PATH) {
+    memcpy(&dst->pathVecTlv, &src->pathVecTlv, sizeof(mplsLdpPathTlv_t));
+    dst->pathVecTlvExists = src->pathVecTlvExists;
+  }
+  if (flag & LDP_ATTR_MSGID) {
+    memcpy(&dst->lblMsgIdTlv, &src->lblMsgIdTlv, sizeof(mplsLdpLblMsgIdTlv_t));
+    dst->lblMsgIdTlvExists = src->lblMsgIdTlvExists;
+  }
+  if (flag & LDP_ATTR_LSPID) {
+    memcpy(&dst->lspidTlv, &src->lspidTlv, sizeof(mplsLdpLspIdTlv_t));
+    dst->lspidTlvExists = src->lspidTlvExists;
+  }
+  if (flag & LDP_ATTR_TRAFFIC) {
+    memcpy(&dst->trafficTlv, &src->trafficTlv, sizeof(mplsLdpTrafficTlv_t));
+    dst->trafficTlvExists = src->trafficTlvExists;
+  }
+}
+#endif
+
+ldp_fec *_ldp_attr_get_fec2(ldp_global * g, mpls_fec * f, mpls_bool flag)
+{
+  ldp_fec *fnode = NULL;
+
+  if (!(fnode = ldp_fec_find(g,f))) {
+    if (flag == MPLS_BOOL_FALSE) {
+      return NULL;
+    }
+
+    /* this FEC doesn't exist in the tree yet, create one ... */
+    if (!(fnode = ldp_fec_create(g, f))) {
+      /* insert failed */
+      return NULL;
+    }
+  }
+  return fnode;
+}
+
+static ldp_fec *_ldp_attr_get_fec(ldp_global * g, ldp_attr * a, mpls_bool flag)
+{
+  mpls_fec fec;
+
+  /* get FEC from attr */
+  fec_tlv2mpls_fec(&a->fecTlv, 0, &fec);
+  return _ldp_attr_get_fec2(g, &fec, flag);
+}
+
+static ldp_fs *_ldp_fec_add_fs_ds(ldp_fec * fec, ldp_session * s)
+{
+  ldp_fs *fs = _ldp_fec_find_fs_ds(fec, s, MPLS_BOOL_FALSE);
+
+  if (fs == NULL) {
+    fs = _ldp_fs_create(s);
+    if (fs == NULL) {
+      return NULL;
+    }
+    MPLS_LIST_ADD_HEAD(&fec->fs_root_ds, fs, _fec, ldp_fs);
+  }
+  return fs;
+}
+
+static ldp_fs *_ldp_fec_add_fs_us(ldp_fec * fec, ldp_session * s)
+{
+  ldp_fs *fs = _ldp_fec_find_fs_us(fec, s, MPLS_BOOL_FALSE);
+
+  if (fs == NULL) {
+    fs = _ldp_fs_create(s);
+    if (fs == NULL) {
+      return NULL;
+    }
+    MPLS_LIST_ADD_HEAD(&fec->fs_root_us, fs, _fec, ldp_fs);
+  }
+  return fs;
+}
+
+static ldp_fs *_ldp_fec_find_fs_us(ldp_fec * fec, ldp_session * s,
+  mpls_bool flag)
+{
+  ldp_fs *fs = MPLS_LIST_HEAD(&fec->fs_root_us);
+
+  while (fs != NULL) {
+    if (fs->session->index == s->index) {
+      return fs;
+    }
+    fs = MPLS_LIST_NEXT(&fec->fs_root_us, fs, _fec);
+  }
+  if (flag == MPLS_BOOL_FALSE) {
+    return NULL;
+  }
+  return _ldp_fec_add_fs_us(fec, s);
+}
+
+static ldp_fs *_ldp_fec_find_fs_ds(ldp_fec * fec, ldp_session * s,
+  mpls_bool flag)
+{
+  ldp_fs *fs = MPLS_LIST_HEAD(&fec->fs_root_ds);
+
+  while (fs != NULL) {
+    if (fs->session->index == s->index) {
+      return fs;
+    }
+    fs = MPLS_LIST_NEXT(&fec->fs_root_ds, fs, _fec);
+  }
+  if (flag == MPLS_BOOL_FALSE) {
+    return NULL;
+  }
+  return _ldp_fec_add_fs_ds(fec, s);
+}
+
+static void _ldp_fec_del_fs_us(ldp_fec * fec, ldp_fs * fs)
+{
+  if (fs == NULL) {
+    return;
+  }
+  MPLS_LIST_REMOVE(&fec->fs_root_us, fs, _fec);
+  _ldp_fs_delete(fs);
+}
+
+static void _ldp_fec_del_fs_ds(ldp_fec * fec, ldp_fs * fs)
+{
+  if (fs == NULL) {
+    return;
+  }
+  MPLS_LIST_REMOVE(&fec->fs_root_ds, fs, _fec);
+  _ldp_fs_delete(fs);
+}
+
+static ldp_fs *_ldp_fs_create(ldp_session * s)
+{
+  ldp_fs *fs = (ldp_fs *) mpls_malloc(sizeof(ldp_fs));
+
+  if (fs != NULL) {
+    memset(fs, 0, sizeof(ldp_fs));
+    MPLS_LIST_INIT(&fs->attr_root, ldp_attr);
+    MPLS_LIST_ELEM_INIT(fs, _fec);
+    if (s != NULL) {
+      MPLS_REFCNT_HOLD(s);
+      fs->session = s;
+    }
+  }
+  return fs;
+}
+
+static void _ldp_fs_delete(ldp_fs * fs)
+{
+  LDP_PRINT(NULL, "fs delete %p", fs);
+  if (fs->session != NULL) {
+    MPLS_REFCNT_RELEASE(fs->session, ldp_session_delete);
+  }
+  mpls_free(fs);
+}
+
+static ldp_attr *_ldp_fs_find_attr(ldp_fs * fs, ldp_attr * a)
+{
+  ldp_attr *ptr = MPLS_LIST_HEAD(&fs->attr_root);
+
+  while (ptr != NULL) {
+    if (ldp_attr_is_equal(a, ptr, LDP_ATTR_LABEL | LDP_ATTR_FEC) == MPLS_BOOL_TRUE) {
+      return ptr;
+    }
+    ptr = MPLS_LIST_NEXT(&fs->attr_root, ptr, _fs);
+  }
+  return NULL;
+}
+
+static mpls_return_enum _ldp_fs_add_attr(ldp_fs * fs, ldp_attr * a)
+{
+  ldp_attr *ptr = _ldp_fs_find_attr(fs, a);
+
+  MPLS_ASSERT(ptr == NULL);
+  MPLS_REFCNT_HOLD(a);
+  MPLS_LIST_ADD_HEAD(&fs->attr_root, a, _fs, ldp_attr);
+  return MPLS_SUCCESS;
+}
+
+static mpls_bool _ldp_fs_del_attr(ldp_global *g, ldp_fs * fs, ldp_attr * a)
+{
+  ldp_attr *ptr = _ldp_fs_find_attr(fs, a);
+
+  if (ptr != NULL) {
+    MPLS_LIST_REMOVE(&fs->attr_root, ptr, _fs);
+    MPLS_REFCNT_RELEASE2(g, ptr, ldp_attr_delete);
+  }
+  if (MPLS_LIST_HEAD(&fs->attr_root) == NULL)
+    return MPLS_BOOL_TRUE;
+  return MPLS_BOOL_FALSE;
+}
+
+ldp_attr *ldp_attr_find_upstream_map_in_labelspace(ldp_fec *f, int labelspace)
+{
+  ldp_fs *fs = MPLS_LIST_HEAD(&f->fs_root_us);
+
+  while (fs) {
+    ldp_attr *attr = MPLS_LIST_HEAD(&fs->attr_root);
+    while (attr) {
+      if (attr->state == LDP_LSP_STATE_MAP_SENT) {
+        if (attr->session->cfg_label_space == labelspace) {
+          return attr;
+        }
+      }
+      attr = MPLS_LIST_NEXT(&fs->attr_root, attr, _fs);
+    }
+    fs = MPLS_LIST_NEXT(&f->fs_root_us, fs, _fec);
+  }
+  return NULL;
+}
+
+static uint32_t _ldp_attr_get_next_index()
+{
+  uint32_t retval = _ldp_attr_next_index;
+
+  _ldp_attr_next_index++;
+  if (retval > _ldp_attr_next_index) {
+    _ldp_attr_next_index = 1;
+  }
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_attr.h quagga-mpls/ldpd/ldp_attr.h
--- quagga-0.99.10/ldpd/ldp_attr.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_attr.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,91 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_ATTR_H_
+#define _LDP_ATTR_H_
+#include "ldp_struct.h"
+
+#define LDP_ATTR_LABEL          0x01
+#define LDP_ATTR_HOPCOUNT       0x02
+#define LDP_ATTR_PATH           0x04
+#define LDP_ATTR_FEC            0x08
+#define LDP_ATTR_MSGID          0x10
+#define LDP_ATTR_LSPID          0x20
+#define LDP_ATTR_TRAFFIC        0x40
+#define LDP_ATTR_STATUS		0x80
+#define LDP_ATTR_ALL            0xFF
+
+extern void ldp_attr_action_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle g);
+
+extern void ldp_attr_add_fec(ldp_attr *a, ldp_fec *fec);
+extern void ldp_attr_del_fec(ldp_global *g, ldp_attr *a);
+
+extern void ldp_attr_add_us2ds(ldp_attr * us, ldp_attr * ds);
+extern void ldp_attr_del_us2ds(ldp_global *g, ldp_attr * us, ldp_attr * ds);
+extern mpls_bool ldp_attr_us_partof_ds(ldp_attr * us, ldp_attr * ds);
+extern int ldp_attr_num_us2ds(ldp_attr * ds);
+
+extern ldp_attr *ldp_attr_create(ldp_global * g, mpls_fec * fec);
+extern void ldp_attr_delete(ldp_global * g, ldp_attr * a);
+extern void ldp_attr2ldp_attr(ldp_attr * a, ldp_attr * b, uint32_t flag);
+extern void ldp_attr_remove_complete(ldp_global * g, ldp_attr * attr, mpls_bool);
+
+extern ldp_attr *ldp_attr_find_downstream_state2(ldp_global * g,ldp_session * s,
+  ldp_fec * f, ldp_lsp_state state);
+extern ldp_attr *ldp_attr_find_downstream_state(ldp_global * g, ldp_session * s,
+  mpls_fec * f, ldp_lsp_state state);
+extern ldp_attr *ldp_attr_find_upstream_state2(ldp_global * g, ldp_session * s,
+  ldp_fec * f, ldp_lsp_state state);
+extern ldp_attr *ldp_attr_find_upstream_state(ldp_global * g, ldp_session * s,
+  mpls_fec * f, ldp_lsp_state state);
+
+extern ldp_attr *ldp_attr_find_downstream_state_any2(ldp_global *g, ldp_fec *f,
+  ldp_lsp_state state);
+extern ldp_attr *ldp_attr_find_downstream_state_any(ldp_global *g, mpls_fec *f,
+  ldp_lsp_state state);
+extern ldp_attr *ldp_attr_find_upstream_state_any2(ldp_global * g, ldp_fec * f,
+  ldp_lsp_state state);
+extern ldp_attr *ldp_attr_find_upstream_state_any(ldp_global * g, mpls_fec * f,
+  ldp_lsp_state state);
+extern ldp_attr *ldp_attr_find_upstream_map_in_labelspace(ldp_fec *f,
+  int labelspace);
+
+
+extern mpls_return_enum ldp_attr_del_outlabel(ldp_global * g,ldp_attr * a);
+extern mpls_return_enum ldp_attr_add_outlabel(ldp_attr * a, ldp_outlabel * o);
+extern mpls_return_enum ldp_attr_add_inlabel(ldp_global * g, ldp_attr * a, ldp_inlabel * i);
+extern mpls_return_enum ldp_attr_del_inlabel(ldp_global * g,ldp_attr * a);
+extern mpls_return_enum ldp_attr_add_session(ldp_attr * a, ldp_session * s);
+extern mpls_return_enum ldp_attr_del_session(ldp_global *g, ldp_attr * a);
+
+extern mpls_bool ldp_attr_is_equal(ldp_attr * a, ldp_attr * b, uint32_t flag);
+extern ldp_attr_list *ldp_attr_find_upstream_all2(ldp_global * g,
+  ldp_session * s, ldp_fec * f);
+extern ldp_attr_list *ldp_attr_find_upstream_all(ldp_global * g,
+  ldp_session * s, mpls_fec * f);
+extern ldp_attr_list *ldp_attr_find_downstream_all2(ldp_global * g,
+  ldp_session * s, ldp_fec * f);
+extern ldp_attr_list *ldp_attr_find_downstream_all(ldp_global * g,
+  ldp_session * s, mpls_fec * f);
+extern void ldp_attr_delete_upstream(ldp_global *, ldp_session *, ldp_attr *);
+extern void ldp_attr_delete_downstream(ldp_global *, ldp_session *, ldp_attr *);
+extern mpls_return_enum ldp_attr_insert_upstream2(ldp_global *g,ldp_session *s,
+  ldp_attr * a, ldp_fec *f);
+extern mpls_return_enum ldp_attr_insert_upstream(ldp_global *g, ldp_session *s,
+  ldp_attr * a);
+extern mpls_return_enum ldp_attr_insert_downstream2(ldp_global * g,
+  ldp_session * s, ldp_attr * a, ldp_fec *f);
+extern mpls_return_enum ldp_attr_insert_downstream(ldp_global * g,
+  ldp_session * s, ldp_attr * a);
+
+extern void mpls_label_struct2ldp_attr(mpls_label_struct * l, ldp_attr * a);
+extern void ldp_attr2mpls_label_struct(ldp_attr * a, mpls_label_struct * l);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_buf.c quagga-mpls/ldpd/ldp_buf.c
--- quagga-0.99.10/ldpd/ldp_buf.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_buf.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,469 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdio.h>
+#include <netinet/in.h>
+#include "ldp_struct.h"
+#include "ldp_nortel.h"
+#include "ldp_buf.h"
+#include "ldp_mesg.h"
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+#include <errno.h>
+
+int debug = 0;
+
+ldp_buf *ldp_buf_create(int size)
+{
+  ldp_buf *b = (ldp_buf *) mpls_malloc(sizeof(ldp_buf));
+  char *c = NULL;
+
+  if (!b) {
+    return NULL;
+  }
+  memset(b, 0 , sizeof(ldp_buf));
+  c = (char*) mpls_malloc(size);
+
+  if (!c) {
+    mpls_free(b);
+    return NULL;
+  }
+
+  memset(c, 0, size);
+
+  b->buffer = c;
+  b->total = size;
+  b->size = 0;
+  b->current_size = 0;
+  b->current = b->buffer;
+
+  return b;
+}
+
+void ldp_buf_delete(ldp_buf * b)
+{
+  MPLS_ASSERT(b);
+  mpls_free(b);
+}
+
+void ldp_buf_dump(mpls_instance_handle handle, ldp_buf * b, int size)
+{
+  unsigned char *buf = b->current;
+  int i;
+  int j = 0;
+
+  for (i = 0; i < size; i++) {
+    LDP_TRACE_OUT(handle, "%02x ", buf[i]);
+    j++;
+    if (j == 16) {
+      LDP_TRACE_OUT(handle, "\n");
+      j = 0;
+    }
+  }
+  LDP_TRACE_OUT(handle, "\n");
+}
+
+int ldp_encode_one_mesg(ldp_global * g, uint32_t lsraddr, int label_space,
+  ldp_buf * b, ldp_mesg * msg)
+{
+  ldp_trace_flags type = LDP_TRACE_FLAG_INIT;
+
+  unsigned char *hdrBuf = b->buffer;
+  unsigned char *bodyBuf = hdrBuf + MPLS_LDP_HDRSIZE;
+
+  int bodyBuf_size = b->total - MPLS_LDP_HDRSIZE;
+  int hdrBuf_size = MPLS_LDP_HDRSIZE;
+
+  int hdr_size;
+  int body_size;
+
+  switch (msg->u.generic.flags.flags.msgType) {
+    case MPLS_INIT_MSGTYPE:
+      body_size = Mpls_encodeLdpInitMsg(&msg->u.init, bodyBuf, bodyBuf_size);
+      break;
+    case MPLS_NOT_MSGTYPE:
+      body_size = Mpls_encodeLdpNotMsg(&msg->u.notif, bodyBuf, bodyBuf_size);
+      break;
+    case MPLS_KEEPAL_MSGTYPE:
+      body_size =
+        Mpls_encodeLdpKeepAliveMsg(&msg->u.keep, bodyBuf, bodyBuf_size);
+      break;
+    case MPLS_HELLO_MSGTYPE:
+      body_size = Mpls_encodeLdpHelloMsg(&msg->u.hello, bodyBuf, bodyBuf_size);
+      break;
+    case MPLS_LBLREQ_MSGTYPE:
+      body_size =
+        Mpls_encodeLdpLblReqMsg(&msg->u.request, bodyBuf, bodyBuf_size);
+      break;
+    case MPLS_LBLMAP_MSGTYPE:
+      body_size = Mpls_encodeLdpLblMapMsg(&msg->u.map, bodyBuf, bodyBuf_size);
+      break;
+    case MPLS_ADDR_MSGTYPE:
+    case MPLS_ADDRWITH_MSGTYPE:
+      body_size = Mpls_encodeLdpAdrMsg(&msg->u.addr, bodyBuf, bodyBuf_size);
+      break;
+    case MPLS_LBLWITH_MSGTYPE:
+    case MPLS_LBLREL_MSGTYPE:
+      body_size =
+        Mpls_encodeLdpLbl_W_R_Msg(&msg->u.release, bodyBuf, bodyBuf_size);
+      break;
+    case MPLS_LBLABORT_MSGTYPE:
+      body_size =
+        Mpls_encodeLdpLblAbortMsg(&msg->u.abort, bodyBuf, bodyBuf_size);
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+
+  if (body_size < 0) {
+    return body_size;
+  }
+
+  msg->header.protocolVersion = 1;
+  msg->header.pduLength = body_size;
+  msg->header.pduLength = body_size + MPLS_LDPIDLEN;
+  msg->header.lsrAddress = lsraddr;
+  msg->header.labelSpace = label_space;
+
+  switch (msg->u.generic.flags.flags.msgType) {
+    case MPLS_INIT_MSGTYPE:
+      type = LDP_TRACE_FLAG_INIT;
+      LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_INIT,
+        printHeader(g->user_data, &msg->header),
+        printInitMsg(g->user_data, &msg->u.init));
+      break;
+    case MPLS_NOT_MSGTYPE:
+      type = LDP_TRACE_FLAG_NOTIF;
+      LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_NOTIF,
+        printHeader(g->user_data, &msg->header),
+        printNotMsg(g->user_data, &msg->u.notif));
+      break;
+    case MPLS_KEEPAL_MSGTYPE:
+      type = LDP_TRACE_FLAG_PERIODIC;
+      LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_PERIODIC,
+        printHeader(g->user_data, &msg->header),
+        printKeepAliveMsg(g->user_data, &msg->u.keep));
+      break;
+    case MPLS_HELLO_MSGTYPE:
+      type = LDP_TRACE_FLAG_PERIODIC;
+      LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_PERIODIC,
+        printHeader(g->user_data, &msg->header),
+        printHelloMsg(g->user_data, &msg->u.hello));
+      break;
+    case MPLS_LBLREQ_MSGTYPE:
+      type = LDP_TRACE_FLAG_LABEL;
+      LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+        printHeader(g->user_data, &msg->header),
+        printLlbReqMsg(g->user_data, &msg->u.request));
+      break;
+    case MPLS_LBLMAP_MSGTYPE:
+      type = LDP_TRACE_FLAG_LABEL;
+      LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+        printHeader(g->user_data, &msg->header),
+        printLlbMapMsg(g->user_data, &msg->u.map));
+      break;
+    case MPLS_ADDR_MSGTYPE:
+    case MPLS_ADDRWITH_MSGTYPE:
+      type = LDP_TRACE_FLAG_ADDRESS;
+      LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_ADDRESS,
+        printHeader(g->user_data, &msg->header),
+        printAddressMsg(g->user_data, &msg->u.addr));
+      break;
+    case MPLS_LBLWITH_MSGTYPE:
+    case MPLS_LBLREL_MSGTYPE:
+      type = LDP_TRACE_FLAG_LABEL;
+      LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+        printHeader(g->user_data, &msg->header),
+        printLbl_W_R_Msg(g->user_data, &msg->u.release));
+      break;
+    case MPLS_LBLABORT_MSGTYPE:
+      type = LDP_TRACE_FLAG_LABEL;
+      LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+        printHeader(g->user_data, &msg->header),
+        printLlbAbortMsg(g->user_data, &msg->u.abort));
+      break;
+  }
+
+  if ((hdr_size =
+      Mpls_encodeLdpMsgHeader(&msg->header, hdrBuf, hdrBuf_size)) < 0) {
+    return hdr_size;
+  }
+
+  b->current_size = hdr_size + body_size;
+  b->current = b->buffer;
+  b->size = b->current_size;
+
+  LDP_DUMP_PKT(g->user_data, type, MPLS_TRACE_STATE_SEND,
+    ldp_buf_dump(g->user_data, b, b->size));
+
+  return b->size;
+}
+
+mpls_return_enum ldp_decode_header(ldp_global * g, ldp_buf * b, ldp_mesg * msg)
+{
+  int encodedSize;
+
+  LDP_ENTER(g->user_data, "ldp_decode_header");
+
+  encodedSize =
+    Mpls_decodeLdpMsgHeader(&msg->header, b->current, b->current_size);
+
+  if (encodedSize < 0) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_PACKET,
+      "Failed while decoding HEADER:%d\n", encodedSize);
+    LDP_EXIT(g->user_data, "ldp_decode_header - failure");
+    return MPLS_FAILURE;
+  }
+
+  LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_PACKET, MPLS_TRACE_STATE_RECV,
+    ldp_buf_dump(g->user_data, b, encodedSize));
+
+  b->current_size -= encodedSize;
+  b->current += encodedSize;
+
+  LDP_EXIT(g->user_data, "ldp_decode_header");
+  return MPLS_SUCCESS;
+}
+
+int ldp_decode_one_mesg(ldp_global * g, ldp_buf * b, ldp_mesg * msg)
+{
+  int max_mesg_size;
+  int encodedSize = 0;
+  u_short type = 0;
+  int mesgSize = 0;
+
+  MPLS_ASSERT(b);
+
+  LDP_ENTER(g->user_data, "ldp_decode_one_mesg");
+
+  if (msg->header.pduLength > (b->size - 4)) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+      LDP_TRACE_FLAG_PACKET, "Buffer too small. Decoding failed\n");
+    LDP_EXIT(g->user_data, "ldp_decode_one_mesg - failure");
+    return MPLS_FAILURE;
+  }
+
+  max_mesg_size = b->current_size;
+
+  /* found the message type */
+  memcpy((u_char *) & type, b->current, 2);
+  type = ntohs(type) & 0x7fff;  /* ignore the U bit for now */
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_PACKET,
+    "Found type %x\n", type);
+
+  switch (type) {
+    case MPLS_INIT_MSGTYPE:
+      {
+        MPLS_MSGPTR(Init) = &msg->u.init;
+        encodedSize = Mpls_decodeLdpInitMsg(MPLS_MSGPARAM(Init),
+          b->current, max_mesg_size);
+        LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_INIT, MPLS_TRACE_STATE_RECV,
+          ldp_buf_dump(g->user_data, b, encodedSize));
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_INIT, "decodedSize for Init msg = %d\n", encodedSize);
+        if (encodedSize < 0) {
+          goto ldp_decode_one_mesg;
+        }
+        LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_INIT,
+          printHeader(g->user_data, &msg->header),
+          printInitMsg(g->user_data, MPLS_MSGPARAM(Init)));
+        b->current += encodedSize;
+        mesgSize += encodedSize;
+        break;
+      }
+    case MPLS_NOT_MSGTYPE:
+      {
+        MPLS_MSGPTR(Notif) = &msg->u.notif;
+        encodedSize = Mpls_decodeLdpNotMsg(MPLS_MSGPARAM(Notif),
+          b->current, max_mesg_size);
+        LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_NOTIF, MPLS_TRACE_STATE_RECV,
+          ldp_buf_dump(g->user_data, b,
+            (encodedSize < 0) ? max_mesg_size : encodedSize));
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_NOTIF,
+          "decodedSize for Notif msg = %d\n", encodedSize);
+        if (encodedSize < 0) {
+          goto ldp_decode_one_mesg;
+        }
+        LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_NOTIF,
+          printHeader(g->user_data, &msg->header),
+          printNotMsg(g->user_data, MPLS_MSGPARAM(Notif)));
+        b->current += encodedSize;
+        mesgSize += encodedSize;
+        break;
+      }
+    case MPLS_KEEPAL_MSGTYPE:
+      {
+        MPLS_MSGPTR(KeepAl) = &msg->u.keep;
+        encodedSize = Mpls_decodeLdpKeepAliveMsg(MPLS_MSGPARAM(KeepAl),
+          b->current, max_mesg_size);
+        LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_PERIODIC,
+          MPLS_TRACE_STATE_RECV, ldp_buf_dump(g->user_data, b, encodedSize));
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_PERIODIC,
+          "decodedSize for KeepAlive msg = %d\n", encodedSize);
+        if (encodedSize < 0) {
+          goto ldp_decode_one_mesg;
+        }
+        LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_PERIODIC,
+          printHeader(g->user_data, &msg->header),
+          printKeepAliveMsg(g->user_data, MPLS_MSGPARAM(KeepAl)));
+        b->current += encodedSize;
+        mesgSize += encodedSize;
+        break;
+      }
+    case MPLS_HELLO_MSGTYPE:
+      {
+        MPLS_MSGPTR(Hello) = &msg->u.hello;
+        encodedSize = Mpls_decodeLdpHelloMsg(MPLS_MSGPARAM(Hello),
+          b->current, max_mesg_size);
+        LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_PERIODIC,
+          MPLS_TRACE_STATE_RECV, ldp_buf_dump(g->user_data, b, encodedSize));
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_PERIODIC, "decodedSize for Hello msg = %d\n",
+          encodedSize);
+        if (encodedSize < 0) {
+          goto ldp_decode_one_mesg;
+        }
+        LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_PERIODIC,
+          printHeader(g->user_data, &msg->header),
+          printHelloMsg(g->user_data, MPLS_MSGPARAM(Hello)));
+        b->current += encodedSize;
+        mesgSize += encodedSize;
+        break;
+      }
+    case MPLS_LBLREQ_MSGTYPE:
+      {
+        MPLS_MSGPTR(LblReq) = &msg->u.request;
+        encodedSize = Mpls_decodeLdpLblReqMsg(MPLS_MSGPARAM(LblReq),
+          b->current, max_mesg_size);
+        LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_LABEL, MPLS_TRACE_STATE_RECV,
+          ldp_buf_dump(g->user_data, b, encodedSize));
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_LABEL, "decodedSize for Req msg = %d\n", encodedSize);
+        if (encodedSize < 0) {
+          goto ldp_decode_one_mesg;
+        }
+        LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_LABEL,
+          printHeader(g->user_data, &msg->header),
+          printLlbReqMsg(g->user_data, MPLS_MSGPARAM(LblReq)));
+        b->current += encodedSize;
+        mesgSize += encodedSize;
+        break;
+      }
+    case MPLS_LBLMAP_MSGTYPE:
+      {
+        MPLS_MSGPTR(LblMap) = &msg->u.map;
+        encodedSize = Mpls_decodeLdpLblMapMsg(MPLS_MSGPARAM(LblMap),
+          b->current, max_mesg_size);
+        LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_LABEL, MPLS_TRACE_STATE_RECV,
+          ldp_buf_dump(g->user_data, b, encodedSize));
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_LABEL, "decodedSize for Map msg = %d\n", encodedSize);
+        if (encodedSize < 0) {
+          goto ldp_decode_one_mesg;
+        }
+        LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_LABEL,
+          printHeader(g->user_data, &msg->header),
+          printLlbMapMsg(g->user_data, MPLS_MSGPARAM(LblMap)));
+        b->current += encodedSize;
+        mesgSize += encodedSize;
+        break;
+      }
+    case MPLS_ADDR_MSGTYPE:
+    case MPLS_ADDRWITH_MSGTYPE:
+      {
+        MPLS_MSGPTR(Adr) = &msg->u.addr;
+        encodedSize = Mpls_decodeLdpAdrMsg(MPLS_MSGPARAM(Adr),
+          b->current, max_mesg_size);
+        LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_ADDRESS,
+          MPLS_TRACE_STATE_RECV, ldp_buf_dump(g->user_data, b, encodedSize));
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_ADDRESS, "decodedSize for Adr msg = %d\n",
+          encodedSize);
+        if (encodedSize < 0) {
+          goto ldp_decode_one_mesg;
+        }
+        LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_ADDRESS,
+          printHeader(g->user_data, &msg->header),
+          printAddressMsg(g->user_data, MPLS_MSGPARAM(Adr)));
+        b->current += encodedSize;
+        mesgSize += encodedSize;
+        break;
+      }
+    case MPLS_LBLWITH_MSGTYPE:
+    case MPLS_LBLREL_MSGTYPE:
+      {
+        MPLS_MSGPTR(Lbl_W_R_) = &msg->u.release;
+        encodedSize = Mpls_decodeLdpLbl_W_R_Msg(MPLS_MSGPARAM(Lbl_W_R_),
+          b->current, max_mesg_size);
+        LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_LABEL, MPLS_TRACE_STATE_RECV,
+          ldp_buf_dump(g->user_data, b, encodedSize));
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_LABEL,
+          "decodedSize for Lbl Release/Mapping msg = %d\n", encodedSize);
+        if (encodedSize < 0) {
+          goto ldp_decode_one_mesg;
+        }
+        LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_LABEL,
+          printHeader(g->user_data, &msg->header),
+          printLbl_W_R_Msg(g->user_data, MPLS_MSGPARAM(Lbl_W_R_)));
+        b->current += encodedSize;
+        mesgSize += encodedSize;
+        break;
+      }
+    case MPLS_LBLABORT_MSGTYPE:
+      {
+        MPLS_MSGPTR(LblAbort) = &msg->u.abort;
+        encodedSize = Mpls_decodeLdpLblAbortMsg(MPLS_MSGPARAM(LblAbort),
+          b->current, max_mesg_size);
+        LDP_DUMP_PKT(g->user_data, LDP_TRACE_FLAG_LABEL, MPLS_TRACE_STATE_RECV,
+          ldp_buf_dump(g->user_data, b, encodedSize));
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_LABEL, "decodedSize for Abort msg = %d\n",
+          encodedSize);
+        if (encodedSize < 0) {
+          goto ldp_decode_one_mesg;
+        }
+        LDP_TRACE_PKT(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_LABEL,
+          printHeader(g->user_data, &msg->header),
+          printLlbAbortMsg(g->user_data, MPLS_MSGPARAM(LblAbort)));
+        b->current += encodedSize;
+        mesgSize += encodedSize;
+        break;
+      }
+    default:
+      {
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+          LDP_TRACE_FLAG_PACKET, "Unknown message type = %x\n", type);
+        goto ldp_decode_one_mesg;
+      }
+  }                             /* switch */
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+    LDP_TRACE_FLAG_PACKET, "Mesg size: %d (%d)\n", mesgSize, b->size);
+
+  b->current_size -= mesgSize;
+
+  LDP_EXIT(g->user_data, "ldp_decode_one_mesg");
+  return MPLS_SUCCESS;
+
+ldp_decode_one_mesg:
+
+  LDP_EXIT(g->user_data, "ldp_decode_one_mesg - failure");
+  return MPLS_FAILURE;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_buf.h quagga-mpls/ldpd/ldp_buf.h
--- quagga-0.99.10/ldpd/ldp_buf.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_buf.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,32 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_BUF_H_
+#define _LDP_BUF_H_
+
+#include "mpls_mm_impl.h"
+
+#define MPLS_MSGMALLOC( e ) mplsLdp ## e ## Msg_t *test ## e ## Msg = (mplsLdp ## e ## Msg_t*)ldp_malloc(sizeof(mplsLdp ## e ## Msg_t))
+#define MPLS_MSGSTRUCT( e ) mplsLdp ## e ## Msg_t test ## e ## Msg
+#define MPLS_MSGPTR( e ) mplsLdp ## e ## Msg_t *test ## e ## Msg
+#define MPLS_MSGCAST( e , f ) test ## e ## Msg = (mplsLdp ## e ## Msg_t*) f
+#define MPLS_MSGPARAM( e ) test ## e ## Msg
+
+#include "ldp_struct.h"
+
+extern ldp_buf *ldp_buf_create(int);
+extern void ldp_buf_delete(ldp_buf *);
+extern int ldp_encode_one_mesg(ldp_global * g, uint32_t lsraddr,
+  int label_space, ldp_buf * b, ldp_mesg * msg);
+extern int ldp_decode_one_mesg(ldp_global * g, ldp_buf * pdu, ldp_mesg * msg);
+extern mpls_return_enum ldp_decode_header(ldp_global * g, ldp_buf * b,
+
+  ldp_mesg * msg);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp.c quagga-mpls/ldpd/ldp.c
--- quagga-0.99.10/ldpd/ldp.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,195 @@
+#include <zebra.h>
+
+#include "memory.h"
+#include "log.h"
+#include "thread.h"
+#include "prefix.h"
+#include "table.h"
+#include "linklist.h"
+#include "filter.h"
+#include "vty.h"
+#include "plist.h"
+
+#include "ldp.h"
+#include "ldp_cfg.h"
+#include "ldp_struct.h"
+#include "ldp_interface.h"
+#include "ldp_zebra.h"
+
+#include "impl_fib.h"
+
+int ldp_shutdown(struct ldp *ldp) {
+  ldp_global g;
+
+  g.admin_state = MPLS_ADMIN_DISABLE;
+  return ldp_cfg_global_set(ldp->h,&g,LDP_GLOBAL_CFG_ADMIN_STATE);
+}
+
+int ldp_startup(struct ldp *ldp) {
+  ldp_global g;
+
+  g.admin_state = MPLS_ADMIN_ENABLE;
+  return ldp_cfg_global_set(ldp->h,&g,LDP_GLOBAL_CFG_ADMIN_STATE);
+}
+
+int ldp_admin_state_start(struct ldp *ldp) {
+  if (ldp->admin_up == MPLS_BOOL_TRUE) {
+    return ldp_shutdown(ldp);
+  }
+  return MPLS_SUCCESS;
+}
+
+int ldp_admin_state_finish(struct ldp *ldp) {
+  if (ldp->admin_up == MPLS_BOOL_TRUE) {
+    return ldp_startup(ldp);
+  }
+  return MPLS_SUCCESS;
+}
+
+int do_ldp_router_id_update(struct ldp *ldp, unsigned int router_id) {
+    ldp_global g;
+    g.lsr_identifier.type = MPLS_FAMILY_IPV4;
+    g.lsr_identifier.u.ipv4 = router_id;
+    g.transport_address.type = MPLS_FAMILY_NONE;
+    g.transport_address.u.ipv4 = 0;
+
+    if (ldp->trans_addr == LDP_TRANS_ADDR_LSRID) {
+	g.transport_address.type = MPLS_FAMILY_IPV4;
+	g.transport_address.u.ipv4 = router_id;
+    }
+
+    return ldp_cfg_global_set(ldp->h,&g,
+	LDP_GLOBAL_CFG_LSR_IDENTIFIER|LDP_GLOBAL_CFG_TRANS_ADDR);
+}
+
+int ldp_router_id_update(struct ldp *ldp, struct prefix *router_id) {
+
+  zlog_info("router-id update %s", inet_ntoa(router_id->u.prefix4));
+
+  if (!ldp->lsr_id_is_static) {
+    ldp_admin_state_start(ldp);
+
+    do_ldp_router_id_update(ldp, ntohl(router_id->u.prefix4.s_addr));
+
+    ldp_admin_state_finish(ldp);
+  }
+  return 0;
+}
+
+/* LDP instance top. */
+struct ldp *ldp_top = NULL;
+
+struct ldp *ldp_new(void) {
+    struct ldp *new = XMALLOC(MTYPE_LDP, sizeof(struct ldp));
+    ldp_global g;
+    struct route_node *rn;
+    struct prefix n;
+
+    struct interface *ifp;
+    struct connected *c;
+    struct listnode *node, *cnode;
+    struct ldp_interface *li;
+    struct ldp_addr addr;
+    struct prefix *p;
+
+    memset(new,0,sizeof(*new));
+
+    new->h = ldp_cfg_open(new);
+    new->admin_up = MPLS_BOOL_TRUE;
+    new->lsr_id_is_static = 0;
+
+    new->egress = LDP_EGRESS_CONNECTED;
+    new->address = LDP_ADDRESS_ALL;
+    new->peer_list = list_new();
+
+    ldp_top = new;
+
+    do_ldp_router_id_update(new, ntohl(router_id.u.prefix4.s_addr));
+    g.admin_state = MPLS_ADMIN_ENABLE;
+
+    ldp_cfg_global_set(new->h,&g, LDP_GLOBAL_CFG_LSR_HANDLE|
+	LDP_GLOBAL_CFG_ADMIN_STATE);
+
+    n.u.prefix4.s_addr = htonl(INADDR_LOOPBACK);
+    n.prefixlen = 8;
+    n.family = AF_INET;
+
+    for (ALL_LIST_ELEMENTS_RO(iflist, node, ifp)) {
+        MPLS_ASSERT(ifp->info);
+	li = ifp->info;
+
+	ldp_interface_create(li);
+
+	for (ALL_LIST_ELEMENTS_RO(ifp->connected, cnode, c)) {
+	    p = c->address;
+	    if (p->family == AF_INET) {
+		if (!prefix_match(&n, c->address)) {
+		    prefix2mpls_inet_addr(p, &addr.address);
+		    ldp_cfg_if_addr_set(new->h, &li->iff, &addr, LDP_CFG_ADD);
+		}
+	    }
+	}
+
+	if (li->configured == MPLS_BOOL_TRUE)
+	    ldp_interface_create2(li);
+    }
+
+    ldp_zebra_startup();
+
+    return new;
+}
+
+struct ldp *ldp_get() {
+    if (ldp_top) {
+	return ldp_top;
+    }
+    return NULL;
+}
+
+void ldp_finish(struct ldp *ldp) {
+    struct ldp_interface *li;
+    struct interface *ifp;
+    struct listnode* node;
+    int flag;
+
+    ldp_zebra_shutdown();
+
+    ldp_admin_state_start(ldp);
+
+    for (ALL_LIST_ELEMENTS_RO(iflist, node, ifp)) {
+        MPLS_ASSERT(ifp->info);
+	flag = li->iff.index ? 1 : 0;
+	li = ifp->info;
+	ldp_interface_delete(li);
+	if (flag) {
+	    li->configured = MPLS_BOOL_TRUE;
+	    li->admin_up = MPLS_BOOL_TRUE;
+	}
+    }
+
+    ldp_cfg_close(ldp->h);
+    list_free(ldp->peer_list);
+
+    XFREE(MTYPE_LDP,ldp);
+    ldp_top = NULL;
+}
+
+#if 0
+/* Update access-list list. */
+void mpls_access_list_update(struct access_list *access) {
+}
+
+/* Update prefix-list list. */
+void mpls_prefix_list_update(struct prefix_list *plist) {
+}
+#endif
+
+void ldp_init() {
+
+#if 0
+    access_list_init();
+    access_list_add_hook(mpls_access_list_update);
+    access_list_delete_hook(mpls_access_list_update);
+#endif
+
+}
diff -Naur quagga-0.99.10/ldpd/ldp_cfg.c quagga-mpls/ldpd/ldp_cfg.c
--- quagga-0.99.10/ldpd/ldp_cfg.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_cfg.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,2919 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_cfg.h"
+#include "ldp_global.h"
+#include "ldp_entity.h"
+#include "ldp_attr.h"
+#include "ldp_if.h"
+#include "ldp_peer.h"
+#include "ldp_fec.h"
+#include "ldp_addr.h"
+#include "ldp_nexthop.h"
+#include "ldp_tunnel.h"
+#include "ldp_resource.h"
+#include "mpls_ifmgr_impl.h"
+#include "ldp_label_mapping.h"
+#include "ldp_hop.h"
+#include "ldp_hop_list.h"
+#include "mpls_lock_impl.h"
+#include "mpls_trace_impl.h"
+#include "mpls_tree_impl.h"
+
+mpls_cfg_handle ldp_cfg_open(mpls_instance_handle data)
+{
+  ldp_global *g = ldp_global_create(data);
+
+  LDP_ENTER(data, "ldp_cfg_open");
+  LDP_EXIT(data, "ldp_cfg_open");
+
+  return (mpls_cfg_handle) g;
+}
+
+void ldp_cfg_close(mpls_cfg_handle g)
+{
+  LDP_ENTER((mpls_instance_handle) g->user_data, "ldp_cfg_close");
+  ldp_global_delete(g);
+  LDP_EXIT((mpls_instance_handle) g->user_data, "ldp_cfg_close");
+}
+
+/******************* GLOBAL **********************/
+
+void ldp_cfg_global_attr(mpls_cfg_handle handle) {
+  ldp_global *global = (ldp_global *) handle;
+  ldp_attr *attr = MPLS_LIST_HEAD(&global->attr);
+  while (attr) {
+    if (attr->state == LDP_LSP_STATE_MAP_SENT && attr->ds_attr) {
+      LDP_PRINT(global->user_data, "%p(%s) xc to %p(%s)", attr,
+        attr->session->session_name, attr->ds_attr,
+        attr->ds_attr->session->session_name);
+    }
+    attr = MPLS_LIST_NEXT(&global->attr, attr, _global);
+  }
+}
+
+mpls_return_enum ldp_cfg_global_get(mpls_cfg_handle handle, ldp_global * g,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_global_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_GLOBAL_CFG_LSR_IDENTIFIER) {
+    memcpy(&(g->lsr_identifier), &(global->lsr_identifier),
+      sizeof(mpls_inet_addr));
+  }
+  if (flag & LDP_GLOBAL_CFG_ADMIN_STATE) {
+    g->admin_state = global->admin_state;
+  }
+  if (flag & LDP_GLOBAL_CFG_CONTROL_MODE) {
+    g->lsp_control_mode = global->lsp_control_mode;
+  }
+  if (flag & LDP_GLOBAL_CFG_RETENTION_MODE) {
+    g->label_retention_mode = global->label_retention_mode;
+  }
+  if (flag & LDP_GLOBAL_CFG_REPAIR_MODE) {
+    g->lsp_repair_mode = global->lsp_repair_mode;
+  }
+  if (flag & LDP_GLOBAL_CFG_PROPOGATE_RELEASE) {
+    g->propagate_release = global->propagate_release;
+  }
+  if (flag & LDP_GLOBAL_CFG_LABEL_MERGE) {
+    g->label_merge = global->label_merge;
+  }
+  if (flag & LDP_GLOBAL_CFG_LOOP_DETECTION_MODE) {
+    g->loop_detection_mode = global->loop_detection_mode;
+  }
+  if (flag & LDP_GLOBAL_CFG_TTLLESS_DOMAIN) {
+    g->ttl_less_domain = global->ttl_less_domain;
+  }
+  if (flag & LDP_GLOBAL_CFG_LOCAL_TCP_PORT) {
+    g->local_tcp_port = global->local_tcp_port;
+  }
+  if (flag & LDP_GLOBAL_CFG_LOCAL_UDP_PORT) {
+    g->local_udp_port = global->local_udp_port;
+  }
+  if (flag & LDP_GLOBAL_CFG_TRANS_ADDR) {
+    memcpy(&(g->transport_address), &(global->transport_address),
+      sizeof(mpls_inet_addr));
+  }
+  if (flag & LDP_GLOBAL_CFG_KEEPALIVE_TIMER) {
+    g->keepalive_timer = global->keepalive_timer;
+  }
+  if (flag & LDP_GLOBAL_CFG_KEEPALIVE_INTERVAL) {
+    g->keepalive_interval = global->keepalive_interval;
+  }
+  if (flag & LDP_GLOBAL_CFG_HELLOTIME_TIMER) {
+    g->hellotime_timer = global->hellotime_timer;
+  }
+  if (flag & LDP_GLOBAL_CFG_HELLOTIME_INTERVAL) {
+    g->hellotime_interval = global->hellotime_interval;
+  }
+#if MPLS_USE_LSR
+  if (flag & LDP_GLOBAL_CFG_LSR_HANDLE) {
+    g->lsr_handle = global->lsr_handle;
+  }
+#endif
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_global_get");
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_cfg_global_test(mpls_cfg_handle handle, ldp_global * g,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_SUCCESS;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_global_test");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (global->admin_state == MPLS_ADMIN_ENABLE && (flag & LDP_GLOBAL_CFG_WHEN_DOWN))
+    retval = MPLS_FAILURE;
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_global_test");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_global_set(mpls_cfg_handle handle, ldp_global * g,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_global_set");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if ((global->admin_state == MPLS_ADMIN_ENABLE && (flag & LDP_GLOBAL_CFG_WHEN_DOWN)))
+    goto ldp_cfg_global_set_end;
+
+  if (flag & LDP_GLOBAL_CFG_CONTROL_MODE) {
+    global->lsp_control_mode = g->lsp_control_mode;
+  }
+  if (flag & LDP_GLOBAL_CFG_RETENTION_MODE) {
+    global->label_retention_mode = g->label_retention_mode;
+  }
+  if (flag & LDP_GLOBAL_CFG_REPAIR_MODE) {
+    global->lsp_repair_mode = g->lsp_repair_mode;
+  }
+  if (flag & LDP_GLOBAL_CFG_PROPOGATE_RELEASE) {
+    global->propagate_release = g->propagate_release;
+  }
+  if (flag & LDP_GLOBAL_CFG_LABEL_MERGE) {
+    global->label_merge = g->label_merge;
+  }
+  if (flag & LDP_GLOBAL_CFG_LOOP_DETECTION_MODE) {
+    global->loop_detection_mode = g->loop_detection_mode;
+  }
+  if (flag & LDP_GLOBAL_CFG_TTLLESS_DOMAIN) {
+    global->ttl_less_domain = g->ttl_less_domain;
+  }
+  if (flag & LDP_GLOBAL_CFG_LOCAL_TCP_PORT) {
+    global->local_tcp_port = g->local_tcp_port;
+  }
+  if (flag & LDP_GLOBAL_CFG_LOCAL_UDP_PORT) {
+    global->local_udp_port = g->local_udp_port;
+  }
+  if (flag & LDP_GLOBAL_CFG_LSR_IDENTIFIER) {
+    memcpy(&(global->lsr_identifier), &(g->lsr_identifier),
+      sizeof(mpls_inet_addr));
+  }
+#if MPLS_USE_LSR
+  if (flag & LDP_GLOBAL_CFG_LSR_HANDLE) {
+    global->lsr_handle = g->lsr_handle;
+  }
+#endif
+  if (flag & LDP_GLOBAL_CFG_ADMIN_STATE) {
+    if (global->admin_state == MPLS_ADMIN_ENABLE && g->admin_state == MPLS_ADMIN_DISABLE) {
+      ldp_global_shutdown(global);
+    } else if (global->admin_state == MPLS_ADMIN_DISABLE && g->admin_state ==
+      MPLS_ADMIN_ENABLE) {
+      ldp_global_startup(global);
+    }
+  }
+  if (flag & LDP_GLOBAL_CFG_TRANS_ADDR) {
+    memcpy(&(global->transport_address), &(g->transport_address),
+      sizeof(mpls_inet_addr));
+  }
+  if (flag & LDP_GLOBAL_CFG_KEEPALIVE_TIMER) {
+    if (g->keepalive_timer == 0) {
+      global->keepalive_timer = LDP_ENTITY_DEF_KEEPALIVE_TIMER;
+    } else {
+      global->keepalive_timer = g->keepalive_timer;
+    }
+  }
+  if (flag & LDP_GLOBAL_CFG_KEEPALIVE_INTERVAL) {
+    if (g->keepalive_interval == 0) {
+      global->keepalive_interval = LDP_ENTITY_DEF_KEEPALIVE_INTERVAL;
+    } else {
+      global->keepalive_interval = g->keepalive_interval;
+    }
+  }
+  if (flag & LDP_GLOBAL_CFG_HELLOTIME_TIMER) {
+    if (g->hellotime_timer == 0) {
+      global->hellotime_timer = LDP_ENTITY_DEF_HELLOTIME_TIMER;
+    } else {
+      global->hellotime_timer = g->hellotime_timer;
+    }
+  }
+  if (flag & LDP_GLOBAL_CFG_HELLOTIME_INTERVAL) {
+    if (g->hellotime_interval == 0) {
+      global->hellotime_interval = LDP_ENTITY_DEF_HELLOTIME_INTERVAL;
+    } else {
+      global->hellotime_interval = g->hellotime_interval;
+    }
+  }
+#if MPLS_USE_LSR
+  if (flag & LDP_GLOBAL_CFG_LSR_HANDLE) {
+    global->lsr_handle = g->lsr_handle ;
+  }
+#endif
+  global->configuration_sequence_number++;
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_global_set_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_global_set");
+
+  return retval;
+}
+
+/******************* ENTITY **********************/
+
+/* must set ldp_entity->index */
+mpls_return_enum ldp_cfg_entity_get(mpls_cfg_handle handle, ldp_entity * e,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_entity *entity = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && e != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_entity_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (ldp_global_find_entity_index(global, e->index, &entity) != MPLS_SUCCESS)
+      goto ldp_cfg_entity_get_end;
+
+  if (flag & LDP_ENTITY_CFG_ADMIN_STATE) {
+    e->admin_state = entity->admin_state;
+  }
+  if (flag & LDP_ENTITY_CFG_TRANS_ADDR) {
+    e->transport_address = entity->transport_address;
+  }
+  if (flag & LDP_ENTITY_CFG_PROTO_VER) {
+    e->protocol_version = entity->protocol_version;
+  }
+  if (flag & LDP_ENTITY_CFG_REMOTE_TCP) {
+    e->remote_tcp_port = entity->remote_tcp_port;
+  }
+  if (flag & LDP_ENTITY_CFG_REMOTE_UDP) {
+    e->remote_udp_port = entity->remote_udp_port;
+  }
+  if (flag & LDP_ENTITY_CFG_MAX_PDU) {
+    e->max_pdu = entity->max_pdu;
+  }
+  if (flag & LDP_ENTITY_CFG_KEEPALIVE_TIMER) {
+    e->keepalive_timer = entity->keepalive_timer;
+  }
+  if (flag & LDP_ENTITY_CFG_KEEPALIVE_INTERVAL) {
+    e->keepalive_interval = entity->keepalive_interval;
+  }
+  if (flag & LDP_ENTITY_CFG_HELLOTIME_TIMER) {
+    e->hellotime_timer = entity->hellotime_timer;
+  }
+  if (flag & LDP_ENTITY_CFG_HELLOTIME_INTERVAL) {
+    e->hellotime_interval = entity->hellotime_interval;
+  }
+  if (flag & LDP_ENTITY_CFG_SESSION_SETUP_COUNT) {
+    e->session_setup_count = entity->session_setup_count;
+  }
+  if (flag & LDP_ENTITY_CFG_SESSION_BACKOFF_TIMER) {
+    e->session_backoff_timer = entity->session_backoff_timer;
+  }
+  if (flag & LDP_ENTITY_CFG_DISTRIBUTION_MODE) {
+    e->label_distribution_mode = entity->label_distribution_mode;
+  }
+  if (flag & LDP_ENTITY_CFG_PATHVECTOR_LIMIT) {
+    e->path_vector_limit = entity->path_vector_limit;
+  }
+  if (flag & LDP_ENTITY_CFG_HOPCOUNT_LIMIT) {
+    e->hop_count_limit = entity->hop_count_limit;
+  }
+  if (flag & LDP_ENTITY_CFG_REQUEST_COUNT) {
+    e->label_request_count = entity->label_request_count;
+  }
+  if (flag & LDP_ENTITY_CFG_REQUEST_TIMER) {
+    e->label_request_timer = entity->label_request_timer;
+  }
+  if (flag & LDP_ENTITY_CFG_TYPE) {
+    e->entity_type = entity->entity_type;
+  }
+  if (flag & LDP_ENTITY_CFG_SUB_INDEX) {
+    e->sub_index = entity->sub_index;
+  }
+  if (flag & LDP_ENTITY_CFG_MESG_TX) {
+    e->mesg_tx = entity->mesg_tx;
+  }
+  if (flag & LDP_ENTITY_CFG_MESG_RX) {
+    e->mesg_rx = entity->mesg_rx;
+  }
+  if (flag & LDP_ENTITY_CFG_ADJ_COUNT) {
+    e->adj_count = entity->adj_root.count;
+  }
+  if (flag & LDP_ENTITY_CFG_ADJ_INDEX) {
+    ldp_adj *a = MPLS_LIST_HEAD(&entity->adj_root);
+    e->adj_index = a ? a->index : 0;
+  }
+  if (flag & LDP_ENTITY_CFG_INHERIT_FLAG) {
+    e->inherit_flag = entity->inherit_flag;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_entity_get_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_entity_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_entity_getnext(mpls_cfg_handle handle, ldp_entity * e,
+  uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_entity *entity = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_entity_getnext");
+
+  if (e->index == 0) {
+    index = 1;
+  } else {
+    index = e->index + 1;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_entity_index(g, index, &entity))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    e->index = entity->index;
+    LDP_EXIT(g->user_data, "ldp_cfg_entity_getnext");
+    return ldp_cfg_entity_get(g, e, flag);
+  }
+  LDP_EXIT(g->user_data, "ldp_cfg_entity_getnext");
+  return r;
+}
+
+mpls_return_enum ldp_cfg_entity_test(mpls_cfg_handle handle, ldp_entity * e,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_entity *entity = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_entity_test");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (!(flag & LDP_CFG_ADD)) {
+    if (e == NULL)
+      goto ldp_cfg_entity_test_end;
+
+    ldp_global_find_entity_index(global, e->index, &entity);
+  } else {
+    retval = MPLS_SUCCESS;
+    goto ldp_cfg_entity_test_end;
+  }
+
+  if (entity == NULL) {
+     goto ldp_cfg_entity_test_end;
+  }
+
+  if ((ldp_entity_is_active(entity) == MPLS_BOOL_TRUE) &&
+      (flag & LDP_ENTITY_CFG_WHEN_DOWN)) {
+     goto ldp_cfg_entity_test_end;
+  }
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_entity_test_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_entity_test");
+
+  return retval;
+}
+
+/* must set ldp_entity->index if not an add */
+mpls_return_enum ldp_cfg_entity_set(mpls_cfg_handle handle, ldp_entity * e,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_entity *entity = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && e != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_entity_set");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_CFG_ADD) {
+    entity = ldp_entity_create();
+    _ldp_global_add_entity(global, entity);
+
+    e->index = entity->index;
+  } else {
+    ldp_global_find_entity_index(global, e->index, &entity);
+  }
+
+  if (entity == NULL) {
+    LDP_PRINT(global->user_data, "ldp_cfg_entity_set: can't find entity\n");
+    goto ldp_cfg_entity_set_end;
+  }
+
+  if ((ldp_entity_is_active(entity) == MPLS_BOOL_TRUE) &&
+      (flag & LDP_ENTITY_CFG_WHEN_DOWN)) {
+    LDP_PRINT(global->user_data, "ldp_cfg_entity_set: entity is active\n");
+    goto ldp_cfg_entity_set_end;
+  }
+
+  if (flag & LDP_CFG_DEL) {
+    switch (entity->entity_type) {
+      case LDP_DIRECT:
+        ldp_entity_del_if(global, entity);
+        break;
+      case LDP_INDIRECT:
+        ldp_entity_del_peer(entity);
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    _ldp_global_del_entity(global, entity);
+
+    retval = MPLS_SUCCESS;
+    goto ldp_cfg_entity_set_end;
+  }
+
+  if (flag & LDP_ENTITY_CFG_SUB_INDEX) {
+    if (entity->sub_index != 0) {
+      /* unlink the old sub object */
+      switch (entity->entity_type) {
+        case LDP_DIRECT:
+          ldp_entity_del_if(global, entity);
+          break;
+        case LDP_INDIRECT:
+          ldp_entity_del_peer(entity);
+          break;
+        default:
+          MPLS_ASSERT(0);
+      }
+    }
+
+    /* link the new sub object */
+    switch (e->entity_type) {
+      case LDP_DIRECT:
+        {
+          ldp_if *iff = NULL;
+          if (ldp_global_find_if_index(global, e->sub_index,
+              &iff) != MPLS_SUCCESS) {
+            LDP_PRINT(global->user_data,
+              "ldp_cfg_entity_set: no such interface\n");
+
+            if (flag & LDP_CFG_ADD) {
+              _ldp_global_del_entity(global, entity);
+            }
+            goto ldp_cfg_entity_set_end;
+          }
+          ldp_entity_add_if(entity, iff);
+          break;
+        }
+      case LDP_INDIRECT:
+        {
+          ldp_peer *peer = NULL;
+
+          if (ldp_global_find_peer_index(global, e->sub_index, &peer) !=
+            MPLS_SUCCESS) {
+            LDP_PRINT(global->user_data, "ldp_cfg_entity_set: no such peer\n");
+
+            if (flag & LDP_CFG_ADD) {
+              _ldp_global_del_entity(global, entity);
+            }
+            goto ldp_cfg_entity_set_end;
+          }
+          ldp_entity_add_peer(entity, peer);
+          break;
+        }
+      default:
+        MPLS_ASSERT(0);
+    }
+  }
+
+  if (flag & LDP_ENTITY_CFG_TRANS_ADDR) {
+    if (e->transport_address.type == MPLS_FAMILY_NONE) {
+      entity->inherit_flag |= LDP_ENTITY_CFG_TRANS_ADDR;
+    } else {
+      entity->inherit_flag &= ~LDP_ENTITY_CFG_TRANS_ADDR;
+    }
+    memcpy(&entity->transport_address, &e->transport_address,
+      sizeof(mpls_inet_addr));;
+  }
+  if (flag & LDP_ENTITY_CFG_PROTO_VER) {
+    entity->protocol_version = e->protocol_version;
+  }
+  if (flag & LDP_ENTITY_CFG_REMOTE_TCP) {
+    entity->remote_tcp_port = e->remote_tcp_port;
+  }
+  if (flag & LDP_ENTITY_CFG_REMOTE_UDP) {
+    entity->remote_udp_port = e->remote_udp_port;
+  }
+  if (flag & LDP_ENTITY_CFG_MAX_PDU) {
+    entity->max_pdu = e->max_pdu;
+  }
+  if (flag & LDP_ENTITY_CFG_KEEPALIVE_TIMER) {
+    if (e->transport_address.type == MPLS_FAMILY_NONE) {
+      entity->inherit_flag |= LDP_ENTITY_CFG_KEEPALIVE_TIMER;
+    } else {
+      entity->inherit_flag &= ~LDP_ENTITY_CFG_KEEPALIVE_TIMER;
+    }
+    entity->keepalive_timer = e->keepalive_timer;
+  }
+  if (flag & LDP_ENTITY_CFG_KEEPALIVE_INTERVAL) {
+    if (e->transport_address.type == MPLS_FAMILY_NONE) {
+      entity->inherit_flag |= LDP_ENTITY_CFG_KEEPALIVE_INTERVAL;
+    } else {
+      entity->inherit_flag &= ~LDP_ENTITY_CFG_KEEPALIVE_INTERVAL;
+    }
+    entity->keepalive_interval = e->keepalive_interval;
+  }
+  if (flag & LDP_ENTITY_CFG_HELLOTIME_TIMER) {
+    if (e->transport_address.type == MPLS_FAMILY_NONE) {
+      entity->inherit_flag |= LDP_ENTITY_CFG_HELLOTIME_TIMER;
+    } else {
+      entity->inherit_flag &= ~LDP_ENTITY_CFG_HELLOTIME_TIMER;
+    }
+    entity->hellotime_timer = e->hellotime_timer;
+  }
+  if (flag & LDP_ENTITY_CFG_HELLOTIME_INTERVAL) {
+    if (e->transport_address.type == MPLS_FAMILY_NONE) {
+      entity->inherit_flag |= LDP_ENTITY_CFG_HELLOTIME_INTERVAL;
+    } else {
+      entity->inherit_flag &= ~LDP_ENTITY_CFG_HELLOTIME_INTERVAL;
+    }
+    entity->hellotime_interval = e->hellotime_interval;
+  }
+  if (flag & LDP_ENTITY_CFG_SESSION_SETUP_COUNT) {
+    entity->session_setup_count = e->session_setup_count;
+  }
+  if (flag & LDP_ENTITY_CFG_SESSION_BACKOFF_TIMER) {
+    entity->session_backoff_timer = e->session_backoff_timer;
+  }
+  if (flag & LDP_ENTITY_CFG_DISTRIBUTION_MODE) {
+    entity->label_distribution_mode = e->label_distribution_mode;
+  }
+  if (flag & LDP_ENTITY_CFG_PATHVECTOR_LIMIT) {
+    entity->path_vector_limit = e->path_vector_limit;
+  }
+  if (flag & LDP_ENTITY_CFG_HOPCOUNT_LIMIT) {
+    entity->hop_count_limit = e->hop_count_limit;
+  }
+  if (flag & LDP_ENTITY_CFG_REQUEST_COUNT) {
+    entity->label_request_count = e->label_request_count;
+  }
+  if (flag & LDP_ENTITY_CFG_REQUEST_TIMER) {
+    entity->label_request_timer = e->label_request_timer;
+  }
+  if (flag & LDP_ENTITY_CFG_TYPE) {
+    entity->entity_type = e->entity_type;
+  }
+  if (flag & LDP_ENTITY_CFG_ADMIN_STATE) {
+    if (ldp_entity_is_active(entity) == MPLS_BOOL_TRUE &&
+      e->admin_state == MPLS_ADMIN_DISABLE) {
+      if (ldp_entity_shutdown(global, entity, 0) == MPLS_FAILURE) {
+        goto ldp_cfg_entity_set_end;
+      }
+    } else if (ldp_entity_is_active(entity) == MPLS_BOOL_FALSE &&
+      e->admin_state == MPLS_ADMIN_ENABLE && ldp_entity_is_ready(entity) == MPLS_BOOL_TRUE) {
+      if (ldp_entity_startup(global, entity) == MPLS_FAILURE) {
+        goto ldp_cfg_entity_set_end;
+      }
+    } else {
+      LDP_PRINT(global->user_data, "ldp_cfg_entity_set: entity not ready\n");
+
+      goto ldp_cfg_entity_set_end;
+    }
+  }
+  if (flag & LDP_ENTITY_CFG_INHERIT_FLAG) {
+    entity->inherit_flag = e->inherit_flag;
+  }
+  global->configuration_sequence_number++;
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_entity_set_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_entity_set");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_entity_adj_getnext(mpls_cfg_handle handle,
+  ldp_entity * e)
+{
+  ldp_global *g = (ldp_global *) handle;
+  mpls_bool this_one = MPLS_BOOL_FALSE;
+  mpls_return_enum r = MPLS_FAILURE;
+  ldp_adj *adj_next = NULL;
+  ldp_adj *adj = NULL;
+  ldp_entity *entity = NULL;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_entity_adj_getnext");
+
+  /* if an adj_index of zero is sent, get the index of
+   * the first adj in the list
+   */
+  if (!e->adj_index) {
+    this_one = MPLS_BOOL_TRUE;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+
+  if (ldp_global_find_entity_index(g, e->index, &entity) == MPLS_SUCCESS) {
+    adj = MPLS_LIST_HEAD(&entity->adj_root);
+    while (adj) {
+      if (this_one == MPLS_BOOL_TRUE) {
+        adj_next = adj;
+        break;
+      }
+
+      /* since the entities are sort in the list ... */
+      if (adj->index > e->adj_index) {
+        break;
+      } else if (adj->index == e->adj_index) {
+        this_one = MPLS_BOOL_TRUE;
+      }
+      adj = MPLS_LIST_NEXT(&entity->adj_root, adj, _entity);
+    }
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (adj_next) {
+    e->adj_index = adj_next->index;
+    r = MPLS_SUCCESS;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_cfg_entity_adj_getnext");
+  return r;
+}
+
+/******************* INTERFACE **********************/
+
+mpls_return_enum ldp_cfg_if_get(mpls_cfg_handle handle, ldp_if * i, uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_if *iff = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && i != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_if_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_IF_CFG_BY_INDEX) {
+    ldp_global_find_if_index(global, i->index, &iff);
+  } else {
+    iff = ldp_global_find_if_handle(global, i->handle);
+  }
+  if (!iff)
+      goto ldp_cfg_if_get_end;
+
+  if (flag & LDP_IF_CFG_LABEL_SPACE) {
+    i->label_space = iff->label_space;
+  }
+  if (flag & LDP_IF_CFG_ENTITY_INDEX) {
+    i->entity_index = iff->entity ? iff->entity->index : 0;
+  }
+  if (flag & LDP_IF_CFG_OPER_STATE) {
+    i->oper_state = iff->oper_state;
+  }
+  if (flag & LDP_IF_CFG_HANDLE) {
+    memcpy(&i->handle, &iff->handle, sizeof(mpls_if_handle));
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_if_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_if_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_if_getnext(mpls_cfg_handle handle, ldp_if * i,
+  uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_if *iff = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_if_getnext");
+
+  if (i->index == 0) {
+    index = 1;
+  } else {
+    index = i->index + 1;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_if_index(g, index, &iff))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    i->index = iff->index;
+    LDP_EXIT(g->user_data, "ldp_cfg_if_getnext");
+    return ldp_cfg_if_get(g, i, flag);
+  }
+  LDP_EXIT(g->user_data, "ldp_cfg_if_getnext");
+  return r;
+}
+
+mpls_return_enum ldp_cfg_if_test(mpls_cfg_handle handle, ldp_if * i,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_if *iff = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && i != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_if_test");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (!(flag & LDP_CFG_ADD)) {
+    ldp_global_find_if_index(global, i->index, &iff);
+  } else {
+    retval = MPLS_SUCCESS;
+    goto ldp_cfg_if_test_end;
+  }
+
+  if ((!iff) || ((ldp_if_is_active(iff) == MPLS_BOOL_TRUE) &&
+    (flag & LDP_IF_CFG_WHEN_DOWN))) {
+    goto ldp_cfg_if_test_end;
+  }
+
+  if (flag & LDP_CFG_DEL) {
+    if (iff->entity != NULL) {
+      goto ldp_cfg_if_test_end;
+    }
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_if_test_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_if_test");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_if_set(mpls_cfg_handle handle, ldp_if * i, uint32_t flag)
+{
+  ldp_global *global = (ldp_global*)handle;
+  ldp_if *iff = NULL;
+  ldp_addr *ap;
+  ldp_nexthop *np;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && i != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_if_set");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_CFG_ADD) {
+    /* duplicate interface handles are not allowed */
+    /* ADDs require a valid interface handle */
+    if (((iff = ldp_global_find_if_handle(global, i->handle)) != NULL) ||
+      (mpls_if_handle_verify(global->ifmgr_handle, i->handle) ==
+      MPLS_BOOL_FALSE) || ((iff = ldp_if_create(global)) == NULL)) {
+      goto ldp_cfg_if_set_end;
+    }
+
+    /* copy the handle from the user */
+    iff->handle = i->handle;
+
+    /* search for addrs and nexthops that are waiting for this interface */
+    ap = MPLS_LIST_HEAD(&global->addr);
+    while (ap) {
+      if (ap->if_handle == iff->handle && (!MPLS_LIST_IN_LIST(ap, _if))) {
+        ldp_if_add_addr(iff, ap);
+      }
+      ap = MPLS_LIST_NEXT(&global->addr, ap, _global);
+    }
+
+    np = MPLS_LIST_HEAD(&global->nexthop);
+    while (np) {
+      if ((np->info.type & MPLS_NH_IF) &&
+	(np->info.if_handle == iff->handle) && (!MPLS_LIST_IN_LIST(np, _if))) {
+        ldp_if_add_nexthop(iff, np);
+      }
+      np = MPLS_LIST_NEXT(&global->nexthop, np, _global);
+    }
+
+    /* send the newly created index back to the user */
+    i->index = iff->index;
+    MPLS_REFCNT_HOLD(iff);
+
+  } else {
+    if (flag & LDP_IF_CFG_BY_INDEX) {
+      ldp_global_find_if_index(global, i->index, &iff);
+    } else {
+      iff = ldp_global_find_if_handle(global, i->handle);
+    }
+  }
+
+  /*
+   * if we can't find this interface or if the interface is active and
+   * we are trying to change propertises that can not be changed on a
+   * active interface
+   */
+  if ((!iff) || ((ldp_if_is_active(iff) == MPLS_BOOL_TRUE) &&
+    (flag & LDP_IF_CFG_WHEN_DOWN))) {
+    goto ldp_cfg_if_set_end;
+  }
+
+  if (flag & LDP_IF_CFG_LABEL_SPACE) {
+    iff->label_space = i->label_space;
+  }
+
+  if (flag & LDP_CFG_DEL) {
+    /*
+     * if this interface is still attached to a entity that it is not ready
+     * to be removed
+     */
+    if (iff->entity != NULL) {
+      goto ldp_cfg_if_set_end;
+    }
+
+    np = MPLS_LIST_HEAD(&iff->nh_root);
+    while ((np = MPLS_LIST_HEAD(&iff->nh_root))) {
+      ldp_if_del_nexthop(global, iff, np);
+    }
+
+    ap = MPLS_LIST_HEAD(&iff->addr_root);
+    while ((ap = MPLS_LIST_HEAD(&iff->addr_root))) {
+      ldp_if_del_addr(global, iff, ap);
+    }
+
+    MPLS_REFCNT_RELEASE2(global, iff, ldp_if_delete);
+  }
+
+  global->configuration_sequence_number++;
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_if_set_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_if_set");
+
+  return retval;
+}
+
+/******************* ATTR **********************/
+
+mpls_return_enum ldp_cfg_attr_get(mpls_cfg_handle handle, ldp_attr * a,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_attr *attr = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && a != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_attr_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (ldp_global_find_attr_index(global, a->index, &attr) != MPLS_SUCCESS)
+      goto ldp_cfg_attr_get_end;
+
+  if (flag & LDP_ATTR_CFG_STATE) {
+    a->state = attr->state;
+  }
+  if (flag & LDP_ATTR_CFG_FEC) {
+    ldp_attr2ldp_attr(attr, a, LDP_ATTR_FEC);
+  }
+  if (flag & LDP_ATTR_CFG_LABEL) {
+    ldp_attr2ldp_attr(attr, a, LDP_ATTR_LABEL);
+  }
+  if (flag & LDP_ATTR_CFG_HOP_COUNT) {
+    ldp_attr2ldp_attr(attr, a, LDP_ATTR_HOPCOUNT);
+  }
+  if (flag & LDP_ATTR_CFG_PATH) {
+    ldp_attr2ldp_attr(attr, a, LDP_ATTR_PATH);
+  }
+  if (flag & LDP_ATTR_CFG_SESSION_INDEX) {
+    a->session_index = (attr->session) ? (attr->session->index) : 0;
+  }
+  if (flag & LDP_ATTR_CFG_INLABEL_INDEX) {
+    a->inlabel_index = (attr->inlabel) ? (attr->inlabel->index) : 0;
+  }
+  if (flag & LDP_ATTR_CFG_OUTLABEL_INDEX) {
+    a->outlabel_index = (attr->outlabel) ? (attr->outlabel->index) : 0;
+  }
+  if (flag & LDP_ATTR_CFG_INGRESS) {
+    a->ingress = attr->ingress;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_attr_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_attr_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_attr_getnext(mpls_cfg_handle handle, ldp_attr * a,
+  uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_attr *attr = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_attr_getnext");
+
+  if (a->index == 0) {
+    index = 1;
+  } else {
+    index = a->index + 1;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_attr_index(g, index, &attr))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    a->index = attr->index;
+    LDP_EXIT(g->user_data, "ldp_cfg_attr_getnext");
+    return ldp_cfg_attr_get(g, a, flag);
+  }
+  LDP_EXIT(g->user_data, "ldp_cfg_attr_getnext");
+  return r;
+}
+
+/******************* PEER **********************/
+
+mpls_return_enum ldp_cfg_peer_get(mpls_cfg_handle handle, ldp_peer * p,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_peer *peer = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && p != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_peer_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (ldp_global_find_peer_index(global, p->index, &peer) != MPLS_SUCCESS)
+      goto ldp_cfg_peer_get_end;
+
+  if (flag & LDP_PEER_CFG_LABEL_SPACE) {
+    p->label_space = peer->label_space;
+  }
+  if (flag & LDP_PEER_CFG_TARGET_ROLE) {
+    p->target_role = peer->target_role;
+  }
+  if (flag & LDP_PEER_CFG_DEST_ADDR) {
+    memcpy(&p->dest.addr, &peer->dest.addr, sizeof(mpls_inet_addr));
+  }
+  if (flag & LDP_PEER_CFG_ENTITY_INDEX) {
+    p->entity_index = peer->entity->index;
+  }
+  if (flag & LDP_PEER_CFG_OPER_STATE) {
+    p->oper_state = peer->oper_state;
+  }
+  if (flag & LDP_PEER_CFG_PEER_NAME) {
+    strncpy(p->peer_name, peer->peer_name, MPLS_MAX_IF_NAME);
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_peer_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_peer_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_peer_getnext(mpls_cfg_handle handle, ldp_peer * p,
+  uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_peer *peer = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_peer_getnext");
+
+  if (p->index == 0) {
+    index = 1;
+  } else {
+    index = p->index + 1;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_peer_index(g, index, &peer))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    p->index = peer->index;
+    LDP_EXIT(g->user_data, "ldp_cfg_peer_getnext");
+    return ldp_cfg_peer_get(g, p, flag);
+  }
+  LDP_EXIT(g->user_data, "ldp_cfg_peer_getnext");
+  return r;
+}
+
+mpls_return_enum ldp_cfg_peer_test(mpls_cfg_handle handle, ldp_peer * p,
+  uint32_t flag)
+{
+  // ldp_global* g = (ldp_global*)handle;
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_cfg_peer_set(mpls_cfg_handle handle, ldp_peer * p,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_peer *peer = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && p != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_peer_set");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_CFG_ADD) {
+    if ((peer = ldp_peer_create()) == NULL) {
+      goto ldp_cfg_peer_set_end;
+    }
+    p->index = peer->index;
+    _ldp_global_add_peer(global, peer);
+  } else {
+    ldp_global_find_peer_index(global, p->index, &peer);
+  }
+
+  if (peer == NULL) {
+    LDP_PRINT(global->user_data, "ldp_cfg_peer_set: no such peer\n");
+
+    goto ldp_cfg_peer_set_end;
+  }
+  if ((ldp_peer_is_active(peer) == MPLS_BOOL_TRUE) && (flag & LDP_PEER_CFG_WHEN_DOWN)) {
+    LDP_PRINT(global->user_data, "ldp_cfg_peer_set: peer is activer\n");
+
+    goto ldp_cfg_peer_set_end;
+  }
+
+  if (flag & LDP_CFG_DEL) {
+    if (peer->entity != NULL) {
+      LDP_PRINT(global->user_data,
+        "ldp_cfg_peer_set: not cleanup correctly is activer\n");
+
+      goto ldp_cfg_peer_set_end;
+    }
+
+    _ldp_global_del_peer(global, peer);
+
+    retval = MPLS_SUCCESS;
+    goto ldp_cfg_peer_set_end;
+  }
+  if (flag & LDP_PEER_CFG_LABEL_SPACE) {
+    peer->label_space = p->label_space;
+  }
+  if (flag & LDP_PEER_CFG_TARGET_ROLE) {
+    peer->target_role = p->target_role;
+  }
+  if (flag & LDP_PEER_CFG_DEST_ADDR) {
+    memcpy(&peer->dest.addr, &p->dest.addr, sizeof(mpls_inet_addr));
+  }
+  if (flag & LDP_PEER_CFG_PEER_NAME) {
+    LDP_PRINT(global->user_data, "ldp_cfg_peer_set: peer_name = %s\n",
+
+      p->peer_name);
+    strncpy(peer->peer_name, p->peer_name, MPLS_MAX_IF_NAME);
+  }
+  global->configuration_sequence_number++;
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_peer_set_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_peer_set");
+
+  return retval;
+}
+/******************* FEC **********************/
+
+mpls_return_enum ldp_cfg_fec_get(mpls_cfg_handle handle, mpls_fec * f,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_fec *fec = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && f != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_fec_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_FEC_CFG_BY_INDEX) {
+    ldp_global_find_fec_index(global, f->index, &fec);
+  } else {
+    fec = ldp_fec_find(global, f);
+  }
+  if (!fec)
+      goto ldp_cfg_fec_get_end;
+
+  memcpy(f, &fec->info, sizeof(mpls_fec));
+  f->index = fec->index;
+  f->is_route = fec->is_route;
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_fec_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_fec_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_fec_getnext(mpls_cfg_handle handle, mpls_fec * f,
+  uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_fec *fec = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_fec_getnext");
+
+  if (f->index == 0) {
+    index = 1;
+  } else {
+    index = f->index + 1;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_fec_index(g, index, &fec))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    f->index = fec->index;
+    LDP_EXIT(g->user_data, "ldp_cfg_fec_getnext");
+    return ldp_cfg_fec_get(g, f, flag);
+  }
+  LDP_EXIT(g->user_data, "ldp_cfg_fec_getnext");
+  return r;
+}
+
+mpls_return_enum ldp_cfg_fec_test(mpls_cfg_handle handle, mpls_fec * f,
+  uint32_t flag)
+{
+  // ldp_global* g = (ldp_global*)handle;
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_cfg_fec_set(mpls_cfg_handle handle, mpls_fec * f,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_fec *fec = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global != NULL && f != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_fec_set");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_CFG_ADD) {
+    if ((fec = ldp_fec_find(global, f))) {
+      if (fec->is_route == MPLS_BOOL_TRUE) {
+        goto ldp_cfg_fec_set_end;
+      }
+    } else {
+      if ((fec = ldp_fec_create(global, f)) == NULL) {
+        goto ldp_cfg_fec_set_end;
+      }
+    }
+    fec->is_route = MPLS_BOOL_TRUE;
+    MPLS_REFCNT_HOLD(fec);
+    f->index = fec->index;
+  } else {
+    if (flag & LDP_FEC_CFG_BY_INDEX) {
+      ldp_global_find_fec_index(global, f->index, &fec);
+    } else {
+      fec = ldp_fec_find(global, f);
+    }
+  }
+
+  if (fec == NULL) {
+    LDP_PRINT(global->user_data, "ldp_cfg_fec_set: no such fec\n");
+    goto ldp_cfg_fec_set_end;
+  }
+
+  if (flag & LDP_CFG_DEL) {
+    /*
+     * we can only delete the fec if all of the nexthops have been removed
+     */
+    if (!MPLS_LIST_EMPTY(&fec->nh_root)) {
+      goto ldp_cfg_fec_set_end;
+    }
+
+    fec->is_route = MPLS_BOOL_FALSE;
+
+    /*
+     * we hold the last refcnt, this should result in a call to
+     * ldp_fec_delete
+     */
+    MPLS_REFCNT_RELEASE2(global, fec, ldp_fec_delete);
+  }
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_fec_set_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_fec_set");
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_fec_nexthop_get(mpls_cfg_handle handle, mpls_fec * f,
+  mpls_nexthop *n, uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_fec *fec = NULL;
+  ldp_nexthop *nh = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && f != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_fec_nexthop_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_FEC_CFG_BY_INDEX) {
+    ldp_global_find_fec_index(global, f->index, &fec);
+  } else {
+    fec = ldp_fec_find(global, f);
+  }
+  if (!fec)
+      goto ldp_cfg_fec_nexthop_get_end;
+
+  if (flag & LDP_FEC_NEXTHOP_CFG_BY_INDEX) {
+    ldp_fec_find_nexthop_index(fec, n->index, &nh);
+  } else {
+    nh = ldp_fec_nexthop_find(fec, n);
+  }
+  if (!nh)
+    goto ldp_cfg_fec_nexthop_get_end;
+
+  memcpy(n, &nh->info, sizeof(mpls_nexthop));
+  n->index = nh->index;
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_fec_nexthop_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_fec_nexthop_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_fec_nexthop_getnext(mpls_cfg_handle handle,
+  mpls_fec * f, mpls_nexthop *n, uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_fec *fec = NULL;
+  ldp_nexthop *nh = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(global->user_data, "ldp_cfg_fec_nexthop_getnext");
+
+  if (n->index == 0) {
+    index = 1;
+  } else {
+    index = n->index + 1;
+  }
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_FEC_CFG_BY_INDEX) {
+    ldp_global_find_fec_index(global, f->index, &fec);
+  } else {
+    fec = ldp_fec_find(global, f);
+  }
+  if (!fec)
+      goto ldp_cfg_fec_nexthop_getnext_end;
+
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_fec_find_nexthop_index(fec, index, &nh))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    n->index = nh->index;
+    LDP_EXIT(global->user_data, "ldp_cfg_fec_nexthop_getnext");
+    return ldp_cfg_fec_nexthop_get(global, f, n, flag);
+  }
+
+ldp_cfg_fec_nexthop_getnext_end:
+
+  LDP_EXIT(global->user_data, "ldp_cfg_fec_nexthop_getnext");
+  return r;
+}
+
+mpls_return_enum ldp_cfg_fec_nexthop_test(mpls_cfg_handle handle, mpls_fec * f,
+  mpls_nexthop *n, uint32_t flag)
+{
+  // ldp_global* g = (ldp_global*)handle;
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_cfg_fec_nexthop_set(mpls_cfg_handle handle, mpls_fec * f,
+  mpls_nexthop *n, uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_fec *fec = NULL;
+  ldp_nexthop *nh = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global != NULL && f != NULL && n != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_fec_nexthop_set");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_FEC_CFG_BY_INDEX) {
+    ldp_global_find_fec_index(global, f->index, &fec);
+  } else {
+    fec = ldp_fec_find(global, f);
+  }
+  if (!fec)
+      goto ldp_cfg_fec_nexthop_set_end;
+
+  if (flag & LDP_CFG_ADD) {
+    if (ldp_fec_nexthop_find(fec, n) ||
+      (nh = ldp_nexthop_create(global, n)) == NULL) {
+      goto ldp_cfg_fec_nexthop_set_end;
+    }
+    n->index = nh->index;
+    ldp_fec_add_nexthop(global, fec, nh);
+    ldp_fec_process_add(global, fec, nh, NULL);
+  } else {
+    if (flag & LDP_FEC_NEXTHOP_CFG_BY_INDEX) {
+      ldp_fec_find_nexthop_index(fec, n->index, &nh);
+    } else {
+      nh = ldp_fec_nexthop_find(fec, n);
+    }
+  }
+
+  if (nh == NULL) {
+    LDP_PRINT(global->user_data, "ldp_cfg_fec_nexthop_set: no such nh\n");
+    goto ldp_cfg_fec_nexthop_set_end;
+  }
+
+  if (flag & LDP_CFG_DEL) {
+    MPLS_REFCNT_HOLD(nh);
+    ldp_fec_del_nexthop(global, fec, nh);
+    if (ldp_fec_process_change(global, fec, MPLS_LIST_HEAD(&fec->nh_root),
+      nh, NULL) != MPLS_SUCCESS) {
+      MPLS_ASSERT(0);
+    }
+    MPLS_REFCNT_RELEASE2(global, nh, ldp_nexthop_delete);
+  }
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_fec_nexthop_set_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_fec_nexthop_set");
+
+  return retval;
+}
+
+/******************* ADDR **********************/
+
+mpls_return_enum ldp_cfg_addr_get(mpls_cfg_handle handle, ldp_addr * a,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_session *session = NULL;
+  ldp_nexthop *nexthop = NULL;
+  ldp_addr *addr = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && a != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_addr_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  ldp_global_find_addr_index(global, a->index, &addr);
+
+  if (!addr)
+    goto ldp_cfg_addr_get_end;
+
+  memcpy(&a->address, &addr->address, sizeof(mpls_inet_addr));
+  a->index = addr->index;
+
+  if (addr->session) {
+    a->session_index = addr->session->index;
+  }
+
+  if ((nexthop = MPLS_LIST_HEAD(&addr->nh_root))) {
+    a->nexthop_index = nexthop->index;
+  }
+
+  if (addr->iff) {
+    a->if_index = addr->iff->index;
+  }
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_addr_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_addr_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_addr_getnext(mpls_cfg_handle handle, ldp_addr *a,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_addr *addr = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(global->user_data, "ldp_cfg_addr_getnext");
+
+  if (a->index == 0) {
+    index = 1;
+  } else {
+    index = a->index + 1;
+  }
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_addr_index(global, index, &addr))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    a->index = addr->index;
+    LDP_EXIT(global->user_data, "ldp_cfg_addr_getnext");
+    return ldp_cfg_addr_get(global, a, flag);
+  }
+
+  LDP_EXIT(global->user_data, "ldp_cfg_addr_getnext");
+  return r;
+}
+
+/******************* IF ADDR **********************/
+
+mpls_return_enum ldp_cfg_if_addr_get(mpls_cfg_handle handle, ldp_if * i,
+  ldp_addr * a, uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_addr *addr = NULL;
+  ldp_if *iff = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && i != NULL && a != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_if_addr_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_IF_CFG_BY_INDEX) {
+    ldp_global_find_if_index(global, i->index, &iff);
+  } else {
+    iff = ldp_global_find_if_handle(global, i->handle);
+  }
+  if (!iff)
+      goto ldp_cfg_if_addr_get_end;
+
+  if (flag & LDP_IF_ADDR_CFG_BY_INDEX) {
+    ldp_if_find_addr_index(iff, a->index, &addr);
+  } else {
+    addr = ldp_if_addr_find(iff, &a->address);
+  }
+  if (!addr)
+    goto ldp_cfg_if_addr_get_end;
+
+  memcpy(&a->address, &addr->address, sizeof(mpls_inet_addr));
+  a->index = addr->index;
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_if_addr_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_if_addr_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_if_addr_getnext(mpls_cfg_handle handle,
+  ldp_if * i, ldp_addr *a, uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_if *iff = NULL;
+  ldp_addr *addr = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(global->user_data, "ldp_cfg_if_addr_getnext");
+
+  if (a->index == 0) {
+    index = 1;
+  } else {
+    index = a->index + 1;
+  }
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_IF_CFG_BY_INDEX) {
+    ldp_global_find_if_index(global, i->index, &iff);
+  } else {
+    iff = ldp_global_find_if_handle(global, i->handle);
+  }
+  if (!iff)
+      goto ldp_cfg_if_addr_getnext_end;
+
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_if_find_addr_index(iff, index, &addr))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    a->index = addr->index;
+    LDP_EXIT(global->user_data, "ldp_cfg_if_addr_getnext");
+    return ldp_cfg_if_addr_get(global, i, a, flag);
+  }
+
+ldp_cfg_if_addr_getnext_end:
+
+  LDP_EXIT(global->user_data, "ldp_cfg_if_addr_getnext");
+  return r;
+}
+
+mpls_return_enum ldp_cfg_if_addr_set(mpls_cfg_handle handle, ldp_if * i,
+  ldp_addr *a, uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_if *iff = NULL;
+  ldp_addr *addr = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global != NULL && i != NULL && a != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_if_addr_set");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_IF_CFG_BY_INDEX) {
+    ldp_global_find_if_index(global, i->index, &iff);
+  } else {
+    iff = ldp_global_find_if_handle(global, i->handle);
+  }
+  if (!iff)
+      goto ldp_cfg_if_addr_set_end;
+
+  if (flag & LDP_CFG_ADD) {
+    if (ldp_if_addr_find(iff, &a->address) || ((addr = ldp_addr_create(global,
+      &a->address)) == NULL)) {
+      goto ldp_cfg_if_addr_set_end;
+    }
+    a->index = addr->index;
+    ldp_if_add_addr(iff, addr);
+    ldp_addr_process_add(global, addr);
+  } else {
+    if (flag & LDP_IF_ADDR_CFG_BY_INDEX) {
+      ldp_if_find_addr_index(iff, a->index, &addr);
+    } else {
+      addr = ldp_if_addr_find(iff, &a->address);
+    }
+  }
+
+  if (addr == NULL) {
+    LDP_PRINT(global->user_data, "ldp_cfg_if_addr_set: no such addr\n");
+    goto ldp_cfg_if_addr_set_end;
+  }
+
+  if (flag & LDP_CFG_DEL) {
+    ldp_addr_process_remove(global, addr);
+    ldp_if_del_addr(global, iff, addr);
+  }
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_if_addr_set_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_if_addr_set");
+
+  return retval;
+}
+
+/******************* ADJACENCY **********************/
+
+mpls_return_enum ldp_cfg_adj_get(mpls_cfg_handle handle, ldp_adj * a,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_adj *adj = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global != NULL && a != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_adj_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (ldp_global_find_adj_index(global, a->index, &adj) != MPLS_SUCCESS)
+      goto ldp_cfg_adj_get_end;
+
+  if (flag & LDP_ADJ_CFG_REMOTE_TRADDR) {
+    memcpy(&a->remote_transport_address, &adj->remote_transport_address,
+      sizeof(mpls_inet_addr));
+  }
+  if (flag & LDP_ADJ_CFG_REMOTE_SRCADDR) {
+    memcpy(&a->remote_source_address, &adj->remote_source_address,
+      sizeof(mpls_inet_addr));
+  }
+  if (flag & LDP_ADJ_CFG_REMOTE_LSRADDR) {
+    memcpy(&a->remote_lsr_address, &adj->remote_lsr_address,
+      sizeof(mpls_inet_addr));
+  }
+  if (flag & LDP_ADJ_CFG_REMOTE_CSN) {
+    a->remote_csn = adj->remote_csn;
+  }
+  if (flag & LDP_ADJ_CFG_REMOTE_LABELSPACE) {
+    a->remote_label_space = adj->remote_label_space;
+  }
+  if (flag & LDP_ADJ_CFG_REMOTE_HELLOTIME) {
+    a->remote_hellotime = adj->remote_hellotime;
+  }
+  if (flag & LDP_ADJ_CFG_ENTITY_INDEX) {
+    a->entity_index = adj->entity ? adj->entity->index : 0;
+  }
+  if (flag & LDP_ADJ_CFG_REMOTE_SESSION_INDEX) {
+    a->session_index = (adj->session) ? (adj->session->index) : 0;
+  }
+  if (flag & LDP_ADJ_CFG_ROLE) {
+    a->role = adj->role;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_adj_get_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_adj_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_adj_getnext(mpls_cfg_handle handle, ldp_adj * a,
+  uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_adj *adj = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_adj_getnext");
+
+  if (a->index == 0) {
+    index = 1;
+  } else {
+    index = a->index + 1;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_adj_index(g, index, &adj))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    a->index = adj->index;
+    LDP_EXIT(g->user_data, "ldp_cfg_adj_getnext");
+    return ldp_cfg_adj_get(g, a, flag);
+  }
+  LDP_EXIT(g->user_data, "ldp_cfg_adj_getnext");
+  return r;
+}
+
+/******************* SESSION **********************/
+
+mpls_return_enum ldp_cfg_session_get(mpls_cfg_handle handle, ldp_session * s,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_session *session = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && s != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_session_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (ldp_global_find_session_index(global, s->index, &session) != MPLS_SUCCESS)
+      goto ldp_cfg_session_get_end;
+
+  if (flag & LDP_SESSION_CFG_STATE) {
+    s->state = session->state;
+  }
+  if (flag & LDP_SESSION_CFG_OPER_UP) {
+    s->oper_up = session->oper_up;
+  }
+  if (flag & LDP_SESSION_CFG_MAX_PDU) {
+    s->oper_max_pdu = session->oper_max_pdu;
+  }
+  if (flag & LDP_SESSION_CFG_KEEPALIVE) {
+    s->oper_keepalive = session->oper_keepalive;
+  }
+  if (flag & LDP_SESSION_CFG_PATH_LIMIT) {
+    s->oper_path_vector_limit = session->oper_path_vector_limit;
+  }
+  if (flag & LDP_SESSION_CFG_DIST_MODE) {
+    s->oper_distribution_mode = session->oper_distribution_mode;
+  }
+  if (flag & LDP_SESSION_CFG_LOOP_DETECTION) {
+    s->oper_loop_detection = session->oper_loop_detection;
+  }
+  if (flag & LDP_SESSION_CFG_REMOTE_MAX_PDU) {
+    s->remote_max_pdu = session->remote_max_pdu;
+  }
+  if (flag & LDP_SESSION_CFG_REMOTE_KEEPALIVE) {
+    s->remote_keepalive = session->remote_keepalive;
+  }
+  if (flag & LDP_SESSION_CFG_REMOTE_PATH_LIMIT) {
+    s->remote_path_vector_limit = session->remote_path_vector_limit;
+  }
+  if (flag & LDP_SESSION_CFG_REMOTE_DIST_MODE) {
+    s->remote_distribution_mode = session->remote_distribution_mode;
+  }
+  if (flag & LDP_SESSION_CFG_REMOTE_LOOP_DETECTION) {
+    s->remote_loop_detection = session->remote_loop_detection;
+  }
+  if (flag & LDP_SESSION_CFG_REMOTE_ADDR) {
+    s->remote_dest.addr.type = session->remote_dest.addr.type;
+    s->remote_dest.addr.u.ipv4 = session->remote_dest.addr.u.ipv4;
+  }
+  if (flag & LDP_SESSION_CFG_REMOTE_PORT) {
+    s->remote_dest.port = session->remote_dest.port;
+  }
+  if (flag & LDP_SESSION_CFG_LABEL_RESOURCE_STATE_LOCAL) {
+    s->no_label_resource_sent = session->no_label_resource_sent;
+  }
+  if (flag & LDP_SESSION_CFG_LABEL_RESOURCE_STATE_REMOTE) {
+    s->no_label_resource_recv = session->no_label_resource_recv;
+  }
+  if (flag & LDP_SESSION_CFG_ADJ_INDEX) {
+    ldp_adj *a = MPLS_LIST_HEAD(&session->adj_root);
+    s->adj_index = a ? a->index : 0;
+  }
+  if (flag & LDP_SESSION_CFG_MESG_TX) {
+    s->mesg_tx = session->mesg_tx;
+  }
+  if (flag & LDP_SESSION_CFG_MESG_RX) {
+    s->mesg_rx = session->mesg_rx;
+  }
+  if (flag & LDP_SESSION_CFG_LOCAL_NAME) {
+    if (mpls_socket_handle_verify(global->socket_handle,
+      session->socket) == MPLS_BOOL_TRUE) {
+      mpls_socket_get_local_name(global->socket_handle, session->socket,
+	&s->local_name);
+    }
+  }
+  if (flag & LDP_SESSION_CFG_REMOTE_NAME) {
+    if (mpls_socket_handle_verify(global->socket_handle,
+      session->socket) == MPLS_BOOL_TRUE) {
+      mpls_socket_get_remote_name(global->socket_handle, session->socket,
+	&s->remote_name);
+    }
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_session_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_session_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_session_getnext(mpls_cfg_handle handle, ldp_session * s,
+  uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_session *ses = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_session_getnext");
+
+  if (s->index == 0) {
+    index = 1;
+  } else {
+    index = s->index + 1;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_session_index(g, index, &ses))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    s->index = ses->index;
+
+    LDP_EXIT(g->user_data, "ldp_cfg_session_getnext");
+    return ldp_cfg_session_get(g, s, flag);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_cfg_session_getnext");
+
+  return r;
+}
+
+mpls_return_enum ldp_cfg_session_adj_getnext(mpls_cfg_handle handle,
+  ldp_session * s)
+{
+  ldp_global *g = (ldp_global *) handle;
+  mpls_bool this_one = MPLS_BOOL_FALSE;
+  mpls_return_enum r = MPLS_FAILURE;
+  ldp_adj *adj_next = NULL;
+  ldp_adj *adj = NULL;
+  ldp_session *session = NULL;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_session_adj_getnext");
+
+  /* if an adj_index of zero is sent, get the index of
+   * the first adj in the list
+   */
+  if (!s->adj_index) {
+    this_one = MPLS_BOOL_TRUE;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+
+  if (ldp_global_find_session_index(g, s->index, &session) == MPLS_SUCCESS) {
+    adj = MPLS_LIST_HEAD(&session->adj_root);
+    while (adj) {
+      if (this_one == MPLS_BOOL_TRUE) {
+        adj_next = adj;
+        break;
+      }
+
+      /* since the entities are sort in the list ... */
+      if (adj->index > s->adj_index) {
+        break;
+      } else if (adj->index == s->adj_index) {
+        this_one = MPLS_BOOL_TRUE;
+      }
+      adj = MPLS_LIST_NEXT(&session->adj_root, adj, _session);
+    }
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (adj_next) {
+    s->adj_index = adj_next->index;
+    r = MPLS_SUCCESS;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_cfg_session_adj_getnext");
+  return r;
+}
+
+mpls_return_enum ldp_cfg_session_raddr_get(mpls_cfg_handle handle,
+  ldp_session * s, ldp_addr * a, uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_session *session = NULL;
+  ldp_addr *addr = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && s != NULL && a != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_session_raddr_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (ldp_global_find_session_index(global, s->index, &session) != MPLS_SUCCESS) 
+      goto ldp_cfg_session_raddr_get_end;
+
+  if (ldp_session_find_raddr_index(session, a->index, &addr) != MPLS_SUCCESS)
+      goto ldp_cfg_session_raddr_get_end;
+
+  if (flag & LDP_SESSION_RADDR_CFG_ADDR) {
+    memcpy(&a->address,&addr->address,sizeof(struct mpls_inet_addr));
+  }
+  if (flag & LDP_SESSION_RADDR_CFG_INDEX) {
+    a->index = addr->index;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_session_raddr_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_session_raddr_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_session_raddr_getnext(mpls_cfg_handle handle,
+  ldp_session * s, ldp_addr * a, uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_addr *addr = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  ldp_session *sp = NULL;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_session_raddr_getnext");
+
+  if (a->index == 0) {
+    index = 1;
+  } else {
+    index = a->index + 1;
+  }
+
+  r = ldp_global_find_session_index(g, s->index, &sp);
+  if (r != MPLS_SUCCESS) {
+    return r;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_session_find_raddr_index(sp, index, &addr))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    a->index = addr->index;
+    r = ldp_cfg_session_raddr_get(handle, sp, a, flag);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_cfg_session_getnext");
+  return r;
+}
+
+/******************* IN LABEL **********************/
+
+mpls_return_enum ldp_cfg_inlabel_get(mpls_cfg_handle handle, ldp_inlabel * i,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_inlabel *inlabel = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && i != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_inlabel_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (ldp_global_find_inlabel_index(global, i->index, &inlabel) != MPLS_SUCCESS)
+      goto ldp_cfg_inlabel_get_end;
+
+  if (flag & LDP_INLABEL_CFG_LABELSPACE) {
+    i->info.labelspace = inlabel->info.labelspace;
+  }
+  if (flag & LDP_INLABEL_CFG_LABEL) {
+    memcpy(&i->info.label, &inlabel->info.label, sizeof(mpls_label_struct));
+  }
+  if (flag & LDP_INLABEL_CFG_OUTLABEL_INDEX) {
+    i->outlabel_index = (inlabel->outlabel) ? (inlabel->outlabel->index) : 0;
+  }
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_inlabel_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_inlabel_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_inlabel_getnext(mpls_cfg_handle handle, ldp_inlabel * i,
+  uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_inlabel *inlabel = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_inlabel_getnext");
+
+  if (i->index == 0) {
+    index = 1;
+  } else {
+    index = i->index + 1;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_inlabel_index(g, index, &inlabel))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    i->index = inlabel->index;
+
+    LDP_EXIT(g->user_data, "ldp_cfg_inlabel_getnext");
+    return ldp_cfg_inlabel_get(g, i, flag);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_cfg_inlabel_getnext");
+
+  return r;
+}
+
+/******************* OUT LABEL **********************/
+
+mpls_return_enum ldp_cfg_outlabel_get(mpls_cfg_handle handle, ldp_outlabel * o,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  ldp_outlabel *outlabel = NULL;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(global !=NULL && o != NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_outlabel_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (ldp_global_find_outlabel_index(global, o->index,
+      &outlabel) != MPLS_SUCCESS) goto ldp_cfg_outlabel_get_end;
+
+  if (flag & LDP_OUTLABEL_CFG_NH_INDEX) {
+    if (outlabel->nh) {
+      o->nh_index = outlabel->nh->index;
+    } else {
+      o->nh_index = 0;
+    }
+  }
+  if (flag & LDP_OUTLABEL_CFG_SESSION_INDEX) {
+    o->session_index = (outlabel->session) ? (outlabel->session->index) : 0;
+  }
+  if (flag & LDP_OUTLABEL_CFG_LABEL) {
+    memcpy(&o->info.label, &outlabel->info.label, sizeof(mpls_label_struct));
+  }
+  if (flag & LDP_OUTLABEL_CFG_MERGE_COUNT) {
+    o->merge_count = outlabel->merge_count;
+  }
+
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_outlabel_get_end:
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_outlabel_get");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_outlabel_getnext(mpls_cfg_handle handle,
+  ldp_outlabel * o, uint32_t flag)
+{
+  ldp_global *g = (ldp_global *) handle;
+  ldp_outlabel *outlabel = NULL;
+  mpls_return_enum r = MPLS_FAILURE;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  int index;
+
+  LDP_ENTER(g->user_data, "ldp_cfg_outlabel_getnext");
+
+  if (o->index == 0) {
+    index = 1;
+  } else {
+    index = o->index + 1;
+  }
+
+  mpls_lock_get(g->global_lock); /* LOCK */
+  while (done == MPLS_BOOL_FALSE) {
+    switch ((r = ldp_global_find_outlabel_index(g, index, &outlabel))) {
+      case MPLS_SUCCESS:
+      case MPLS_END_OF_LIST:
+        done = MPLS_BOOL_TRUE;
+        break;
+      case MPLS_FAILURE:
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+    index++;
+  }
+  mpls_lock_release(g->global_lock); /* UNLOCK */
+
+  if (r == MPLS_SUCCESS) {
+    o->index = outlabel->index;
+
+    LDP_EXIT(g->user_data, "ldp_cfg_outlabel_getnext");
+    return ldp_cfg_outlabel_get(g, o, flag);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_cfg_outlabel_getnext");
+
+  return r;
+}
+
+/******************* TUNNEL **********************/
+
+mpls_return_enum ldp_cfg_tunnel_set(mpls_cfg_handle handle, ldp_tunnel * t,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_tunnel *tunnel = NULL;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_tunnel_set");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_CFG_ADD) {
+    if (!(tunnel = ldp_tunnel_create())) {
+      goto ldp_cfg_tunnel_set_end;
+    }
+    _ldp_global_add_tunnel(global, tunnel);
+
+    t->index = tunnel->index;
+  } else {
+    ldp_global_find_tunnel_index(global, t->index, &tunnel);
+  }
+
+  if (!tunnel) {
+    LDP_PRINT(global->user_data,
+
+      "ldp_cfg_tunnel_set:could not create tunnel\n");
+    goto ldp_cfg_tunnel_set_end;
+  }
+
+  if ((ldp_tunnel_is_active(tunnel) == MPLS_BOOL_TRUE) &&
+    (flag & LDP_TUNNEL_CFG_WHEN_DOWN)) {
+    LDP_PRINT(global->user_data, "ldp_cfg_tunnel_set: tunnel is active\n");
+
+    goto ldp_cfg_tunnel_set_end;
+  }
+
+  if (flag & LDP_CFG_DEL) {
+    if (tunnel->outlabel)
+      ldp_tunnel_del_outlabel(global, tunnel);
+    if (tunnel->resource)
+      ldp_tunnel_del_resource(tunnel);
+    if (tunnel->hop_list)
+      ldp_tunnel_del_hop_list(tunnel);
+    _ldp_global_del_tunnel(global, tunnel);
+
+    retval = MPLS_SUCCESS;
+    goto ldp_cfg_tunnel_set_end;
+  }
+
+  if (flag & LDP_TUNNEL_CFG_INGRESS) {
+    memcpy(&tunnel->ingress_lsrid, &t->ingress_lsrid, sizeof(ldp_addr));
+  }
+  if (flag & LDP_TUNNEL_CFG_EGRESS) {
+    memcpy(&tunnel->egress_lsrid, &t->egress_lsrid, sizeof(ldp_addr));
+  }
+  if (flag & LDP_TUNNEL_CFG_NAME) {
+    memcpy(&tunnel->name, &t->name, MPLS_MAX_IF_NAME);
+  }
+  if (flag & LDP_TUNNEL_CFG_IS_IF) {
+    tunnel->is_interface = t->is_interface;
+  }
+  if (flag & LDP_TUNNEL_CFG_OUTLABEL) {
+    ldp_outlabel *outlabel = NULL;
+
+    if (t->outlabel_index) {
+      ldp_global_find_outlabel_index(global, t->outlabel_index, &outlabel);
+
+      if (!outlabel) {
+        goto ldp_cfg_tunnel_set_end;
+      }
+      ldp_tunnel_add_outlabel(tunnel, outlabel);
+    } else {
+      ldp_tunnel_del_outlabel(global, tunnel);
+    }
+  }
+  if (flag & LDP_TUNNEL_CFG_SETUP_PRIO) {
+    tunnel->setup_prio = t->setup_prio;
+  }
+  if (flag & LDP_TUNNEL_CFG_HOLD_PRIO) {
+    tunnel->hold_prio = t->hold_prio;
+  }
+  if (flag & LDP_TUNNEL_CFG_INSTANCE_PRIO) {
+    tunnel->instance_prio = t->instance_prio;
+  }
+  if (flag & LDP_TUNNEL_CFG_LOCAL_PROTECT) {
+    tunnel->local_protect = t->local_protect;
+  }
+  if (flag & LDP_TUNNEL_CFG_RESOURCE_INDEX) {
+    ldp_resource *resource = NULL;
+
+    if (t->resource_index) {
+      ldp_global_find_resource_index(global, t->resource_index, &resource);
+
+      if (!resource) {
+        goto ldp_cfg_tunnel_set_end;
+      }
+      ldp_tunnel_add_resource(tunnel, resource);
+    } else {
+      ldp_tunnel_del_resource(tunnel);
+    }
+  }
+  if (flag & LDP_TUNNEL_CFG_HOP_LIST_INDEX) {
+    ldp_hop_list *hop_list = NULL;
+
+    if (t->hop_list_index) {
+      ldp_global_find_hop_list_index(global, t->hop_list_index, &hop_list);
+
+      if (!hop_list) {
+        goto ldp_cfg_tunnel_set_end;
+      }
+      ldp_tunnel_add_hop_list(tunnel, hop_list);
+    } else {
+      ldp_tunnel_del_hop_list(tunnel);
+    }
+  }
+  if (flag & LDP_TUNNEL_CFG_FEC) {
+    memcpy(&tunnel->fec, &t->fec, sizeof(ldp_fec));
+  }
+  if (flag & LDP_TUNNEL_CFG_ADMIN_STATE) {
+    if (ldp_tunnel_is_active(tunnel) == MPLS_BOOL_TRUE) {
+      if (t->admin_state == MPLS_ADMIN_DISABLE) {
+        if (ldp_tunnel_shutdown(global, tunnel, 0) == MPLS_FAILURE) {
+          goto ldp_cfg_tunnel_set_end;
+        }
+      }
+    } else {
+      if (t->admin_state == MPLS_ADMIN_ENABLE) {
+        if (ldp_tunnel_is_ready(tunnel) == MPLS_BOOL_TRUE) {
+          if (ldp_tunnel_startup(global, tunnel) == MPLS_FAILURE) {
+            goto ldp_cfg_tunnel_set_end;
+          }
+        } else {
+          LDP_PRINT(global->user_data,
+
+            "ldp_cfg_tunnel_set: tunnel not ready\n");
+          goto ldp_cfg_tunnel_set_end;
+        }
+      }
+    }
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_tunnel_set_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_tunnel_set");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_tunnel_test(mpls_cfg_handle handle, ldp_tunnel * t,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_tunnel *tunnel = NULL;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_tunnel_test");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_CFG_ADD) {
+    retval = MPLS_SUCCESS;
+    goto ldp_cfg_tunnel_test_end;
+  }
+
+  ldp_global_find_tunnel_index(global, t->index, &tunnel);
+
+  if (!tunnel) {
+    goto ldp_cfg_tunnel_test_end;
+  }
+
+  if (flag & LDP_TUNNEL_CFG_RESOURCE_INDEX) {
+    ldp_resource *resource = NULL;
+
+    if (t->resource_index) {
+      ldp_global_find_resource_index(global, t->resource_index, &resource);
+
+      if (!resource) {
+        goto ldp_cfg_tunnel_test_end;
+      }
+    }
+  }
+  if (flag & LDP_TUNNEL_CFG_HOP_LIST_INDEX) {
+    ldp_hop_list *hop_list = NULL;
+
+    if (t->hop_list_index) {
+      ldp_global_find_hop_list_index(global, t->hop_list_index, &hop_list);
+
+      if (!hop_list) {
+        goto ldp_cfg_tunnel_test_end;
+      }
+    }
+  }
+  if (flag & LDP_TUNNEL_CFG_OUTLABEL) {
+    ldp_outlabel *outlabel = NULL;
+
+    if (t->outlabel_index) {
+      ldp_global_find_outlabel_index(global, t->outlabel_index, &outlabel);
+
+      if (!outlabel) {
+        goto ldp_cfg_tunnel_test_end;
+      }
+    }
+  }
+  if ((flag & LDP_TUNNEL_CFG_ADMIN_STATE) &&
+    (ldp_tunnel_is_active(tunnel) == MPLS_BOOL_FALSE) &&
+    (t->admin_state == MPLS_ADMIN_ENABLE) && (ldp_tunnel_is_ready(tunnel) != MPLS_BOOL_TRUE)) {
+    goto ldp_cfg_tunnel_test_end;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_tunnel_test_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_tunnel_test");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_tunnel_get(mpls_cfg_handle handle, ldp_tunnel * t,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_tunnel *tunnel = NULL;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_tunnel_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  ldp_global_find_tunnel_index(global, t->index, &tunnel);
+
+  if (!tunnel) {
+    goto ldp_cfg_tunnel_get_end;
+  }
+  if (flag & LDP_TUNNEL_CFG_INGRESS) {
+    memcpy(&t->ingress_lsrid, &tunnel->ingress_lsrid, sizeof(ldp_addr));
+  }
+  if (flag & LDP_TUNNEL_CFG_EGRESS) {
+    memcpy(&t->egress_lsrid, &tunnel->egress_lsrid, sizeof(ldp_addr));
+  }
+  if (flag & LDP_TUNNEL_CFG_NAME) {
+    memcpy(&t->name, &tunnel->name, MPLS_MAX_IF_NAME);
+  }
+  if (flag & LDP_TUNNEL_CFG_IS_IF) {
+    t->is_interface = tunnel->is_interface;
+  }
+  if (flag & LDP_TUNNEL_CFG_OUTLABEL) {
+    if (tunnel->outlabel) {
+      t->outlabel_index = tunnel->outlabel->index;
+    } else {
+      t->outlabel_index = 0;
+    }
+  }
+  if (flag & LDP_TUNNEL_CFG_SETUP_PRIO) {
+    t->setup_prio = tunnel->setup_prio;
+  }
+  if (flag & LDP_TUNNEL_CFG_HOLD_PRIO) {
+    t->hold_prio = tunnel->hold_prio;
+  }
+  if (flag & LDP_TUNNEL_CFG_INSTANCE_PRIO) {
+    tunnel->instance_prio = t->instance_prio;
+  }
+  if (flag & LDP_TUNNEL_CFG_LOCAL_PROTECT) {
+    tunnel->local_protect = t->local_protect;
+  }
+  if (flag & LDP_TUNNEL_CFG_RESOURCE_INDEX) {
+    if (tunnel->resource) {
+      t->resource_index = tunnel->resource->index;
+    } else {
+      t->resource_index = 0;
+    }
+  }
+  if (flag & LDP_TUNNEL_CFG_HOP_LIST_INDEX) {
+    if (tunnel->hop_list) {
+      t->hop_list_index = tunnel->hop_list->index;
+    } else {
+      t->hop_list_index = 0;
+    }
+  }
+  if (flag & LDP_TUNNEL_CFG_FEC) {
+    memcpy(&t->fec, &tunnel->fec, sizeof(ldp_fec));
+  }
+  if (flag & LDP_TUNNEL_CFG_ADMIN_STATE) {
+    t->admin_state = tunnel->admin_state;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_tunnel_get_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_tunnel_get");
+
+  return retval;
+}
+
+/******************* RESOURCE **********************/
+
+mpls_return_enum ldp_cfg_resource_set(mpls_cfg_handle handle, ldp_resource * r,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_resource *resource = NULL;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_resource_set");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_CFG_ADD) {
+    resource = ldp_resource_create();
+    _ldp_global_add_resource(global, resource);
+
+    r->index = resource->index;
+  } else {
+    ldp_global_find_resource_index(global, r->index, &resource);
+  }
+
+  if (!resource) {
+    goto ldp_cfg_resource_set_end;
+  }
+
+  if (flag & LDP_RESOURCE_CFG_MAXBPS) {
+    resource->max_rate = r->max_rate;
+  }
+  if (flag & LDP_RESOURCE_CFG_MEANBPS) {
+    resource->mean_rate = r->mean_rate;
+  }
+  if (flag & LDP_RESOURCE_CFG_BURSTSIZE) {
+    resource->burst_size = r->burst_size;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_resource_set_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_resource_set");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_resource_test(mpls_cfg_handle handle, ldp_resource * r,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_resource *resource = NULL;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_resource_test");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_CFG_ADD) {
+    retval = MPLS_SUCCESS;
+    goto ldp_cfg_resource_test_end;
+  }
+
+  ldp_global_find_resource_index(global, r->index, &resource);
+
+  if (!resource) {
+    goto ldp_cfg_resource_test_end;
+  }
+
+  if (ldp_resource_in_use(resource) == MPLS_BOOL_TRUE) {
+    goto ldp_cfg_resource_test_end;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_resource_test_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_resource_test");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_resource_get(mpls_cfg_handle handle, ldp_resource * r,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_resource *resource = NULL;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_resource_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  ldp_global_find_resource_index(global, r->index, &resource);
+
+  if (!resource) {
+    goto ldp_cfg_resource_get_end;
+  }
+
+  if (flag & LDP_RESOURCE_CFG_MAXBPS) {
+    r->max_rate = resource->max_rate;
+  }
+  if (flag & LDP_RESOURCE_CFG_MEANBPS) {
+    r->mean_rate = resource->mean_rate;
+  }
+  if (flag & LDP_RESOURCE_CFG_BURSTSIZE) {
+    r->burst_size = resource->burst_size;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_resource_get_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_resource_get");
+
+  return retval;
+}
+
+/******************* HOP **********************/
+
+mpls_return_enum ldp_cfg_hop_set(mpls_cfg_handle handle, ldp_hop * h,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_hop_list *hop_list = NULL;
+  ldp_hop *hop = NULL;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_hop_set");
+
+  if (!h->hop_list_index && !h->index) {
+    return retval;
+  }
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  ldp_global_find_hop_list_index(global, h->hop_list_index, &hop_list);
+
+  if (!hop_list) {
+    if (flag & LDP_CFG_ADD) {
+      if (!(hop_list = ldp_hop_list_create())) {
+        goto ldp_cfg_hop_set_end;
+      }
+      _ldp_global_add_hop_list(global, hop_list);
+
+      h->hop_list_index = hop_list->index;
+    } else {
+      goto ldp_cfg_hop_set_end;
+    }
+  }
+
+  ldp_hop_list_find_hop_index(hop_list, h->index, &hop);
+  if (!hop) {
+    if (h->index && (flag & LDP_CFG_ADD)) {
+      if (!(hop = ldp_hop_create())) {
+        goto ldp_cfg_hop_set_end;
+      }
+      hop->index = h->index;
+      ldp_hop_list_add_hop(hop_list, hop);
+    } else {
+      goto ldp_cfg_hop_set_end;
+    }
+  }
+
+  if (flag & LDP_HOP_CFG_PATH_OPTION) {
+    hop->path_option = h->path_option;
+  }
+  if (flag & LDP_HOP_CFG_ADDR) {
+    memcpy(&hop->addr, &h->addr, sizeof(ldp_addr));
+  }
+  if (flag & LDP_HOP_CFG_TYPE) {
+    hop->type = h->type;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_hop_set_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_hop_set");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_hop_test(mpls_cfg_handle handle, ldp_hop * h,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_hop_list *hop_list = NULL;
+  ldp_hop *hop = NULL;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_hop_test");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  if (flag & LDP_CFG_ADD) {
+    retval = MPLS_SUCCESS;
+    goto ldp_cfg_hop_test_end;
+  }
+
+  ldp_global_find_hop_list_index(global, h->hop_list_index, &hop_list);
+
+  if (!hop_list) {
+    goto ldp_cfg_hop_test_end;
+  }
+
+  ldp_hop_list_find_hop_index(hop_list, h->index, &hop);
+  if (!hop) {
+    goto ldp_cfg_hop_test_end;
+  }
+
+  if (ldp_hop_in_use(hop) == MPLS_BOOL_TRUE) {
+    goto ldp_cfg_hop_test_end;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_hop_test_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_hop_test");
+
+  return retval;
+}
+
+mpls_return_enum ldp_cfg_hop_get(mpls_cfg_handle handle, ldp_hop * h,
+  uint32_t flag)
+{
+  ldp_global *global = (ldp_global *) handle;
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_hop_list *hop_list = NULL;
+  ldp_hop *hop = NULL;
+
+  MPLS_ASSERT(global !=NULL);
+
+  LDP_ENTER(global->user_data, "ldp_cfg_hop_get");
+
+  mpls_lock_get(global->global_lock); /* LOCK */
+
+  ldp_global_find_hop_list_index(global, h->hop_list_index, &hop_list);
+
+  if (!hop_list) {
+    goto ldp_cfg_hop_get_end;
+  }
+
+  ldp_hop_list_find_hop_index(hop_list, h->index, &hop);
+  if (!hop) {
+    goto ldp_cfg_hop_get_end;
+  }
+
+  if (flag & LDP_HOP_CFG_PATH_OPTION) {
+    h->path_option = hop->path_option;
+  }
+  if (flag & LDP_HOP_CFG_ADDR) {
+    memcpy(&h->addr, &hop->addr, sizeof(ldp_addr));
+  }
+  if (flag & LDP_HOP_CFG_TYPE) {
+    h->type = hop->type;
+  }
+  retval = MPLS_SUCCESS;
+
+ldp_cfg_hop_get_end:
+
+  mpls_lock_release(global->global_lock); /* UNLOCK */
+
+  LDP_EXIT(global->user_data, "ldp_cfg_hop_get");
+
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_cfg.h quagga-mpls/ldpd/ldp_cfg.h
--- quagga-0.99.10/ldpd/ldp_cfg.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_cfg.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,341 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_CFG_H_
+#define _LDP_CFG_H_
+
+#include "ldp_struct.h"
+#include "ldp_entity.h"
+#include "ldp_session.h"
+
+#define LDP_CFG_ADD				0x00000001
+#define LDP_CFG_DEL				0x10000000
+
+#define LDP_GLOBAL_CFG_ADMIN_STATE		0x00000002
+#define LDP_GLOBAL_CFG_CONTROL_MODE		0x00000004
+#define LDP_GLOBAL_CFG_RETENTION_MODE		0x00000008
+#define LDP_GLOBAL_CFG_REPAIR_MODE		0x00000010
+#define LDP_GLOBAL_CFG_PROPOGATE_RELEASE	0x00000020
+#define LDP_GLOBAL_CFG_LABEL_MERGE		0x00000040
+#define LDP_GLOBAL_CFG_LOOP_DETECTION_MODE	0x00000080
+#define LDP_GLOBAL_CFG_TTLLESS_DOMAIN		0x00000100
+#define LDP_GLOBAL_CFG_LOCAL_TCP_PORT		0x00000200
+#define LDP_GLOBAL_CFG_LOCAL_UDP_PORT		0x00000400
+#define LDP_GLOBAL_CFG_LSR_IDENTIFIER		0x00000800
+#define LDP_GLOBAL_CFG_TRANS_ADDR		0x00001000
+#define LDP_GLOBAL_CFG_KEEPALIVE_TIMER		0x00002000
+#define LDP_GLOBAL_CFG_KEEPALIVE_INTERVAL	0x00004000
+#define LDP_GLOBAL_CFG_HELLOTIME_TIMER		0x00008000
+#define LDP_GLOBAL_CFG_HELLOTIME_INTERVAL	0x00010000
+#define LDP_GLOBAL_CFG_LSR_HANDLE		0x00020000
+
+#define LDP_GLOBAL_CFG_WHEN_DOWN	(LDP_GLOBAL_CFG_LOCAL_TCP_PORT|\
+					LDP_GLOBAL_CFG_LOCAL_UDP_PORT|\
+					LDP_GLOBAL_CFG_LSR_IDENTIFIER)
+
+#define LDP_ENTITY_CFG_TRANS_ADDR		0x00000002
+#define LDP_ENTITY_CFG_PROTO_VER		0x00000004
+#define LDP_ENTITY_CFG_REMOTE_TCP		0x00000008
+#define LDP_ENTITY_CFG_REMOTE_UDP		0x00000010
+#define LDP_ENTITY_CFG_MAX_PDU			0x00000020
+#define LDP_ENTITY_CFG_KEEPALIVE_TIMER		0x00000040
+#define LDP_ENTITY_CFG_KEEPALIVE_INTERVAL       0x00000080
+#define LDP_ENTITY_CFG_HELLOTIME_TIMER		0x00000100
+#define LDP_ENTITY_CFG_HELLOTIME_INTERVAL       0x00000200
+#define LDP_ENTITY_CFG_SESSION_SETUP_COUNT      0x00000400
+#define LDP_ENTITY_CFG_SESSION_BACKOFF_TIMER    0x00000800
+#define LDP_ENTITY_CFG_DISTRIBUTION_MODE	0x00001000
+#define LDP_ENTITY_CFG_PATHVECTOR_LIMIT		0x00002000
+#define LDP_ENTITY_CFG_HOPCOUNT_LIMIT		0x00004000
+#define LDP_ENTITY_CFG_REQUEST_TIMER		0x00008000
+#define LDP_ENTITY_CFG_REQUEST_COUNT		0x00010000
+#define LDP_ENTITY_CFG_ADMIN_STATE		0x00020000
+#define LDP_ENTITY_CFG_ADJ_COUNT		0x00040000
+#define LDP_ENTITY_CFG_TYPE			0x00080000
+#define LDP_ENTITY_CFG_SUB_INDEX		0x00100000
+#define LDP_ENTITY_CFG_INHERIT_FLAG		0x00200000
+#define LDP_ENTITY_CFG_MESG_TX			0x00400000
+#define LDP_ENTITY_CFG_MESG_RX			0x00800000
+#define LDP_ENTITY_CFG_ADJ_INDEX		0x01000000
+
+#define LDP_ENTITY_CFG_WHEN_DOWN	(LDP_CFG_DEL|\
+					LDP_ENTITY_CFG_TRANS_ADDR|\
+					LDP_ENTITY_CFG_PROTO_VER|\
+					LDP_ENTITY_CFG_REMOTE_TCP|\
+					LDP_ENTITY_CFG_REMOTE_UDP|\
+					LDP_ENTITY_CFG_DISTRIBUTION_MODE|\
+					LDP_ENTITY_CFG_TYPE|\
+					LDP_ENTITY_CFG_SUB_INDEX)
+
+#define LDP_FEC_CFG_BY_INDEX			0x00000002
+#define LDP_FEC_NEXTHOP_CFG_BY_INDEX		0x00000004
+
+#define LDP_IF_CFG_LABEL_SPACE			0x00000002
+#define LDP_IF_CFG_INDEX			0x00000004
+#define LDP_IF_CFG_ENTITY_INDEX			0x00000008
+#define LDP_IF_CFG_OPER_STATE			0x00000010
+#define LDP_IF_CFG_BY_INDEX			0x00000080
+#define LDP_IF_ADDR_CFG_BY_INDEX		0x00000100
+#define LDP_IF_CFG_HANDLE			0x00000200
+
+#define LDP_IF_CFG_WHEN_DOWN		(LDP_CFG_DEL|\
+					LDP_IF_CFG_LABEL_SPACE|\
+					LDP_IF_CFG_INDEX|\
+					LDP_IF_CFG_ENTITY_INDEX|\
+					LDP_IF_CFG_OPER_STATE|\
+					LDP_IF_CFG_HANDLE)
+
+#define LDP_PEER_CFG_LABEL_SPACE		0x00000002
+#define LDP_PEER_CFG_DEST_ADDR			0x00000004
+#define LDP_PEER_CFG_TARGET_ROLE		0x00000008
+#define LDP_PEER_CFG_ENTITY_INDEX		0x00000010
+#define LDP_PEER_CFG_OPER_STATE			0x00000020
+#define LDP_PEER_CFG_PEER_NAME			0x00000040
+#define LDP_PEER_CFG_LOCAL_SOURCE_ADDR		0x00000080
+
+#define LDP_PEER_CFG_WHEN_DOWN 		(LDP_CFG_DEL|\
+					LDP_PEER_CFG_LABEL_SPACE|\
+					LDP_PEER_CFG_DEST_ADDR|\
+					LDP_PEER_CFG_TARGET_ROLE)
+
+#define LDP_SESSION_CFG_INDEX				0x00000002
+#define LDP_SESSION_CFG_STATE				0x00000004
+#define LDP_SESSION_CFG_MAX_PDU				0x00000008
+#define LDP_SESSION_CFG_KEEPALIVE			0x00000010
+#define LDP_SESSION_CFG_PATH_LIMIT			0x00000020
+#define LDP_SESSION_CFG_DIST_MODE			0x00000040
+#define LDP_SESSION_CFG_LOOP_DETECTION			0x00000080
+#define LDP_SESSION_CFG_REMOTE_MAX_PDU			0x00000100
+#define LDP_SESSION_CFG_REMOTE_KEEPALIVE		0x00000200
+#define LDP_SESSION_CFG_REMOTE_PATH_LIMIT		0x00000400
+#define LDP_SESSION_CFG_REMOTE_DIST_MODE		0x00000800
+#define LDP_SESSION_CFG_REMOTE_LOOP_DETECTION		0x00001000
+#define LDP_SESSION_CFG_REMOTE_ADDR			0x00002000
+#define LDP_SESSION_CFG_REMOTE_PORT			0x00004000
+#define LDP_SESSION_CFG_LABEL_RESOURCE_STATE_LOCAL	0x00008000
+#define LDP_SESSION_CFG_LABEL_RESOURCE_STATE_REMOTE	0x00010000
+#define LDP_SESSION_CFG_ENTITY_INDEX			0x00020000
+#define LDP_SESSION_CFG_ADJ_INDEX			0x00040000
+#define LDP_SESSION_CFG_MESG_TX				0x00080000
+#define LDP_SESSION_CFG_MESG_RX				0x00100000
+#define LDP_SESSION_CFG_OPER_UP				0x00200000
+#define LDP_SESSION_CFG_LOCAL_NAME			0x00400000
+#define LDP_SESSION_CFG_REMOTE_NAME			0x00800000
+
+#define LDP_SESSION_RADDR_CFG_ADDR			0x00000002
+#define LDP_SESSION_RADDR_CFG_INDEX			0x00000004
+
+#define LDP_ATTR_CFG_STATE				0x00000002
+#define LDP_ATTR_CFG_FEC				0x00000004
+#define LDP_ATTR_CFG_LABEL				0x00000008
+#define LDP_ATTR_CFG_HOP_COUNT				0x00000010
+#define LDP_ATTR_CFG_PATH				0x00000020
+#define LDP_ATTR_CFG_SESSION_INDEX			0x00000040
+#define LDP_ATTR_CFG_INLABEL_INDEX			0x00000080
+#define LDP_ATTR_CFG_OUTLABEL_INDEX			0x00000100
+#define LDP_ATTR_CFG_INGRESS				0x00000200
+
+#define LDP_ADJ_CFG_REMOTE_TRADDR			0x00000002
+#define LDP_ADJ_CFG_REMOTE_SRCADDR			0x00000004
+#define LDP_ADJ_CFG_REMOTE_LSRADDR			0x00000008
+#define LDP_ADJ_CFG_REMOTE_CSN				0x00000010
+#define LDP_ADJ_CFG_REMOTE_LABELSPACE			0x00000020
+#define LDP_ADJ_CFG_REMOTE_HELLOTIME			0x00000040
+#define LDP_ADJ_CFG_ENTITY_INDEX			0x00000080
+#define LDP_ADJ_CFG_REMOTE_SESSION_INDEX		0x00000100
+#define LDP_ADJ_CFG_ROLE				0x00000200
+
+#define LDP_INLABEL_CFG_LABELSPACE			0x00000002
+#define LDP_INLABEL_CFG_LABEL				0x00000004
+#define LDP_INLABEL_CFG_OUTLABEL_INDEX			0x00000008
+
+#define LDP_OUTLABEL_CFG_NH_INDEX			0x00000002
+#define LDP_OUTLABEL_CFG_SESSION_INDEX			0x00000004
+#define LDP_OUTLABEL_CFG_LABEL				0x00000008
+#define LDP_OUTLABEL_CFG_MERGE_COUNT			0x00000010
+
+#define LDP_TUNNEL_CFG_INDEX				0x00000002
+#define LDP_TUNNEL_CFG_INSTANCE				0x00000004
+#define LDP_TUNNEL_CFG_INGRESS				0x00000008
+#define LDP_TUNNEL_CFG_EGRESS				0x00000010
+#define LDP_TUNNEL_CFG_NAME				0x00000020
+#define LDP_TUNNEL_CFG_IS_IF				0x00000040
+#define LDP_TUNNEL_CFG_OUTLABEL				0x00000080
+#define LDP_TUNNEL_CFG_SETUP_PRIO			0x00000100
+#define LDP_TUNNEL_CFG_HOLD_PRIO			0x00000200
+#define LDP_TUNNEL_CFG_INSTANCE_PRIO			0x00000400
+#define LDP_TUNNEL_CFG_LOCAL_PROTECT			0x00000800
+#define LDP_TUNNEL_CFG_RESOURCE_INDEX			0x00001000
+#define LDP_TUNNEL_CFG_HOP_LIST_INDEX			0x00002000
+#define LDP_TUNNEL_CFG_ROLE				0x00004000
+#define LDP_TUNNEL_CFG_ADMIN_STATE			0x00008000
+#define LDP_TUNNEL_CFG_FEC				0x00010000
+
+#define LDP_TUNNEL_CFG_WHEN_DOWN		(LDP_CFG_DEL|\
+						LDP_TUNNEL_CFG_OUTLABEL|\
+						LDP_TUNNEL_CFG_RESOURCE_INDEX|\
+						LDP_TUNNEL_CFG_HOP_LIST_INDEX)
+
+#define LDP_RESOURCE_CFG_INDEX				0x00000002
+#define LDP_RESOURCE_CFG_MAXBPS				0x00000004
+#define LDP_RESOURCE_CFG_MEANBPS			0x00000008
+#define LDP_RESOURCE_CFG_BURSTSIZE			0x00000010
+
+#define LDP_RESOURCE_CFG_WHEN_DOWN		(LDP_CFG_DEL|\
+						LDP_RESOURCE_CFG_MAXBPS|\
+						LDP_RESOURCE_CFG_MEANBPS|\
+						LDP_RESOURCE_CFG_BURSTSIZE)
+
+#define LDP_HOP_CFG_INDEX				0x00000002
+#define LDP_HOP_CFG_LIST_INDEX				0x00000004
+#define LDP_HOP_CFG_PATH_OPTION				0x00000008
+#define LDP_HOP_CFG_ADDR				0x00000010
+#define LDP_HOP_CFG_TYPE				0x00000020
+
+#define LDP_HOP_CFG_WHEN_DOWN			(LDP_CFG_DEL|\
+						LDP_HOP_CFG_INDEX|\
+						LDP_HOP_CFG_LIST_INDEX|\
+						LDP_HOP_CFG_ADDR|\
+						LDP_HOP_CFG_TYPE)
+
+extern mpls_cfg_handle ldp_cfg_open(mpls_instance_handle data);
+extern void ldp_cfg_close(mpls_cfg_handle handle);
+
+extern mpls_return_enum ldp_cfg_global_get(mpls_cfg_handle handle,
+  ldp_global * g, uint32_t flag);
+extern mpls_return_enum ldp_cfg_global_set(mpls_cfg_handle handle,
+  ldp_global * g, uint32_t flag);
+extern void ldp_cfg_global_attr(mpls_cfg_handle handle);
+
+extern mpls_return_enum ldp_cfg_entity_get(mpls_cfg_handle handle,
+  ldp_entity * e, uint32_t flag);
+extern mpls_return_enum ldp_cfg_entity_getnext(mpls_cfg_handle handle,
+  ldp_entity * e, uint32_t flag);
+extern mpls_return_enum ldp_cfg_entity_test(mpls_cfg_handle handle,
+  ldp_entity * e, uint32_t flag);
+extern mpls_return_enum ldp_cfg_entity_set(mpls_cfg_handle handle,
+  ldp_entity * e, uint32_t flag);
+extern mpls_return_enum ldp_cfg_entity_adj_getnext(mpls_cfg_handle handle,
+  ldp_entity * e);
+
+extern mpls_return_enum ldp_cfg_attr_get(mpls_cfg_handle handle, ldp_attr * a,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_attr_getnext(mpls_cfg_handle handle,
+  ldp_attr * a, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_peer_get(mpls_cfg_handle handle, ldp_peer * p,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_peer_getnext(mpls_cfg_handle handle,
+  ldp_peer * p, uint32_t flag);
+extern mpls_return_enum ldp_cfg_peer_test(mpls_cfg_handle handle, ldp_peer * p,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_peer_set(mpls_cfg_handle handle, ldp_peer * p,
+  uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_fec_get(mpls_cfg_handle handle, mpls_fec * p,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_fec_getnext(mpls_cfg_handle handle,
+  mpls_fec * p, uint32_t flag);
+extern mpls_return_enum ldp_cfg_fec_test(mpls_cfg_handle handle, mpls_fec * p,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_fec_set(mpls_cfg_handle handle, mpls_fec * p,
+  uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_fec_nexthop_get(mpls_cfg_handle handle,
+  mpls_fec * p, mpls_nexthop *nh, uint32_t flag);
+extern mpls_return_enum ldp_cfg_fec_nexthop_getnext(mpls_cfg_handle handle,
+  mpls_fec * p, mpls_nexthop *nh, uint32_t flag);
+extern mpls_return_enum ldp_cfg_fec_nexthop_test(mpls_cfg_handle handle,
+  mpls_fec * p, mpls_nexthop *nh, uint32_t flag);
+extern mpls_return_enum ldp_cfg_fec_nexthop_set(mpls_cfg_handle handle,
+  mpls_fec * p, mpls_nexthop *nh, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_addr_get(mpls_cfg_handle handle, ldp_addr * a,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_addr_getnext(mpls_cfg_handle handle,
+  ldp_addr * a, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_if_get(mpls_cfg_handle handle, ldp_if * i,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_if_getnext(mpls_cfg_handle handle, ldp_if * i,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_if_test(mpls_cfg_handle handle, ldp_if * i,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_if_set(mpls_cfg_handle handle, ldp_if * i,
+  uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_if_addr_get(mpls_cfg_handle handle, ldp_if * i,
+  ldp_addr * a, uint32_t flag);
+extern mpls_return_enum ldp_cfg_if_addr_getnext(mpls_cfg_handle handle,
+  ldp_if * i, ldp_addr *a, uint32_t flag);
+extern mpls_return_enum ldp_cfg_if_addr_set(mpls_cfg_handle handle, ldp_if *i,
+  ldp_addr * a, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_labelrange_get(mpls_cfg_handle handle,
+  mpls_range * r, uint32_t flag);
+extern mpls_return_enum ldp_cfg_labelrange_test(mpls_cfg_handle handle,
+  mpls_range * r, uint32_t flag);
+extern mpls_return_enum ldp_cfg_labelrange_set(mpls_cfg_handle handle,
+  mpls_range * r, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_adj_get(mpls_cfg_handle handle, ldp_adj * a,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_adj_getnext(mpls_cfg_handle handle, ldp_adj * a,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_adj_entity_getnext(mpls_cfg_handle handle,
+  ldp_adj * a);
+
+extern mpls_return_enum ldp_cfg_session_get(mpls_cfg_handle handle,
+  ldp_session * s, uint32_t flag);
+extern mpls_return_enum ldp_cfg_session_getnext(mpls_cfg_handle handle,
+  ldp_session * s, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_session_raddr_get(mpls_cfg_handle handle,
+  ldp_session * s, ldp_addr * a, uint32_t flag);
+extern mpls_return_enum ldp_cfg_session_raddr_getnext(mpls_cfg_handle handle,
+  ldp_session * s, ldp_addr * a, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_inlabel_get(mpls_cfg_handle handle,
+  ldp_inlabel * i, uint32_t flag);
+mpls_return_enum ldp_cfg_inlabel_getnext(mpls_cfg_handle handle,
+  ldp_inlabel * i, uint32_t flag);
+extern mpls_return_enum ldp_cfg_outlabel_get(mpls_cfg_handle handle,
+  ldp_outlabel * o, uint32_t flag);
+mpls_return_enum ldp_cfg_outlabel_getnext(mpls_cfg_handle handle,
+  ldp_outlabel * o, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_range_set(mpls_cfg_handle handle,
+  mpls_range * r, uint32_t flag);
+extern mpls_return_enum ldp_cfg_range_test(mpls_cfg_handle handle,
+  mpls_range * r, uint32_t flag);
+extern mpls_return_enum ldp_cfg_range_get(mpls_cfg_handle handle,
+  mpls_range * r, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_tunnel_set(mpls_cfg_handle handle,
+  ldp_tunnel * r, uint32_t flag);
+extern mpls_return_enum ldp_cfg_tunnel_test(mpls_cfg_handle handle,
+  ldp_tunnel * r, uint32_t flag);
+extern mpls_return_enum ldp_cfg_tunnel_get(mpls_cfg_handle handle,
+  ldp_tunnel * r, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_resource_set(mpls_cfg_handle handle,
+  ldp_resource * r, uint32_t flag);
+extern mpls_return_enum ldp_cfg_resource_test(mpls_cfg_handle handle,
+  ldp_resource * r, uint32_t flag);
+extern mpls_return_enum ldp_cfg_resource_get(mpls_cfg_handle handle,
+  ldp_resource * r, uint32_t flag);
+
+extern mpls_return_enum ldp_cfg_hop_set(mpls_cfg_handle handle, ldp_hop * r,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_hop_test(mpls_cfg_handle handle, ldp_hop * r,
+  uint32_t flag);
+extern mpls_return_enum ldp_cfg_hop_get(mpls_cfg_handle handle, ldp_hop * r,
+  uint32_t flag);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldpd.conf.sample quagga-mpls/ldpd/ldpd.conf.sample
--- quagga-0.99.10/ldpd/ldpd.conf.sample	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldpd.conf.sample	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,17 @@
+!
+! Zebra configuration saved from vty
+!   2002/03/23 17:07:30
+!
+hostname uml-1
+password root
+enable password root
+!
+mpls ip
+!
+interface lo
+!
+interface eth0
+ mpls ip
+!
+line vty
+!
diff -Naur quagga-0.99.10/ldpd/ldp_defaults.h quagga-mpls/ldpd/ldp_defaults.h
--- quagga-0.99.10/ldpd/ldp_defaults.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_defaults.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,55 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_DEFAULTS_H_
+#define _LDP_DEFAULTS_H_
+
+#define LDP_GLOBAL_DEF_CONTROL_MODE		LDP_CONTROL_ORDERED
+#define LDP_GLOBAL_DEF_RETENTION_MODE		LDP_RETENTION_LIBERAL
+#define LDP_GLOBAL_DEF_REPAIR_MODE		LDP_REPAIR_GLOBAL
+#define LDP_GLOBAL_DEF_PROPOGATE_RELEASE	MPLS_BOOL_TRUE
+#define LDP_GLOBAL_DEF_LABEL_MERGE		MPLS_BOOL_TRUE
+#define LDP_GLOBAL_DEF_LOOP_DETECTION_MODE	LDP_LOOP_NONE
+#define LDP_GLOBAL_DEF_TTLLESS_DOMAIN		MPLS_BOOL_FALSE
+#define LDP_GLOBAL_DEF_LOCAL_TCP_PORT		646
+#define LDP_GLOBAL_DEF_LOCAL_UDP_PORT		646
+#define LDP_GLOBAL_DEF_SEND_ADDR_MSG		MPLS_BOOL_TRUE
+#define LDP_GLOBAL_DEF_BACKOFF_STEP		15
+#define LDP_GLOBAL_DEF_SEND_LSRID_MAPPING	MPLS_BOOL_TRUE
+#define LDP_GLOBAL_DEF_NO_ROUTE_RETRY_TIME	10
+
+#define LDP_ENTITY_DEF_TRANS_ADDR		0
+#define LDP_ENTITY_DEF_PROTO_VER		1
+#define LDP_ENTITY_DEF_REMOTE_TCP		646
+#define LDP_ENTITY_DEF_REMOTE_UDP		646
+#define LDP_ENTITY_DEF_MAX_PDU			4096
+#define LDP_ENTITY_DEF_KEEPALIVE_TIMER		45
+#define LDP_ENTITY_DEF_KEEPALIVE_INTERVAL	15
+#define LDP_ENTITY_DEF_HELLOTIME_TIMER		15
+#define LDP_ENTITY_DEF_HELLOTIME_INTERVAL	5
+#define LDP_ENTITY_DEF_SESSIONSETUP_COUNT	LDP_INFINIT
+#define LDP_ENTITY_DEF_SESSION_BACKOFF_TIMER	10
+#define LDP_ENTITY_DEF_DISTRIBUTION_MODE	LDP_DISTRIBUTION_UNSOLICITED
+#define LDP_ENTITY_DEF_PATHVECTOR_LIMIT		10
+#define LDP_ENTITY_DEF_HOPCOUNT_LIMIT		30
+#define LDP_ENTITY_DEF_REQUEST_TIMER		30
+#define LDP_ENTITY_DEF_REQUEST_COUNT		LDP_INFINIT
+#define LDP_ENTITY_DEF_REQUIRE_HOPCOUNT		MPLS_BOOL_FALSE
+
+/* you can infer this from REQUEST_COUNT */
+#define LDP_ENTITY_DEF_REQUEST_RETRY		MPLS_BOOL_TRUE
+#define LDP_ENTITY_DEF_INHERIT_FLAG	LDP_ENTITY_CFG_TRANS_ADDR|\
+					LDP_ENTITY_CFG_KEEPALIVE_TIMER|\
+					LDP_ENTITY_CFG_KEEPALIVE_INTERVAL|\
+					LDP_ENTITY_CFG_HELLOTIME_TIMER|\
+					LDP_ENTITY_CFG_HELLOTIME_INTERVAL
+
+#define LDP_REQUEST_CHUNK			2
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_entity.c quagga-mpls/ldpd/ldp_entity.c
--- quagga-0.99.10/ldpd/ldp_entity.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_entity.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,328 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdlib.h>
+#include <string.h>
+#include <netinet/in.h>
+#include <stdio.h>
+#include "ldp_struct.h"
+#include "mpls_assert.h"
+#include "ldp_session.h"
+#include "ldp_global.h"
+#include "ldp_entity.h"
+#include "ldp_hello.h"
+#include "ldp_peer.h"
+#include "ldp_adj.h"
+#include "ldp_if.h"
+#include "ldp_inet_addr.h"
+#include "ldp_mesg.h"
+#include "ldp_cfg.h"
+
+#include "mpls_mm_impl.h"
+#include "mpls_timer_impl.h"
+#include "mpls_socket_impl.h"
+#include "mpls_trace_impl.h"
+
+static uint32_t _ldp_entity_next_index = 1;
+
+void ldp_entity_set_defaults(ldp_entity *e) {
+    memset(e, 0, sizeof(ldp_entity));
+
+    e->entity_type = LDP_UNKNOWN;
+
+    if (LDP_ENTITY_DEF_TRANS_ADDR != 0) {
+      e->transport_address.type = MPLS_FAMILY_IPV4;
+      e->transport_address.u.ipv4 = LDP_ENTITY_DEF_TRANS_ADDR;
+    }
+    e->protocol_version = LDP_ENTITY_DEF_PROTO_VER;
+    e->remote_tcp_port = LDP_ENTITY_DEF_REMOTE_TCP;
+    e->remote_udp_port = LDP_ENTITY_DEF_REMOTE_UDP;
+    e->max_pdu = LDP_ENTITY_DEF_MAX_PDU;
+    e->keepalive_timer = LDP_ENTITY_DEF_KEEPALIVE_TIMER;
+    e->keepalive_interval = LDP_ENTITY_DEF_KEEPALIVE_INTERVAL;
+    e->hellotime_timer = LDP_ENTITY_DEF_HELLOTIME_TIMER;
+    e->hellotime_interval = LDP_ENTITY_DEF_HELLOTIME_INTERVAL;
+    e->session_setup_count = LDP_ENTITY_DEF_SESSIONSETUP_COUNT;
+    e->session_backoff_timer = LDP_ENTITY_DEF_SESSION_BACKOFF_TIMER;
+    e->label_distribution_mode = LDP_ENTITY_DEF_DISTRIBUTION_MODE;
+    e->path_vector_limit = LDP_ENTITY_DEF_PATHVECTOR_LIMIT;
+    e->hop_count_limit = LDP_ENTITY_DEF_HOPCOUNT_LIMIT;
+    e->label_request_timer = LDP_ENTITY_DEF_REQUEST_TIMER;
+    e->label_request_count = LDP_ENTITY_DEF_REQUEST_COUNT;
+    e->inherit_flag = LDP_ENTITY_DEF_INHERIT_FLAG;
+    e->admin_state = MPLS_ADMIN_DISABLE;
+    e->remote_in_ttl_less_domain = MPLS_BOOL_FALSE;
+    e->request_retry = LDP_ENTITY_DEF_REQUEST_RETRY;
+}
+
+ldp_entity *ldp_entity_create()
+{
+  ldp_entity *e = (ldp_entity *) mpls_malloc(sizeof(ldp_entity));
+
+  if (e) {
+    memset(e, 0, sizeof(ldp_entity));
+    ldp_entity_set_defaults(e);
+
+    MPLS_REFCNT_INIT(e, 0);
+    MPLS_LIST_ELEM_INIT(e, _global);
+    MPLS_LIST_INIT(&e->adj_root, ldp_adj);
+
+    e->index = _ldp_entity_get_next_index();
+  }
+  return e;
+}
+
+void ldp_entity_delete(ldp_entity * e)
+{
+  LDP_PRINT(NULL, "entity delete %p", e);
+  MPLS_REFCNT_ASSERT(e, 0);
+  mpls_free(e);
+}
+
+int ldp_entity_label_space(ldp_entity * e)
+{
+  if (e) {
+    switch (e->entity_type) {
+      case LDP_DIRECT:
+        return e->p.iff->label_space;
+      case LDP_INDIRECT:
+        return e->p.peer->label_space;
+      default:
+        MPLS_ASSERT(0);
+    }
+  }
+  return -1;
+}
+
+mpls_bool ldp_entity_is_active(ldp_entity * e)
+{
+  if (e && e->admin_state == MPLS_ADMIN_ENABLE)
+    return MPLS_BOOL_TRUE;
+
+  return MPLS_BOOL_FALSE;
+}
+
+mpls_bool ldp_entity_is_ready(ldp_entity * e)
+{
+  if (e) {
+    switch (e->entity_type) {
+      case LDP_DIRECT:
+        if (e->p.iff)
+          return MPLS_BOOL_TRUE;
+        break;
+      case LDP_INDIRECT:
+        if (e->p.peer)
+          return MPLS_BOOL_TRUE;
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+  }
+  return MPLS_BOOL_FALSE;
+}
+
+mpls_return_enum ldp_entity_startup(ldp_global * g, ldp_entity * e)
+{
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(g && e && e->p.iff);
+
+  LDP_ENTER(g->user_data, "ldp_entity_startup");
+
+  if (g->admin_state == MPLS_ADMIN_ENABLE) {
+    if (e->inherit_flag & LDP_ENTITY_CFG_TRANS_ADDR) {
+      memcpy(&e->transport_address, &g->transport_address,
+	sizeof(mpls_inet_addr));
+    }
+    if (e->inherit_flag & LDP_ENTITY_CFG_KEEPALIVE_TIMER) {
+      e->keepalive_timer = g->keepalive_timer;
+    }
+    if (e->inherit_flag & LDP_ENTITY_CFG_KEEPALIVE_INTERVAL) {
+      e->keepalive_interval = g->keepalive_interval;
+    }
+    if (e->inherit_flag & LDP_ENTITY_CFG_HELLOTIME_TIMER) {
+      e->hellotime_timer = g->hellotime_timer;
+    }
+    if (e->inherit_flag & LDP_ENTITY_CFG_HELLOTIME_INTERVAL) {
+      e->hellotime_interval = g->hellotime_interval;
+    }
+
+    e->loop_detection_mode = g->loop_detection_mode;
+
+    switch (e->entity_type) {
+      case LDP_DIRECT:
+        retval = ldp_if_startup(g, e->p.iff);
+        break;
+      case LDP_INDIRECT:
+        retval = ldp_peer_startup(g, e->p.peer);
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+  } else {
+    LDP_PRINT(g->user_data, "ldp_entity_startup: global not enabled\n");
+    retval = MPLS_SUCCESS;
+  }
+
+  if (retval == MPLS_SUCCESS) {
+    e->admin_state = MPLS_ADMIN_ENABLE;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_entity_startup");
+
+  return retval;
+}
+
+mpls_return_enum ldp_entity_shutdown(ldp_global * g, ldp_entity * e,
+  int global_shutdown)
+{
+  ldp_adj *adj = NULL;
+
+  MPLS_ASSERT(g && e);
+
+  LDP_ENTER(g->user_data, "ldp_entity_shutdown");
+
+  if (g->admin_state == MPLS_ADMIN_ENABLE) {
+    if (!global_shutdown) {
+      e->admin_state = MPLS_ADMIN_DISABLE;
+    }
+
+    switch (e->entity_type) {
+      case LDP_DIRECT:
+        if (ldp_if_shutdown(g, e->p.iff) != MPLS_SUCCESS) {
+          LDP_PRINT(g->user_data,
+		"ldp_entity_shutdown: shut down of if failed\n");
+        }
+        break;
+      case LDP_INDIRECT:
+        if (ldp_peer_shutdown(g, e->p.peer) != MPLS_SUCCESS) {
+          LDP_PRINT(g->user_data,
+		"ldp_entity_shutdown: shut down of peer failed\n");
+        }
+        break;
+      default:
+        MPLS_ASSERT(0);
+    }
+
+    while ((adj = MPLS_LIST_HEAD(&e->adj_root))) {
+      /* ldp_adj_shutdown() does a ldp_entity_del_adj(e,adj) */
+      ldp_adj_shutdown(g, adj);
+    }
+  } else {
+    LDP_PRINT(g->user_data, "ldp_entity_shutdown: global not enabled\n");
+    e->admin_state = MPLS_ADMIN_DISABLE;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_entity_shutdown");
+
+  return MPLS_SUCCESS;
+}
+
+uint32_t _ldp_entity_get_next_index()
+{
+  uint32_t retval = _ldp_entity_next_index;
+
+  _ldp_entity_next_index++;
+  if (retval > _ldp_entity_next_index) {
+    _ldp_entity_next_index = 1;
+  }
+  return retval;
+}
+
+void ldp_entity_add_if(ldp_entity * e, ldp_if * i)
+{
+  MPLS_ASSERT(e && i && e->entity_type == LDP_UNKNOWN);
+
+  e->entity_type = LDP_DIRECT;
+  MPLS_REFCNT_HOLD(i);
+  e->p.iff = i;
+  e->sub_index = i->index;
+  _ldp_if_add_entity(i, e);
+}
+
+void ldp_entity_del_if(ldp_global * g, ldp_entity * e)
+{
+  MPLS_ASSERT(e && e->entity_type == LDP_DIRECT && e->p.iff);
+  _ldp_if_del_entity(e->p.iff);
+  MPLS_REFCNT_RELEASE2(g, e->p.iff, ldp_if_delete);
+  e->p.iff = NULL;
+  e->entity_type = LDP_UNKNOWN;
+  e->sub_index = 0;
+}
+
+void ldp_entity_add_peer(ldp_entity * e, ldp_peer * p)
+{
+  MPLS_ASSERT(e && e->entity_type == LDP_UNKNOWN);
+
+  e->entity_type = LDP_INDIRECT;
+  MPLS_REFCNT_HOLD(p);
+  e->p.peer = p;
+  e->sub_index = p->index;
+  _ldp_peer_add_entity(p, e);
+}
+
+void ldp_entity_del_peer(ldp_entity * e)
+{
+  MPLS_ASSERT(e && e->entity_type == LDP_INDIRECT && e->p.peer);
+  _ldp_peer_del_entity(e->p.peer);
+  MPLS_REFCNT_RELEASE(e->p.peer, ldp_peer_delete);
+  e->p.peer = NULL;
+  e->entity_type = LDP_UNKNOWN;
+  e->sub_index = 0;
+}
+
+void ldp_entity_add_adj(ldp_entity * e, ldp_adj * a)
+{
+  ldp_adj *ap = NULL;
+
+  MPLS_ASSERT(e && a);
+  MPLS_REFCNT_HOLD(a);
+
+  _ldp_adj_add_entity(a, e);
+  ap = MPLS_LIST_HEAD(&e->adj_root);
+  while (ap) {
+    if (ap->index > a->index) {
+      MPLS_LIST_INSERT_BEFORE(&e->adj_root, ap, a, _entity);
+      return;
+    }
+    ap = MPLS_LIST_NEXT(&e->adj_root, ap, _entity);
+  }
+  MPLS_LIST_ADD_TAIL(&e->adj_root, a, _entity, ldp_adj);
+}
+
+void ldp_entity_del_adj(ldp_entity * e, ldp_adj * a)
+{
+  MPLS_ASSERT(e && a);
+  MPLS_LIST_REMOVE(&e->adj_root, a, _entity);
+  _ldp_adj_del_entity(a, e);
+  MPLS_REFCNT_RELEASE(a, ldp_adj_delete);
+}
+
+ldp_adj *ldp_entity_find_adj(ldp_entity * e, ldp_mesg * msg)
+{
+  ldp_adj *a = NULL;
+  mpls_inet_addr lsraddr;
+  int labelspace;
+
+  MPLS_ASSERT(e);
+
+  ldp_mesg_hdr_get_labelspace(msg, &labelspace);
+  ldp_mesg_hdr_get_lsraddr(msg, &lsraddr);
+
+  a = MPLS_LIST_HEAD(&e->adj_root);
+  while (a != NULL) {
+    if (a->remote_label_space == labelspace &&
+      (!mpls_inet_addr_compare(&lsraddr, &a->remote_lsr_address))) {
+      return a;
+    }
+    a = MPLS_LIST_NEXT(&e->adj_root, a, _entity);
+  }
+
+  return NULL;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_entity.h quagga-mpls/ldpd/ldp_entity.h
--- quagga-0.99.10/ldpd/ldp_entity.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_entity.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,45 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_ENTITY_H_
+#define _LDP_ENTITY_H_
+
+#include "ldp_struct.h"
+
+extern void ldp_entity_set_defaults(ldp_entity *e);
+extern ldp_entity *ldp_entity_create();
+extern void ldp_entity_delete(ldp_entity * e);
+extern mpls_bool ldp_entity_is_active(ldp_entity * e);
+extern mpls_bool ldp_entity_is_ready(ldp_entity * e);
+extern int ldp_entity_label_space(ldp_entity * e);
+extern ldp_mesg *ldp_entity_get_message(ldp_entity * e);
+
+extern mpls_return_enum ldp_entity_startup(ldp_global * g, ldp_entity * e);
+extern mpls_return_enum ldp_entity_shutdown(ldp_global * g, ldp_entity * e,
+  int flag);
+
+extern void ldp_entity_register(ldp_global * g, ldp_entity * e);
+extern void ldp_entity_unregister(ldp_global * g, ldp_entity * e);
+
+extern void ldp_entity_add_if(ldp_entity * e, ldp_if * i);
+extern void ldp_entity_del_if(ldp_global * g, ldp_entity * e);
+
+extern void ldp_entity_add_peer(ldp_entity * e, ldp_peer * p);
+extern void ldp_entity_del_peer(ldp_entity * e);
+
+extern void ldp_entity_add_adj(ldp_entity * e, ldp_adj * a);
+extern void ldp_entity_del_adj(ldp_entity * e, ldp_adj * a);
+extern ldp_adj *ldp_entity_find_adj(ldp_entity * e, ldp_mesg * msg);
+
+extern mpls_return_enum ldp_entity_set_admin_state(ldp_global * g,
+  ldp_entity * e, mpls_admin_state_enum state);
+
+extern uint32_t _ldp_entity_get_next_index();
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_fec.c quagga-mpls/ldpd/ldp_fec.c
--- quagga-0.99.10/ldpd/ldp_fec.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_fec.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,608 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_fec.h"
+#include "ldp_if.h"
+#include "ldp_attr.h"
+#include "ldp_addr.h"
+#include "ldp_nexthop.h"
+#include "ldp_session.h"
+#include "ldp_inlabel.h"
+#include "ldp_outlabel.h"
+#include "ldp_global.h"
+#include "ldp_label_mapping.h"
+#include "ldp_label_request.h"
+#include "ldp_label_abort.h"
+#include "ldp_label_rel_with.h"
+#include "mpls_assert.h"
+#include "mpls_compare.h"
+#include "mpls_mm_impl.h"
+#include "mpls_tree_impl.h"
+#include "mpls_policy_impl.h"
+#include "mpls_trace_impl.h"
+
+#if MPLS_USE_LSR
+#include "lsr_cfg.h"
+#else
+#include "mpls_mpls_impl.h"
+#endif
+
+static uint32_t _ldp_fec_next_index = 1;
+
+static mpls_return_enum ldp_fec_insert(ldp_global *g, ldp_fec * fec)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+  uint32_t key;
+  uint8_t len;
+
+  MPLS_ASSERT(g && fec);
+  LDP_ENTER(g->user_data, "ldp_fec_insert");
+
+  switch(fec->info.type) {
+    case MPLS_FEC_PREFIX:
+      key = fec->info.u.prefix.network.u.ipv4;
+      len = fec->info.u.prefix.length;
+      break;
+    case MPLS_FEC_HOST:
+      key = fec->info.u.host.u.ipv4;
+      len = 32;
+      break;
+    case MPLS_FEC_L2CC:
+      /* they had better insert it into the global list */
+      LDP_EXIT(g->user_data, "ldp_fec_insert: l2cc");
+      return MPLS_SUCCESS;
+    default:
+      MPLS_ASSERT(0);
+  }
+
+  LDP_PRINT(g->user_data, "ldp_fec_insert: 0x%08x/%d\n", key, len);
+
+  if (mpls_tree_insert(g->fec_tree, key, len, (void *)fec) != MPLS_SUCCESS) {
+    LDP_PRINT(g->user_data, "ldp_fec_insert: error adding fec\n");
+    retval = MPLS_FATAL;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_fec_insert");
+  return retval;
+}
+
+static void ldp_fec_remove(ldp_global *g, mpls_fec *fec)
+{
+  ldp_fec *f = NULL;
+  uint32_t key;
+  uint8_t len;
+
+  MPLS_ASSERT(g && fec);
+  LDP_ENTER(g->user_data, "ldp_fec_remove");
+
+  switch(fec->type) {
+    case MPLS_FEC_PREFIX:
+      key = fec->u.prefix.network.u.ipv4;
+      len = fec->u.prefix.length;
+      break;
+    case MPLS_FEC_HOST:
+      key = fec->u.host.u.ipv4;
+      len = 32;
+      break;
+    case MPLS_FEC_L2CC:
+      /* they had better remove it from the global list */
+      LDP_EXIT(g->user_data, "ldp_fec_remove");
+      return;
+    default:
+      MPLS_ASSERT(0);
+  }
+
+  LDP_PRINT(g->user_data, "ldp_fec_remove: 0x%08x/%d\n", key, len);
+  mpls_tree_remove(g->fec_tree, key, len, (void **)&f);
+
+  MPLS_ASSERT(f);
+
+  LDP_EXIT(g->user_data, "ldp_fec_remove");
+}
+
+static uint32_t _ldp_fec_get_next_index()
+{
+  uint32_t retval = _ldp_fec_next_index;
+
+  _ldp_fec_next_index++;
+  if (retval > _ldp_fec_next_index) {
+    _ldp_fec_next_index = 1;
+  }
+  return retval;
+}
+
+ldp_fec *ldp_fec_create(ldp_global *g, mpls_fec *f)
+{
+  ldp_fec *fec = (ldp_fec *) mpls_malloc(sizeof(ldp_fec));
+
+  if (fec != NULL) {
+    memset(fec, 0, sizeof(ldp_fec));
+    /*
+     * note: this is init to 1 for a reason!
+     * We're placing it in the global list, so this is our refcnt
+     * when this refcnt gets to zero, it will be removed from the
+     * global list and deleted
+     */
+    /*
+     * TESTING: jleu 6/7/2004, since I want the FEC to be cleaned up
+     * when it no longer has a nexthop, addr, or label, the only things that
+     * should increment the ref are those (nh, addr, label etc), not global
+     * nor inserting into the tree.  I also added this comment in
+     * _ldp_global_add_fec()
+    MPLS_REFCNT_INIT(fec, 1);
+     */
+    MPLS_REFCNT_INIT(fec, 0);
+    MPLS_LIST_ELEM_INIT(fec, _global);
+    MPLS_LIST_ELEM_INIT(fec, _inlabel);
+    MPLS_LIST_ELEM_INIT(fec, _outlabel);
+    MPLS_LIST_ELEM_INIT(fec, _fec);
+    MPLS_LIST_INIT(&fec->nh_root, ldp_nexthop);
+    MPLS_LIST_INIT(&fec->fs_root_us, ldp_fs);
+    MPLS_LIST_INIT(&fec->fs_root_ds, ldp_fs);
+    fec->index = _ldp_fec_get_next_index();
+    fec->is_route = MPLS_BOOL_FALSE;
+    mpls_fec2ldp_fec(f,fec);
+
+    _ldp_global_add_fec(g, fec);
+    ldp_fec_insert(g, fec);
+  }
+  return fec;
+}
+
+void ldp_fec_delete(ldp_global *g, ldp_fec * fec)
+{
+  LDP_PRINT(g->user_data, "fec delete: %08x/%d",
+    fec->info.u.prefix.network.u.ipv4, fec->info.u.prefix.length);
+  ldp_fec_remove(g, &fec->info);
+  _ldp_global_del_fec(g, fec);
+  mpls_free(fec);
+}
+
+ldp_fec *ldp_fec_find(ldp_global *g, mpls_fec *fec)
+{
+  ldp_fec *f = NULL;
+  uint32_t key;
+  uint8_t len;
+
+  switch(fec->type) {
+    case MPLS_FEC_PREFIX:
+      key = fec->u.prefix.network.u.ipv4;
+      len = fec->u.prefix.length;
+      break;
+    case MPLS_FEC_HOST:
+      key = fec->u.host.u.ipv4;
+      len = 32;
+      break;
+    case MPLS_FEC_L2CC:
+      if (ldp_global_find_fec(g, fec, &f) == MPLS_SUCCESS) {
+	return f;
+      }
+      return NULL;
+    default:
+      MPLS_ASSERT(0);
+  }
+
+  LDP_PRINT(g->user_data, "ldp_fec_find: 0x%08x/%d\n", key, len);
+  if (mpls_tree_get(g->fec_tree, key, len, (void **)&f) != MPLS_SUCCESS) {
+    return NULL;
+  }
+  return f;
+}
+
+ldp_fec *ldp_fec_find2(ldp_global *g, mpls_fec *fec)
+{
+  ldp_fec *f = NULL;
+  f = ldp_fec_find(g, fec);
+  if (!f) {
+    f = ldp_fec_create(g, fec);
+  }
+  return f;
+}
+
+ldp_nexthop *ldp_fec_nexthop_find(ldp_fec *f, mpls_nexthop *n)
+{
+  ldp_nexthop *nh = NULL;
+
+  MPLS_ASSERT(f && n);
+
+  nh = MPLS_LIST_HEAD(&f->nh_root);
+  while (nh) {
+    if (!mpls_nexthop_compare(&nh->info, n)) {
+      return nh;
+    }
+    nh = MPLS_LIST_NEXT(&f->nh_root, nh, _fec);
+  }
+
+  return NULL;
+}
+
+mpls_return_enum ldp_fec_find_nexthop_index(ldp_fec *f, int index,
+  ldp_nexthop **n)
+{
+  ldp_nexthop *nh = NULL;
+
+  MPLS_ASSERT(f);
+
+  if (index > 0) {
+
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    nh = MPLS_LIST_TAIL(&f->nh_root);
+    if (!nh || nh->index < index) {
+      *n = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    nh = MPLS_LIST_HEAD(&f->nh_root);
+    do {
+      if (nh->index == index) {
+        *n = nh;
+        return MPLS_SUCCESS;
+      }
+    } while((nh = MPLS_LIST_NEXT(&f->nh_root, nh, _fec)));
+  }
+  *n = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_fec_add_nexthop(ldp_global *g, ldp_fec * f,
+  ldp_nexthop * nh)
+{
+  MPLS_ASSERT(f && nh);
+
+  LDP_ENTER(g->user_data, "ldp_fec_add_nexthop");
+
+  MPLS_REFCNT_HOLD(nh);
+  MPLS_LIST_ADD_HEAD(&f->nh_root, nh, _fec, ldp_nexthop);
+
+  ldp_nexthop_add_fec(nh, f);
+
+  LDP_EXIT(g->user_data, "ldp_fec_add_nexthop: success");
+  return MPLS_SUCCESS;
+
+ldp_fec_add_nexthop_error:
+
+  ldp_fec_del_nexthop(g, f, nh);
+  LDP_EXIT(g->user_data, "ldp_fec_add_nexthop: fail");
+  return MPLS_FATAL;
+}
+
+void ldp_fec_del_nexthop(ldp_global *g, ldp_fec * f, ldp_nexthop *nh)
+{
+  MPLS_ASSERT(f && nh);
+
+  MPLS_LIST_REMOVE(&f->nh_root, nh, _fec);
+  ldp_nexthop_del_fec(g, nh);
+  MPLS_REFCNT_RELEASE2(g, nh, ldp_nexthop_delete);
+}
+
+mpls_return_enum ldp_fec_process_add(ldp_global * g, ldp_fec * f,
+  ldp_nexthop *nh, ldp_session *nh_session)
+{
+  ldp_session *peer = NULL;
+  ldp_attr *ds_attr = NULL;
+  ldp_attr *us_attr = NULL;
+  mpls_bool egress;
+  ldp_outlabel *out;
+
+  LDP_ENTER(g->user_data, "ldp_fec_process_add");
+
+  /*
+   * find the info about the next hop for this FEC
+   */
+  if (!nh_session) {
+    nh_session = ldp_get_next_hop_session_for_fec2(f, nh);
+  }
+
+  if (nh_session) {
+    /* check if we've received and retainted a label from nh_session for f */
+    ds_attr = ldp_attr_find_downstream_state2(g, nh_session, f,
+      LDP_LSP_STATE_MAP_RECV);
+    if (ds_attr && !ds_attr->outlabel) {
+      /* if so, and we have not installed that label, install it now */
+      out = ldp_outlabel_create_complete(g, nh_session, ds_attr, nh);
+      if (!out) {
+        return MPLS_FAILURE;
+      }
+      ds_attr->outlabel = out;
+    }
+  }
+
+  /* are we willing to egress for this FEC */
+  egress = mpls_policy_egress_check(g->user_data, &f->info, &nh->info);
+
+  /*
+   * for every peer except the nh hop peer, check to see if we need to
+   * send a mapping
+   */
+  peer = MPLS_LIST_HEAD(&g->session);
+  while (peer != NULL) {        /* FEC.1 */
+    if ((peer->state != LDP_STATE_OPERATIONAL) ||
+      (nh_session && peer->index == nh_session->index)) {
+      goto next_peer;
+    }
+    /* have I already sent a mapping for FEC to peer */
+    if ((us_attr = ldp_attr_find_upstream_state2(g, peer, f,
+      LDP_LSP_STATE_MAP_SENT))) {
+      /* yep, don't send another */
+      if (ds_attr) {
+	/* we need to XC the label we sent with the one we already have */
+        if (ldp_inlabel_add_outlabel(g, us_attr->inlabel,
+          ds_attr->outlabel) != MPLS_SUCCESS) {
+	  return MPLS_FAILURE;
+	}
+      }
+      goto next_peer;
+    }
+
+    /* we need to send a label */
+    if (peer->oper_distribution_mode == LDP_DISTRIBUTION_UNSOLICITED) {
+      if (g->lsp_control_mode == LDP_CONTROL_INDEPENDENT) {
+	/* if we have received a pending request, give that as input to
+	 * ldp_label_mapping_with_xc */
+        us_attr =
+          ldp_attr_find_upstream_state2(g, peer, f, LDP_LSP_STATE_REQ_RECV);
+
+        /* FEC.1.DUI3,4 */
+        if (ldp_label_mapping_with_xc(g, peer, f, &us_attr, ds_attr) !=
+          MPLS_SUCCESS) {
+          if (us_attr->in_tree) {
+            ldp_attr_remove_complete(g, us_attr, MPLS_BOOL_FALSE);
+          }
+          goto next_peer;
+        }
+      } else {
+        /*
+         *LDP_CONTROL_ORDERED
+         */
+
+        if (ds_attr || (egress == MPLS_BOOL_TRUE)) { /* FEC.1.DUO2 */
+          /* FEC.1.DUO3-4 */
+
+	  /*
+	   * ldp_label_mapping_with_xc will create a us_attr if
+	   * one does not exist yet
+	   */
+          if (ldp_label_mapping_with_xc(g, peer, f, &us_attr, ds_attr) !=
+            MPLS_SUCCESS) {
+            return MPLS_FAILURE;
+          }
+        }
+      }
+    }
+  next_peer:
+    peer = MPLS_LIST_NEXT(&g->session, peer, _global);
+  }
+
+  if (ds_attr) {                /* FEC.2 */
+    /* does this send an updated mapping? */
+    if (ldp_label_mapping_process(g, nh_session, NULL, NULL, ds_attr, f) ==
+      MPLS_FAILURE) { /* FEC.5 */
+      return MPLS_FAILURE;
+    }
+    return MPLS_SUCCESS;
+  }
+
+  /*
+   * LDP_DISTRIBUTION_ONDEMAND
+   */
+  /* FEC.3 */
+  if (nh_session &&
+      nh_session->oper_distribution_mode == LDP_DISTRIBUTION_ONDEMAND) {
+    /* assume we're always "request when needed" */
+    ds_attr = NULL;
+    if (ldp_label_request_for_xc(g, nh_session, &f->info, NULL, &ds_attr) ==
+      MPLS_FAILURE) { /* FEC.4 */
+      return MPLS_FAILURE;
+    }
+  }
+
+  LDP_EXIT(g->user_data, "ldp_fec_process_add");
+
+  return MPLS_SUCCESS;           /* FEC.6 */
+}
+
+mpls_return_enum ldp_fec_process_change(ldp_global * g, ldp_fec * f,
+  ldp_nexthop *nh, ldp_nexthop *nh_old, ldp_session *nh_session_old) {
+  ldp_session *peer = NULL;
+  ldp_attr *us_attr = NULL;
+  ldp_attr *ds_attr = NULL;
+  ldp_session *nh_session = NULL;
+
+  LDP_ENTER(g->user_data,
+    "ldp_fec_process_change: fec %p nh %p nh_old %p nh_session_old %p",
+    f, nh, nh_old, nh_session_old);
+
+  if (!nh_session_old) {
+    nh_session_old = ldp_session_for_nexthop(nh_old);
+  }
+
+  /*
+   * NH 1-5 decide if we need to release an existing mapping
+   */
+  ds_attr = ldp_attr_find_downstream_state2(g, nh_session_old, f,
+      LDP_LSP_STATE_MAP_RECV);
+  if (!ds_attr) {               /* NH.1 */
+    goto Detect_Change_Fec_Next_Hop_6;
+  }
+
+  if (ds_attr->ingress == MPLS_BOOL_TRUE) {
+
+#if MPLS_USE_LSR
+    lsr_ftn ftn;
+    ftn.outsegment_index = ds_attr->outlabel->info.handle;
+    memcpy(&ftn.fec, &f->info, sizeof(mpls_fec));
+    lsr_cfg_ftn_set2(g->lsr_handle, &ftn, LSR_CFG_DEL);
+#else
+    mpls_mpls_fec2out_del(g->mpls_handle, &f->info, &ds_attr->outlabel->info);
+#endif
+    ds_attr->ingress = MPLS_BOOL_FALSE;
+    ds_attr->outlabel->merge_count--;
+  }
+
+  if (g->label_retention_mode == LDP_RETENTION_LIBERAL) { /* NH.3 */
+    ldp_attr *us_temp;
+    us_attr = MPLS_LIST_HEAD(&ds_attr->us_attr_root);
+    while (us_attr) {
+      /* need to walk the list in such a way as not to
+       * "pull the rug out from under me self"
+       */
+      us_temp = MPLS_LIST_NEXT(&ds_attr->us_attr_root, us_attr, _ds_attr);
+      if (us_attr->state == LDP_LSP_STATE_MAP_SENT) {
+        ldp_inlabel_del_outlabel(g, us_attr->inlabel);  /* NH.2 */
+        ldp_attr_del_us2ds(g, us_attr, ds_attr);
+      }
+      us_attr = us_temp;
+    }
+    goto Detect_Change_Fec_Next_Hop_6;
+  }
+
+  ldp_label_release_send(g, nh_session_old, ds_attr, LDP_NOTIF_NONE); /* NH.4 */
+  ldp_attr_remove_complete(g, ds_attr, MPLS_BOOL_FALSE); /* NH.2,5 */
+
+Detect_Change_Fec_Next_Hop_6:
+
+  /*
+   * NH 6-9 decides is we need to send a label request abort
+   */
+  ds_attr = ldp_attr_find_downstream_state2(g, nh_session_old, f,
+    LDP_LSP_STATE_REQ_SENT);
+  if (ds_attr) {               /* NH.6 */
+    if (g->label_retention_mode != LDP_RETENTION_CONSERVATIVE) { /* NH.7 */
+      /* NH.8,9 */
+      if (ldp_label_abort_send(g, nh_session_old, ds_attr) != MPLS_SUCCESS) {
+        return MPLS_FAILURE;
+      }
+    }
+  }
+
+  /*
+   * NH 10-12 decides if we can use a mapping from our database
+   */
+  if ((!nh) || (!(nh_session = ldp_get_next_hop_session_for_fec2(f,nh)))) {
+    goto Detect_Change_Fec_Next_Hop_16;
+  }
+  
+  ds_attr = ldp_attr_find_downstream_state2(g, nh_session, f,
+    LDP_LSP_STATE_MAP_RECV);
+  if (!ds_attr) {               /* NH.11 */
+    goto Detect_Change_Fec_Next_Hop_13;
+  }
+
+  if (ldp_label_mapping_process(g, nh_session, NULL, NULL, ds_attr, f) !=
+    MPLS_SUCCESS) { /* NH.12 */
+    return MPLS_FAILURE;
+  }
+  goto Detect_Change_Fec_Next_Hop_20;
+
+Detect_Change_Fec_Next_Hop_13:
+
+  /*
+   * NH 13-15 decides if we need to make a label request
+   */
+  if (nh_session->oper_distribution_mode == LDP_DISTRIBUTION_ONDEMAND &&
+    g->label_retention_mode == LDP_RETENTION_CONSERVATIVE) {
+    /* NH.14-15 */
+    if (ldp_label_request_for_xc(g, nh_session, &f->info, NULL, &ds_attr) !=
+        MPLS_SUCCESS) {
+      return MPLS_FAILURE;
+    }
+  }
+  goto Detect_Change_Fec_Next_Hop_20;
+
+Detect_Change_Fec_Next_Hop_16:
+
+  peer = MPLS_LIST_HEAD(&g->session);
+  while (peer) {
+    if (peer->state == LDP_STATE_OPERATIONAL) {
+      us_attr = ldp_attr_find_upstream_state2(g, peer, f,
+	LDP_LSP_STATE_MAP_SENT);
+      if (us_attr) {	/* NH.17 */
+	mpls_return_enum retval;
+	MPLS_REFCNT_HOLD(us_attr);
+        ldp_attr_remove_complete(g, us_attr, MPLS_BOOL_FALSE);
+        retval = ldp_label_withdraw_send(g, peer, us_attr, LDP_NOTIF_NONE);
+	MPLS_REFCNT_RELEASE2(g, us_attr, ldp_attr_delete);
+        if (retval != MPLS_SUCCESS) { /* NH.18 */
+	  /*
+	   * I think it is best to exit out immediatly with an error
+	   * and let the caller do something about it, the only real
+	   * option is a global reset of LDP
+	   */
+          return MPLS_FAILURE;
+        }
+      }
+    }
+    peer = MPLS_LIST_NEXT(&g->session, peer, _global);
+  }
+
+Detect_Change_Fec_Next_Hop_20:
+
+  LDP_EXIT(g->user_data, "ldp_fec_process_change");
+
+  return MPLS_SUCCESS;
+}
+
+void mpls_fec2ldp_fec(mpls_fec * a, ldp_fec * b)
+{
+  memcpy(&b->info, a, sizeof(mpls_fec));
+}
+
+void mpls_fec2fec_tlv(mpls_fec * lf, mplsLdpFecTlv_t * tlv, int i)
+{
+  tlv->fecElArray[i].addressEl.addressFam = 1;
+
+  switch (lf->type) {
+    case MPLS_FEC_PREFIX:
+      tlv->fecElArray[i].addressEl.type = MPLS_PREFIX_FEC;
+      tlv->fecElArray[i].addressEl.preLen = lf->u.prefix.length;
+      tlv->fecElArray[i].addressEl.address = lf->u.prefix.network.u.ipv4;
+      tlv->fecElemTypes[i] = MPLS_PREFIX_FEC;
+      break;
+    case MPLS_FEC_HOST:
+      tlv->fecElArray[i].addressEl.type = MPLS_HOSTADR_FEC;
+      tlv->fecElArray[i].addressEl.preLen = MPLS_IPv4LEN;
+      tlv->fecElArray[i].addressEl.address = lf->u.host.u.ipv4;
+      tlv->fecElemTypes[i] = MPLS_HOSTADR_FEC;
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+}
+
+void fec_tlv2mpls_fec(mplsLdpFecTlv_t * tlv, int i, mpls_fec * lf) {
+  switch (tlv->fecElemTypes[i]) {
+    case MPLS_PREFIX_FEC:
+      lf->type = MPLS_FEC_PREFIX;
+      lf->u.prefix.length = tlv->fecElArray[i].addressEl.preLen;
+      lf->u.prefix.network.u.ipv4 = tlv->fecElArray[i].addressEl.address;
+      lf->u.prefix.network.type = MPLS_FAMILY_IPV4;
+      break;
+    case MPLS_HOSTADR_FEC:
+      lf->type = MPLS_FEC_HOST;
+      lf->u.host.u.ipv4 = tlv->fecElArray[i].addressEl.address;
+      lf->u.host.type = MPLS_FAMILY_IPV4;
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+}
+
+mpls_bool ldp_fec_empty(ldp_fec *fec)
+{
+  if (MPLS_LIST_EMPTY(&fec->fs_root_us) && 
+      MPLS_LIST_EMPTY(&fec->nh_root) &&
+      MPLS_LIST_EMPTY(&fec->fs_root_ds)) {
+    return MPLS_BOOL_TRUE;
+  }
+  return MPLS_BOOL_FALSE;
+}
+
diff -Naur quagga-0.99.10/ldpd/ldp_fec.h quagga-mpls/ldpd/ldp_fec.h
--- quagga-0.99.10/ldpd/ldp_fec.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_fec.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,34 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_FEC_H_
+#define _LDP_FEC_H_
+
+extern ldp_fec *ldp_fec_create(ldp_global *g, mpls_fec *fec);
+extern void ldp_fec_delete(ldp_global *g, ldp_fec * fec);
+extern ldp_fec *ldp_fec_find(ldp_global *g, mpls_fec *fec);
+extern ldp_fec *ldp_fec_find2(ldp_global *g, mpls_fec *fec);
+extern ldp_nexthop *ldp_fec_nexthop_find(ldp_fec *f, mpls_nexthop *n);
+extern mpls_return_enum ldp_fec_find_nexthop_index(ldp_fec *f, int index,
+  ldp_nexthop **n);
+extern mpls_return_enum ldp_fec_add_nexthop(ldp_global *g, ldp_fec *f,
+  ldp_nexthop *n);
+extern void ldp_fec_del_nexthop(ldp_global *g, ldp_fec *f, ldp_nexthop *n);
+
+extern mpls_return_enum ldp_fec_process_add(ldp_global * g, ldp_fec * f,
+  ldp_nexthop *nh, ldp_session *nh_session);
+extern mpls_return_enum ldp_fec_process_change(ldp_global * g, ldp_fec * f,
+  ldp_nexthop *nh, ldp_nexthop *nh_old, ldp_session * nh_session_old);
+
+extern mpls_bool ldp_fec_empty(ldp_fec *fec);
+extern void mpls_fec2ldp_fec(mpls_fec * a, ldp_fec * b);
+extern void fec_tlv2mpls_fec(mplsLdpFecTlv_t * tlv, int num, mpls_fec * lf);
+extern void mpls_fec2fec_tlv(mpls_fec * lf, mplsLdpFecTlv_t * tlv, int num);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_global.c quagga-mpls/ldpd/ldp_global.c
--- quagga-0.99.10/ldpd/ldp_global.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_global.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,1291 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdlib.h>
+#include <netinet/in.h>
+#include "ldp_struct.h"
+#include "ldp_inet_addr.h"
+#include "ldp_session.h"
+#include "ldp_entity.h"
+#include "ldp_global.h"
+#include "ldp_nexthop.h"
+#include "ldp_outlabel.h"
+#include "ldp_inlabel.h"
+#include "ldp_hello.h"
+#include "ldp_peer.h"
+#include "ldp_attr.h"
+#include "ldp_addr.h"
+#include "ldp_adj.h"
+#include "ldp_fec.h"
+#include "ldp_if.h"
+#include "ldp_label_mapping.h"
+#include "ldp_tunnel.h"
+#include "ldp_resource.h"
+#include "ldp_hop_list.h"
+
+#include "mpls_compare.h"
+
+#include "mpls_socket_impl.h"
+#include "mpls_timer_impl.h"
+#include "mpls_ifmgr_impl.h"
+#include "mpls_tree_impl.h"
+#include "mpls_lock_impl.h"
+#include "mpls_fib_impl.h"
+#include "mpls_policy_impl.h"
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+
+#if MPLS_USE_LSR
+#include "lsr_cfg.h"
+#else
+#include "mpls_mpls_impl.h"
+#endif
+
+ldp_global *ldp_global_create(mpls_instance_handle data)
+{
+  ldp_global *g = (ldp_global *) mpls_malloc(sizeof(ldp_global));
+
+  if (g) {
+    memset(g, 0, sizeof(ldp_global));
+
+    LDP_ENTER(g->user_data, "ldp_global_create");
+
+    g->global_lock = mpls_lock_create("_ldp_global_lock_");
+    mpls_lock_get(g->global_lock);
+
+    MPLS_LIST_INIT(&g->hop_list, ldp_hop_list);
+    MPLS_LIST_INIT(&g->outlabel, ldp_outlabel);
+    MPLS_LIST_INIT(&g->resource, ldp_resource);
+    MPLS_LIST_INIT(&g->inlabel, ldp_inlabel);
+    MPLS_LIST_INIT(&g->session, ldp_session);
+    MPLS_LIST_INIT(&g->nexthop, ldp_nexthop);
+    MPLS_LIST_INIT(&g->tunnel, ldp_tunnel);
+    MPLS_LIST_INIT(&g->entity, ldp_entity);
+    MPLS_LIST_INIT(&g->addr, ldp_addr);
+    MPLS_LIST_INIT(&g->attr, ldp_attr);
+    MPLS_LIST_INIT(&g->peer, ldp_peer);
+    MPLS_LIST_INIT(&g->fec, ldp_fec);
+    MPLS_LIST_INIT(&g->adj, ldp_adj);
+    MPLS_LIST_INIT(&g->iff, ldp_if);
+
+    g->message_identifier = 1;
+    g->configuration_sequence_number = 1;
+    g->lsp_control_mode = LDP_GLOBAL_DEF_CONTROL_MODE;
+    g->label_retention_mode = LDP_GLOBAL_DEF_RETENTION_MODE;
+    g->lsp_repair_mode = LDP_GLOBAL_DEF_REPAIR_MODE;
+    g->propagate_release = LDP_GLOBAL_DEF_PROPOGATE_RELEASE;
+    g->label_merge = LDP_GLOBAL_DEF_LABEL_MERGE;
+    g->loop_detection_mode = LDP_GLOBAL_DEF_LOOP_DETECTION_MODE;
+    g->ttl_less_domain = LDP_GLOBAL_DEF_TTLLESS_DOMAIN;
+    g->local_tcp_port = LDP_GLOBAL_DEF_LOCAL_TCP_PORT;
+    g->local_udp_port = LDP_GLOBAL_DEF_LOCAL_UDP_PORT;
+    g->send_address_messages = LDP_GLOBAL_DEF_SEND_ADDR_MSG;
+    g->backoff_step = LDP_GLOBAL_DEF_BACKOFF_STEP;
+    g->send_lsrid_mapping = LDP_GLOBAL_DEF_SEND_LSRID_MAPPING;
+    g->no_route_to_peer_time = LDP_GLOBAL_DEF_NO_ROUTE_RETRY_TIME;
+
+    g->keepalive_timer = LDP_ENTITY_DEF_KEEPALIVE_TIMER;
+    g->keepalive_interval = LDP_ENTITY_DEF_KEEPALIVE_INTERVAL;
+    g->hellotime_timer = LDP_ENTITY_DEF_HELLOTIME_TIMER;
+    g->hellotime_interval = LDP_ENTITY_DEF_HELLOTIME_INTERVAL;
+
+    g->admin_state = MPLS_ADMIN_DISABLE;
+    g->user_data = data;
+
+    g->addr_tree = mpls_tree_create(32);
+    g->fec_tree = mpls_tree_create(32);
+
+    mpls_lock_release(g->global_lock);
+
+    LDP_EXIT(g->user_data, "ldp_global_create");
+  }
+
+  return g;
+}
+
+mpls_return_enum ldp_global_startup(ldp_global * g)
+{
+  ldp_entity *e = NULL;
+  mpls_dest dest;
+
+  MPLS_ASSERT(g != NULL);
+
+  LDP_ENTER(g->user_data, "ldp_global_startup");
+
+  if (g->lsr_identifier.type == MPLS_FAMILY_NONE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+      "ldp_global_startup: invalid LSRID\n");
+    goto ldp_global_startup_cleanup;
+  }
+
+  g->timer_handle = mpls_timer_open(g->user_data);
+  if (mpls_timer_mgr_handle_verify(g->timer_handle) == MPLS_BOOL_FALSE) {
+    goto ldp_global_startup_cleanup;
+  }
+
+  g->socket_handle = mpls_socket_mgr_open(g->user_data);
+  if (mpls_socket_mgr_handle_verify(g->socket_handle) == MPLS_BOOL_FALSE) {
+    goto ldp_global_startup_cleanup;
+  }
+
+  g->ifmgr_handle = mpls_ifmgr_open(g->user_data, g);
+  if (mpls_ifmgr_handle_verify(g->ifmgr_handle) == MPLS_BOOL_FALSE) {
+    goto ldp_global_startup_cleanup;
+  }
+
+  g->fib_handle = mpls_fib_open(g->user_data, g);
+  if (mpls_fib_handle_verify(g->fib_handle) == MPLS_BOOL_FALSE) {
+    goto ldp_global_startup_cleanup;
+  }
+
+#if MPLS_USE_LSR
+  if (!g->lsr_handle) {
+    goto ldp_global_startup_cleanup;
+  }
+#else
+  g->mpls_handle = mpls_mpls_open(g->user_data);
+  if (mpls_mpls_handle_verify(g->mpls_handle) == MPLS_BOOL_FALSE) {
+    goto ldp_global_startup_cleanup;
+  }
+#endif
+
+  g->hello_socket = mpls_socket_create_udp(g->socket_handle);
+  if (mpls_socket_handle_verify(g->socket_handle, g->hello_socket) == MPLS_BOOL_FALSE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_global_startup: error creating UDP socket\n");
+    goto ldp_global_startup_cleanup;
+  }
+
+  dest.addr.type = MPLS_FAMILY_IPV4;
+  dest.port = g->local_udp_port;
+  dest.addr.u.ipv4 = INADDR_ANY;
+  // dest.addr.u.ipv4 = INADDR_ALLRTRS_GROUP;
+
+  if (mpls_socket_bind(g->socket_handle, g->hello_socket, &dest) == MPLS_FAILURE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_global_startup: error binding UDP socket\n");
+    goto ldp_global_startup_cleanup;
+  }
+
+  if (mpls_socket_options(g->socket_handle, g->hello_socket,
+      MPLS_SOCKOP_NONBLOCK | MPLS_SOCKOP_REUSE) == MPLS_FAILURE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_global_startup: error setting UDP socket options\n");
+    goto ldp_global_startup_cleanup;
+  }
+  if (mpls_socket_multicast_options(g->socket_handle, g->hello_socket, 1, 0) ==
+    MPLS_FAILURE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_global_startup: error setting UDP socket multicast options\n");
+    goto ldp_global_startup_cleanup;
+  }
+  mpls_socket_readlist_add(g->socket_handle, g->hello_socket, 0, MPLS_SOCKET_UDP_DATA);
+
+  g->listen_socket = mpls_socket_create_tcp(g->socket_handle);
+  if (mpls_socket_handle_verify(g->socket_handle, g->listen_socket) == MPLS_BOOL_FALSE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_global_startup: error creating TCP socket\n");
+    goto ldp_global_startup_cleanup;
+  }
+  if (mpls_socket_options(g->socket_handle, g->listen_socket,
+      MPLS_SOCKOP_NONBLOCK | MPLS_SOCKOP_REUSE) == MPLS_FAILURE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_global_startup: error setting TCP socket options\n");
+    goto ldp_global_startup_cleanup;
+  }
+
+  dest.addr.type = MPLS_FAMILY_IPV4;
+  dest.port = g->local_tcp_port;
+  dest.addr.u.ipv4 = INADDR_ANY;
+
+  if (mpls_socket_bind(g->socket_handle, g->listen_socket, &dest) == MPLS_FAILURE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_global_startup: error binding TCP socket\n");
+    goto ldp_global_startup_cleanup;
+  }
+
+  if (mpls_socket_tcp_listen(g->socket_handle, g->listen_socket, 15) ==
+    MPLS_FAILURE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_global_startup: error setting listen buffer for TCP socket\n");
+    goto ldp_global_startup_cleanup;
+  }
+
+  mpls_socket_readlist_add(g->socket_handle, g->listen_socket, 0,
+    MPLS_SOCKET_TCP_LISTEN);
+
+  g->admin_state = MPLS_ADMIN_ENABLE;
+
+  e = MPLS_LIST_HEAD(&g->entity);
+  while (e != NULL) {
+    ldp_entity_startup(g, e);
+    e = MPLS_LIST_NEXT(&g->entity, e, _global);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_global_startup");
+  return MPLS_SUCCESS;
+
+ldp_global_startup_cleanup:
+  ldp_global_shutdown(g);
+  mpls_socket_close(g->socket_handle, g->hello_socket);
+  mpls_socket_close(g->socket_handle, g->listen_socket);
+  g->hello_socket = 0;
+  g->listen_socket = 0;
+
+  LDP_EXIT(g->user_data, "ldp_global_startup-error");
+
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_shutdown(ldp_global * g)
+{
+  ldp_entity *e = NULL;
+  ldp_nexthop *n;
+  ldp_fec *f;
+  ldp_addr *a;
+  ldp_if *i;
+
+  MPLS_ASSERT(g);
+
+  LDP_ENTER(g->user_data, "ldp_global_shutdown");
+
+  e = MPLS_LIST_HEAD(&g->entity);
+  while (e != NULL) {
+    ldp_entity_shutdown(g, e, 1);
+    e = MPLS_LIST_NEXT(&g->entity, e, _global);
+  }
+
+  g->admin_state = MPLS_ADMIN_DISABLE;
+
+  mpls_socket_readlist_del(g->socket_handle, g->hello_socket);
+  mpls_socket_close(g->socket_handle, g->hello_socket);
+
+  mpls_socket_readlist_del(g->socket_handle, g->listen_socket);
+  mpls_socket_close(g->socket_handle, g->listen_socket);
+
+  mpls_lock_release(g->global_lock);
+  mpls_timer_close(g->timer_handle);
+  mpls_lock_get(g->global_lock);
+
+  mpls_socket_mgr_close(g->socket_handle);
+  mpls_ifmgr_close(g->ifmgr_handle);
+  mpls_fib_close(g->fib_handle);
+
+#if MPLS_USE_LSR
+#else
+  mpls_mpls_close(g->mpls_handle);
+#endif
+
+  LDP_EXIT(g->user_data, "ldp_global_shutdown");
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_global_delete(ldp_global * g)
+{
+  ldp_fec *fp;
+  ldp_fec *nfp;
+  ldp_if *ifp;
+  ldp_if *nifp;
+  ldp_addr *ap;
+  ldp_addr *nap;
+  ldp_nexthop *nhp;
+  ldp_nexthop *nnhp;
+  ldp_attr *atp;
+  ldp_attr *natp;
+  ldp_inlabel *inp;
+  ldp_inlabel *ninp;
+  ldp_outlabel *outp;
+  ldp_outlabel *noutp;
+  ldp_entity *ep;
+  ldp_entity *nep;
+
+  if (g) {
+    /* clean up the entities that were configured, sessions and adj should
+     * already have been cleaned up when the entity was shutdown
+     */
+    ep = MPLS_LIST_HEAD(&g->entity);
+    while (ep != NULL) {
+      nep = MPLS_LIST_NEXT(&g->entity, ep, _global);
+      switch (ep->entity_type) {
+        case LDP_DIRECT:
+          ldp_entity_del_if(g,ep);
+          break;
+        case LDP_INDIRECT:
+          ldp_entity_del_peer(ep);
+          break;
+        default:
+          MPLS_ASSERT(0);
+      }
+      _ldp_global_del_entity(g, ep);
+      ep = nep;
+    }
+
+    /* need to properly purge FECs/nexthops/interfaces/addresses */
+
+    fp = MPLS_LIST_HEAD(&g->fec);
+    while (fp != NULL) {
+      nfp = MPLS_LIST_NEXT(&g->fec, fp, _global);
+
+      nhp = MPLS_LIST_HEAD(&fp->nh_root);
+      while (nhp) {
+        nnhp = MPLS_LIST_NEXT(&fp->nh_root, nhp, _fec);
+	ldp_fec_del_nexthop(g, fp, nhp);
+        nhp = nnhp;
+      }
+      MPLS_REFCNT_RELEASE2(g, fp, ldp_fec_delete);
+
+      fp = nfp;
+    }
+
+    ifp = MPLS_LIST_HEAD(&g->iff);
+    while (ifp != NULL) {
+      nifp = MPLS_LIST_NEXT(&g->iff, ifp, _global);
+
+      ap = MPLS_LIST_HEAD(&ifp->addr_root);
+      while (ap != NULL) {
+        nap = MPLS_LIST_NEXT(&ifp->addr_root, ap, _if);
+	ldp_if_del_addr(g, ifp, ap);
+	ap = nap;
+      }
+      MPLS_REFCNT_RELEASE2(g, ifp, ldp_if_delete);
+
+      ifp = nifp;
+    }
+
+    nhp = MPLS_LIST_HEAD(&g->nexthop);
+    while (nhp != NULL) {
+      LDP_PRINT(g->user_data,"Left over NH: %p type %d ref %d",
+        nhp, nhp->info.type, nhp->_refcnt);
+      switch(nhp->info.type) {
+        case MPLS_NH_IP:
+          LDP_PRINT(g->user_data,"    IP %08x addr %p",
+	    nhp->info.ip.u.ipv4, nhp->addr);
+          break;
+        case MPLS_NH_IF:
+          LDP_PRINT(g->user_data,"    IF %s handle %p",
+	    nhp->info.if_handle->name, nhp->iff);
+          break;
+        case MPLS_NH_OUTSEGMENT:
+          LDP_PRINT(g->user_data,"    OS %p", nhp->outlabel);
+          break;
+        default:
+          LDP_PRINT(g->user_data,"    EMPTY");
+          break;
+      }
+      nnhp = MPLS_LIST_NEXT(&g->nexthop, nhp, _global);
+//      _ldp_global_del_nexthop(g, nhp);
+      nhp = nnhp;
+    }
+
+    ap = MPLS_LIST_HEAD(&g->addr);
+    while (ap != NULL) {
+      LDP_PRINT(g->user_data, "Left over ADDR: %p address %08x",
+	ap, ap->address.u.ipv4);
+      nap = MPLS_LIST_NEXT(&g->addr, ap, _global);
+//      _ldp_global_del_addr(g, ap);
+      ap = nap;
+    }
+
+    atp = MPLS_LIST_HEAD(&g->attr);
+    while (atp != NULL) {
+      LDP_PRINT(g->user_data, "Left over ATTR: %p %d", atp, atp->_refcnt);
+      natp = MPLS_LIST_NEXT(&g->attr, atp, _global);
+//      _ldp_global_del_attr(g, atp);
+      atp = natp;
+    }
+
+    inp = MPLS_LIST_HEAD(&g->inlabel);
+    while (inp != NULL) {
+      LDP_PRINT(g->user_data,"Left over INLABEL: %p %d", inp, inp->_refcnt);
+      ninp = MPLS_LIST_NEXT(&g->inlabel, inp, _global);
+      inp = ninp;
+    }
+
+    outp = MPLS_LIST_HEAD(&g->outlabel);
+    while (outp != NULL) {
+      LDP_PRINT(g->user_data, "Left over OUTLABEL: %p %d", outp, outp->_refcnt);
+      noutp = MPLS_LIST_NEXT(&g->outlabel, outp, _global);
+      outp = noutp;
+    }
+
+    mpls_tree_delete(g->addr_tree);
+    mpls_tree_delete(g->fec_tree);
+
+    mpls_lock_delete(g->global_lock);
+    LDP_PRINT(g->user_data, "global delete");
+    mpls_free(g);
+  }
+  return MPLS_SUCCESS;
+}
+
+void _ldp_global_add_attr(ldp_global * g, ldp_attr * a)
+{
+  ldp_attr *ap = NULL;
+
+  MPLS_ASSERT(g && a);
+  ap = MPLS_LIST_HEAD(&g->attr);
+  while (ap != NULL) {
+    if (ap->index > a->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->attr, ap, a, _global);
+      return;
+    }
+    ap = MPLS_LIST_NEXT(&g->attr, ap, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->attr, a, _global, ldp_attr);
+}
+
+void _ldp_global_del_attr(ldp_global * g, ldp_attr * a)
+{
+  MPLS_ASSERT(g && a);
+  MPLS_LIST_REMOVE(&g->attr, a, _global);
+}
+
+void _ldp_global_add_peer(ldp_global * g, ldp_peer * p)
+{
+  ldp_peer *pp = NULL;
+
+  MPLS_ASSERT(g && p);
+  MPLS_REFCNT_HOLD(p);
+  pp = MPLS_LIST_HEAD(&g->peer);
+  while (pp != NULL) {
+    if (pp->index > p->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->peer, pp, p, _global);
+      return;
+    }
+    pp = MPLS_LIST_NEXT(&g->peer, pp, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->peer, p, _global, ldp_peer);
+}
+
+void _ldp_global_del_peer(ldp_global * g, ldp_peer * p)
+{
+  MPLS_ASSERT(g && p);
+  MPLS_LIST_REMOVE(&g->peer, p, _global);
+  MPLS_REFCNT_RELEASE(p, ldp_peer_delete);
+}
+
+/*
+ * _ldp_global_add_if/del_if and _ldp_global_add_addr/del_addr are
+ * not the same as the rest of the global_add/del functions.  They
+ * do not hold refcnts, they are used as part of the create and delete
+ * process of these structures
+ */
+
+void _ldp_global_add_if(ldp_global * g, ldp_if * i)
+{
+  ldp_if *ip = NULL;
+
+  MPLS_ASSERT(g && i);
+  ip = MPLS_LIST_HEAD(&g->iff);
+  while (ip != NULL) {
+    if (ip->index > i->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->iff, ip, i, _global);
+      return;
+    }
+    ip = MPLS_LIST_NEXT(&g->iff, ip, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->iff, i, _global, ldp_if);
+}
+
+void _ldp_global_del_if(ldp_global * g, ldp_if * i)
+{
+  MPLS_ASSERT(g && i);
+  MPLS_LIST_REMOVE(&g->iff, i, _global);
+}
+
+void _ldp_global_add_addr(ldp_global * g, ldp_addr * a)
+{
+  ldp_addr *ap = NULL;
+
+  MPLS_ASSERT(g && a);
+  ap = MPLS_LIST_HEAD(&g->addr);
+  while (ap != NULL) {
+    if (ap->index > a->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->addr, ap, a, _global);
+      return;
+    }
+    ap = MPLS_LIST_NEXT(&g->addr, ap, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->addr, a, _global, ldp_addr);
+}
+
+void _ldp_global_del_addr(ldp_global * g, ldp_addr * a)
+{
+  MPLS_ASSERT(g && a);
+  MPLS_LIST_REMOVE(&g->addr, a, _global);
+}
+
+void _ldp_global_add_adj(ldp_global * g, ldp_adj * a)
+{
+  ldp_adj *ap = NULL;
+
+  MPLS_ASSERT(g && a);
+  MPLS_REFCNT_HOLD(a);
+  ap = MPLS_LIST_HEAD(&g->adj);
+  while (ap != NULL) {
+    if (ap->index > a->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->adj, ap, a, _global);
+      return;
+    }
+    ap = MPLS_LIST_NEXT(&g->adj, ap, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->adj, a, _global, ldp_adj);
+}
+
+void _ldp_global_del_adj(ldp_global * g, ldp_adj * a)
+{
+  MPLS_ASSERT(g && a);
+  MPLS_LIST_REMOVE(&g->adj, a, _global);
+  MPLS_REFCNT_RELEASE(a, ldp_adj_delete);
+}
+
+void _ldp_global_add_entity(ldp_global * g, ldp_entity * e)
+{
+  ldp_entity *ep = NULL;
+
+  MPLS_ASSERT(g && e);
+  MPLS_REFCNT_HOLD(e);
+  ep = MPLS_LIST_HEAD(&g->entity);
+  while (ep != NULL) {
+    if (ep->index > e->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->entity, ep, e, _global);
+      return;
+    }
+    ep = MPLS_LIST_NEXT(&g->entity, ep, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->entity, e, _global, ldp_entity);
+}
+
+void _ldp_global_del_entity(ldp_global * g, ldp_entity * e)
+{
+  MPLS_ASSERT(g && e);
+  MPLS_LIST_REMOVE(&g->entity, e, _global);
+  MPLS_REFCNT_RELEASE(e, ldp_entity_delete);
+}
+
+void _ldp_global_add_session(ldp_global * g, ldp_session * s)
+{
+  ldp_session *sp = NULL;
+
+  MPLS_ASSERT(g && s);
+  MPLS_REFCNT_HOLD(s);
+  s->on_global = MPLS_BOOL_TRUE;
+  sp = MPLS_LIST_HEAD(&g->session);
+  while (sp != NULL) {
+    if (sp->index > s->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->session, sp, s, _global);
+      return;
+    }
+    sp = MPLS_LIST_NEXT(&g->session, sp, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->session, s, _global, ldp_session);
+}
+
+void _ldp_global_del_session(ldp_global * g, ldp_session * s)
+{
+  MPLS_ASSERT(g && s);
+  MPLS_ASSERT(s->on_global == MPLS_BOOL_TRUE);
+  MPLS_LIST_REMOVE(&g->session, s, _global);
+  s->on_global = MPLS_BOOL_FALSE;
+  MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+}
+
+mpls_return_enum _ldp_global_add_inlabel(ldp_global * g, ldp_inlabel * i)
+{
+  ldp_inlabel *ip = NULL;
+  mpls_return_enum result;
+
+  MPLS_ASSERT(g && i);
+
+#if MPLS_USE_LSR
+  {
+    lsr_insegment iseg;
+    memcpy(&iseg.info,&i->info,sizeof(mpls_insegment));
+    result = lsr_cfg_insegment_set(g->lsr_handle, &iseg, LSR_CFG_ADD|
+      LSR_INSEGMENT_CFG_NPOP|LSR_INSEGMENT_CFG_FAMILY|
+      LSR_INSEGMENT_CFG_LABELSPACE|LSR_INSEGMENT_CFG_LABEL|
+      LSR_INSEGMENT_CFG_OWNER);
+    memcpy(&i->info, &iseg.info, sizeof(mpls_insegment));
+    i->info.handle = iseg.index;
+  }
+#else
+  result = mpls_mpls_insegment_add(g->mpls_handle, &i->info);
+#endif
+  if (result != MPLS_SUCCESS) {
+    return result;
+  }
+
+  ip = MPLS_LIST_HEAD(&g->inlabel);
+  while (ip != NULL) {
+    if (ip->index > i->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->inlabel, ip, i, _global);
+      return MPLS_SUCCESS;
+    }
+    ip = MPLS_LIST_NEXT(&g->inlabel, ip, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->inlabel, i, _global, ldp_inlabel);
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum _ldp_global_del_inlabel(ldp_global * g, ldp_inlabel * i)
+{
+  MPLS_ASSERT(g && i);
+  MPLS_ASSERT(i->reuse_count == 0);
+#if MPLS_USE_LSR
+  {
+    lsr_insegment iseg;
+    iseg.index = i->info.handle;
+    lsr_cfg_insegment_set(g->lsr_handle, &iseg, LSR_CFG_DEL);
+  }
+#else
+  mpls_mpls_insegment_del(g->mpls_handle, &i->info);
+#endif
+  MPLS_LIST_REMOVE(&g->inlabel, i, _global);
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum _ldp_global_add_outlabel(ldp_global * g, ldp_outlabel * o)
+{
+  ldp_outlabel *op = NULL;
+  mpls_return_enum result;
+
+  MPLS_ASSERT(g && o);
+#if MPLS_USE_LSR
+  {
+    lsr_outsegment oseg;
+    memcpy(&oseg.info, &o->info, sizeof(mpls_outsegment));
+    result = lsr_cfg_outsegment_set(g->lsr_handle, &oseg, LSR_CFG_ADD|
+      LSR_OUTSEGMENT_CFG_PUSH_LABEL|LSR_OUTSEGMENT_CFG_OWNER|
+      LSR_OUTSEGMENT_CFG_INTERFACE|LSR_OUTSEGMENT_CFG_LABEL|
+      LSR_OUTSEGMENT_CFG_NEXTHOP);
+    o->info.handle = oseg.index;
+  }
+#else
+  result = mpls_mpls_outsegment_add(g->mpls_handle, &o->info);
+#endif
+
+  if (result != MPLS_SUCCESS) {
+    return result;
+  }
+
+  o->switching = MPLS_BOOL_TRUE;
+  op = MPLS_LIST_HEAD(&g->outlabel);
+  while (op != NULL) {
+    if (op->index > o->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->outlabel, op, o, _global);
+      return MPLS_SUCCESS;
+    }
+    op = MPLS_LIST_NEXT(&g->outlabel, op, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->outlabel, o, _global, ldp_outlabel);
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum _ldp_global_del_outlabel(ldp_global * g, ldp_outlabel * o)
+{
+  MPLS_ASSERT(g && o);
+#if MPLS_USE_LSR
+  {
+    lsr_outsegment oseg;
+    oseg.index = o->info.handle;
+    lsr_cfg_outsegment_set(g->lsr_handle, &oseg, LSR_CFG_DEL);
+  }
+#else
+  mpls_mpls_outsegment_del(g->mpls_handle, &o->info);
+#endif
+
+  o->switching = MPLS_BOOL_FALSE;
+  MPLS_ASSERT(o->merge_count == 0);
+  MPLS_LIST_REMOVE(&g->outlabel, o, _global);
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_global_find_attr_index(ldp_global * g, uint32_t index,
+  ldp_attr ** attr)
+{
+  ldp_attr *a = NULL;
+
+  if (g && index > 0) {
+
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    a = MPLS_LIST_TAIL(&g->attr);
+    if (a == NULL || a->index < index) {
+      return MPLS_END_OF_LIST;
+      *attr = NULL;
+    }
+
+    a = MPLS_LIST_HEAD(&g->attr);
+    while (a != NULL) {
+      if (a->index == index) {
+        *attr = a;
+        return MPLS_SUCCESS;
+      }
+      a = MPLS_LIST_NEXT(&g->attr, a, _global);
+    }
+  }
+  *attr = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_session_index(ldp_global * g, uint32_t index,
+  ldp_session ** session)
+{
+  ldp_session *s = NULL;
+
+  if (g && index > 0) {
+
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    s = MPLS_LIST_TAIL(&g->session);
+    if (s == NULL || s->index < index) {
+      *session = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    s = MPLS_LIST_HEAD(&g->session);
+    while (s != NULL) {
+      if (s->index == index) {
+        *session = s;
+        return MPLS_SUCCESS;
+      }
+      s = MPLS_LIST_NEXT(&g->session, s, _global);
+    }
+  }
+  *session = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_inlabel_index(ldp_global * g, uint32_t index,
+  ldp_inlabel ** inlabel)
+{
+  ldp_inlabel *i = NULL;
+
+  if (g && index > 0) {
+
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    i = MPLS_LIST_TAIL(&g->inlabel);
+    if (i == NULL || i->index < index) {
+      *inlabel = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    i = MPLS_LIST_HEAD(&g->inlabel);
+    while (i != NULL) {
+      if (i->index == index) {
+        *inlabel = i;
+        return MPLS_SUCCESS;
+      }
+      i = MPLS_LIST_NEXT(&g->inlabel, i, _global);
+    }
+  }
+  *inlabel = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_outlabel_index(ldp_global * g, uint32_t index,
+  ldp_outlabel ** outlabel)
+{
+  ldp_outlabel *o = NULL;
+
+  if (g && index > 0) {
+
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    o = MPLS_LIST_TAIL(&g->outlabel);
+    if (o == NULL || o->index < index) {
+      *outlabel = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    o = MPLS_LIST_HEAD(&g->outlabel);
+    while (o != NULL) {
+      if (o->index == index) {
+        *outlabel = o;
+        return MPLS_SUCCESS;
+      }
+      o = MPLS_LIST_NEXT(&g->outlabel, o, _global);
+    }
+  }
+  *outlabel = NULL;
+  return MPLS_FAILURE;
+}
+
+ldp_outlabel *ldp_global_find_outlabel_handle(ldp_global * g,
+  mpls_outsegment_handle handle)
+{
+  ldp_outlabel *o = MPLS_LIST_HEAD(&g->outlabel);
+
+  if (g) {
+    while (o != NULL) {
+      if (!mpls_outsegment_handle_compare(o->info.handle, handle))
+        return o;
+
+      o = MPLS_LIST_NEXT(&g->outlabel, o, _global);
+    }
+  }
+  return NULL;
+}
+
+mpls_return_enum ldp_global_find_entity_index(ldp_global * g, uint32_t index,
+  ldp_entity ** entity)
+{
+  ldp_entity *e = NULL;
+
+  if (g && index > 0) {
+
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    e = MPLS_LIST_TAIL(&g->entity);
+    if (e == NULL || e->index < index) {
+      *entity = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    e = MPLS_LIST_HEAD(&g->entity);
+    while (e != NULL) {
+      if (e->index == index) {
+        *entity = e;
+        return MPLS_SUCCESS;
+      }
+      e = MPLS_LIST_NEXT(&g->entity, e, _global);
+    }
+  }
+  *entity = NULL;
+  return MPLS_FAILURE;
+}
+
+ldp_peer *ldp_global_find_peer_addr(ldp_global * g, mpls_inet_addr * addr)
+{
+  ldp_peer *p;
+
+  MPLS_ASSERT(g && addr);
+
+  /* JLEU: we will need to add a tree to optimize this search,
+     known peers will be in tree, unknown will take a "slow path" to
+     verify them, then be added to tree */
+
+  p = MPLS_LIST_HEAD(&g->peer);
+  while (p) {
+    LDP_PRINT(g->user_data,
+      "ldp_global_find_peer_lsrid: peer: %08x lsrid: %08x\n",
+      p->dest.addr.u.ipv4, addr->u.ipv4);
+    if (!mpls_inet_addr_compare(&p->dest.addr, addr)) {
+      return p;
+    }
+    p = MPLS_LIST_NEXT(&g->peer, p, _global);
+  }
+  return NULL;
+}
+
+mpls_return_enum ldp_global_find_adj_index(ldp_global * g, uint32_t index,
+  ldp_adj ** adj)
+{
+  ldp_adj *a = NULL;
+
+  if (g && index > 0) {
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    a = MPLS_LIST_TAIL(&g->adj);
+    if (a == NULL || a->index < index) {
+      return MPLS_END_OF_LIST;
+      *adj = NULL;
+    }
+
+    a = MPLS_LIST_HEAD(&g->adj);
+    while (a != NULL) {
+      if (a->index == index) {
+        *adj = a;
+        return MPLS_SUCCESS;
+      }
+      a = MPLS_LIST_NEXT(&g->adj, a, _global);
+    }
+  }
+  *adj = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_peer_index(ldp_global * g, uint32_t index,
+  ldp_peer ** peer)
+{
+  ldp_peer *p = NULL;
+
+  if (g && index > 0) {
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    p = MPLS_LIST_TAIL(&g->peer);
+    if (p == NULL || p->index < index) {
+      *peer = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    p = MPLS_LIST_HEAD(&g->peer);
+    while (p != NULL) {
+      if (p->index == index) {
+        *peer = p;
+        return MPLS_SUCCESS;
+      }
+      p = MPLS_LIST_NEXT(&g->peer, p, _global);
+    }
+  }
+  *peer = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_fec_index(ldp_global * g, uint32_t index,
+  ldp_fec ** fec)
+{
+  ldp_fec *f = NULL;
+
+  if (g && index > 0) {
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    f = MPLS_LIST_TAIL(&g->fec);
+    if (f == NULL || f->index < index) {
+      *fec = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    f = MPLS_LIST_HEAD(&g->fec);
+    while (f != NULL) {
+      if (f->index == index) {
+        *fec = f;
+        return MPLS_SUCCESS;
+      }
+      f = MPLS_LIST_NEXT(&g->fec, f, _global);
+    }
+  }
+  *fec = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_fec(ldp_global * g, mpls_fec * m,
+  ldp_fec ** fec)
+{
+  ldp_fec *f = NULL;
+
+  MPLS_ASSERT(g && m);
+
+  f = MPLS_LIST_HEAD(&g->fec);
+  do {
+    if (!mpls_fec_compare(m, &f->info)) {
+      *fec = f;
+      return MPLS_SUCCESS;
+    }
+  } while((f = MPLS_LIST_NEXT(&g->fec, f, _global)));
+  *fec = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_addr_index(ldp_global * g, uint32_t index,
+  ldp_addr ** addr)
+{
+  ldp_addr *a = NULL;
+
+  if (g && index > 0) {
+
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    a = MPLS_LIST_TAIL(&g->addr);
+    if (a == NULL || a->index < index) {
+      *addr = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    a = MPLS_LIST_HEAD(&g->addr);
+    while (a != NULL) {
+      if (a->index == index) {
+        *addr = a;
+        return MPLS_SUCCESS;
+      }
+      a = MPLS_LIST_NEXT(&g->addr, a, _global);
+    }
+  }
+  *addr = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_if_index(ldp_global * g, uint32_t index,
+  ldp_if ** iff)
+{
+  ldp_if *i = NULL;
+
+  if (g && index > 0) {
+
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    i = MPLS_LIST_TAIL(&g->iff);
+    if (i == NULL || i->index < index) {
+      *iff = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    i = MPLS_LIST_HEAD(&g->iff);
+    while (i != NULL) {
+      if (i->index == index) {
+        *iff = i;
+        return MPLS_SUCCESS;
+      }
+      i = MPLS_LIST_NEXT(&g->iff, i, _global);
+    }
+  }
+  *iff = NULL;
+  return MPLS_FAILURE;
+}
+
+ldp_if *ldp_global_find_if_handle(ldp_global * g, mpls_if_handle handle)
+{
+  ldp_if *i = MPLS_LIST_HEAD(&g->iff);
+
+  if (g) {
+    while (i != NULL) {
+      if (!mpls_if_handle_compare(i->handle, handle))
+        return i;
+
+      i = MPLS_LIST_NEXT(&g->iff, i, _global);
+    }
+  }
+  return NULL;
+}
+
+ldp_adj *ldp_global_find_adj_ldpid(ldp_global * g, mpls_inet_addr * lsraddr,
+  int labelspace)
+{
+
+  ldp_adj *a = MPLS_LIST_HEAD(&g->adj);
+
+  while (a != NULL) {
+    if ((!mpls_inet_addr_compare(lsraddr, &a->remote_lsr_address)) &&
+      labelspace == a->remote_label_space)
+      return a;
+
+    a = MPLS_LIST_NEXT(&g->adj, a, _global);
+  }
+  return NULL;
+}
+
+mpls_return_enum ldp_global_find_tunnel_index(ldp_global * g, uint32_t index,
+  ldp_tunnel ** tunnel)
+{
+  ldp_tunnel *t = NULL;
+
+  if (g && index > 0) {
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    t = MPLS_LIST_TAIL(&g->tunnel);
+    if (t == NULL || t->index < index) {
+      *tunnel = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    t = MPLS_LIST_HEAD(&g->tunnel);
+    while (t != NULL) {
+      if (t->index == index) {
+        *tunnel = t;
+        return MPLS_SUCCESS;
+      }
+      t = MPLS_LIST_NEXT(&g->tunnel, t, _global);
+    }
+  }
+  *tunnel = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_resource_index(ldp_global * g, uint32_t index,
+  ldp_resource ** resource)
+{
+  ldp_resource *r = NULL;
+
+  if (g && index > 0) {
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    r = MPLS_LIST_TAIL(&g->resource);
+    if (r == NULL || r->index < index) {
+      *resource = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    r = MPLS_LIST_HEAD(&g->resource);
+    while (r != NULL) {
+      if (r->index == index) {
+        *resource = r;
+        return MPLS_SUCCESS;
+      }
+      r = MPLS_LIST_NEXT(&g->resource, r, _global);
+    }
+  }
+  *resource = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_global_find_hop_list_index(ldp_global * g, uint32_t index,
+  ldp_hop_list ** hop_list)
+{
+  ldp_hop_list *h = NULL;
+
+  if (g && index > 0) {
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    h = MPLS_LIST_TAIL(&g->hop_list);
+    if (h == NULL || h->index < index) {
+      *hop_list = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    h = MPLS_LIST_HEAD(&g->hop_list);
+    while (h != NULL) {
+      if (h->index == index) {
+        *hop_list = h;
+        return MPLS_SUCCESS;
+      }
+      h = MPLS_LIST_NEXT(&g->hop_list, h, _global);
+    }
+  }
+  *hop_list = NULL;
+  return MPLS_FAILURE;
+}
+
+void _ldp_global_add_tunnel(ldp_global * g, ldp_tunnel * t)
+{
+  ldp_tunnel *tp = NULL;
+
+  MPLS_ASSERT(g && t);
+  MPLS_REFCNT_HOLD(t);
+  tp = MPLS_LIST_HEAD(&g->tunnel);
+  while (tp != NULL) {
+    if (tp->index > t->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->tunnel, tp, t, _global);
+      return;
+    }
+    tp = MPLS_LIST_NEXT(&g->tunnel, tp, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->tunnel, t, _global, ldp_tunnel);
+}
+
+void _ldp_global_del_tunnel(ldp_global * g, ldp_tunnel * t)
+{
+  MPLS_ASSERT(g && t);
+  MPLS_LIST_REMOVE(&g->tunnel, t, _global);
+  MPLS_REFCNT_RELEASE(t, ldp_tunnel_delete);
+}
+
+void _ldp_global_add_resource(ldp_global * g, ldp_resource * r)
+{
+  ldp_resource *rp = NULL;
+
+  MPLS_ASSERT(g && r);
+  MPLS_REFCNT_HOLD(r);
+  rp = MPLS_LIST_HEAD(&g->resource);
+  while (rp != NULL) {
+    if (rp->index > r->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->resource, rp, r, _global);
+      return;
+    }
+    rp = MPLS_LIST_NEXT(&g->resource, rp, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->resource, r, _global, ldp_resource);
+}
+
+void _ldp_global_del_resource(ldp_global * g, ldp_resource * r)
+{
+  MPLS_ASSERT(g && r);
+  MPLS_LIST_REMOVE(&g->resource, r, _global);
+  MPLS_REFCNT_RELEASE(r, ldp_resource_delete);
+}
+
+void _ldp_global_add_hop_list(ldp_global * g, ldp_hop_list * h)
+{
+  ldp_hop_list *hp = NULL;
+
+  MPLS_ASSERT(g && h);
+  MPLS_REFCNT_HOLD(h);
+  hp = MPLS_LIST_HEAD(&g->hop_list);
+  while (hp != NULL) {
+    if (hp->index > h->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->hop_list, hp, h, _global);
+      return;
+    }
+    hp = MPLS_LIST_NEXT(&g->hop_list, hp, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->hop_list, h, _global, ldp_hop_list);
+}
+
+void _ldp_global_del_hop_list(ldp_global * g, ldp_hop_list * h)
+{
+  MPLS_ASSERT(g && h);
+  MPLS_LIST_REMOVE(&g->hop_list, h, _global);
+  MPLS_REFCNT_RELEASE(h, ldp_hop_list_delete);
+}
+
+void _ldp_global_add_fec(ldp_global * g, ldp_fec * f)
+{
+  ldp_fec *fp = NULL;
+
+  MPLS_ASSERT(g && f);
+  /*
+   * TESTING: jleu 6/7/2004, since I want the FEC to be cleaned up
+   * when it no longer has a nexthop, addr, or label, the only things that
+   * should increment the ref are those (nh, addr, label etc), not global
+   * nor inserting into the tree.  I also added this comment in
+   * ldp_fec_create()
+   * MPLS_REFCNT_HOLD(f);
+   */
+  fp = MPLS_LIST_HEAD(&g->fec);
+  while (fp != NULL) {
+    if (fp->index > f->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->fec, fp, f, _global);
+      return;
+    }
+    fp = MPLS_LIST_NEXT(&g->fec, fp, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->fec, f, _global, ldp_fec);
+}
+
+void _ldp_global_del_fec(ldp_global * g, ldp_fec * f)
+{
+  MPLS_ASSERT(g && f);
+  MPLS_LIST_REMOVE(&g->fec, f, _global);
+}
+
+void _ldp_global_add_nexthop(ldp_global * g, ldp_nexthop * nh)
+{
+  ldp_nexthop *nhp = NULL;
+
+  MPLS_ASSERT(g && nh);
+  nhp = MPLS_LIST_HEAD(&g->nexthop);
+  while (nhp != NULL) {
+    if (nhp->index > nh->index) {
+      MPLS_LIST_INSERT_BEFORE(&g->nexthop, nhp, nh, _global);
+      return;
+    }
+    nhp = MPLS_LIST_NEXT(&g->nexthop, nhp, _global);
+  }
+  MPLS_LIST_ADD_TAIL(&g->nexthop, nh, _global, ldp_nexthop);
+}
+
+void _ldp_global_del_nexthop(ldp_global * g, ldp_nexthop * nh)
+{
+  MPLS_ASSERT(g && nh);
+  MPLS_LIST_REMOVE(&g->nexthop, nh, _global);
+}
diff -Naur quagga-0.99.10/ldpd/ldp_global.h quagga-mpls/ldpd/ldp_global.h
--- quagga-0.99.10/ldpd/ldp_global.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_global.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,102 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_GLOBAL_H_
+#define _LDP_GLOBAL_H_
+
+#include "ldp_struct.h"
+
+extern ldp_global *ldp_global_create(mpls_instance_handle data);
+extern mpls_return_enum ldp_global_delete(ldp_global * g);
+extern mpls_return_enum ldp_global_startup(ldp_global * g);
+extern mpls_return_enum ldp_global_shutdown(ldp_global * g);
+
+extern ldp_peer *ldp_global_find_peer_addr(ldp_global * g,
+  mpls_inet_addr * addr);
+extern ldp_if *ldp_global_find_if_handle(ldp_global * g, mpls_if_handle handle);
+extern ldp_adj *ldp_global_find_adj_ldpid(ldp_global * g,
+  mpls_inet_addr * lsraddr, int labelspace);
+
+extern mpls_return_enum ldp_global_find_adj_index(ldp_global * g, uint32_t index, ldp_adj ** adj);
+extern mpls_return_enum ldp_global_find_if_index(ldp_global * g, uint32_t index,
+  ldp_if **);
+extern mpls_return_enum ldp_global_find_addr_index(ldp_global * g,
+  uint32_t index, ldp_addr ** addr);
+extern mpls_return_enum ldp_global_find_attr_index(ldp_global * g,
+  uint32_t index, ldp_attr **);
+extern mpls_return_enum ldp_global_find_session_index(ldp_global * g,
+  uint32_t index, ldp_session **);
+extern mpls_return_enum ldp_global_find_peer_index(ldp_global * g,
+  uint32_t index, ldp_peer ** peer);
+extern mpls_return_enum ldp_global_find_entity_index(ldp_global * g,
+  uint32_t index, ldp_entity ** entity);
+extern mpls_return_enum ldp_global_find_fec_index(ldp_global * g,
+  uint32_t index, ldp_fec ** fec);
+extern mpls_return_enum ldp_global_find_fec(ldp_global * g, mpls_fec * m,
+  ldp_fec ** fec);
+
+extern mpls_return_enum ldp_global_find_inlabel_index(ldp_global * g, uint32_t,
+  ldp_inlabel ** inlabel);
+extern mpls_return_enum ldp_global_find_outlabel_index(ldp_global * g, uint32_t,
+  ldp_outlabel ** outlabel);
+extern ldp_outlabel *ldp_global_find_outlabel_handle(ldp_global * g,
+  mpls_outsegment_handle handle);
+
+extern mpls_return_enum ldp_global_find_tunnel_index(ldp_global * g,
+  uint32_t index, ldp_tunnel ** tunnel);
+extern mpls_return_enum ldp_global_find_resource_index(ldp_global * g,
+  uint32_t index, ldp_resource ** resource);
+extern mpls_return_enum ldp_global_find_hop_list_index(ldp_global * g,
+  uint32_t index, ldp_hop_list ** hop_list);
+
+extern void _ldp_global_add_entity(ldp_global * g, ldp_entity * e);
+extern void _ldp_global_del_entity(ldp_global * g, ldp_entity * e);
+
+extern void _ldp_global_add_session(ldp_global * g, ldp_session * s);
+extern void _ldp_global_del_session(ldp_global * g, ldp_session * s);
+
+extern void _ldp_global_add_peer(ldp_global * g, ldp_peer * p);
+extern void _ldp_global_del_peer(ldp_global * g, ldp_peer * p);
+
+extern void _ldp_global_add_fec(ldp_global * g, ldp_fec * l);
+extern void _ldp_global_del_fec(ldp_global * g, ldp_fec * l);
+
+extern void _ldp_global_add_nexthop(ldp_global * g, ldp_nexthop * l);
+extern void _ldp_global_del_nexthop(ldp_global * g, ldp_nexthop * l);
+
+extern void _ldp_global_add_attr(ldp_global * g, ldp_attr * a);
+extern void _ldp_global_del_attr(ldp_global * g, ldp_attr * a);
+
+extern void _ldp_global_add_if(ldp_global * g, ldp_if * i);
+extern void _ldp_global_del_if(ldp_global * g, ldp_if * i);
+
+extern void _ldp_global_add_addr(ldp_global * g, ldp_addr * a);
+extern void _ldp_global_del_addr(ldp_global * g, ldp_addr * a);
+
+extern void _ldp_global_add_adj(ldp_global * g, ldp_adj * a);
+extern void _ldp_global_del_adj(ldp_global * g, ldp_adj * a);
+
+extern mpls_return_enum _ldp_global_add_inlabel(ldp_global * g, ldp_inlabel * i);
+extern mpls_return_enum _ldp_global_del_inlabel(ldp_global * g, ldp_inlabel * i);
+
+extern mpls_return_enum _ldp_global_add_outlabel(ldp_global * g,
+  ldp_outlabel * o);
+extern mpls_return_enum _ldp_global_del_outlabel(ldp_global * g,
+  ldp_outlabel * o);
+
+extern void _ldp_global_add_tunnel(ldp_global * g, ldp_tunnel * t);
+extern void _ldp_global_del_tunnel(ldp_global * g, ldp_tunnel * t);
+
+extern void _ldp_global_add_resource(ldp_global * g, ldp_resource * r);
+extern void _ldp_global_del_resource(ldp_global * g, ldp_resource * r);
+
+extern void _ldp_global_add_hop_list(ldp_global * g, ldp_hop_list * h);
+extern void _ldp_global_del_hop_list(ldp_global * g, ldp_hop_list * h);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp.h quagga-mpls/ldpd/ldp.h
--- quagga-0.99.10/ldpd/ldp.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,61 @@
+#ifndef LDP_H
+#define LDP_H
+
+#include <zebra.h>
+#include "sockunion.h"
+#include "prefix.h"
+#include "zclient.h"
+#include "linklist.h"
+#include "if.h"
+
+#include "ldp_struct.h"
+
+#define LDP_DEFAULT_CONFIG "ldpd.conf"
+#define LDP_VTY_PORT                2610
+
+typedef enum {
+    LDP_EGRESS_ALL,
+    LDP_EGRESS_LSRID,
+    LDP_EGRESS_CONNECTED
+} ldp_egress_mode;
+
+typedef enum {
+    LDP_ADDRESS_ALL,
+    LDP_ADDRESS_LSRID,
+    LDP_ADDRESS_LDP
+} ldp_address_mode;
+
+typedef enum {
+  LDP_TRANS_ADDR_NONE = 0,
+  LDP_TRANS_ADDR_INTERFACE,
+  LDP_TRANS_ADDR_LSRID,
+  LDP_TRANS_ADDR_STATIC_IP,
+  LDP_TRANS_ADDR_STATIC_INTERFACE,
+} ldp_trans_addr_mode;
+
+struct ldp {
+    struct list *peer_list;
+    mpls_cfg_handle h;
+    mpls_bool admin_up;
+    mpls_bool lsr_id_is_static;
+    ldp_egress_mode egress;
+    ldp_address_mode address;
+    ldp_trans_addr_mode trans_addr;
+    char trans_addr_ifname[IFNAMSIZ + 1];
+    mpls_bool use_lsr_id_for_global_trans_addr;
+    mpls_bool use_interface_addr_for_local_trans_addr;
+};
+
+struct ldp *ldp_get();
+struct ldp *ldp_new();
+void ldp_init();
+int ldp_router_id_update(struct ldp *ldp, struct prefix *router_id);
+int do_ldp_router_id_update(struct ldp *ldp, unsigned int router_id);
+void ldp_finish(struct ldp *ldp);
+
+int ldp_admin_state_start(struct ldp *ldp);
+int ldp_admin_state_finish(struct ldp *ldp);
+int ldp_add_ipv4(struct ldp *ldp, mpls_fec *fec, mpls_nexthop *nexthop);
+int ldp_delete_ipv4(struct ldp *ldp, mpls_fec *fec, mpls_nexthop *nexthop);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_hello.c quagga-mpls/ldpd/ldp_hello.c
--- quagga-0.99.10/ldpd/ldp_hello.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_hello.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,297 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdio.h>
+#include <sys/socket.h>
+
+#include "ldp_struct.h"
+#include "ldp_hello.h"
+#include "ldp_mesg.h"
+#include "ldp_buf.h"
+#include "ldp_adj.h"
+#include "ldp_hello.h"
+#include "ldp_entity.h"
+#include "ldp_session.h"
+#include "ldp_inet_addr.h"
+#include "ldp_pdu_setup.h"
+
+#include "mpls_assert.h"
+#include "mpls_socket_impl.h"
+#include "mpls_timer_impl.h"
+#include "mpls_lock_impl.h"
+#include "mpls_trace_impl.h"
+
+void ldp_hello_timeout_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle handle)
+{
+  ldp_adj *a = (ldp_adj *) extra;
+  ldp_global *g = (ldp_global*)handle;
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_TIMER,
+    "Hello Timout fired: adj(%d)\n", a->index);
+
+  mpls_lock_get(g->global_lock);
+
+  if (a->session) {
+    a->session->shutdown_notif = LDP_NOTIF_HOLD_TIMER_EXPIRED;
+    a->session->shutdown_fatal = MPLS_BOOL_FALSE;
+  }
+  ldp_adj_shutdown(g, a);
+  /* timer is deleted inside of ldp_adj_shutdown */
+  /* the refcount release for the time is done in ldp_adj_shutdown as well */
+
+  mpls_lock_release(g->global_lock);
+}
+
+void ldp_hello_send_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle handle)
+{
+  ldp_entity *e = (ldp_entity*)extra;
+  ldp_global *g = (ldp_global*)handle;
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_TIMER,
+    "Hello Send fired: entity(%d)\n", e->index);
+
+  mpls_lock_get(g->global_lock);
+
+  ldp_hello_send(g, e);
+
+  mpls_lock_release(g->global_lock);
+}
+
+mpls_return_enum ldp_hello_send(ldp_global * g, ldp_entity * e)
+{
+  ldp_mesg **hello = NULL;
+  mpls_timer_handle *timer;
+  int *oper_duration = 0;
+  int targeted = 0;
+  int duration = 0;
+  int request = 0;
+
+  MPLS_ASSERT(g != NULL && e != NULL);
+
+  switch (e->entity_type) {
+    case LDP_DIRECT:
+      MPLS_ASSERT(e->p.iff != NULL);
+      hello = &e->p.iff->hello;
+      oper_duration = &e->p.iff->hellotime_send_timer_duration;
+      timer = &e->p.iff->hellotime_send_timer;
+      targeted = 0;
+      request = 0;
+      break;
+    case LDP_INDIRECT:
+      MPLS_ASSERT(e->p.peer != NULL);
+      hello = &e->p.peer->hello;
+      oper_duration = &e->p.peer->hellotime_send_timer_duration;
+      timer = &e->p.peer->hellotime_send_timer;
+      targeted = 1;
+      if (e->p.peer->target_role == LDP_ACTIVE) {
+        request = 1;
+      } else {
+        request = 0;
+      }
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+  if (!*hello) {
+    *hello = ldp_hello_create(g->message_identifier++,
+      e->hellotime_timer, &e->transport_address,
+      g->configuration_sequence_number, targeted, request);
+  }
+
+  duration = e->hellotime_interval;
+
+  if (mpls_timer_handle_verify(g->timer_handle, *timer) == MPLS_BOOL_FALSE) {
+    MPLS_REFCNT_HOLD(e);
+    *timer = mpls_timer_create(g->timer_handle, MPLS_UNIT_SEC,
+      duration, (void *)e, g, ldp_hello_send_callback);
+    if (mpls_timer_handle_verify(g->timer_handle, *timer) == MPLS_BOOL_FALSE) {
+      *oper_duration = 0;
+      MPLS_REFCNT_RELEASE(e, ldp_entity_delete);
+      return MPLS_FAILURE;
+    }
+    *oper_duration = duration;
+    mpls_timer_start(g->timer_handle, *timer, MPLS_TIMER_REOCCURRING);
+  } else {
+    if ((*oper_duration) != duration) {
+      mpls_timer_stop(g->timer_handle, *timer);
+      *oper_duration = duration;
+      mpls_timer_modify(g->timer_handle, *timer, duration);
+      mpls_timer_start(g->timer_handle, *timer, MPLS_TIMER_REOCCURRING);
+    }
+  }
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_PERIODIC,
+    "Hello Send: entity(%d)\n", e->index);
+
+  return ldp_mesg_send_udp(g, e, *hello);
+}
+
+ldp_mesg *ldp_hello_create(uint32_t msgid, int holdtime, mpls_inet_addr * traddr,
+  uint32_t confnum, int targeted, int request)
+{
+  mplsLdpHelloMsg_t *hello = NULL;
+  ldp_mesg *msg = NULL;
+
+  msg = ldp_mesg_create();
+  ldp_mesg_prepare(msg, MPLS_HELLO_MSGTYPE, msgid);
+  if (msg != NULL) {
+    hello = &msg->u.hello;
+
+    hello->trAdrTlvExists = 0;
+    hello->csnTlvExists = 0;
+
+    hello->chpTlvExists = 1;
+
+    /* this assumes we always want to receive updates for targeted hellos */
+    hello->baseMsg.msgLength += setupChpTlv(&(hello->chp), targeted,
+      request, 0, holdtime);
+
+    if (traddr && traddr->type == MPLS_FAMILY_IPV4 && traddr->u.ipv4 > 0) {
+      hello->trAdrTlvExists = 1;
+      hello->baseMsg.msgLength +=
+        setupTrAddrTlv(&(hello->trAdr), traddr->u.ipv4);
+    }
+
+    if (confnum > 0) {
+      hello->csnTlvExists = 1;
+      hello->baseMsg.msgLength += setupCsnTlv(&(hello->csn), confnum);
+    }
+  }
+  return msg;
+}
+
+mpls_return_enum ldp_hello_process(ldp_global * g, ldp_adj * a, ldp_entity *e,
+  int hellotime, uint32_t csn, mpls_inet_addr * traddr, int targeted,
+  int request)
+{
+  mpls_inet_addr *local = NULL, *remote = NULL;
+
+  MPLS_ASSERT(a && e);
+
+  LDP_ENTER(g->user_data, "ldp_hello_process: a = %p, e = %p", a, e);
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_PERIODIC,
+    "Hello Recv: entity(%d)\n", e->index);
+
+  switch (e->entity_type) {
+    case LDP_DIRECT:
+      /* ldp-11 3.5.2. Hello Message */
+      if (hellotime == 0) {
+        hellotime = 15;
+      }
+
+      if (MPLS_LIST_HEAD(&e->p.iff->addr_root)) {
+	local = &(MPLS_LIST_HEAD(&e->p.iff->addr_root)->address);
+      } else {
+        local = &g->lsr_identifier;
+      }
+
+      break;
+    case LDP_INDIRECT:
+      /* ldp-11 3.5.2. Hello Message */
+      if (hellotime == 0) {
+        hellotime = 45;
+      }
+
+      local = &g->lsr_identifier;
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+
+  if (hellotime < e->hellotime_timer) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_NORMAL,
+      "ldp_hello_process: adjusting hellotime_timer to match adj\n");
+    e->hellotime_timer = hellotime;
+  }
+
+  if (traddr != NULL) {
+    memcpy(&a->remote_transport_address, traddr, sizeof(struct mpls_inet_addr));
+  }
+
+  if (csn != a->remote_csn) {
+    /* the remote csn changes all we can do is clear the backoff time */
+    /* this will only enable a lsr in the active role to try again */
+    a->remote_csn = csn;
+    if (a->session && mpls_timer_handle_verify(g->timer_handle,
+      a->session->backoff_timer) == MPLS_BOOL_TRUE) {
+      ldp_session_backoff_stop(g, a->session);
+    }
+  }
+
+  /* JLEU should verify that the hello hasn't changed */
+
+  if (a->session) {
+    /*  && a->session->state == LDP_STATE_OPERATIONAL) */
+    /* all that matters is that we have a session in progress */
+    /* we already have an established session */
+    LDP_EXIT(g->user_data, "ldp_hello_process");
+    return MPLS_SUCCESS;
+  }
+
+  if (e->transport_address.type != MPLS_FAMILY_NONE) {
+    local = &e->transport_address;
+  }
+
+  if (a->remote_transport_address.type != MPLS_FAMILY_NONE) {
+    remote = &a->remote_transport_address;
+  } else {
+    remote = &a->remote_source_address;
+  }
+
+  switch (mpls_inet_addr_compare(local, remote)) {
+    case 1:
+      /* if at one point we through WE were passive */
+      if (a->role == LDP_PASSIVE && a->session) {
+        ldp_session_shutdown(g, a->session, MPLS_BOOL_TRUE);
+      }
+      a->role = LDP_ACTIVE;
+
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_STATE,
+        "ldp_hello_process: ACTIVE(%d)\n", a->index);
+
+      if (ldp_session_create_active(g, a) != MPLS_SUCCESS) {
+	LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_NORMAL,
+	  "ldp_hello_process: creating an active session failed(%d)\n",
+	  a->index);
+        /* return FAILURE so we don't try to continue with the new adj */
+	return MPLS_FAILURE;
+      }
+      break;
+    case -1:
+      /* if at one point we through WE were active */
+      if (a->role == LDP_ACTIVE && a->session) {
+	ldp_session_shutdown(g, a->session, MPLS_BOOL_TRUE);
+      }
+      a->role = LDP_PASSIVE;
+
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_STATE,
+        "ldp_hello_process: PASSIVE(%d)\n", a->index);
+
+      break;
+    default:
+      LDP_PRINT(g->user_data,
+        "ldp_hello_process: exit(%d) configuration error\n", a->index);
+
+      if (a->session) {
+	ldp_session_shutdown(g, a->session, MPLS_BOOL_TRUE);
+      }
+      a->role = LDP_NONE;
+      MPLS_ASSERT(a->session == NULL);
+
+      /* return FAILURE so we don't try to continue with the new adj */
+      LDP_EXIT(g->user_data, "ldp_hello_process: FAILURE");
+      return MPLS_FAILURE;
+  }
+  LDP_EXIT(g->user_data, "ldp_hello_process");
+
+  return MPLS_SUCCESS;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_hello.h quagga-mpls/ldpd/ldp_hello.h
--- quagga-0.99.10/ldpd/ldp_hello.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_hello.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,27 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_HELLO_H_
+#define _LDP_HELLO_H_
+
+extern void ldp_hello_timeout_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle g);
+
+extern void ldp_hello_send_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle g);
+extern mpls_return_enum ldp_hello_send(ldp_global * g, ldp_entity * e);
+
+extern ldp_mesg *ldp_hello_create(uint32_t msgid, int holdtime,
+  mpls_inet_addr * traddr, uint32_t confnum, int targeted, int request);
+
+extern mpls_return_enum ldp_hello_process(ldp_global * g, ldp_adj * a,
+  ldp_entity *e, int hellotime, uint32_t csn, mpls_inet_addr * traddr,
+  int target, int request);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_hop.c quagga-mpls/ldpd/ldp_hop.c
--- quagga-0.99.10/ldpd/ldp_hop.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_hop.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,64 @@
+
+/*
+ *  Copyright (C) James R. Leu 2001
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_hop_list.h"
+#include "ldp_hop.h"
+
+#include "mpls_assert.h"
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+
+ldp_hop *ldp_hop_create()
+{
+  ldp_hop *h = (ldp_hop *) mpls_malloc(sizeof(ldp_hop));
+
+  if (h) {
+    memset(h, 0, sizeof(ldp_hop));
+    MPLS_REFCNT_INIT(h, 0);
+    MPLS_LIST_ELEM_INIT(h, _hop_list);
+  }
+  return h;
+}
+
+void ldp_hop_delete(ldp_hop * h)
+{
+  // LDP_PRINT(g->user_data,"hop delete\n");
+  MPLS_REFCNT_ASSERT(h, 0);
+  mpls_free(h);
+}
+
+mpls_return_enum _ldp_hop_add_hop_list(ldp_hop * h, ldp_hop_list * hl)
+{
+  if (h && hl) {
+    MPLS_REFCNT_HOLD(hl);
+    h->hop_list = hl;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum _ldp_hop_del_hop_list(ldp_hop * h)
+{
+  if (h && h->hop_list) {
+    MPLS_REFCNT_RELEASE(h->hop_list, ldp_hop_list_delete);
+    h->hop_list = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_bool ldp_hop_in_use(ldp_hop * h)
+{
+  if (h->hop_list && h->hop_list->tunnel &&
+    (h->hop_list->tunnel->admin_state == MPLS_ADMIN_ENABLE)) {
+    return MPLS_BOOL_TRUE;
+  }
+  return MPLS_BOOL_FALSE;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_hop.h quagga-mpls/ldpd/ldp_hop.h
--- quagga-0.99.10/ldpd/ldp_hop.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_hop.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,23 @@
+
+/*
+ *  Copyright (C) James R. Leu 2001
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_HOP_H_
+#define _LDP_HOP_H_
+
+#include "ldp_struct.h"
+
+extern ldp_hop *ldp_hop_create();
+extern void ldp_hop_delete(ldp_hop * h);
+
+extern mpls_return_enum _ldp_hop_add_hop_list(ldp_hop * h, ldp_hop_list * hl);
+extern mpls_return_enum _ldp_hop_del_hop_list(ldp_hop * h);
+
+extern mpls_bool ldp_hop_in_use(ldp_hop * h);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_hop_list.c quagga-mpls/ldpd/ldp_hop_list.c
--- quagga-0.99.10/ldpd/ldp_hop_list.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_hop_list.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,133 @@
+
+/*
+ *  Copyright (C) James R. Leu 2001
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_hop_list.h"
+#include "ldp_hop.h"
+#include "ldp_tunnel.h"
+
+#include "mpls_assert.h"
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+
+static uint32_t _ldp_hop_list_next_index = 1;
+
+ldp_hop_list *ldp_hop_list_create()
+{
+  ldp_hop_list *h = (ldp_hop_list *) mpls_malloc(sizeof(ldp_hop_list));
+
+  if (h) {
+    memset(h, 0, sizeof(ldp_hop_list));
+    MPLS_REFCNT_INIT(h, 0);
+    MPLS_LIST_ELEM_INIT(h, _global);
+    MPLS_LIST_INIT(&h->hop, ldp_hop);
+
+    h->index = _ldp_hop_list_get_next_index();
+  }
+  return h;
+}
+
+void ldp_hop_list_delete(ldp_hop_list * h)
+{
+  // LDP_PRINT(g->user_data,"hop_list delete\n");
+  MPLS_REFCNT_ASSERT(h, 0);
+  mpls_free(h);
+}
+
+uint32_t _ldp_hop_list_get_next_index()
+{
+  uint32_t retval = _ldp_hop_list_next_index;
+
+  _ldp_hop_list_next_index++;
+  if (retval > _ldp_hop_list_next_index) {
+    _ldp_hop_list_next_index = 1;
+  }
+  return retval;
+}
+
+mpls_return_enum ldp_hop_list_find_hop_index(ldp_hop_list * hl, uint32_t index,
+  ldp_hop ** hop)
+{
+  ldp_hop *h = NULL;
+
+  if (hl && index > 0) {
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    h = MPLS_LIST_TAIL(&hl->hop);
+    if (h == NULL || h->index < index) {
+      *hop = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    h = MPLS_LIST_HEAD(&hl->hop);
+    while (h != NULL) {
+      if (h->index == index) {
+        *hop = h;
+        return MPLS_SUCCESS;
+      }
+      h = MPLS_LIST_NEXT(&hl->hop, h, _hop_list);
+    }
+  }
+  *hop = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_hop_list_add_hop(ldp_hop_list * hl, ldp_hop * h)
+{
+  ldp_hop *hp = NULL;
+
+  if (hl && h) {
+    MPLS_REFCNT_HOLD(h);
+    hp = MPLS_LIST_HEAD(&hl->hop);
+    while (hp != NULL) {
+      if (hp->index > h->index) {
+        MPLS_LIST_INSERT_BEFORE(&hl->hop, hp, h, _hop_list);
+        _ldp_hop_add_hop_list(h, hl);
+        return MPLS_SUCCESS;
+      }
+      hp = MPLS_LIST_NEXT(&hl->hop, hp, _hop_list);
+    }
+    MPLS_LIST_ADD_TAIL(&hl->hop, h, _hop_list, ldp_hop);
+    _ldp_hop_add_hop_list(h, hl);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_hop_list_del_hop(ldp_hop_list * hl, ldp_hop * h)
+{
+  if (hl && h) {
+    MPLS_LIST_REMOVE(&hl->hop, h, _hop_list);
+    _ldp_hop_del_hop_list(h);
+    MPLS_REFCNT_RELEASE(h, ldp_hop_delete);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum _ldp_hop_list_add_tunnel(ldp_hop_list * h, ldp_tunnel * t)
+{
+  if (h && t) {
+    MPLS_REFCNT_HOLD(t);
+    h->tunnel = t;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum _ldp_hop_list_del_tunnel(ldp_hop_list * h)
+{
+  if (h && h->tunnel) {
+    MPLS_REFCNT_RELEASE(h->tunnel, ldp_tunnel_delete);
+    h->tunnel = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_hop_list.h quagga-mpls/ldpd/ldp_hop_list.h
--- quagga-0.99.10/ldpd/ldp_hop_list.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_hop_list.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,30 @@
+
+/*
+ *  Copyright (C) James R. Leu 2001
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_HOP_LIST_H_
+#define _LDP_HOP_LIST_H_
+
+#include "ldp_struct.h"
+
+extern ldp_hop_list *ldp_hop_list_create();
+extern void ldp_hop_list_delete(ldp_hop_list * h);
+extern uint32_t _ldp_hop_list_get_next_index();
+
+extern mpls_return_enum ldp_hop_list_find_hop_index(ldp_hop_list * hl,
+  uint32_t index, ldp_hop ** hop);
+
+extern mpls_return_enum ldp_hop_list_add_hop(ldp_hop_list * hl, ldp_hop * e);
+extern mpls_return_enum ldp_hop_list_del_hop(ldp_hop_list * hl, ldp_hop * e);
+
+extern mpls_return_enum _ldp_hop_list_add_tunnel(ldp_hop_list * h,
+
+  ldp_tunnel * t);
+extern mpls_return_enum _ldp_hop_list_del_tunnel(ldp_hop_list * h);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_if.c quagga-mpls/ldpd/ldp_if.c
--- quagga-0.99.10/ldpd/ldp_if.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_if.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,332 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdlib.h>
+#include <netinet/in.h>
+#include <sys/socket.h>
+#include "ldp_struct.h"
+#include "ldp_global.h"
+#include "ldp_entity.h"
+#include "ldp_nexthop.h"
+#include "ldp_nortel.h"
+#include "ldp_addr.h"
+#include "ldp_if.h"
+#include "ldp_fec.h"
+#include "ldp_mesg.h"
+#include "ldp_buf.h"
+#include "ldp_hello.h"
+
+#include "mpls_assert.h"
+#include "mpls_mm_impl.h"
+#include "mpls_compare.h"
+#include "mpls_socket_impl.h"
+#include "mpls_timer_impl.h"
+#include "mpls_ifmgr_impl.h"
+#include "mpls_trace_impl.h"
+
+extern uint32_t _ldp_sub_entity_next_index;
+
+ldp_if *ldp_if_create(ldp_global *g)
+{
+  ldp_if *i = (ldp_if *) mpls_malloc(sizeof(ldp_if));
+
+  if (i) {
+    memset(i, 0, sizeof(ldp_if));
+    /*
+     * note: this is init to 1 for a reason!
+     * We're placing it in the global list, so this is our refcnt
+     * when this refcnt gets to zero, it will be removed from the
+     * global list and deleted
+     */
+    /*
+     * TESTING: jleu 6/7/2004, since I want the iff to be cleaned up
+     * when it no longer has a nexthop, fec, or label, the only things that
+     * should increment the ref are those (nh, fec, label etc), not global
+     * nor inserting into the tree.
+    MPLS_REFCNT_INIT(i, 1);
+     */
+    MPLS_LIST_ELEM_INIT(i, _global);
+    MPLS_LIST_INIT(&i->nh_root, ldp_nexthop);
+    MPLS_LIST_INIT(&i->addr_root, ldp_addr);
+    i->label_space = -1;
+    i->dest.addr.type = MPLS_FAMILY_IPV4;
+    i->dest.addr.u.ipv4 = INADDR_ALLRTRS_GROUP;
+    i->tx_buffer = ldp_buf_create(MPLS_PDUMAXLEN);
+    i->tx_message = ldp_mesg_create();
+    i->index = _ldp_if_get_next_index();
+    i->oper_state = MPLS_OPER_DOWN;
+    i->is_p2p = MPLS_BOOL_FALSE;
+    _ldp_global_add_if(g, i);
+  }
+  return i;
+}
+
+void ldp_if_delete(ldp_global *g, ldp_if * i)
+{
+  LDP_PRINT(g->user_data, "if delete: %p", i);
+  MPLS_REFCNT_ASSERT(i, 0);
+  mpls_free(i->tx_buffer);
+  mpls_free(i->tx_message);
+  i->tx_buffer = NULL;
+  i->tx_message = NULL;
+  _ldp_global_del_if(g, i);
+  mpls_free(i);
+}
+
+/*
+ * ldp_if_insert and ldp_if_remove should ONLY be used in conjuction with
+ * adding and removing nexthops (or fecs).
+ */
+
+ldp_if *ldp_if_insert(ldp_global *g, mpls_if_handle handle)
+{
+  ldp_if *iff = NULL;
+
+  MPLS_ASSERT(g);
+  MPLS_ASSERT(mpls_if_handle_verify(g->ifmgr_handle, handle) == MPLS_BOOL_TRUE);
+
+  if ((iff = ldp_if_create(g)) == NULL) {
+    LDP_PRINT(g->user_data,"ldp_if_insert: unable to alloc ldp_if\n");
+    return NULL;
+  }
+  iff->handle = handle;
+  return iff;
+}
+
+#if 0
+void ldp_if_remove(ldp_global *g, ldp_if *iff)
+{
+  MPLS_ASSERT(g && iff);
+  MPLS_REFCNT_RELEASE2(g, iff, ldp_if_delete);
+}
+#endif
+
+/*
+ * We do not hold a ref to the nexthop.  The nexthop holds a ref to the
+ * if.  Nexthop creation calls ldp_if_add_nexthop, nexthop deletion
+ * calls ldp_if_del_nexthop.  There is no way a nexthop can be deleted
+ * without removing the ifs ref to the nexthop.
+ */
+void ldp_if_add_nexthop(ldp_if * i, ldp_nexthop * n)
+{
+  ldp_nexthop *np = NULL;
+
+  MPLS_ASSERT(i && n);
+
+  ldp_nexthop_add_if(n,i);
+
+  np = MPLS_LIST_HEAD(&i->nh_root);
+  while (np != NULL) {
+    if (np->index > n->index) {
+       MPLS_LIST_INSERT_BEFORE(&i->nh_root, np, n, _if);
+       return;
+    }
+    np = MPLS_LIST_NEXT(&i->nh_root, np, _if);
+  }
+  MPLS_LIST_ADD_TAIL(&i->nh_root, n, _if, ldp_nexthop);
+}
+
+void ldp_if_del_nexthop(ldp_global *g, ldp_if * i, ldp_nexthop * n)
+{
+  MPLS_ASSERT(i && n);
+  MPLS_LIST_REMOVE(&i->nh_root, n, _if);
+  ldp_nexthop_del_if(g, n);
+}
+
+void ldp_if_add_addr(ldp_if * i, ldp_addr * a)
+{
+  ldp_addr *ap = NULL;
+
+  MPLS_ASSERT(i && a);
+  MPLS_REFCNT_HOLD(a);
+
+  ldp_addr_add_if(a,i);
+
+  ap = MPLS_LIST_HEAD(&i->addr_root);
+  while (ap != NULL) {
+    if (ap->index > a->index) {
+       MPLS_LIST_INSERT_BEFORE(&i->addr_root, ap, a, _if);
+       return;
+    }
+    ap = MPLS_LIST_NEXT(&i->addr_root, ap, _if);
+  }
+  MPLS_LIST_ADD_TAIL(&i->addr_root, a, _if, ldp_addr);
+}
+
+void ldp_if_del_addr(ldp_global *g, ldp_if * i, ldp_addr * a)
+{
+  MPLS_ASSERT(i && a);
+  MPLS_LIST_REMOVE(&i->addr_root, a, _if);
+  ldp_addr_del_if(g, a);
+  MPLS_REFCNT_RELEASE2(g, a, ldp_addr_delete);
+}
+
+mpls_return_enum ldp_if_find_addr_index(ldp_if *i, int index, ldp_addr **a)
+{
+  ldp_addr *ap = NULL;
+
+  MPLS_ASSERT(i);
+
+  if (index > 0) {
+
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    ap = MPLS_LIST_TAIL(&i->addr_root);
+    if (!ap || ap->index < index) {
+      *a = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    ap = MPLS_LIST_HEAD(&i->addr_root);
+    do {
+      if (ap->index == index) {
+        *a = ap;
+        return MPLS_SUCCESS;
+      }
+    } while((ap = MPLS_LIST_NEXT(&i->addr_root, ap, _if)));
+  }
+  *a = NULL;
+  return MPLS_FAILURE;
+}
+
+ldp_addr *ldp_if_addr_find(ldp_if *i, mpls_inet_addr *a)
+{
+  ldp_addr *ap = NULL;
+
+  MPLS_ASSERT(i && a);
+
+  ap = MPLS_LIST_HEAD(&i->addr_root);
+  
+  while(ap) {
+    if (!mpls_inet_addr_compare(&ap->address, a)) {
+      return ap;
+    }
+    ap = MPLS_LIST_NEXT(&i->addr_root, ap, _if);
+  }
+  return NULL;
+}
+
+mpls_return_enum ldp_if_startup(ldp_global * g, ldp_if * i)
+{
+  ldp_entity *e = NULL;
+
+  LDP_ENTER(g->user_data, "ldp_if_startup");
+
+  MPLS_ASSERT(i != NULL);
+  e = i->entity;
+  MPLS_ASSERT(e != NULL);
+  MPLS_ASSERT(e->p.iff != NULL);
+
+  if (mpls_socket_multicast_if_join(g->socket_handle, g->hello_socket, i,
+      &i->dest.addr) == MPLS_FAILURE) {
+    goto ldp_if_startup_delay;
+  }
+
+  i->dest.port = e->remote_udp_port;
+  if (ldp_hello_send(g, e) == MPLS_FAILURE) {
+    ldp_if_shutdown(g, i);
+    return MPLS_FAILURE;
+  }
+  i->oper_state = MPLS_OPER_UP;
+
+  LDP_EXIT(g->user_data, "ldp_if_startup");
+
+  return MPLS_SUCCESS;
+
+ldp_if_startup_delay:
+
+  /*
+   * when a interface update comes in, it will search the global 
+   * list of interfaces, and start up the interface then
+   */
+  i->oper_state = MPLS_OPER_DOWN;
+
+  LDP_EXIT(g->user_data, "ldp_if_startup-delayed");
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_if_shutdown(ldp_global * g, ldp_if * i)
+{
+  ldp_entity *e = NULL;
+
+  MPLS_ASSERT(i != NULL && ((e = i->entity) != NULL));
+
+  LDP_ENTER(g->user_data, "ldp_if_shutdown");
+
+  i->oper_state = MPLS_OPER_DOWN;
+
+  mpls_socket_multicast_if_drop(g->socket_handle, g->hello_socket, i,
+    &i->dest.addr);
+
+  mpls_timer_stop(g->timer_handle, i->hellotime_send_timer);
+  mpls_timer_delete(g->timer_handle, i->hellotime_send_timer);
+  i->hellotime_send_timer_duration = 0;
+  i->hellotime_send_timer = 0;
+
+  /* the entity is held in ldp_hello_send when it creates the timer
+   * ldp_hello_send is called by ldp_if_startup
+   */
+  MPLS_ASSERT(e != NULL);
+  MPLS_REFCNT_RELEASE(e, ldp_entity_delete);
+
+  if (i->hello) {
+    ldp_mesg_delete(i->hello);
+    i->hello = NULL;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_if_shutdown");
+
+  return MPLS_SUCCESS;
+}
+
+mpls_bool ldp_if_is_active(ldp_if * i)
+{
+  if (i && i->entity && i->entity->admin_state == MPLS_ADMIN_ENABLE)
+    return MPLS_BOOL_TRUE;
+
+  return MPLS_BOOL_FALSE;
+}
+
+mpls_return_enum _ldp_if_add_entity(ldp_if * i, ldp_entity * e)
+{
+  if (i && e) {
+    MPLS_REFCNT_HOLD(e);
+    i->entity = e;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+ldp_entity *ldp_if_get_entity(ldp_if * i)
+{
+  return i->entity;
+}
+
+mpls_return_enum _ldp_if_del_entity(ldp_if * i)
+{
+  if (i && i->entity) {
+    MPLS_REFCNT_RELEASE(i->entity, ldp_entity_delete);
+    i->entity = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+uint32_t _ldp_if_get_next_index()
+{
+  uint32_t retval = _ldp_sub_entity_next_index;
+
+  _ldp_sub_entity_next_index++;
+  if (retval > _ldp_sub_entity_next_index) {
+    _ldp_sub_entity_next_index = 1;
+  }
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_if.h quagga-mpls/ldpd/ldp_if.h
--- quagga-0.99.10/ldpd/ldp_if.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_if.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,34 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_IF_H_
+#define _LDP_IF_H_
+
+#include "ldp_struct.h"
+
+extern ldp_if *ldp_if_create(ldp_global *g);
+extern void ldp_if_delete(ldp_global *g, ldp_if * i);
+extern ldp_if *ldp_if_insert(ldp_global *g, mpls_if_handle handle);
+extern void ldp_if_remove(ldp_global *g, ldp_if *iff);
+extern void ldp_if_add_nexthop(ldp_if * i, ldp_nexthop * n);
+extern void ldp_if_del_nexthop(ldp_global *g, ldp_if * i, ldp_nexthop * n);
+extern ldp_addr *ldp_if_addr_find(ldp_if *i, mpls_inet_addr *a);
+extern mpls_return_enum ldp_if_find_addr_index(ldp_if *i, int index,
+    ldp_addr **a);
+extern void ldp_if_del_addr(ldp_global *g, ldp_if * i, ldp_addr * a);
+extern void ldp_if_add_addr(ldp_if * i, ldp_addr * a);
+extern mpls_return_enum ldp_if_startup(ldp_global * g, ldp_if * i);
+extern mpls_return_enum ldp_if_shutdown(ldp_global * g, ldp_if * i);
+extern mpls_bool ldp_if_is_active(ldp_if * i);
+extern mpls_return_enum _ldp_if_add_entity(ldp_if * i, ldp_entity * e);
+extern ldp_entity *ldp_if_get_entity(ldp_if * i);
+extern mpls_return_enum _ldp_if_del_entity(ldp_if * i);
+extern uint32_t _ldp_if_get_next_index();
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_inet_addr.c quagga-mpls/ldpd/ldp_inet_addr.c
--- quagga-0.99.10/ldpd/ldp_inet_addr.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_inet_addr.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,23 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_inet_addr.h"
+
+#include "mpls_mm_impl.h"
+
+mpls_inet_addr *mpls_inet_addr_create()
+{
+  mpls_inet_addr *ia = (mpls_inet_addr *) mpls_malloc(sizeof(mpls_inet_addr));
+
+  if (ia != NULL)
+    memset(ia, 0, sizeof(mpls_inet_addr));
+
+  return ia;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_inet_addr.h quagga-mpls/ldpd/ldp_inet_addr.h
--- quagga-0.99.10/ldpd/ldp_inet_addr.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_inet_addr.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,17 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_INET_ADDR_H_
+#define _LDP_INET_ADDR_H_
+
+extern mpls_inet_addr *mpls_inet_addr_create();
+extern mpls_bool mpls_inet_addr_is_equal(mpls_inet_addr *, mpls_inet_addr *);
+extern int mpls_inet_addr_compare(mpls_inet_addr *, mpls_inet_addr *);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_init.c quagga-mpls/ldpd/ldp_init.c
--- quagga-0.99.10/ldpd/ldp_init.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_init.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,235 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_mesg.h"
+#include "ldp_entity.h"
+#include "ldp_nortel.h"
+#include "ldp_buf.h"
+#include "ldp_pdu_setup.h"
+
+#include "mpls_assert.h"
+#include "mpls_socket_impl.h"
+#include "mpls_trace_impl.h"
+#if MPLS_USE_LSR
+#include "lsr_cfg.h"
+#else
+#include "mpls_mpls_impl.h"
+#endif
+
+void ldp_init_prepare(ldp_mesg * msg, ldp_global * g, uint32_t msgid,
+  ldp_session * s)
+{
+  mplsLdpInitMsg_t *init = NULL;
+  uint32_t remote_labelspace;
+  uint32_t path_vector_limit;
+  uint32_t remote_lsraddr;
+  uint8_t direction = 0;
+  ldp_adj *a = MPLS_LIST_HEAD(&s->adj_root);
+  uint32_t loop = 0;
+  uint8_t merge = 0;
+  mpls_range range;
+  uint8_t len = 0;
+
+  MPLS_ASSERT(s && a);
+
+  LDP_ENTER(g->user_data, "ldp_init_create");
+
+  ldp_mesg_prepare(msg, MPLS_INIT_MSGTYPE, msgid);
+  init = &msg->u.init;
+
+  remote_lsraddr = a->remote_lsr_address.u.ipv4;
+  remote_labelspace = a->remote_label_space;
+
+  loop = (s->cfg_loop_detection_mode == LDP_LOOP_NONE) ? (0) : (1);
+  if (loop == LDP_LOOP_NONE) {
+    path_vector_limit = 0;
+  } else {
+    path_vector_limit = s->cfg_path_vector_limit;
+  }
+
+  init->cspExists = 1;
+
+  init->baseMsg.msgLength += setupCspTlv(&(init->csp), s->cfg_keepalive,
+    s->cfg_distribution_mode, loop, path_vector_limit, s->cfg_max_pdu,
+    remote_lsraddr, remote_labelspace, 0);
+
+  init->aspExists = 0;
+  init->fspExists = 0;
+
+  range.label_space = s->cfg_label_space;
+#if MPLS_USE_LSR
+#else
+  mpls_mpls_get_label_space_range(g->mpls_handle,&range);
+#endif
+
+  switch (range.type) {
+    case MPLS_LABEL_RANGE_ATM_VP:
+      MPLS_ASSERT(0);
+    case MPLS_LABEL_RANGE_ATM_VC:
+    case MPLS_LABEL_RANGE_ATM_VP_VC:
+      init->aspExists = 1;
+      init->baseMsg.msgLength += setupAspTlv(&(init->asp), merge, direction);
+      init->baseMsg.msgLength += addLblRng2AspTlv(&(init->asp),
+        range.min.u.atm.vpi, range.min.u.atm.vci, range.max.u.atm.vpi,
+        range.max.u.atm.vci);
+      break;
+    case MPLS_LABEL_RANGE_FR_10:
+      len = 0;                /* Section 3.5.3 fspTlv */
+    case MPLS_LABEL_RANGE_FR_24:
+      init->fspExists = 1;
+
+      if (range.type == MPLS_LABEL_RANGE_FR_24) {
+        len = 2;              /* Section 3.5.3 fspTlv */
+      }
+
+      init->baseMsg.msgLength += setupFspTlv(&(init->fsp), merge, direction);
+      init->baseMsg.msgLength += addLblRng2FspTlv(&(init->fsp), 0, len,
+        range.min.u.fr.dlci, 0, range.max.u.fr.dlci);
+      break;
+    case MPLS_LABEL_RANGE_GENERIC:
+      break;
+  }
+  LDP_EXIT(g->user_data, "ldp_init_create");
+}
+
+mpls_return_enum ldp_init_send(ldp_global * g, ldp_session * s)
+{
+  mpls_return_enum result = MPLS_FAILURE;
+
+  MPLS_ASSERT(s);
+
+  LDP_ENTER(g->user_data, "ldp_init_send");
+
+  ldp_init_prepare(s->tx_message, g, g->message_identifier++, s);
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_INIT,
+    "Init Send: session(%d)\n", s->index);
+
+  result = ldp_mesg_send_tcp(g, s, s->tx_message);
+
+  LDP_EXIT(g->user_data, "ldp_init_send");
+
+  return result;
+}
+
+mpls_return_enum ldp_init_process(ldp_global * g, ldp_session * s,
+  ldp_mesg * msg)
+{
+  mpls_range range;
+
+  MPLS_MSGPTR(Init);
+
+  MPLS_ASSERT(s);
+
+  LDP_ENTER(g->user_data, "ldp_init_process");
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_INIT,
+    "Init Recv: session(%d)\n", s->index);
+
+  MPLS_MSGPARAM(Init) = &msg->u.init;
+
+  range.label_space = s->cfg_label_space;
+
+#if MPLS_USE_LSR
+  range.type = MPLS_LABEL_RANGE_GENERIC;
+#else
+  mpls_mpls_get_label_space_range(g->mpls_handle, &range);
+#endif
+
+  if (MPLS_MSGPARAM(Init)->csp.rcvLsrAddress != g->lsr_identifier.u.ipv4 ||
+    MPLS_MSGPARAM(Init)->csp.rcvLsId != range.label_space) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_INIT,
+      "Init failed(%d): sending bad LDP-ID\n", s->index);
+    LDP_EXIT(g->user_data, "ldp_init_process-error");
+    s->shutdown_notif = LDP_NOTIF_BAD_LDP_ID;
+    s->shutdown_fatal = MPLS_BOOL_FALSE;
+    return MPLS_FAILURE;
+  }
+
+  if (MPLS_MSGPARAM(Init)->csp.holdTime == 0) {
+    LDP_EXIT(g->user_data, "ldp_init_process-error");
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_INIT,
+      "Init failed(%d): sending bad Keepalive Time\n", s->index);
+    s->shutdown_notif = LDP_NOTIF_SESSION_REJECTED_BAD_KEEPALIVE_TIME;
+    s->shutdown_fatal = MPLS_BOOL_FALSE;
+    return MPLS_FAILURE;
+  }
+
+  if (MPLS_MSGPARAM(Init)->csp.maxPduLen <= 255)
+    MPLS_MSGPARAM(Init)->csp.maxPduLen = 4096; /* Section 3.5.3. */
+
+  s->remote_max_pdu = MPLS_MSGPARAM(Init)->csp.maxPduLen;
+  s->remote_keepalive = MPLS_MSGPARAM(Init)->csp.holdTime;
+  s->remote_path_vector_limit = MPLS_MSGPARAM(Init)->csp.flags.flags.pvl;
+  s->remote_distribution_mode =
+    (ldp_distribution_mode) MPLS_MSGPARAM(Init)->csp.flags.flags.lad;
+
+  if (s->remote_keepalive < s->cfg_keepalive) {
+    s->oper_keepalive = s->remote_keepalive;
+  } else {
+    s->oper_keepalive = s->cfg_keepalive;
+  }
+
+  /* JLEU: eventually this should be configured by the user */
+  s->oper_keepalive_interval = s->oper_keepalive / 3;
+
+  if (MPLS_MSGPARAM(Init)->csp.flags.flags.ld == 0) {
+    s->remote_loop_detection = MPLS_BOOL_FALSE;
+  } else {
+    s->remote_loop_detection = MPLS_BOOL_TRUE;
+  }
+
+  if (s->remote_max_pdu < s->cfg_max_pdu) {
+    s->oper_max_pdu = s->remote_max_pdu;
+  }
+
+  if (s->remote_distribution_mode != s->cfg_distribution_mode) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_INIT,
+      "Init(%d): distribution modes do not match, using default\n", s->index);
+    if (range.type == MPLS_LABEL_RANGE_GENERIC) {
+      s->oper_distribution_mode = LDP_DISTRIBUTION_UNSOLICITED;
+    } else {
+      s->oper_distribution_mode = LDP_DISTRIBUTION_ONDEMAND;
+    }
+  }
+
+  if ((s->remote_loop_detection == MPLS_BOOL_TRUE) &&
+    (g->loop_detection_mode != LDP_LOOP_NONE)) {
+    s->oper_loop_detection = s->cfg_loop_detection_mode;
+  } else {
+    s->oper_loop_detection = LDP_LOOP_NONE;
+  }
+
+  if (MPLS_MSGPARAM(Init)->aspExists) {
+    if (range.type >= MPLS_LABEL_RANGE_ATM_VP && range.type <= MPLS_LABEL_RANGE_ATM_VP_VC) {
+      MPLS_ASSERT(0);
+    } else {
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_INIT,
+        "Init Failed(%d): sending bad Label Range (ATM)\n", s->index);
+      s->shutdown_notif = LDP_NOTIF_SESSION_REJECTED_PARAMETERS_LABEL_RANGE;
+      s->shutdown_fatal = MPLS_BOOL_FALSE;
+      return MPLS_FAILURE;
+    }
+  } else if (MPLS_MSGPARAM(Init)->fspExists) {
+    if (range.type >= MPLS_LABEL_RANGE_FR_10 && range.type <= MPLS_LABEL_RANGE_FR_24) {
+      MPLS_ASSERT(0);
+    } else {
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_INIT,
+        "Init Failed(%d): sending bad Label Range (FR)\n", s->index);
+      s->shutdown_notif = LDP_NOTIF_SESSION_REJECTED_PARAMETERS_LABEL_RANGE;
+      s->shutdown_fatal = MPLS_BOOL_FALSE;
+      return MPLS_FAILURE;
+    }
+  }
+
+  LDP_EXIT(g->user_data, "ldp_init_process");
+
+  return MPLS_SUCCESS;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_init.h quagga-mpls/ldpd/ldp_init.h
--- quagga-0.99.10/ldpd/ldp_init.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_init.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,21 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_INIT_H_
+#define _LDP_INIT_H_
+
+#include "ldp_struct.h"
+
+extern ldp_mesg *ldp_init_create(ldp_global * g, uint32_t msgid,
+  ldp_session * session);
+extern mpls_return_enum ldp_init_send(ldp_global * g, ldp_session * s);
+extern mpls_return_enum ldp_init_process(ldp_global * g, ldp_session * s,
+  ldp_mesg * msg);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_inlabel.c quagga-mpls/ldpd/ldp_inlabel.c
--- quagga-0.99.10/ldpd/ldp_inlabel.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_inlabel.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,201 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdlib.h>
+#include "ldp_struct.h"
+#include "ldp_outlabel.h"
+#include "ldp_inlabel.h"
+#include "ldp_session.h"
+#include "ldp_entity.h"
+#include "ldp_attr.h"
+#include "ldp_global.h"
+
+#include "mpls_assert.h"
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+
+#if MPLS_USE_LSR
+#include "lsr_cfg.h"
+#else
+#include "mpls_mpls_impl.h"
+#endif
+
+static uint32_t _ldp_inlabel_next_index = 1;
+
+/*
+ * even through we're trying to mimic what FECs/addrs/interfaces are doing
+ * with respect to being added to the global list upon create and
+ * automagically be removed from the global list upon delete, we have to
+ * change thing up for inlabels.  We want the global add/delete to call
+ * the porting layer to install the segments, but an inlabel needs more
+ * info then just being allocated before the porting layer can add it.
+ * so ldp_inlabel_create is not in charge of adding to the global list.
+ * Instead the only entrance to creating a inlabel is
+ * ldp_inlabel_create_complete which uses ldp_inlabel_create just to
+ * allocate and initialize the memory, then after all of the necessary info
+ * has been attached, it is added to the global list, which calls the
+ * porting layer
+ */
+
+static ldp_inlabel *ldp_inlabel_create(ldp_global * g)
+{
+  ldp_inlabel *i = (ldp_inlabel *) mpls_malloc(sizeof(ldp_inlabel));
+
+  if (i) {
+    memset(i, 0, sizeof(ldp_inlabel));
+    MPLS_REFCNT_INIT(i, 0);
+    mpls_link_list_init(&i->session_root);
+    mpls_link_list_init(&i->attr_root);
+    MPLS_LIST_ELEM_INIT(i, _global);
+    MPLS_LIST_ELEM_INIT(i, _outlabel);
+    i->index = _ldp_inlabel_get_next_index();
+    i->info.label.type = MPLS_LABEL_TYPE_NONE;
+  }
+  return i;
+}
+
+ldp_inlabel *ldp_inlabel_create_complete(ldp_global * g, ldp_session * s,
+  ldp_attr * a)
+{
+  ldp_inlabel *in = ldp_inlabel_create(g);
+  mpls_return_enum result;
+
+  if (in != NULL) {
+
+    in->info.labelspace = s->cfg_label_space;
+    in->info.npop = 1;
+    in->info.family = MPLS_FAMILY_IPV4;
+    in->info.owner = MPLS_OWNER_LDP;
+
+    /* _ldp_global_add_inlabel must be here so the porting layer has all the
+     * info needed for installing the label */
+    result = _ldp_global_add_inlabel(g, in);
+
+    if (result == MPLS_FAILURE) {
+      _ldp_global_del_inlabel(g, in);
+      return NULL;
+    }
+
+    if (ldp_session_add_inlabel(g, s, in) == MPLS_FAILURE) {
+      /* if ldp_session_add_inlabel fails its use of MPLS_HOLD and
+       * RELEASE2 will result in the inlabel being deleted */
+      return NULL;
+    }
+
+    mpls_label_struct2ldp_attr(&in->info.label, a);
+    ldp_attr_add_inlabel(g, a, in);
+  }
+  return in;
+}
+
+void ldp_inlabel_delete(ldp_global * g, ldp_inlabel * i)
+{
+  LDP_PRINT(g->user_data,"inlabel delete: %p", i);
+  MPLS_REFCNT_ASSERT(i, 0);
+  _ldp_global_del_inlabel(g, i);
+  mpls_free(i);
+}
+
+mpls_return_enum ldp_inlabel_add_outlabel(ldp_global *g, ldp_inlabel *i,
+  ldp_outlabel *o) {
+  mpls_return_enum result;
+
+  MPLS_ASSERT(i && o);
+  MPLS_ASSERT(i->outlabel == NULL);
+
+#if MPLS_USE_LSR
+  {
+    lsr_xconnect xcon;
+    xcon.insegment_index = i->info.handle;
+    xcon.outsegment_index = o->info.handle;
+    xcon.info.owner = MPLS_OWNER_LDP;
+    result = lsr_cfg_xconnect_set2(g->lsr_handle, &xcon, LSR_CFG_ADD|
+      LSR_XCONNECT_CFG_OUTSEGMENT|LSR_XCONNECT_CFG_INSEGMENT|
+      LSR_XCONNECT_CFG_LSPID|LSR_XCONNECT_CFG_OWNER);
+  }
+#else
+  result = mpls_mpls_xconnect_add(g->mpls_handle, &i->info, &o->info);
+#endif
+  if (result == MPLS_SUCCESS) {
+    MPLS_REFCNT_HOLD(o);
+    i->outlabel = o;
+    _ldp_outlabel_add_inlabel(o, i);
+  }
+  return result;
+}
+
+mpls_return_enum ldp_inlabel_del_outlabel(ldp_global *g, ldp_inlabel * i)
+{
+  MPLS_ASSERT(i && i->outlabel);
+  {
+#if MPLS_USE_LSR
+    lsr_xconnect xcon;
+    xcon.insegment_index = i->info.handle;
+    xcon.outsegment_index = i->outlabel->info.handle;
+    lsr_cfg_xconnect_set2(g->lsr_handle, &xcon, LSR_CFG_DEL);
+#else
+    mpls_mpls_xconnect_del(g->mpls_handle, &i->info, &i->outlabel->info);
+#endif
+    _ldp_outlabel_del_inlabel(g, i->outlabel, i);
+    MPLS_REFCNT_RELEASE2(g, i->outlabel, ldp_outlabel_delete);
+    i->outlabel = NULL;
+  }
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum _ldp_inlabel_add_attr(ldp_global *g, ldp_inlabel * i, ldp_attr * a)
+{
+  MPLS_ASSERT(i && a);
+
+  MPLS_REFCNT_HOLD(a);
+  if (mpls_link_list_add_tail(&i->attr_root, a) == MPLS_SUCCESS) {
+    i->reuse_count++;
+    return MPLS_SUCCESS;
+  }
+  MPLS_REFCNT_RELEASE2(g, a, ldp_attr_delete);
+  return MPLS_FAILURE;
+}
+
+void _ldp_inlabel_del_attr(ldp_global *g, ldp_inlabel * i, ldp_attr * a)
+{
+  MPLS_ASSERT(i && a);
+  mpls_link_list_remove_data(&i->attr_root, a);
+  MPLS_REFCNT_RELEASE2(g, a, ldp_attr_delete);
+  i->reuse_count--;
+}
+
+mpls_return_enum _ldp_inlabel_add_session(ldp_inlabel * i, ldp_session * s)
+{
+  MPLS_ASSERT(i && s);
+
+  MPLS_REFCNT_HOLD(s);
+  if (mpls_link_list_add_tail(&i->session_root, s) == MPLS_SUCCESS) {
+    return MPLS_SUCCESS;
+  }
+  MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+  return MPLS_FAILURE;
+}
+
+void _ldp_inlabel_del_session(ldp_inlabel * i, ldp_session * s)
+{
+  MPLS_ASSERT(i && s);
+  mpls_link_list_remove_data(&i->session_root, s);
+  MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+}
+
+uint32_t _ldp_inlabel_get_next_index()
+{
+  uint32_t retval = _ldp_inlabel_next_index;
+
+  _ldp_inlabel_next_index++;
+  if (retval > _ldp_inlabel_next_index) {
+    _ldp_inlabel_next_index = 1;
+  }
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_inlabel.h quagga-mpls/ldpd/ldp_inlabel.h
--- quagga-0.99.10/ldpd/ldp_inlabel.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_inlabel.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,36 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_INLABEL_H_
+#define _LDP_INLABEL_H_
+
+#include "ldp_struct.h"
+
+extern void ldp_inlabel_delete(ldp_global * g, ldp_inlabel * i);
+
+extern ldp_inlabel *ldp_inlabel_create_complete(ldp_global * g, ldp_session * s,
+  ldp_attr * a);
+extern void ldp_inlabel_delete_complete(ldp_global * g, ldp_inlabel * in,
+  ldp_session * s, ldp_attr * a);
+
+extern mpls_return_enum ldp_inlabel_add_outlabel(ldp_global *g,
+  ldp_inlabel *i, ldp_outlabel *o);
+extern mpls_return_enum ldp_inlabel_del_outlabel(ldp_global *g,
+  ldp_inlabel *i);
+
+extern mpls_return_enum _ldp_inlabel_add_session(ldp_inlabel * i,
+  ldp_session * s);
+extern void _ldp_inlabel_del_session(ldp_inlabel * i, ldp_session * s);
+
+extern uint32_t _ldp_inlabel_get_next_index();
+
+extern mpls_return_enum _ldp_inlabel_add_attr(ldp_global *g, ldp_inlabel * i, ldp_attr * a);
+extern void _ldp_inlabel_del_attr(ldp_global *g, ldp_inlabel * i, ldp_attr * a);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_interface.c quagga-mpls/ldpd/ldp_interface.c
--- quagga-0.99.10/ldpd/ldp_interface.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_interface.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,208 @@
+#include <zebra.h>
+
+#include "if.h"
+#include "memory.h"
+
+#include "ldp_cfg.h"
+#include "ldp_struct.h"
+
+#include "ldp.h"
+#include "ldp_interface.h"
+#include "impl_mpls.h"
+
+extern struct prefix router_id;
+
+unsigned int if_ipv4_src_address (struct interface *ifp) {
+  struct listnode *node;
+  struct connected *c;
+  for (ALL_LIST_ELEMENTS_RO(ifp->connected, node, c))
+  {
+    struct prefix *p = c->address;
+
+    if (p && p->family == AF_INET)
+      return p->u.prefix4.s_addr;
+  }
+  return router_id.u.prefix4.s_addr;
+}
+
+struct ldp_interface *ldp_interface_new(struct interface *ifp) {
+    struct ldp_interface *li;
+
+    li = XMALLOC(MTYPE_LDP, sizeof(struct ldp_interface));
+    if (!li) {
+	return NULL;
+    }
+    memset(li, 0, sizeof(struct ldp_interface));
+    li->ifp = ifp;
+    ifp->info = li;
+
+    li->configured = MPLS_BOOL_FALSE;
+    li->admin_up = MPLS_BOOL_FALSE;
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    ldp_entity_set_defaults(&li->entity);
+
+    return li;
+}
+
+void ldp_interface_free(struct ldp_interface *li) {
+    XFREE(MTYPE_LDP, li);
+}
+
+int ldp_interface_create2(struct ldp_interface *li) {
+    struct ldp *ldp = ldp_get();
+
+    if (!ldp || !li->iff.index) {
+	li->create_on_hold = MPLS_BOOL_TRUE;
+	return MPLS_SUCCESS;
+    }
+
+    li->create_on_hold = MPLS_BOOL_FALSE;
+
+    li->entity.sub_index = li->iff.index;
+    li->entity.entity_type = LDP_DIRECT;
+    li->entity.admin_state = MPLS_ADMIN_DISABLE;
+
+    if (ldp->trans_addr == LDP_TRANS_ADDR_INTERFACE) {
+	li->entity.transport_address.type = MPLS_FAMILY_IPV4;
+	li->entity.transport_address.u.ipv4 =
+	    ntohl(if_ipv4_src_address (li->ifp));
+    } else {
+	li->entity.transport_address.type = MPLS_FAMILY_NONE;
+    }
+
+    ldp_cfg_entity_set(ldp->h, &li->entity,
+	LDP_CFG_ADD | LDP_ENTITY_CFG_SUB_INDEX |
+	LDP_ENTITY_CFG_ADMIN_STATE | LDP_ENTITY_CFG_TRANS_ADDR);
+
+    ldp_cfg_entity_get(ldp->h, &li->entity, 0xFFFFFFFF);
+    return ldp_interface_admin_state_finish(li);
+}
+
+int ldp_interface_create(struct ldp_interface *li) {
+    struct ldp *ldp = ldp_get();
+
+    MPLS_ASSERT (!li->iff.index);
+    MPLS_ASSERT(ldp);
+
+    /* tell LDP about this interface */
+    if (li->ifp->mpls_labelspace < 0) {
+	li->ifp->mpls_labelspace = 0;
+    }
+    li->iff.label_space = li->ifp->mpls_labelspace;
+    li->iff.handle = li->ifp;
+
+    zlog_debug("Creating interface %s(%p)\n", li->ifp->name, li->ifp);
+
+    ldp_cfg_if_set(ldp->h, &li->iff,LDP_CFG_ADD|LDP_IF_CFG_LABEL_SPACE);
+    ldp_cfg_if_get(ldp->h, &li->iff, 0xFFFFFFFF);
+
+    return MPLS_SUCCESS;
+}
+
+void ldp_interface_delete2(struct ldp_interface *li) {
+    struct ldp *ldp = ldp_get();
+
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    li->entity.admin_state = MPLS_ADMIN_DISABLE;
+
+    if (ldp) {
+	ldp_interface_admin_state_start(li);
+	if (li->entity.index) {
+	    ldp_cfg_entity_set(ldp->h, &li->entity, LDP_CFG_DEL);
+	}
+    }
+    li->entity.index = 0;
+}
+
+void ldp_interface_delete(struct ldp_interface *li) {
+    struct ldp *ldp = ldp_get();
+
+    MPLS_ASSERT(ldp);
+    MPLS_ASSERT(li->iff.index);
+
+    ldp_cfg_if_set(ldp->h, &li->iff, LDP_CFG_DEL);
+    li->iff.index = 0;
+}
+
+int ldp_interface_startup(struct ldp_interface *li) {
+    struct ldp *ldp = ldp_get();
+
+    MPLS_ASSERT(ldp && li->iff.index && li->entity.index);
+
+    /* only real interfaces get here */
+    li->entity.admin_state = MPLS_ADMIN_ENABLE;
+    ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_ADMIN_STATE);
+
+    return MPLS_SUCCESS;
+}
+
+int ldp_interface_shutdown(struct ldp_interface *li) {
+    struct ldp *ldp = ldp_get();
+
+    MPLS_ASSERT(ldp && li->iff.index && li->entity.index);
+
+    li->entity.admin_state = MPLS_ADMIN_DISABLE;
+    ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_ADMIN_STATE);
+
+    return MPLS_SUCCESS;
+}
+
+int ldp_interface_admin_state_start(struct ldp_interface *li) {
+  if (li->admin_up == MPLS_BOOL_TRUE && ldp_interface_is_up(li)) {
+    return ldp_interface_shutdown(li);
+  }
+  return MPLS_SUCCESS;
+}
+
+int ldp_interface_admin_state_finish(struct ldp_interface *li) {
+  if (li->admin_up == MPLS_BOOL_TRUE && ldp_interface_is_up(li)) {
+    return ldp_interface_startup(li);
+  }
+  return MPLS_SUCCESS;
+}
+
+void ldp_interface_up(struct ldp_interface *li) {
+    if (li->configured == MPLS_BOOL_TRUE && li->admin_up == MPLS_BOOL_TRUE) {
+	ldp_interface_startup(li);
+    }
+}
+
+void ldp_interface_down(struct ldp_interface *li) {
+    if (li->configured == MPLS_BOOL_TRUE && li->admin_up == MPLS_BOOL_TRUE) {
+	ldp_interface_shutdown(li);
+    }
+}
+
+int ldp_interface_is_up(struct ldp_interface *li) {
+    return if_is_up(li->ifp);
+}
+
+static
+int ldp_interface_new_hook(struct interface *ifp) {
+    if (!ldp_interface_new(ifp)) {
+	return 1;
+    }
+
+    if (ldp_get())
+	ldp_interface_create(ifp->info);
+
+    return 0;
+}
+
+static
+int ldp_interface_delete_hook(struct interface *ifp) {
+    if (ifp->info) {
+	if (ldp_get())
+	    ldp_interface_delete(ifp->info);
+	ldp_interface_free(ifp->info);
+    }
+    ifp->info = NULL;
+    return 0;
+}
+
+void ldp_interface_init() {
+    /* Initialize Zebra interface data structure. */
+    if_init();
+    if_add_hook(IF_NEW_HOOK, ldp_interface_new_hook);
+    if_add_hook(IF_DELETE_HOOK, ldp_interface_delete_hook);
+}
diff -Naur quagga-0.99.10/ldpd/ldp_interface.h quagga-mpls/ldpd/ldp_interface.h
--- quagga-0.99.10/ldpd/ldp_interface.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_interface.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,49 @@
+#ifndef LDP_IF_H
+#define LDP_IF_H
+
+#include <zebra.h>
+                                                                                
+#include "if.h"
+#include "command.h"
+#include "prefix.h"
+#include "zclient.h"
+
+#include "ldp_struct.h"
+#include "l2cc_interface.h"
+
+struct ldp_interface {
+    struct interface *ifp;
+    struct connected *connected;
+    struct l2cc_interface *l2cc;
+
+    ldp_entity entity;
+    ldp_if iff;
+    mpls_bool configured;
+    mpls_bool admin_up;
+    mpls_bool create_on_hold;
+    mpls_bool use_for_global_trans_addr;
+    mpls_bool use_for_local_trans_addr;
+};
+
+unsigned int if_ipv4_src_address (struct interface *ifp);
+
+struct ldp_interface *ldp_interface_new(struct interface *ifp);
+void ldp_interface_free(struct ldp_interface *li);
+
+void ldp_interface_up(struct ldp_interface *li);
+void ldp_interface_down(struct ldp_interface *li);
+
+int ldp_interface_startup(struct ldp_interface *li);
+int ldp_interface_shutdown(struct ldp_interface *li);
+
+int ldp_interface_create2(struct ldp_interface *li);
+void ldp_interface_delete2(struct ldp_interface *li);
+int ldp_interface_create(struct ldp_interface *li);
+void ldp_interface_delete(struct ldp_interface *li);
+int ldp_interface_admin_state_start(struct ldp_interface *li);
+int ldp_interface_admin_state_finish(struct ldp_interface *li);
+int ldp_interface_is_up(struct ldp_interface *li);
+
+void ldp_interface_init();
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_keepalive.c quagga-mpls/ldpd/ldp_keepalive.c
--- quagga-0.99.10/ldpd/ldp_keepalive.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_keepalive.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,127 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_mesg.h"
+#include "ldp_nortel.h"
+#include "ldp_buf.h"
+#include "ldp_keepalive.h"
+#include "ldp_session.h"
+#include "ldp_pdu_setup.h"
+
+#include "mpls_assert.h"
+#include "mpls_socket_impl.h"
+#include "mpls_timer_impl.h"
+#include "mpls_lock_impl.h"
+#include "mpls_trace_impl.h"
+
+void ldp_keepalive_timeout_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle handle)
+{
+  ldp_session *s = (ldp_session *) extra;
+  ldp_global *g = (ldp_global*)handle;
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_TIMER,
+    "Keepalive Timeout fired: session(%d)\n", s->index);
+
+  mpls_lock_get(g->global_lock);
+
+  s->shutdown_notif = LDP_NOTIF_KEEPALIVE_TIMER_EXPIRED;
+  s->shutdown_fatal = MPLS_BOOL_FALSE;
+  /* we should go into backoff, so don't completly kill the session */
+  ldp_session_shutdown(g, s, MPLS_BOOL_FALSE);
+  MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+
+  mpls_lock_release(g->global_lock);
+}
+
+void ldp_keepalive_send_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle handle)
+{
+  ldp_session *s = (ldp_session *) extra;
+  ldp_global *g = (ldp_global*)handle;
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_TIMER,
+    "Keepalive Send fired: session(%d)\n", s->index);
+
+  mpls_lock_get(g->global_lock);
+  ldp_keepalive_send(g, s);
+  mpls_lock_release(g->global_lock);
+}
+
+ldp_mesg *ldp_keepalive_create(uint32_t msgid)
+{
+  ldp_mesg *msg = NULL;
+
+  msg = ldp_mesg_create();
+  ldp_mesg_prepare(msg, MPLS_KEEPAL_MSGTYPE, msgid);
+
+  return msg;
+}
+
+void ldp_keepalive_set_message_id(ldp_mesg * msg, uint32_t msgid)
+{
+  mplsLdpKeepAlMsg_t *keep;
+
+  MPLS_ASSERT(msg);
+  keep = &msg->u.keep;
+  setBaseMsgId(&(keep->baseMsg), msgid);
+}
+
+mpls_return_enum ldp_keepalive_send(ldp_global * g, ldp_session * s)
+{
+  MPLS_ASSERT(s);
+
+  if (s->keepalive == NULL) {
+    if ((s->keepalive = ldp_keepalive_create(g->message_identifier++)) == NULL) {
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+        "ldp_keepalive_send: error creating keepalve\n");
+      return MPLS_FAILURE;
+    }
+  } else {
+    ldp_keepalive_set_message_id(s->keepalive, g->message_identifier++);
+  }
+
+  if (mpls_timer_handle_verify(g->timer_handle, s->keepalive_recv_timer) ==
+    MPLS_BOOL_FALSE) {
+    MPLS_REFCNT_HOLD(s);
+    s->keepalive_recv_timer = mpls_timer_create(g->timer_handle, MPLS_UNIT_SEC,
+      s->oper_keepalive, (void *)s, g, ldp_keepalive_timeout_callback);
+    if (mpls_timer_handle_verify(g->timer_handle, s->keepalive_recv_timer) ==
+      MPLS_BOOL_FALSE) {
+      MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+        "ldp_keepalive_send: error creating timer\n");
+      return MPLS_FAILURE;
+    }
+    mpls_timer_start(g->timer_handle, s->keepalive_recv_timer, MPLS_TIMER_ONESHOT);
+  }
+
+  if (mpls_timer_handle_verify(g->timer_handle, s->keepalive_send_timer) ==
+    MPLS_BOOL_FALSE) {
+    MPLS_REFCNT_HOLD(s);
+    s->keepalive_send_timer = mpls_timer_create(g->timer_handle, MPLS_UNIT_SEC,
+      s->oper_keepalive_interval, (void *)s, g, ldp_keepalive_send_callback);
+    if (mpls_timer_handle_verify(g->timer_handle, s->keepalive_send_timer) ==
+      MPLS_BOOL_FALSE) {
+      MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+        "ldp_keepalive_send: error creating timer\n");
+      return MPLS_FAILURE;
+    }
+    mpls_timer_start(g->timer_handle, s->keepalive_send_timer, MPLS_TIMER_REOCCURRING);
+  }
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_PERIODIC,
+    "Keepalive Send: session(%d)\n", s->index);
+
+  ldp_mesg_send_tcp(g, s, s->keepalive);
+
+  return MPLS_SUCCESS;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_keepalive.h quagga-mpls/ldpd/ldp_keepalive.h
--- quagga-0.99.10/ldpd/ldp_keepalive.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_keepalive.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,23 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_KEEPALIVE_H_
+#define _LDP_KEEPALIVE_H_
+
+#include "ldp_struct.h"
+
+extern ldp_mesg *ldp_keepalive_create(uint32_t msgid);
+extern mpls_return_enum ldp_keepalive_send(ldp_global * g, ldp_session * s);
+extern void ldp_keepalive_send_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle g);
+extern void ldp_keepalive_timeout_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle g);
+extern void ldp_keepalive_set_message_id(ldp_mesg * keep, uint32_t msgid);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_label_abort.c quagga-mpls/ldpd/ldp_label_abort.c
--- quagga-0.99.10/ldpd/ldp_label_abort.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_label_abort.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,165 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_attr.h"
+#include "ldp_fec.h"
+#include "ldp_mesg.h"
+#include "ldp_pdu_setup.h"
+#include "ldp_entity.h"
+#include "ldp_session.h"
+#include "ldp_notif.h"
+#include "ldp_label_abort.h"
+#include "ldp_label_rel_with.h"
+#include "ldp_label_mapping.h"
+
+#include "mpls_trace_impl.h"
+
+void ldp_label_abort_prepare_msg(ldp_mesg * msg, uint32_t msgid,
+  ldp_attr * s_attr)
+{
+  mplsLdpLblAbortMsg_t *abrt = NULL;
+
+  ldp_mesg_prepare(msg, MPLS_LBLABORT_MSGTYPE, msgid);
+
+  abrt = &msg->u.abort;
+
+  if (s_attr->fecTlvExists) {
+    abrt->fecTlvExists = 1;
+    abrt->baseMsg.msgLength += setupFecTlv(&abrt->fecTlv);
+    abrt->baseMsg.msgLength +=
+      addFecElem2FecTlv(&abrt->fecTlv, &s_attr->fecTlv.fecElArray[0]);
+  }
+
+  if (s_attr->lblMsgIdTlvExists) {
+    abrt->lblMsgIdTlvExists = 1;
+    abrt->baseMsg.msgLength +=
+      setupLblMsgIdTlv(&abrt->lblMsgIdTlv, s_attr->msg_id);
+  }
+}
+
+mpls_return_enum ldp_label_abort_send(ldp_global * g, ldp_session * s,
+  ldp_attr * s_attr)
+{
+  mpls_fec fec;
+  ldp_attr *ds_attr = NULL;
+
+  LDP_ENTER(g->user_data, "ldp_label_abort_send");
+
+  fec_tlv2mpls_fec(&s_attr->fecTlv, 0, &fec);
+  if ((ds_attr = ldp_attr_find_downstream_state(g, s, &fec,
+        LDP_LSP_STATE_ABORT_SENT)) != NULL) {
+    return MPLS_SUCCESS;
+  }
+
+  ldp_label_abort_prepare_msg(s->tx_message, g->message_identifier++, s_attr);
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_LABEL,
+    "Label Abort Sent: session (%d) \n", s->index);
+
+  s_attr->state = LDP_LSP_STATE_ABORT_SENT;
+
+  if (ldp_mesg_send_tcp(g, s, s->tx_message) == MPLS_FAILURE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_ERROR,
+      "Label Abort Sent Failed .\n");
+    goto ldp_label_abort_send_error;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_label_abort_send");
+  return MPLS_SUCCESS;
+
+ldp_label_abort_send_error:
+
+  if (s_attr) {
+    ldp_attr_remove_complete(g, s_attr, MPLS_BOOL_FALSE);
+  }
+  LDP_EXIT(g->user_data, "ldp_label_abort_send-error");
+
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_label_abort_process(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, ldp_attr * r_attr, ldp_fec * f)
+{
+  ldp_attr_list *us_list = NULL;
+  ldp_attr *us_temp = NULL;
+  ldp_attr *us_attr = NULL;
+  ldp_attr *ds_req_attr = NULL;
+  ldp_attr *ds_map_attr = NULL;
+  mpls_return_enum retval = MPLS_SUCCESS;
+
+  if ((us_list = ldp_attr_find_upstream_all2(g, s, f))) {
+    us_temp = MPLS_LIST_HEAD(us_list);
+    while (us_temp) {
+      if (((us_temp->state == LDP_LSP_STATE_REQ_RECV) &&
+          (us_temp->msg_id == r_attr->msg_id)) ||
+        (us_temp->state == LDP_LSP_STATE_MAP_SENT)) {
+        us_attr = us_temp;
+        break;
+      }
+      us_temp = MPLS_LIST_NEXT(us_list, us_temp, _fs);
+    }
+  }
+  if ((!us_attr) || (us_attr->state == LDP_LSP_STATE_MAP_SENT)) { /* LAbR.1,2 */
+    retval = MPLS_FAILURE;
+    goto LAbR_12;
+  }
+  /* LAbR.3 */
+  if (ldp_notif_send(g, s, us_attr, LDP_NOTIF_LABEL_ABORT) != MPLS_SUCCESS) {
+    retval = MPLS_FAILURE;
+    goto LAbR_12;
+  }
+  /* LAbR.4 */
+  if (us_attr->ds_attr && (us_attr->ds_attr->state == LDP_LSP_STATE_REQ_SENT)) {
+    ds_req_attr = us_attr->ds_attr;
+    goto LAbR_7;
+  }
+  /* LAbR.5 */
+  if (us_attr->ds_attr && (us_attr->ds_attr->state == LDP_LSP_STATE_MAP_RECV)) {
+    ds_map_attr = us_attr->ds_attr;
+  } else {
+    goto LAbR_11;
+  }
+
+  /* this may results in us sending a label withdraw to s and possibly
+     propogating a release */
+  if (ldp_label_release_process(g, s, NULL, e, us_attr, f) != MPLS_SUCCESS) { /* LAbR.6 */
+    retval = MPLS_FAILURE;
+  }
+  goto LAbR_11;
+
+LAbR_7:
+
+  if (g->label_merge == MPLS_BOOL_TRUE) { /* LAbR.7 */
+    /* by now us_attr has been removed from the downstream us_attr_root
+       so any left overs (reflect by count > 0) are from other peers */
+    if (ds_req_attr && ldp_attr_num_us2ds(ds_req_attr)) { /* LAbR.8 */
+      goto LAbR_11;
+    }
+  }
+
+  if (ldp_label_abort_send(g, ds_req_attr->session, ds_req_attr) != MPLS_SUCCESS) { /* LAbR.9,10 */
+    retval = MPLS_FAILURE;
+  }
+
+LAbR_11:
+
+  if (us_attr) {
+    ldp_attr_remove_complete(g, us_attr, MPLS_BOOL_FALSE);
+  }
+
+LAbR_12:
+
+  LDP_EXIT(g->user_data, "ldp_label_abort_processed");
+  return retval;
+}
+
+void abort2attr(mplsLdpLblAbortMsg_t * abrt, ldp_attr * a, uint32_t flag)
+{
+}
diff -Naur quagga-0.99.10/ldpd/ldp_label_abort.h quagga-mpls/ldpd/ldp_label_abort.h
--- quagga-0.99.10/ldpd/ldp_label_abort.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_label_abort.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,28 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_LABEL_ABORT_H_
+#define _LDP_LABEL_ABORT_H_
+#include "ldp_struct.h"
+
+extern ldp_mesg *ldp_label_abort_create_msg(uint32_t msgid, ldp_attr * s_attr);
+
+extern mpls_return_enum ldp_label_abort_send(ldp_global * g, ldp_session * s,
+  ldp_attr * a);
+
+extern mpls_return_enum ldp_label_abort_process(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, ldp_attr * r_attr, ldp_fec * fec);
+
+extern void Prepare_Label_Abort_Attributes(ldp_global * g, ldp_session * s,
+  mpls_fec * fec, ldp_attr * r_attr, ldp_attr * s_attr);
+
+extern void abort2attr(mplsLdpLblAbortMsg_t * abrt, ldp_attr * a,
+  uint32_t flag);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_label_mapping.c quagga-mpls/ldpd/ldp_label_mapping.c
--- quagga-0.99.10/ldpd/ldp_label_mapping.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_label_mapping.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,1155 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_session.h"
+#include "ldp_attr.h"
+#include "ldp_fec.h"
+#include "ldp_mesg.h"
+#include "ldp_notif.h"
+#include "ldp_entity.h"
+#include "ldp_inlabel.h"
+#include "ldp_outlabel.h"
+#include "ldp_nexthop.h"
+#include "ldp_global.h"
+#include "ldp_pdu_setup.h"
+#include "ldp_label_rel_with.h"
+#include "ldp_label_mapping.h"
+#include "ldp_label_request.h"
+
+#include "mpls_timer_impl.h"
+#include "mpls_fib_impl.h"
+#include "mpls_lock_impl.h"
+#include "mpls_tree_impl.h"
+#include "mpls_trace_impl.h"
+#include "mpls_mm_impl.h"
+#include "mpls_policy_impl.h"
+
+#if MPLS_USE_LSR
+#include "lsr_cfg.h"
+#else
+#include "mpls_mpls_impl.h"
+#endif
+
+mpls_return_enum ldp_label_mapping_with_xc(ldp_global * g, ldp_session * s,
+  ldp_fec * f, ldp_attr ** us_attr, ldp_attr * ds_attr)
+{
+  mpls_return_enum result = MPLS_SUCCESS;
+  mpls_bool propogating = MPLS_BOOL_TRUE;
+  mpls_bool egress = MPLS_BOOL_FALSE;
+  mpls_bool egress_flag = MPLS_BOOL_FALSE;
+  mpls_bool created = MPLS_BOOL_FALSE;
+  ldp_nexthop *nh;
+
+  MPLS_ASSERT(us_attr);
+
+  nh = MPLS_LIST_HEAD(&f->nh_root);
+  while (nh) {
+    if (egress_flag == MPLS_BOOL_FALSE) {
+      egress_flag = mpls_policy_egress_check(g->user_data, &f->info, &nh->info);
+    }
+    nh = MPLS_LIST_NEXT(&f->nh_root, nh, _fec);
+  }
+
+  if (!(*us_attr)) {
+    if (!((*us_attr) = ldp_attr_create(g, &f->info))) {
+      return MPLS_FAILURE;
+    }
+    MPLS_REFCNT_HOLD((*us_attr));
+    created = MPLS_BOOL_TRUE;
+  }
+  if ((!ds_attr) && (egress_flag == MPLS_BOOL_TRUE)) {
+    propogating = MPLS_BOOL_FALSE;
+    egress = MPLS_BOOL_TRUE;
+  }
+
+  Prepare_Label_Mapping_Attributes(g, s, &f->info, ds_attr, (*us_attr),
+    propogating, MPLS_BOOL_TRUE, egress);
+
+  result = ldp_label_mapping_send(g, s, f, (*us_attr), ds_attr);
+  if (result != MPLS_SUCCESS) {
+    if (created == MPLS_BOOL_TRUE) {
+      /* this should result in it being deleted, since we're
+       * the only one who should be holding a ref
+       */
+      MPLS_REFCNT_RELEASE2(g, (*us_attr), ldp_attr_delete);
+    }
+    return result;
+  }
+
+  if (created == MPLS_BOOL_TRUE) {
+    result = ldp_attr_insert_upstream2(g, s, (*us_attr), f);
+    /* now that it is in the tree (supposedly) we can safely
+     * release our ref, if it is not in the tree, then this should
+     * result in it beig deleted
+     */
+    MPLS_REFCNT_RELEASE2(g, (*us_attr), ldp_attr_delete);
+    if (result != MPLS_SUCCESS) {
+      return result;
+    }
+  }
+
+  /*
+   * If we have a downstream mapping (not neccessarily installed) and
+   * the downstream and upstream session are not the same....
+   */
+  if (ds_attr && ((*us_attr)->session->index != ds_attr->session->index)) {
+    /* then link the attra */
+    ldp_attr_add_us2ds((*us_attr), ds_attr);
+
+    /* if we just created the upstream, and we have install the
+     * downstream, then cross connect them */
+    if ((created == MPLS_BOOL_TRUE) && ds_attr->outlabel) {
+
+      if ((*us_attr)->inlabel->outlabel) {
+        /*
+         * if we use an existing upstream mapping (in ldp_label_mapping_send())
+         * the inlabel will already be be connected to an outlabel;
+         */
+        MPLS_ASSERT((*us_attr)->inlabel->outlabel == ds_attr->outlabel);
+      } else {
+        LDP_TRACE_LOG(g->user_data,MPLS_TRACE_STATE_ALL,LDP_TRACE_FLAG_BINDING,
+          "Cross Connect Added for %08x/%d from %s -> %s\n",
+          f->info.u.prefix.network.u.ipv4, f->info.u.prefix.length,
+          (*us_attr)->session->session_name, ds_attr->session->session_name);
+
+        result = ldp_inlabel_add_outlabel(g,(*us_attr)->inlabel,
+          ds_attr->outlabel);
+        if (result != MPLS_SUCCESS) {
+          return result;
+        }
+      }
+    }
+  }
+  return MPLS_SUCCESS;
+}
+
+ldp_session *ldp_get_next_hop_session_for_fec2(ldp_fec * f, ldp_nexthop *nh) {
+  ldp_session *session = NULL;
+  /*
+   * find the info about the next hop for this FEC
+   */
+  if (nh->addr && nh->addr->session) {
+    session = nh->addr->session;
+  } else if (nh->iff && nh->iff->is_p2p == MPLS_BOOL_TRUE &&
+    nh->iff->entity) {
+    ldp_adj *adj = MPLS_LIST_HEAD(&nh->iff->entity->adj_root);
+    session = adj ? adj->session : NULL;
+  }
+  return session;
+}
+
+mpls_return_enum ldp_get_next_hop_session_for_fec(ldp_global * g,
+  mpls_fec * fec, mpls_nexthop *nh, ldp_session ** next_hop_session)
+{
+  ldp_fec *f = NULL;
+  ldp_nexthop *n = NULL;
+
+  MPLS_ASSERT(next_hop_session);
+
+  if (!(f = ldp_fec_find(g, fec))) {
+    return MPLS_NO_ROUTE;
+  }
+
+  if (!(n = ldp_fec_nexthop_find(f, nh))) {
+    return MPLS_NO_ROUTE;
+  }
+
+  *next_hop_session = ldp_get_next_hop_session_for_fec2(f,n);
+  return (*next_hop_session) ? MPLS_SUCCESS : MPLS_FAILURE;
+}
+
+mpls_return_enum Check_Received_Attributes(ldp_global * g, ldp_session * s,
+  ldp_attr * r_attr, uint16_t type)
+{
+  int count = 0;
+  int i;
+
+  if (!r_attr->hopCountTlvExists) { /* CRa.1 */
+    goto Check_Received_Attributes_5;
+  }
+
+  if (r_attr->hopCountTlv.hcValue >= s->cfg_hop_count_limit) { /* CRa.2 */
+    LDP_PRINT(g->user_data, "CRa.2\n");
+    goto Check_Received_Attributes_6;
+  }
+
+  if (!r_attr->pathVecTlvExists) { /* CRa.3 */
+    goto Check_Received_Attributes_5;
+  }
+
+  for (i = 0; i < MPLS_MAXHOPSNUMBER; i++) { /* CRa.4 */
+    if (r_attr->pathVecTlv.lsrId[i]) {
+      count++;
+      if (r_attr->pathVecTlv.lsrId[i] == g->lsr_identifier.u.ipv4) {
+        goto Check_Received_Attributes_6;
+        LDP_PRINT(g->user_data, "CRa.4a\n");
+      }
+      if (count > s->oper_path_vector_limit) {
+        goto Check_Received_Attributes_6;
+        LDP_PRINT(g->user_data, "CRa.4b\n");
+      }
+    }
+  }
+
+Check_Received_Attributes_5:
+  return MPLS_SUCCESS;
+
+Check_Received_Attributes_6:
+  if (type != MPLS_LBLMAP_MSGTYPE) {
+    ldp_notif_send(g, s, r_attr, LDP_NOTIF_LOOP_DETECTED); /* CRa.7 */
+  }
+  return MPLS_FAILURE;           /* CRa.8 */
+}
+
+void Prepare_Label_Mapping_Attributes(ldp_global * g, ldp_session * s,
+  mpls_fec * fec, ldp_attr * r_attr, ldp_attr * s_attr, mpls_bool propogating,
+  mpls_bool already, mpls_bool egress)
+{
+  ldp_attr dummy;
+  int i;
+
+  /* NOTE: PMpA.21 is the end of the procedure (ie return) */
+  /* this function uses goto quite extensivly for a REASON!! */
+  /* Check Appedix A of the LDP draft */
+
+  LDP_ENTER(g->user_data, "Prepare_Label_Mapping_Attributes");
+
+  if (!r_attr) {
+    memset(&dummy, 0, sizeof(ldp_attr));
+    mpls_fec2fec_tlv(fec, &dummy.fecTlv, 0);
+    dummy.fecTlvExists = 1;
+    dummy.fecTlv.numberFecElements = 1;
+    r_attr = &dummy;
+  }
+
+  if (!(s->oper_loop_detection == LDP_LOOP_HOPCOUNT ||
+    s->oper_loop_detection == LDP_LOOP_HOPCOUNT_PATHVECTOR ||
+    r_attr->hopCountTlvExists)) { /* PMpA.1 */
+    LDP_EXIT(g->user_data, "Prepare_Label_Mapping_Attributes");
+    return;
+  }
+
+  if (egress) {/* PMpA.2 */
+    /* I'm egress (for now) */
+    s_attr->hopCountTlvExists = 1;
+    s_attr->hopCountTlv.hcValue = 1; /* PMpA.3 */
+    LDP_EXIT(g->user_data, "Prepare_Label_Mapping_Attributes");
+    return;
+  }
+
+  if (!(r_attr->hopCountTlvExists)) { /* PMpA.4 */
+    goto Prepare_Label_Mapping_Attributes_8;
+  }
+
+  if (!(g->ttl_less_domain == MPLS_BOOL_TRUE &&
+    s->cfg_remote_in_ttl_less_domain == MPLS_BOOL_TRUE)) { /* PMpA.5 */
+    goto Prepare_Label_Mapping_Attributes_7;
+  }
+
+  s_attr->hopCountTlvExists = 1;
+  s_attr->hopCountTlv.hcValue = 1; /* PMpA.6 */
+  goto Prepare_Label_Mapping_Attributes_9;
+
+Prepare_Label_Mapping_Attributes_7:
+  s_attr->hopCountTlvExists = 1;
+  s_attr->hopCountTlv.hcValue = (r_attr->hopCountTlv.hcValue) ?
+    (r_attr->hopCountTlv.hcValue + 1) : 0;
+  goto Prepare_Label_Mapping_Attributes_9;
+
+Prepare_Label_Mapping_Attributes_8:
+  s_attr->hopCountTlvExists = 1;
+  s_attr->hopCountTlv.hcValue = 0;
+
+Prepare_Label_Mapping_Attributes_9:
+  if (s->oper_loop_detection == LDP_LOOP_NONE) {
+    LDP_EXIT(g->user_data, "Prepare_Label_Mapping_Attributes");
+    return;
+  }
+
+  if (r_attr->pathVecTlvExists) { /* PMpA.10 */
+    goto Prepare_Label_Mapping_Attributes_19;
+  }
+
+  if (propogating == MPLS_BOOL_FALSE) { /* PMpA.11 */
+    goto Prepare_Label_Mapping_Attributes_20;
+  }
+
+  if (g->label_merge != MPLS_BOOL_TRUE) { /* PMpA.12 */
+    goto Prepare_Label_Mapping_Attributes_14;
+  }
+
+  if (already == MPLS_BOOL_FALSE) {   /* PMpA.13 */
+    goto Prepare_Label_Mapping_Attributes_20;
+  }
+
+Prepare_Label_Mapping_Attributes_14:
+  if (!r_attr->hopCountTlvExists) {
+    LDP_EXIT(g->user_data, "Prepare_Label_Mapping_Attributes");
+    return;
+  }
+
+  if (r_attr->hopCountTlv.hcValue == 0) { /* PMpA.15 */
+    goto Prepare_Label_Mapping_Attributes_20;
+  }
+
+  if (already == MPLS_BOOL_FALSE) {   /* PMpA.16 */
+    LDP_EXIT(g->user_data, "Prepare_Label_Mapping_Attributes");
+    return;
+  }
+
+  /* r_attr contain PrevHopCount _IF_ we had one */
+  LDP_EXIT(g->user_data, "Prepare_Label_Mapping_Attributes");
+  return;                       /* PMpA.17 */
+
+  if (r_attr->hopCountTlv.hcValue != 0) { /* PMpA.18 */
+    LDP_EXIT(g->user_data, "Prepare_Label_Mapping_Attributes");
+    return;
+  }
+
+Prepare_Label_Mapping_Attributes_19:
+  s_attr->pathVecTlvExists = 1;
+  s_attr->pathVecTlv.lsrId[0] = g->lsr_identifier.u.ipv4;
+  for (i = 1; i < (MPLS_MAXHOPSNUMBER - 1); i++) {
+    if (r_attr->pathVecTlv.lsrId[i - 1]) {
+      s_attr->pathVecTlv.lsrId[0] = r_attr->pathVecTlv.lsrId[i - 1];
+    }
+  }
+
+  LDP_EXIT(g->user_data, "Prepare_Label_Mapping_Attributes");
+  return;
+
+Prepare_Label_Mapping_Attributes_20:
+  s_attr->pathVecTlvExists = 1;
+  s_attr->pathVecTlv.lsrId[0] = g->lsr_identifier.u.ipv4;
+
+  LDP_EXIT(g->user_data, "Prepare_Label_Mapping_Attributes");
+  return;
+}
+
+void map2attr(mplsLdpLblMapMsg_t * map, ldp_attr * attr, uint32_t flag)
+{
+  attr->msg_id = map->baseMsg.msgId;
+
+  if (map->fecTlvExists && flag & LDP_ATTR_FEC) {
+    memcpy(&attr->fecTlv, &map->fecTlv, sizeof(mplsLdpFecTlv_t));
+    attr->fecTlvExists = 1;
+  }
+  if (map->genLblTlvExists && flag & LDP_ATTR_LABEL) {
+    memcpy(&attr->genLblTlv, &map->genLblTlv, sizeof(mplsLdpGenLblTlv_t));
+    attr->genLblTlvExists = 1;
+  } else if (map->atmLblTlvExists && flag & LDP_ATTR_LABEL) {
+    memcpy(&attr->atmLblTlv, &map->atmLblTlv, sizeof(mplsLdpAtmLblTlv_t));
+    attr->atmLblTlvExists = 1;
+  } else if (map->frLblTlvExists && flag & LDP_ATTR_LABEL) {
+    memcpy(&attr->frLblTlv, &map->frLblTlv, sizeof(mplsLdpFrLblTlv_t));
+    attr->frLblTlvExists = 1;
+  }
+  if (map->hopCountTlvExists && flag & LDP_ATTR_HOPCOUNT) {
+    memcpy(&attr->hopCountTlv, &map->hopCountTlv, sizeof(mplsLdpHopTlv_t));
+    attr->hopCountTlvExists = 1;
+  }
+  if (map->pathVecTlvExists && flag & LDP_ATTR_PATH) {
+    memcpy(&attr->pathVecTlv, &map->pathVecTlv, sizeof(mplsLdpPathTlv_t));
+    attr->pathVecTlvExists = 1;
+  }
+  if (map->lblMsgIdTlvExists && flag & LDP_ATTR_MSGID) {
+    memcpy(&attr->lblMsgIdTlv, &map->lblMsgIdTlv, sizeof(mplsLdpLblMsgIdTlv_t));
+    attr->lblMsgIdTlvExists = 1;
+  }
+  if (map->lspidTlvExists && flag & LDP_ATTR_LSPID) {
+    memcpy(&attr->lspidTlv, &map->lspidTlv, sizeof(mplsLdpLspIdTlv_t));
+    attr->lspidTlvExists = 1;
+  }
+  if (map->trafficTlvExists && flag & LDP_ATTR_TRAFFIC) {
+    memcpy(&attr->trafficTlv, &map->trafficTlv, sizeof(mplsLdpTrafficTlv_t));
+    attr->trafficTlvExists = 1;
+  }
+}
+
+void attr2map(ldp_attr * attr, mplsLdpLblMapMsg_t * map)
+{
+  if (attr->fecTlvExists) {
+    memcpy(&map->fecTlv, &attr->fecTlv, sizeof(mplsLdpFecTlv_t));
+    map->fecTlvExists = 1;
+  }
+  if (attr->genLblTlvExists) {
+    memcpy(&map->genLblTlv, &attr->genLblTlv, sizeof(mplsLdpGenLblTlv_t));
+    map->genLblTlvExists = 1;
+  }
+  if (attr->atmLblTlvExists) {
+    memcpy(&map->atmLblTlv, &attr->atmLblTlv, sizeof(mplsLdpAtmLblTlv_t));
+    map->atmLblTlvExists = 1;
+  }
+  if (attr->frLblTlvExists) {
+    memcpy(&map->frLblTlv, &attr->frLblTlv, sizeof(mplsLdpFrLblTlv_t));
+    map->frLblTlvExists = 1;
+  }
+  if (attr->hopCountTlvExists) {
+    memcpy(&map->hopCountTlv, &attr->hopCountTlv, sizeof(mplsLdpHopTlv_t));
+    map->hopCountTlvExists = 1;
+  }
+  if (attr->pathVecTlvExists) {
+    memcpy(&map->pathVecTlv, &attr->pathVecTlv, sizeof(mplsLdpPathTlv_t));
+    map->pathVecTlvExists = 1;
+  }
+  if (attr->lblMsgIdTlvExists) {
+    memcpy(&map->lblMsgIdTlv, &attr->lblMsgIdTlv, sizeof(mplsLdpLblMsgIdTlv_t));
+    map->lblMsgIdTlvExists = 1;
+  }
+  if (attr->lspidTlvExists) {
+    memcpy(&map->lspidTlv, &attr->lspidTlv, sizeof(mplsLdpLspIdTlv_t));
+    map->lspidTlvExists = 1;
+  }
+  if (attr->trafficTlvExists) {
+    memcpy(&map->trafficTlv, &attr->trafficTlv, sizeof(mplsLdpTrafficTlv_t));
+    map->trafficTlvExists = 1;
+  }
+}
+
+void ldp_label_mapping_initial_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle handle)
+{
+  ldp_session *s = (ldp_session *) extra;
+  ldp_global *g = (ldp_global*)handle;
+  ldp_attr *ds_attr = NULL;
+  ldp_attr *us_attr = NULL;
+  ldp_session *nh_session = NULL;
+  mpls_bool done = MPLS_BOOL_FALSE;
+  ldp_fec *f;
+  ldp_nexthop *nh;
+
+  LDP_ENTER(g->user_data, "ldp_label_mapping_initial_callback");
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_TIMER,
+    "Initial Label Mapping fired: session(%d)\n", s->index);
+
+  mpls_lock_get(g->global_lock);
+
+  mpls_timer_stop(g->timer_handle, timer);
+
+  f = MPLS_LIST_HEAD(&g->fec);
+  while (f) {
+    nh = MPLS_LIST_HEAD(&f->nh_root);
+    while (nh) {
+      switch (f->info.type) {
+	case MPLS_FEC_PREFIX:
+          LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+            LDP_TRACE_FLAG_ROUTE, "Processing prefix FEC: %08x/%d ",
+	    f->info.u.prefix.network.u.ipv4, f->info.u.prefix.length);
+	  break;
+	case MPLS_FEC_HOST:
+          LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+            LDP_TRACE_FLAG_ROUTE, "Processing host FEC: %08x ",
+	    f->info.u.host.u.ipv4);
+	  break;
+	case MPLS_FEC_L2CC:
+          LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+            LDP_TRACE_FLAG_ROUTE, "Processingu L2CC FEC: %d %d %d ",
+	    f->info.u.l2cc.connection_id, f->info.u.l2cc.group_id, 
+	    f->info.u.l2cc.type);
+	  break;
+	default:
+	  MPLS_ASSERT(0);
+      }
+
+      if (nh->info.type & MPLS_NH_IP) {
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+          LDP_TRACE_FLAG_ROUTE, "via %08x\n", nh->addr->address.u.ipv4);
+      }
+      if (nh->info.type & MPLS_NH_IF && nh->iff) {
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+          LDP_TRACE_FLAG_ROUTE, "via %p\n", nh->iff->handle);
+      }
+
+      /* are we allowed to export this route from the rib */
+      if (mpls_policy_export_check(g->user_data, &f->info, &nh->info) ==
+        MPLS_BOOL_FALSE) {
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+	  LDP_TRACE_FLAG_POLICY, "Rejected by export policy\n");
+        goto ldp_label_mapping_initial_callback_end_nh;
+      }
+
+      /* have we already sent a mapping for this fec to the new session? */
+      if ((us_attr = ldp_attr_find_upstream_state2(g, s, f,
+        LDP_LSP_STATE_MAP_SENT))) {
+        /* no need to sent another mapping */
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+          LDP_TRACE_FLAG_ROUTE, "Already sent this FEC to session %d\n",
+	  s->index);
+        goto ldp_label_mapping_initial_callback_end_nh;
+      }
+
+      if (!(nh_session = ldp_get_next_hop_session_for_fec2(f,nh))) {
+        ds_attr = NULL;
+      } else {
+        if (nh_session->index == s->index) {
+          LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+            LDP_TRACE_FLAG_ROUTE, "Nexthop session(%d) == session(%d)\n",
+            nh_session->index, s->index);
+          goto ldp_label_mapping_initial_callback_end_nh;
+        }
+        ds_attr = ldp_attr_find_downstream_state2(g, nh_session, f,
+          LDP_LSP_STATE_MAP_RECV);
+      }
+
+      if ((g->label_merge != MPLS_BOOL_TRUE) &&
+        ldp_attr_num_us2ds(ds_attr)) {
+        /* we have a ds label, but can't use it */
+        ds_attr = NULL;
+      }
+
+      us_attr = NULL;
+      if (ds_attr) {
+        /* we can use it, merge on baby */
+        ldp_label_mapping_with_xc(g, s, f, &us_attr, ds_attr);
+      } else {
+        /* we don't have a ds label */
+
+        /* we will be egress? */
+        if (g->lsp_control_mode == LDP_CONTROL_ORDERED) {
+          if (mpls_policy_egress_check(g->user_data, &f->info,
+	    &nh->info) == MPLS_BOOL_TRUE) {
+            ldp_label_mapping_with_xc(g, s, f, &us_attr, NULL);
+          }
+        } else {
+          ldp_label_mapping_with_xc(g, s, f, &us_attr, NULL);
+        }
+      }
+ldp_label_mapping_initial_callback_end_nh:
+      nh = MPLS_LIST_NEXT(&f->nh_root, nh, _fec);
+    }
+    f = MPLS_LIST_NEXT(&g->fec, f, _global);
+  }
+  done = MPLS_BOOL_TRUE;
+
+  if (done == MPLS_BOOL_TRUE) {
+    mpls_timer_delete(g->timer_handle, timer);
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+    s->initial_distribution_timer = (mpls_timer_handle) 0;
+  } else {
+    mpls_timer_start(g->timer_handle, timer, MPLS_TIMER_ONESHOT);
+    /* need to mark the session with where it left off */
+  }
+
+  mpls_lock_release(g->global_lock);
+
+  LDP_EXIT(g->user_data, "ldp_label_mapping_initial_callback");
+}
+
+mpls_return_enum ldp_label_mapping_send(ldp_global * g, ldp_session * s,
+  ldp_fec *f, ldp_attr * us_attr, ldp_attr * ds_attr)
+{
+  ldp_inlabel *in = NULL;
+  ldp_attr *us_temp, *existing = NULL;
+
+  LDP_ENTER(g->user_data, "ldp_label_mapping_send");
+  MPLS_ASSERT(us_attr);
+
+#if 0
+  /*
+   * before we can enable this, inlabels need to keep track of all of
+   * the attr that link to it.  Then when running in DU independent mode we
+   * can correctly attach the us and ds attrs involved when propogating a
+   * new mapping for a FEC we've already distributed labels for
+   */
+  existing = ldp_attr_find_upstream_map_in_labelspace(f, s->cfg_label_space);
+#endif
+
+  if (existing) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_BINDING,
+      "Using an existing label\n");
+    in = existing->inlabel;
+    ldp_attr_add_inlabel(g, us_attr, in);
+  } else {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_BINDING,
+      "Generating a label\n");
+    in = ldp_inlabel_create_complete(g, s, us_attr);
+  }
+
+  if (!in) { /* SL.1-3 */
+    goto Send_Label_9;
+  }
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_BINDING,
+    "In Label Added\n");
+
+  us_attr->state = LDP_LSP_STATE_MAP_SENT;
+
+  us_attr->msg_id = g->message_identifier;
+  ldp_label_mapping_prepare_msg(s->tx_message, g->message_identifier++,
+    us_attr);
+
+  if (ldp_mesg_send_tcp(g, s, s->tx_message) != MPLS_SUCCESS) { /* SL.4 */
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_ERROR,
+      "Failed sending Label Mapping to %s\n",
+      s->session_name);
+    goto ldp_label_mapping_send_error;
+  }
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_LABEL,
+    "Label Mapping Sent to %s for %08x/%d\n",
+    s->session_name,
+    us_attr->fecTlv.fecElArray[0].addressEl.address,
+    us_attr->fecTlv.fecElArray[0].addressEl.preLen);
+
+  us_attr->state = LDP_LSP_STATE_MAP_SENT; /* SL.6,7 */
+
+  LDP_EXIT(g->user_data, "ldp_label_mapping_send");
+  return MPLS_SUCCESS;           /* SL.8 */
+
+Send_Label_9:
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_STATE,
+    "No Label Resources\n");
+
+  while ((us_temp = ldp_attr_find_upstream_state2(g, s, us_attr->fec,
+        LDP_LSP_STATE_REQ_RECV)) != NULL) { /* SL.9 */
+    ldp_notif_send(g, s, us_temp, LDP_NOTIF_NO_LABEL_RESOURCES_AVAILABLE);
+    /* SL.10 */
+    s->no_label_resource_sent = MPLS_BOOL_TRUE; /* SL.12 */
+    us_temp->state = LDP_LSP_STATE_NO_LABEL_RESOURCE_SENT; /* SL.13 */
+  }
+
+  LDP_EXIT(g->user_data, "ldp_label_mapping_send");
+
+  return MPLS_SUCCESS;
+
+ldp_label_mapping_send_error:
+
+  LDP_EXIT(g->user_data, "ldp_label_mapping_send-error");
+  return MPLS_FAILURE;
+}
+
+void ldp_label_mapping_prepare_msg(ldp_mesg * msg, uint32_t msgid,
+  ldp_attr * s_attr)
+{
+  mplsLdpLblMapMsg_t *map = NULL;
+  int i;
+
+  MPLS_ASSERT(msg);
+
+  ldp_mesg_prepare(msg, MPLS_LBLMAP_MSGTYPE, msgid);
+  map = &msg->u.map;
+
+  if (s_attr->fecTlvExists) {
+    /* JLEU: only 1 FEC is allowed!! */
+    map->fecTlvExists = 1;
+    map->baseMsg.msgLength += setupFecTlv(&map->fecTlv);
+    map->baseMsg.msgLength += addFecElem2FecTlv(&map->fecTlv,
+      &s_attr->fecTlv.fecElArray[0]);
+  }
+  if (s_attr->genLblTlvExists) {
+    map->genLblTlvExists = 1;
+    map->baseMsg.msgLength += setupGenLblTlv(&map->genLblTlv,
+      s_attr->genLblTlv.label);
+  }
+  if (s_attr->atmLblTlvExists) {
+    map->atmLblTlvExists = 1;
+    map->baseMsg.msgLength += setupAtmLblTlv(&map->atmLblTlv, 0, 0,
+      s_attr->atmLblTlv.flags.flags.vpi, s_attr->atmLblTlv.vci);
+  }
+  if (s_attr->frLblTlvExists) {
+    map->frLblTlvExists = 1;
+    map->baseMsg.msgLength += setupFrLblTlv(&map->frLblTlv, 0,
+      s_attr->frLblTlv.flags.flags.len, s_attr->frLblTlv.flags.flags.dlci);
+  }
+  if (s_attr->hopCountTlvExists) {
+    map->hopCountTlvExists = 1;
+    map->baseMsg.msgLength += setupHopCountTlv(&map->hopCountTlv,
+      s_attr->hopCountTlv.hcValue);
+  }
+  if (s_attr->pathVecTlvExists) {
+    map->pathVecTlvExists = 1;
+    map->baseMsg.msgLength += setupPathTlv(&map->pathVecTlv);
+    for (i = 0; i < MPLS_MAXHOPSNUMBER; i++) {
+      if (s_attr->pathVecTlv.lsrId[i]) {
+        map->baseMsg.msgLength += addLsrId2PathTlv(&map->pathVecTlv,
+          s_attr->pathVecTlv.lsrId[i]);
+      }
+    }
+  }
+#if 0
+  if (s_attr->lblMsgIdTlvExists) {
+  }
+  if (s_attr->lspidTlvExists) {
+  }
+  if (s_attr->trafficTlvExists) {
+  }
+#endif
+}
+
+mpls_return_enum ldp_label_mapping_process(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, ldp_attr * r_attr, ldp_fec * f)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+  ldp_session *peer = NULL;
+  ldp_attr_list *us_list = NULL;
+  ldp_attr_list *ds_list = NULL;
+  ldp_attr *ds_attr = NULL;
+  ldp_attr *ds_temp = NULL;
+  ldp_attr *us_attr = NULL;
+  ldp_attr *us_temp = NULL;
+  ldp_attr dumb_attr;
+  ldp_nexthop *nh = NULL;
+
+  ldp_outlabel *out = NULL;
+  mpls_bool requested = MPLS_BOOL_FALSE;
+  ldp_attr *existing = NULL;
+  mpls_bool need_request = MPLS_BOOL_FALSE;
+
+  LDP_ENTER(g->user_data, "ldp_label_mapping_process");
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+    "Label Mapping Recv from %s for %08x/%d\n",
+    s->session_name,
+    r_attr->fecTlv.fecElArray[0].addressEl.address,
+    r_attr->fecTlv.fecElArray[0].addressEl.preLen);
+
+  if ((ds_attr = ldp_attr_find_downstream_state2(g, s, f,
+        LDP_LSP_STATE_REQ_SENT)) != NULL) { /* LMp.1 */
+    /* just remove the req from the tree, we will use the r_attr sent to us */
+    ldp_attr_delete_downstream(g, s, ds_attr);
+    requested = MPLS_BOOL_TRUE;
+  } else {
+    requested = MPLS_BOOL_FALSE;
+  }
+
+  ds_attr = r_attr;
+  ds_attr->state = LDP_LSP_STATE_MAP_RECV; /* LMp.2 */
+
+  /*
+   * ds_attr is the mapping we will keep and is NOT in the tree, unless
+   * it is an update mapping ...
+   */
+  if (Check_Received_Attributes(g, s, ds_attr, MPLS_LBLMAP_MSGTYPE) ==
+    MPLS_SUCCESS) { /* LMp.3 */
+    goto LMp_9;
+  }
+
+  /*
+   * A loop was detected
+   */
+  if ((ds_list = ldp_attr_find_downstream_all2(g, s, f))) {
+    ds_temp = MPLS_LIST_HEAD(ds_list);
+    /*
+     * check all the labels this session has received from "s" for "fec"
+     * do we have a duplicat?
+     */
+    while (ds_temp) {
+      if ((ds_temp->state == LDP_LSP_STATE_MAP_RECV) && /* LMp.4 */
+        ldp_attr_is_equal(ds_temp, ds_attr, LDP_ATTR_LABEL) == /* LMp.5 */
+        MPLS_BOOL_TRUE) {
+        /* remove record of the label and remove it switching */
+        ldp_attr_remove_complete(g, ds_temp, MPLS_BOOL_TRUE); /* LMp.6,7 */
+        /*
+         * I think this is supposed to be 32 NOT 33, we need to release
+         * it don't we?
+         */
+        goto LMp_33;
+      }
+      ds_temp = MPLS_LIST_NEXT(ds_list, ds_temp, _fs);
+    }
+  }
+
+  LDP_PRINT(g->user_data, "Receive_Label_Map_8: send release");
+  if (ldp_label_release_send(g, s, ds_attr, LDP_NOTIF_LOOP_DETECTED) !=
+    MPLS_SUCCESS) { /* LMp.8 */
+    retval = MPLS_FAILURE;
+  }
+  goto LMp_33;
+
+LMp_9:
+  /*
+   * No Loop Detected
+   */
+  ds_temp = ldp_attr_find_downstream_state2(g, s, f, LDP_LSP_STATE_MAP_RECV);
+  if (requested == MPLS_BOOL_TRUE ||
+      g->label_merge == MPLS_BOOL_FALSE || !ds_temp) {
+    /* !merging then this is always a new LSP
+     * merging w/o a recv'd mapping is a new LSP
+     * this check comes from Note 6
+     */
+    goto LMp_11;
+  }
+
+  /* searching all recv'd attrs for matched mappings,
+   * stop after finding 1st match
+   */
+  if ((ds_list = ldp_attr_find_downstream_all2(g, s, f))) {
+    ds_temp = MPLS_LIST_HEAD(ds_list);
+    while (ds_temp) {
+      if (ds_temp->state == LDP_LSP_STATE_MAP_RECV) { /* LMp.9 */
+        if (ldp_attr_is_equal(ds_attr, ds_temp, LDP_ATTR_LABEL) ==
+          MPLS_BOOL_TRUE) { /* LMp.10 */
+          /*
+           * this mapping matches an existing mapping, but it
+           * could contain updated attributes
+           */
+          existing = ds_temp;
+          break;
+        } else {
+          /*
+           * we have been given another label for the same FEC and we
+           * didn't request it, release it
+           */
+          LDP_PRINT(g->user_data, "LMp.10 dup without req\n");
+          goto LMp_32;
+        }
+      }
+      ds_temp = MPLS_LIST_NEXT(ds_list, ds_temp, _fs);
+    }
+  }
+  if (existing) {
+    ldp_attr2ldp_attr(ds_attr, existing, LDP_ATTR_HOPCOUNT | LDP_ATTR_PATH |
+      LDP_ATTR_MSGID | LDP_ATTR_LSPID | LDP_ATTR_TRAFFIC);
+    ds_attr = existing;
+    /*
+     * no need to free ds_attr, since it was not added to the tree it
+     * will be deleted when we exit ldp_label_mapping_process(), see
+     * ldp_state_process().
+     */
+  }
+  /*
+   * from this point on.... if this is an updated mapping then ds_attr
+   * is the existing mapping which has now been update, else ds_attr
+   * is the new mapping
+   */
+
+LMp_11:
+  /*
+   * existing ONLY has a value for updated label mapping
+   */
+  nh = ldp_nexthop_for_fec_session(f,s);			 /* LMp.11 */
+
+  /*
+   * the following departs from the procedure, it allows for filtering
+   * of label mappings
+   *
+   * Are we configured to accept and INSTALL this mapping?
+   */
+  if (mpls_policy_import_check(g->user_data, &f->info, &nh->info) ==
+    MPLS_BOOL_FALSE) {
+    /*
+     * policy has rejected it, store it away
+     */
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+      "Label Mapping for %08x/%d from %s filtered by import policy\n",
+      r_attr->fecTlv.fecElArray[0].addressEl.address,
+      r_attr->fecTlv.fecElArray[0].addressEl.preLen, s->session_name);
+
+    if (existing) {
+      ds_attr->filtered = MPLS_BOOL_TRUE;
+      if (ds_attr->outlabel && ds_attr->outlabel->switching == MPLS_BOOL_TRUE) {
+        /* the mapping has been filtered, but the original wasn't? */
+        MPLS_ASSERT(0);
+      }
+    } else {
+      ds_attr->filtered = MPLS_BOOL_TRUE;
+      if (ldp_attr_insert_downstream(g, s, ds_attr) != MPLS_SUCCESS) {
+        retval = MPLS_FAILURE;
+      }
+    }
+    goto LMp_33;
+  }
+
+  if (!nh) {							 /* LMp.12 */
+    /*
+     * if we did not find a nh hop for this FEC that corresponded to the
+     * MsgSource then the MsgSource is not a nexthop for the FEC
+     */
+    if (g->label_retention_mode == LDP_RETENTION_CONSERVATIVE) { /* LMp.13C */
+      LDP_PRINT(g->user_data, "LMp.13C conservative\n");
+      goto LMp_32;
+    }
+
+    /*
+     * store it away
+     */
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+      "Session %s is not a valid nexthop for %08x/%d\n", s->session_name,
+      r_attr->fecTlv.fecElArray[0].addressEl.address,
+      r_attr->fecTlv.fecElArray[0].addressEl.preLen);
+
+    if (!existing) {
+      /* LMp.13L */
+      if (ldp_attr_insert_downstream(g, s, ds_attr) != MPLS_SUCCESS) {
+        retval = MPLS_FAILURE;
+      }
+    }
+    goto LMp_33;
+  }
+
+  /*
+   * this is slightly different form the procedure, we can still be
+   * transit for a FEC we are not configured to be ingress for.
+   * Either way we only need to do the "install for fwd/switching"
+   * only once.  We could arrive here multiple times due to updates,
+   * only install it the first time
+   */
+  if ((!existing) || (!existing->outlabel)) {
+    /*
+     * we haven't installed it yet.
+     * Either new (!existing), or a result of a "Detect FEC Nexthop Change"
+     * and we had this mapping in our database (!existing->outlabel))
+     */
+
+    if (!(out = ldp_outlabel_create_complete(g, s, ds_attr, nh))) {
+      LDP_PRINT(g->user_data, "LMp.15 failure creating outlabel\n");
+      goto LMp_32;
+    }
+
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_BINDING,
+      "Out Label Added\n");
+  }
+
+  /*
+   * are we configured to act as ingress for this FEC?
+   */
+  if (mpls_policy_ingress_check(g->user_data, &f->info, &nh->info) ==
+    MPLS_BOOL_TRUE) { /* LMp.14 */
+    /*
+     * yep, bind the label to the FEC
+     */
+    if (ds_attr->ingress != MPLS_BOOL_TRUE) {
+#if MPLS_USE_LSR
+      lsr_ftn ftn;
+      ftn.outsegment_index = ds_attr->outlabel->info.handle;
+      memcpy(&ftn.fec, &f->info, sizeof(mpls_fec));
+      lsr_cfg_ftn_set2(g->lsr_handle, &ftn, LSR_CFG_ADD|LSR_FTN_CFG_FEC|
+        LSR_FTN_CFG_OUTSEGMENT);
+#else
+      mpls_mpls_fec2out_add(g->mpls_handle, &f->info, &ds_attr->outlabel->info);
+#endif
+      ds_attr->ingress = MPLS_BOOL_TRUE;
+      ds_attr->outlabel->merge_count++;
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_BINDING,
+        "Acting as ingress for %08x/%d from %s\n",
+        r_attr->fecTlv.fecElArray[0].addressEl.address,
+        r_attr->fecTlv.fecElArray[0].addressEl.preLen, s->session_name);
+    }
+  }
+
+  /* create a set of attrs that we will fill and compare against
+   * if this mapping were to be propogate these are the attrs it would have
+   * by comparing what we did sent in the past to these, we con figure out
+   * if we need to send an updated mapping
+   */
+  memset(&dumb_attr, 0, sizeof(ldp_attr));
+  mpls_fec2fec_tlv(&f->info, &dumb_attr.fecTlv, 0);
+  dumb_attr.fecTlvExists = 1;
+  dumb_attr.fecTlv.numberFecElements = 1;
+
+  /*
+   * by definition (we received a label mapping that will be used) this
+   * LSR is _not_ the egress, so calculate a hop and path based on the
+   * mapping we received.  We will compare this with mapping that have
+   * already been sent.  If they differ, we will send an updated mapping
+   */
+  Prepare_Label_Mapping_Attributes(g, s, &f->info, ds_attr, &dumb_attr,
+    MPLS_BOOL_TRUE, MPLS_BOOL_TRUE, MPLS_BOOL_FALSE);
+
+  if (!existing) {
+    /*
+     * this is the first time we've seen this mapping, add it to the database.
+     * all future updates will modify this entry in place
+     */
+    /* LMp.16 */
+    if (ldp_attr_insert_downstream(g, s, ds_attr) != MPLS_SUCCESS) {
+      retval = MPLS_FAILURE;
+      goto LMp_33;
+    }
+  }
+
+  peer = MPLS_LIST_HEAD(&g->session);
+  while (peer) {					/* LMp.17 */
+
+    /* can't send messages to non-operational sessions */
+    if (peer->state != LDP_STATE_OPERATIONAL) {
+      goto next_peer;
+    }
+
+    /*
+     * don't send the mapping to the session
+     * from which we recv'd the mapping
+     */
+    if (peer->index == s->index) {
+      goto next_peer;
+    }
+
+    /*
+     * it is just as easy to walk the list of all upstream attr for this
+     * peer as it is to the individual check to see if we have sent a
+     * label mapping for this FEC LSP
+     */
+
+    /* LMp.22 - 27 */
+    if ((us_list = ldp_attr_find_upstream_all2(g, peer, f))) {
+      us_temp = MPLS_LIST_HEAD(us_list);
+      while (us_temp) {
+	/*
+	 * if we have sent a label mapping for the FEC and that label mapping
+	 * was an done in independent mode or it is part of an LSP created
+         * due as part of an existing received label mapping
+	 */
+	/* LMp.18 */
+        if (us_temp->state == LDP_LSP_STATE_MAP_SENT) {
+
+          LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+            LDP_TRACE_FLAG_BINDING, "Already sent mapping for %08x/%d to %s\n",
+            r_attr->fecTlv.fecElArray[0].addressEl.address,
+            r_attr->fecTlv.fecElArray[0].addressEl.preLen, peer->session_name);
+
+          if ((!existing) || (existing->index == us_temp->ds_attr->index)) {
+
+            LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+              LDP_TRACE_FLAG_BINDING, "Part of same LSP\n");
+
+            /* LMp.23 */
+            if (ldp_attr_is_equal(us_temp, &dumb_attr,
+                LDP_ATTR_HOPCOUNT | LDP_ATTR_PATH) != MPLS_BOOL_TRUE) {
+
+              LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV,
+                LDP_TRACE_FLAG_BINDING, "Propogating updated attrs\n");
+
+              /* send an updated label mapping */
+              if (ldp_label_mapping_with_xc(g, us_temp->session, f, &us_temp,
+                  ds_attr) != MPLS_SUCCESS) {			/* LMp.24-26 */
+                retval = MPLS_FAILURE;
+                goto LMp_33;
+              }
+            }
+          }
+        }
+        us_temp = MPLS_LIST_NEXT(us_list, us_temp, _fs);
+      }
+    }
+
+    if ((peer->oper_distribution_mode == LDP_DISTRIBUTION_UNSOLICITED) &&
+      (g->lsp_control_mode == LDP_CONTROL_ORDERED)) { /* LMp.19 */
+
+      /*
+       * if we're not merging and we have multiple ORDERED DU sessions,
+       * we will need to start requesting labels after we propogate the
+       * mapping to the first peer
+       */
+      if (need_request == MPLS_BOOL_TRUE) {
+        if (ldp_attr_find_downstream_state2(g, peer, f,
+            LDP_LSP_STATE_REQ_SENT) == NULL) {
+          /*
+           * we don't have a request for FEC to peer outstanding, make one
+           */
+          ds_temp = NULL;
+          if (ldp_label_request_for_xc(g, peer, &f->info, NULL, &ds_temp) !=
+            MPLS_SUCCESS) {
+            retval = MPLS_FAILURE;
+            goto LMp_33;
+          }
+        }
+      } else {
+        /*
+         * We're in DU more, either we're merging, or we're not merging and
+         * this is the first peer we're propogating this mapping to
+         */
+        /* LMp.20-21,30 */
+        us_attr = NULL;
+        if (ldp_label_mapping_with_xc(g, peer, f, &us_attr, ds_attr) !=
+          MPLS_SUCCESS) {
+          retval = MPLS_FAILURE;
+          goto LMp_33;
+        }
+        /*
+         * if we're not merging, we will need to request a label for
+         * the next DU peer
+         */
+        if (g->label_merge == MPLS_BOOL_FALSE) {
+          need_request = MPLS_BOOL_TRUE;
+        }
+      }
+    }
+
+    /* LMp.28 */
+    while ((us_temp = ldp_attr_find_upstream_state2(g, peer, f,
+      LDP_LSP_STATE_REQ_RECV))) {
+
+      if (peer->oper_distribution_mode == LDP_DISTRIBUTION_UNSOLICITED) {
+        if (need_request == MPLS_BOOL_TRUE) {
+          if (ldp_attr_find_downstream_state2(g, peer, f,
+            LDP_LSP_STATE_REQ_SENT) == NULL) {
+            /* 
+             * we don't have a request for FEC to peer outstanding
+             */
+            ds_temp = NULL;
+            if (ldp_label_request_for_xc(g, peer, &f->info, us_temp,
+                &ds_temp) != MPLS_SUCCESS) {
+              retval = MPLS_FAILURE;
+              goto LMp_33;
+            }
+          }
+        } else {
+          if (ldp_label_mapping_with_xc(g, peer, f, &us_temp,
+            ds_attr) != MPLS_SUCCESS) {
+            retval = MPLS_FAILURE;
+            goto LMp_33;
+          }
+        }
+      } else {
+        if ((us_list = ldp_attr_find_upstream_all2(g, peer, f))) {
+          us_temp = MPLS_LIST_HEAD(ds_list);
+          while (us_temp) {
+            if (us_temp->state == LDP_LSP_STATE_REQ_RECV) {
+              if (need_request == MPLS_BOOL_TRUE) {
+                if (ldp_attr_find_downstream_state2(g, peer, f,
+                  LDP_LSP_STATE_REQ_SENT) == NULL) {
+                  /*
+                   * we don't have a request for FEC to peer outstanding
+                   */
+                  ds_temp = NULL;
+                  if (ldp_label_request_for_xc(g, peer, &f->info, us_temp,
+                      &ds_temp) != MPLS_SUCCESS) {
+                    retval = MPLS_FAILURE;
+                    goto LMp_33;
+                  }
+                }
+              } else {
+                if (ldp_label_mapping_with_xc(g, peer, f, &us_temp,
+                    ds_attr) != MPLS_SUCCESS) {
+                  retval = MPLS_FAILURE;
+                  goto LMp_33;
+                }
+                /*
+                 * if we're not merging, we will need to request a label for
+                 * the next DU peer
+                 */
+                if (g->label_merge == MPLS_BOOL_FALSE) {
+                  need_request = MPLS_BOOL_TRUE;
+                }
+              }
+            }
+            us_temp = MPLS_LIST_NEXT(us_list, us_temp, _fs);
+          }
+        }
+      }
+    }
+
+  next_peer:
+    peer = MPLS_LIST_NEXT(&g->session, peer, _global);
+  }
+
+LMp_33:
+  LDP_EXIT(g->user_data, "ldp_label_mapping_process");
+  return retval;
+
+LMp_32:
+  LDP_PRINT(g->user_data, "Receive_Label_Map_32: send release");
+  if (ldp_label_release_send(g, s, ds_attr, LDP_NOTIF_NONE) != MPLS_SUCCESS) {
+    retval = MPLS_FAILURE;
+  }
+  LDP_EXIT(g->user_data, "ldp_label_mapping_process");
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_label_mapping.h quagga-mpls/ldpd/ldp_label_mapping.h
--- quagga-0.99.10/ldpd/ldp_label_mapping.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_label_mapping.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,44 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_LABEL_MAPPING_H_
+#define _LDP_LABEL_MAPPING_H_
+#include "ldp_struct.h"
+
+extern mpls_return_enum ldp_label_mapping_with_xc(ldp_global * g,
+  ldp_session * s, ldp_fec * fec, ldp_attr ** us_attr, ldp_attr * ds_attr);
+
+extern void map2attr(mplsLdpLblMapMsg_t * map, ldp_attr * attr, uint32_t flag);
+extern void attr2map(ldp_attr * attr, mplsLdpLblMapMsg_t * map);
+
+extern void ldp_label_mapping_initial_callback(mpls_timer_handle timer,
+  void *extra, mpls_cfg_handle g);
+
+extern void ldp_label_mapping_prepare_msg(ldp_mesg * msg, uint32_t msgid,
+  ldp_attr * s_attr);
+extern mpls_return_enum ldp_label_mapping_send(ldp_global * g, ldp_session * s,
+  ldp_fec *f, ldp_attr * us_attr, ldp_attr * ds_attr);
+
+extern mpls_return_enum ldp_label_mapping_process(ldp_global * g,
+  ldp_session * s, ldp_adj * a, ldp_entity * e, ldp_attr * r_attr,
+  ldp_fec * fec);
+
+extern mpls_return_enum Check_Received_Attributes(ldp_global * g,
+  ldp_session * s, ldp_attr * r_attr, uint16_t type);
+
+extern ldp_session *ldp_get_next_hop_session_for_fec2(ldp_fec *f,
+  ldp_nexthop *nh);
+extern mpls_return_enum ldp_get_next_hop_session_for_fec(ldp_global * g,
+  mpls_fec * fec, mpls_nexthop *nh, ldp_session ** next_hop_session);
+
+extern void Prepare_Label_Mapping_Attributes(ldp_global * g, ldp_session * s,
+  mpls_fec * fec, ldp_attr * r_attr, ldp_attr * s_attr, mpls_bool propogating,
+  mpls_bool already, mpls_bool egress);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_label_rel_with.c quagga-mpls/ldpd/ldp_label_rel_with.c
--- quagga-0.99.10/ldpd/ldp_label_rel_with.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_label_rel_with.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,294 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_attr.h"
+#include "ldp_session.h"
+#include "ldp_global.h"
+#include "ldp_inlabel.h"
+#include "ldp_entity.h"
+#include "ldp_outlabel.h"
+#include "ldp_label_rel_with.h"
+#include "ldp_nexthop.h"
+#include "ldp_label_mapping.h"
+#include "ldp_fec.h"
+#include "ldp_mesg.h"
+#include "ldp_pdu_setup.h"
+
+#include "mpls_trace_impl.h"
+
+mpls_bool rel_with2attr(mplsLdpLbl_W_R_Msg_t * rw, ldp_attr * attr)
+{
+  mpls_bool retval = MPLS_BOOL_FALSE;
+
+  if (rw->fecTlvExists) {
+    memcpy(&attr->fecTlv, &rw->fecTlv, sizeof(mplsLdpFecTlv_t));
+    attr->fecTlvExists = 1;
+  }
+  if (rw->genLblTlvExists) {
+    retval = MPLS_BOOL_TRUE;
+    memcpy(&attr->genLblTlv, &rw->genLblTlv, sizeof(mplsLdpGenLblTlv_t));
+    attr->genLblTlvExists = 1;
+  } else if (rw->atmLblTlvExists) {
+    retval = MPLS_BOOL_TRUE;
+    memcpy(&attr->atmLblTlv, &rw->atmLblTlv, sizeof(mplsLdpAtmLblTlv_t));
+    attr->atmLblTlvExists = 1;
+  } else if (rw->frLblTlvExists) {
+    retval = MPLS_BOOL_TRUE;
+    memcpy(&attr->frLblTlv, &rw->frLblTlv, sizeof(mplsLdpFrLblTlv_t));
+    attr->frLblTlvExists = 1;
+  }
+  return retval;
+}
+
+void ldp_label_rel_with_prepare_msg(ldp_mesg * msg, uint32_t msgid,
+  ldp_attr * a, ldp_notif_status status, uint16_t type)
+{
+  mplsLdpLbl_W_R_Msg_t *rw = NULL;
+
+  ldp_mesg_prepare(msg, type, msgid);
+  rw = &msg->u.release;
+  if (a->fecTlvExists) {
+    rw->fecTlvExists = 1;
+    rw->baseMsg.msgLength += setupFecTlv(&rw->fecTlv);
+    rw->baseMsg.msgLength += addFecElem2FecTlv(&rw->fecTlv,
+      &a->fecTlv.fecElArray[0]);
+  }
+  if (a->genLblTlvExists) {
+    rw->genLblTlvExists = 1;
+    rw->baseMsg.msgLength += setupGenLblTlv(&rw->genLblTlv, a->genLblTlv.label);
+  }
+  if (a->atmLblTlvExists) {
+    rw->atmLblTlvExists = 1;
+    rw->baseMsg.msgLength += setupAtmLblTlv(&rw->atmLblTlv, 0, 0,
+      a->atmLblTlv.flags.flags.vpi, a->atmLblTlv.vci);
+  }
+  if (a->frLblTlvExists) {
+    rw->frLblTlvExists = 1;
+    rw->baseMsg.msgLength += setupFrLblTlv(&rw->frLblTlv, 0,
+      a->frLblTlv.flags.flags.len, a->frLblTlv.flags.flags.dlci);
+  }
+  if (a->lspidTlvExists) {
+    rw->lspidTlvExists = 1;
+    rw->baseMsg.msgLength += setupLspidTlv(&rw->lspidTlv, 0,
+      a->lspidTlv.localCrlspId, a->lspidTlv.routerId);
+  }
+}
+
+mpls_return_enum ldp_label_rel_with_send(ldp_global * g, ldp_session * s,
+  ldp_attr * a, ldp_notif_status status, uint16_t type)
+{
+  LDP_ENTER(g->user_data, "ldp_label_rel_with_send");
+
+  ldp_label_rel_with_prepare_msg(s->tx_message, g->message_identifier++, a,
+    status, type);
+
+  ldp_mesg_send_tcp(g, s, s->tx_message);
+
+  LDP_EXIT(g->user_data, "ldp_label_rel_with_send");
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_label_release_send(ldp_global * g, ldp_session * s,
+  ldp_attr * a, ldp_notif_status status)
+{
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_LABEL,
+    "Release Sent: session(%d)\n", s->index);
+
+  return ldp_label_rel_with_send(g, s, a, status, MPLS_LBLREL_MSGTYPE);
+}
+
+mpls_return_enum ldp_label_withdraw_send(ldp_global * g, ldp_session * s,
+  ldp_attr * us_attr, ldp_notif_status status)
+{
+
+  us_attr->state = LDP_LSP_STATE_WITH_SENT;
+  if (ldp_label_rel_with_send(g, s, us_attr, status, MPLS_LBLWITH_MSGTYPE) ==
+    MPLS_FAILURE) {
+    return MPLS_FAILURE;
+  }
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_LABEL,
+    "Withdraw Sent: session(%d)\n", s->index);
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_label_release_process(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, ldp_attr * r_attr, ldp_fec * f)
+{
+  mpls_bool label_exists = MPLS_BOOL_FALSE;
+  ldp_attr *us_attr = NULL;
+  ldp_attr *ds_attr = NULL;
+  mpls_return_enum retval = MPLS_SUCCESS;
+
+  LDP_ENTER(g->user_data, "ldp_label_release_process");
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+    "Release Recv from %s\n", s->session_name);
+
+  if (r_attr->genLblTlvExists || r_attr->atmLblTlvExists
+    || r_attr->frLblTlvExists) {
+    label_exists = MPLS_BOOL_TRUE;
+  }
+
+  if (f) {
+    /* LRl.1 is accomplished at LRl.10 */
+    us_attr = ldp_attr_find_upstream_state2(g, s, f, LDP_LSP_STATE_MAP_SENT);
+    if (!us_attr) {
+      us_attr =
+        ldp_attr_find_upstream_state2(g, s, f, LDP_LSP_STATE_WITH_SENT);
+      if (!us_attr) {           /* LRl.2 */
+        goto LRl_13;
+      }
+      /* LRl.3 is accomplished at LRl.10 */
+    }
+
+    if (g->label_merge == MPLS_BOOL_FALSE) { /* LR1.4 */
+      goto LRl_6;
+    }
+    /* LR1.5 */
+    if (ldp_attr_find_upstream_state_any2(g, f, LDP_LSP_STATE_MAP_SENT)) {
+      goto LRl_10;
+    }
+
+  LRl_6:
+    /* we can only propogate a release to the downstream attached to
+       the upstream we found up top */
+    /* LRl.6,7 */
+    if (us_attr->ds_attr && us_attr->ds_attr->state == LDP_LSP_STATE_MAP_RECV) {
+      ds_attr = us_attr->ds_attr;
+    } else {
+      goto LRl_10;
+    }
+
+    if (g->propagate_release == MPLS_BOOL_FALSE) { /* LRl.8 */
+      goto LRl_10;
+    }
+
+    if (ldp_label_release_send(g, ds_attr->session, ds_attr,
+      LDP_NOTIF_NONE) != MPLS_SUCCESS) { /* LRl.9 */
+      retval = MPLS_FAILURE;
+    }
+    ldp_attr_remove_complete(g, ds_attr, MPLS_BOOL_FALSE);
+
+  LRl_10:
+    ldp_attr_remove_complete(g, us_attr, MPLS_BOOL_FALSE); /* LRl.10,11 */
+
+  } else {
+    LDP_PRINT(g->user_data, "No FEC in release, need to implement\n");
+    MPLS_ASSERT(0);
+  }
+
+LRl_13:
+  LDP_EXIT(g->user_data, "ldp_label_release_process");
+  return retval;
+}
+
+mpls_return_enum ldp_label_withdraw_process(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, ldp_attr * r_attr, ldp_fec * f)
+{
+  mpls_bool label_exists = MPLS_BOOL_FALSE;
+  ldp_attr_list *ds_list = NULL;
+  ldp_attr *ds_attr = NULL;
+  ldp_attr *ds_temp = NULL;
+  ldp_attr *us_temp = NULL;
+  ldp_nexthop *nh = NULL;
+  mpls_return_enum retval = MPLS_SUCCESS;
+
+  LDP_ENTER(g->user_data, "ldp_label_withdraw_process");
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+    "Withdraw Recv for %s\n", s->session_name);
+
+  if (r_attr->genLblTlvExists || r_attr->atmLblTlvExists
+    || r_attr->frLblTlvExists) {
+    label_exists = MPLS_BOOL_TRUE;
+  } else {
+    MPLS_ASSERT(0);
+  }
+
+  if (f) {
+    if ((ds_list = ldp_attr_find_downstream_all2(g, s, f)) != NULL) {
+      ds_temp = MPLS_LIST_HEAD(ds_list);
+      while (ds_temp) {
+        if (ds_temp->state == LDP_LSP_STATE_MAP_RECV) { /* LWd.3 */
+          if (ldp_attr_is_equal(r_attr, ds_temp, LDP_ATTR_LABEL)) {
+            ds_attr = ds_temp;
+	    break;
+          }
+        }
+        ds_temp = MPLS_LIST_NEXT(ds_list, ds_temp, _fs);
+      }
+    }
+
+    if (!ds_attr) {
+      retval = MPLS_FAILURE;
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_LABEL,
+        "Withdraw Recv for a non-existant mapping from %s\n",s->session_name);
+      goto LWd_13;
+    }
+
+    /*
+     * we want to remove it from the tree, but not delete it yet
+     * so hold a refcnt, we will release that refcnt at the end, thus
+     * deleting it if no one else it holding a refcnt
+     */
+    MPLS_REFCNT_HOLD(ds_attr);
+    ldp_attr_remove_complete(g, ds_attr, MPLS_BOOL_FALSE); /* LWd.4 */
+
+    /* LWd.2 */
+    if (ldp_label_release_send(g, s, ds_attr, LDP_NOTIF_NONE) != MPLS_SUCCESS) {
+      retval = MPLS_FATAL;
+      goto LWd_13;
+    }
+
+    if (g->lsp_control_mode == LDP_CONTROL_ORDERED) { /* LWd.5 */
+      goto LWd_8;
+    }
+
+    if (s->oper_distribution_mode != LDP_DISTRIBUTION_ONDEMAND) { /* LWd.6 */
+      goto LWd_13;
+    }
+
+    MPLS_ASSERT((nh = ldp_nexthop_for_fec_session(f, s)));
+    retval = ldp_fec_process_add(g, f, nh, s);	/* LWd.7 */
+    goto LWd_13;
+
+  LWd_8:
+    /* I can only propogate a label withdraw to the upstreams attached
+       to the downstream found above */
+
+    us_temp = MPLS_LIST_HEAD(&ds_attr->us_attr_root);
+    while (us_temp) {
+      if (us_temp->state == LDP_LSP_STATE_MAP_SENT) {
+        if (ldp_label_withdraw_send(g, us_temp->session, us_temp,
+            LDP_NOTIF_NONE) != MPLS_SUCCESS) { /* LWd.11 */
+          retval = MPLS_FATAL;
+          goto LWd_13;
+        }
+      }
+      us_temp = MPLS_LIST_NEXT(&ds_attr->us_attr_root, us_temp, _ds_attr);
+    }
+  } else {
+    /* JLEU: process wildcard FEC stuff here */
+    MPLS_ASSERT(0);
+  }
+
+LWd_13:
+  if (ds_attr) {
+    MPLS_REFCNT_RELEASE2(g, ds_attr, ldp_attr_delete);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_label_withdraw_process");
+
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_label_rel_with.h quagga-mpls/ldpd/ldp_label_rel_with.h
--- quagga-0.99.10/ldpd/ldp_label_rel_with.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_label_rel_with.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,27 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_LABEL_RELEASE_H_
+#define _LDP_LABEL_RELEASE_H_
+
+extern mpls_return_enum ldp_label_release_send(ldp_global *, ldp_session *,
+  ldp_attr *, ldp_notif_status);
+extern mpls_return_enum ldp_label_withdraw_send(ldp_global *, ldp_session *,
+  ldp_attr *, ldp_notif_status);
+extern mpls_bool rel_with2attr(mplsLdpLbl_W_R_Msg_t * rw, ldp_attr * attr);
+extern ldp_mesg *ldp_label_rel_with_create_msg(uint32_t msgid, ldp_attr * a,
+  ldp_notif_status status, uint16_t type);
+extern mpls_return_enum ldp_label_release_process(ldp_global * g,
+  ldp_session * s, ldp_adj * a, ldp_entity * e, ldp_attr * r_attr,
+  ldp_fec * fec);
+extern mpls_return_enum ldp_label_withdraw_process(ldp_global * g,
+  ldp_session * s, ldp_adj * a, ldp_entity * e, ldp_attr * r_attr,
+  ldp_fec * fec);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_label_request.c quagga-mpls/ldpd/ldp_label_request.c
--- quagga-0.99.10/ldpd/ldp_label_request.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_label_request.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,479 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_attr.h"
+#include "ldp_fec.h"
+#include "ldp_mesg.h"
+#include "ldp_pdu_setup.h"
+#include "ldp_notif.h"
+#include "ldp_session.h"
+#include "ldp_entity.h"
+#include "ldp_label_mapping.h"
+#include "ldp_label_request.h"
+
+#include "mpls_timer_impl.h"
+#include "mpls_policy_impl.h"
+#include "mpls_tree_impl.h"
+#include "mpls_trace_impl.h"
+#include "mpls_fib_impl.h"
+#include "mpls_lock_impl.h"
+
+mpls_return_enum ldp_label_request_for_xc(ldp_global * g, ldp_session * s,
+  mpls_fec * fec, ldp_attr * us_attr, ldp_attr ** ds_attr)
+{
+
+  LDP_ENTER(g->user_data, "ldp_label_request_for_xc");
+
+  if (!(*ds_attr)) {
+    if (!((*ds_attr) = ldp_attr_create(g, fec))) {
+      return MPLS_FATAL;
+    }
+    MPLS_REFCNT_HOLD((*ds_attr));
+  }
+  Prepare_Label_Request_Attributes(g, s, fec, (*ds_attr), us_attr);
+  (*ds_attr)->state = LDP_LSP_STATE_REQ_SENT;
+  if (ldp_label_request_send(g, s, us_attr, ds_attr) != MPLS_SUCCESS) {
+    return MPLS_FAILURE;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_label_request_for_xc");
+
+  return MPLS_SUCCESS;
+}
+
+void ldp_label_request_prepare_msg(ldp_mesg * msg, uint32_t msgid,
+  ldp_attr * s_attr)
+{
+  mplsLdpLblReqMsg_t *req = NULL;
+  int i;
+
+  ldp_mesg_prepare(msg, MPLS_LBLREQ_MSGTYPE, msgid);
+  req = &msg->u.request;
+
+  if (s_attr->fecTlvExists) {
+    req->fecTlvExists = 1;
+    req->baseMsg.msgLength += setupFecTlv(&req->fecTlv);
+    req->baseMsg.msgLength += addFecElem2FecTlv(&req->fecTlv,
+      &s_attr->fecTlv.fecElArray[0]);
+  }
+  if (s_attr->hopCountTlvExists) {
+    req->hopCountTlvExists = 1;
+    req->baseMsg.msgLength += setupHopCountTlv(&req->hopCountTlv,
+      s_attr->hopCountTlv.hcValue);
+  }
+  if (s_attr->pathVecTlvExists) {
+    req->pathVecTlvExists = 1;
+    req->baseMsg.msgLength += setupPathTlv(&req->pathVecTlv);
+    for (i = 0; i < MPLS_MAXHOPSNUMBER; i++) {
+      if (s_attr->pathVecTlv.lsrId[i]) {
+        req->baseMsg.msgLength += addLsrId2PathTlv(&req->pathVecTlv,
+          s_attr->pathVecTlv.lsrId[i]);
+      }
+    }
+  }
+}
+
+mpls_return_enum ldp_label_request_send(ldp_global * g, ldp_session * s,
+  ldp_attr * us_attr, ldp_attr ** ds_attr)
+{
+  ldp_attr *ds_temp;
+  mpls_fec fec;
+
+  LDP_ENTER(g->user_data, "ldp_label_request_send");
+  MPLS_ASSERT(ds_attr && *ds_attr);
+
+  fec_tlv2mpls_fec(&((*ds_attr)->fecTlv), 0, &fec);
+
+  if ((ds_temp = ldp_attr_find_downstream_state(g, s, &fec,
+        LDP_LSP_STATE_REQ_SENT)) != NULL) { /* SLRq.1 */
+
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_LABEL,
+      "Label Request Send: request already pending(%d)\n", ds_temp->index);
+
+    ldp_attr_add_us2ds(us_attr, ds_temp);
+
+    /* we do not need the one passed in, but make sure that the caller
+       is using this one from here forth */
+    ldp_attr_remove_complete(g, *ds_attr, MPLS_BOOL_TRUE);
+    *ds_attr = ds_temp;
+    return MPLS_SUCCESS;
+  }
+
+  if (s->no_label_resource_recv == MPLS_BOOL_TRUE) { /* SLRq.2 */
+    goto ldp_label_request_send_error;
+  }
+
+  (*ds_attr)->msg_id = g->message_identifier++;
+  ldp_label_request_prepare_msg(s->tx_message, (*ds_attr)->msg_id, *ds_attr);
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_LABEL,
+    "Label Request Sent: session(%d)\n", s->index);
+
+  if (ldp_mesg_send_tcp(g, s, s->tx_message) == MPLS_FAILURE) { /* SLRq.3 */
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_ERROR,
+      "Label Request send failed\n");
+    goto ldp_label_request_send_error;
+  }
+
+  (*ds_attr)->state = LDP_LSP_STATE_REQ_SENT;
+  if (ldp_attr_insert_downstream(g, s, (*ds_attr)) == MPLS_FAILURE) { /* SLRq.4 */
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_ERROR,
+      "Couldn't insert sent attributes in tree\n");
+    goto ldp_label_request_send_error;
+  }
+  if (us_attr) {
+    ldp_attr_add_us2ds(us_attr, *ds_attr);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_label_request_send");
+
+  return MPLS_SUCCESS;           /* SLRq.5 */
+
+ldp_label_request_send_error:
+
+  LDP_PRINT(g->user_data, "SLRq.6\n");
+  (*ds_attr)->state = LDP_LSP_STATE_NO_LABEL_RESOURCE_SENT;
+  ldp_attr_insert_downstream(g, s, (*ds_attr)); /* SLRq.6 */
+
+  LDP_EXIT(g->user_data, "ldp_label_request_send-error");
+
+  return MPLS_FAILURE;           /* SLRq.7 */
+}
+
+void req2attr(mplsLdpLblReqMsg_t * req, ldp_attr * attr, uint32_t flag)
+{
+  attr->msg_id = req->baseMsg.msgId;
+
+  if (req->fecTlvExists && flag & LDP_ATTR_FEC) {
+    memcpy(&attr->fecTlv, &req->fecTlv, sizeof(mplsLdpFecTlv_t));
+    attr->fecTlvExists = 1;
+  }
+  if (req->hopCountTlvExists && flag & LDP_ATTR_HOPCOUNT) {
+    memcpy(&attr->hopCountTlv, &req->hopCountTlv, sizeof(mplsLdpHopTlv_t));
+    attr->hopCountTlvExists = 1;
+  }
+  if (req->pathVecTlvExists && flag & LDP_ATTR_PATH) {
+    memcpy(&attr->pathVecTlv, &req->pathVecTlv, sizeof(mplsLdpPathTlv_t));
+    attr->pathVecTlvExists = 1;
+  }
+  if (req->lblMsgIdTlvExists && flag & LDP_ATTR_MSGID) {
+    memcpy(&attr->lblMsgIdTlv, &req->lblMsgIdTlv, sizeof(mplsLdpLblMsgIdTlv_t));
+    attr->lblMsgIdTlvExists = 1;
+  }
+  if (req->lspidTlvExists && flag & LDP_ATTR_LSPID) {
+    memcpy(&attr->lspidTlv, &req->lspidTlv, sizeof(mplsLdpLspIdTlv_t));
+    attr->lspidTlvExists = 1;
+  }
+  if (req->trafficTlvExists && flag & LDP_ATTR_TRAFFIC) {
+    memcpy(&attr->trafficTlv, &req->trafficTlv, sizeof(mplsLdpTrafficTlv_t));
+    attr->trafficTlvExists = 1;
+  }
+}
+
+void ldp_label_request_initial_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle handle)
+{
+  ldp_session *s = (ldp_session *)extra;
+  ldp_global *g = (ldp_global*)handle;
+  ldp_nexthop *nh = NULL;
+  ldp_fec *f = NULL;
+
+  ldp_session *nh_session = NULL;
+  mpls_bool done = MPLS_BOOL_FALSE;
+
+  ldp_attr *attr = NULL;
+  ldp_fs *fs = NULL;
+  ldp_attr *ds_attr = NULL;
+
+  LDP_ENTER(g->user_data, "ldp_label_request_initial_callback");
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_TIMER,
+    "Initial Label Request Callback fired: session(%d)\n", s->index);
+
+  mpls_lock_get(g->global_lock);
+
+  mpls_timer_stop(g->timer_handle, timer);
+
+  if ((f = MPLS_LIST_HEAD(&g->fec))) {
+    do {
+      if ((nh = MPLS_LIST_HEAD(&f->nh_root))) {
+        do {
+          switch (f->info.type) {
+            case MPLS_FEC_PREFIX:
+              LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+                LDP_TRACE_FLAG_ROUTE, "Processing prefix FEC: %08x/%d ",
+                f->info.u.prefix.network.u.ipv4, f->info.u.prefix.length);
+              break;
+            case MPLS_FEC_HOST:
+              LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+                LDP_TRACE_FLAG_ROUTE, "Processing host FEC: %08x ",
+                f->info.u.host.u.ipv4);
+              break;
+            case MPLS_FEC_L2CC:
+              LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+              LDP_TRACE_FLAG_ROUTE, "Processing L2CC FEC: %d %d %d ",
+                f->info.u.l2cc.connection_id, f->info.u.l2cc.group_id,
+                f->info.u.l2cc.type);
+              break;
+            default:
+              MPLS_ASSERT(0);
+          }
+
+          if (nh->info.type & MPLS_NH_IP) {
+            LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+              LDP_TRACE_FLAG_ROUTE, "via %08x\n", nh->addr->address.u.ipv4);
+          }
+          if (nh->info.type & MPLS_NH_IF) {
+            LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+              LDP_TRACE_FLAG_ROUTE, "via %p\n", nh->iff->handle);
+          }
+
+          /* check to see if export policy allows us to 'see' this route */
+          if (mpls_policy_export_check(g->user_data, &f->info, &nh->info)
+              == MPLS_BOOL_FALSE) {
+            LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+              LDP_TRACE_FLAG_DEBUG, "Rejected by export policy\n");
+            continue;
+          }
+
+	  /* find the next hop session corresponding to this FEC */
+	  nh_session = ldp_session_for_nexthop(nh);
+
+          /* do we have a valid next hop session, and is the nexp hop session
+           * this session? */
+          if ((!nh_session) || (nh_session->index != s->index)) {
+            continue;
+          }
+
+          /* have we already sent a label request to this peer for this FEC? */
+          if (ldp_attr_find_downstream_state(g, s, &f->info,
+	    LDP_LSP_STATE_REQ_SENT)) {
+            continue;
+          }
+
+          /* clear out info from the last FEC */
+          ds_attr = NULL;
+
+          /* jleu: duplicate code from ldp_attr_find_upstream_state_any */
+          fs = MPLS_LIST_HEAD(&f->fs_root_us);
+          while (fs) {
+            attr = MPLS_LIST_HEAD(&fs->attr_root);
+            while (attr) {
+              if (attr->state == LDP_LSP_STATE_REQ_RECV ||
+	        attr->state == LDP_LSP_STATE_MAP_SENT) {
+	        if (!ds_attr) {
+                  /* this is not neccessarily going to be XC'd to something */
+                  ldp_label_request_for_xc(g, s, &f->info, attr, &ds_attr);
+	        }
+	      }
+              attr = MPLS_LIST_NEXT(&fs->attr_root, attr, _fs);
+            }
+            fs = MPLS_LIST_NEXT(&f->fs_root_us, fs, _fec);
+          }
+      
+          if (!ds_attr) {
+            /*
+	     * we did not find any received requests or sent mappings so
+	     * send a request and xc it to nothing
+	     */
+            ldp_label_request_for_xc(g, s, &f->info, NULL, &ds_attr);
+          }
+        } while ((nh = MPLS_LIST_NEXT(&f->nh_root, nh, _fec)));
+      }
+    } while ((f = MPLS_LIST_NEXT(&g->fec, f, _global)));
+    done = MPLS_BOOL_TRUE;
+  }
+
+  if (done == MPLS_BOOL_TRUE) {
+    mpls_timer_delete(g->timer_handle, timer);
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+    s->initial_distribution_timer = (mpls_timer_handle) 0;
+  } else {
+    mpls_timer_start(g->timer_handle, timer, MPLS_TIMER_ONESHOT);
+    /* need to mark the session with where it left off */
+  }
+
+  mpls_lock_release(g->global_lock);
+
+  LDP_EXIT(g->user_data, "ldp_label_request_initial_callback");
+}
+
+void Prepare_Label_Request_Attributes(ldp_global * g, ldp_session * s,
+  mpls_fec * fec, ldp_attr * r_attr, ldp_attr * s_attr)
+{
+  int i;
+
+  MPLS_ASSERT(s && r_attr);
+
+  if (!(s->oper_loop_detection == LDP_LOOP_HOPCOUNT ||
+    s->oper_loop_detection == LDP_LOOP_HOPCOUNT_PATHVECTOR ||
+    r_attr->hopCountTlvExists)) { /* PRqA.1 */
+    return;
+  }
+
+/* is this LSR allowed to be an LER for FEC? *//* PRqA.2 */
+  /* some policy gunk needs to be checked here */
+  /* if not goto PRqA.6 */
+
+  s_attr->hopCountTlvExists = 1; /* PRqA.3 */
+  s_attr->hopCountTlv.hcValue = 1;
+
+  if (s->oper_loop_detection == LDP_LOOP_NONE) { /* PRqA.4 */
+    return;
+  }
+
+  if (g->label_merge == MPLS_BOOL_TRUE) { /* PRqA.5 */
+    return;
+  }
+  goto Prepare_Label_Request_Attributes_13;
+
+  if (r_attr && r_attr->hopCountTlvExists) { /* PRqA.6 */
+    s_attr->hopCountTlvExists = 1; /* PRqA.7 */
+    s_attr->hopCountTlv.hcValue = (r_attr->hopCountTlv.hcValue) ?
+      (r_attr->hopCountTlv.hcValue + 1) : 0;
+  } else {
+    s_attr->hopCountTlvExists = 1; /* PRqA.8 */
+    s_attr->hopCountTlv.hcValue = 0;
+  }
+
+  if (s->oper_loop_detection == LDP_LOOP_NONE) { /* PRqA.9 */
+    return;
+  }
+
+  if (r_attr && r_attr->pathVecTlvExists) { /* PRqA.10 */
+    goto Prepare_Label_Request_Attributes_12;
+  }
+
+  if (g->label_merge == MPLS_BOOL_TRUE) { /* PRqA.11 */
+    return;
+  }
+  goto Prepare_Label_Request_Attributes_13;
+
+Prepare_Label_Request_Attributes_12:
+  /* we only get to PRqA.12 if we have verified we have a r_attr */
+  s_attr->pathVecTlvExists = 1;
+  s_attr->pathVecTlv.lsrId[0] = g->lsr_identifier.u.ipv4;
+  for (i = 1; i < (MPLS_MAXHOPSNUMBER - 1); i++) {
+    if (r_attr->pathVecTlv.lsrId[i - 1]) {
+      s_attr->pathVecTlv.lsrId[i] = r_attr->pathVecTlv.lsrId[i - 1];
+    }
+  }
+  return;
+
+Prepare_Label_Request_Attributes_13:
+  s_attr->pathVecTlvExists = 1;
+  s_attr->pathVecTlv.lsrId[0] = g->lsr_identifier.u.ipv4;
+}
+
+mpls_return_enum ldp_label_request_process(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, ldp_attr * us_attr, ldp_fec * f)
+{
+  ldp_session *nh_session = NULL;
+  ldp_nexthop *nh = NULL;
+  ldp_attr_list *us_list = NULL;
+  mpls_bool egress = MPLS_BOOL_FALSE;
+  mpls_bool egress_flag = MPLS_BOOL_FALSE;
+  ldp_attr *ds_attr = NULL;
+  ldp_attr *us_temp = NULL;
+
+  if (Check_Received_Attributes(g, s, us_attr, MPLS_LBLREQ_MSGTYPE) !=
+    MPLS_SUCCESS) { /* LRp.1 */
+    goto LRq_13;
+  }
+
+  if (f == NULL) {
+    ldp_notif_send(g, s, us_attr, LDP_NOTIF_NO_ROUTE); /* LRq.5 */
+    goto LRq_13;
+  }
+
+  /* just find one valid nexthop session for now */
+  nh = MPLS_LIST_HEAD(&f->nh_root);
+  while (nh) {
+    if (!nh_session) {
+      nh_session = ldp_session_for_nexthop(nh);
+    }
+    if (egress_flag == MPLS_BOOL_FALSE) {
+      egress_flag = mpls_policy_egress_check(g->user_data, &f->info, &nh->info);
+    }
+    nh = MPLS_LIST_NEXT(&f->nh_root, nh, _fec);
+  }
+
+  if ((!nh_session) && (egress_flag == MPLS_BOOL_TRUE)) {
+    egress = MPLS_BOOL_TRUE;
+  }
+  if (nh_session != NULL && s->index == nh_session->index) { /* LRq.3 */
+    ldp_notif_send(g, s, us_attr, LDP_NOTIF_LOOP_DETECTED); /* LRq.4 */
+    goto LRq_13;
+  }
+
+  if ((us_list = ldp_attr_find_upstream_all2(g, s, f)) != NULL) {
+    us_temp = MPLS_LIST_HEAD(us_list);
+    while (us_temp != NULL) {
+      if (us_temp->state == LDP_LSP_STATE_REQ_RECV && /* LRq.6 */
+        us_temp->msg_id == us_attr->msg_id) { /* LRq.7 */
+        goto LRq_13;
+      }
+      us_temp = MPLS_LIST_NEXT(us_list, us_temp, _fs);
+    }
+  }
+
+  us_attr->state = LDP_LSP_STATE_REQ_RECV; /* LRq.8 */
+
+  if (ldp_attr_insert_upstream2(g, s, us_attr, f) != MPLS_SUCCESS) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_RECV, LDP_TRACE_FLAG_ERROR,
+      "Couldn't insert recv attributes in tree\n");
+    goto ldp_label_request_process_error;
+  }
+
+  if (nh_session) {
+    ds_attr = ldp_attr_find_downstream_state2(g, nh_session, f,
+      LDP_LSP_STATE_MAP_RECV);
+  } else {
+    ds_attr = NULL;
+  }
+
+  if (g->lsp_control_mode == LDP_CONTROL_INDEPENDENT) { /* LRq.9 */
+    if (ldp_label_mapping_with_xc(g, s, f, &us_attr, ds_attr) != MPLS_SUCCESS) {
+      goto ldp_label_request_process_error;
+    }
+
+    if (egress == MPLS_BOOL_TRUE || ds_attr) {
+      goto LRq_11;
+    }
+  } else {
+    if ((!(egress == MPLS_BOOL_TRUE || ds_attr)) ||
+        (g->label_merge == MPLS_BOOL_FALSE)) {
+      goto LRq_10;
+    }
+
+    if (ldp_label_mapping_with_xc(g, s, f, &us_attr, ds_attr) != MPLS_SUCCESS) {
+      goto ldp_label_request_process_error;
+    }
+    goto LRq_11;
+  }
+
+LRq_10:
+  ds_attr = NULL;
+  if (ldp_label_request_for_xc(g, nh_session, &f->info, us_attr, &ds_attr) !=
+    MPLS_SUCCESS) {
+    goto ldp_label_request_process_error;
+  }
+
+LRq_11:
+  /* the work done by LRq_11 is handled in ldp_label_mapping_with_xc() */
+LRq_13:
+  if (ds_attr != NULL && ds_attr->in_tree == MPLS_BOOL_FALSE) {
+    ldp_attr_remove_complete(g, ds_attr, MPLS_BOOL_FALSE);
+  }
+  return MPLS_SUCCESS;
+
+ldp_label_request_process_error:
+  return MPLS_FAILURE;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_label_request.h quagga-mpls/ldpd/ldp_label_request.h
--- quagga-0.99.10/ldpd/ldp_label_request.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_label_request.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,30 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_LABEL_REQUEST_H_
+#define _LDP_LABEL_REQUEST_H_
+#include "ldp_struct.h"
+
+extern void ldp_label_request_initial_callback(mpls_timer_handle timer,
+  void *extra, mpls_cfg_handle g);
+
+extern mpls_return_enum ldp_label_request_send(ldp_global * g, ldp_session * s,
+  ldp_attr * us_attr, ldp_attr ** ds_attr);
+
+extern mpls_return_enum ldp_label_request_process(ldp_global * g,
+  ldp_session * s, ldp_adj * a, ldp_entity * e, ldp_attr * r_attr,
+  ldp_fec * fec);
+
+extern void Prepare_Label_Request_Attributes(ldp_global * g, ldp_session * s,
+  mpls_fec * fec, ldp_attr * r_attr, ldp_attr * s_attr);
+
+extern mpls_return_enum ldp_label_request_for_xc(ldp_global * g, ldp_session * s, mpls_fec * fec, ldp_attr * us_attr, ldp_attr ** ds_attr);
+
+extern void req2attr(mplsLdpLblReqMsg_t * req, ldp_attr * attr, uint32_t flag);
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_main.c quagga-mpls/ldpd/ldp_main.c
--- quagga-0.99.10/ldpd/ldp_main.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_main.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,261 @@
+#include <zebra.h>
+
+#include "version.h"
+#include "getopt.h"
+#include "command.h"
+#include "thread.h"
+#include "filter.h"
+#include "memory.h"
+#include "prefix.h"
+#include "log.h"
+#include "privs.h"
+#include "sigevent.h"
+
+#include "ldp.h"
+#include "ldp_vty.h"
+#include "ldp_zebra.h"
+#include "ldp_interface.h"
+
+/* ldpd privileges */
+zebra_capabilities_t _caps_p [] =
+{
+  ZCAP_NET_RAW,
+  ZCAP_BIND,
+  ZCAP_NET_ADMIN,
+  ZCAP_SETID,
+};
+
+struct zebra_privs_t ldpd_privs =
+{
+#if defined(QUAGGA_USER) && defined(QUAGGA_GROUP)
+  .user = QUAGGA_USER,
+  .group = QUAGGA_GROUP,
+#endif
+#ifdef VTY_GROUP
+  .vty_group = VTY_GROUP,
+#endif
+  .caps_p = _caps_p,
+  .cap_num_p = sizeof(_caps_p)/sizeof(_caps_p[0]),
+  .cap_num_i = 0
+};
+
+/* Configuration filename and directory. */
+char config_default[] = SYSCONFDIR LDP_DEFAULT_CONFIG;
+
+/* LDPd options. */
+struct option longopts[] =
+{
+  { "daemon",      no_argument,       NULL, 'd'},
+  { "config_file", required_argument, NULL, 'f'},
+  { "pid_file",    required_argument, NULL, 'i'},
+  { "log_mode",    no_argument,       NULL, 'l'},
+  { "help",        no_argument,       NULL, 'h'},
+  { "vty_addr",    required_argument, NULL, 'A'},
+  { "vty_port",    required_argument, NULL, 'P'},
+  { "user",        required_argument, NULL, 'u'},
+  { "group",       required_argument, NULL, 'g'},
+  { "version",     no_argument,       NULL, 'v'},
+  { 0 }
+};
+
+/* Master of threads. */
+struct thread_master *master;
+
+/* Process ID saved for use by init system */
+char *pid_file = PATH_LDPD_PID;
+
+/* Help information display. */
+static void __attribute__ ((noreturn))
+usage (char *progname, int status)
+{
+  if (status != 0)
+    fprintf (stderr, "Try `%s --help' for more information.\n", progname);
+  else
+    {    
+      printf ("Usage : %s [OPTION...]\n\n\
+Daemon which manages LDP related configuration.\n\n\
+-d, --daemon       Runs in daemon mode\n\
+-f, --config_file  Set configuration file name\n\
+-i, --pid_file     Set process identifier file name\n\
+-A, --vty_addr     Set vty's bind address\n\
+-P, --vty_port     Set vty's port number\n\
+-u, --user         User and group to run as\n\
+-g, --group        Group to run as\n\
+-h, --help         Display this help and exit\n\
+-v, --version      Print program version\n\
+\n\
+Report bugs to %s\n", progname, ZEBRA_BUG_ADDRESS);
+    }
+  exit (status);
+}
+
+/* SIGHUP handler. */
+void 
+sighup (int sig)
+{
+  zlog (NULL, LOG_INFO, "SIGHUP received");
+}
+
+/* SIGINT handler. */
+void
+sigint (int sig)
+{
+  zlog (NULL, LOG_INFO, "Terminating on signal");
+  exit (0);
+}
+
+/* SIGUSR1 handler. */
+void
+sigusr1 (int sig)
+{
+  zlog_rotate (NULL);
+}
+
+struct quagga_signal_t ldp_signals[] =
+{
+  {
+    .signal = SIGHUP,
+    .handler = &sighup,
+  },
+  {
+    .signal = SIGUSR1,
+    .handler = &sigusr1,
+  },
+  {
+    .signal = SIGINT,
+    .handler = &sigint,
+  },
+  {
+    .signal = SIGTERM,
+    .handler = &sigint,
+  },
+};
+
+
+/* LDP main routine. */
+int
+main (int argc, char **argv)
+{
+  char *p;
+  char *vty_addr = NULL;
+  int vty_port = LDP_VTY_PORT;
+  int daemon_mode = 0;
+  char *config_file = NULL;
+  char *progname;
+  struct thread thread;
+
+  /* Set umask before anything for security */
+  umask (0027);
+
+  /* preserve my name */
+  progname = ((p = strrchr (argv[0], '/')) ? ++p : argv[0]);
+
+  /* Invoked by a priviledged user? -- endo. */
+  if (geteuid () != 0)
+    {
+      errno = EPERM;
+      perror (progname);
+      exit (1);
+    }
+
+  zlog_default = openzlog (progname, ZLOG_LDP,
+			   LOG_CONS|LOG_NDELAY|LOG_PID, LOG_DAEMON);
+
+  while (1) 
+    {
+      int opt;
+  
+      opt = getopt_long (argc, argv, "dlf:i:hA:P:u:g:v", longopts, 0);
+
+      if (opt == EOF)
+	break;
+
+      switch (opt) 
+	{
+	case 0:
+	  break;
+	case 'd':
+	  daemon_mode = 1;
+	  break;
+	case 'f':
+	  config_file = optarg;
+	  break;
+	case 'A':
+	  vty_addr = optarg;
+          break;
+	case 'i':
+	  pid_file = optarg;
+          break;
+	case 'P':
+          /* Deal with atoi() returning 0 on failure, and ldpd not
+             listening on ldp port... */
+          if (strcmp(optarg, "0") == 0)
+            {
+              vty_port = 0;
+              break;
+            }
+          vty_port = atoi (optarg);
+          vty_port = (vty_port ? vty_port : LDP_VTY_PORT);
+          break;
+        case 'u':
+          ldpd_privs.user = optarg;
+          break;
+        case 'g':
+          ldpd_privs.group = optarg;
+          break;
+	case 'v':
+	  print_version (progname);
+	  exit (0);
+	  break;
+	case 'h':
+	  usage (progname, 0);
+	  break;
+	default:
+	  usage (progname, 1);
+	  break;
+	}
+    }
+
+  /* Make master thread emulator. */
+  master = thread_master_create ();
+
+  /* Vty related initialize. */
+  zprivs_init (&ldpd_privs);
+  signal_init (master, Q_SIGC(ldp_signals), ldp_signals);
+  cmd_init (1);
+  vty_init (master);
+  memory_init ();
+
+  /* LDP inits */
+  ldp_init ();
+  ldp_interface_init ();
+  ldp_vty_init ();
+  ldp_vty_show_init ();
+  ldp_zebra_init ();
+
+  /* Sort all installed commands. */
+  sort_node();
+
+  /* Configuration file read*/
+  vty_read_config(config_file, config_default);
+
+  /* Change to the daemon program. */
+  if (daemon_mode)
+    daemon(0, 0);
+
+  /* Process id file create. */
+  pid_output(pid_file);
+
+  /* Create VTY socket */
+  vty_serv_sock (vty_addr, vty_port, LDP_VTYSH_PATH);
+
+  /* Print banner. */
+  zlog_notice ("LDPd %s starting vty@%d", QUAGGA_VERSION, vty_port);
+
+   /* Fetch next active thread. */
+  while(thread_fetch (master, &thread))
+    thread_call (&thread);
+
+  /* Not reached... */
+  exit (0);
+}
diff -Naur quagga-0.99.10/ldpd/ldp_mesg.c quagga-mpls/ldpd/ldp_mesg.c
--- quagga-0.99.10/ldpd/ldp_mesg.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_mesg.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,221 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdio.h>
+#include <sys/socket.h>
+#include "ldp_struct.h"
+#include "ldp_mesg.h"
+#include "ldp_buf.h"
+
+#include "mpls_assert.h"
+#include "mpls_mm_impl.h"
+#include "mpls_socket_impl.h"
+#include "mpls_trace_impl.h"
+
+mpls_return_enum ldp_mesg_send_tcp(ldp_global * g, ldp_session * s,
+  ldp_mesg * msg)
+{
+  int32_t result = 0;
+
+  MPLS_ASSERT(s);
+
+  result = ldp_encode_one_mesg(g, g->lsr_identifier.u.ipv4,
+    s->cfg_label_space, s->tx_buffer, msg);
+
+  if (result <= 0)
+    return MPLS_FAILURE;
+
+  s->mesg_tx++;
+
+  result = mpls_socket_tcp_write(g->socket_handle, s->socket,
+    s->tx_buffer->buffer, s->tx_buffer->size);
+
+  if (result <= 0) {
+    LDP_PRINT(g->user_data, "send failed(%d)\n", result);
+    perror("send");
+    return MPLS_FAILURE;
+  }
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_mesg_send_udp(ldp_global * g, ldp_entity * e,
+  ldp_mesg * msg)
+{
+  ldp_buf *buf = NULL;
+  mpls_dest *dest = NULL;
+  int32_t result = 0;
+  uint16_t label_space = 0;
+
+  MPLS_ASSERT(e);
+
+  switch (e->entity_type) {
+    case LDP_DIRECT:
+      MPLS_ASSERT(e->p.iff != NULL);
+      if (mpls_socket_multicast_if_tx(g->socket_handle, g->hello_socket,
+          e->p.iff) == MPLS_FAILURE) {
+        LDP_PRINT(g->user_data, "ldp_mesg_send_udp: muticast tx error(%d)\n",
+          mpls_socket_get_errno(g->socket_handle, g->hello_socket));
+        return MPLS_FAILURE;
+      }
+      dest = &e->p.iff->dest;
+      buf = e->p.iff->tx_buffer;
+      label_space = e->p.iff->label_space;
+      break;
+    case LDP_INDIRECT:
+      MPLS_ASSERT(e->p.peer != NULL);
+      dest = &e->p.peer->dest;
+      buf = e->p.peer->tx_buffer;
+      label_space = e->p.peer->label_space;
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+  result =
+    ldp_encode_one_mesg(g, g->lsr_identifier.u.ipv4, label_space, buf, msg);
+
+  if (result <= 0)
+    return MPLS_FAILURE;
+
+  e->mesg_tx++;
+
+  result = mpls_socket_udp_sendto(g->socket_handle, g->hello_socket,
+    buf->buffer, buf->size, dest);
+
+  switch (e->entity_type) {
+    case LDP_DIRECT:
+      mpls_socket_multicast_if_tx(g->socket_handle, g->hello_socket, NULL);
+      break;
+    case LDP_INDIRECT:
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+
+  if (result <= 0) {
+    LDP_PRINT(g->user_data, "sendto failed(%d)\n", result);
+    perror("sendto");
+    return MPLS_FAILURE;
+  }
+  return MPLS_SUCCESS;
+}
+
+ldp_mesg *ldp_mesg_create()
+{
+  ldp_mesg *msg = (ldp_mesg *) mpls_malloc(sizeof(ldp_mesg));
+
+  if (!msg) {
+    return NULL;
+  }
+  return msg;
+}
+
+void ldp_mesg_prepare(ldp_mesg * msg, uint16_t type, uint32_t id)
+{
+  memset(msg, 0, sizeof(ldp_mesg));
+
+  msg->u.generic.flags.flags.msgType = type;
+  msg->u.generic.msgId = id;
+  msg->u.generic.msgLength = MPLS_MSGIDFIXLEN;
+}
+
+void ldp_mesg_delete(ldp_mesg * msg)
+{
+  MPLS_ASSERT(msg);
+  mpls_free(msg);
+}
+
+void ldp_mesg_hdr_get_lsraddr(ldp_mesg * msg, mpls_inet_addr * lsraddr)
+{
+  MPLS_ASSERT(msg && lsraddr);
+
+  lsraddr->type = MPLS_FAMILY_IPV4;
+  lsraddr->u.ipv4 = msg->header.lsrAddress;
+}
+
+void ldp_mesg_hdr_get_labelspace(ldp_mesg * msg, int *labelspace)
+{
+  MPLS_ASSERT(msg && labelspace);
+  *labelspace = msg->header.labelSpace;
+}
+
+uint16_t ldp_mesg_get_type(ldp_mesg * msg)
+{
+  MPLS_ASSERT(msg);
+  return msg->u.generic.flags.flags.msgType;
+}
+
+mpls_return_enum ldp_mesg_hello_get_traddr(ldp_mesg * msg,
+  mpls_inet_addr * traddr)
+{
+  MPLS_MSGPTR(Hello);
+  MPLS_ASSERT(msg && traddr);
+
+  MPLS_MSGPARAM(Hello) = &msg->u.hello;
+  if (!MPLS_MSGPARAM(Hello)->trAdrTlvExists)
+    return MPLS_FAILURE;
+
+  traddr->type = MPLS_FAMILY_IPV4;
+  traddr->u.ipv4 = MPLS_MSGPARAM(Hello)->trAdr.address;
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_mesg_hello_get_hellotime(ldp_mesg * msg, int *hellotime)
+{
+  MPLS_MSGPTR(Hello);
+  MPLS_ASSERT(msg && hellotime);
+
+  MPLS_MSGPARAM(Hello) = &msg->u.hello;
+  if (!MPLS_MSGPARAM(Hello)->chpTlvExists) {
+    LDP_PRINT(NULL, "No chp!");
+    return MPLS_FAILURE;
+  }
+
+  *hellotime = MPLS_MSGPARAM(Hello)->chp.holdTime;
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_mesg_hello_get_csn(ldp_mesg * msg, uint32_t * csn)
+{
+  MPLS_MSGPTR(Hello);
+  MPLS_ASSERT(msg && csn);
+
+  MPLS_MSGPARAM(Hello) = &msg->u.hello;
+  if (!MPLS_MSGPARAM(Hello)->csnTlvExists)
+    return MPLS_FAILURE;
+
+  *csn = MPLS_MSGPARAM(Hello)->csn.seqNumber;
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_mesg_hello_get_request(ldp_mesg * msg, int *req)
+{
+  MPLS_MSGPTR(Hello);
+  MPLS_ASSERT(msg && req);
+
+  MPLS_MSGPARAM(Hello) = &msg->u.hello;
+
+  *req = MPLS_MSGPARAM(Hello)->chp.flags.flags.request;
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_mesg_hello_get_targeted(ldp_mesg * msg, int *tar)
+{
+  MPLS_MSGPTR(Hello);
+  MPLS_ASSERT(msg && tar);
+
+  MPLS_MSGPARAM(Hello) = &msg->u.hello;
+
+  *tar = MPLS_MSGPARAM(Hello)->chp.flags.flags.target;
+
+  return MPLS_SUCCESS;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_mesg.h quagga-mpls/ldpd/ldp_mesg.h
--- quagga-0.99.10/ldpd/ldp_mesg.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_mesg.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,36 @@
+
+/*
+ *  Copyright (C) James R. Leu 2001
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_MESG_H_
+#define _LDP_MESG_H_
+
+#include "ldp_struct.h"
+
+extern ldp_mesg *ldp_mesg_create();
+extern void ldp_mesg_prepare(ldp_mesg * msg, uint16_t type, uint32_t id);
+extern void ldp_mesg_delete(ldp_mesg * msg);
+extern uint16_t ldp_mesg_get_type(ldp_mesg * mesg);
+extern void ldp_mesg_hdr_get_lsraddr(ldp_mesg * mesg, mpls_inet_addr * lsraddr);
+extern void ldp_mesg_hdr_get_labelspace(ldp_mesg * mesg, int *labelspace);
+
+extern mpls_return_enum ldp_mesg_hello_get_traddr(ldp_mesg * mesg,
+  mpls_inet_addr * traddr);
+extern mpls_return_enum ldp_mesg_hello_get_hellotime(ldp_mesg * mesg,
+
+  int *hellotime);
+extern mpls_return_enum ldp_mesg_hello_get_csn(ldp_mesg * mesg, uint32_t * csn);
+extern mpls_return_enum ldp_mesg_hello_get_targeted(ldp_mesg * mesg, int *tar);
+extern mpls_return_enum ldp_mesg_hello_get_request(ldp_mesg * mesg, int *req);
+
+extern mpls_return_enum ldp_mesg_send_tcp(ldp_global * g, ldp_session * s,
+  ldp_mesg * mesg);
+extern mpls_return_enum ldp_mesg_send_udp(ldp_global * g, ldp_entity * s,
+  ldp_mesg * mesg);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_nexthop.c quagga-mpls/ldpd/ldp_nexthop.c
--- quagga-0.99.10/ldpd/ldp_nexthop.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_nexthop.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,217 @@
+
+/*
+ *  Copyright (C) James R. Leu 2003
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_fec.h"
+#include "ldp_if.h"
+#include "ldp_addr.h"
+#include "ldp_session.h"
+#include "ldp_outlabel.h"
+#include "ldp_global.h"
+#include "mpls_assert.h"
+#include "mpls_compare.h"
+#include "mpls_mm_impl.h"
+#include "mpls_tree_impl.h"
+#include "mpls_policy_impl.h"
+#include "mpls_trace_impl.h"
+
+#if MPLS_USE_LSR
+#include "lsr_cfg.h"
+#else
+#include "mpls_mpls_impl.h"
+#endif
+
+static uint32_t _ldp_nexthop_next_index = 1;
+static uint32_t _ldp_nexthop_get_next_index();
+
+void mpls_nexthop2ldp_nexthop(mpls_nexthop *mnh, ldp_nexthop *lnh)
+{
+  memcpy(&lnh->info, mnh, sizeof(mpls_nexthop));
+}
+
+ldp_nexthop *ldp_nexthop_for_fec_session(ldp_fec *fec, ldp_session *s)
+{
+  ldp_nexthop *nh = MPLS_LIST_HEAD(&fec->nh_root);
+  ldp_session *sp;
+
+  LDP_ENTER(g->user_data, "ldp_nexthop_for_fec_session");
+
+  while (nh) {
+    sp = ldp_session_for_nexthop(nh);
+    if (sp && (sp->index == s->index)) {
+      LDP_EXIT(g->user_data, "ldp_nexthop_for_fec_session: %p", nh);
+      return nh;
+    }
+    nh = MPLS_LIST_NEXT(&fec->nh_root, nh, _fec);
+  }
+  LDP_EXIT(g->user_data, "ldp_nexthop_for_fec_session: NULL");
+  return NULL;
+}
+
+void ldp_nexthop_delete(ldp_global *g, ldp_nexthop *nh)
+{
+  LDP_PRINT(g->user_data, "nexthop delete: %p", nh);
+  MPLS_REFCNT_ASSERT(nh, 0);
+
+  if (nh->addr) {
+    ldp_addr_del_nexthop(g, nh->addr, nh);
+  }
+  if (nh->iff) {
+    ldp_if_del_nexthop(g, nh->iff, nh);
+  }
+  if (nh->outlabel) {
+    ldp_outlabel_del_nexthop(g, nh->outlabel, nh);
+  }
+
+  _ldp_global_del_nexthop(g, nh);
+  mpls_free(nh);
+}
+
+ldp_nexthop *ldp_nexthop_create(ldp_global *g, mpls_nexthop *n)
+{
+  ldp_nexthop *nh = (ldp_nexthop *) mpls_malloc(sizeof(ldp_nexthop));
+
+  if (nh != NULL) {
+    memset(nh, 0, sizeof(ldp_nexthop));
+    MPLS_REFCNT_INIT(nh, 0);
+    MPLS_LIST_INIT(&nh->outlabel_root, ldp_outlabel);
+    MPLS_LIST_ELEM_INIT(nh, _global);
+    MPLS_LIST_ELEM_INIT(nh, _fec);
+    MPLS_LIST_ELEM_INIT(nh, _addr);
+    MPLS_LIST_ELEM_INIT(nh, _if);
+    MPLS_LIST_ELEM_INIT(nh, _outlabel);
+    nh->index = _ldp_nexthop_get_next_index();
+    mpls_nexthop2ldp_nexthop(n, nh);
+
+    if (nh->info.type & MPLS_NH_IP) {
+      ldp_addr *addr = NULL;
+      if (!(addr = ldp_addr_find(g, &nh->info.ip))) {
+        if (!(addr = ldp_addr_insert(g, &nh->info.ip))) {
+          goto ldp_nexthop_create_error;
+        }
+      }
+      ldp_addr_add_nexthop(addr, nh);
+    }
+
+    if (nh->info.type & MPLS_NH_IF) {
+      ldp_if *iff = NULL;
+      if ((iff = ldp_global_find_if_handle(g, nh->info.if_handle))) {
+        ldp_if_add_nexthop(iff, nh);
+      } else {
+        goto ldp_nexthop_create_error;
+      }
+    }
+
+    if (nh->info.type & MPLS_NH_OUTSEGMENT) {
+      ldp_outlabel *out = NULL;
+      MPLS_ASSERT((out = ldp_global_find_outlabel_handle(g,
+        nh->info.outsegment_handle)));
+      ldp_outlabel_add_nexthop(out, nh);
+    }
+
+    _ldp_global_add_nexthop(g, nh);
+  }
+  return nh;
+
+ldp_nexthop_create_error:
+  ldp_nexthop_delete(g, nh);
+  return NULL;
+}
+
+void ldp_nexthop_add_if(ldp_nexthop * nh, ldp_if * i)
+{
+  MPLS_ASSERT(nh && i);
+  MPLS_REFCNT_HOLD(i);
+  nh->info.if_handle = i->handle;
+  nh->iff = i;
+}
+
+void ldp_nexthop_del_if(ldp_global *g, ldp_nexthop * nh)
+{
+  MPLS_ASSERT(nh);
+  MPLS_REFCNT_RELEASE2(g, nh->iff, ldp_if_delete);
+  nh->iff = NULL;
+}
+
+void ldp_nexthop_add_addr(ldp_nexthop * nh, ldp_addr * a)
+{
+  MPLS_ASSERT(nh && a);
+  MPLS_REFCNT_HOLD(a);
+  nh->addr = a;
+}
+
+void ldp_nexthop_del_addr(ldp_global *g, ldp_nexthop * nh)
+{
+  MPLS_ASSERT(nh);
+  MPLS_REFCNT_RELEASE2(g, nh->addr, ldp_addr_delete);
+  nh->addr = NULL;
+}
+
+/* this is for a nexthops outlabel used to describe hierarchy */
+void ldp_nexthop_add_outlabel(ldp_nexthop * nh, ldp_outlabel * o)
+{
+  MPLS_ASSERT(nh && o);
+  MPLS_REFCNT_HOLD(o);
+  nh->outlabel = o;
+}
+
+/* this is for a nexthops outlabel used to describe hierarchy */
+void ldp_nexthop_del_outlabel(ldp_global * g,ldp_nexthop * nh)
+{
+  MPLS_ASSERT(nh);
+  MPLS_REFCNT_RELEASE2(g, nh->outlabel, ldp_outlabel_delete);
+  nh->outlabel = NULL;
+}
+
+/*
+ * just like addrs with respect to NHs,  NHs do not need to hold a ref to
+ * outlabels (upper).
+ */
+
+/* this is for the outlabels nexthops, not the nexthop's outlabel
+ * used to describe hierarchy */
+void ldp_nexthop_add_outlabel2(ldp_nexthop * n, ldp_outlabel * o)
+{
+  MPLS_ASSERT(n && o);
+  MPLS_LIST_ADD_HEAD(&n->outlabel_root, o, _nexthop, ldp_outlabel);
+  memcpy(&o->info.nexthop, &n->info, sizeof(mpls_nexthop));
+}
+
+/* this is for the outlabels nexthops, not the nexthop's outlabel
+ * used to describe hierarchy */
+void ldp_nexthop_del_outlabel2(ldp_global *g, ldp_nexthop * n, ldp_outlabel * o)
+{
+  MPLS_ASSERT(n && o);
+  MPLS_LIST_REMOVE(&n->outlabel_root, o, _nexthop);
+}
+
+void ldp_nexthop_add_fec(ldp_nexthop *nh, ldp_fec *f)
+{
+  MPLS_ASSERT(nh && f);
+  MPLS_REFCNT_HOLD(f);
+  nh->fec = f;
+}
+
+void ldp_nexthop_del_fec(ldp_global *g, ldp_nexthop * nh)
+{
+  MPLS_ASSERT(nh);
+  MPLS_REFCNT_RELEASE2(g, nh->fec, ldp_fec_delete);
+  nh->fec = NULL;
+}
+
+static uint32_t _ldp_nexthop_get_next_index()
+{
+  uint32_t retval = _ldp_nexthop_next_index;
+
+  _ldp_nexthop_next_index++;
+  if (retval > _ldp_nexthop_next_index) {
+    _ldp_nexthop_next_index = 1;
+  }
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_nexthop.h quagga-mpls/ldpd/ldp_nexthop.h
--- quagga-0.99.10/ldpd/ldp_nexthop.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_nexthop.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,29 @@
+
+/*
+ *  Copyright (C) James R. Leu 2003
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_NEXTHOP_H_
+#define _LDP_NEXTHOP_H_
+
+extern ldp_nexthop *ldp_nexthop_create(ldp_global *g, mpls_nexthop *n);
+extern ldp_nexthop *ldp_nexthop_for_fec_session(ldp_fec *fec, ldp_session *s);
+extern void ldp_nexthop_delete(ldp_global *g, ldp_nexthop *nh);
+extern void ldp_nexthop_add_if(ldp_nexthop * nh, ldp_if * i);
+extern void ldp_nexthop_del_if(ldp_global *g, ldp_nexthop * nh);
+extern void ldp_nexthop_add_addr(ldp_nexthop * nh, ldp_addr * a);
+extern void ldp_nexthop_del_addr(ldp_global *g, ldp_nexthop * nh);
+extern void ldp_nexthop_add_outlabel(ldp_nexthop * nh, ldp_outlabel * o);
+extern void ldp_nexthop_del_outlabel(ldp_global *g, ldp_nexthop * nh);
+extern void ldp_nexthop_add_outlabel2(ldp_nexthop * nh, ldp_outlabel * o);
+extern void ldp_nexthop_del_outlabel2(ldp_global *g, ldp_nexthop * nh, ldp_outlabel * o);
+extern void ldp_nexthop_add_fec(ldp_nexthop * nh, ldp_fec * f);
+extern void ldp_nexthop_del_fec(ldp_global * g, ldp_nexthop * nh);
+extern void mpls_nexthop2ldp_nexthop(mpls_nexthop *mnh, ldp_nexthop *lnh);
+
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_nortel.c quagga-mpls/ldpd/ldp_nortel.c
--- quagga-0.99.10/ldpd/ldp_nortel.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_nortel.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,5769 @@
+
+/******************************************************************************
+*                       Nortel Networks Software License                      *
+*                                                                             *
+* READ THE TERMS OF THIS LICENSE CAREFULLY.  BY USING, MODIFYING, OR          *
+* DISTRIBUTING THIS SOFTWARE AND ANY ACCOMPANYING DOCUMENTATION (COLLECTIVELY,*
+* "SOFTWARE") YOU ARE AGREEING TO ALL OF THE TERMS OF THIS LICENSE.           *
+*                                                                             *
+* 1.      Nortel Telecom Limited, on behalf of itself and its subsidiaries    *
+* (collectively "Nortel Networks") grants to you a non-exclusive, perpetual,  *
+* world-wide right to use, copy, modify, and distribute the Software at no    *
+* charge.                                                                     *
+*                                                                             *
+* 2.      You may sublicense recipients of redistributed Software to use,     *
+* copy, modify, and distribute the Software on substantially the same terms as*
+* this License.  You may not impose any further restrictions on the           *
+* recipient's exercise of the rights in the Software granted under this       *
+* License.  Software distributed to other parties must be accompanied by a    *
+* License containing a grant, disclaimer and limitation of liability          *
+* substantially in the form of 3, 4, and 5 below provided that references to  *
+* "Nortel Networks" may be changed to "Supplier".                             *
+*                                                                             *
+* 3.      Nortel Networks reserves the right to modify and release new        *
+* versions of the Software from time to time which may include modifications  *
+* made by third parties like you. Accordingly, you agree that you shall       *
+* automatically grant a license to Nortel Networks to include, at its option, *
+* in any new version of the Software any modifications to the Software made by*
+* you and made available directly or indirectly to Nortel Networks.  Nortel   *
+* Networks shall have the right to use, copy, modify, and distribute any such *
+* modified Software on substantially the same terms as this License.          *
+*                                                                             *
+* 4.      THE SOFTWARE IS PROVIDED ON AN "AS IS" BASIS.  NORTEL NETWORKS AND  *
+* ITS AGENTS AND SUPPLIERS DISCLAIM ALL REPRESENTATIONS, WARRANTIES AND       *
+* CONDITIONS RELATING TO THE SOFTWARE, INCLUDING, BUT NOT LIMITED TO, IMPLIED *
+* WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND         *
+* NON-INFRINGEMENT OF THIRD-PARTY INTELLECTUAL PROPERTY RIGHTS.  NORTEL       *
+* NETWORKS AND ITS AGENTS AND SUPPLIERS DO NOT WARRANT, GUARANTEE, OR MAKE ANY*
+* REPRESENTATIONS REGARDING THE USE, OR THE RESULTS OF THE USE, OF THE        *
+* SOFTWARE IN TERMS OR CORRECTNESS, ACCURACY, RELIABILITY, CURRENTNESS, OR    *
+* OTHERWISE.                                                                  *
+*                                                                             *
+* 5.      NEITHER NORTEL NETWORKS NOR ANY OF ITS AGENTS OR SUPPLIERS SHALL BE *
+* LIABLE FOR ANY DIRECT, INDIRECT, CONSEQUENTIAL, INCIDENTAL OR EXEMPLARY     *
+* DAMAGES, OR ECONOMIC LOSSES (INCLUDING DAMAGES FOR LOSS OF BUSINESS PROFITS,*
+* BUSINESS INTERRUPTION, LOSS OF BUSINESS INFORMATION AND THE LIKE), ARISING  *
+* FROM THE SOFTWARE OR THIS LICENSE AGREEMENT, EVEN IF NORTEL NETWORKS OR SUCH*
+* AGENT OR SUPPLIER HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR    *
+* LOSSES, AND WHETHER ANY SUCH DAMAGE OR LOSS ARISES OUT OF CONTRACT, TORT, OR*
+* OTHERWISE.                                                                  *
+*                                                                             *
+* 6.      This License shall be governed by the laws of the Province of       *
+* Ontario, Canada.                                                            *
+*******************************************************************************/
+
+/******************************************************************************
+ * This file contains the C implementation for encode/decode functions        * 
+ * for the following types of messages: notification, hello, initialization,  *
+ * keepAlive, address, address Withdraw, label Mapping, label Request, label  *
+ * Withdraw and label Release. There are also encode/decode methods for all   * 
+ * tlv types required by the previously enumerated messages.                  * 
+ * Please remember that the pdu will always contain the header followed by 1  *
+ * or more LDP messages. The file contains functions to encode/decode the LDP *
+ * header as well.  							      * 
+ * All the messages, header message and the tlvs are in conformity with the   * 
+ * draft-ietf-mpls-ldp-04  (May 1999) and with draft-ietf-mpls-cr-ldp-01      *
+ * (Jan 1999). 								      * 
+ *								              *
+ * Please note that the U bit in the message and the F bit in the tlv are     *
+ * ignored in this version of the code.                                       *
+ *								              *
+ * Please note that the traffic parameters for traffic TLV have to be IEEE    *
+ * single precision floating point numbers.                                   *
+ *								              *
+ * Please note that there might be a small chance for bit field manipulation  *
+ * portability inconsistency. If such problems occure, the code requires      *
+ * changes for a suitable bit-field manipulation. The code for encoding and   *
+ * decoding makes the assumption that the compiler packs the bit fields in a  *
+ * structure into adjacent bits of the same unit.                             * 
+ *								              *
+ * The usage of the encode/decode functions is described below.               * 
+ *								              *
+ * The encode functions take as arguments: a pointer to the structure which   *
+ * implements msg/tlv, a buffer (where the encoding is done) and the buffer   *
+ * length.							              *
+ * If the encode is successfull, the function returns the total encoded       * 
+ * length.								      *
+ * If the encode fails, the function returns an error code.                   *
+ * The encode functions for messages and message headers do not modify the    *
+ * content of the struct which is to be encoded. All the other encode         *
+ * functions will change the content of the structure. The pointer which      *
+ * points to the beginning of the buffer is not changed.                      *
+ *									      *
+ * The decode functions take as arguments: a pointer to the structure which   *
+ * is going to be populated after decoding, a pointer to a buffer and the     *
+ * buffer length.							      *
+ * If the decode is successful, the function returns the total decoded length *
+ * If the decode fails, the function returns an error code. The decode        *
+ * functions do not modify the pointer to the buffer which contains the data  *
+ * to be decoded.							      *
+ *									      *
+ * Example on how to use the encode/decode functions for a keepAlive message: *
+ *									      *
+ *           Encode the keep alive message:                                   * 
+ *           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    				      *
+ *           u_char buffer[500];	 				      *
+ *           int returnCode; 						      *
+ *           struct mplsLdpKeepAlMsg_s keepAliveMsg;            	      *
+ *           keepAliveMsg.baseMsg.msgType   = MPLS_KEEPAL_MSGTYPE;            *
+ *           keepAliveMsg.baseMsg.msgLength = MPLS_MSGIDFIXLEN;               *
+ *           keepAliveMsg.baseMsg.msgId     = 123;		              *
+ *           memset(buffer, 0, 500);                                  	      *
+ *           returnCode = Mpls_encodeLdpKeepAliveMsg(&keepAliveMsg,           *
+ *                                                   buffer,                  *
+ *                                                   500);                    *
+ *           if (returnCode < 0)                                              *
+ *              check the error code				              *
+ *           else                                                             *
+ *              write(fd, buffer, returnCode);                                *
+ *									      *
+ *									      *
+ *           Decode the keep alive meesage:                                   *
+ *           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^		                      *
+ *           u_char buffer[500];					      *
+ *           int returnCode;					              *
+ *           struct mplsLdpKeepAlMsg_s keepAliveMsg;	            	      *
+ *           read(fd, buffer, length);                                        *
+ *           returnCode =  Mpls_decodeLdpKeepAliveMsg(&keepAliveMsg,          * 
+ *                                                    buffer,                 *
+ *                                                    500); 		      *
+ *           if (returnCode < 0)	                                      *
+ *              check the error code					      *
+ *           else				 			      *
+ *           { 								      *
+ *              printKeepAliveMsg(&keepAliveMsg);	 	              *
+ *           } 						                      *
+ *								              *
+ * An example on how to use the decode functions for the header and the       *
+ * messages can be found in the main function.                                *
+ *								              *
+ * The code was tested for big endian and little endian for sparc5, linux     *
+ * and i960.                                                                  *
+ *								              *
+ * In order to compile for little endian, the LITTLE_ENDIAN_BYTE_ORDER should *
+ * be defined.								      *
+ *								              *
+ * At the end of this file there is an examples of a hex buffers and its      *
+ * corresponding values.                                                      *
+ *								              *
+ *								              *
+ * Version History                                                            *
+ * Version          Date      Authors            Description                  *
+ * ===========      ========  =========          ======================       *
+ * mpls_encdec_01.c 99/03/15  Antonela Paraschiv draft-ietf-mpls-ldp-03 and   * 
+ *                                               draft-ietf-mpls-cr-ldp-01    *
+ *								              *
+ * mpls_encdec_02.c 99/05/19  Antonela Paraschiv draft-ietf-mpls-ldp-04 and   * 
+ *                                               draft-ietf-mpls-cr-ldp-01    *
+ *								              *
+ ******************************************************************************/
+
+#ifdef VXWORKS
+#include <in.h>                 /* htons, htonl, ntohs, ntohl         */
+#include <types.h>              /* u_int, u_char, u_short, float etc. */
+#else
+#include <netinet/in.h>         /* htons, htonl, ntohs, ntohl         */
+#include <sys/types.h>          /* u_int, u_char, u_short, float etc. */
+#endif /* VXWORKS */
+
+#include "ldp_struct.h"
+#include "mpls_trace_impl.h"
+#include "ldp_nortel.h"
+
+int global_ldp_pdu_debug = 0;
+
+/*
+ *      Encode-decode for Ldp Msg Header 
+ */
+
+/* 
+ * Encode:
+ */
+int Mpls_encodeLdpMsgHeader
+  (mplsLdpHeader_t * header, u_char * buff, int bufSize) {
+  mplsLdpHeader_t headerCopy;
+
+  if (MPLS_LDP_HDRSIZE > bufSize) {
+    /* not enough room for header */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  headerCopy = *header;
+  headerCopy.protocolVersion = htons(headerCopy.protocolVersion);
+  headerCopy.pduLength = htons(headerCopy.pduLength);
+  headerCopy.lsrAddress = htonl(headerCopy.lsrAddress);
+  headerCopy.labelSpace = htons(headerCopy.labelSpace);
+
+  MEM_COPY(buff, (u_char *) & headerCopy, MPLS_LDP_HDRSIZE);
+
+  return MPLS_LDP_HDRSIZE;
+
+}                               /* End : Mpls_encodeLdpMsgHeader */
+
+/* 
+ * Decode: 
+ */
+int Mpls_decodeLdpMsgHeader
+  (mplsLdpHeader_t * header, u_char * buff, int bufSize) {
+  if (MPLS_LDP_HDRSIZE > bufSize) {
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  MEM_COPY((u_char *) header, buff, MPLS_LDP_HDRSIZE);
+
+  header->protocolVersion = ntohs(header->protocolVersion);
+  header->pduLength = ntohs(header->pduLength);
+  header->lsrAddress = ntohl(header->lsrAddress);
+  header->labelSpace = ntohs(header->labelSpace);
+
+  /* check if the length is over the max length */
+  if (header->pduLength > MPLS_PDUMAXLEN) {
+    return MPLS_PDU_LENGTH_ERROR;
+  }
+
+  return MPLS_LDP_HDRSIZE;
+
+}                               /* End: Mpls_decodeLdpMsgHeader */
+
+/*
+ *      Encode-decode for Ldp Base Message
+ */
+
+/* 
+ * Encode:
+ */
+int Mpls_encodeLdpBaseMsg(mplsLdpMsg_t * ldpMsg, u_char * buff, int bufSize)
+{
+  if (MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN > bufSize) {
+    /* not enough room for header */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  ldpMsg->flags.mark = htons(ldpMsg->flags.mark);
+  ldpMsg->msgLength = htons(ldpMsg->msgLength);
+  ldpMsg->msgId = htonl(ldpMsg->msgId);
+
+  MEM_COPY(buff, (u_char *) ldpMsg, MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN);
+
+  return (MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End : Mpls_encodeLdpBaseMsg */
+
+/* 
+ * Decode: 
+ */
+int Mpls_decodeLdpBaseMsg(mplsLdpMsg_t * ldpMsg, u_char * buff, int bufSize)
+{
+  if (MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN > bufSize) {
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  MEM_COPY((u_char *) ldpMsg, buff, MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN);
+
+  ldpMsg->flags.mark = ntohs(ldpMsg->flags.mark);
+  ldpMsg->msgLength = ntohs(ldpMsg->msgLength);
+  ldpMsg->msgId = ntohl(ldpMsg->msgId);
+
+  return MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN;
+
+}                               /* End: Mpls_decodeLdpBaseMsg */
+
+/*
+ *      Encode-decode for ATM Label Range Component
+ */
+
+/* 
+ * encode: 
+ */
+int Mpls_encodeLdpAtmLblRng
+  (mplsLdpAtmLblRng_t * atmLbl, u_char * buff, int bufSize) {
+  if (MPLS_ATMLRGFIXLEN > bufSize) {
+    /* not enough room for label */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  atmLbl->flags.flags.res1 = 0;
+  atmLbl->flags.flags.res2 = 0;
+  atmLbl->flags.mark[0] = htonl(atmLbl->flags.mark[0]);
+  atmLbl->flags.mark[1] = htonl(atmLbl->flags.mark[1]);
+
+  MEM_COPY(buff, (u_char *) atmLbl, MPLS_ATMLRGFIXLEN);
+
+  return MPLS_ATMLRGFIXLEN;
+
+}                               /* End Mpls_encodeLdpAtmLblRng */
+
+/* 
+ * decode: 
+ */
+int Mpls_decodeLdpAtmLblRng
+  (mplsLdpAtmLblRng_t * atmLbl, u_char * buff, int bufSize) {
+  if (MPLS_ATMLRGFIXLEN > bufSize) {
+    PRINT_ERR("failed decoding the Atm Lbl Rng\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  MEM_COPY((u_char *) atmLbl, buff, MPLS_ATMLRGFIXLEN);
+
+  atmLbl->flags.mark[0] = ntohl(atmLbl->flags.mark[0]);
+  atmLbl->flags.mark[1] = ntohl(atmLbl->flags.mark[1]);
+
+  return MPLS_ATMLRGFIXLEN;
+
+}                               /* End Mpls_decodeLdpAtmLblRng */
+
+/*
+ *      Encode-decode for ATM Session Parameters 
+ */
+
+/* 
+ * encode: 
+ */
+int Mpls_encodeLdpAsp(mplsLdpAspTlv_t * atmAsp, u_char * buff, int bufSize)
+{
+  int encodedSize = 0;
+  u_short totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_int i, numLblRng;
+
+  /* get the size of the atmAsp to be encoded and check it against
+     the buffer size */
+
+  if (MPLS_TLVFIXLEN + (int)(atmAsp->baseTlv.length) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(atmAsp->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  /* 
+   *  encode for M + N + D + res 
+   */
+  numLblRng = atmAsp->flags.flags.numLblRng;
+  atmAsp->flags.flags.res = 0;
+  atmAsp->flags.mark = htonl(atmAsp->flags.mark);
+
+  MEM_COPY(tempBuf, (u_char *) & (atmAsp->flags.mark), MPLS_ASPFIXLEN);
+  tempBuf += MPLS_ASPFIXLEN;
+  totalSize += MPLS_ASPFIXLEN;
+
+  /* 
+   *  encode for ATM labels 
+   */
+  for (i = 0; i < numLblRng; i++) {
+    encodedSize = Mpls_encodeLdpAtmLblRng(&(atmAsp->lblRngList[i]),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_ATMLBLERROR;
+    }
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End Mpls_encodeLdpAsp */
+
+/* 
+ * decode: 
+ */
+int Mpls_decodeLdpAsp(mplsLdpAspTlv_t * atmAsp, u_char * buff, int bufSize)
+{
+  int decodedSize = 0;
+  u_short totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_int i;
+
+  if (MPLS_ASPFIXLEN > bufSize) {
+    /* the buffer does not contain even the required field */
+    PRINT_ERR("failed in decoding LdpAsp\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  decode for M + N + D + res 
+   */
+  MEM_COPY((u_char *) & (atmAsp->flags.mark), tempBuf, MPLS_ASPFIXLEN);
+  tempBuf += MPLS_ASPFIXLEN;
+  totalSize += MPLS_ASPFIXLEN;
+
+  atmAsp->flags.mark = ntohl(atmAsp->flags.mark);
+
+  /*
+   *  decode for ATM labels 
+   */
+  for (i = 0; i < atmAsp->flags.flags.numLblRng; i++) {
+    decodedSize = Mpls_decodeLdpAtmLblRng(&(atmAsp->lblRngList[i]),
+      tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      PRINT_ERR("failed in decoding LdpAtmLabel[%d] for LdpAsp\n", i);
+      return MPLS_DEC_ATMLBLERROR;
+    }
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End Mpls_decodeLdpAsp */
+
+/*
+ *      Encode-decode for TLV
+ */
+
+/* 
+ * encode: 
+ */
+int Mpls_encodeLdpTlv(mplsLdpTlv_t * tlv, u_char * buff, int bufSize)
+{
+  if (MPLS_TLVFIXLEN > bufSize) {
+    /* not enough room for label */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  tlv->flags.mark = htons(tlv->flags.mark);
+  tlv->length = htons(tlv->length);
+
+  MEM_COPY(buff, (u_char *) tlv, MPLS_TLVFIXLEN);
+
+  return MPLS_TLVFIXLEN;
+
+}                               /* End: Mpls_encodeLdpTlv */
+
+/* 
+ * decode: 
+ */
+int Mpls_decodeLdpTlv(mplsLdpTlv_t * tlv, u_char * buff, int bufSize)
+{
+  if (MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("Failed decoding TLV\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  MEM_COPY((u_char *) tlv, buff, MPLS_TLVFIXLEN);
+
+  tlv->flags.mark = ntohs(tlv->flags.mark);
+  tlv->length = ntohs(tlv->length);
+
+  return MPLS_TLVFIXLEN;
+
+}                               /* End: Mpls_decodeLdpTlv */
+
+/*
+ *      Encode-decode for CSP (common session param)
+ */
+
+/* 
+ * encode: 
+ */
+int Mpls_encodeLdpCsp(mplsLdpCspTlv_t * csp, u_char * buff, int bufSize)
+{
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_char *cspPtr;
+
+  if (MPLS_CSPFIXLEN + MPLS_TLVFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  cspPtr = (u_char *) csp;
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(csp->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in CSP\n");
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+  cspPtr += encodedSize;
+
+  /* 
+   *  encode for the rest of the Csp 
+   */
+  csp->protocolVersion = htons(csp->protocolVersion);
+  csp->holdTime = htons(csp->holdTime);
+  csp->flags.mark = htons(csp->flags.mark);
+  csp->maxPduLen = htons(csp->maxPduLen);
+  csp->rcvLsrAddress = htonl(csp->rcvLsrAddress);
+  csp->rcvLsId = htons(csp->rcvLsId);
+
+  MEM_COPY(tempBuf, cspPtr, MPLS_CSPFIXLEN);
+
+  return (MPLS_CSPFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpCsp */
+
+/* 
+ * decode: 
+ */
+int Mpls_decodeLdpCsp(mplsLdpCspTlv_t * csp, u_char * buff, int bufSize)
+{
+  u_char *cspPtr;
+
+  if (MPLS_CSPFIXLEN > bufSize) {
+    /* not enough data for Csp */
+    PRINT_ERR("failed decoding LdpCsp\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  cspPtr = (u_char *) csp;
+  cspPtr += MPLS_TLVFIXLEN;     /* we want to point to the flags since the
+                                   tlv was decoded before we reach here */
+
+  /* 
+   *  decode for the rest of the Csp 
+   */
+  MEM_COPY(cspPtr, buff, MPLS_CSPFIXLEN);
+
+  csp->protocolVersion = ntohs(csp->protocolVersion);
+  csp->holdTime = ntohs(csp->holdTime);
+  csp->flags.mark = ntohs(csp->flags.mark);
+  csp->maxPduLen = ntohs(csp->maxPduLen);
+  csp->rcvLsrAddress = ntohl(csp->rcvLsrAddress);
+  csp->rcvLsId = ntohs(csp->rcvLsId);
+
+  return MPLS_CSPFIXLEN;
+
+}                               /* Mpls_decodeLdpCsp */
+
+/*
+ *      Encode-decode for Fr Session Parameters
+ */
+
+/* 
+ * encode
+ */
+int Mpls_encodeLdpFsp(mplsLdpFspTlv_t * frFsp, u_char * buff, int bufSize)
+{
+  int encodedSize = 0;
+  u_short totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_int i, numLblRng;
+
+  /* get the size of the frAsp to be encoded and check it against
+     the buffer size */
+
+  if (MPLS_TLVFIXLEN + (int)(frFsp->baseTlv.length) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(frFsp->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  /* 
+   *  encode for M + N + dir + res 
+   */
+  numLblRng = frFsp->flags.flags.numLblRng;
+  frFsp->flags.flags.res = 0;
+  frFsp->flags.mark = htonl(frFsp->flags.mark);
+
+  MEM_COPY(tempBuf, (u_char *) & (frFsp->flags.mark), MPLS_FSPFIXLEN);
+  tempBuf += MPLS_FSPFIXLEN;
+  totalSize += MPLS_FSPFIXLEN;
+
+  /* 
+   *  encode for FR labels 
+   */
+  for (i = 0; i < numLblRng; i++) {
+    encodedSize = Mpls_encodeLdpFrLblRng(&(frFsp->lblRngList[i]),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_FSPLBLERROR;
+    }
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_encodeLdpFsp */
+
+/* 
+ * decode
+ */
+int Mpls_decodeLdpFsp(mplsLdpFspTlv_t * frFsp, u_char * buff, int bufSize)
+{
+  int decodedSize = 0;
+  u_short totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_int i;
+
+  if (MPLS_FSPFIXLEN > bufSize) {
+    /* the buffer does not contain even the required field */
+    PRINT_ERR("failed in decoding LdpFsp\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  decode for M + N + res 
+   */
+  MEM_COPY((u_char *) & (frFsp->flags.mark), tempBuf, MPLS_FSPFIXLEN);
+  tempBuf += MPLS_FSPFIXLEN;
+  totalSize += MPLS_FSPFIXLEN;
+
+  frFsp->flags.mark = ntohl(frFsp->flags.mark);
+
+  /*
+   *  decode for FR labels 
+   */
+  for (i = 0; i < frFsp->flags.flags.numLblRng; i++) {
+    decodedSize = Mpls_decodeLdpFrLblRng(&(frFsp->lblRngList[i]),
+      tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      PRINT_ERR("failed in decoding LdpFrLabel[%d] for LdpFsp\n", i);
+      return MPLS_DEC_FSPLBLERROR;
+    }
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_decodeLdpFsp */
+
+/*
+ *      Encode-decode for INIT msg 
+ */
+
+/* 
+ * encode for init message 
+ */
+int Mpls_encodeLdpInitMsg
+  (mplsLdpInitMsg_t * initMsg, u_char * buff, int bufSize) {
+  mplsLdpInitMsg_t initMsgCopy;
+  int encodedSize, totalSize;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  initMsgCopy = *initMsg;
+  totalSize = 0;
+
+  /* check the length of the messageId + mandatory param +
+     optional param */
+  if ((int)(initMsgCopy.baseMsg.msgLength) + MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("failed to encode the init msg: BUFFER TOO SMALL\n");
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  encode the base part of the pdu message
+   */
+  encodedSize = Mpls_encodeLdpBaseMsg(&(initMsgCopy.baseMsg), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_BASEMSGERROR;
+  }
+  PRINT_OUT("Encode BaseMsg for init on %d bytes\n", encodedSize);
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  /*
+   *  encode the csp if any 
+   */
+  if (initMsgCopy.cspExists) {
+    encodedSize = Mpls_encodeLdpCsp(&(initMsgCopy.csp),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_CSPERROR;
+    }
+    PRINT_OUT("Encoded for CSP %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  /*
+   *  encode the asp if any 
+   */
+  if (initMsgCopy.aspExists) {
+
+    encodedSize = Mpls_encodeLdpAsp(&(initMsgCopy.asp),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_ASPERROR;
+    }
+    PRINT_OUT("Encoded for ASP %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  /*
+   *  encode the fsp if any 
+   */
+  if (initMsgCopy.fspExists) {
+    encodedSize = Mpls_encodeLdpFsp(&(initMsgCopy.fsp),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_FSPERROR;
+    }
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_encodeLdpInitMsg */
+
+/* 
+ * decode for unknown message 
+ */
+int Mpls_decodeLdpUnknownMsg
+  (mplsLdpUnknownMsg_t * msg, u_char * buff, int bufSize) {
+  int decodedSize = 0;
+  u_int totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  /*
+   *  decode the base part of the pdu message
+   */
+  memset(msg, 0, sizeof(mplsLdpMsg_t));
+  decodedSize = Mpls_decodeLdpBaseMsg(&(msg->baseMsg), tempBuf, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for unknown on %d bytes\n", decodedSize);
+
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  if (bufSize - totalSize <= 0) {
+    /* nothing left for decoding */
+    PRINT_ERR("Init msg does not have anything beside base msg\n");
+    return totalSize;
+  }
+
+  if (msg->baseMsg.msgLength > MPLS_NOT_MAXSIZE) {
+    PRINT_ERR("Message is too big for unknow message buffer.\n");
+    return MPLS_DEC_BASEMSGERROR;
+  }
+
+  memcpy(msg->data, tempBuf, msg->baseMsg.msgLength);
+  decodedSize = msg->baseMsg.msgLength;
+
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  PRINT_OUT("totalsize for Mpls_decodeLdpUnknowntMsg is %d\n", totalSize);
+
+  return totalSize;
+}
+
+/* 
+ * decode for init message 
+ */
+int Mpls_decodeLdpInitMsg
+  (mplsLdpInitMsg_t * initMsg, u_char * buff, int bufSize) {
+  int decodedSize = 0;
+  u_int totalSize = 0;
+  u_int stopLength = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_int totalSizeParam = 0;
+  mplsLdpTlv_t tlvTemp;
+
+  /*
+   *  decode the base part of the pdu message
+   */
+  memset(initMsg, 0, sizeof(mplsLdpInitMsg_t));
+  decodedSize = Mpls_decodeLdpBaseMsg(&(initMsg->baseMsg), tempBuf, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for init on %d bytes\n", decodedSize);
+
+  if (initMsg->baseMsg.flags.flags.msgType != MPLS_INIT_MSGTYPE) {
+    PRINT_ERR("Not the right message type; expected init and got %x\n",
+      initMsg->baseMsg.flags.flags.msgType);
+    return MPLS_MSGTYPEERROR;
+  }
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  if (bufSize - totalSize <= 0) {
+    /* nothing left for decoding */
+    PRINT_ERR("Init msg does not have anything beside base msg\n");
+    return totalSize;
+  }
+
+  PRINT_OUT("bufSize = %d,  totalSize = %d, initMsg->baseMsg.msgLength = %d\n",
+    bufSize, totalSize, initMsg->baseMsg.msgLength);
+
+  /* Have to check the baseMsg.msgLength to know when to finish.
+   * We finsh when the totalSizeParam is >= to the base message length - the
+   * message id length (4) 
+   */
+
+  stopLength = initMsg->baseMsg.msgLength - MPLS_MSGIDFIXLEN;
+  while (stopLength > totalSizeParam) {
+    /*
+     *  decode the tlv to check what's next
+     */
+    decodedSize = Mpls_decodeLdpTlv(&tlvTemp, tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      /* something wrong */
+      PRINT_ERR("INIT msg decode failed for tlv\n");
+      return MPLS_DEC_TLVERROR;
+    }
+
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+    totalSizeParam += decodedSize;
+
+    switch (tlvTemp.flags.flags.tBit) {
+      case MPLS_CSP_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpCsp(&(initMsg->csp),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding Csp from init msg\n");
+            return MPLS_DEC_CSPERROR;
+          }
+          PRINT_OUT("Decoded for CSP %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+          initMsg->cspExists = 1;
+          initMsg->csp.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_ASP_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpAsp(&(initMsg->asp),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding Asp from init msg\n");
+            return MPLS_DEC_ASPERROR;
+          }
+          PRINT_OUT("Decoded for ASP %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+          initMsg->aspExists = 1;
+          initMsg->asp.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_FSP_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpFsp(&(initMsg->fsp),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding Fsp from init msg\n");
+            return MPLS_DEC_FSPERROR;
+          }
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+          initMsg->fspExists = 1;
+          initMsg->fsp.baseTlv = tlvTemp;
+          break;
+        }
+      default:
+        {
+          PRINT_ERR("Found wrong tlv type while decoding init msg (%d)\n",
+            tlvTemp.flags.flags.tBit);
+          if (tlvTemp.flags.flags.uBit == 1) {
+            /* ignore the Tlv and continue processing */
+            tempBuf += tlvTemp.length;
+            totalSize += tlvTemp.length;
+            totalSizeParam += tlvTemp.length;
+            break;
+          } else {
+            /* drop the message; return error */
+            return MPLS_TLVTYPEERROR;
+          }
+        }
+    }                           /* switch type */
+
+  }                             /* while */
+
+  PRINT_OUT("totalsize for Mpls_decodeLdpInitMsg is %d\n", totalSize);
+
+  return totalSize;
+
+}                               /* End: Mpls_decodeLdpInitMsg */
+
+/*
+ *      Encode-decode for Fr Label Range 
+ */
+
+/* 
+ * encode
+ */
+int Mpls_encodeLdpFrLblRng
+  (mplsLdpFrLblRng_t * frLabel, u_char * buff, int bufSize) {
+  if (MPLS_FRLRGFIXLEN > bufSize) {
+    /* not enough room for label */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  frLabel->flags.flags.res_min = 0;
+  frLabel->flags.flags.res_max = 0;
+  frLabel->flags.mark[0] = htonl(frLabel->flags.mark[0]);
+  frLabel->flags.mark[1] = htonl(frLabel->flags.mark[1]);
+
+  MEM_COPY(buff, (u_char *) frLabel, MPLS_FRLRGFIXLEN);
+
+  return MPLS_FRLRGFIXLEN;
+
+}                               /* End: Mpls_encodeLdpFrLblRng */
+
+/* 
+ * decode
+ */
+int Mpls_decodeLdpFrLblRng
+  (mplsLdpFrLblRng_t * frLabel, u_char * buff, int bufSize) {
+  if (MPLS_FRLRGFIXLEN > bufSize) {
+    PRINT_ERR("failed decoding the Fr Lbl Rng\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  MEM_COPY((u_char *) frLabel, buff, MPLS_FRLRGFIXLEN);
+
+  frLabel->flags.mark[0] = ntohl(frLabel->flags.mark[0]);
+  frLabel->flags.mark[1] = ntohl(frLabel->flags.mark[1]);
+
+  return MPLS_FRLRGFIXLEN;
+
+}                               /* End: Mpls_decodeLdpFrLblRng */
+
+/*
+ *      Encode-decode for NOTIFICATION msg 
+ */
+
+/* 
+ * encode for notification message 
+ */
+int Mpls_encodeLdpNotMsg(mplsLdpNotifMsg_t * notMsg, u_char * buff, int bufSize)
+{
+  mplsLdpNotifMsg_t notMsgCopy;
+  int encodedSize = 0;
+  u_int totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  /* check the length of the messageId + mandatory param +
+     optional param */
+  if ((int)(notMsg->baseMsg.msgLength) + MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("failed to encode the not msg: BUFFER TOO SMALL\n");
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  notMsgCopy = *notMsg;
+
+  /*
+   *  encode the base part of the pdu message
+   */
+  encodedSize = Mpls_encodeLdpBaseMsg(&(notMsgCopy.baseMsg), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_BASEMSGERROR;
+  }
+  PRINT_OUT("Encode BaseMsg for not on %d bytes\n", encodedSize);
+
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  if (notMsgCopy.statusTlvExists) {
+    encodedSize = Mpls_encodeLdpStatus(&(notMsgCopy.status),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_STATUSERROR;
+    }
+    PRINT_OUT("Encoded for STATUS %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (notMsgCopy.exStatusTlvExists) {
+    encodedSize = Mpls_encodeLdpExStatus(&(notMsgCopy.exStatus),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_EXSTATERROR;
+    }
+    PRINT_OUT("Encoded for EXTENDED STATUS %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (notMsgCopy.retPduTlvExists) {
+    encodedSize = Mpls_encodeLdpRetPdu(&(notMsgCopy.retPdu),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_RETPDUERROR;
+    }
+    PRINT_OUT("Encoded for RET PDU %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (notMsgCopy.retMsgTlvExists) {
+    encodedSize = Mpls_encodeLdpRetMsg(&(notMsgCopy.retMsg),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_RETMSGERROR;
+    }
+    PRINT_OUT("Encoded for RET MSG %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (notMsgCopy.lspidTlvExists) {
+    encodedSize = Mpls_encodeLdpLspIdTlv(&(notMsgCopy.lspidTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_LSPIDERROR;
+    }
+    PRINT_OUT("Encoded for LSPID Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_encodeLdpNotMsg */
+
+/* 
+ * decode for notification message 
+ */
+int Mpls_decodeLdpNotMsg(mplsLdpNotifMsg_t * notMsg, u_char * buff, int bufSize)
+{
+  int decodedSize = 0;
+  u_int totalSize = 0;
+  u_int stopLength = 0;
+  u_int totalSizeParam = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  mplsLdpTlv_t tlvTemp;
+
+  /*
+   *  decode the base part of the pdu message
+   */
+  memset(notMsg, 0, sizeof(mplsLdpNotifMsg_t));
+  decodedSize = Mpls_decodeLdpBaseMsg(&(notMsg->baseMsg), tempBuf, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for not on %d bytes\n", decodedSize);
+
+  if (notMsg->baseMsg.flags.flags.msgType != MPLS_NOT_MSGTYPE) {
+    PRINT_ERR("Not the right message type; expected not and got %x\n",
+      notMsg->baseMsg.flags.flags.msgType);
+    return MPLS_MSGTYPEERROR;
+  }
+
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  if (bufSize - totalSize <= 0) {
+    /* nothing left for decoding */
+    PRINT_ERR("Not msg does not have anything beside base msg\n");
+    return totalSize;
+  }
+
+  PRINT_OUT("bufSize = %d,  totalSize = %d, notMsg->baseMsg.msgLength = %d\n",
+    bufSize, totalSize, notMsg->baseMsg.msgLength);
+
+  /* Have to check the baseMsg.msgLength to know when to finish.
+   * We finsh when the totalSizeParam is >= to the base message length - the
+   * message id length (4) 
+   */
+
+  stopLength = notMsg->baseMsg.msgLength - MPLS_MSGIDFIXLEN;
+  while (stopLength > totalSizeParam) {
+    /*
+     *  decode the tlv to check what's next
+     */
+    memset(&tlvTemp, 0, MPLS_TLVFIXLEN);
+    decodedSize = Mpls_decodeLdpTlv(&tlvTemp, tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      /* something wrong */
+      PRINT_ERR("NOT msg decode failed for tlv\n");
+      return MPLS_DEC_TLVERROR;
+    }
+
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+    totalSizeParam += decodedSize;
+
+    switch (tlvTemp.flags.flags.tBit) {
+      case MPLS_NOT_ST_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpStatus(&(notMsg->status),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding Status from not msg\n");
+            return MPLS_DEC_STATUSERROR;
+          }
+          PRINT_OUT("Decoded for STATUS %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          notMsg->statusTlvExists = 1;
+          notMsg->status.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_NOT_ES_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpExStatus(&(notMsg->exStatus),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding Extended Status from not msg\n");
+            return MPLS_DEC_EXSTATERROR;
+          }
+          PRINT_OUT("Decoded for EX_STATUS %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          notMsg->exStatusTlvExists = 1;
+          notMsg->exStatus.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_NOT_RP_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpRetPdu(&(notMsg->retPdu),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding Returned PDU from not msg\n");
+            return MPLS_DEC_RETPDUERROR;
+          }
+          PRINT_OUT("Decoded for RET_PDU %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          notMsg->retPduTlvExists = 1;
+          notMsg->retPdu.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_NOT_RM_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpRetMsg(&(notMsg->retMsg),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding Returned MSG from not msg\n");
+            return MPLS_DEC_RETMSGERROR;
+          }
+          PRINT_OUT("Decoded for RET_MSG %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          notMsg->retMsgTlvExists = 1;
+          notMsg->retMsg.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_LSPID_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpLspIdTlv(&(notMsg->lspidTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec LSPID tlv from Not msg\n");
+            return MPLS_DEC_LSPIDERROR;
+          }
+          PRINT_OUT("Decoded for lspid tlv %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          notMsg->lspidTlvExists = 1;
+          notMsg->lspidTlv.baseTlv = tlvTemp;
+          break;
+        }
+      default:
+        {
+          PRINT_ERR("Found wrong tlv type while decoding not msg (%d)\n",
+            tlvTemp.flags.flags.tBit);
+          if (tlvTemp.flags.flags.uBit == 1) {
+            /* ignore the Tlv and continue processing */
+            tempBuf += tlvTemp.length;
+            totalSize += tlvTemp.length;
+            totalSizeParam += tlvTemp.length;
+            break;
+          } else {
+            /* drop the message; return error */
+            return MPLS_TLVTYPEERROR;
+          }
+        }
+    }                           /* switch type */
+
+  }                             /* while */
+
+  PRINT_OUT("totalsize for Mpls_decodeLdpNotMsg is %d\n", totalSize);
+
+  return totalSize;
+
+}                               /* End: Mpls_decodeLdpNotMsg */
+
+/*
+ *      Encode-decode for Status TLV 
+ */
+
+/* 
+ * encode:
+ */
+int Mpls_encodeLdpStatus
+  (mplsLdpStatusTlv_t * status, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_char *statusPtr;
+
+  if (MPLS_STATUSFIXLEN + MPLS_TLVFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(status->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in STATUS\n");
+    return MPLS_ENC_TLVERROR;
+  }
+
+  statusPtr = (u_char *) status;
+  tempBuf += encodedSize;
+  statusPtr += encodedSize;
+
+  /* 
+   *  encode for the rest of the  Status
+   */
+  status->flags.mark = htonl(status->flags.mark);
+  status->msgId = htonl(status->msgId);
+  status->msgType = htons(status->msgType);
+
+  MEM_COPY(tempBuf, statusPtr, MPLS_STATUSFIXLEN);
+
+  return (MPLS_STATUSFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpStatus */
+
+/* 
+ * decode:
+ */
+int Mpls_decodeLdpStatus
+  (mplsLdpStatusTlv_t * status, u_char * buff, int bufSize) {
+  u_char *statusPtr;
+
+  if (MPLS_STATUSFIXLEN > bufSize) {
+    /* not enough data for Status */
+    PRINT_ERR("failed decoding Status\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  statusPtr = (u_char *) status;
+  statusPtr += MPLS_TLVFIXLEN;  /* we want to point to the flags since the
+                                   tlv was decoded before we reach here */
+
+  /* 
+   *  decode for the rest of the Status
+   */
+  MEM_COPY(statusPtr, buff, MPLS_STATUSFIXLEN);
+
+  status->flags.mark = ntohl(status->flags.mark);
+  status->msgId = ntohl(status->msgId);
+  status->msgType = ntohs(status->msgType);
+
+  return MPLS_STATUSFIXLEN;
+
+}                               /* End: Mpls_decodeLdpStatus */
+
+/*
+ *      Encode-decode for Extended Status TLV 
+ */
+
+/* 
+ * encode:
+ */
+int Mpls_encodeLdpExStatus
+  (mplsLdpExStatusTlv_t * status, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_EXSTATUSLEN + MPLS_TLVFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(status->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in EX_STATUS\n");
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  status->value = htonl(status->value);
+
+  MEM_COPY(tempBuf, (u_char *) & (status->value), sizeof(u_int));
+
+  return (MPLS_EXSTATUSLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpExStatus */
+
+/* 
+ * decode:
+ */
+int Mpls_decodeLdpExStatus
+  (mplsLdpExStatusTlv_t * status, u_char * buff, int bufSize) {
+  if (MPLS_EXSTATUSLEN > bufSize) {
+    /* not enough data for ExStatus */
+    PRINT_ERR("failed decoding ExStatus\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  decode for the rest of the Status
+   */
+  MEM_COPY(&(status->value), buff, MPLS_EXSTATUSLEN);
+
+  status->value = ntohl(status->value);
+
+  return MPLS_EXSTATUSLEN;
+
+}                               /* End: Mpls_decodeLdpExStatus */
+
+/*
+ *      Encode-decode for Return PDU TLV
+ */
+
+/* 
+ * encode:
+ */
+int Mpls_encodeLdpRetPdu
+  (mplsLdpRetPduTlv_t * retPdu, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_short tempLength;           /* to store the tlv length for
+
+                                   later use */
+
+  if (MPLS_TLVFIXLEN + (int)(retPdu->baseTlv.length) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  tempLength = retPdu->baseTlv.length;
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(retPdu->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in RET_PDU\n");
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  /* 
+   *  encode the data of the ret pdu
+   */
+
+  encodedSize = Mpls_encodeLdpMsgHeader(&(retPdu->headerTlv),
+    tempBuf, bufSize - encodedSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the header Tlv in RET_PDU\n");
+    return MPLS_ENC_HDRTLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  MEM_COPY(tempBuf, retPdu->data, tempLength);
+
+  return (MPLS_TLVFIXLEN + tempLength);
+
+}                               /* End: Mpls_encodeLdpRetPdu */
+
+/* 
+ * decode:
+ */
+int Mpls_decodeLdpRetPdu
+  (mplsLdpRetPduTlv_t * retPdu, u_char * buff, int bufSize, u_short tlvLength) {
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  int decodedSize;
+
+  if ((int)tlvLength > bufSize) {
+    /* not enough data for ExStatus */
+    PRINT_ERR("failed decoding Ret pdu\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  decode data for ret pdu
+   */
+  decodedSize = Mpls_decodeLdpMsgHeader(&(retPdu->headerTlv), tempBuf, bufSize);
+  if (decodedSize < 0) {
+    PRINT_ERR("failed decoding the header Tlv in RET_PDU\n");
+    return MPLS_DEC_HDRTLVERROR;
+  }
+  tempBuf += decodedSize;
+
+  MEM_COPY(retPdu->data, tempBuf, tlvLength);
+
+  return tlvLength;
+
+}                               /* End: Mpls_decodeLdpRetPdu */
+
+/*
+ *      Encode-decode for Return Msg TLV 
+ */
+
+/* 
+ * encode:
+ */
+int Mpls_encodeLdpRetMsg
+  (mplsLdpRetMsgTlv_t * retMsg, u_char * buff, int bufSize) {
+  u_char *retMsgPtr;
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_short tempLength;           /* to store the tlv length for
+
+                                   later use */
+
+  if (MPLS_TLVFIXLEN + (int)(retMsg->baseTlv.length) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  tempLength = retMsg->baseTlv.length;
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(retMsg->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in RET_MSG\n");
+    return MPLS_ENC_TLVERROR;
+  }
+
+  retMsgPtr = (u_char *) retMsg;
+  tempBuf += encodedSize;
+  retMsgPtr += encodedSize;
+
+  /* 
+   *  encode the data of the ret pdu
+   */
+
+  retMsg->msgType = htons(retMsg->msgType);
+  retMsg->msgLength = htons(retMsg->msgLength);
+
+  MEM_COPY(tempBuf, retMsgPtr, tempLength);
+
+  return (MPLS_TLVFIXLEN + tempLength);
+
+}                               /* End: Mpls_encodeLdpRetMsg */
+
+/* 
+ * decode:
+ */
+int Mpls_decodeLdpRetMsg
+  (mplsLdpRetMsgTlv_t * retMsg, u_char * buff, int bufSize, u_short tlvLength) {
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_char *retMsgPtr;
+
+  if ((int)tlvLength > bufSize) {
+    /* not enough data for ExStatus */
+    PRINT_ERR("failed decoding Ret msg\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+  retMsgPtr = (u_char *) retMsg;
+  retMsgPtr += MPLS_TLVFIXLEN;
+
+  /* 
+   *  decode data for ret msg 
+   */
+  MEM_COPY(retMsgPtr, tempBuf, tlvLength);
+
+  retMsg->msgType = ntohs(retMsg->msgType);
+  retMsg->msgLength = ntohs(retMsg->msgLength);
+
+  return tlvLength;
+
+}                               /* End: Mpls_decodeLdpRetMsg */
+
+/*
+ *      Encode-decode for HELLO msg 
+ */
+
+/* 
+ * encode for HELLO message 
+ */
+int Mpls_encodeLdpHelloMsg
+  (mplsLdpHelloMsg_t * helloMsg, u_char * buff, int bufSize) {
+  mplsLdpHelloMsg_t helloMsgCopy;
+  int encodedSize = 0;
+  u_int totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  /* check the length of the messageId + mandatory param +
+     optional param */
+  if ((int)(helloMsg->baseMsg.msgLength) + MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("failed to encode the hello msg: BUFFER TOO SMALL\n");
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  helloMsgCopy = *helloMsg;
+
+  /*
+   *  encode the base part of the pdu message
+   */
+  encodedSize = Mpls_encodeLdpBaseMsg(&(helloMsgCopy.baseMsg),
+    tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_BASEMSGERROR;
+  }
+  PRINT_OUT("Encode BaseMsg for hello on %d bytes\n", encodedSize);
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  /*
+   *  encode the status tlv if any 
+   */
+  if (helloMsgCopy.chpTlvExists) {
+    encodedSize = Mpls_encodeLdpChp(&(helloMsgCopy.chp),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_CHPERROR;
+    }
+    PRINT_OUT("Encoded for CHP %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (helloMsgCopy.trAdrTlvExists) {
+    encodedSize = Mpls_encodeLdpTrAdr(&(helloMsgCopy.trAdr),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_TRADRERROR;
+    }
+    PRINT_OUT("Encoded for TR ADDR %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (helloMsgCopy.csnTlvExists) {
+    encodedSize = Mpls_encodeLdpCsn(&(helloMsgCopy.csn),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_CSNERROR;
+    }
+    PRINT_OUT("Encoded for CSN %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_encodeLdpHelloMsg */
+
+/* 
+ * decode for HELLO message 
+ */
+int Mpls_decodeLdpHelloMsg
+  (mplsLdpHelloMsg_t * helloMsg, u_char * buff, int bufSize) {
+  int decodedSize = 0;
+  u_int totalSize = 0;
+  u_int stopLength = 0;
+  u_int totalSizeParam = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  mplsLdpTlv_t tlvTemp;
+
+  /*
+   *  decode the base part of the pdu message
+   */
+  memset(helloMsg, 0, sizeof(mplsLdpHelloMsg_t));
+  decodedSize = Mpls_decodeLdpBaseMsg(&(helloMsg->baseMsg), tempBuf, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for hello on %d bytes\n", decodedSize);
+
+  if (helloMsg->baseMsg.flags.flags.msgType != MPLS_HELLO_MSGTYPE) {
+    PRINT_ERR("Not the right message type; expected hello and got %x\n",
+      helloMsg->baseMsg.flags.flags.msgType);
+    return MPLS_MSGTYPEERROR;
+  }
+
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  if (bufSize - totalSize <= 0) {
+    /* nothing left for decoding */
+    PRINT_ERR("Hello msg does not have anything beside base msg\n");
+    return totalSize;
+  }
+
+  PRINT_OUT("bufSize = %d,  totalSize = %d, helloMsg->baseMsg.msgLength = %d\n",
+    bufSize, totalSize, helloMsg->baseMsg.msgLength);
+
+  /* Have to check the baseMsg.msgLength to know when to finish.
+   * We finsh when the totalSizeParam is >= to the base message length - the
+   * message id length (4) 
+   */
+
+  stopLength = helloMsg->baseMsg.msgLength - MPLS_MSGIDFIXLEN;
+  while (stopLength > totalSizeParam) {
+    /*
+     *  decode the tlv to check what's next
+     */
+    memset(&tlvTemp, 0, MPLS_TLVFIXLEN);
+    decodedSize = Mpls_decodeLdpTlv(&tlvTemp, tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      /* something wrong */
+      PRINT_ERR("NOT msg decode failed for tlv\n");
+      return MPLS_DEC_TLVERROR;
+    }
+
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+    totalSizeParam += decodedSize;
+
+    switch (tlvTemp.flags.flags.tBit) {
+      case MPLS_CHP_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpChp(&(helloMsg->chp),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding Chp from hello msg\n");
+            return MPLS_DEC_CHPERROR;
+          }
+          PRINT_OUT("Decoded for CHP %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          helloMsg->chpTlvExists = 1;
+          helloMsg->chp.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_TRADR_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpTrAdr(&(helloMsg->trAdr),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding TrAdr from hello msg\n");
+            return MPLS_DEC_TRADRERROR;
+          }
+          PRINT_OUT("Decoded for TrAdr %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          helloMsg->trAdrTlvExists = 1;
+          helloMsg->trAdr.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_CSN_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpCsn(&(helloMsg->csn),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding Csn from hello msg\n");
+            return MPLS_DEC_CSNERROR;
+          }
+          PRINT_OUT("Decoded for CSN %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          helloMsg->csnTlvExists = 1;
+          helloMsg->csn.baseTlv = tlvTemp;
+          break;
+        }
+      default:
+        {
+          PRINT_ERR("Found wrong tlv type while decoding hello msg (%d)\n",
+            tlvTemp.flags.flags.tBit);
+          if (tlvTemp.flags.flags.uBit == 1) {
+            /* ignore the Tlv and continue processing */
+            tempBuf += tlvTemp.length;
+            totalSize += tlvTemp.length;
+            totalSizeParam += tlvTemp.length;
+            break;
+          } else {
+            /* drop the message; return error */
+            return MPLS_TLVTYPEERROR;
+          }
+        }
+    }                           /* switch type */
+
+  }                             /* while */
+
+  PRINT_OUT("totalsize for Mpls_decodeLdpHelloMsg is %d\n", totalSize);
+
+  return totalSize;
+
+}                               /* End: Mpls_decodeLdpHelloMsg */
+
+/* 
+ * Encode for Common Hello Parameters TLV
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpChp(mplsLdpChpTlv_t * chp, u_char * buff, int bufSize)
+{
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_char *chpPtr;
+
+  /* get the size of the chp to be encoded and check it against
+     the buffer size */
+
+  if (MPLS_TLVFIXLEN + MPLS_CHPFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(chp->baseTlv), tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+
+  chpPtr = (u_char *) chp;
+  tempBuf += encodedSize;
+  chpPtr += encodedSize;
+
+  /* 
+   *  encode for hold time + T +  R + res 
+   */
+  chp->flags.flags.res = 0;
+  chp->flags.mark = htons(chp->flags.mark);
+  chp->holdTime = htons(chp->holdTime);
+
+  MEM_COPY(tempBuf, chpPtr, MPLS_CHPFIXLEN);
+
+  return (MPLS_TLVFIXLEN + MPLS_CHPFIXLEN);
+
+}                               /* End: Mpls_encodeLdpChp */
+
+/* 
+ * decode
+ */
+int Mpls_decodeLdpChp(mplsLdpChpTlv_t * chp, u_char * buff, int bufSize)
+{
+  u_char *chpPtr;
+
+  if (MPLS_CHPFIXLEN > bufSize) {
+    /* not enough data for Chp */
+    PRINT_ERR("failed decoding hello Chp\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  chpPtr = (u_char *) chp;
+  chpPtr += MPLS_TLVFIXLEN;     /* we want to point to the flags since the
+                                   tlv was decoded before we reach here */
+
+  /*
+   *  decode for the rest of the Chp
+   */
+  MEM_COPY(chpPtr, buff, MPLS_CHPFIXLEN);
+
+  chp->holdTime = ntohs(chp->holdTime);
+  chp->flags.mark = ntohs(chp->flags.mark);
+
+  return MPLS_CHPFIXLEN;
+
+}                               /* End: Mpls_decodeLdpChp */
+
+/* 
+ * Encode for Configuration Sequence Number TLV
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpCsn(mplsLdpCsnTlv_t * csn, u_char * buff, int bufSize)
+{
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_CSNFIXLEN + MPLS_TLVFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  encode for tlv
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(csn->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in hello Csn\n");
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  csn->seqNumber = htonl(csn->seqNumber);
+
+  MEM_COPY(tempBuf, (u_char *) & (csn->seqNumber), MPLS_CSNFIXLEN);
+
+  return (MPLS_CSNFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpCsn */
+
+/* 
+ * decode
+ */
+int Mpls_decodeLdpCsn(mplsLdpCsnTlv_t * csn, u_char * buff, int bufSize)
+{
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_CSNFIXLEN > bufSize) {
+    /* not enough data for csn data */
+    PRINT_ERR("failed decoding hello Csn\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  decode for the rest of the Csn 
+   */
+  MEM_COPY(&(csn->seqNumber), tempBuf, MPLS_CSNFIXLEN);
+
+  csn->seqNumber = ntohl(csn->seqNumber);
+
+  return MPLS_CSNFIXLEN;
+
+}                               /* End: Mpls_decodeLdpCsn */
+
+/* 
+ * Encode for Transport Address TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpTrAdr(mplsLdpTrAdrTlv_t * trAdr, u_char * buff, int bufSize)
+{
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_TRADRFIXLEN + MPLS_TLVFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  encode for tlv
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(trAdr->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in hello TrAdr\n");
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  trAdr->address = htonl(trAdr->address);
+
+  MEM_COPY(tempBuf, (u_char *) & (trAdr->address), MPLS_TRADRFIXLEN);
+
+  return (MPLS_TRADRFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpTrAdr */
+
+/* 
+ * decode 
+ */
+int Mpls_decodeLdpTrAdr(mplsLdpTrAdrTlv_t * trAdr, u_char * buff, int bufSize)
+{
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_TRADRFIXLEN > bufSize) {
+    /* not enough data for csn data */
+    PRINT_ERR("failed decoding hello TrAdr\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  decode for the rest of the TrAdr 
+   */
+  MEM_COPY(&(trAdr->address), tempBuf, MPLS_TRADRFIXLEN);
+
+  trAdr->address = ntohl(trAdr->address);
+
+  return MPLS_TRADRFIXLEN;
+
+}                               /* End: Mpls_decodeLdpTrAdr */
+
+/* 
+ * Encode for KeepAlive Message
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpKeepAliveMsg
+  (mplsLdpKeepAlMsg_t * keepAlive, u_char * buff, int bufSize) {
+  mplsLdpKeepAlMsg_t keepAliveCopy;
+  int encodedSize = 0;
+
+  if (MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("failed to encode the keep alive msg: BUFFER TOO SMALL\n");
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  keepAliveCopy = *keepAlive;
+
+  encodedSize = Mpls_encodeLdpBaseMsg(&(keepAliveCopy.baseMsg), buff, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_BASEMSGERROR;
+  }
+  PRINT_OUT("Encode BaseMsg for keep alive on %d bytes\n", encodedSize);
+
+  return (MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpKeepAliveMsg */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpKeepAliveMsg
+  (mplsLdpKeepAlMsg_t * keepAlive, u_char * buff, int bufSize) {
+  int decodedSize = 0;
+
+  memset(keepAlive, 0, MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN);
+  decodedSize = Mpls_decodeLdpBaseMsg(&(keepAlive->baseMsg), buff, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for keep alive on %d bytes\n", decodedSize);
+
+  if (keepAlive->baseMsg.flags.flags.msgType != MPLS_KEEPAL_MSGTYPE) {
+    PRINT_ERR("Not the right message type; expected keep alive and got %x\n",
+      keepAlive->baseMsg.flags.flags.msgType);
+    return MPLS_MSGTYPEERROR;
+  }
+
+  return (MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_decodeLdpKeepAliveMsg */
+
+/* 
+ * Encode for Address List TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpAdrTlv(mplsLdpAdrTlv_t * adrList, u_char * buff, int bufSize)
+{
+  int i, numberAdr;
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_short tempLength;           /* to store the tlv length for
+
+                                   later use */
+
+  if (MPLS_TLVFIXLEN + (int)(adrList->baseTlv.length) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  tempLength = adrList->baseTlv.length;
+  /*
+   *  encode for tlv
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(adrList->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in AdrList\n");
+    return MPLS_ENC_TLVERROR;
+  }
+
+  tempBuf += encodedSize;
+
+  adrList->addrFamily = htons(adrList->addrFamily);
+
+  numberAdr = (tempLength - sizeof(u_short)) / sizeof(u_int);
+  for (i = 0; i < numberAdr; i++) {
+    adrList->address[i] = htonl(adrList->address[i]);
+  }
+
+  MEM_COPY(tempBuf, (u_char *) & adrList->addrFamily, sizeof(u_short));
+
+  tempBuf += sizeof(u_short);
+
+  MEM_COPY(tempBuf,
+    (u_char *) & adrList->address, tempLength - sizeof(u_short));
+
+  return (tempLength + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpAdrTlv */
+
+/*
+ *  decode
+ *
+ *  Note: the tlvLength is used to specify what is the length of the 
+ *        encoding in the AdrTlv.
+ */
+int Mpls_decodeLdpAdrTlv
+  (mplsLdpAdrTlv_t * adrList, u_char * buff, int bufSize, u_short tlvLength) {
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  int i, numberAdr;
+
+  if ((int)tlvLength > bufSize) {
+    /* not enough data for Adr list tlv */
+    PRINT_ERR("failed decoding AddrList tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  decode for the addressFamily and addresses of the address list
+   */
+  MEM_COPY((u_char *) & adrList->addrFamily, tempBuf, sizeof(u_short));
+  tempBuf += sizeof(u_short);
+
+  adrList->addrFamily = ntohs(adrList->addrFamily);
+
+  MEM_COPY((u_char *) & adrList->address, tempBuf, tlvLength - sizeof(u_short));
+
+  numberAdr = (tlvLength - sizeof(u_short)) / sizeof(u_int);
+  for (i = 0; i < numberAdr; i++) {
+    adrList->address[i] = ntohl(adrList->address[i]);
+  }
+
+  return tlvLength;
+
+}                               /* End: Mpls_decodeLdpAdrTlv */
+
+/* 
+ * Encode for Address / Address Withdraw messages
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpAdrMsg(mplsLdpAdrMsg_t * addrMsg, u_char * buff, int bufSize)
+{
+  mplsLdpAdrMsg_t addrMsgCopy;
+  int encodedSize = 0;
+  u_int totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  /* check the length of the messageId + param */
+  if ((int)(addrMsg->baseMsg.msgLength) + MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("failed to encode the address msg: BUFFER TOO SMALL\n");
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  addrMsgCopy = *addrMsg;
+
+  /*
+   *  encode the base part of the pdu message
+   */
+  encodedSize = Mpls_encodeLdpBaseMsg(&(addrMsgCopy.baseMsg), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_BASEMSGERROR;
+  }
+  PRINT_OUT("Encode BaseMsg for address on %d bytes\n", encodedSize);
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  /*
+   *  encode the address list tlv if any
+   */
+  if (addrMsg->adrListTlvExists) {
+    encodedSize = Mpls_encodeLdpAdrTlv(&(addrMsgCopy.addressList),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_ADRLISTERROR;
+    }
+    PRINT_OUT("Encoded for AddressList Tlv %d bytes\n", encodedSize);
+  }
+
+  return (addrMsg->baseMsg.msgLength + MPLS_TLVFIXLEN);
+
+}                               /* End: */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpAdrMsg(mplsLdpAdrMsg_t * addrMsg, u_char * buff, int bufSize)
+{
+  int decodedSize = 0;
+  u_int totalSize = 0;
+  u_int stopLength = 0;
+  u_int totalSizeParam = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  mplsLdpTlv_t tlvTemp;
+
+  /*
+   *  decode the base part of the pdu message
+   */
+  memset(addrMsg, 0, sizeof(mplsLdpAdrMsg_t));
+  decodedSize = Mpls_decodeLdpBaseMsg(&(addrMsg->baseMsg), tempBuf, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for address msg on %d bytes\n", decodedSize);
+
+  if ((addrMsg->baseMsg.flags.flags.msgType != MPLS_ADDR_MSGTYPE) &&
+    (addrMsg->baseMsg.flags.flags.msgType != MPLS_ADDRWITH_MSGTYPE)) {
+    PRINT_ERR("Not the right message type; expected adr and got %x\n",
+      addrMsg->baseMsg.flags.flags.msgType);
+    return MPLS_MSGTYPEERROR;
+  }
+
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  if (bufSize - totalSize <= 0) {
+    /* nothing left for decoding */
+    PRINT_ERR("Adr msg does not have anything beside base msg\n");
+    return totalSize;
+  }
+
+  PRINT_OUT("bufSize = %d,  totalSize = %d, addrMsg->baseMsg.msgLength = %d\n",
+    bufSize, totalSize, addrMsg->baseMsg.msgLength);
+
+  /* Have to check the baseMsg.msgLength to know when to finish.
+   * We finsh when the totalSizeParam is >= to the base message length - the
+   * message id length (4) 
+   */
+
+  stopLength = addrMsg->baseMsg.msgLength - MPLS_MSGIDFIXLEN;
+  while (stopLength > totalSizeParam) {
+    /*
+     *  decode the tlv to check what's next
+     */
+    memset(&tlvTemp, 0, MPLS_TLVFIXLEN);
+    decodedSize = Mpls_decodeLdpTlv(&tlvTemp, tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      /* something wrong */
+      PRINT_ERR("ADR msg decode failed for tlv\n");
+      return MPLS_DEC_TLVERROR;
+    }
+
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+    totalSizeParam += decodedSize;
+
+    switch (tlvTemp.flags.flags.tBit) {
+      case MPLS_ADDRLIST_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpAdrTlv(&(addrMsg->addressList),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding AdrList tlv from adr msg\n");
+            return MPLS_DEC_ADRLISTERROR;
+          }
+          PRINT_OUT("Decoded for ADRLIST %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          addrMsg->adrListTlvExists = 1;
+          addrMsg->addressList.baseTlv = tlvTemp;
+          break;
+        }
+      default:
+        {
+          PRINT_ERR("Found wrong tlv type while decoding adr msg (%x)\n",
+            tlvTemp.flags.flags.tBit);
+          if (tlvTemp.flags.flags.uBit == 1) {
+            /* ignore the Tlv and continue processing */
+            tempBuf += tlvTemp.length;
+            totalSize += tlvTemp.length;
+            totalSizeParam += tlvTemp.length;
+            break;
+          } else {
+            /* drop the message; return error */
+            return MPLS_TLVTYPEERROR;
+          }
+        }
+    }                           /* switch type */
+
+  }                             /* while */
+
+  PRINT_OUT("totalsize for Mpls_decodeLdpAdrMsg is %d\n", totalSize);
+
+  return totalSize;
+
+}                               /* End: Mpls_decodeLdpAdrMsg */
+
+/* 
+ * Encode for FEC ELEMENT 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpFecAdrEl
+  (mplsFecElement_t * fecAdrEl, u_char * buff, int bufSize, u_char type) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;
+
+  switch (type) {
+    case MPLS_WC_FEC:
+      {
+        if (MPLS_FEC_ELEMTYPELEN > bufSize) {
+          return MPLS_ENC_BUFFTOOSMALL;
+        }
+        *buff = fecAdrEl->wildcardEl.type;
+        encodedSize = MPLS_FEC_ELEMTYPELEN;
+        break;
+      }
+    case MPLS_PREFIX_FEC:
+      {
+        int preLenOctets;
+
+        fecAdrEl->addressEl.addressFam = htons(fecAdrEl->addressEl.addressFam);
+        fecAdrEl->addressEl.address = htonl(fecAdrEl->addressEl.address);
+        preLenOctets = (int)(fecAdrEl->addressEl.preLen / 8) +
+          ((int)(fecAdrEl->addressEl.preLen % 8) > 0 ? 1 : 0);
+
+        encodedSize = MPLS_FEC_ADRFAMLEN + MPLS_FEC_ELEMTYPELEN +
+          MPLS_FEC_PRELENLEN + preLenOctets;
+
+        if (encodedSize > bufSize) {
+          return MPLS_ENC_BUFFTOOSMALL;
+        }
+        *tempBuf = fecAdrEl->addressEl.type;
+        tempBuf++;              /* for MPLS_FEC_ELEMTYPELEN */
+
+        MEM_COPY(tempBuf,
+          (u_char *) & (fecAdrEl->addressEl.addressFam), MPLS_FEC_ADRFAMLEN);
+        tempBuf += MPLS_FEC_ADRFAMLEN;
+
+        *tempBuf = fecAdrEl->addressEl.preLen;
+        tempBuf++;              /* for MPLS_FEC_PRELENLEN */
+
+        MEM_COPY(tempBuf, (u_char *) & (fecAdrEl->addressEl.address),
+          preLenOctets);
+        break;
+      }
+    case MPLS_HOSTADR_FEC:
+      {
+        fecAdrEl->addressEl.addressFam = htons(fecAdrEl->addressEl.addressFam);
+        fecAdrEl->addressEl.address = htonl(fecAdrEl->addressEl.address);
+
+        encodedSize = MPLS_FEC_ADRFAMLEN + MPLS_FEC_ELEMTYPELEN +
+          MPLS_FEC_PRELENLEN + fecAdrEl->addressEl.preLen;
+
+        if (encodedSize > bufSize) {
+          return MPLS_ENC_BUFFTOOSMALL;
+        }
+        *tempBuf = fecAdrEl->addressEl.type;
+        tempBuf++;              /* for MPLS_FEC_ELEMTYPELEN */
+
+        MEM_COPY(tempBuf,
+          (u_char *) & (fecAdrEl->addressEl.addressFam), MPLS_FEC_ADRFAMLEN);
+        tempBuf += MPLS_FEC_ADRFAMLEN;
+
+        *tempBuf = fecAdrEl->addressEl.preLen;
+        tempBuf++;              /* for MPLS_FEC_PRELENLEN */
+
+        MEM_COPY(tempBuf,
+          (u_char *) & (fecAdrEl->addressEl.address),
+          fecAdrEl->addressEl.preLen);
+        break;
+      }
+    case MPLS_CRLSP_FEC:
+      {
+        if (MPLS_FEC_CRLSPLEN > bufSize) {
+          return MPLS_ENC_BUFFTOOSMALL;
+        }
+        fecAdrEl->crlspEl.res1 = 0;
+        fecAdrEl->crlspEl.res2 = 0;
+        MEM_COPY(tempBuf, (u_char *) & (fecAdrEl->crlspEl), MPLS_FEC_CRLSPLEN);
+        encodedSize = MPLS_FEC_CRLSPLEN;
+        break;
+      }
+    default:
+      {
+        PRINT_ERR("Found wrong FEC type while encoding FEC elem (%d)\n", type);
+        return MPLS_ENC_FECELEMERROR;
+        break;
+      }
+  }                             /* end: switch */
+
+  return encodedSize;
+
+}                               /* End: Mpls_encodeLdpFecAdrEl */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpFecAdrEl
+  (mplsFecElement_t * fecAdrEl, u_char * buff, int bufSize, u_char type) {
+  int decodedSize = 0;
+  u_char *tempBuff = buff;
+  u_int preLen = 0;
+
+  switch (type) {
+    case MPLS_WC_FEC:
+      {
+        fecAdrEl->wildcardEl.type = *buff;
+        decodedSize = MPLS_FEC_ELEMTYPELEN;
+        break;
+      }
+    case MPLS_PREFIX_FEC:
+      {
+        decodedSize = MPLS_FEC_ADRFAMLEN + MPLS_FEC_ELEMTYPELEN +
+          MPLS_FEC_PRELENLEN;
+        if (decodedSize > bufSize) {
+          return MPLS_DEC_BUFFTOOSMALL;
+        }
+        fecAdrEl->addressEl.type = *tempBuff;
+        tempBuff++;             /* for MPLS_FEC_ELEMTYPELEN */
+
+        MEM_COPY((u_char *) & (fecAdrEl->addressEl.addressFam),
+          tempBuff, MPLS_FEC_ADRFAMLEN);
+        tempBuff += MPLS_FEC_ADRFAMLEN;
+
+        fecAdrEl->addressEl.preLen = *tempBuff;
+        tempBuff++;             /* for MPLS_FEC_PRELENLEN */
+
+        fecAdrEl->addressEl.addressFam = ntohs(fecAdrEl->addressEl.addressFam);
+
+        /* now we get the prefix; we need to use the preLen which was
+           decoded from buff */
+
+        preLen = (int)(fecAdrEl->addressEl.preLen / 8) +
+          ((int)(fecAdrEl->addressEl.preLen % 8) > 0 ? 1 : 0);
+
+        if (fecAdrEl->addressEl.preLen > sizeof(u_int) * 8) {
+          /* error - the length cannot exeed 32 bits */
+          /* skip the FEC and return error code */
+          /* fill in the preLen field to the number of bytes for this
+             fec; we need it to know how much to skip from the buffer 
+             when we do the decoding for the following fec element */
+          fecAdrEl->addressEl.preLen = preLen + decodedSize;
+          return MPLS_FECERROR;
+        }
+        if ((int)preLen > bufSize - decodedSize) {
+          return MPLS_DEC_BUFFTOOSMALL;
+        }
+        MEM_COPY((u_char *) & (fecAdrEl->addressEl.address), tempBuff, preLen);
+
+        fecAdrEl->addressEl.address = ntohl(fecAdrEl->addressEl.address);
+        decodedSize += preLen;
+        break;
+      }
+    case MPLS_HOSTADR_FEC:
+      {
+        decodedSize = MPLS_FEC_ADRFAMLEN + MPLS_FEC_ELEMTYPELEN +
+          MPLS_FEC_PRELENLEN;
+        if (decodedSize > bufSize) {
+          return MPLS_DEC_BUFFTOOSMALL;
+        }
+        fecAdrEl->addressEl.type = *tempBuff;
+        tempBuff++;             /* for MPLS_FEC_ELEMTYPELEN */
+
+        MEM_COPY((u_char *) & (fecAdrEl->addressEl.addressFam),
+          tempBuff, MPLS_FEC_ADRFAMLEN);
+        tempBuff += MPLS_FEC_ADRFAMLEN;
+
+        fecAdrEl->addressEl.preLen = *tempBuff;
+        tempBuff++;             /* for MPLS_FEC_PRELENLEN */
+
+        fecAdrEl->addressEl.addressFam = ntohs(fecAdrEl->addressEl.addressFam);
+
+        /* now we get the host address; we need to use the preLen which was
+           decoded from buff */
+
+        preLen = fecAdrEl->addressEl.preLen;
+        if (fecAdrEl->addressEl.preLen > sizeof(u_int)) {
+          /* error - the length cannot exeed 32 bits */
+          /* skip the FEC and return error code */
+          /* fill in the preLen field to the number of bytes for this
+             fec; we need it to know how much to skip from the buffer 
+             when we do the decoding for the following fec element */
+          fecAdrEl->addressEl.preLen = preLen + decodedSize;
+          return MPLS_FECERROR;
+        }
+        if ((int)preLen > bufSize - decodedSize) {
+          return MPLS_DEC_BUFFTOOSMALL;
+        }
+        MEM_COPY((u_char *) & (fecAdrEl->addressEl.address), tempBuff, preLen);
+
+        fecAdrEl->addressEl.address = ntohl(fecAdrEl->addressEl.address);
+        decodedSize += preLen;
+        break;
+      }
+    case MPLS_CRLSP_FEC:
+      {
+        if (MPLS_FEC_CRLSPLEN > bufSize) {
+          return MPLS_DEC_BUFFTOOSMALL;
+        }
+        MEM_COPY((u_char *) & (fecAdrEl->crlspEl), tempBuff, MPLS_FEC_CRLSPLEN);
+        decodedSize = MPLS_FEC_CRLSPLEN;
+        break;
+      }
+    default:
+      {
+        PRINT_ERR("Found wrong FEC type while decoding FEC elem (%d)\n", type);
+        return MPLS_DEC_FECELEMERROR;
+        break;
+      }
+  }                             /* end: switch */
+
+  return decodedSize;
+
+}                               /* End: Mpls_decodeLdpFecAdrEl */
+
+/* 
+ * Encode for FEC TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpFecTlv(mplsLdpFecTlv_t * fecTlv, u_char * buff, int bufSize)
+{
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_short i;
+  int encodedSize = 0;
+  u_int fecElSize = 0;          /* used to compute the sum of
+
+                                   all fec elements */
+
+  if ((int)fecTlv->baseTlv.length + MPLS_TLVFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* check how many fec elements we have */
+  if (fecTlv->numberFecElements > MPLS_MAXNUMFECELEMENT) {
+    /* too many fec elem; need to increase MPLS_MAXNUMFECELEMENT */
+    PRINT_ERR("Too many fec elem\n");
+    return MPLS_FECTLVERROR;
+  }
+
+  for (i = 0; i < fecTlv->numberFecElements; i++) {
+    if ((fecTlv->fecElemTypes[i] == MPLS_WC_FEC) &&
+      (fecTlv->numberFecElements != 1)) {
+      return MPLS_WC_FECERROR;
+    }
+  }
+
+  /*
+   *  encode for tlv
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(fecTlv->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in FEC tlv\n");
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+  fecElSize += encodedSize;
+
+  /* encode now the FEC elements; check if wc exists; if it is there
+     then it should be the only element */
+
+  for (i = 0; i < fecTlv->numberFecElements; i++) {
+    encodedSize = Mpls_encodeLdpFecAdrEl(&(fecTlv->fecElArray[i]),
+      tempBuf, bufSize - fecElSize, fecTlv->fecElemTypes[i]);
+    if (encodedSize < 0) {
+      return MPLS_ENC_FECELEMERROR;
+    }
+    tempBuf += encodedSize;
+    fecElSize += encodedSize;
+  }
+
+  return fecElSize;
+
+}                               /* End: Mpls_encodeLdpFecTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpFecTlv
+  (mplsLdpFecTlv_t * fecTlv, u_char * buff, int bufSize, u_short tlvLength) {
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  int decodedSize = 0;
+  u_int fecElSize = 0;          /* used to compute the sum of
+
+                                   all fec elements */
+  u_short i = 0;
+  u_char type;
+
+  if ((int)tlvLength > bufSize) {
+    /* not enough data for Fec elements tlv */
+    PRINT_ERR("failed decoding FEC elements tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  decode for the FEC elements; check also that if we have a wc element,
+   *  it is the only element encoded in the FEC;
+   */
+  type = *tempBuf;              /* first thing after the TLV base should be the type
+                                   of the fec element */
+
+  fecTlv->numberFecElements = 0;
+
+  while (tlvLength > fecElSize) {
+
+    /* check how many fec elements we have */
+    if (fecTlv->numberFecElements > (u_short) (MPLS_MAXNUMFECELEMENT - 1)) {
+      /* too many fec elem; need to increase MPLS_MAXNUMFECELEMENT */
+      PRINT_ERR("Too many fec elem\n");
+      return MPLS_FECTLVERROR;
+    }
+
+    decodedSize = Mpls_decodeLdpFecAdrEl(&(fecTlv->fecElArray[i]),
+      tempBuf, bufSize - fecElSize, type);
+    if ((decodedSize < 0) && (decodedSize != MPLS_FECERROR)) {
+      return MPLS_DEC_FECELEMERROR;
+    } else {
+      /* if the element had wrong preLen value, just skip it */
+      if (decodedSize != MPLS_FECERROR) {
+        fecTlv->fecElemTypes[i] = type;
+        fecTlv->numberFecElements++;
+        i++;
+
+        tempBuf += decodedSize;
+        fecElSize += decodedSize;
+      } else {
+        /* the preLen was filled with the total length
+           of the fec element to be skipped */
+        tempBuf += fecTlv->fecElArray[i].addressEl.preLen;
+        fecElSize += fecTlv->fecElArray[i].addressEl.preLen;
+      }
+    }
+
+    /* get the type of the next element */
+    type = *tempBuf;
+
+  }                             /* end while */
+
+  for (i = 0; i < fecTlv->numberFecElements; i++) {
+    if ((fecTlv->fecElemTypes[i] == MPLS_WC_FEC) &&
+      (fecTlv->numberFecElements != 1)) {
+      return MPLS_WC_FECERROR;
+    }
+  }
+
+  return fecElSize;             /* fecElSize should be equal to tlvLength */
+
+}                               /* End: Mpls_decodeLdpFecTlv */
+
+/* 
+ * Encode for Generic label TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpGenLblTlv
+  (mplsLdpGenLblTlv_t * genLbl, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_TLVFIXLEN + (int)(genLbl->baseTlv.length) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  encode for tlv
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(genLbl->baseTlv), tempBuf, bufSize);
+  if (encodedSize < 0) {
+    PRINT_ERR("failed encoding the tlv in Generic Label\n");
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  genLbl->label = htonl(genLbl->label);
+
+  MEM_COPY(tempBuf, (u_char *) & (genLbl->label), MPLS_LBLFIXLEN);
+
+  return (MPLS_TLVFIXLEN + MPLS_LBLFIXLEN);
+
+}                               /* End: Mpls_encodeLdpGenLblTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpGenLblTlv
+  (mplsLdpGenLblTlv_t * genLbl, u_char * buff, int bufSize) {
+  if (MPLS_LBLFIXLEN > bufSize) {
+    /* not enough data for generic label tlv */
+    PRINT_ERR("failed decoding Generic tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  decode the label
+   */
+  MEM_COPY((u_char *) & (genLbl->label), buff, MPLS_LBLFIXLEN);
+
+  genLbl->label = ntohl(genLbl->label);
+
+  return MPLS_LBLFIXLEN;
+
+}                               /* End: Mpls_decodeLdpGenLblTlv */
+
+/* 
+ * Encode for ATM Label TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpAtmLblTlv
+  (mplsLdpAtmLblTlv_t * atmLblTlv, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_char *atmLblPtr;
+
+  if (MPLS_TLVFIXLEN + MPLS_LBLFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  atmLblPtr = (u_char *) atmLblTlv;
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(atmLblTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+  atmLblPtr += encodedSize;
+
+  /* 
+   *  encode for flags
+   */
+  atmLblTlv->flags.flags.res = 0;
+  atmLblTlv->flags.mark = htons(atmLblTlv->flags.mark);
+  atmLblTlv->vci = htons(atmLblTlv->vci);
+
+  MEM_COPY(tempBuf, atmLblPtr, MPLS_LBLFIXLEN);
+
+  return (MPLS_LBLFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpAtmLblTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpAtmLblTlv
+  (mplsLdpAtmLblTlv_t * atmLblTlv, u_char * buff, int bufSize) {
+  u_char *atmLblTlvPtr;
+
+  if (MPLS_LBLFIXLEN > bufSize) {
+    /* not enough data for AtmLabel */
+    PRINT_ERR("failed decoding atm label tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  atmLblTlvPtr = (u_char *) atmLblTlv;
+  atmLblTlvPtr += MPLS_TLVFIXLEN; /* to point after the Tlv which was
+                                     decoded before we reach here */
+  /*
+   *  decode for the rest of the AtmLblTlv 
+   */
+  MEM_COPY(atmLblTlvPtr, buff, MPLS_LBLFIXLEN);
+
+  atmLblTlv->flags.mark = ntohs(atmLblTlv->flags.mark);
+  atmLblTlv->vci = ntohs(atmLblTlv->vci);
+
+  return MPLS_LBLFIXLEN;
+
+}                               /* End: Mpls_decodeLdpAtmLblTlv */
+
+/* 
+ * Encode for FR Label TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpFrLblTlv
+  (mplsLdpFrLblTlv_t * frLblTlv, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_TLVFIXLEN + MPLS_LBLFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(frLblTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  /* 
+   *  encode for flags
+   */
+  frLblTlv->flags.mark = htonl(frLblTlv->flags.mark);
+
+  MEM_COPY(tempBuf, (u_char *) & (frLblTlv->flags.mark), MPLS_LBLFIXLEN);
+
+  return (MPLS_LBLFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpFrLblTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpFrLblTlv
+  (mplsLdpFrLblTlv_t * frLblTlv, u_char * buff, int bufSize) {
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_LBLFIXLEN > bufSize) {
+    /* not enough data for FrLabel */
+    PRINT_ERR("failed decoding fr label tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  decode for the rest of the FrLblTlv 
+   */
+  MEM_COPY((u_char *) & (frLblTlv->flags.mark), tempBuf, MPLS_LBLFIXLEN);
+
+  frLblTlv->flags.mark = ntohl(frLblTlv->flags.mark);
+
+  return MPLS_LBLFIXLEN;
+
+}                               /* End: Mpls_decodeLdpFrLblTlv */
+
+/* 
+ * Encode for Hop Count TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpHopTlv
+  (mplsLdpHopTlv_t * hopCountTlv, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_TLVFIXLEN + MPLS_HOPCOUNTFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(hopCountTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  /* 
+   *  encode for hop count value 
+   */
+  *tempBuf = hopCountTlv->hcValue;
+
+  return (MPLS_HOPCOUNTFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpFrLblTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpHopTlv
+  (mplsLdpHopTlv_t * hopCountTlv, u_char * buff, int bufSize) {
+  if (MPLS_HOPCOUNTFIXLEN > bufSize) {
+    /* not enough data for hop count value */
+    PRINT_ERR("failed decoding hop count tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  decode for the hop count value
+   */
+  hopCountTlv->hcValue = *buff;
+
+  return MPLS_HOPCOUNTFIXLEN;
+
+}                               /* End: Mpls_decodeLdpHopTlv */
+
+/* 
+ * Encode for Lbl Msg Id TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpLblMsgIdTlv
+  (mplsLdpLblMsgIdTlv_t * lblMsgIdTlv, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_TLVFIXLEN + MPLS_LBLFIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(lblMsgIdTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  /* 
+   *  encode for msg id 
+   */
+
+  lblMsgIdTlv->msgId = htonl(lblMsgIdTlv->msgId);
+
+  MEM_COPY(tempBuf, (u_char *) & (lblMsgIdTlv->msgId), MPLS_LBLFIXLEN);
+
+  return (MPLS_LBLFIXLEN + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpFrLblTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpLblMsgIdTlv
+  (mplsLdpLblMsgIdTlv_t * lblMsgIdTlv, u_char * buff, int bufSize) {
+  if (MPLS_LBLFIXLEN > bufSize) {
+    /* not enough data for msg id tlv */
+    PRINT_ERR("failed decoding lbl msg id tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  /*
+   *  decode for the rest of the LblMsgId Tlv 
+   */
+  MEM_COPY((u_char *) & (lblMsgIdTlv->msgId), buff, MPLS_LBLFIXLEN);
+
+  lblMsgIdTlv->msgId = ntohl(lblMsgIdTlv->msgId);
+
+  return MPLS_LBLFIXLEN;
+
+}                               /* End: Mpls_decodeLdpLblMsgIdTlv */
+
+/* 
+ * Encode for Path Vector TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpPathVectorTlv
+  (mplsLdpPathTlv_t * pathVectorTlv, u_char * buff, int bufSize) {
+  u_char *pathVectorTlvPtr;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  int encodedSize = 0;
+  u_int i, numLsrIds;
+  u_short tempLength;           /* to store the tlv length for
+
+                                   later use */
+
+  if (MPLS_TLVFIXLEN + (int)(pathVectorTlv->baseTlv.length) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  pathVectorTlvPtr = (u_char *) pathVectorTlv;
+  tempLength = pathVectorTlv->baseTlv.length;
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(pathVectorTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+  pathVectorTlvPtr += encodedSize;
+
+  /* 
+   *  encode for labels
+   */
+
+  if (tempLength % MPLS_LBLFIXLEN != 0) {
+    return MPLS_PATHVECTORERROR;
+  }
+
+  numLsrIds = tempLength / MPLS_LBLFIXLEN;
+  if (numLsrIds > MPLS_MAXHOPSNUMBER) {
+    /* too many lsrIds; need to increase MPLS_MAXHOPSNUMBER */
+    PRINT_ERR("Too many lsr ids (%d)\n", numLsrIds);
+    return MPLS_PATHVECTORERROR;
+  }
+
+  for (i = 0; i < numLsrIds; i++) {
+    pathVectorTlv->lsrId[i] = htonl(pathVectorTlv->lsrId[i]);
+  }
+
+  MEM_COPY(tempBuf, pathVectorTlvPtr, tempLength);
+
+  return (tempLength + MPLS_TLVFIXLEN);
+
+}                               /* End: Mpls_encodeLdpPathVectorTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpPathVectorTlv
+  (mplsLdpPathTlv_t * pathVectorTlv,
+  u_char * buff, int bufSize, u_short tlvLength) {
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_int i, numLsrIds;
+
+  if (MPLS_LBLFIXLEN > bufSize) {
+    /* not enough data for msg id tlv */
+    PRINT_ERR("failed decoding lbl msg id tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  if (tlvLength % MPLS_LBLFIXLEN != 0) {
+    PRINT_ERR("Wrong length for Path vector tlv (%d)\n", tlvLength);
+    return MPLS_PATHVECTORERROR;
+  }
+
+  numLsrIds = tlvLength / MPLS_LBLFIXLEN;
+  if (numLsrIds > MPLS_MAXHOPSNUMBER) {
+    /* too many lsrIds; need to increase MPLS_MAXHOPSNUMBER */
+    PRINT_ERR("Too many lsr ids (%d)\n", numLsrIds);
+    return MPLS_PATHVECTORERROR;
+  }
+
+  /*
+   *  decode for the rest of the LblMsgId Tlv 
+   */
+  MEM_COPY((u_char *) (pathVectorTlv->lsrId), tempBuf, tlvLength);
+
+  for (i = 0; i < numLsrIds; i++) {
+    pathVectorTlv->lsrId[i] = ntohl(pathVectorTlv->lsrId[i]);
+  }
+
+  return tlvLength;
+
+}                               /* End: Mpls_decodeLdpPathVectorTlv */
+
+/* 
+ * Encode for Label Mapping Message
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpLblMapMsg
+  (mplsLdpLblMapMsg_t * lblMapMsg, u_char * buff, int bufSize) {
+  mplsLdpLblMapMsg_t lblMapMsgCopy;
+  int encodedSize = 0;
+  u_int totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  /* check the length of the messageId + param */
+  if ((int)(lblMapMsg->baseMsg.msgLength) + MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("failed to encode the lbl mapping msg: BUFFER TOO SMALL\n");
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  lblMapMsgCopy = *lblMapMsg;
+
+  /*
+   *  encode the base part of the pdu message
+   */
+  encodedSize = Mpls_encodeLdpBaseMsg(&(lblMapMsgCopy.baseMsg),
+    tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_BASEMSGERROR;
+  }
+  PRINT_OUT("Encode BaseMsg for label mapping on %d bytes\n", encodedSize);
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  /*
+   *  encode the tlv if any
+   */
+  if (lblMapMsgCopy.fecTlvExists) {
+    encodedSize = Mpls_encodeLdpFecTlv(&(lblMapMsgCopy.fecTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_FECERROR;
+    }
+    PRINT_OUT("Encoded for FEC Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  if (lblMapMsgCopy.genLblTlvExists) {
+    encodedSize = Mpls_encodeLdpGenLblTlv(&(lblMapMsgCopy.genLblTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_GENLBLERROR;
+    }
+    PRINT_OUT("Encoded for Generic Label Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblMapMsgCopy.atmLblTlvExists) {
+    encodedSize = Mpls_encodeLdpAtmLblTlv(&(lblMapMsgCopy.atmLblTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_MAPATMERROR;
+    }
+    PRINT_OUT("Encoded for Atm Label Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblMapMsgCopy.frLblTlvExists) {
+    encodedSize = Mpls_encodeLdpFrLblTlv(&(lblMapMsgCopy.frLblTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_FRLBLERROR;
+    }
+    PRINT_OUT("Encoded for Fr Label Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblMapMsgCopy.hopCountTlvExists) {
+    encodedSize = Mpls_encodeLdpHopTlv(&(lblMapMsgCopy.hopCountTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_HOPCOUNTERROR;
+    }
+    PRINT_OUT("Encoded for Hop Count Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblMapMsgCopy.pathVecTlvExists) {
+    encodedSize = Mpls_encodeLdpPathVectorTlv(&(lblMapMsgCopy.pathVecTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_PATHVECERROR;
+    }
+    PRINT_OUT("Encoded for Path Vector Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblMapMsgCopy.lblMsgIdTlvExists) {
+    encodedSize = Mpls_encodeLdpLblMsgIdTlv(&(lblMapMsgCopy.lblMsgIdTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_LBLMSGIDERROR;
+    }
+    PRINT_OUT("Encoded for lbl request msg id Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblMapMsgCopy.trafficTlvExists) {
+    encodedSize = Mpls_encodeLdpTrafficTlv(&(lblMapMsgCopy.trafficTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_TRAFFICERROR;
+    }
+    PRINT_OUT("Encoded for Traffic Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblMapMsgCopy.lspidTlvExists) {
+    encodedSize = Mpls_encodeLdpLspIdTlv(&(lblMapMsgCopy.lspidTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_LSPIDERROR;
+    }
+    PRINT_OUT("Encoded for LSPID Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_encodeLdpLblMapMsg */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpLblMapMsg
+  (mplsLdpLblMapMsg_t * lblMapMsg, u_char * buff, int bufSize) {
+  int decodedSize = 0;
+  u_int totalSize = 0;
+  u_int stopLength = 0;
+  u_int totalSizeParam = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  mplsLdpTlv_t tlvTemp;
+
+  /*
+   *  decode the base part of the pdu message
+   */
+  memset(lblMapMsg, 0, sizeof(mplsLdpLblMapMsg_t));
+  decodedSize = Mpls_decodeLdpBaseMsg(&(lblMapMsg->baseMsg), tempBuf, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for Lbl Mapping on %d bytes\n", decodedSize);
+
+  if (lblMapMsg->baseMsg.flags.flags.msgType != MPLS_LBLMAP_MSGTYPE) {
+    PRINT_ERR("Not the right message type; expected lbl map and got %x\n",
+      lblMapMsg->baseMsg.flags.flags.msgType);
+    return MPLS_MSGTYPEERROR;
+  }
+
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  if (bufSize - totalSize <= 0) {
+    /* nothing left for decoding */
+    PRINT_ERR("Lbl Mapping msg does not have anything beside base msg\n");
+    return totalSize;
+  }
+
+  PRINT_OUT
+    ("bufSize = %d,  totalSize = %d, lblMapMsg->baseMsg.msgLength = %d\n",
+    bufSize, totalSize, lblMapMsg->baseMsg.msgLength);
+
+  /* Have to check the baseMsg.msgLength to know when to finish.
+   * We finsh when the totalSizeParam is >= to the base message length - the
+   * message id length (4) 
+   */
+
+  stopLength = lblMapMsg->baseMsg.msgLength - MPLS_MSGIDFIXLEN;
+  while (stopLength > totalSizeParam) {
+    /*
+     *  decode the tlv to check what's next
+     */
+    memset(&tlvTemp, 0, MPLS_TLVFIXLEN);
+    decodedSize = Mpls_decodeLdpTlv(&tlvTemp, tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      /* something wrong */
+      PRINT_ERR("Label Mapping msg decode failed for tlv\n");
+      return MPLS_DEC_TLVERROR;
+    }
+
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+    totalSizeParam += decodedSize;
+
+    switch (tlvTemp.flags.flags.tBit) {
+      case MPLS_FEC_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpFecTlv(&(lblMapMsg->fecTlv),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding FEC tlv from LblMap msg\n");
+            return MPLS_DEC_FECERROR;
+          }
+          PRINT_OUT("Decoded for FEC %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblMapMsg->fecTlvExists = 1;
+          lblMapMsg->fecTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_GENLBL_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpGenLblTlv(&(lblMapMsg->genLblTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec GEN Lbl tlv from LblMap msg\n");
+            return MPLS_DEC_GENLBLERROR;
+          }
+          PRINT_OUT("Decoded for Gen Lbl %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblMapMsg->genLblTlvExists = 1;
+          lblMapMsg->genLblTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_ATMLBL_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpAtmLblTlv(&(lblMapMsg->atmLblTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec ATM Lbl tlv from LblMap msg\n");
+            return MPLS_DEC_MAPATMERROR;
+          }
+          PRINT_OUT("Decoded for Atm Lbl %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblMapMsg->atmLblTlvExists = 1;
+          lblMapMsg->atmLblTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_FRLBL_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpFrLblTlv(&(lblMapMsg->frLblTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec FR Lbl tlv from LblMap msg\n");
+            return MPLS_DEC_FRLBLERROR;
+          }
+          PRINT_OUT("Decoded for Fr Lbl %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblMapMsg->frLblTlvExists = 1;
+          lblMapMsg->frLblTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_HOPCOUNT_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpHopTlv(&(lblMapMsg->hopCountTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec HopCount tlv from LblMap msg\n");
+            return MPLS_DEC_HOPCOUNTERROR;
+          }
+          PRINT_OUT("Decoded for HopCount %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblMapMsg->hopCountTlvExists = 1;
+          lblMapMsg->hopCountTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_PATH_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpPathVectorTlv(&(lblMapMsg->pathVecTlv),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec Path Vec tlv from LblMap msg\n");
+            return MPLS_DEC_PATHVECERROR;
+          }
+          PRINT_OUT("Decoded for PATH VECTOR %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblMapMsg->pathVecTlvExists = 1;
+          lblMapMsg->pathVecTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_REQMSGID_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpLblMsgIdTlv(&(lblMapMsg->lblMsgIdTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec LblMsgId tlv from LblMap msg\n");
+            return MPLS_DEC_LBLMSGIDERROR;
+          }
+          PRINT_OUT("Decoded for LblMsgId %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblMapMsg->lblMsgIdTlvExists = 1;
+          lblMapMsg->lblMsgIdTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_TRAFFIC_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpTrafficTlv(&(lblMapMsg->trafficTlv),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec Traffic tlv from LblMap msg\n");
+            return MPLS_DEC_TRAFFICERROR;
+          }
+          PRINT_OUT("Decoded for Traffic %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblMapMsg->trafficTlvExists = 1;
+          lblMapMsg->trafficTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_LSPID_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpLspIdTlv(&(lblMapMsg->lspidTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec LSPID tlv from LblMap msg\n");
+            return MPLS_DEC_LSPIDERROR;
+          }
+          PRINT_OUT("Decoded for lspid tlv %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblMapMsg->lspidTlvExists = 1;
+          lblMapMsg->lspidTlv.baseTlv = tlvTemp;
+          break;
+        }
+      default:
+        {
+          PRINT_ERR("Found wrong tlv type while decoding lbl map msg (%x)\n",
+            tlvTemp.flags.flags.tBit);
+          if (tlvTemp.flags.flags.uBit == 1) {
+            /* ignore the Tlv and continue processing */
+            tempBuf += tlvTemp.length;
+            totalSize += tlvTemp.length;
+            totalSizeParam += tlvTemp.length;
+            break;
+          } else {
+            /* drop the message; return error */
+            return MPLS_TLVTYPEERROR;
+          }
+        }
+    }                           /* switch type */
+
+  }                             /* while */
+
+  PRINT_OUT("totalsize for Mpls_decodeLdpLblMapMsg is %d\n", totalSize);
+
+  return totalSize;
+
+}                               /* End: Mpls_decodeLdpLblMapMsg */
+
+/* 
+ * Encode for Retrun MessageId TLV 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpLblRetMsgIdTlv
+  (mplsLdpLblRetMsgIdTlv_t * lblMsgIdTlv, u_char * buff, int bufSize) {
+  /* 
+   *  encode for tlv 
+   */
+  if (Mpls_encodeLdpTlv(&(lblMsgIdTlv->baseTlv), buff, MPLS_TLVFIXLEN) < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+
+  return MPLS_TLVFIXLEN;
+
+}                               /* End: Mpls_encodeLdpLblRetMsgIdTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpLblRetMsgIdTlv
+  (mplsLdpLblRetMsgIdTlv_t * lblMsgIdTlv, u_char * buff, int bufSize) {
+  /* this function does not need to do anything */
+  return 0;
+}                               /* End: Mpls_decodeLdpLblRetMsgIdTlv */
+
+/* 
+ * Encode for Label Request Message
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpLblReqMsg
+  (mplsLdpLblReqMsg_t * lblReqMsg, u_char * buff, int bufSize) {
+  mplsLdpLblReqMsg_t lblReqMsgCopy;
+  int encodedSize;
+  u_int totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  /* check the length of the messageId + param */
+  if ((int)(lblReqMsg->baseMsg.msgLength) + MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("failed to encode the lbl request msg: BUFFER TOO SMALL\n");
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  lblReqMsgCopy = *lblReqMsg;
+
+  /*
+   *  encode the base part of the pdu message
+   */
+  encodedSize = Mpls_encodeLdpBaseMsg(&(lblReqMsgCopy.baseMsg),
+    tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_BASEMSGERROR;
+  }
+  PRINT_OUT("Encode BaseMsg for label request on %d bytes\n", encodedSize);
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  /*
+   *  encode the tlv if any
+   */
+  if (lblReqMsgCopy.fecTlvExists) {
+    encodedSize = Mpls_encodeLdpFecTlv(&(lblReqMsgCopy.fecTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_FECERROR;
+    }
+    PRINT_OUT("Encoded for FEC Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblReqMsgCopy.hopCountTlvExists) {
+    encodedSize = Mpls_encodeLdpHopTlv(&(lblReqMsgCopy.hopCountTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_HOPCOUNTERROR;
+    }
+    PRINT_OUT("Encoded for Hop Count Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblReqMsgCopy.pathVecTlvExists) {
+    encodedSize = Mpls_encodeLdpPathVectorTlv(&(lblReqMsgCopy.pathVecTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_PATHVECERROR;
+    }
+    PRINT_OUT("Encoded for Hop Count Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblReqMsgCopy.lblMsgIdTlvExists) {
+    encodedSize = Mpls_encodeLdpLblRetMsgIdTlv(&(lblReqMsgCopy.lblMsgIdTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_LBLMSGIDERROR;
+    }
+    PRINT_OUT("Encoded for Hop Count Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblReqMsgCopy.erTlvExists) {
+    encodedSize = Mpls_encodeLdpERTlv(&(lblReqMsgCopy.erTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_ERTLVERROR;
+    }
+    PRINT_OUT("Encoded for CR Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblReqMsgCopy.trafficTlvExists) {
+    encodedSize = Mpls_encodeLdpTrafficTlv(&(lblReqMsgCopy.trafficTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_TRAFFICERROR;
+    }
+    PRINT_OUT("Encoded for Traffic Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblReqMsgCopy.lspidTlvExists) {
+    encodedSize = Mpls_encodeLdpLspIdTlv(&(lblReqMsgCopy.lspidTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_LSPIDERROR;
+    }
+    PRINT_OUT("Encoded for LSPID Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblReqMsgCopy.pinningTlvExists) {
+    encodedSize = Mpls_encodeLdpPinningTlv(&(lblReqMsgCopy.pinningTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_PINNINGERROR;
+    }
+    PRINT_OUT("Encoded for Pinning Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblReqMsgCopy.recClassTlvExists) {
+    encodedSize = Mpls_encodeLdpResClsTlv(&(lblReqMsgCopy.resClassTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_RESCLSERROR;
+    }
+    PRINT_OUT("Encoded for Resource class Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblReqMsgCopy.preemptTlvExists) {
+    encodedSize = Mpls_encodeLdpPreemptTlv(&(lblReqMsgCopy.preemptTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_PREEMPTERROR;
+    }
+    PRINT_OUT("Encoded for Preempt Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_encodeLdpLblReqMsg */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpLblReqMsg
+  (mplsLdpLblReqMsg_t * lblReqMsg, u_char * buff, int bufSize) {
+  int decodedSize = 0;
+  u_int totalSize = 0;
+  u_int stopLength = 0;
+  u_int totalSizeParam = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  mplsLdpTlv_t tlvTemp;
+
+  /*
+   *  decode the base part of the pdu message
+   */
+  memset(lblReqMsg, 0, sizeof(mplsLdpLblReqMsg_t));
+  decodedSize = Mpls_decodeLdpBaseMsg(&(lblReqMsg->baseMsg), tempBuf, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for Lbl Request on %d bytes\n", decodedSize);
+
+  if (lblReqMsg->baseMsg.flags.flags.msgType != MPLS_LBLREQ_MSGTYPE) {
+    PRINT_ERR("Not the right message type; expected lbl req and got %x\n",
+      lblReqMsg->baseMsg.flags.flags.msgType);
+    return MPLS_MSGTYPEERROR;
+  }
+
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  if (bufSize - totalSize <= 0) {
+    /* nothing left for decoding */
+    PRINT_ERR("Lbl Request msg does not have anything beside base msg\n");
+    return totalSize;
+  }
+
+  PRINT_OUT
+    ("bufSize = %d,  totalSize = %d, lblReqMsg->baseMsg.msgLength = %d\n",
+    bufSize, totalSize, lblReqMsg->baseMsg.msgLength);
+
+  /* Have to check the baseMsg.msgLength to know when to finish.
+   * We finsh when the totalSizeParam is >= to the base message length - the
+   * message id length (4) 
+   */
+
+  stopLength = lblReqMsg->baseMsg.msgLength - MPLS_MSGIDFIXLEN;
+  while (stopLength > totalSizeParam) {
+    /*
+     *  decode the tlv to check what's next
+     */
+    memset(&tlvTemp, 0, MPLS_TLVFIXLEN);
+    decodedSize = Mpls_decodeLdpTlv(&tlvTemp, tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      /* something wrong */
+      PRINT_ERR("Label Request msg decode failed for tlv\n");
+      return MPLS_DEC_TLVERROR;
+    }
+
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+    totalSizeParam += decodedSize;
+
+    switch (tlvTemp.flags.flags.tBit) {
+      case MPLS_FEC_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpFecTlv(&(lblReqMsg->fecTlv),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding FEC tlv from LblReq msg\n");
+            return MPLS_DEC_FECERROR;
+          }
+          PRINT_OUT("Decoded for FEC %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblReqMsg->fecTlvExists = 1;
+          lblReqMsg->fecTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_HOPCOUNT_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpHopTlv(&(lblReqMsg->hopCountTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec HopCount tlv from LblReq msg\n");
+            return MPLS_DEC_HOPCOUNTERROR;
+          }
+          PRINT_OUT("Decoded for HopCount %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblReqMsg->hopCountTlvExists = 1;
+          lblReqMsg->hopCountTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_PATH_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpPathVectorTlv(&(lblReqMsg->pathVecTlv),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec Path Vec tlv from LblReq msg\n");
+            return MPLS_DEC_PATHVECERROR;
+          }
+          PRINT_OUT("Decoded for PATH VECTOR %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblReqMsg->pathVecTlvExists = 1;
+          lblReqMsg->pathVecTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_LBLMSGID_TLVTYPE:
+        {
+          lblReqMsg->lblMsgIdTlvExists = 1;
+          lblReqMsg->lblMsgIdTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_ER_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpERTlv(&(lblReqMsg->erTlv),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec CR tlv from LblReq msg\n");
+            return MPLS_DEC_ERTLVERROR;
+          }
+          PRINT_OUT("Decoded for CR %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblReqMsg->erTlvExists = 1;
+          lblReqMsg->erTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_TRAFFIC_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpTrafficTlv(&(lblReqMsg->trafficTlv),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec Traffic tlv from LblReq msg\n");
+            return MPLS_DEC_TRAFFICERROR;
+          }
+          PRINT_OUT("Decoded for Traffic %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblReqMsg->trafficTlvExists = 1;
+          lblReqMsg->trafficTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_LSPID_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpLspIdTlv(&(lblReqMsg->lspidTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec LSPID tlv from LblReq msg\n");
+            return MPLS_DEC_LSPIDERROR;
+          }
+          PRINT_OUT("Decoded for lspid tlv %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblReqMsg->lspidTlvExists = 1;
+          lblReqMsg->lspidTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_PINNING_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpPinningTlv(&(lblReqMsg->pinningTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec Pinning tlv from LblReq msg\n");
+            return MPLS_DEC_PINNINGERROR;
+          }
+          PRINT_OUT("Decoded for pining tlv %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblReqMsg->pinningTlvExists = 1;
+          lblReqMsg->pinningTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_RESCLASS_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpResClsTlv(&(lblReqMsg->resClassTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec ResClass tlv from LblReq msg\n");
+            return MPLS_DEC_RESCLSERROR;
+          }
+          PRINT_OUT("Decoded for %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblReqMsg->recClassTlvExists = 1;
+          lblReqMsg->resClassTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_PREEMPT_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpPreemptTlv(&(lblReqMsg->preemptTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec preempt tlv from LblReq msg\n");
+            return MPLS_DEC_PREEMPTERROR;
+          }
+          PRINT_OUT("Decoded for preempt tlv %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblReqMsg->preemptTlvExists = 1;
+          lblReqMsg->preemptTlv.baseTlv = tlvTemp;
+          break;
+        }
+      default:
+        {
+          PRINT_ERR("Found wrong type while decoding lbl req msg (%x)\n",
+            tlvTemp.flags.flags.tBit);
+          if (tlvTemp.flags.flags.uBit == 1) {
+            /* ignore the Tlv and continue processing */
+            tempBuf += tlvTemp.length;
+            totalSize += tlvTemp.length;
+            totalSizeParam += tlvTemp.length;
+            break;
+          } else {
+            /* drop the message; return error */
+            return MPLS_TLVTYPEERROR;
+          }
+        }
+    }                           /* switch type */
+
+  }                             /* while */
+
+  PRINT_OUT("totalsize for Mpls_decodeLdpLblReqMsg is %d\n", totalSize);
+  return totalSize;
+
+}                               /*End: Mpls_decodeLdpLblReqMsg */
+
+/* 
+ * Encode for Label Withdraw and Label Release Message
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpLbl_W_R_Msg
+  (mplsLdpLbl_W_R_Msg_t * lbl_W_R_Msg, u_char * buff, int bufSize) {
+  mplsLdpLbl_W_R_Msg_t lbl_W_R_MsgCopy;
+  int encodedSize;
+  u_int totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  /* check the length of the messageId + param */
+  if ((int)(lbl_W_R_Msg->baseMsg.msgLength) + MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("failed to encode the lbl mapping msg: BUFFER TOO SMALL\n");
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  lbl_W_R_MsgCopy = *lbl_W_R_Msg;
+
+  /*
+   *  encode the base part of the pdu message
+   */
+  encodedSize = Mpls_encodeLdpBaseMsg(&(lbl_W_R_MsgCopy.baseMsg),
+    tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_BASEMSGERROR;
+  }
+  PRINT_OUT("Encode BaseMsg for label withdraw on %d bytes\n", encodedSize);
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  /*
+   *  encode the tlv if any
+   */
+  if (lbl_W_R_MsgCopy.fecTlvExists) {
+    encodedSize = Mpls_encodeLdpFecTlv(&(lbl_W_R_MsgCopy.fecTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_FECERROR;
+    }
+    PRINT_OUT("Encoded for FEC Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  if (lbl_W_R_MsgCopy.genLblTlvExists) {
+    encodedSize = Mpls_encodeLdpGenLblTlv(&(lbl_W_R_MsgCopy.genLblTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_GENLBLERROR;
+    }
+    PRINT_OUT("Encoded for Generic Label Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lbl_W_R_MsgCopy.atmLblTlvExists) {
+    encodedSize = Mpls_encodeLdpAtmLblTlv(&(lbl_W_R_MsgCopy.atmLblTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_MAPATMERROR;
+    }
+    PRINT_OUT("Encoded for Atm Label Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lbl_W_R_MsgCopy.frLblTlvExists) {
+    encodedSize = Mpls_encodeLdpFrLblTlv(&(lbl_W_R_MsgCopy.frLblTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_FRLBLERROR;
+    }
+    PRINT_OUT("Encoded for Fr Label Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lbl_W_R_MsgCopy.lspidTlvExists) {
+    encodedSize = Mpls_encodeLdpLspIdTlv(&(lbl_W_R_MsgCopy.lspidTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_LSPIDERROR;
+    }
+    PRINT_OUT("Encoded for LSPID Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_encodeLdpLbl_W_R_Msg */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpLbl_W_R_Msg
+  (mplsLdpLbl_W_R_Msg_t * lbl_W_R_Msg, u_char * buff, int bufSize) {
+  int decodedSize;
+  u_int totalSize = 0;
+  u_int stopLength = 0;
+  u_int totalSizeParam = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  mplsLdpTlv_t tlvTemp;
+
+  /*
+   *  decode the base part of the pdu message
+   */
+  memset(lbl_W_R_Msg, 0, sizeof(mplsLdpLbl_W_R_Msg_t));
+  decodedSize = Mpls_decodeLdpBaseMsg(&(lbl_W_R_Msg->baseMsg),
+    tempBuf, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for Lbl Withdraw on %d bytes\n", decodedSize);
+
+  if ((lbl_W_R_Msg->baseMsg.flags.flags.msgType != MPLS_LBLWITH_MSGTYPE) &&
+    (lbl_W_R_Msg->baseMsg.flags.flags.msgType != MPLS_LBLREL_MSGTYPE)) {
+    PRINT_ERR("Not the right message type; expected lbl W_R and got %x\n",
+      lbl_W_R_Msg->baseMsg.flags.flags.msgType);
+    return MPLS_MSGTYPEERROR;
+  }
+
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  if (bufSize - totalSize <= 0) {
+    /* nothing left for decoding */
+    PRINT_ERR("Lbl Withdraw msg does not have anything beside base msg\n");
+    return totalSize;
+  }
+
+  PRINT_OUT
+    ("bufSize = %d,  totalSize = %d, lbl_W_R_Msg->baseMsg.msgLength = %d\n",
+    bufSize, totalSize, lbl_W_R_Msg->baseMsg.msgLength);
+
+  /* Have to check the baseMsg.msgLength to know when to finish.
+   * We finsh when the totalSizeParam is >= to the base message length - the
+   * message id length (4) 
+   */
+
+  stopLength = lbl_W_R_Msg->baseMsg.msgLength - MPLS_MSGIDFIXLEN;
+  while (stopLength > totalSizeParam) {
+    /*
+     *  decode the tlv to check what's next
+     */
+    memset(&tlvTemp, 0, MPLS_TLVFIXLEN);
+    decodedSize = Mpls_decodeLdpTlv(&tlvTemp, tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      /* something wrong */
+      PRINT_ERR("Label Mapping msg decode failed for tlv\n");
+      return MPLS_DEC_TLVERROR;
+    }
+
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+    totalSizeParam += decodedSize;
+
+    switch (tlvTemp.flags.flags.tBit) {
+      case MPLS_FEC_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpFecTlv(&(lbl_W_R_Msg->fecTlv),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding FEC tlv from LblWithdr msg\n");
+            return MPLS_DEC_FECERROR;
+          }
+          PRINT_OUT("Decoded for FEC %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lbl_W_R_Msg->fecTlvExists = 1;
+          lbl_W_R_Msg->fecTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_GENLBL_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpGenLblTlv(&(lbl_W_R_Msg->genLblTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec GEN Lbl tlv from LblWithdr msg\n");
+            return MPLS_DEC_GENLBLERROR;
+          }
+          PRINT_OUT("Decoded for Gen Lbl %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lbl_W_R_Msg->genLblTlvExists = 1;
+          lbl_W_R_Msg->genLblTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_ATMLBL_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpAtmLblTlv(&(lbl_W_R_Msg->atmLblTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec ATM Lbl tlv from LblWithdr msg\n");
+            return MPLS_DEC_MAPATMERROR;
+          }
+          PRINT_OUT("Decoded for Atm Lbl %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lbl_W_R_Msg->atmLblTlvExists = 1;
+          lbl_W_R_Msg->atmLblTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_FRLBL_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpFrLblTlv(&(lbl_W_R_Msg->frLblTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec FR Lbl tlv from LblWithdr msg\n");
+            return MPLS_DEC_FRLBLERROR;
+          }
+          PRINT_OUT("Decoded for Fr Lbl %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lbl_W_R_Msg->frLblTlvExists = 1;
+          lbl_W_R_Msg->frLblTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_LSPID_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpLspIdTlv(&(lbl_W_R_Msg->lspidTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec LSPID tlv from LblW_R msg\n");
+            return MPLS_DEC_LSPIDERROR;
+          }
+          PRINT_OUT("Decoded for lspid tlv %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lbl_W_R_Msg->lspidTlvExists = 1;
+          lbl_W_R_Msg->lspidTlv.baseTlv = tlvTemp;
+          break;
+        }
+      default:
+        {
+          PRINT_ERR("Found wrong tlv type while decoding lbl withdr msg (%x)\n",
+            tlvTemp.flags.flags.tBit);
+          if (tlvTemp.flags.flags.uBit == 1) {
+            /* ignore the Tlv and continue processing */
+            tempBuf += tlvTemp.length;
+            totalSize += tlvTemp.length;
+            totalSizeParam += tlvTemp.length;
+            break;
+          } else {
+            /* drop the message; return error */
+            return MPLS_TLVTYPEERROR;
+          }
+        }
+    }                           /* switch type */
+
+  }                             /* while */
+
+  PRINT_OUT("totalsize for Mpls_decodeLdpLblWithdrawMsgIdTlv is %d\n",
+    totalSize);
+
+  return totalSize;
+
+}                               /* End: Mpls_decodeLdpLbl_W_R_Msg */
+
+/* 
+ * Encode for CR Tlv 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpERTlv(mplsLdpErTlv_t * erTlv, u_char * buff, int bufSize)
+{
+  int encodedSize = 0;
+  u_int totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_int i;
+
+  if (MPLS_TLVFIXLEN + (int)(erTlv->baseTlv.length) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(erTlv->baseTlv), tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  if (erTlv->numberErHops > MPLS_MAX_ER_HOPS) {
+    PRINT_ERR("MPLS_MAX_ER_HOPS is too small. Increase it if nec\n");
+    return MPLS_ER_HOPSNUMERROR;
+  }
+
+  /* 
+   *  encode for ER hops 
+   */
+  for (i = 0; i < erTlv->numberErHops; i++) {
+    encodedSize = Mpls_encodeLdpErHop(&(erTlv->erHopArray[i]),
+      tempBuf, bufSize - totalSize, erTlv->erHopTypes[i]);
+    if (encodedSize < 0) {
+      return MPLS_ENC_ERHOPERROR;
+    }
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_encodeLdpERTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpERTlv
+  (mplsLdpErTlv_t * erTlv, u_char * buff, int bufSize, u_short tlvLength) {
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_char *erTlvPtr;
+  u_int i = 0;
+  int decodedSize = 0;
+  u_int erHopSize = 0;          /* used to compute the sum of
+
+                                   all er hop elements + flags */
+  u_short type;                 /* filled in by Mpls_decodeLdpErHop
+
+                                   with the type of the ER hop 
+                                   decoded */
+
+  if ((int)tlvLength > bufSize) {
+    /* not enough data for Fec elements tlv */
+    PRINT_ERR("failed decoding CR tlv \n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  erTlvPtr = (u_char *) erTlv;
+  erTlvPtr += MPLS_TLVFIXLEN;   /* we want to point to the flags since the
+                                   tlv was decoded before we reach here */
+
+  while (tlvLength > erHopSize) {
+    if (erTlv->numberErHops > (u_short) (MPLS_MAX_ER_HOPS - 1)) {
+      PRINT_ERR("MPLS_MAX_ER_HOPS is too small. Increase it if nec\n");
+      return MPLS_ER_HOPSNUMERROR;
+    }
+
+    decodedSize = Mpls_decodeLdpErHop(&(erTlv->erHopArray[i]),
+      tempBuf, bufSize - erHopSize, &type);
+    if (decodedSize < 0) {
+      return MPLS_DEC_ERHOPERROR;
+    }
+
+    erTlv->erHopTypes[i] = type;
+    erTlv->numberErHops++;
+    i++;
+
+    tempBuf += decodedSize;
+    erHopSize += decodedSize;
+
+  }                             /* end while */
+
+  return erHopSize;
+
+}                               /* End: Mpls_decodeLdpERTlv */
+
+/* 
+ * Encode for ER Hop 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpErHop
+  (mplsLdpErHop_t * erHop, u_char * buff, int bufSize, u_short type) {
+  int encodedSize = 0;
+  u_char *tempBuff = buff;
+  u_char *startPtr;
+
+  switch (type) {
+    case MPLS_ERHOP_IPV4_TLVTYPE:
+      {
+        if (MPLS_ERHOP_IPV4_FIXLEN + MPLS_TLVFIXLEN > bufSize) {
+          return MPLS_ENC_BUFFTOOSMALL;
+        }
+
+        /* check how much is the preLen; should be between 0-32 */
+        if (erHop->erIpv4.flags.flags.preLen > 32) {
+          return MPLS_IPV4LENGTHERROR;
+        }
+
+        encodedSize = Mpls_encodeLdpTlv(&(erHop->erIpv4.baseTlv),
+          tempBuff, bufSize);
+        if (encodedSize < 0) {
+          return MPLS_ENC_TLVERROR;
+        }
+        tempBuff += encodedSize;
+        startPtr = (u_char *) & (erHop->erIpv4);
+        startPtr += encodedSize;
+
+        erHop->erIpv4.flags.flags.res = 0;
+        erHop->erIpv4.flags.mark = htonl(erHop->erIpv4.flags.mark);
+        erHop->erIpv4.address = htonl(erHop->erIpv4.address);
+
+        MEM_COPY(tempBuff, startPtr, MPLS_ERHOP_IPV4_FIXLEN);
+        encodedSize += MPLS_ERHOP_IPV4_FIXLEN;
+        break;
+      }
+    case MPLS_ERHOP_IPV6_TLVTYPE:
+      {
+        if (MPLS_ERHOP_IPV6_FIXLEN + MPLS_TLVFIXLEN > bufSize) {
+          return MPLS_ENC_BUFFTOOSMALL;
+        }
+        encodedSize = Mpls_encodeLdpTlv(&(erHop->erIpv6.baseTlv),
+          tempBuff, bufSize);
+        if (encodedSize < 0) {
+          return MPLS_ENC_TLVERROR;
+        }
+        tempBuff += encodedSize;
+        startPtr = (u_char *) & (erHop->erIpv6);
+        startPtr += encodedSize;
+
+        erHop->erIpv6.flags.flags.res = 0;
+        erHop->erIpv6.flags.mark = htonl(erHop->erIpv6.flags.mark);
+
+        MEM_COPY(tempBuff, startPtr, MPLS_ERHOP_IPV6_FIXLEN);
+
+        encodedSize += MPLS_ERHOP_IPV6_FIXLEN;
+        break;
+      }
+    case MPLS_ERHOP_AS_TLVTYPE:
+      {
+        if (MPLS_ERHOP_AS_FIXLEN + MPLS_TLVFIXLEN > bufSize) {
+          return MPLS_ENC_BUFFTOOSMALL;
+        }
+        encodedSize =
+          Mpls_encodeLdpTlv(&(erHop->erAs.baseTlv), tempBuff, bufSize);
+        if (encodedSize < 0) {
+          return MPLS_ENC_TLVERROR;
+        }
+        tempBuff += encodedSize;
+        startPtr = (u_char *) & (erHop->erAs);
+        startPtr += encodedSize;
+
+        erHop->erAs.flags.flags.res = 0;
+        erHop->erAs.flags.mark = htons(erHop->erAs.flags.mark);
+        erHop->erAs.asNumber = htons(erHop->erAs.asNumber);
+
+        MEM_COPY(tempBuff, startPtr, MPLS_ERHOP_AS_FIXLEN);
+
+        encodedSize += MPLS_ERHOP_AS_FIXLEN;
+        break;
+      }
+    case MPLS_ERHOP_LSPID_TLVTYPE:
+      {
+        if (MPLS_ERHOP_LSPID_FIXLEN + MPLS_TLVFIXLEN > bufSize) {
+          return MPLS_ENC_BUFFTOOSMALL;
+        }
+        encodedSize = Mpls_encodeLdpTlv(&(erHop->erLspId.baseTlv),
+          tempBuff, bufSize);
+        if (encodedSize < 0) {
+          return MPLS_ENC_TLVERROR;
+        }
+        tempBuff += encodedSize;
+        startPtr = (u_char *) & (erHop->erLspId);
+        startPtr += encodedSize;
+
+        erHop->erLspId.flags.flags.res = 0;
+        erHop->erLspId.flags.mark = htons(erHop->erLspId.flags.mark);
+        erHop->erLspId.lspid = htons(erHop->erLspId.lspid);
+        erHop->erLspId.routerId = htonl(erHop->erLspId.routerId);
+
+        MEM_COPY(tempBuff, startPtr, MPLS_ERHOP_LSPID_FIXLEN);
+
+        encodedSize += MPLS_ERHOP_LSPID_FIXLEN;
+        break;
+      }
+    default:
+      {
+        PRINT_ERR("Found wrong ER hop type while encoding FEC elem (%d)\n",
+          type);
+        return MPLS_ENC_ERHOPERROR;
+        break;
+      }
+  }                             /* end: switch */
+
+  return encodedSize;
+
+}                               /* End: Mpls_encodeLdpErHop */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpErHop
+  (mplsLdpErHop_t * erHop, u_char * buff, int bufSize, u_short * type) {
+  int decodedSize = 0;
+  u_char *tempBuf = buff;
+  u_char *startPtr;
+  mplsLdpTlv_t tlvTemp;
+
+  /*
+   *  decode the tlv to check what is the type of the ER hop
+   */
+  decodedSize = Mpls_decodeLdpTlv(&tlvTemp, tempBuf, bufSize);
+  if (decodedSize < 0) {
+    /* something wrong */
+    PRINT_ERR("ErHop decode failed for tlv\n");
+    return MPLS_DEC_TLVERROR;
+  }
+  tempBuf += decodedSize;
+
+  switch (tlvTemp.flags.flags.tBit) {
+    case MPLS_ERHOP_IPV4_TLVTYPE:
+      {
+        if (MPLS_ERHOP_IPV4_FIXLEN > bufSize - MPLS_TLVFIXLEN) {
+          return MPLS_DEC_BUFFTOOSMALL;
+        }
+        startPtr = (u_char *) & (erHop->erIpv4);
+        startPtr += decodedSize; /* skip the tlv */
+
+        MEM_COPY(startPtr, tempBuf, MPLS_ERHOP_IPV4_FIXLEN);
+        erHop->erIpv4.flags.mark = ntohl(erHop->erIpv4.flags.mark);
+        erHop->erIpv4.address = ntohl(erHop->erIpv4.address);
+        erHop->erIpv4.baseTlv = tlvTemp;
+
+        /* check how much is the preLen; should be between 0-32 */
+        if (erHop->erIpv4.flags.flags.preLen > 32) {
+          return MPLS_IPV4LENGTHERROR;
+        }
+
+        decodedSize += MPLS_ERHOP_IPV4_FIXLEN;
+        break;
+      }
+    case MPLS_ERHOP_IPV6_TLVTYPE:
+      {
+        if (MPLS_ERHOP_IPV6_FIXLEN > bufSize - MPLS_TLVFIXLEN) {
+          return MPLS_DEC_BUFFTOOSMALL;
+        }
+        startPtr = (u_char *) & (erHop->erIpv6);
+        startPtr += decodedSize; /* skip the tlv */
+
+        MEM_COPY(startPtr, tempBuf, MPLS_ERHOP_IPV6_FIXLEN);
+        erHop->erIpv6.flags.mark = ntohl(erHop->erIpv6.flags.mark);
+        erHop->erIpv6.baseTlv = tlvTemp;
+
+        decodedSize += MPLS_ERHOP_IPV6_FIXLEN;
+        break;
+      }
+    case MPLS_ERHOP_AS_TLVTYPE:
+      {
+        if (MPLS_ERHOP_AS_FIXLEN > bufSize - MPLS_TLVFIXLEN) {
+          return MPLS_DEC_BUFFTOOSMALL;
+        }
+        startPtr = (u_char *) & (erHop->erAs);
+        startPtr += decodedSize; /* skip the tlv */
+
+        MEM_COPY(startPtr, tempBuf, MPLS_ERHOP_AS_FIXLEN);
+        erHop->erAs.flags.mark = ntohs(erHop->erAs.flags.mark);
+        erHop->erAs.asNumber = ntohs(erHop->erAs.asNumber);
+        erHop->erAs.baseTlv = tlvTemp;
+
+        decodedSize += MPLS_ERHOP_AS_FIXLEN;
+        break;
+      }
+    case MPLS_ERHOP_LSPID_TLVTYPE:
+      {
+        if (MPLS_ERHOP_LSPID_FIXLEN > bufSize - MPLS_TLVFIXLEN) {
+          return MPLS_DEC_BUFFTOOSMALL;
+        }
+        startPtr = (u_char *) & (erHop->erLspId);
+        startPtr += decodedSize; /* skip the tlv */
+
+        MEM_COPY(startPtr, tempBuf, MPLS_ERHOP_LSPID_FIXLEN);
+        erHop->erLspId.flags.mark = ntohs(erHop->erLspId.flags.mark);
+        erHop->erLspId.lspid = ntohs(erHop->erLspId.lspid);
+        erHop->erLspId.routerId = ntohl(erHop->erLspId.routerId);
+        erHop->erLspId.baseTlv = tlvTemp;
+
+        decodedSize += MPLS_ERHOP_LSPID_FIXLEN;
+        break;
+      }
+    default:
+      {
+        PRINT_ERR("Found wrong ER hop type while decoding ER (%d)\n", *type);
+        return MPLS_DEC_ERHOPERROR;
+        break;
+      }
+  }                             /* end: switch */
+
+  *type = tlvTemp.flags.flags.tBit;
+  return decodedSize;
+
+}                               /* End: Mpls_decodeLdpErHop */
+
+/* 
+ * Encode for Traffic Tlv 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpTrafficTlv
+  (mplsLdpTrafficTlv_t * trafficTlv, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_char *trafficTlvPtr;
+  u_short tempLength;           /* to store the tlv length for
+
+                                   later use */
+
+  if (MPLS_TLVFIXLEN + (int)(trafficTlv->baseTlv.length) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  tempLength = trafficTlv->baseTlv.length;
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(trafficTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+  trafficTlvPtr = (u_char *) trafficTlv;
+  trafficTlvPtr += encodedSize;
+
+  /*
+   *   encode Traffic flags + Frequency + Reserved + Weight
+   */
+  encodedSize = sizeof(u_char) * 4;
+  MEM_COPY(tempBuf, trafficTlvPtr, encodedSize);
+  tempBuf += encodedSize;
+  trafficTlvPtr += encodedSize;
+
+  /*
+   *   encode for Traffic parameters 
+   */
+  if ((MPLS_TRAFFICPARAMLENGTH != sizeof(float)) ||
+    (sizeof(float) != sizeof(u_int))) {
+    PRINT_ERR("There is not compatibility for float type (%d)\n",
+
+      (int)sizeof(float));
+    return MPLS_FLOATTYPEERROR;
+  }
+
+  trafficTlv->pdr.mark = htonl(trafficTlv->pdr.mark);
+  trafficTlv->pbs.mark = htonl(trafficTlv->pbs.mark);
+  trafficTlv->cdr.mark = htonl(trafficTlv->cdr.mark);
+  trafficTlv->cbs.mark = htonl(trafficTlv->cbs.mark);
+  trafficTlv->ebs.mark = htonl(trafficTlv->ebs.mark);
+
+  MEM_COPY(tempBuf, trafficTlvPtr, MPLS_TRAFFICPARAMLENGTH * 5);
+
+  return (MPLS_TLVFIXLEN + tempLength);
+
+}                               /* End: Mpls_encodeLdpTrafficTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpTrafficTlv
+  (mplsLdpTrafficTlv_t * trafficTlv,
+  u_char * buff, int bufSize, u_short tlvLength) {
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  int decodedSize = 0;
+  u_char *trafficTlvPtr;
+
+  if ((int)tlvLength > bufSize) {
+    /* not enough data for Fec elements tlv */
+    PRINT_ERR("failed decoding Traffic tlv \n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+  trafficTlvPtr = (u_char *) trafficTlv;
+  trafficTlvPtr += MPLS_TLVFIXLEN;
+
+  /*
+   *   decode Traffic flags + Frequency + Reserved + Weight
+   */
+  decodedSize = sizeof(u_char) * 4;
+  MEM_COPY(trafficTlvPtr, tempBuf, decodedSize);
+  tempBuf += decodedSize;
+  trafficTlvPtr += decodedSize;
+
+  /* 
+   * decode the traffic parameters
+   */
+  if (MPLS_TRAFFICPARAMLENGTH != sizeof(float)) {
+    PRINT_ERR("There is not compatibility for float type (%d)\n", decodedSize);
+    return MPLS_FLOATTYPEERROR;
+  }
+  MEM_COPY(trafficTlvPtr, tempBuf, MPLS_TRAFFICPARAMLENGTH * 5);
+
+  trafficTlv->pdr.mark = ntohl(trafficTlv->pdr.mark);
+  trafficTlv->pbs.mark = ntohl(trafficTlv->pbs.mark);
+  trafficTlv->cdr.mark = ntohl(trafficTlv->cdr.mark);
+  trafficTlv->cbs.mark = ntohl(trafficTlv->cbs.mark);
+  trafficTlv->ebs.mark = ntohl(trafficTlv->ebs.mark);
+
+  return tlvLength;
+
+}                               /* End: Mpls_decodeLdpTrafficTlv */
+
+/* 
+ * Encode for Preempt Tlv 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpPreemptTlv
+  (mplsLdpPreemptTlv_t * preemptTlv, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_char *preemptTlvPtr;
+
+  if (MPLS_TLVFIXLEN + MPLS_PREEMPTTLV_FIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(preemptTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  preemptTlv->res = 0;
+  preemptTlvPtr = (u_char *) preemptTlv;
+  preemptTlvPtr += encodedSize;
+
+  MEM_COPY(tempBuf, preemptTlvPtr, MPLS_PREEMPTTLV_FIXLEN);
+
+  return (MPLS_TLVFIXLEN + MPLS_PREEMPTTLV_FIXLEN);
+
+}                               /* End: Mpls_encodeLdpPreemptTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpPreemptTlv
+  (mplsLdpPreemptTlv_t * preemptTlv, u_char * buff, int bufSize) {
+  u_char *preemptTlvPtr;
+
+  if (MPLS_PREEMPTTLV_FIXLEN > bufSize) {
+    PRINT_ERR("failed decoding preempt tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+  preemptTlvPtr = (u_char *) preemptTlv;
+  preemptTlvPtr += MPLS_TLVFIXLEN;
+
+  MEM_COPY(preemptTlvPtr, buff, MPLS_PREEMPTTLV_FIXLEN);
+
+  return MPLS_PREEMPTTLV_FIXLEN;
+
+}                               /* End: Mpls_decodeLdpPreemptTlv */
+
+/* 
+ * Encode for LSPID Tlv 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpLspIdTlv
+  (mplsLdpLspIdTlv_t * lspIdTlv, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  u_char *lspIdTlvPtr;
+
+  if (MPLS_TLVFIXLEN + MPLS_LSPIDTLV_FIXLEN > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(lspIdTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  lspIdTlvPtr = (u_char *) lspIdTlv;
+  lspIdTlvPtr += encodedSize;
+
+  lspIdTlv->res = 0;
+  lspIdTlv->localCrlspId = htons(lspIdTlv->localCrlspId);
+  lspIdTlv->routerId = htonl(lspIdTlv->routerId);
+
+  MEM_COPY(tempBuf, lspIdTlvPtr, MPLS_LSPIDTLV_FIXLEN);
+
+  return (MPLS_TLVFIXLEN + MPLS_LSPIDTLV_FIXLEN);
+
+}                               /* End: Mpls_encodeLdpLspIdTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpLspIdTlv
+  (mplsLdpLspIdTlv_t * lspIdTlv, u_char * buff, int bufSize) {
+  u_char *lspIdTlvPtr;
+
+  if (MPLS_PREEMPTTLV_FIXLEN > bufSize) {
+    PRINT_ERR("failed decoding LspId\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+  lspIdTlvPtr = (u_char *) lspIdTlv;
+  lspIdTlvPtr += MPLS_TLVFIXLEN;
+
+  MEM_COPY(lspIdTlvPtr, buff, MPLS_LSPIDTLV_FIXLEN);
+
+  lspIdTlv->localCrlspId = ntohs(lspIdTlv->localCrlspId);
+  lspIdTlv->routerId = ntohl(lspIdTlv->routerId);
+
+  return MPLS_LSPIDTLV_FIXLEN;
+
+}                               /* End:  Mpls_decodeLdpLspIdTlv */
+
+/* 
+ * Encode for Resource Class Tlv 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpResClsTlv
+  (mplsLdpResClsTlv_t * resClsTlv, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_TLVFIXLEN + (int)sizeof(u_int) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(resClsTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  resClsTlv->rsCls = htonl(resClsTlv->rsCls);
+
+  MEM_COPY(tempBuf, (u_char *) & (resClsTlv->rsCls), sizeof(u_int));
+
+  return (MPLS_TLVFIXLEN + sizeof(u_int));
+
+}                               /* End: Mpls_encodeLdpResClsTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpResClsTlv
+  (mplsLdpResClsTlv_t * resClsTlv, u_char * buff, int bufSize) {
+  if ((int)sizeof(u_int) > bufSize) {
+    PRINT_ERR("failed decoding resClass tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  MEM_COPY((u_char *) & (resClsTlv->rsCls), buff, sizeof(u_int));
+  resClsTlv->rsCls = ntohl(resClsTlv->rsCls);
+
+  return sizeof(u_int);
+
+}                               /* End: Mpls_decodeLdpResClsTlv */
+
+/* 
+ * Encode for Route Pinning Tlv 
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpPinningTlv
+  (mplsLdpPinningTlv_t * pinningTlv, u_char * buff, int bufSize) {
+  int encodedSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  if (MPLS_TLVFIXLEN + (int)sizeof(u_int) > bufSize) {
+    /* not enough room */
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  /* 
+   *  encode for tlv 
+   */
+  encodedSize = Mpls_encodeLdpTlv(&(pinningTlv->baseTlv),
+    tempBuf, MPLS_TLVFIXLEN);
+  if (encodedSize < 0) {
+    return MPLS_ENC_TLVERROR;
+  }
+  tempBuf += encodedSize;
+
+  pinningTlv->flags.flags.res = 0;
+  pinningTlv->flags.mark = htonl(pinningTlv->flags.mark);
+
+  MEM_COPY(tempBuf, (u_char *) & (pinningTlv->flags.mark), sizeof(u_int));
+
+  return (MPLS_TLVFIXLEN + sizeof(u_int));
+
+}                               /* End: Mpls_encodeLdpPinningTlv */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpPinningTlv
+  (mplsLdpPinningTlv_t * pinningTlv, u_char * buff, int bufSize) {
+  if ((int)sizeof(u_int) > bufSize) {
+    PRINT_ERR("failed decoding route pinning tlv\n");
+    return MPLS_DEC_BUFFTOOSMALL;
+  }
+
+  MEM_COPY((u_char *) & (pinningTlv->flags.mark), buff, sizeof(u_int));
+  pinningTlv->flags.mark = ntohl(pinningTlv->flags.mark);
+
+  return sizeof(u_int);
+
+}                               /* End: Mpls_decodeLdpPinningTlv */
+
+/* 
+ * Label Abort Request Message
+ */
+
+/*
+ *  encode
+ */
+int Mpls_encodeLdpLblAbortMsg
+  (mplsLdpLblAbortMsg_t * lblAbortMsg, u_char * buff, int bufSize) {
+  mplsLdpLblAbortMsg_t lblAbortMsgCopy;
+  int encodedSize = 0;
+  u_int totalSize = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+
+  /* check the length of the messageId + param */
+  if ((int)(lblAbortMsg->baseMsg.msgLength) + MPLS_TLVFIXLEN > bufSize) {
+    PRINT_ERR("failed to encode the lbl abort request msg: BUFFER TOO SMALL\n");
+    return MPLS_ENC_BUFFTOOSMALL;
+  }
+
+  lblAbortMsgCopy = *lblAbortMsg;
+
+  /*
+   *  encode the base part of the pdu message
+   */
+  encodedSize = Mpls_encodeLdpBaseMsg(&(lblAbortMsgCopy.baseMsg),
+    tempBuf, bufSize);
+  if (encodedSize < 0) {
+    return MPLS_ENC_BASEMSGERROR;
+  }
+  PRINT_OUT("Encode BaseMsg for label abort request msg on %d bytes\n",
+    encodedSize);
+  tempBuf += encodedSize;
+  totalSize += encodedSize;
+
+  /*
+   *  encode the tlv if any
+   */
+  if (lblAbortMsgCopy.fecTlvExists) {
+    encodedSize = Mpls_encodeLdpFecTlv(&(lblAbortMsgCopy.fecTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_FECERROR;
+    }
+    PRINT_OUT("Encoded for FEC Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+  if (lblAbortMsgCopy.lblMsgIdTlvExists) {
+    encodedSize = Mpls_encodeLdpLblMsgIdTlv(&(lblAbortMsgCopy.lblMsgIdTlv),
+      tempBuf, bufSize - totalSize);
+    if (encodedSize < 0) {
+      return MPLS_ENC_LBLMSGIDERROR;
+    }
+    PRINT_OUT("Encoded for lbl request msg id Tlv %d bytes\n", encodedSize);
+    tempBuf += encodedSize;
+    totalSize += encodedSize;
+  }
+
+  return totalSize;
+
+}                               /* End: Mpls_encodeLdpLblAbortMsg */
+
+/*
+ *  decode
+ */
+int Mpls_decodeLdpLblAbortMsg
+  (mplsLdpLblAbortMsg_t * lblAbortMsg, u_char * buff, int bufSize) {
+  int decodedSize = 0;
+  u_int totalSize = 0;
+  u_int stopLength = 0;
+  u_int totalSizeParam = 0;
+  u_char *tempBuf = buff;       /* no change for the buff ptr */
+  mplsLdpTlv_t tlvTemp;
+
+  /*
+   *  decode the base part of the pdu message
+   */
+  memset(lblAbortMsg, 0, sizeof(mplsLdpLblAbortMsg_t));
+  decodedSize = Mpls_decodeLdpBaseMsg(&(lblAbortMsg->baseMsg),
+    tempBuf, bufSize);
+  if (decodedSize < 0) {
+    return MPLS_DEC_BASEMSGERROR;
+  }
+  PRINT_OUT("Decode BaseMsg for Lbl Abort Request Msg on %d bytes\n",
+    decodedSize);
+
+  if (lblAbortMsg->baseMsg.flags.flags.msgType != MPLS_LBLABORT_MSGTYPE) {
+    PRINT_ERR("Not the right message type; expected lbl abort and got %x\n",
+      lblAbortMsg->baseMsg.flags.flags.msgType);
+    return MPLS_MSGTYPEERROR;
+  }
+
+  tempBuf += decodedSize;
+  totalSize += decodedSize;
+
+  if (bufSize - totalSize <= 0) {
+    /* nothing left for decoding */
+    PRINT_ERR("Lbl Abort msg does not have anything beside base msg\n");
+    return totalSize;
+  }
+
+  PRINT_OUT
+    ("bufSize = %d,  totalSize = %d, lblAbortMsg->baseMsg.msgLength = %d\n",
+    bufSize, totalSize, lblAbortMsg->baseMsg.msgLength);
+
+  /* Have to check the baseMsg.msgLength to know when to finish.
+   * We finsh when the totalSizeParam is >= to the base message length - the
+   * message id length (4) 
+   */
+
+  stopLength = lblAbortMsg->baseMsg.msgLength - MPLS_MSGIDFIXLEN;
+  while (stopLength > totalSizeParam) {
+    /*
+     *  decode the tlv to check what's next
+     */
+    memset(&tlvTemp, 0, MPLS_TLVFIXLEN);
+    decodedSize = Mpls_decodeLdpTlv(&tlvTemp, tempBuf, bufSize - totalSize);
+    if (decodedSize < 0) {
+      /* something wrong */
+      PRINT_ERR("Label Abort msg decode failed for tlv\n");
+      return MPLS_DEC_TLVERROR;
+    }
+
+    tempBuf += decodedSize;
+    totalSize += decodedSize;
+    totalSizeParam += decodedSize;
+
+    switch (tlvTemp.flags.flags.tBit) {
+      case MPLS_FEC_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpFecTlv(&(lblAbortMsg->fecTlv),
+            tempBuf, bufSize - totalSize, tlvTemp.length);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when decoding FEC tlv from LblAbort msg\n");
+            return MPLS_DEC_FECERROR;
+          }
+          PRINT_OUT("Decoded for FEC %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblAbortMsg->fecTlvExists = 1;
+          lblAbortMsg->fecTlv.baseTlv = tlvTemp;
+          break;
+        }
+      case MPLS_REQMSGID_TLVTYPE:
+        {
+          decodedSize = Mpls_decodeLdpLblMsgIdTlv(&(lblAbortMsg->lblMsgIdTlv),
+            tempBuf, bufSize - totalSize);
+          if (decodedSize < 0) {
+            PRINT_ERR("Failure when dec LblMsgId tlv from LblAbort msg\n");
+            return MPLS_DEC_LBLMSGIDERROR;
+          }
+          PRINT_OUT("Decoded for LblMsgId %d bytes\n", decodedSize);
+          tempBuf += decodedSize;
+          totalSize += decodedSize;
+          totalSizeParam += decodedSize;
+
+          lblAbortMsg->lblMsgIdTlvExists = 1;
+          lblAbortMsg->lblMsgIdTlv.baseTlv = tlvTemp;
+          break;
+        }
+      default:
+        {
+          PRINT_ERR("Found wrong tlv type while decoding lbl abort msg (%x)\n",
+            tlvTemp.flags.flags.tBit);
+          if (tlvTemp.flags.flags.uBit == 1) {
+            /* ignore the Tlv and continue processing */
+            tempBuf += tlvTemp.length;
+            totalSize += tlvTemp.length;
+            totalSizeParam += tlvTemp.length;
+            break;
+          } else {
+            /* drop the message; return error */
+            return MPLS_TLVTYPEERROR;
+          }
+        }
+    }                           /* switch type */
+
+  }                             /* while */
+
+  PRINT_OUT("totalsize for Mpls_decodeLdpLblAbortMsg is %d\n", totalSize);
+
+  return totalSize;
+
+}                               /* End: Mpls_decodeLdpLblAbortMsg */
+
+/*
+ *   DEBUG functions 
+ */
+void printTlv(mpls_instance_handle handle, mplsLdpTlv_t * tlv)
+{
+  LDP_TRACE_OUT(handle, "\t Tlv:\n");
+  LDP_TRACE_OUT(handle, "\t BaseTlv: uBit = %d\n", tlv->flags.flags.uBit);
+  LDP_TRACE_OUT(handle, "\t\t  fBit = %d\n", tlv->flags.flags.fBit);
+  LDP_TRACE_OUT(handle, "\t\t  type = %x\n", tlv->flags.flags.tBit);
+  LDP_TRACE_OUT(handle, "\t\t  length = %d\n", tlv->length);
+}
+
+void printHeader(mpls_instance_handle handle, mplsLdpHeader_t * header)
+{
+  LDP_TRACE_OUT(handle, "LPD Header : protocolVersion = %d\n",
+    header->protocolVersion);
+  LDP_TRACE_OUT(handle, "\tpduLength = %d\n", header->pduLength);
+  LDP_TRACE_OUT(handle, "\tlsrAddress = %x\n", header->lsrAddress);
+  LDP_TRACE_OUT(handle, "\tlabelSpace = %x\n", header->labelSpace);
+}
+
+void printCspFlags(mpls_instance_handle handle, mplsLdpCspFlag_t * cspFlags)
+{
+  LDP_TRACE_OUT(handle, "\tCSP Flags: lad = %d, ld = %d, pvl = %d, res = %d\n",
+    cspFlags->lad, cspFlags->ld, cspFlags->pvl, cspFlags->res);
+}
+
+void printCspFlagsPerByte(mpls_instance_handle handle, u_short * cspFlags)
+{
+  u_char *ptr;
+
+  ptr = (u_char *) cspFlags;
+  LDP_TRACE_OUT(handle, "\tCSP Flags: (byte 0) %x\n", *ptr++);
+  LDP_TRACE_OUT(handle, "\t\t (byte 1) %x\n", *ptr);
+}
+
+void printCspTlv(mpls_instance_handle handle, mplsLdpCspTlv_t * csp)
+{
+  LDP_TRACE_OUT(handle, "\tCSP:\n");
+  printTlv(handle, &(csp->baseTlv));
+  LDP_TRACE_OUT(handle, "\tcsp        : protocolVersion = %d\n",
+    csp->protocolVersion);
+  LDP_TRACE_OUT(handle, "\t\tholdTime = %d\n", csp->holdTime);
+  LDP_TRACE_OUT(handle, "\t\tmaxPduLen = %d\n", csp->maxPduLen);
+  LDP_TRACE_OUT(handle, "\t\trcvLsrAddress = %08x\n", csp->rcvLsrAddress);
+  LDP_TRACE_OUT(handle, "\t\trcvLsId = %d\n", csp->rcvLsId);
+
+  printCspFlags(handle, &(csp->flags.flags));
+}
+
+void printAspFlags(mpls_instance_handle handle, mplsLdpSPFlag_t * aspFlags)
+{
+  LDP_TRACE_OUT(handle,
+    "\t ASP Flags: mergeType = %d, numLblRng = %d, dir = %d, res = %d\n",
+    aspFlags->mergeType, aspFlags->numLblRng, aspFlags->dir, aspFlags->res);
+}
+
+void printAspFlagsPerByte(mpls_instance_handle handle, u_int * aspFlags)
+{
+  u_char *ptr;
+
+  ptr = (u_char *) aspFlags;
+  LDP_TRACE_OUT(handle, "\tASP Flags: (byte 0) %x\n", *ptr++);
+  LDP_TRACE_OUT(handle, "\t\t (byte 1) %x\n", *ptr++);
+  LDP_TRACE_OUT(handle, "\t\t (byte 2) %x\n", *ptr++);
+  LDP_TRACE_OUT(handle, "\t\t (byte 3) %x\n", *ptr);
+}
+
+void printAtmLabel(mpls_instance_handle handle, mplsLdpAtmLblRng_t * label,
+  int i)
+{
+  LDP_TRACE_OUT(handle,
+    "\tATM LABEL (%d) : res1 = %d, minVci = %d, minVpi = %d, res2 = %d, maxVci = %d, maxVpi = %d\n",
+    i, label->flags.flags.res1, label->flags.flags.minVci,
+    label->flags.flags.minVpi, label->flags.flags.res2,
+    label->flags.flags.maxVci, label->flags.flags.maxVpi);
+}
+
+void printAspTlv(mpls_instance_handle handle, mplsLdpAspTlv_t * asp)
+{
+  int i = 0;
+
+  LDP_TRACE_OUT(handle, "\t asp:\n");
+  printTlv(handle, &(asp->baseTlv));
+  LDP_TRACE_OUT(handle, "\t asp labes (%d)\n",
+    (int)(asp->flags.flags.numLblRng));
+  for (i = 0; i < (int)(asp->flags.flags.numLblRng); i++) {
+    printAtmLabel(handle, &(asp->lblRngList[i]), i);
+  }
+  printAspFlags(handle, &(asp->flags.flags));
+}
+
+void printFspFlags(mpls_instance_handle handle, mplsLdpSPFlag_t * fspFlags)
+{
+  LDP_TRACE_OUT(handle,
+    "\t FSP Flags: mergeType = %d, numLblRng = %d, dir = %d, res = %d\n",
+    fspFlags->mergeType, fspFlags->numLblRng, fspFlags->dir, fspFlags->res);
+}
+
+void printFspLabel(mpls_instance_handle handle, mplsLdpFrLblRng_t * label, int i)
+{
+  LDP_TRACE_OUT(handle,
+    "\tFR LABEL (%d) : res_max = %d, maxDlci = %d, res_min = %d, len = %d minDlci = %d\n",
+    i, label->flags.flags.res_max, label->flags.flags.maxDlci,
+    label->flags.flags.res_min, label->flags.flags.len,
+    label->flags.flags.minDlci);
+}
+
+void printFspTlv(mpls_instance_handle handle, mplsLdpFspTlv_t * fsp)
+{
+  int i = 0;
+
+  LDP_TRACE_OUT(handle, "\t fsp:\n");
+  printTlv(handle, &(fsp->baseTlv));
+  LDP_TRACE_OUT(handle, "\t fsp labes (%d)\n",
+    (int)(fsp->flags.flags.numLblRng));
+  for (i = 0; i < (int)(fsp->flags.flags.numLblRng); i++) {
+    printFspLabel(handle, &(fsp->lblRngList[i]), i);
+  }
+  printFspFlags(handle, &(fsp->flags.flags));
+}
+
+void printMsgBase(mpls_instance_handle handle, mplsLdpMsg_t * msg)
+{
+  LDP_TRACE_OUT(handle, "\tbaseMsg : uBit = %d\n", msg->flags.flags.uBit);
+  LDP_TRACE_OUT(handle, "\t\t  msgType = %x\n", msg->flags.flags.msgType);
+  LDP_TRACE_OUT(handle, "\t\t  msgLength = %d\n", msg->msgLength);
+  LDP_TRACE_OUT(handle, "\t\t  msgId = %d\n", msg->msgId);
+}
+
+void printInitMsg(mpls_instance_handle handle, mplsLdpInitMsg_t * initMsg)
+{
+  LDP_TRACE_OUT(handle, "INIT MSG ***START***:\n");
+  printMsgBase(handle, &(initMsg->baseMsg));
+  if (initMsg->cspExists) {
+    printCspTlv(handle, &(initMsg->csp));
+  } else {
+    LDP_TRACE_OUT(handle, "\tINIT msg does NOT have CSP\n");
+  }
+  if (initMsg->aspExists) {
+    printAspTlv(handle, &(initMsg->asp));
+  } else {
+    LDP_TRACE_OUT(handle, "\tINIT msg does NOT have ASP\n");
+  }
+  if (initMsg->fspExists) {
+    printFspTlv(handle, &(initMsg->fsp));
+  } else {
+    LDP_TRACE_OUT(handle, "\tINIT msg does NOT have FSP\n");
+  }
+  LDP_TRACE_OUT(handle, "\nINIT MSG ***END***\n");
+}
+
+void printRetMsgTlv(mpls_instance_handle handle, mplsLdpRetMsgTlv_t * retMsg)
+{
+  LDP_TRACE_OUT(handle, "\t retMsgTlv:\n");
+  printTlv(handle, &(retMsg->baseTlv));
+  LDP_TRACE_OUT(handle, "\t retMsgTlv.data is %s\n", retMsg->data);
+}
+
+void printRetPduTlv(mpls_instance_handle handle, mplsLdpRetPduTlv_t * retPdu)
+{
+  LDP_TRACE_OUT(handle, "\t retPduTlv:\n");
+  printTlv(handle, &(retPdu->baseTlv));
+  LDP_TRACE_OUT(handle, "\t retPduTlv.data is %s\n", retPdu->data);
+}
+
+void printExStatusTlv(mpls_instance_handle handle, mplsLdpExStatusTlv_t * status)
+{
+  LDP_TRACE_OUT(handle, "\t exStatusTlv:\n");
+  printTlv(handle, &(status->baseTlv));
+  LDP_TRACE_OUT(handle, "\t exStatus data: value = %d\n", status->value);
+}
+
+void printStatusTlv(mpls_instance_handle handle, mplsLdpStatusTlv_t * status)
+{
+  LDP_TRACE_OUT(handle, "\t statusTlv:\n");
+  printTlv(handle, &(status->baseTlv));
+  LDP_TRACE_OUT(handle, "\t status data:   msgId = %x\n", status->msgId);
+  LDP_TRACE_OUT(handle, "\t\t\tmsgType = %x\n", status->msgType);
+  LDP_TRACE_OUT(handle, "\t status Flags:  error = %d\n",
+    status->flags.flags.error);
+  LDP_TRACE_OUT(handle, "\t\t\tforward = %d\n", status->flags.flags.forward);
+  LDP_TRACE_OUT(handle, "\t\t\tstatus = %d\n", status->flags.flags.status);
+}
+
+void printNotMsg(mpls_instance_handle handle, mplsLdpNotifMsg_t * notMsg)
+{
+  LDP_TRACE_OUT(handle, "NOTIF MSG ***START***:\n");
+  printMsgBase(handle, &(notMsg->baseMsg));
+
+  if (notMsg->statusTlvExists) {
+    printStatusTlv(handle, &(notMsg->status));
+  } else {
+    LDP_TRACE_OUT(handle, "\tNotif msg does not have Status TLV\n");
+  }
+  if (notMsg->exStatusTlvExists) {
+    printExStatusTlv(handle, &(notMsg->exStatus));
+  } else {
+    LDP_TRACE_OUT(handle, "\tNotif msg does not have Extended Status TLV\n");
+  }
+  if (notMsg->retPduTlvExists) {
+    printRetPduTlv(handle, &(notMsg->retPdu));
+  } else {
+    LDP_TRACE_OUT(handle, "\tNotif msg does not have Return PDU\n");
+  }
+  if (notMsg->retMsgTlvExists) {
+    printRetMsgTlv(handle, &(notMsg->retMsg));
+  } else {
+    LDP_TRACE_OUT(handle, "\tNotif msg does not have Return MSG\n");
+  }
+  LDP_TRACE_OUT(handle, "NOTIF MSG ***END***:\n");
+}
+
+void printCsnTlv(mpls_instance_handle handle, mplsLdpCsnTlv_t * csn)
+{
+  LDP_TRACE_OUT(handle, "\t csnTlv:\n");
+  printTlv(handle, &(csn->baseTlv));
+  LDP_TRACE_OUT(handle, "\t csnTlv data: value = %d\n", csn->seqNumber);
+}
+
+void printTrAdrTlv(mpls_instance_handle handle, mplsLdpTrAdrTlv_t * trAdr)
+{
+  LDP_TRACE_OUT(handle, "\t trAdrTlv:\n");
+  printTlv(handle, &(trAdr->baseTlv));
+  LDP_TRACE_OUT(handle, "\t trAdrTlv data: value = %08x\n", trAdr->address);
+}
+
+void printChpTlv(mpls_instance_handle handle, mplsLdpChpTlv_t * chp)
+{
+  LDP_TRACE_OUT(handle, "\t chpTlv:\n");
+  printTlv(handle, &(chp->baseTlv));
+  LDP_TRACE_OUT(handle, "\t chpTlv data: holdTime = %d\n", chp->holdTime);
+  LDP_TRACE_OUT(handle, "\t chpTlv Flags:  target = %d\n",
+    chp->flags.flags.target);
+  LDP_TRACE_OUT(handle, "\t\t\trequest = %d\n", chp->flags.flags.request);
+  LDP_TRACE_OUT(handle, "\t\t\tres = %d\n", chp->flags.flags.res);
+}
+
+void printHelloMsg(mpls_instance_handle handle, mplsLdpHelloMsg_t * helloMsg)
+{
+  LDP_TRACE_OUT(handle, "HELLO MSG ***START***:\n");
+  printMsgBase(handle, &(helloMsg->baseMsg));
+
+  if (helloMsg->chpTlvExists) {
+    printChpTlv(handle, &(helloMsg->chp));
+  } else {
+    LDP_TRACE_OUT(handle, "\tHello msg does not have Chp TLV\n");
+  }
+  if (helloMsg->trAdrTlvExists) {
+    printTrAdrTlv(handle, &(helloMsg->trAdr));
+  } else {
+    LDP_TRACE_OUT(handle, "\tHello msg does not have TrAdr TLV\n");
+  }
+  if (helloMsg->csnTlvExists) {
+    printCsnTlv(handle, &(helloMsg->csn));
+  } else {
+    LDP_TRACE_OUT(handle, "\tHello msg does not have Csn TLV\n");
+  }
+  LDP_TRACE_OUT(handle, "HELLO MSG ***END***:\n");
+}
+
+void printKeepAliveMsg(mpls_instance_handle handle,
+  mplsLdpKeepAlMsg_t * keepAliveMsg)
+{
+  LDP_TRACE_OUT(handle, "KEEP ALIVE MSG ***START***:\n");
+  printMsgBase(handle, &(keepAliveMsg->baseMsg));
+  LDP_TRACE_OUT(handle, "KEEP ALIVE MSG ***END***:\n");
+}
+
+void printAdrListTlv(mpls_instance_handle handle, mplsLdpAdrTlv_t * adrList)
+{
+  u_short i;
+  u_short length;
+
+  LDP_TRACE_OUT(handle, "\t adrListTlv:\n");
+  printTlv(handle, &(adrList->baseTlv));
+  LDP_TRACE_OUT(handle, "\t adrListTlv data: addrFamily = %x\n",
+    adrList->addrFamily);
+
+  /* get the current length of the encoding for addresses */
+
+  length = adrList->baseTlv.length - MPLS_ADDFAMFIXLEN;
+  LDP_TRACE_OUT(handle, "\t adrListTlv addresses (with %d addresses) :\n",
+    length / 4);
+  for (i = 0; i < (u_short) (length / 4); i++) {
+    if (i % 4 == 0) {
+      LDP_TRACE_OUT(handle, "\n\t\t\t");
+    }
+    LDP_TRACE_OUT(handle, "%02x  ", adrList->address[i]);
+  }
+  LDP_TRACE_OUT(handle, "\n");
+}
+
+void printAddressMsg(mpls_instance_handle handle, mplsLdpAdrMsg_t * adrMsg)
+{
+  if (adrMsg->baseMsg.flags.flags.msgType == MPLS_ADDR_MSGTYPE) {
+    LDP_TRACE_OUT(handle, "ADDRESS MSG ***START***:\n");
+  } else if (adrMsg->baseMsg.flags.flags.msgType == MPLS_ADDRWITH_MSGTYPE) {
+    LDP_TRACE_OUT(handle, "ADDRESS WITHDRAW MSG ***START***:\n");
+  }
+
+  printMsgBase(handle, &(adrMsg->baseMsg));
+
+  if (adrMsg->adrListTlvExists) {
+    printAdrListTlv(handle, &(adrMsg->addressList));
+  } else {
+    LDP_TRACE_OUT(handle, "\tAddress msg does not have addrList Tlv\n");
+  }
+  if (adrMsg->baseMsg.flags.flags.msgType == MPLS_ADDR_MSGTYPE) {
+    LDP_TRACE_OUT(handle, "ADDRESS MSG ***END***:\n");
+  } else if (adrMsg->baseMsg.flags.flags.msgType == MPLS_ADDRWITH_MSGTYPE) {
+    LDP_TRACE_OUT(handle, "ADDRESS WITHDRAW MSG ***END***:\n");
+  }
+}
+
+void printFecListTlv(mpls_instance_handle handle, mplsLdpFecTlv_t * fecTlv)
+{
+  u_short i;
+
+  LDP_TRACE_OUT(handle, "\t fecTlv:\n");
+  printTlv(handle, &(fecTlv->baseTlv));
+  LDP_TRACE_OUT(handle, "\t\tfecTlv->numberFecElements = %d\n",
+    fecTlv->numberFecElements);
+  for (i = 0; i < fecTlv->numberFecElements; i++) {
+    LDP_TRACE_OUT(handle, "\t\telem %d type is %d\n", i,
+      fecTlv->fecElemTypes[i]);
+    if ((fecTlv->fecElemTypes[i] == 2) || (fecTlv->fecElemTypes[i] == 3)) {
+      LDP_TRACE_OUT(handle,
+        "\t\tFec Element : type = %d, addFam = %x, preLen = %d, address = %x\n",
+        fecTlv->fecElArray[i].addressEl.type,
+        fecTlv->fecElArray[i].addressEl.addressFam,
+        fecTlv->fecElArray[i].addressEl.preLen,
+        fecTlv->fecElArray[i].addressEl.address);
+    }
+  }
+  LDP_TRACE_OUT(handle, "\n");
+  LDP_TRACE_OUT(handle, "\tfecTlv.wcElemExists = %d\n", fecTlv->wcElemExists);
+
+}
+
+void printLblMsgIdTlv(mpls_instance_handle handle,
+  mplsLdpLblMsgIdTlv_t * lblMsgId)
+{
+  LDP_TRACE_OUT(handle, "\t lblMsgIdTlv:\n");
+  printTlv(handle, &(lblMsgId->baseTlv));
+  LDP_TRACE_OUT(handle, "\t LblMsgId data:  msgId = %d\n", lblMsgId->msgId);
+}
+
+void printPathVecTlv(mpls_instance_handle handle, mplsLdpPathTlv_t * pathVec)
+{
+  u_int i, numlsrId;
+
+  LDP_TRACE_OUT(handle, "\t pathVecTlv:\n");
+  printTlv(handle, &(pathVec->baseTlv));
+  LDP_TRACE_OUT(handle, "\t PathVec data: ");
+
+  numlsrId = pathVec->baseTlv.length / 4;
+
+  for (i = 0; i < numlsrId; i++) {
+    if (i == 0) {
+      LDP_TRACE_OUT(handle, "lsrId[%d] = %x\n", i, pathVec->lsrId[i]);
+    } else {
+      LDP_TRACE_OUT(handle, "\t\t\tlsrId[%d] = %x\n", i, pathVec->lsrId[i]);
+    }
+  }
+  LDP_TRACE_OUT(handle, "\n");
+}
+
+void printHopTlv(mpls_instance_handle handle, mplsLdpHopTlv_t * hopCount)
+{
+  LDP_TRACE_OUT(handle, "\t hopCountTlv:\n");
+  printTlv(handle, &(hopCount->baseTlv));
+  LDP_TRACE_OUT(handle, "\t hopCount data:  hcValue = %d\n", hopCount->hcValue);
+}
+
+void printFrLblTlv(mpls_instance_handle handle, mplsLdpFrLblTlv_t * fr)
+{
+  LDP_TRACE_OUT(handle, "\t frTlv :\n");
+  printTlv(handle, &(fr->baseTlv));
+  LDP_TRACE_OUT(handle, "\t Fr flags: res = %d\n", fr->flags.flags.res);
+  LDP_TRACE_OUT(handle, "\t\t len = %d\n", fr->flags.flags.len);
+  LDP_TRACE_OUT(handle, "\t\tdlci = %d\n", fr->flags.flags.dlci);
+}
+
+void printAtmLblTlv(mpls_instance_handle handle, mplsLdpAtmLblTlv_t * atm)
+{
+  LDP_TRACE_OUT(handle, "\t atmTlv :\n");
+  printTlv(handle, &(atm->baseTlv));
+  LDP_TRACE_OUT(handle, "\t Atm flags: res = %d\n", atm->flags.flags.res);
+  LDP_TRACE_OUT(handle, "\t\t v = %d\n", atm->flags.flags.v);
+  LDP_TRACE_OUT(handle, "\t\tvpi = %d\n", atm->flags.flags.vpi);
+  LDP_TRACE_OUT(handle, "\t Atm data : vci = %d\n", atm->vci);
+}
+
+void printGenLblTlv(mpls_instance_handle handle, mplsLdpGenLblTlv_t * genLbl)
+{
+  LDP_TRACE_OUT(handle, "\t genLblTlv:\n");
+  printTlv(handle, &(genLbl->baseTlv));
+  LDP_TRACE_OUT(handle, "\t genLbl data: label = %d\n", genLbl->label);
+}
+
+void printLlbMapMsg(mpls_instance_handle handle, mplsLdpLblMapMsg_t * lblMapMsg)
+{
+  LDP_TRACE_OUT(handle, "LABEL MAPPING MSG ***START***:\n");
+  printMsgBase(handle, &(lblMapMsg->baseMsg));
+
+  if (lblMapMsg->fecTlvExists) {
+    printFecListTlv(handle, &(lblMapMsg->fecTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel mapping msg does not have fec Tlv\n");
+  }
+  if (lblMapMsg->genLblTlvExists) {
+    printGenLblTlv(handle, &(lblMapMsg->genLblTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel mapping msg does not have gen label Tlv\n");
+  }
+  if (lblMapMsg->atmLblTlvExists) {
+    printAtmLblTlv(handle, &(lblMapMsg->atmLblTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel mapping msg does not have atm label Tlv\n");
+  }
+  if (lblMapMsg->frLblTlvExists) {
+    printFrLblTlv(handle, &(lblMapMsg->frLblTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel mapping msg does not have fr label Tlv\n");
+  }
+  if (lblMapMsg->hopCountTlvExists) {
+    printHopTlv(handle, &(lblMapMsg->hopCountTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel mapping msg does not have hop count Tlv\n");
+  }
+  if (lblMapMsg->pathVecTlvExists) {
+    printPathVecTlv(handle, &(lblMapMsg->pathVecTlv));
+  } else {
+    LDP_TRACE_OUT(handle,
+      "\tLabel mapping msg does not have path vector Tlv\n");
+  }
+  if (lblMapMsg->lblMsgIdTlvExists) {
+    printLblMsgIdTlv(handle, &(lblMapMsg->lblMsgIdTlv));
+  } else {
+    LDP_TRACE_OUT(handle,
+      "\tLabel mapping msg does not have label messageId Tlv\n");
+  }
+  if (lblMapMsg->lspidTlvExists) {
+    printLspIdTlv(handle, &(lblMapMsg->lspidTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel mapping msg does not have LSPID Tlv\n");
+  }
+  if (lblMapMsg->trafficTlvExists) {
+    printTrafficTlv(handle, &(lblMapMsg->trafficTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel mapping msg does not have traffic Tlv\n");
+  }
+  LDP_TRACE_OUT(handle, "LABEL MAPPING MSG ***END***:\n");
+}
+
+void printErFlags(mpls_instance_handle handle, mplsLdpErFlag_t * flags)
+{
+  LDP_TRACE_OUT(handle, "\t\tER FLAGS: l = %d, res = %d\n",
+    flags->l, flags->res);
+}
+
+void printErIPFlags(mpls_instance_handle handle, mplsLdpErIPFlag_t * flags)
+{
+  LDP_TRACE_OUT(handle, "\t\tER IP FLAGS: l = %d, res = %d, preLen = %d\n",
+    flags->l, flags->res, flags->preLen);
+}
+
+void printErHop(mpls_instance_handle handle, mplsLdpErHop_t * erHop,
+  u_short type)
+{
+  int i;
+
+  switch (type) {
+    case MPLS_ERHOP_IPV4_TLVTYPE:
+      {
+        printErIPFlags(handle, &(erHop->erIpv4.flags.flags));
+        LDP_TRACE_OUT(handle, "\t\t IPv4: address = %x\n",
+          erHop->erIpv4.address);
+        break;
+      }
+    case MPLS_ERHOP_IPV6_TLVTYPE:
+      {
+        printErIPFlags(handle, &(erHop->erIpv6.flags.flags));
+        LDP_TRACE_OUT(handle, "\t\t IPv6: address ");
+        for (i = 0; i < MPLS_IPV6ADRLENGTH; i++) {
+          LDP_TRACE_OUT(handle, "\t\t a[%d] = %x\n", i,
+            erHop->erIpv6.address[i]);
+        }
+        break;
+      }
+    case MPLS_ERHOP_AS_TLVTYPE:
+      {
+        printErFlags(handle, &(erHop->erAs.flags.flags));
+        LDP_TRACE_OUT(handle, "\t\t ASnumber: asNumber = %d\n",
+          erHop->erAs.asNumber);
+        break;
+      }
+    case MPLS_ERHOP_LSPID_TLVTYPE:
+      {
+        printErFlags(handle, &(erHop->erLspId.flags.flags));
+        LDP_TRACE_OUT(handle, "\t\t LSPID: lspid = %d, routerId = %d\n",
+          erHop->erLspId.lspid, erHop->erLspId.routerId);
+        break;
+      }
+    default:
+      {
+        LDP_TRACE_OUT(handle, "UNKNWON ER HOP type = %d\n", type);
+      }
+  }
+}
+
+void printErTlv(mpls_instance_handle handle, mplsLdpErTlv_t * erTlv)
+{
+  u_short i;
+
+  LDP_TRACE_OUT(handle, "\t erTlv:\n");
+  printTlv(handle, &(erTlv->baseTlv));
+  LDP_TRACE_OUT(handle, "\t erTlv has %d ErHops\n", erTlv->numberErHops);
+  for (i = 0; i < erTlv->numberErHops; i++) {
+    LDP_TRACE_OUT(handle, "\tTYPE[%i] = %x\n", i, erTlv->erHopTypes[i]);
+    printErHop(handle, &(erTlv->erHopArray[i]), erTlv->erHopTypes[i]);
+  }
+}
+
+void printTrafficFlags(mpls_instance_handle handle,
+  mplsLdpTrafficFlag_t * traflag)
+{
+  LDP_TRACE_OUT(handle,
+    "\t\tTraffic flags: res = %d, F6 = %d, F5 = %d, F4 = %d, F3 = %d, F2 = %d, F1 = %d\n",
+    traflag->res, traflag->f6Bit, traflag->f5Bit, traflag->f4Bit,
+    traflag->f3Bit, traflag->f2Bit, traflag->f1Bit);
+}
+
+void printTrafficTlv(mpls_instance_handle handle,
+  mplsLdpTrafficTlv_t * trafficTlv)
+{
+  LDP_TRACE_OUT(handle, "\t trafficTlv:\n");
+  printTlv(handle, &(trafficTlv->baseTlv));
+  printTrafficFlags(handle, &(trafficTlv->flags.flags));
+  LDP_TRACE_OUT(handle,
+    "\t trafficTlv data: freq = %d, res = %d, weight = %d\n", trafficTlv->freq,
+    trafficTlv->res, trafficTlv->weight);
+  LDP_TRACE_OUT(handle, "\t trafficTlv param: \n");
+  LDP_TRACE_OUT(handle, "\t\t PDR = %f (%x)\n", trafficTlv->pdr.pdr,
+    *(u_int *) & (trafficTlv->pdr.pdr));
+  LDP_TRACE_OUT(handle, "\t\t PBS = %f (%x)\n", trafficTlv->pbs.pbs,
+    *(u_int *) & (trafficTlv->pbs.pbs));
+  LDP_TRACE_OUT(handle, "\t\t CDR = %f (%x)\n", trafficTlv->cdr.cdr,
+    *(u_int *) & (trafficTlv->cdr.cdr));
+  LDP_TRACE_OUT(handle, "\t\t CBS = %f (%x)\n", trafficTlv->cbs.cbs,
+    *(u_int *) & (trafficTlv->cbs.cbs));
+  LDP_TRACE_OUT(handle, "\t\t EBS = %f (%x)\n", trafficTlv->ebs.ebs,
+    *(u_int *) & (trafficTlv->ebs.ebs));
+}
+
+void printLlbReqMsg(mpls_instance_handle handle, mplsLdpLblReqMsg_t * lblReqMsg)
+{
+  LDP_TRACE_OUT(handle, "LABEL REQUEST MSG ***START***:\n");
+  printMsgBase(handle, &(lblReqMsg->baseMsg));
+
+  if (lblReqMsg->fecTlvExists) {
+    printFecListTlv(handle, &(lblReqMsg->fecTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel request msg does not have fec Tlv\n");
+  }
+  if (lblReqMsg->hopCountTlvExists) {
+    printHopTlv(handle, &(lblReqMsg->hopCountTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel request msg does not have hop count Tlv\n");
+  }
+  if (lblReqMsg->pathVecTlvExists) {
+    printPathVecTlv(handle, &(lblReqMsg->pathVecTlv));
+  } else {
+    LDP_TRACE_OUT(handle,
+      "\tLabel request msg does not have path vector Tlv\n");
+  }
+  if (lblReqMsg->lblMsgIdTlvExists) {
+    printTlv(handle, &(lblReqMsg->lblMsgIdTlv.baseTlv));
+  } else {
+    LDP_TRACE_OUT(handle,
+      "\tLabel request msg does not have return msgId Tlv\n");
+  }
+  if (lblReqMsg->erTlvExists) {
+    printErTlv(handle, &(lblReqMsg->erTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel request msg does not have cr Tlv\n");
+  }
+  if (lblReqMsg->trafficTlvExists) {
+    printTrafficTlv(handle, &(lblReqMsg->trafficTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel request msg does not have traffic Tlv\n");
+  }
+  if (lblReqMsg->lspidTlvExists) {
+    printLspIdTlv(handle, &(lblReqMsg->lspidTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel request msg does not have LSPID Tlv\n");
+  }
+  if (lblReqMsg->pinningTlvExists) {
+    printPinningTlv(handle, &(lblReqMsg->pinningTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel request msg does not have Pinning Tlv\n");
+  }
+  if (lblReqMsg->recClassTlvExists) {
+    printResClsTlv(handle, &(lblReqMsg->resClassTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel request msg does not have ResClass Tlv\n");
+  }
+  if (lblReqMsg->preemptTlvExists) {
+    printPreemptTlv(handle, &(lblReqMsg->preemptTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel request msg does not have Preempt Tlv\n");
+  }
+  LDP_TRACE_OUT(handle, "LABEL REQUEST MSG ***END***:\n");
+}
+
+void printLbl_W_R_Msg(mpls_instance_handle handle, mplsLdpLbl_W_R_Msg_t * msg)
+{
+  if (msg->baseMsg.flags.flags.msgType == MPLS_LBLWITH_MSGTYPE) {
+    LDP_TRACE_OUT(handle, "LABEL WITHDRAW MSG ***START***:\n");
+  } else if (msg->baseMsg.flags.flags.msgType == MPLS_LBLREL_MSGTYPE) {
+    LDP_TRACE_OUT(handle, "LABEL RELEASE MSG ***START***:\n");
+  }
+  printMsgBase(handle, &(msg->baseMsg));
+
+  if (msg->fecTlvExists) {
+    printFecListTlv(handle, &(msg->fecTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel msg does not have fec Tlv\n");
+  }
+  if (msg->genLblTlvExists) {
+    printGenLblTlv(handle, &(msg->genLblTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel msg does not have gen Tlv\n");
+  }
+  if (msg->atmLblTlvExists) {
+    printAtmLblTlv(handle, &(msg->atmLblTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel msg does not have atm Tlv\n");
+  }
+  if (msg->frLblTlvExists) {
+    printFrLblTlv(handle, &(msg->frLblTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel msg does not have fr Tlv\n");
+  }
+  if (msg->lspidTlvExists) {
+    printLspIdTlv(handle, &(msg->lspidTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel msg does not have LSPID Tlv\n");
+  }
+  if (msg->baseMsg.flags.flags.msgType == MPLS_LBLWITH_MSGTYPE) {
+    LDP_TRACE_OUT(handle, "LABEL WITHDRAW MSG *** END ***:\n");
+  } else if (msg->baseMsg.flags.flags.msgType == MPLS_LBLREL_MSGTYPE) {
+    LDP_TRACE_OUT(handle, "LABEL RELEASE MSG *** END ***:\n");
+  }
+}
+
+void printPreemptTlv(mpls_instance_handle handle,
+  mplsLdpPreemptTlv_t * preemptTlv)
+{
+  LDP_TRACE_OUT(handle, "\t preemptTlv:\n");
+  printTlv(handle, &(preemptTlv->baseTlv));
+  LDP_TRACE_OUT(handle,
+    "\t preemptTlv data: setPrio = %d, holdPrio = %d, res = %d\n",
+    preemptTlv->setPrio, preemptTlv->holdPrio, preemptTlv->res);
+}
+
+void printResClsTlv(mpls_instance_handle handle, mplsLdpResClsTlv_t * tlv)
+{
+  LDP_TRACE_OUT(handle, "\t resClsTlv:\n");
+  printTlv(handle, &(tlv->baseTlv));
+  LDP_TRACE_OUT(handle, "\t resClsTlv data: rsCls = %x\n", tlv->rsCls);
+}
+
+void printLspIdTlv(mpls_instance_handle handle, mplsLdpLspIdTlv_t * tlv)
+{
+  LDP_TRACE_OUT(handle, "\t lspIdTlv:\n");
+  printTlv(handle, &(tlv->baseTlv));
+  LDP_TRACE_OUT(handle,
+    "\t lspIdTlv data: res = %d, localCrlspId = %d, routerId = %x\n", tlv->res,
+    tlv->localCrlspId, tlv->routerId);
+}
+
+void printPinningTlv(mpls_instance_handle handle, mplsLdpPinningTlv_t * tlv)
+{
+  LDP_TRACE_OUT(handle, "\t pinningTlv:\n");
+  printTlv(handle, &(tlv->baseTlv));
+  LDP_TRACE_OUT(handle, "\t pinningTlv data: pBit = %d, res = %d\n",
+    tlv->flags.flags.pBit, tlv->flags.flags.res);
+}
+
+void printLlbAbortMsg(mpls_instance_handle handle, mplsLdpLblAbortMsg_t * lblMsg)
+{
+  LDP_TRACE_OUT(handle, "LABEL ABORT MSG ***START***:\n");
+  printMsgBase(handle, &(lblMsg->baseMsg));
+
+  if (lblMsg->fecTlvExists) {
+    printFecListTlv(handle, &(lblMsg->fecTlv));
+  } else {
+    LDP_TRACE_OUT(handle, "\tLabel abort msg does not have fec Tlv\n");
+  }
+  if (lblMsg->lblMsgIdTlvExists) {
+    printLblMsgIdTlv(handle, &(lblMsg->lblMsgIdTlv));
+  } else {
+    LDP_TRACE_OUT(handle,
+      "\tLabel abort msg does not have label messageId Tlv\n");
+  }
+  LDP_TRACE_OUT(handle, "LABEL ABORT MSG ***END***:\n");
+}
+
+/* 
+ *   Routine to convert hex string to ascii string
+ */
+
+int converHexToAscii(u_char * buffHex, int buffHexLen, u_char * buffAscii)
+{
+  /* convert the hexEncrypP hex string to a char sting */
+  int i = 0;
+  int j = 0;
+  char c, c1;
+  u_char *p = buffHex;
+  u_char *q = buffAscii;
+
+  for (i = 0; i < buffHexLen; i += 2, j++) {
+    c = *p;
+    p++;
+    c1 = *p;
+    p++;
+    if (c >= '0' && c <= '9')
+      c -= '0';
+    else if (c >= 'A' && c <= 'F')
+      c -= 'A' - 0xa;
+    else if (c >= 'a' && c <= 'f')
+      c -= 'a' - 0xa;
+    else
+      return 0;
+    if (c1 >= '0' && c1 <= '9')
+      c1 -= '0';
+    else if (c1 >= 'A' && c1 <= 'F')
+      c1 -= 'A' - 0xa;
+    else if (c1 >= 'a' && c1 <= 'f')
+      c1 -= 'a' - 0xa;
+    else
+      return 0;
+
+    *q++ = (c << 4) + (c1 & 0x0f);
+  }
+  return j;
+
+}                               /* End : converHexToAscii */
+
+/* 
+ *   Routine to convert ascii string to hex string
+ */
+int converAsciiToHex(u_char * buffHex, int buffAsciiLen, u_char * buffAscii)
+{
+  int i;
+  u_char *p2 = buffHex;
+  u_char *p1 = buffAscii;
+  u_char buf[3];
+
+  for (i = 0; i < buffAsciiLen; i++) {
+    memset(buf, 0, 3);
+    sprintf((char *)buf, "%02x", *p1++);
+    memcpy(p2, buf, 2);
+    p2 += strlen((char *)buf);
+  }
+  *p2 = '\0';
+
+  p2 = buffHex;
+  for (i = 0; i < 2 * buffAsciiLen; i++) {
+    PRINT_OUT("%c", *p2++);
+  }
+  PRINT_OUT("\n");
+  return i;
+
+}                               /* End : converAsciiToHex */
+
+/*****************************************************************************
+* This section includes one example  of hex buffers which contains encoding  *
+* for a pdu header and a request message.                                    *
+*                                                                            *
+* the hex buffer for the request message contains (where q represents the end*
+* of the buffer):                                                            *
+*                                                                            *
+* 0001009AC00003050002040100900000000806010000010000100200011B00194059030001 *
+* 042F7D308308210008000000013A1D65030800003008040008000000193A1D651708040008 * 
+* 800000053A1D6503080400088000000F3A1D650D08040008000000233A1D65210810001824 * 
+* 01000040e3333342c8000040e00000447a0000412000000823000480000000082200040ABC * 
+* DEFF0820000407070000q                                                      *
+*                                                                            *
+* Make sure that when copy and paste the buffer, there are no new line chars *
+* or blanks.                                                                 *
+* When decoding the above buffer, the following debug output should show if  *
+* the debug flag is defined and set:                                         *
+*                                                                            *
+*LPD Header : protocolVersion = 1                                            *
+*        pduLength = 154                                                     *
+*        lsrAddress = c0000305                                               *
+*        labelSpace = 2                                                      *
+*                                                                            *
+*LABEL REQUEST MSG ***START***:                                              *
+*        baseMsg : msgType = 401                                             *
+*                msgLength = 144                                             *
+*                msgId = 8                                                   *
+*         fecTlv:                                                            *
+*         Tlv:                                                               *
+*         BaseTlv: type = 100                                                *
+*                  length = 16                                               *
+*                  uBit = 0                                                  *
+*                  fBit = 0                                                  *
+*                fecTlv->numberFecElements = 2                               *
+*                elem 0 type is 2                                            *
+*                Fec Element : type = 2, addFam = 1, preLen = 27,            *
+*                              address = 194059                              *
+*                elem 1 type is 3                                            *
+*                Fec Element : type = 3, addFam = 1, preLen = 4,             *
+*                              address = 2f7d3083                            *
+*                                                                            * 
+*        fecTlv.wcElemExists = 0                                             *
+*        Label request msg does not have cos label Tlv                       *
+*        Label request msg does not have hop count Tlv                       *
+*        Label request msg does not have path vector Tlv                     *
+*         Tlv:                                                               *
+*         BaseTlv: type = 601                                                *
+*                  length = 0                                                *
+*                  uBit = 0                                                  *
+*                  fBit = 0                                                  *
+*         erTlv:                                                             *
+*         Tlv:                                                               *
+*         BaseTlv: type = 800                                                *
+*                  length = 48                                               *
+*                  uBit = 0                                                  *
+*                  fBit = 0                                                  *
+*         erTlv has 4 ErHops                                                 *
+*        TYPE[0] = 804                                                       *
+*                ER FLAGS: l = 0, res = 0                                    *
+*                 LSPID: lspid = 25, routerId = 975004951                    *
+*        TYPE[1] = 804                                                       *
+*                ER FLAGS: l = 1, res = 0                                    *
+*                 LSPID: lspid = 5, routerId = 975004931                     *
+*        TYPE[2] = 804                                                       *
+*                ER FLAGS: l = 1, res = 0                                    *
+*                 LSPID: lspid = 15, routerId = 975004941                    *
+*        TYPE[3] = 804                                                       *
+*                ER FLAGS: l = 0, res = 0                                    *
+*                 LSPID: lspid = 35, routerId = 975004961                    *
+*         trafficTlv:                                                        *
+*         Tlv:                                                               *
+*         BaseTlv: type = 810                                                *
+*                  length = 24                                               *
+*                  uBit = 0                                                  *
+*                  fBit = 0                                                  *
+*                Traffic flags: res = 0, F6 = 1, F5 = 0, F4 = 0, F3 = 1,     * 
+*                                        F2 = 0, F1 = 0                      *
+*         trafficTlv data: freq = 1, res = 0, weight = 0                     *
+*         trafficTlv param:                                                  *
+*                 PDR = 7.1(40e33333)                                        *
+*                 PBS = 100.0(42c80000)                                      *
+*                 CDR = 7.0(40e00000)                                        *
+*                 CBS = 1000.0(447a0000)                                     *
+*                 EBS = 10.0(41200000)                                       *
+*         lspIdTlv:                                                          *
+*         Tlv:                                                               *
+*         BaseTlv: type = 821                                                *
+*                  length = 8                                                *
+*                  uBit = 0                                                  *
+*                  fBit = 0                                                  *
+*         lspIdTlv data: res = 0, localCrlspId = 1, routerId = 3a1d6503      *
+*         pinningTlv:                                                        *
+*         Tlv:                                                               *
+*         BaseTlv: type = 823                                                *
+*                  length = 4                                                *
+*                  uBit = 0                                                  *
+*                  fBit = 0                                                  *
+*         pinningTlv data: pBit = 1, res = 0                                 *
+*         resClsTlv:                                                         *
+*         Tlv:                                                               *
+*         BaseTlv: type = 822                                                *
+*                  length = 4                                                *
+*                  uBit = 0                                                  *
+*                  fBit = 0                                                  *
+*         resClsTlv data: rsCls = abcdeff                                    *
+*         preemptTlv:                                                        *
+*         Tlv:                                                               *
+*         BaseTlv: type = 820                                                *
+*                  length = 4                                                *
+*                  uBit = 0                                                  *
+*                  fBit = 0                                                  *
+*         preemptTlv data: setPrio = 7, holdPrio = 7, res = 0                *
+*LABEL REQUEST MSG ***END***:                                                *
+*****************************************************************************/
diff -Naur quagga-0.99.10/ldpd/ldp_nortel.h quagga-mpls/ldpd/ldp_nortel.h
--- quagga-0.99.10/ldpd/ldp_nortel.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_nortel.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,1830 @@
+#ifndef _LDP_MPLS_H_
+#define _LDP_MPLS_H_
+
+/******************************************************************************
+*                       Nortel Networks Software License                      *
+*                                                                             *
+* READ THE TERMS OF THIS LICENSE CAREFULLY.  BY USING, MODIFYING, OR          *
+* DISTRIBUTING THIS SOFTWARE AND ANY ACCOMPANYING DOCUMENTATION (COLLECTIVELY,*
+* "SOFTWARE") YOU ARE AGREEING TO ALL OF THE TERMS OF THIS LICENSE.           *
+*                                                                             *
+* 1.      Nortel Telecom Limited, on behalf of itself and its subsidiaries    *
+* (collectively "Nortel Networks") grants to you a non-exclusive, perpetual,  *
+* world-wide right to use, copy, modify, and distribute the Software at no    *
+* charge.                                                                     *
+*                                                                             *
+* 2.      You may sublicense recipients of redistributed Software to use,     *
+* copy, modify, and distribute the Software on substantially the same terms as*
+* this License.  You may not impose any further restrictions on the           *
+* recipient's exercise of the rights in the Software granted under this       *
+* License.  Software distributed to other parties must be accompanied by a    *
+* License containing a grant, disclaimer and limitation of liability          *
+* substantially in the form of 3, 4, and 5 below provided that references to  *
+* "Nortel Networks" may be changed to "Supplier".                             *
+*                                                                             *
+* 3.      Nortel Networks reserves the right to modify and release new        *
+* versions of the Software from time to time which may include modifications  *
+* made by third parties like you. Accordingly, you agree that you shall       *
+* automatically grant a license to Nortel Networks to include, at its option, *
+* in any new version of the Software any modifications to the Software made by*
+* you and made available directly or indirectly to Nortel Networks.  Nortel   *
+* Networks shall have the right to use, copy, modify, and distribute any such *
+* modified Software on substantially the same terms as this License.          *
+*                                                                             *
+* 4.      THE SOFTWARE IS PROVIDED ON AN "AS IS" BASIS.  NORTEL NETWORKS AND  *
+* ITS AGENTS AND SUPPLIERS DISCLAIM ALL REPRESENTATIONS, WARRANTIES AND       *
+* CONDITIONS RELATING TO THE SOFTWARE, INCLUDING, BUT NOT LIMITED TO, IMPLIED *
+* WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND         *
+* NON-INFRINGEMENT OF THIRD-PARTY INTELLECTUAL PROPERTY RIGHTS.  NORTEL       *
+* NETWORKS AND ITS AGENTS AND SUPPLIERS DO NOT WARRANT, GUARANTEE, OR MAKE ANY*
+* REPRESENTATIONS REGARDING THE USE, OR THE RESULTS OF THE USE, OF THE        *
+* SOFTWARE IN TERMS OR CORRECTNESS, ACCURACY, RELIABILITY, CURRENTNESS, OR    *
+* OTHERWISE.                                                                  *
+*                                                                             *
+* 5.      NEITHER NORTEL NETWORKS NOR ANY OF ITS AGENTS OR SUPPLIERS SHALL BE *
+* LIABLE FOR ANY DIRECT, INDIRECT, CONSEQUENTIAL, INCIDENTAL OR EXEMPLARY     *
+* DAMAGES, OR ECONOMIC LOSSES (INCLUDING DAMAGES FOR LOSS OF BUSINESS PROFITS,*
+* BUSINESS INTERRUPTION, LOSS OF BUSINESS INFORMATION AND THE LIKE), ARISING  *
+* FROM THE SOFTWARE OR THIS LICENSE AGREEMENT, EVEN IF NORTEL NETWORKS OR SUCH*
+* AGENT OR SUPPLIER HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR    *
+* LOSSES, AND WHETHER ANY SUCH DAMAGE OR LOSS ARISES OUT OF CONTRACT, TORT, OR*
+* OTHERWISE.                                                                  *
+*                                                                             *
+* 6.      This License shall be governed by the laws of the Province of       *
+* Ontario, Canada.                                                            *
+*******************************************************************************/
+
+/******************************************************************************
+ * This file contains the C implementation for encode/decode functions        * 
+ * for the following types of messages: notification, hello, initialization,  *
+ * keepAlive, address, address Withdraw, label Mapping, label Request, label  *
+ * Withdraw and label Release. There are also encode/decode methods for all   * 
+ * tlv types required by the previously enumerated messages.                  * 
+ * Please remember that the pdu will always contain the header followed by 1  *
+ * or more LDP messages. The file contains functions to encode/decode the LDP *
+ * header as well.  							      * 
+ * All the messages, header message and the tlvs are in conformity with the   * 
+ * draft-ietf-mpls-ldp-04  (May 1999) and with draft-ietf-mpls-cr-ldp-01      *
+ * (Jan 1999). 								      * 
+ *								              *
+ * Please note that the U bit in the message and the F bit in the tlv are     *
+ * ignored in this version of the code.                                       *
+ *								              *
+ * Please note that the traffic parameters for traffic TLV have to be IEEE    *
+ * single precision floating point numbers.                                   *
+ *								              *
+ * Please note that there might be a small chance for bit field manipulation  *
+ * portability inconsistency. If such problems occure, the code requires      *
+ * changes for a suitable bit-field manipulation. The code for encoding and   *
+ * decoding makes the assumption that the compiler packs the bit fields in a  *
+ * structure into adjacent bits of the same unit.                             * 
+ *								              *
+ * The usage of the encode/decode functions is described below.               * 
+ *								              *
+ * The encode functions take as arguments: a pointer to the structure which   *
+ * implements msg/tlv, a buffer (where the encoding is done) and the buffer   *
+ * length.							              *
+ * If the encode is successfull, the function returns the total encoded       * 
+ * length.								      *
+ * If the encode fails, the function returns an error code.                   *
+ * The encode functions for messages and message headers do not modify the    *
+ * content of the struct which is to be encoded. All the other encode         *
+ * functions will change the content of the structure. The pointer which      *
+ * points to the beginning of the buffer is not changed.                      *
+ *									      *
+ * The decode functions take as arguments: a pointer to the structure which   *
+ * is going to be populated after decoding, a pointer to a buffer and the     *
+ * buffer length.							      *
+ * If the decode is successful, the function returns the total decoded length *
+ * If the decode fails, the function returns an error code. The decode        *
+ * functions do not modify the pointer to the buffer which contains the data  *
+ * to be decoded.							      *
+ *									      *
+ * Example on how to use the encode/decode functions for a keepAlive message: *
+ *									      *
+ *           Encode the keep alive message:                                   * 
+ *           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    				      *
+ *           u_char buffer[500];	 				      *
+ *           int returnCode; 						      *
+ *           struct mplsLdpKeepAlMsg_s keepAliveMsg;            	      *
+ *           keepAliveMsg.baseMsg.msgType   = MPLS_KEEPAL_MSGTYPE;            *
+ *           keepAliveMsg.baseMsg.msgLength = MPLS_MSGIDFIXLEN;               *
+ *           keepAliveMsg.baseMsg.msgId     = 123;		              *
+ *           bzero(buffer, 500);                                  	      *
+ *           returnCode = Mpls_encodeLdpKeepAliveMsg(&keepAliveMsg,           *
+ *                                                   buffer,                  *
+ *                                                   500);                    *
+ *           if (returnCode < 0)                                              *
+ *              check the error code				              *
+ *           else                                                             *
+ *              write(fd, buffer, returnCode);                                *
+ *									      *
+ *									      *
+ *           Decode the keep alive meesage:                                   *
+ *           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^		                      *
+ *           u_char buffer[500];					      *
+ *           int returnCode;					              *
+ *           struct mplsLdpKeepAlMsg_s keepAliveMsg;	            	      *
+ *           read(fd, buffer, length);                                        *
+ *           returnCode =  Mpls_decodeLdpKeepAliveMsg(&keepAliveMsg,          * 
+ *                                                    buffer,                 *
+ *                                                    500); 		      *
+ *           if (returnCode < 0)	                                      *
+ *              check the error code					      *
+ *           else				 			      *
+ *           { 								      *
+ *              printKeepAliveMsg(&keepAliveMsg);	 	              *
+ *           } 						                      *
+ *								              *
+ * An example on how to use the decode functions for the header and the       *
+ * messages can be found in the main function.                                *
+ *								              *
+ * The code was tested for big endian and little endian for sparc5, linux     *
+ * and i960.                                                                  *
+ *								              *
+ * In order to compile for little endian, the LITTLE_ENDIAN_BYTE_ORDER should *
+ * be defined.								      *
+ *								              *
+ * At the end of this file there is an examples of a hex buffers and its      *
+ * corresponding values.                                                      *
+ *								              *
+ *								              *
+ * Version History                                                            *
+ * Version          Date      Authors            Description                  *
+ * ===========      ========  =========          ======================       *
+ * mpls_encdec_01.c 99/03/15  Antonela Paraschiv draft-ietf-mpls-ldp-03 and   * 
+ *                                               draft-ietf-mpls-cr-ldp-01    *
+ *								              *
+ * mpls_encdec_02.c 99/05/19  Antonela Paraschiv draft-ietf-mpls-ldp-04 and   * 
+ *                                               draft-ietf-mpls-cr-ldp-01    *
+ *								              *
+ ******************************************************************************/
+
+#include "ldp_struct.h"
+#include "mpls_bitfield.h"
+#include <sys/types.h>
+#include <string.h>
+
+#define MEM_COPY(X, Y, Z) memcpy(X, Y, Z)
+
+/* macros used to decode the entire LDP; they declare local var for
+   different type of messages */
+
+/* debug macros */
+#define PRINT_OUT(args...) LDP_PRINT(NULL,args)
+#define PRINT_ERR(args...) LDP_PRINT(NULL,args)
+
+/*
+ *    MESSAGE TYPE CONSTANS & TLV CONSTANTS
+ */
+
+#define MPLS_LDP_HDRSIZE         10 /* the size for mpls ldp hdr  */
+#define MPLS_TLVFIXLEN           4 /* type + len                 */
+#define MPLS_MSGIDFIXLEN         4 /* type + len                 */
+#define MPLS_LDPIDLEN            6
+#define MPLS_PDUMAXLEN           4096 /* octets                    */
+#define MPLS_VERSION             0x0001
+#define MPLS_IPV4ADDRFAMILYN     0x0100 /* rfc 1700 (network order)  */
+#define MPLS_INIFINITE_TIMEVAL   0xfffff
+
+/* for initialize message */
+#define MPLS_INIT_MSGTYPE        0x0200 /* initialization msg          */
+#define MPLS_CSP_TLVTYPE         0x0500 /* common params for init msg  */
+#define MPLS_ASP_TLVTYPE         0x0501 /* atm session params          */
+#define MPLS_FSP_TLVTYPE         0x0502 /* frame relay session params  */
+#define MPLS_ASPFIXLEN           4 /* M + N + D + res             */
+#define MPLS_FSPFIXLEN           4 /* M + N + res                 */
+#define MPLS_CSPFIXLEN           14 /* protocolV + ... + ldp ids   */
+#define MPLS_ATMLBLMAXLEN        10
+#define MPLS_ATMLRGFIXLEN        8
+#define MPLS_FRLRGFIXLEN         8
+#define MPLS_ASP_NOMERGE         0
+#define MPLS_ASP_VPMERGE         1
+#define MPLS_ASP_VCMERGE         2
+#define MPLS_ASP_VPVCMERGE       3
+#define MPLS_FRLBLMAXLEN         10
+#define MPLS_FRDLCI10BITS        0
+#define MPLS_FRDLCI17BITS        1
+#define MPLS_FRDLCI23BITS        2
+
+/* for notification message */
+#define MPLS_NOT_MSGTYPE         0x0001 /* notification msg            */
+#define MPLS_NOT_ST_TLVTYPE      0x0300 /* status tlv for not msg      */
+#define MPLS_NOT_ES_TLVTYPE      0x0301 /* extended status for not msg */
+#define MPLS_NOT_RP_TLVTYPE      0x0302 /* returned PDU for not msg    */
+#define MPLS_NOT_RM_TLVTYPE      0x0303 /* returned msg for not msg    */
+#define MPLS_STATUSFIXLEN        10 /* status code + id + type     */
+#define MPLS_EXSTATUSLEN         4
+#define MPLS_NOT_MAXSIZE         MPLS_PDUMAXLEN - MPLS_TLVFIXLEN - \
+				 MPLS_MSGIDFIXLEN
+
+/* for hello message */
+#define MPLS_HELLO_MSGTYPE       0x0100 /* hello msg                   */
+#define MPLS_CHP_TLVTYPE         0x0400 /* Common Hello Param Tlv      */
+#define MPLS_TRADR_TLVTYPE       0x0401 /* Transport Address Param Tlv */
+#define MPLS_CSN_TLVTYPE         0x0402 /* Conf Seq Number Param Tlv   */
+#define MPLS_CHPFIXLEN           4
+#define MPLS_CSNFIXLEN           4
+#define MPLS_TRADRFIXLEN         4
+
+/* for keep alive message */
+#define MPLS_KEEPAL_MSGTYPE      0x0201 /* keep alive msg              */
+
+/* for address messages */
+#define MPLS_ADDR_MSGTYPE        0x0300 /* address msg                 */
+#define MPLS_ADDRWITH_MSGTYPE    0x0301 /* address withdraw msg        */
+#define MPLS_ADDRLIST_TLVTYPE    0x0101 /* addrss list tlv type        */
+#define MPLS_IPv4LEN             4
+#define MPLS_ADDFAMFIXLEN        2
+#define MPLS_ADDLISTMAXLEN       (MPLS_PDUMAXLEN - (2*MPLS_TLVFIXLEN) - \
+			         MPLS_MSGIDFIXLEN - MPLS_ADDFAMFIXLEN)
+#define MPLS_MAXNUMBERADR        MPLS_ADDLISTMAXLEN / 4
+
+/* for label mapping message */
+#define MPLS_LBLMAP_MSGTYPE      0x0400 /* label mapping msg           */
+#define MPLS_FEC_TLVTYPE         0x0100 /* label mapping msg           */
+#define MPLS_GENLBL_TLVTYPE      0x0200 /* generic label tlv           */
+#define MPLS_ATMLBL_TLVTYPE      0x0201 /* atm label tlv               */
+#define MPLS_FRLBL_TLVTYPE       0x0202 /* frame relay label tlv       */
+#define MPLS_HOPCOUNT_TLVTYPE    0x0103 /* ho count tlv                */
+#define MPLS_PATH_TLVTYPE        0x0104 /* path vector tlv             */
+#define MPLS_REQMSGID_TLVTYPE    0x0600 /* lbl request msg id tlv      */
+#define MPLS_WC_FEC              0x01 /* wildcard fec element        */
+#define MPLS_PREFIX_FEC          0x02 /* prefix fec element          */
+#define MPLS_HOSTADR_FEC         0x03 /* host addr fec element       */
+#define MPLS_CRLSP_FEC           0x04 /* crlsp fec element           */
+#define MPLS_FECMAXLEN           (MPLS_PDUMAXLEN - (2*MPLS_TLVFIXLEN) - \
+			         MPLS_MSGIDFIXLEN)
+#define MPLS_LBLFIXLEN           4 /* v + vpi + vci + res         */
+#define MPLS_HOPCOUNTFIXLEN      1 /* v + vpi + vci + res         */
+#define MPLS_FEC_ELEMTYPELEN     1
+#define MPLS_FEC_PRELENLEN       1
+#define MPLS_FEC_ADRFAMLEN       2
+#define MPLS_FEC_CRLSPLEN        4 /* length of cr lsp fec        */
+#define MPLS_MAXHOPSNUMBER       20 /* max # hops in path vector   */
+#define MPLS_MAXNUMFECELEMENT    10 /* max # of fec elements       */
+
+/* for label request message */
+#define MPLS_LBLREQ_MSGTYPE      0x0401 /* label request msg           */
+#define MPLS_LBLMSGID_TLVTYPE    0x0601 /* lbl return msg id tlv       */
+#define MPLS_ADR_FEC_FIXLEN	 (MPLS_FEC_ELEMTYPELEN + MPLS_FEC_PRELENLEN + MPLS_FEC_ADRFAMLEN)
+
+/* for label withdraw and release messages */
+#define MPLS_LBLWITH_MSGTYPE     0x0402 /* label withdraw msg          */
+#define MPLS_LBLREL_MSGTYPE      0x0403 /* label release msg           */
+
+/* for ER tlvs */
+#define MPLS_ER_TLVTYPE          0x0800 /* constraint routing tlv      */
+#define MPLS_TRAFFIC_TLVTYPE     0x0810 /* traffic parameters tlv      */
+#define MPLS_PDR_TLVTYPE         0x0811 /* traffic peak data rate tlv  */
+#define MPLS_CDR_TLVTYPE         0x0812 /* committed data rate tlv     */
+#define MPLS_CBT_TLVTYPE         0x0813 /* committed burst tolerance   */
+#define MPLS_PREEMPT_TLVTYPE     0x0820 /* preemption tlv              */
+#define MPLS_LSPID_TLVTYPE       0x0821 /* lspid tlv                   */
+#define MPLS_RESCLASS_TLVTYPE    0x0822 /* resource class tlv          */
+#define MPLS_PINNING_TLVTYPE     0x0823 /* route pinning tlv           */
+#define MPLS_ERHOP_IPV4_TLVTYPE  0x801 /* explicit routing ipv4 tlv   */
+#define MPLS_ERHOP_IPV6_TLVTYPE  0x802 /* explicit routing ipv6 tlv   */
+#define MPLS_ERHOP_AS_TLVTYPE    0x803 /* explicit routing autonomous
+                                          system number tlv           */
+#define MPLS_ERHOP_LSPID_TLVTYPE 0x804 /* explicit routing lspid tlv  */
+#define MPLS_ERHOP_IPV4_FIXLEN   8 /* fix length in bytes         */
+#define MPLS_ERHOP_IPV6_FIXLEN   20 /* fix length in bytes         */
+#define MPLS_ERHOP_AS_FIXLEN     4 /* fix length in bytes         */
+#define MPLS_ERHOP_LSPID_FIXLEN  8 /* fix length in bytes         */
+#define MPLS_IPV6ADRLENGTH       16
+#define MPLS_MAX_ER_HOPS         20 /* decent number of hops; 
+                                       change if required          */
+#define MPLS_PREEMPTTLV_FIXLEN   4 /* setPrio + holdPrio + res    */
+#define MPLS_LSPIDTLV_FIXLEN     8 /* res + crlspId + routerId    */
+#define MPLS_TRAFFICPARAMLENGTH  4 /* traffic parameters length   */
+
+/* for label abort request message */
+#define MPLS_LBLABORT_MSGTYPE 0x0404 /* label abort request msg     */
+
+/*
+ * Error codes
+ */
+
+#define MPLS_ENC_BUFFTOOSMALL    -1
+#define MPLS_DEC_BUFFTOOSMALL    -2
+#define MPLS_ENC_TLVERROR        -3
+#define MPLS_DEC_TLVERROR        -4
+#define MPLS_ENC_ATMLBLERROR     -5
+#define MPLS_DEC_ATMLBLERROR     -6
+#define MPLS_ENC_BASEMSGERROR    -7
+#define MPLS_DEC_BASEMSGERROR    -8
+#define MPLS_ENC_CSPERROR        -9
+#define MPLS_DEC_CSPERROR        -10
+#define MPLS_ENC_ASPERROR        -11
+#define MPLS_DEC_ASPERROR        -12
+#define MPLS_ENC_FSPERROR        -13
+#define MPLS_DEC_FSPERROR        -14
+#define MPLS_ENC_STATUSERROR     -16
+#define MPLS_DEC_STATUSERROR     -17
+#define MPLS_ENC_EXSTATERROR     -18
+#define MPLS_DEC_EXSTATERROR     -19
+#define MPLS_ENC_RETPDUERROR     -20
+#define MPLS_DEC_RETPDUERROR     -21
+#define MPLS_ENC_RETMSGERROR     -22
+#define MPLS_DEC_RETMSGERROR     -23
+#define MPLS_PDU_LENGTH_ERROR    -24
+#define MPLS_ENC_CHPERROR        -25
+#define MPLS_DEC_CHPERROR        -26
+#define MPLS_ENC_CSNERROR        -27
+#define MPLS_DEC_CSNERROR        -28
+#define MPLS_ENC_TRADRERROR      -29
+#define MPLS_DEC_TRADRERROR      -30
+#define MPLS_ENC_ADRLISTERROR    -31
+#define MPLS_DEC_ADRLISTERROR    -32
+#define MPLS_WC_FECERROR         -33
+#define MPLS_PATHVECTORERROR     -34
+#define MPLS_ENC_FECERROR        -35
+#define MPLS_DEC_FECERROR        -36
+#define MPLS_ENC_GENLBLERROR     -37
+#define MPLS_DEC_GENLBLERROR     -38
+#define MPLS_ENC_MAPATMERROR     -39
+#define MPLS_DEC_MAPATMERROR     -40
+#define MPLS_ENC_FRLBLERROR      -41
+#define MPLS_DEC_FRLBLERROR      -42
+#define MPLS_ENC_COSERROR        -43
+#define MPLS_DEC_COSERROR        -44
+#define MPLS_ENC_HOPCOUNTERROR   -45
+#define MPLS_DEC_HOPCOUNTERROR   -46
+#define MPLS_ENC_PATHVECERROR    -47
+#define MPLS_DEC_PATHVECERROR    -48
+#define MPLS_ENC_LBLMSGIDERROR   -49
+#define MPLS_DEC_LBLMSGIDERROR   -50
+#define MPLS_ENC_HDRTLVERROR     -51
+#define MPLS_DEC_HDRTLVERROR     -52
+#define MPLS_ENC_FECELEMERROR    -53
+#define MPLS_DEC_FECELEMERROR    -54
+#define MPLS_ENC_FSPLBLERROR     -55
+#define MPLS_DEC_FSPLBLERROR     -56
+#define MPLS_ENC_ERHOPERROR      -57
+#define MPLS_DEC_ERHOPERROR      -58
+#define MPLS_ENC_ERTLVERROR      -59
+#define MPLS_DEC_ERTLVERROR      -60
+#define MPLS_ENC_ERHOPLENERROR   -61
+#define MPLS_DEC_ERHOPLENERROR   -62
+#define MPLS_TLVTYPEERROR        -63
+#define MPLS_MSGTYPEERROR        -64
+#define MPLS_FECERROR            -65
+#define MPLS_ENC_TRAFFICERROR    -66
+#define MPLS_DEC_TRAFFICERROR    -67
+#define MPLS_ENC_LSPIDERROR      -68
+#define MPLS_DEC_LSPIDERROR      -69
+#define MPLS_ENC_RESCLSERROR     -70
+#define MPLS_DEC_RESCLSERROR     -71
+#define MPLS_ENC_PREEMPTERROR    -72
+#define MPLS_DEC_PREEMPTERROR    -73
+#define MPLS_ENC_PINNINGERROR    -74
+#define MPLS_DEC_PINNINGERROR    -75
+#define MPLS_FLOATTYPEERROR      -76
+#define MPLS_FECTLVERROR         -77
+#define MPLS_IPV4LENGTHERROR     -78
+#define MPLS_ER_HOPSNUMERROR     -79
+
+/**********************************************************************
+   LDP header 
+ 
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |  Version                      |         PDU Length            |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                         LDP Identifier                        |
+   +                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+**********************************************************************/
+
+typedef struct mplsLdpHeader_s {
+  u_short protocolVersion;
+  u_short pduLength;            /* length excluding the version and length */
+  u_int lsrAddress;             /* IP address assigned to LSR              */
+  u_short labelSpace;           /* within LSR                              */
+
+} mplsLdpHeader_t;
+
+/**********************************************************************
+   LDP Messages (All LDP messages have the following format:)
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Message Type              |      Message Length           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                                                               |
+   +                                                               +
+   |                     Mandatory Parameters                      |
+   +                                                               +
+   |                                                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                                                               |
+   +                                                               +
+   |                     Optional Parameters                       |
+   +                                                               +
+   |                                                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+Note: the U flag is ignored for now. There is not check for its value.
+**********************************************************************/
+
+typedef struct mplsLdpMsgFlag_s {
+  BITFIELDS_ASCENDING_2(u_short uBit:1, u_short msgType:15)
+} mplsLdpMsgFlag_t;
+
+typedef struct mplsLdpMsg_s {
+  union {
+    struct mplsLdpMsgFlag_s flags;
+    u_short mark;
+  } flags;
+
+  u_short msgLength;            /* msgId + mandatory param + optional param */
+  u_int msgId;                  /* used to identify the notification msg    */
+
+} mplsLdpMsg_t;
+
+typedef struct mplsLdpUnknownMsg_s {
+  struct mplsLdpMsg_s baseMsg;
+  u_char data[MPLS_NOT_MAXSIZE];
+
+} mplsLdpUnknownMsg_t;
+
+/**********************************************************************
+   Type-Length-Value Encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|F|        Type               |            Length             |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                                                               |
+   |                             Value                             |
+   ~                                                               ~
+   |                                                               |
+   |                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+Note: the decode functions for tlv do not check the values for
+      F flag. They check only the value of the U flag; if
+      it is set will ignore the tlv and keep processing the message;
+      otherwise will ignore the message and return error. Please note 
+      that the unknown tlv which is skipped will not be stored anywhere.
+**********************************************************************/
+
+typedef struct mplsLdpTlvFlag_s {
+  BITFIELDS_ASCENDING_3(u_short uBit:1, u_short fBit:1, u_short tBit:14)
+} mplsLdpTlvFlag_t;
+
+typedef struct mplsLdpTlv_s {
+  union {
+    struct mplsLdpTlvFlag_s flags;
+    u_short mark;
+  } flags;
+
+  u_short length;               /* length of the value field */
+
+} mplsLdpTlv_t;
+
+/**********************************************************************
+  Common Session Parameters TLV
+
+        0                   1                   2                   3
+        0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+       +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+       |U|F| Common Sess Parms (0x0500)|      Length                   |
+       +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+       | Protocol Version              |      Keep Alive Time          |
+       +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+       |A|D| Reserved  |     PVLim     |      Max PDU Length           |
+       +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+       |                 Receiver LDP Identifer                        |
+       +                               +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+       |                               |
+       -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-++
+***********************************************************************/
+
+typedef struct mplsLdpCspFlag_s {
+  BITFIELDS_ASCENDING_4(u_short lad:1, /* 1 = downstream on demand  */
+    u_short ld:1,               /* loop detection            */
+    u_short res:6,              /* reserved                  */
+    u_short pvl:8               /* path vec limit            */
+    )
+} mplsLdpCspFlag_t;
+
+typedef struct mplsLdpCspTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_short protocolVersion;
+  u_short holdTime;             /* proposed keep alive interval */
+
+  union {
+    struct mplsLdpCspFlag_s flags;
+    u_short mark;
+  } flags;
+
+  u_short maxPduLen;
+  u_int rcvLsrAddress;
+  u_short rcvLsId;
+
+} mplsLdpCspTlv_t;
+
+/*********************************************************************** 
+   ATM Label Range Component
+
+     0                   1                   2                   3
+     0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |  Res  |    Minimum VPI        |      Minimum VCI              |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |  Res  |    Maximum VPI        |      Maximum VCI              |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpAtmLblRngFlag_s {
+  BITFIELDS_ASCENDING_3(u_int res1:4, /* reserved : 0 on transmision */
+    u_int minVpi:12,            /* if <12 bits right justified */
+    u_int minVci:16             /* if <16 bits right justified */
+    )
+  BITFIELDS_ASCENDING_3(u_int res2:4, /* reserved : 0 on transmision */
+    u_int maxVpi:12,            /* if <12 bits right justified */
+    u_int maxVci:16             /* if <16 bits right justified */
+    )
+} mplsLdpAtmLblRngFlag_t;
+
+typedef struct mplsLdpAtmLblRng_s {
+  union {
+    struct mplsLdpAtmLblRngFlag_s flags;
+    u_int mark[2];
+  } flags;
+} mplsLdpAtmLblRng_t;
+
+/*********************************************************************** 
+ Flags for ATM Session Parameters TLV and 
+	   Frame Relay Session Parameters TLV
+
+ Note: both types of session parameters have the same type of flags;
+       use then the same struct
+***********************************************************************/
+
+typedef struct mplsLdpSPFlag_s {
+  BITFIELDS_ASCENDING_4(u_int mergeType:2, /* merge typ            */
+    u_int numLblRng:4,          /* # of label range com */
+    u_int dir:1,                /* 0 => bidirectional   */
+    u_int res:25)
+} mplsLdpSPFlag_t;
+
+/*********************************************************************** 
+   ATM Session Parameters TLV
+
+  0                   1                   2                   3
+  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  |U|F|   ATM Sess Parms (0x0501) |      Length                   |
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  | M |   N   |D|                        Reserved                 |
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  |                 ATM Label Range Component 1                   |
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  |                                                               |
+  ~                                                               ~
+  |                                                               |
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  |                 ATM Label Range Component N                   |
+  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpAspTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  union {
+    struct mplsLdpSPFlag_s flags;
+    u_int mark;
+  } flags;
+  struct mplsLdpAtmLblRng_s lblRngList[MPLS_ATMLBLMAXLEN];
+
+} mplsLdpAspTlv_t;
+
+/***********************************************************************
+   Frame Relay Label Range Component
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+    | Reserved    |Len|                     Minimum DLCI            |
+    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+    | Reserved        |                     Maximum DLCI            |
+    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpFrFlag_s {
+  BITFIELDS_ASCENDING_3(u_int res_min:7, u_int len:2, u_int minDlci:23)
+  BITFIELDS_ASCENDING_2(u_int res_max:9, u_int maxDlci:23)
+} mplsLdpFrFlag_t;
+
+typedef struct mplsLdpFrLblRng_s {
+  union {
+    struct mplsLdpFrFlag_s flags;
+    u_int mark[2];
+  } flags;
+
+} mplsLdpFrLblRng_t;
+
+/**********************************************************************
+   Frame Relay Session Parameters TLV
+
+     0                   1                   2                   3
+     0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F|   FR Sess Parms (0x0502)  |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     | M |   N   |D|                        Reserved                 |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |             Frame Relay Label Range Component 1               |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                                                               |
+     ~                                                               ~
+     |                                                               |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |             Frame Relay Label Range Component N               |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpFspTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  union {
+    struct mplsLdpSPFlag_s flags;
+    u_int mark;
+  } flags;
+  struct mplsLdpFrLblRng_s lblRngList[MPLS_FRLBLMAXLEN];
+
+} mplsLdpFspTlv_t;
+
+/***********************************************************************
+   Initialization Message Encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Initialization (0x0200)   |      Message Length           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Common Session Parameters TLV             |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Optional Parameters                       |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpInitMsg_s {
+  struct mplsLdpMsg_s baseMsg;
+  struct mplsLdpCspTlv_s csp;
+  struct mplsLdpAspTlv_s asp;
+  struct mplsLdpFspTlv_s fsp;
+  u_char cspExists:1;
+  u_char aspExists:1;
+  u_char fspExists:1;
+
+} mplsLdpInitMsg_t;
+
+/***********************************************************************
+   Status Code Encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |E|F|                 Status Data                               |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+typedef struct mplsLdpStautsFlag_s {
+  BITFIELDS_ASCENDING_3(u_int error:1, /* E bit */
+    u_int forward:1,            /* F bit */
+    u_int status:30)
+} mplsLdpStautsFlag_t;
+
+/***********************************************************************
+   Status (TLV) Encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|F| Status (0x0300)           |      Length                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Status Code                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |      Message Type             |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpStatusTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  union {
+    struct mplsLdpStautsFlag_s flags;
+    u_int mark;
+  } flags;
+  u_int msgId;
+  u_short msgType;
+
+} mplsLdpStatusTlv_t;
+
+/***********************************************************************
+   Extended Status (TLV) Encoding
+***********************************************************************/
+
+typedef struct mplsLdpExStatusTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_int value;                  /* additional info for status */
+
+} mplsLdpExStatusTlv_t;
+
+/***********************************************************************
+   Returned PDU (TLV) Encoding
+***********************************************************************/
+
+typedef struct mplsLdpRetPduTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  struct mplsLdpHeader_s headerTlv;
+  u_char data[MPLS_NOT_MAXSIZE];
+
+} mplsLdpRetPduTlv_t;
+
+/***********************************************************************
+   Returned MSG (TLV) Encoding
+***********************************************************************/
+
+typedef struct mplsLdpRetMsgTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_short msgType;
+  u_short msgLength;
+  u_char data[MPLS_NOT_MAXSIZE];
+
+} mplsLdpRetMsgTlv_t;
+
+/***********************************************************************
+   LSPID Tlv encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F|      LSPID-TLV  (0x0821)  |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |       Reserved                |      Local CRLSP ID           |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                       Ingress LSR Router ID                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpLspIdTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_short res;
+  u_short localCrlspId;
+  u_int routerId;               /* ingress lsr router id */
+
+} mplsLdpLspIdTlv_t;
+
+/***********************************************************************
+   Notification Message Encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Notification (0x0001)     |      Message Length           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Status (TLV)                              |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Optional Parameters                       |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     LSPID TLV (optional for CR-LDP)           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpNotifMsg_s {
+  struct mplsLdpMsg_s baseMsg;
+  struct mplsLdpStatusTlv_s status;
+  struct mplsLdpExStatusTlv_s exStatus; /* extended status tlv */
+  struct mplsLdpRetPduTlv_s retPdu; /* returned PDU tlv    */
+  struct mplsLdpRetMsgTlv_s retMsg; /* returned MSG tlv    */
+  struct mplsLdpLspIdTlv_s lspidTlv; /* lspid tlv           */
+
+  u_char statusTlvExists:1;
+  u_char exStatusTlvExists:1;
+  u_char retPduTlvExists:1;
+  u_char retMsgTlvExists:1;
+  u_char lspidTlvExists:1;
+
+} mplsLdpNotifMsg_t;
+
+/***********************************************************************
+   Common Hello Parameters Tlv encoding
+ 
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F| Common Hello Parms(0x0400)|      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |      Hold Time                |T|R| Reserved                  |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+typedef struct mplsLdpChpFlag_s {
+  BITFIELDS_ASCENDING_3(u_short target:1, /* T bit */
+    u_short request:1,          /* R bit */
+    u_short res:14)
+} mplsLdpChpFlag_t;
+
+typedef struct mplsLdpChpTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_short holdTime;
+  union {
+    struct mplsLdpChpFlag_s flags;
+    u_short mark;
+  } flags;
+
+} mplsLdpChpTlv_t;
+
+/***********************************************************************
+   Transport Address (TLV) Encoding
+***********************************************************************/
+
+typedef struct mplsLdpTrAdrTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_int address;
+
+} mplsLdpTrAdrTlv_t;
+
+/***********************************************************************
+   Configuration Sequence Number (TLV) Encoding
+***********************************************************************/
+
+typedef struct mplsLdpCsnTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_int seqNumber;
+
+} mplsLdpCsnTlv_t;
+
+/***********************************************************************
+     Hello message encoding 
+ 
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Hello (0x0100)            |      Message Length           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Common Hello Parameters TLV               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Optional Parameters                       |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpHelloMsg_s {
+  struct mplsLdpMsg_s baseMsg;
+  struct mplsLdpChpTlv_s chp;   /* common hello param tlv  */
+  struct mplsLdpTrAdrTlv_s trAdr; /* transport address tlv   */
+  struct mplsLdpCsnTlv_s csn;   /* configuration seq # tlv */
+  u_char chpTlvExists:1;
+  u_char trAdrTlvExists:1;
+  u_char csnTlvExists:1;
+
+} mplsLdpHelloMsg_t;
+
+/***********************************************************************
+   KeepAlive Message encoding
+ 
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   KeepAlive (0x0201)        |      Message Length           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Optional Parameters                       |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+
+Note: there are no optional param defined for keep alive.
+***********************************************************************/
+
+typedef struct mplsLdpKeepAlMsg_s {
+  struct mplsLdpMsg_s baseMsg;
+
+} mplsLdpKeepAlMsg_t;
+
+/***********************************************************************
+   Address List TLV encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|F| Address List (0x0101)     |      Length                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |     Address Family            |                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+                               |
+   |                                                               |
+   |                        Addresses                              |
+   ~                                                               ~
+   |                                                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpAdrTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_short addrFamily;
+  u_int address[MPLS_MAXNUMBERADR];
+
+} mplsLdpAdrTlv_t;
+
+/***********************************************************************
+   Address (0x0300) / Address Withdraw(0x0301)  message encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Address                   |      Message Length           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                                                               |
+   |                     Address List TLV                          |
+   |                                                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Optional Parameters                       |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+
+Note: there are no optional param defined for address message.
+***********************************************************************/
+
+typedef struct mplsLdpAdrMsg_s {
+  struct mplsLdpMsg_s baseMsg;
+  struct mplsLdpAdrTlv_s addressList;
+  u_char adrListTlvExists:1;
+
+} mplsLdpAdrMsg_t;
+
+/***********************************************************************
+   Wildcard FEC Element encoding
+***********************************************************************/
+
+typedef struct mplsLdpWildFec_s {
+  u_char type;
+
+} mplsLdpWildFec_t;
+
+/***********************************************************************
+   Prefix FEC Element encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |  Prefix (2)   |     Address Family            |     PreLen    |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                     Prefix                                    |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+
+   Host Address FEC Element encoding
+
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     | Host Addr (3) |     Address Family            | Host Addr Len |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                     Host Addr                                 |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+
+Note: the code handles prefixes and host addresses whose length is 
+      less or equal to 4 bytes.
+***********************************************************************/
+
+typedef struct mplsLdpAddressFec_s {
+  u_char type;
+  u_short addressFam;
+  u_char preLen;                /* prefix FEC: length of the adr prefix (in bits)
+                                   or host adr FEC: length of the host address (in 
+                                   bytes) */
+  u_int address;
+
+} mplsLdpAddressFec_t;
+
+/***********************************************************************
+   CRLSP FEC Element encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     | CR-LSP (4)    |          Reserved                             |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpCrlspFec_s {
+  u_char type;
+  u_char res1;                  /* reserved */
+  u_short res2;                 /* reserved */
+
+} mplsLdpCrlspFec_t;
+
+/***********************************************************************
+   FEC Tlv encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|F| FEC (0x0100)              |      Length                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                        FEC Element 1                          |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                                                               |
+   ~                                                               ~
+   |                                                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                        FEC Element n                          |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef union mplsFecElement_u {
+  struct mplsLdpAddressFec_s addressEl; /* prefix | host adr */
+  struct mplsLdpWildFec_s wildcardEl; /* for wilcard fec   */
+  struct mplsLdpCrlspFec_s crlspEl; /* CRLSP fec elem    */
+
+} mplsFecElement_t;
+
+typedef struct mplsLdpFecTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  union mplsFecElement_u fecElArray[MPLS_MAXNUMFECELEMENT];
+  u_short fecElemTypes[MPLS_MAXNUMFECELEMENT];
+  u_char wcElemExists:1;
+  u_short numberFecElements;
+
+} mplsLdpFecTlv_t;
+
+/***********************************************************************
+   Generic Label Tlv encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|F| Generic Label (0x0200)    |      Length                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |     Label                                                     |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpGenLblTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_int label;                  /* 20-bit number in 4 octet field */
+
+} mplsLdpGenLblTlv_t;
+
+/***********************************************************************
+   Atm Label Tlv encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|F| ATM Label (0x0201)        |         Length                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |Res| V |          VPI          |         VCI                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpAtmLblFlag_s {
+  BITFIELDS_ASCENDING_3(u_short res:2, u_short v:2, u_short vpi:12)
+} mplsLdpAtmLblFlag_t;
+
+typedef struct mplsLdpAtmLblTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+
+  union {
+    struct mplsLdpAtmLblFlag_s flags;
+    u_short mark;
+  } flags;
+
+  u_short vci;
+
+} mplsLdpAtmLblTlv_t;
+
+/***********************************************************************
+   Frame Relay Label Tlv encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|F| Frame Relay Label (0x0202)|       Length                  |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   | Reserved    |Len|                     DLCI                    |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpFrLblFlag_s {
+  BITFIELDS_ASCENDING_3(u_int res:7, u_int len:2, u_int dlci:23)
+
+} mplsLdpFrLblFlag_t;
+
+typedef struct mplsLdpFrLblTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+
+  union {
+    struct mplsLdpFrLblFlag_s flags;
+    u_int mark;
+  } flags;
+
+} mplsLdpFrLblTlv_t;
+
+/***********************************************************************
+   Hop Count Tlv encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|F| Hop Count (0x0103)        |      Length                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |     HC Value  |
+   +-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpHopTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_char hcValue;               /* hop count value */
+
+} mplsLdpHopTlv_t;
+
+/***********************************************************************
+   Path Vector Tlv encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|F| Path Vector (0x0104)      |        Length                 |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                            LSR Id 1                           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                                                               |
+   ~                                                               ~
+   |                                                               |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                            LSR Id n                           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpPathTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_int lsrId[MPLS_MAXHOPSNUMBER];
+
+} mplsLdpPathTlv_t;
+
+/***********************************************************************
+   Lbl request message id Tlv encoding
+***********************************************************************/
+
+typedef struct mplsLdpLblMsgIdTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_int msgId;
+
+} mplsLdpLblMsgIdTlv_t;
+
+/***********************************************************************
+   Preemption Tlv encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F| Preemption-TLV  (0x0820)  |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |  SetPrio      | HoldPrio      |      Reserved                 |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpPreemptTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_char setPrio;               /* 0 => most important path */
+  u_char holdPrio;              /* 0 => most important path */
+  u_short res;
+
+} mplsLdpPreemptTlv_t;
+
+/***********************************************************************
+   Resource class Tlv encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F|      ResCls-TLV  (0x0822) |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                             RsCls                             |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpResClsTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  u_int rsCls;                  /* resource class bit mask */
+
+} mplsLdpResClsTlv_t;
+
+/***********************************************************************
+   Lbl return message id Tlv encoding
+***********************************************************************/
+
+typedef struct mplsLdpRetMsgIdTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+
+} mplsLdpLblRetMsgIdTlv_t;
+
+/***********************************************************************
+   ER flag structure which is common to IPV4 and IPV6 ER TLV
+***********************************************************************/
+
+typedef struct mplsLdpErIPFlag_s {
+  BITFIELDS_ASCENDING_3(u_int l:1, /* 0 => loose hop */
+    u_int res:23, u_int preLen:8)
+} mplsLdpErIPFlag_t;
+
+/***********************************************************************
+   ER flag structure which is common to AS and LSPID ER TLV
+***********************************************************************/
+typedef struct mplsLdpErFlag_s {
+  BITFIELDS_ASCENDING_2(u_short l:1, /* 0 => loose hop */
+    u_short res:15)
+} mplsLdpErFlag_t;
+
+/***********************************************************************
+   Explicit Routing IPv4 Tlv encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F|         0x801             |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |L|      Reserved                               |    PreLen     |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                    IPv4 Address (4 bytes)                     |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpErIpv4_s {
+  struct mplsLdpTlv_s baseTlv;
+  union {
+    struct mplsLdpErIPFlag_s flags;
+    u_int mark;
+  } flags;
+  u_int address;
+
+} mplsLdpErIpv4_t;
+
+/***********************************************************************
+   Explicit Routing IPv6 Tlv encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F|          0x802            |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |L|             Reserved                        |    PreLen     |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                  IPV6 address                                 |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                  IPV6 address (continued)                     |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                  IPV6 address (continued)                     |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                  IPV6 address (continued)                     |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpErIpv6_s {
+  struct mplsLdpTlv_s baseTlv;
+  union {
+    struct mplsLdpErIPFlag_s flags;
+    u_int mark;
+  } flags;
+  u_char address[MPLS_IPV6ADRLENGTH];
+
+} mplsLdpErIpv6_t;
+
+/***********************************************************************
+   Explicit Routing Autonomous systen number Tlv encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F|          0x803            |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |L|          Reserved           |                AS Number      |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpErAs_s {
+  struct mplsLdpTlv_s baseTlv;
+  union {
+    struct mplsLdpErFlag_s flags;
+    u_short mark;
+  } flags;
+  u_short asNumber;
+
+} mplsLdpErAs_t;
+
+/***********************************************************************
+   Explicit Routing LSPID Tlv encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F|          0x804            |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |L|          Reserved           |               Local LSPID     |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                       Ingress LSR Router ID                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpErLspId_s {
+  struct mplsLdpTlv_s baseTlv;
+  union {
+    struct mplsLdpErFlag_s flags;
+    u_short mark;
+  } flags;
+  u_short lspid;
+  u_int routerId;
+
+} mplsLdpErLspId_t;
+
+/***********************************************************************
+   Constraint Routing Tlv encoding
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F|         ER-TLV  (0x0800)  |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                          ER-Hop TLV 1                         |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                          ER-Hop TLV 2                         |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     ~                          ............                         ~
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                          ER-Hop TLV n                         |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef union mplsLdpErHop_u {
+  struct mplsLdpErIpv4_s erIpv4;
+  struct mplsLdpErIpv6_s erIpv6;
+  struct mplsLdpErAs_s erAs;
+  struct mplsLdpErLspId_s erLspId;
+
+} mplsLdpErHop_t;
+
+typedef struct mplsLdpErTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  union mplsLdpErHop_u erHopArray[MPLS_MAX_ER_HOPS];
+  u_short erHopTypes[MPLS_MAX_ER_HOPS]; /* need to know the 
+                                           types when handle
+                                           the union */
+  u_short numberErHops;
+
+} mplsLdpErTlv_t;
+
+/***********************************************************************
+   Traffic parameters TLV
+
+      0                   1                   2                   3
+     0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F| Traf. Param. TLV  (0x0810)|      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |     Flags     |    Frequency  |     Reserved  |    Weight     |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                    Peak Data Rate (PDR)                       |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                    Peak Burst Size (PBS)                      |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                    Committed Data Rate (CDR)                  |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                    Committed Burst Size (CBS)                 |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |                    Excess Burst Size (EBS)                    |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+
+    Flag field:
+     +--+--+--+--+--+--+--+--+
+     | Res |F6|F5|F4|F3|F2|F1|
+     +--+--+--+--+--+--+--+--+
+***********************************************************************/
+
+typedef struct mplsLdpTrafficFlag_s {
+  BITFIELDS_ASCENDING_7(u_char res:2,
+    u_char f6Bit:1,
+    u_char f5Bit:1,
+    u_char f4Bit:1, u_char f3Bit:1, u_char f2Bit:1, u_char f1Bit:1)
+} mplsLdpTrafficFlag_t;
+
+typedef struct mplsLdpTrafficTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  union {
+    struct mplsLdpTrafficFlag_s flags;
+    u_char mark;
+  } flags;
+  u_char freq;
+  u_char res;
+  u_char weight;
+  union {
+    float pdr;
+    u_int mark;
+  } pdr;
+  union {
+    float pbs;
+    u_int mark;
+  } pbs;
+  union {
+    float cdr;
+    u_int mark;
+  } cdr;
+  union {
+    float cbs;
+    u_int mark;
+  } cbs;
+  union {
+    float ebs;
+    u_int mark;
+  } ebs;
+
+} mplsLdpTrafficTlv_t;
+
+/***********************************************************************
+   Route pinning TLV
+
+      0                   1                   2                   3
+      0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |U|F|          0x823            |      Length                   |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+     |P|                        Reserved                             |
+     +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpPinningTlvFlag_s {
+  BITFIELDS_ASCENDING_2(u_int pBit:1, /* 1 => route pinning requested */
+    u_int res:31)
+} mplsLdpPinningTlvFlag_t;
+
+typedef struct mplsLdpPinningTlv_s {
+  struct mplsLdpTlv_s baseTlv;
+  union {
+    struct mplsLdpPinningTlvFlag_s flags;
+    u_int mark;
+  } flags;
+} mplsLdpPinningTlv_t;
+
+/***********************************************************************
+   Label Mapping Message encoding
+ 
+   0                   1                   2                   3
+   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Label Mapping (0x0400)   |      Message Length            |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     FEC TLV                                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Label TLV                                 |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |              Label Request Message ID TLV  (mandatory)        |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     LSPID TLV            (CR-LDP, mandatory)  |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Traffic  TLV         (CR-LDP, optional)   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpLblMapMsg_s {
+  struct mplsLdpMsg_s baseMsg;
+
+  /* FEC tlv */
+  struct mplsLdpFecTlv_s fecTlv;
+
+  /* Label TLV */
+  struct mplsLdpGenLblTlv_s genLblTlv; /* generic label tlv */
+  struct mplsLdpAtmLblTlv_s atmLblTlv; /* atm label tlv     */
+  struct mplsLdpFrLblTlv_s frLblTlv; /* fr label tlv      */
+
+  /* Optional parameters */
+  struct mplsLdpHopTlv_s hopCountTlv; /* hop count tlv     */
+  struct mplsLdpPathTlv_s pathVecTlv; /* path vector tlv   */
+  struct mplsLdpLblMsgIdTlv_s lblMsgIdTlv; /* lbl msg id tlv    */
+  struct mplsLdpLspIdTlv_s lspidTlv; /* lspid tlv         */
+  struct mplsLdpTrafficTlv_s trafficTlv; /* traffic tlv       */
+
+  u_char fecTlvExists:1;
+  u_char genLblTlvExists:1;
+  u_char atmLblTlvExists:1;
+  u_char frLblTlvExists:1;
+  u_char hopCountTlvExists:1;
+  u_char pathVecTlvExists:1;
+  u_char lblMsgIdTlvExists:1;
+  u_char lspidTlvExists:1;
+  u_char trafficTlvExists:1;
+
+} mplsLdpLblMapMsg_t;
+
+/***********************************************************************
+   Label Request Message encoding
+
+   0                   1                   2                   3
+   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Label Request (0x0401)   |      Message Length            |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     FEC TLV                                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Return Message ID TLV  (mandatory)        |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     LSPID TLV            (CR-LDP, mandatory)  |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     ER-TLV               (CR-LDP, optional)   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Traffic  TLV         (CR-LDP, optional)   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Pinning TLV          (CR-LDP, optional)   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Resource Class TLV (CR-LDP, optional)     |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Pre-emption  TLV     (CR-LDP, optional)   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpLblReqMsg_s {
+  struct mplsLdpMsg_s baseMsg;
+
+  /* FEC tlv */
+  struct mplsLdpFecTlv_s fecTlv;
+
+  /* Optional parameters */
+  struct mplsLdpHopTlv_s hopCountTlv; /* hop count tlv     */
+  struct mplsLdpPathTlv_s pathVecTlv; /* path vector tlv   */
+
+  /* Optional parameters for CR */
+  struct mplsLdpRetMsgIdTlv_s lblMsgIdTlv; /* lbl msg id tlv    */
+  struct mplsLdpErTlv_s erTlv;  /* constraint rtg tlv */
+  struct mplsLdpTrafficTlv_s trafficTlv; /* traffic tlv       */
+  struct mplsLdpLspIdTlv_s lspidTlv; /* lspid tlv         */
+  struct mplsLdpPinningTlv_s pinningTlv; /* pinning tlv       */
+  struct mplsLdpResClsTlv_s resClassTlv; /* resource class tlv */
+  struct mplsLdpPreemptTlv_s preemptTlv; /* peemtion tlv      */
+
+  u_char fecTlvExists:1;
+  u_char hopCountTlvExists:1;
+  u_char pathVecTlvExists:1;
+  u_char lblMsgIdTlvExists:1;
+  u_char erTlvExists:1;
+  u_char trafficTlvExists:1;
+  u_char lspidTlvExists:1;
+  u_char pinningTlvExists:1;
+  u_char recClassTlvExists:1;
+  u_char preemptTlvExists:1;
+
+} mplsLdpLblReqMsg_t;
+
+/***********************************************************************
+
+   Label Withdraw Message encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Label Withdraw (0x0402)   |      Message Length           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     FEC TLV                                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Label TLV (optional)                      |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     LSPID TLV (optional for CR-LDP)           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+
+   Label Release Message encoding
+
+    0                   1                   2                   3
+    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Label Release (0x0403)   |      Message Length            |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     FEC TLV                                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Label TLV (optional)                      |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     LSPID TLV (optional for CR-LDP)           |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ 
+Note: the Label Withdraw Message encoding and the Label Release Message enc
+      look very much the same. I will create only one type of struct for 
+      both message types.
+      The Label Withdraw Message and Label Release Message can optionally
+      carry LSPID TLV.
+***********************************************************************/
+
+typedef struct mplsLdpLbl_W_R_Msg_s {
+  struct mplsLdpMsg_s baseMsg;
+
+  /* FEC tlv */
+  struct mplsLdpFecTlv_s fecTlv;
+
+  /* Label TLV */
+  struct mplsLdpGenLblTlv_s genLblTlv; /* generic label tlv */
+  struct mplsLdpAtmLblTlv_s atmLblTlv; /* atm label tlv     */
+  struct mplsLdpFrLblTlv_s frLblTlv; /* fr label tlv      */
+  struct mplsLdpLspIdTlv_s lspidTlv; /* lspid tlv         */
+
+  u_char fecTlvExists:1;
+  u_char genLblTlvExists:1;
+  u_char atmLblTlvExists:1;
+  u_char frLblTlvExists:1;
+  u_char lspidTlvExists:1;
+
+} mplsLdpLbl_W_R_Msg_t;
+
+/***********************************************************************
+   Label Abort Request Message encoding
+ 
+   0                   1                   2                   3
+   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |U|   Label Abort Req (0x0404) |      Message Length            |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     Message ID                                |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |                     FEC TLV                                   |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+   |              Label Request Message ID TLV                     |
+   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+***********************************************************************/
+
+typedef struct mplsLdpLblAbortMsg_s {
+  struct mplsLdpMsg_s baseMsg;
+
+  struct mplsLdpFecTlv_s fecTlv; /* fec tlv        */
+  struct mplsLdpLblMsgIdTlv_s lblMsgIdTlv; /* lbl msg id tlv */
+
+  u_char fecTlvExists:1;
+  u_char lblMsgIdTlvExists:1;
+
+} mplsLdpLblAbortMsg_t;
+
+/***********************************************************************
+ *
+ *          Function declarations
+ *
+ *  Note: Encode functions return the length of the data which was encoded. 
+ *        The first argument (which is a pointer to the structure which
+ *        contains the data to be encoded) is not modified in the encode functions
+ *        which encode the messages and message headers. All the other encode 
+ *        fuctions modify the content of the structures to be encoded (tlvs, 
+ *        message parameters, etc). 
+ *
+ *	  Decode functions for tlv return the length of the value. 
+ */
+
+int Mpls_encodeLdpMsgHeader(mplsLdpHeader_t *, u_char *, int);
+int Mpls_decodeLdpMsgHeader(mplsLdpHeader_t *, u_char *, int);
+int Mpls_encodeLdpAtmLblRng(mplsLdpAtmLblRng_t *, u_char *, int);
+int Mpls_decodeLdpAtmLblRng(mplsLdpAtmLblRng_t *, u_char *, int);
+int Mpls_encodeLdpAsp(mplsLdpAspTlv_t *, u_char *, int);
+int Mpls_decodeLdpAsp(mplsLdpAspTlv_t *, u_char *, int);
+int Mpls_encodeLdpTlv(mplsLdpTlv_t *, u_char *, int);
+int Mpls_decodeLdpTlv(mplsLdpTlv_t *, u_char *, int);
+int Mpls_encodeLdpInitMsg(mplsLdpInitMsg_t *, u_char *, int);
+int Mpls_decodeLdpInitMsg(mplsLdpInitMsg_t *, u_char *, int);
+int Mpls_encodeLdpCsp(mplsLdpCspTlv_t *, u_char *, int);
+int Mpls_decodeLdpCsp(mplsLdpCspTlv_t *, u_char *, int);
+int Mpls_encodeLdpBaseMsg(mplsLdpMsg_t *, u_char *, int);
+int Mpls_decodeLdpBaseMsg(mplsLdpMsg_t *, u_char *, int);
+int Mpls_encodeLdpFrLblRng(mplsLdpFrLblRng_t *, u_char *, int);
+int Mpls_decodeLdpFrLblRng(mplsLdpFrLblRng_t *, u_char *, int);
+int Mpls_encodeLdpFsp(mplsLdpFspTlv_t *, u_char *, int);
+int Mpls_decodeLdpFsp(mplsLdpFspTlv_t *, u_char *, int);
+int Mpls_encodeLdpNotMsg(mplsLdpNotifMsg_t *, u_char *, int);
+int Mpls_decodeLdpNotMsg(mplsLdpNotifMsg_t *, u_char *, int);
+int Mpls_encodeLdpStatus(mplsLdpStatusTlv_t *, u_char *, int);
+int Mpls_decodeLdpStatus(mplsLdpStatusTlv_t *, u_char *, int);
+int Mpls_encodeLdpExStatus(mplsLdpExStatusTlv_t *, u_char *, int);
+int Mpls_decodeLdpExStatus(mplsLdpExStatusTlv_t *, u_char *, int);
+int Mpls_encodeLdpRetPdu(mplsLdpRetPduTlv_t *, u_char *, int);
+int Mpls_decodeLdpRetPdu(mplsLdpRetPduTlv_t *, u_char *, int, u_short);
+int Mpls_encodeLdpRetMsg(mplsLdpRetMsgTlv_t *, u_char *, int);
+int Mpls_decodeLdpRetMsg(mplsLdpRetMsgTlv_t *, u_char *, int, u_short);
+int Mpls_encodeLdpHelloMsg(mplsLdpHelloMsg_t *, u_char *, int);
+int Mpls_decodeLdpHelloMsg(mplsLdpHelloMsg_t *, u_char *, int);
+int Mpls_encodeLdpChp(mplsLdpChpTlv_t *, u_char *, int);
+int Mpls_decodeLdpChp(mplsLdpChpTlv_t *, u_char *, int);
+int Mpls_encodeLdpCsn(mplsLdpCsnTlv_t *, u_char *, int);
+int Mpls_decodeLdpCsn(mplsLdpCsnTlv_t *, u_char *, int);
+int Mpls_encodeLdpTrAdr(mplsLdpTrAdrTlv_t *, u_char *, int);
+int Mpls_decodeLdpTrAdr(mplsLdpTrAdrTlv_t *, u_char *, int);
+int Mpls_encodeLdpKeepAliveMsg(mplsLdpKeepAlMsg_t *, u_char *, int);
+int Mpls_decodeLdpKeepAliveMsg(mplsLdpKeepAlMsg_t *, u_char *, int);
+int Mpls_encodeLdpAdrTlv(mplsLdpAdrTlv_t *, u_char *, int);
+int Mpls_decodeLdpAdrTlv(mplsLdpAdrTlv_t *, u_char *, int, u_short);
+int Mpls_encodeLdpAdrMsg(mplsLdpAdrMsg_t *, u_char *, int);
+int Mpls_decodeLdpAdrMsg(mplsLdpAdrMsg_t *, u_char *, int);
+int Mpls_encodeLdpFecTlv(mplsLdpFecTlv_t *, u_char *, int);
+int Mpls_decodeLdpFecTlv(mplsLdpFecTlv_t *, u_char *, int, u_short);
+int Mpls_encodeLdpGenLblTlv(mplsLdpGenLblTlv_t *, u_char *, int);
+int Mpls_decodeLdpGenLblTlv(mplsLdpGenLblTlv_t *, u_char *, int);
+int Mpls_encodeLdpAtmLblTlv(mplsLdpAtmLblTlv_t *, u_char *, int);
+int Mpls_decodeLdpAtmLblTlv(mplsLdpAtmLblTlv_t *, u_char *, int);
+int Mpls_encodeLdpFrLblTlv(mplsLdpFrLblTlv_t *, u_char *, int);
+int Mpls_decodeLdpFrLblTlv(mplsLdpFrLblTlv_t *, u_char *, int);
+int Mpls_encodeLdpHopTlv(mplsLdpHopTlv_t *, u_char *, int);
+int Mpls_decodeLdpHopTlv(mplsLdpHopTlv_t *, u_char *, int);
+int Mpls_encodeLdpLblMsgIdTlv(mplsLdpLblMsgIdTlv_t *, u_char *, int);
+int Mpls_decodeLdpLblMsgIdTlv(mplsLdpLblMsgIdTlv_t *, u_char *, int);
+int Mpls_encodeLdpPathVectorTlv(mplsLdpPathTlv_t *, u_char *, int);
+int Mpls_decodeLdpPathVectorTlv(mplsLdpPathTlv_t *, u_char *, int, u_short);
+int Mpls_encodeLdpLblMapMsg(mplsLdpLblMapMsg_t *, u_char *, int);
+int Mpls_decodeLdpLblMapMsg(mplsLdpLblMapMsg_t *, u_char *, int);
+int Mpls_encodeLdpFecAdrEl(mplsFecElement_t *, u_char *, int, u_char);
+int Mpls_decodeLdpFecAdrEl(mplsFecElement_t *, u_char *, int, u_char);
+int Mpls_encodeLdpLblRetMsgIdTlv(mplsLdpLblRetMsgIdTlv_t *, u_char *, int);
+int Mpls_decodeLdpLblRetMsgIdTlv(mplsLdpLblRetMsgIdTlv_t *, u_char *, int);
+int Mpls_encodeLdpLbl_W_R_Msg(mplsLdpLbl_W_R_Msg_t *, u_char *, int);
+int Mpls_decodeLdpLbl_W_R_Msg(mplsLdpLbl_W_R_Msg_t *, u_char *, int);
+int Mpls_encodeLdpERTlv(mplsLdpErTlv_t *, u_char *, int);
+int Mpls_decodeLdpERTlv(mplsLdpErTlv_t *, u_char *, int, u_short);
+int Mpls_encodeLdpErHop(mplsLdpErHop_t *, u_char *, int, u_short);
+int Mpls_decodeLdpErHop(mplsLdpErHop_t *, u_char *, int, u_short *);
+int Mpls_encodeLdpTrafficTlv(mplsLdpTrafficTlv_t *, u_char *, int);
+int Mpls_decodeLdpTrafficTlv(mplsLdpTrafficTlv_t *, u_char *, int, u_short);
+int Mpls_encodeLdpLblReqMsg(mplsLdpLblReqMsg_t *, u_char *, int);
+int Mpls_decodeLdpLblReqMsg(mplsLdpLblReqMsg_t *, u_char *, int);
+int Mpls_encodeLdpPreemptTlv(mplsLdpPreemptTlv_t *, u_char *, int);
+int Mpls_decodeLdpPreemptTlv(mplsLdpPreemptTlv_t *, u_char *, int);
+int Mpls_encodeLdpLspIdTlv(mplsLdpLspIdTlv_t *, u_char *, int);
+int Mpls_decodeLdpLspIdTlv(mplsLdpLspIdTlv_t *, u_char *, int);
+int Mpls_encodeLdpResClsTlv(mplsLdpResClsTlv_t *, u_char *, int);
+int Mpls_decodeLdpResClsTlv(mplsLdpResClsTlv_t *, u_char *, int);
+int Mpls_encodeLdpPinningTlv(mplsLdpPinningTlv_t *, u_char *, int);
+int Mpls_decodeLdpPinningTlv(mplsLdpPinningTlv_t *, u_char *, int);
+int Mpls_encodeLdpLblAbortMsg(mplsLdpLblAbortMsg_t *, u_char *, int);
+int Mpls_decodeLdpLblAbortMsg(mplsLdpLblAbortMsg_t *, u_char *, int);
+
+/*
+ *   DEBUG function declarations
+ */
+
+void printTlv(mpls_instance_handle handle, mplsLdpTlv_t *);
+void printHeader(mpls_instance_handle handle, mplsLdpHeader_t *);
+void printCspFlags(mpls_instance_handle handle, mplsLdpCspFlag_t *);
+void printCspFlagsPerByte(mpls_instance_handle handle, u_short *);
+void printCspTlv(mpls_instance_handle handle, mplsLdpCspTlv_t *);
+void printAspFlags(mpls_instance_handle handle, mplsLdpSPFlag_t *);
+void printAspFlagsPerByte(mpls_instance_handle handle, u_int *);
+void printAspTlv(mpls_instance_handle handle, mplsLdpAspTlv_t *);
+void printFspFlags(mpls_instance_handle handle, mplsLdpSPFlag_t *);
+void printFspTlv(mpls_instance_handle handle, mplsLdpFspTlv_t *);
+void printRetMsgTlv(mpls_instance_handle handle, mplsLdpRetMsgTlv_t *);
+void printRetPduTlv(mpls_instance_handle handle, mplsLdpRetPduTlv_t *);
+void printExStatusTlv(mpls_instance_handle handle, mplsLdpExStatusTlv_t *);
+void printStatusTlv(mpls_instance_handle handle, mplsLdpStatusTlv_t *);
+void printCsnTlv(mpls_instance_handle handle, mplsLdpCsnTlv_t *);
+void printTrAdrTlv(mpls_instance_handle handle, mplsLdpTrAdrTlv_t *);
+void printChpTlv(mpls_instance_handle handle, mplsLdpChpTlv_t *);
+void printAdrListTlv(mpls_instance_handle handle, mplsLdpAdrTlv_t *);
+void printFecListTlv(mpls_instance_handle handle, mplsLdpFecTlv_t *);
+void printLblMsgIdTlv(mpls_instance_handle handle, mplsLdpLblMsgIdTlv_t *);
+void printPathVecTlv(mpls_instance_handle handle, mplsLdpPathTlv_t *);
+void printHopTlv(mpls_instance_handle handle, mplsLdpHopTlv_t *);
+void printFrLblTlv(mpls_instance_handle handle, mplsLdpFrLblTlv_t *);
+void printAtmLblTlv(mpls_instance_handle handle, mplsLdpAtmLblTlv_t *);
+void printGenLblTlv(mpls_instance_handle handle, mplsLdpGenLblTlv_t *);
+void printErFlags(mpls_instance_handle handle, mplsLdpErFlag_t *);
+void printErIPFlags(mpls_instance_handle handle, mplsLdpErIPFlag_t *);
+void printErTlv(mpls_instance_handle handle, mplsLdpErTlv_t *);
+void printTrafficTlv(mpls_instance_handle handle, mplsLdpTrafficTlv_t *);
+void printAtmLabel(mpls_instance_handle handle, mplsLdpAtmLblRng_t *, int);
+void printFspLabel(mpls_instance_handle handle, mplsLdpFrLblRng_t *, int);
+void printErHop(mpls_instance_handle handle, mplsLdpErHop_t *, u_short);
+void printPreemptTlv(mpls_instance_handle handle, mplsLdpPreemptTlv_t *);
+void printLspIdTlv(mpls_instance_handle handle, mplsLdpLspIdTlv_t *);
+void printResClsTlv(mpls_instance_handle handle, mplsLdpResClsTlv_t *);
+void printPinningTlv(mpls_instance_handle handle, mplsLdpPinningTlv_t *);
+
+void printInitMsg(mpls_instance_handle handle, mplsLdpInitMsg_t *);
+void printHelloMsg(mpls_instance_handle handle, mplsLdpHelloMsg_t *);
+void printNotMsg(mpls_instance_handle handle, mplsLdpNotifMsg_t *);
+void printKeepAliveMsg(mpls_instance_handle handle, mplsLdpKeepAlMsg_t *);
+void printAddressMsg(mpls_instance_handle handle, mplsLdpAdrMsg_t *);
+void printLlbMapMsg(mpls_instance_handle handle, mplsLdpLblMapMsg_t *);
+void printLlbReqMsg(mpls_instance_handle handle, mplsLdpLblReqMsg_t *);
+void printLbl_W_R_Msg(mpls_instance_handle handle, mplsLdpLbl_W_R_Msg_t *);
+void printLlbAbortMsg(mpls_instance_handle handle, mplsLdpLblAbortMsg_t *);
+
+int converAsciiToHex(u_char *, int, u_char *);
+int converHexToAscii(u_char *, int, u_char *);
+
+#endif /* _LDP_MPLS_H_ */
diff -Naur quagga-0.99.10/ldpd/ldp_notif.c quagga-mpls/ldpd/ldp_notif.c
--- quagga-0.99.10/ldpd/ldp_notif.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_notif.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,375 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_notif.h"
+#include "ldp_attr.h"
+#include "ldp_session.h"
+#include "ldp_nexthop.h"
+#include "ldp_entity.h"
+#include "ldp_mesg.h"
+#include "ldp_pdu_setup.h"
+#include "ldp_label_request.h"
+#include "ldp_label_mapping.h"
+#include "ldp_fec.h"
+
+#include "mpls_trace_impl.h"
+#include "mpls_timer_impl.h"
+
+void ldp_notif_prepare_msg(ldp_mesg * msg, uint32_t msgid, ldp_attr * r_attr,
+  ldp_notif_status status)
+{
+  mplsLdpNotifMsg_t *notif = NULL;
+  int error, forward = 0;
+  uint32_t msg_type = 0;
+  uint32_t msg_id = 0;
+
+  ldp_mesg_prepare(msg, MPLS_NOT_MSGTYPE, msgid);
+  notif = &msg->u.notif;
+
+  notif->statusTlvExists = 1;
+
+  /* we have to pass two more parameters one is F bit and other is E bit
+     E = 1 if it is a fatal error, 0 is for advisory notification
+     F = 1 then notification has to be forwarded. */
+
+  /* check to set the E bit */
+  if (status == LDP_NOTIF_SUCCESS ||
+    status == LDP_NOTIF_UNKNOWN_MESG ||
+    status == LDP_NOTIF_UNKNOWN_TVL ||
+    status == LDP_NOTIF_LOOP_DETECTED ||
+    status == LDP_NOTIF_UNKNOWN_FEC ||
+    status == LDP_NOTIF_NO_ROUTE ||
+    status == LDP_NOTIF_NO_LABEL_RESOURCES_AVAILABLE ||
+    status == LDP_NOTIF_LABEL_RESOURCES_AVAILABLE ||
+    status == LDP_NOTIF_LABEL_ABORT ||
+    status == LDP_NOTIF_MISSING_MSG_PARAMS || status == LDP_NOTIF_UNSUPORTED_AF) {
+    error = 0;
+  } else {
+    error = 1;
+  }
+
+  /* check to set the F bit */
+  if (status == LDP_NOTIF_LOOP_DETECTED ||
+    status == LDP_NOTIF_UNKNOWN_FEC || status == LDP_NOTIF_NO_ROUTE) {
+    forward = 1;
+  } else {
+    forward = 0;
+  }
+
+  if (r_attr) {
+    switch (r_attr->state) {
+      case LDP_LSP_STATE_ABORT_RECV:
+        msg_type = MPLS_LBLABORT_MSGTYPE;
+	msg_id = r_attr->msg_id;
+        break;
+      default:
+        msg_type = 0;
+    }
+  }
+  notif->baseMsg.msgLength += setupStatusTlv(&notif->status, error, forward,
+    status, msg_id, msg_type);
+
+  /* We have to insert other tlv's like retpdu,extended status, returned
+     message 
+     notif->exStatusTlvExists = 1;
+     notif->retPduTlvExists = 1;
+   */
+}
+
+mpls_return_enum ldp_notif_send(ldp_global * g, ldp_session * s,
+  ldp_attr * r_attr, ldp_notif_status status)
+{
+  LDP_ENTER(g->user_data, "ldp_notif_send");
+
+  ldp_notif_prepare_msg(s->tx_message, g->message_identifier++, r_attr, status);
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_LABEL,
+    "Notification Sent(%d)\n", s->index);
+
+  if (ldp_mesg_send_tcp(g, s, s->tx_message) == MPLS_FAILURE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_SEND, LDP_TRACE_FLAG_ERROR,
+      "Notification Send failed\n");
+    goto ldp_notif_send_error;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_notif_send");
+  return MPLS_SUCCESS;
+
+ldp_notif_send_error:
+
+  LDP_EXIT(g->user_data, "ldp_notif_send_error");
+  return MPLS_FAILURE;
+}
+
+void not2attr(mplsLdpNotifMsg_t * not, ldp_attr * attr, uint32_t flag)
+{
+  attr->msg_id = not->baseMsg.msgId;
+
+  if (not->statusTlvExists && flag & LDP_ATTR_STATUS) {
+    memcpy(&attr->statusTlv, &not->status, sizeof(mplsLdpStatusTlv_t));
+    attr->statusTlvExists = 1;
+  }
+  if (not->lspidTlvExists && flag & LDP_ATTR_LSPID) {
+    memcpy(&attr->lspidTlv, &not->lspidTlv, sizeof(mplsLdpLspIdTlv_t));
+    attr->lspidTlvExists = 1;
+  }
+
+  if (not->retMsgTlvExists && flag & LDP_ATTR_MSGID) {
+    memcpy(&attr->retMsgTlv, &not->retMsg, sizeof(mplsLdpLblMsgIdTlv_t));
+    attr->retMsgTlvExists = 1;
+  }
+  /* Attribute types are not defined in ldp_attr.h file need to 
+     define these optional Tlv types */
+
+  /*if(not->exStatusTlvExists && flag & LDP_ATTR_HOPCOUNT) {
+     memcpy(&attr->exStatus,&not->exStatus,sizeof(mplsLdpHopTlv_t));
+     attr->exStatusTlvExists = 1;
+     }
+     if(not->retPduTlvExists && flag & LDP_ATTR_PATH) {
+     memcpy(&attr->retPdu,&not->retPdu,sizeof(mplsLdpPathTlv_t));
+     attr->retPduTlvExists = 1;
+     } */
+}
+
+mpls_return_enum ldp_notif_process(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, ldp_attr * r_attr)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+  int status;
+
+  LDP_ENTER(g->user_data, "ldp_notif_process");
+
+  status = r_attr->statusTlv.flags.flags.status;
+
+  switch (status) {
+    case LDP_NOTIF_LABEL_ABORT:
+      retval = ldp_notif_label_request_aborted(g, s, r_attr);
+      break;
+    case LDP_NOTIF_NO_LABEL_RESOURCES_AVAILABLE:
+      retval = ldp_notif_no_label_resources(g, s, r_attr);
+      break;
+    case LDP_NOTIF_NO_ROUTE:
+    case LDP_NOTIF_LOOP_DETECTED:
+      retval = ldp_notif_no_route(g, s, e, r_attr);
+      break;
+    case LDP_NOTIF_LABEL_RESOURCES_AVAILABLE:
+      retval = ldp_notif_label_resources_available(g, s, r_attr);
+      break;
+    case LDP_NOTIF_SUCCESS:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_SUCCESS:\n");
+      break;
+    case LDP_NOTIF_BAD_LDP_ID:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_BAD_LDP_ID:\n");
+      break;
+    case LDP_NOTIF_BAD_PROTO:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_BAD_PROTO:\n");
+      break;
+    case LDP_NOTIF_BAD_PDU_LEN:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_BAD_PDU_LEN:\n");
+      break;
+    case LDP_NOTIF_UNKNOWN_MESG:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_UNKNOWN_MESG:\n");
+      break;
+    case LDP_NOTIF_BAD_MESG_LEN:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_BAD_MESG_LEN:\n");
+      break;
+    case LDP_NOTIF_UNKNOWN_TVL:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_UNKNOWN_TVL:\n");
+      break;
+    case LDP_NOTIF_BAD_TLV_LEN:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_BAD_TLV_LEN:\n");
+      break;
+    case LDP_NOTIF_MALFORMED_TLV:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_MALFORMED_TLV:\n");
+      break;
+    case LDP_NOTIF_HOLD_TIMER_EXPIRED:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_HOLD_TIMER_EXPIRED:\n");
+      break;
+    case LDP_NOTIF_SHUTDOWN:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_SHUTDOWN:\n");
+      break;
+    case LDP_NOTIF_UNKNOWN_FEC:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_UNKNOWN_FEC:\n");
+      break;
+    case LDP_NOTIF_SESSION_REJECTED_NO_HELLO:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_SESSION_REJECTED_NO_HELLO:\n");
+      break;
+    case LDP_NOTIF_SESSION_REJECTED_PARAMETERS_ADVERTISEMENT_MODE:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_SESSION_REJECTED_PARAMETERS_ADVERTISEMENT_MODE:\n");
+      break;
+    case LDP_NOTIF_SESSION_REJECTED_PARAMETERS_MAX_PDU_LEN:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_SESSION_REJECTED_PARAMETERS_MAX_PDU_LEN:\n");
+      break;
+    case LDP_NOTIF_SESSION_REJECTED_PARAMETERS_LABEL_RANGE:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_SESSION_REJECTED_PARAMETERS_LABEL_RANGE:\n");
+      break;
+    case LDP_NOTIF_KEEPALIVE_TIMER_EXPIRED:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_KEEPALIVE_TIMER_EXPIRED:\n");
+      break;
+    case LDP_NOTIF_MISSING_MSG_PARAMS:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_MISSING_MSG_PARAMS:\n");
+      break;
+    case LDP_NOTIF_UNSUPORTED_AF:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_UNSUPORTED_AF:\n");
+      break;
+    case LDP_NOTIF_SESSION_REJECTED_BAD_KEEPALIVE_TIME:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_SESSION_REJECTED_BAD_KEEPALIVE_TIME:\n");
+      break;
+    case LDP_NOTIF_INTERNAL_ERROR:
+      LDP_TRACE_OUT(g->user_data, "LDP_NOTIF_INTERNAL_ERROR\n");
+      break;
+    default:
+      LDP_TRACE_OUT(g->user_data, "Receive an unknown notification: %08x\n",
+	status);
+      retval = MPLS_SUCCESS;
+      break;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_notif_process");
+  return retval;
+}
+
+mpls_return_enum ldp_notif_label_request_aborted(ldp_global * g, ldp_session * s,
+  ldp_attr * r_attr)
+{
+  ldp_attr *ds_attr = NULL;
+
+  LDP_ENTER(g->user_data, "ldp_notif_label_request_aborted");
+
+  ds_attr = MPLS_LIST_HEAD(&s->attr_root);
+  while (ds_attr != NULL) {
+    if (ds_attr->state == LDP_LSP_STATE_ABORT_SENT &&
+      ds_attr->msg_id == r_attr->msg_id) {
+      break;
+    }
+    ds_attr = MPLS_LIST_NEXT(&s->attr_root, ds_attr, _fs);
+  }
+
+  if (ds_attr) {                /* LRqA.1 */
+    ldp_attr_remove_complete(g, ds_attr, MPLS_BOOL_FALSE); /* LRqA.2 */
+
+    LDP_EXIT(g->user_data, "ldp_notif_label_request_aborted");
+    return MPLS_SUCCESS;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_notif_label_request_abort_error");
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_notif_no_label_resources(ldp_global * g, ldp_session * s,
+  ldp_attr * s_attr)
+{
+  ldp_attr_list *ds_list = NULL;
+  ldp_attr *ds_attr = NULL;
+  mpls_fec nfec;
+
+  LDP_ENTER(g->user_data, "ldp_notif_no_label_resources");
+
+  fec_tlv2mpls_fec(&s_attr->fecTlv, 0, &nfec);
+  /* NoRes.1 do not actually remove from tree, just change it's state */
+
+  if ((ds_list = ldp_attr_find_downstream_all(g, s, &nfec))) {
+    ds_attr = MPLS_LIST_HEAD(&s->attr_root);
+    while (ds_attr) {
+      if (ds_attr->state == LDP_LSP_STATE_REQ_SENT) {
+        ds_attr->state = LDP_LSP_STATE_NO_LABEL_RESOURCE_RECV; /* NoRes.2 */
+      }
+      ds_attr = MPLS_LIST_NEXT(&s->attr_root, ds_attr, _fs);
+    }
+  }
+
+  s->no_label_resource_recv = MPLS_BOOL_TRUE; /* NoRes.3 */
+
+  LDP_EXIT(g->user_data, "ldp_notif_no_label_resource_error");
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_notif_no_route(ldp_global * g, ldp_session * s,
+  ldp_entity * e, ldp_attr * s_attr)
+{
+  ldp_attr *ds_attr = NULL;
+  ldp_attr_list *ds_list = NULL;
+  mpls_fec nfec;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  LDP_ENTER(g->user_data, "ldp_notif_no_route\n");
+
+  fec_tlv2mpls_fec(&s_attr->fecTlv, 0, &nfec);
+
+  if ((ds_list = ldp_attr_find_downstream_all(g, s, &nfec))) {
+    ds_attr = MPLS_LIST_HEAD(&s->attr_root);
+    while (ds_attr) {
+      if (ds_attr->state == LDP_LSP_STATE_REQ_SENT) {
+        if (e->label_request_count) {
+          if (ds_attr->attempt_count < e->label_request_count) {
+            if (mpls_timer_handle_verify(g->timer_handle,
+                ds_attr->action_timer) == MPLS_BOOL_FALSE) {
+              ds_attr->action_timer =
+                mpls_timer_create(g->timer_handle, MPLS_UNIT_SEC,
+                s->cfg_label_request_timer, (void *)ds_attr, g,
+                ldp_attr_action_callback);
+            }
+            mpls_timer_start(g->timer_handle, ds_attr->action_timer,
+              MPLS_TIMER_ONESHOT);
+          }
+          retval = MPLS_SUCCESS;
+        } else {
+          ldp_attr_remove_complete(g, ds_attr, MPLS_BOOL_FALSE);
+          retval = MPLS_FAILURE;
+        }
+      }
+      ds_attr = MPLS_LIST_NEXT(&s->attr_root, ds_attr, _fs);
+    }
+  }
+
+  LDP_EXIT(g->user_data, "ldp_notif_no_route\n");
+  return retval;
+}
+
+/* IV. Receive Notification/ Loop Detected */
+
+/* Algo: Same as receive Notification/No Route */
+
+mpls_return_enum ldp_notif_label_resources_available(ldp_global * g,
+  ldp_session * s, ldp_attr * r_attr)
+{
+  ldp_session *nh_session = NULL;
+  ldp_attr *ds_attr = NULL;
+  ldp_nexthop *nh = NULL;
+  ldp_fec *f = NULL;
+
+  LDP_ENTER(g->user_data, "ldp_notif_label_resources_available");
+
+  s->no_label_resource_recv = MPLS_BOOL_FALSE;			/* Res.1 */
+
+  ds_attr = MPLS_LIST_HEAD(&s->attr_root);
+  while (ds_attr != NULL) {					/* Res.2 */
+    if (ds_attr->state == LDP_LSP_STATE_NO_LABEL_RESOURCE_RECV) {
+      f = ds_attr->fec;
+      nh = MPLS_LIST_HEAD(&f->nh_root);
+      while (nh) {
+	nh_session = ldp_session_for_nexthop(nh);
+        if (nh_session && (nh_session->index == s->index)) {
+								/* Res.4 */
+          if (ldp_label_request_send(g, s, ds_attr, NULL) != MPLS_SUCCESS) {
+	    MPLS_ASSERT(0);
+	  }
+	} else {
+          ldp_attr_remove_complete(g, ds_attr, MPLS_BOOL_FALSE);/* Res.5 */
+	}
+	nh = MPLS_LIST_NEXT(&f->nh_root, nh, _fec);
+      }
+    }
+    ds_attr = MPLS_LIST_NEXT(&s->attr_root, ds_attr, _fs);
+  }								/* Res.6 */
+
+  LDP_EXIT(g->user_data, "ldp_notif_label_resources_available");
+  return MPLS_SUCCESS;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_notif.h quagga-mpls/ldpd/ldp_notif.h
--- quagga-0.99.10/ldpd/ldp_notif.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_notif.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,36 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_NOTIF_H_
+#define _LDP_NOTIF_H_
+
+#include "ldp_struct.h"
+
+extern mpls_return_enum ldp_notif_send(ldp_global *, ldp_session *, ldp_attr *,
+
+  ldp_notif_status);
+
+extern mpls_return_enum ldp_notif_process(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, ldp_attr * r_attr);
+
+extern void not2attr(mplsLdpNotifMsg_t * not, ldp_attr * attr, uint32_t flag);
+
+extern mpls_return_enum ldp_notif_no_route(ldp_global * g, ldp_session * s,
+  ldp_entity * e, ldp_attr * attr);
+
+extern mpls_return_enum ldp_notif_no_label_resources(ldp_global * g,
+  ldp_session * s, ldp_attr * s_attr);
+
+extern mpls_return_enum ldp_notif_label_request_aborted(ldp_global * g,
+  ldp_session * s, ldp_attr * s_attr);
+
+extern mpls_return_enum ldp_notif_label_resources_available(ldp_global * g,
+  ldp_session * s, ldp_attr * s_attr);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_outlabel.c quagga-mpls/ldpd/ldp_outlabel.c
--- quagga-0.99.10/ldpd/ldp_outlabel.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_outlabel.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,235 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdlib.h>
+#include "ldp_struct.h"
+#include "ldp_addr.h"
+#include "ldp_if.h"
+#include "ldp_attr.h"
+#include "ldp_fec.h"
+#include "ldp_nexthop.h"
+#include "ldp_outlabel.h"
+#include "ldp_inlabel.h"
+#include "ldp_session.h"
+#include "ldp_tunnel.h"
+#include "ldp_global.h"
+
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+
+static uint32_t _ldp_outlabel_next_index = 1;
+
+/*
+ * even through we're trying to mimic what FECs/addrs/interfaces are doing
+ * with respect to being added to the global list upon create and
+ * automagically be removed from the global list upon delete, we have to
+ * change thing up for outlabels.  We want the global add/delete to call
+ * the porting layer to install the segments, but an outlabel needs more
+ * info then just being allocated before the porting layer can add it.
+ * so ldp_outlabel_create is not in charge of adding to the global list.
+ * Instead the only entrance to creating a outlabel is
+ * ldp_outlabel_create_complete which uses ldp_outlabel_create just to
+ * allocate and initialize the memory, then after all of the necessary info
+ * has been attached, it is added to the global list, which calls the
+ * porting layer
+ */
+
+static ldp_outlabel *ldp_outlabel_create(ldp_global * g)
+{
+  ldp_outlabel *o = (ldp_outlabel *) mpls_malloc(sizeof(ldp_outlabel));
+
+  if (o) {
+    memset(o, 0, sizeof(ldp_outlabel));
+    MPLS_REFCNT_INIT(o, 0);
+    MPLS_LIST_INIT(&o->inlabel_root, ldp_inlabel);
+    MPLS_LIST_INIT(&o->tunnel_root, ldp_tunnel);
+    MPLS_LIST_INIT(&o->nh_root, ldp_nexthop);
+    MPLS_LIST_ELEM_INIT(o, _global);
+    MPLS_LIST_ELEM_INIT(o, _session);
+    o->index = _ldp_outlabel_get_next_index();
+    o->info.label.type = MPLS_LABEL_TYPE_NONE;
+    o->switching = MPLS_BOOL_FALSE;
+  }
+  return o;
+}
+
+ldp_outlabel *ldp_outlabel_create_complete(ldp_global * g, ldp_session * s,
+  ldp_attr * a, ldp_nexthop *nh)
+{
+  ldp_outlabel *out = ldp_outlabel_create(g);
+
+  if (out != NULL) {
+    ldp_outlabel_add_nexthop2(out, nh);
+    ldp_session_add_outlabel(s, out);
+
+    out->info.push_label = MPLS_BOOL_TRUE;
+    out->info.owner = MPLS_OWNER_LDP;
+
+    ldp_attr2mpls_label_struct(a, &out->info.label);
+    ldp_attr_add_outlabel(a, out);
+
+    /* _ldp_global_add_outlabel must be last so the porting layer has all the
+     * info needed for installing the label */
+    _ldp_global_add_outlabel(g, out);
+  }
+  return out;
+}
+
+void ldp_outlabel_delete(ldp_global * g, ldp_outlabel * o)
+{
+  LDP_PRINT(g->user_data,"outlabel delete");
+  MPLS_REFCNT_ASSERT(o, 0);
+  if (o->nh) {
+    ldp_outlabel_del_nexthop2(g, o);
+  }
+  _ldp_global_del_outlabel(g, o);
+  mpls_free(o);
+}
+
+#if 0
+void ldp_outlabel_delete_complete(ldp_global * g, ldp_outlabel * out)
+{
+  ldp_attr_del_outlabel(g, out->attr);
+  if (out->session) {
+    ldp_session_del_outlabel(g, out->session, out);
+  }
+  _ldp_global_del_outlabel(g, out);
+  ldp_outlabel_del_nexthop2(g, out);
+}
+#endif
+
+void _ldp_outlabel_add_inlabel(ldp_outlabel * o, ldp_inlabel * i)
+{
+  MPLS_ASSERT(o && i);
+  MPLS_REFCNT_HOLD(i);
+  o->merge_count++;
+  MPLS_LIST_ADD_HEAD(&o->inlabel_root, i, _outlabel, ldp_inlabel);
+}
+
+void _ldp_outlabel_del_inlabel(ldp_global * g,ldp_outlabel * o, ldp_inlabel * i)
+{
+  MPLS_ASSERT(o && i);
+  MPLS_LIST_REMOVE(&o->inlabel_root, i, _outlabel);
+  o->merge_count--;
+  MPLS_REFCNT_RELEASE2(g, i, ldp_inlabel_delete);
+}
+
+void _ldp_outlabel_add_attr(ldp_outlabel * o, ldp_attr * a)
+{
+  MPLS_ASSERT(o && a);
+  MPLS_REFCNT_HOLD(a);
+  o->attr = a;
+}
+
+void _ldp_outlabel_del_attr(ldp_global *g, ldp_outlabel * o)
+{
+  MPLS_ASSERT(o && o->attr);
+  MPLS_REFCNT_RELEASE2(g, o->attr, ldp_attr_delete);
+  o->attr = NULL;
+}
+
+/*
+ * We do not hold a ref to the nexthop.  The nexthop holds a ref to the
+ * outlabel.  Nexthop creation calls ldp_outlabel_add_nexthop, nexthop
+ * deletion calls ldp_outlabel_del_nexthop.  There is no way a nexthop can
+ * be deleted without removing the outlabels ref to the nexthop.
+ *
+ * this is for the nexthops outlabel used 
+ * for describing hierachy
+ */
+void ldp_outlabel_add_nexthop(ldp_outlabel * o, ldp_nexthop * nh)
+{
+  ldp_nexthop *np = NULL;
+
+  MPLS_ASSERT(o && nh);
+
+  ldp_nexthop_add_outlabel(nh,o);
+
+  np = MPLS_LIST_HEAD(&o->nh_root);
+  while (np != NULL) {
+    if (np->index > nh->index) {
+       MPLS_LIST_INSERT_BEFORE(&o->nh_root, np, nh, _outlabel);
+       return;
+    }
+    np = MPLS_LIST_NEXT(&o->nh_root, np, _outlabel);
+  }
+  MPLS_LIST_ADD_TAIL(&o->nh_root, nh, _outlabel, ldp_nexthop);
+}
+
+/*
+ * this is for the nexthops outlabel used 
+ * for describing hierachy
+ */
+void ldp_outlabel_del_nexthop(ldp_global *g, ldp_outlabel * o, ldp_nexthop * nh)
+{
+  MPLS_ASSERT(o && nh);
+  MPLS_LIST_REMOVE(&o->nh_root, nh, _outlabel);
+  ldp_nexthop_del_outlabel(g, nh);
+}
+
+/* this is for the outlabels nexthops, not the nexthop's outlabel
+ * used to describe hierarchy */
+void ldp_outlabel_add_nexthop2(ldp_outlabel * o, ldp_nexthop * nh)
+{
+  MPLS_ASSERT(o && nh);
+  MPLS_REFCNT_HOLD(nh);
+  o->nh = nh;
+  ldp_nexthop_add_outlabel2(nh, o);
+}
+
+/* this is for the outlabels nexthops, not the nexthop's outlabel
+ * used to describe hierarchy */
+void ldp_outlabel_del_nexthop2(ldp_global *g, ldp_outlabel * o)
+{
+  MPLS_ASSERT(o);
+  ldp_nexthop_del_outlabel2(g, o->nh, o);
+  MPLS_REFCNT_RELEASE2(g, o->nh, ldp_nexthop_delete);
+  o->nh = NULL;
+}
+
+void _ldp_outlabel_add_session(ldp_outlabel * o, ldp_session * s)
+{
+  MPLS_ASSERT(o && s);
+  MPLS_REFCNT_HOLD(s);
+  o->session = s;
+}
+
+void _ldp_outlabel_del_session(ldp_outlabel * o)
+{
+  MPLS_ASSERT(o && o->session);
+  MPLS_REFCNT_RELEASE(o->session, ldp_session_delete);
+  o->session = NULL;
+}
+
+void _ldp_outlabel_add_tunnel(ldp_outlabel * o, ldp_tunnel * t)
+{
+  MPLS_ASSERT(o && t);
+  MPLS_REFCNT_HOLD(t);
+  o->merge_count++;
+  MPLS_LIST_ADD_HEAD(&o->tunnel_root, t, _outlabel, ldp_tunnel);
+}
+
+void _ldp_outlabel_del_tunnel(ldp_outlabel * o, ldp_tunnel * t)
+{
+  MPLS_ASSERT(o && t);
+  MPLS_LIST_REMOVE(&o->tunnel_root, t, _outlabel);
+  o->merge_count--;
+  MPLS_REFCNT_RELEASE(t, ldp_tunnel_delete);
+}
+
+uint32_t _ldp_outlabel_get_next_index()
+{
+  uint32_t retval = _ldp_outlabel_next_index;
+
+  _ldp_outlabel_next_index++;
+  if (retval > _ldp_outlabel_next_index) {
+    _ldp_outlabel_next_index = 1;
+  }
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_outlabel.h quagga-mpls/ldpd/ldp_outlabel.h
--- quagga-0.99.10/ldpd/ldp_outlabel.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_outlabel.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,40 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_OUTLABEL_H_
+#define _LDP_OUTLABEL_H_
+
+#include "ldp_struct.h"
+
+extern void ldp_outlabel_delete(ldp_global * g, ldp_outlabel * i);
+
+extern ldp_outlabel *ldp_outlabel_create_complete(ldp_global * g,
+  ldp_session * s, ldp_attr * a, ldp_nexthop *nh);
+extern void ldp_outlabel_delete_complete(ldp_global * g, ldp_outlabel * out);
+
+extern void _ldp_outlabel_add_inlabel(ldp_outlabel *, ldp_inlabel *);
+extern void _ldp_outlabel_del_inlabel(ldp_global *,ldp_outlabel *, ldp_inlabel *);
+
+extern void _ldp_outlabel_add_session(ldp_outlabel *, ldp_session *);
+extern void _ldp_outlabel_del_session(ldp_outlabel * o);
+
+extern void _ldp_outlabel_add_attr(ldp_outlabel * o, ldp_attr * a);
+extern void _ldp_outlabel_del_attr(ldp_global *g, ldp_outlabel * o);
+
+extern void ldp_outlabel_add_nexthop(ldp_outlabel * o, ldp_nexthop * nh);
+extern void ldp_outlabel_del_nexthop(ldp_global *g, ldp_outlabel * o, ldp_nexthop * nh);
+
+extern void ldp_outlabel_add_nexthop2(ldp_outlabel * o, ldp_nexthop * nh);
+extern void ldp_outlabel_del_nexthop2(ldp_global *g, ldp_outlabel * o);
+
+extern void _ldp_outlabel_add_tunnel(ldp_outlabel * o, ldp_tunnel * t);
+extern void _ldp_outlabel_del_tunnel(ldp_outlabel * o, ldp_tunnel * t);
+
+extern uint32_t _ldp_outlabel_get_next_index();
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_pdu.h quagga-mpls/ldpd/ldp_pdu.h
--- quagga-0.99.10/ldpd/ldp_pdu.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_pdu.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,32 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_PDU_H_
+#define _LDP_PDU_H_
+
+#include "ldp_mm_impl.h"
+
+#define MPLS_MSGMALLOC( e ) mplsLdp ## e ## Msg_t *test ## e ## Msg = (mplsLdp ## e ## Msg_t*)ldp_malloc(sizeof(mplsLdp ## e ## Msg_t))
+#define MPLS_MSGSTRUCT( e ) mplsLdp ## e ## Msg_t test ## e ## Msg
+#define MPLS_MSGPTR( e ) mplsLdp ## e ## Msg_t *test ## e ## Msg
+#define MPLS_MSGCAST( e , f ) test ## e ## Msg = (mplsLdp ## e ## Msg_t*) f
+#define MPLS_MSGPARAM( e ) test ## e ## Msg
+
+#include "ldp_struct.h"
+
+extern ldp_pdu *ldp_pdu_create();
+extern ldp_pdu *ldp_pdu_create_decode(ldp_global * g, uint8_t * buf,
+  int buf_size, int data_size);
+extern void ldp_pdu_delete(ldp_pdu * p);
+extern int Mpls_encodeLdpPDU(ldp_global * g, uint32_t lsraddr, int label_space,
+  ldp_msg * msg, uint8_t * buf, int buf_size);
+extern mpls_return_enum Mpls_decodeLdpPDU(ldp_global * g, ldp_pdu * pdu,
+  uint8_t * buf, int size, int n);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_pdu_setup.c quagga-mpls/ldpd/ldp_pdu_setup.c
--- quagga-0.99.10/ldpd/ldp_pdu_setup.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_pdu_setup.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,512 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */  
+  
+#include "ldp_struct.h"
+#include "ldp_pdu_setup.h"
+
+void setBaseMsgId(mplsLdpMsg_t * baseMsg, unsigned int msgId)
+{
+  baseMsg->msgId = msgId;
+}
+
+void setupBaseMsg(mplsLdpMsg_t * baseMsg, unsigned int type, int uBit,
+  unsigned int msgId)
+{
+  baseMsg->flags.flags.msgType = type;
+  baseMsg->flags.flags.uBit = uBit;
+  baseMsg->msgLength = MPLS_MSGIDFIXLEN;
+  setBaseMsgId(baseMsg, msgId);
+}
+
+int setupChpTlv(mplsLdpChpTlv_t * chpTlv, int target, int request, int res,
+  int holdTime)
+{
+  chpTlv->baseTlv.flags.flags.tBit = MPLS_CHP_TLVTYPE;
+  chpTlv->baseTlv.flags.flags.uBit = 0;
+  chpTlv->baseTlv.flags.flags.fBit = 0;
+  chpTlv->baseTlv.length = MPLS_CHPFIXLEN;
+  chpTlv->flags.flags.target = target;
+  chpTlv->flags.flags.request = request;
+  chpTlv->flags.flags.res = res;
+  chpTlv->holdTime = holdTime;
+  return MPLS_TLVFIXLEN + MPLS_CHPFIXLEN;
+}
+
+int setupPinningTlv(mplsLdpPinningTlv_t * pinningTlv, int pBit, int res)
+{
+  pinningTlv->baseTlv.flags.flags.tBit = MPLS_PINNING_TLVTYPE;
+  pinningTlv->baseTlv.flags.flags.uBit = 0;
+  pinningTlv->baseTlv.flags.flags.fBit = 0;
+  pinningTlv->baseTlv.length = 4;
+  pinningTlv->flags.flags.pBit = pBit;
+  pinningTlv->flags.flags.res = res;
+  return 4 + MPLS_TLVFIXLEN;
+}
+
+int setupResClassTlv(mplsLdpResClsTlv_t * resClsTlv, unsigned int rsCls)
+{
+  resClsTlv->baseTlv.flags.flags.tBit = MPLS_RESCLASS_TLVTYPE;
+  resClsTlv->baseTlv.flags.flags.uBit = 0;
+  resClsTlv->baseTlv.flags.flags.fBit = 0;
+  resClsTlv->baseTlv.length = 4;
+  resClsTlv->rsCls = rsCls;
+  return 4 + MPLS_TLVFIXLEN;
+}
+
+int setupPreemptTlv(mplsLdpPreemptTlv_t * preemptTlv, unsigned char setPrio,
+  unsigned char holdPrio, unsigned short res)
+{
+  preemptTlv->baseTlv.flags.flags.tBit = MPLS_PREEMPT_TLVTYPE;
+  preemptTlv->baseTlv.flags.flags.uBit = 0;
+  preemptTlv->baseTlv.flags.flags.fBit = 0;
+  preemptTlv->baseTlv.length = MPLS_PREEMPTTLV_FIXLEN;
+  preemptTlv->setPrio = setPrio;
+  preemptTlv->holdPrio = holdPrio;
+  preemptTlv->res = res;
+  return MPLS_PREEMPTTLV_FIXLEN + MPLS_TLVFIXLEN;
+}
+
+int addErHop2ErHopTvl(mplsLdpErTlv_t * erHopTlv, mplsLdpErHop_t * erHop,
+  unsigned short type)
+{
+  int num = erHopTlv->numberErHops;
+  int result = 0;
+
+  memcpy(&(erHopTlv->erHopArray[num]), erHop, sizeof(mplsLdpErHop_t));
+  erHopTlv->erHopTypes[num] = type;
+  erHopTlv->numberErHops++;
+  switch (type) {
+    case MPLS_ERHOP_IPV4_TLVTYPE:
+      result = MPLS_ERHOP_IPV4_FIXLEN;
+      break;
+    case MPLS_ERHOP_IPV6_TLVTYPE:
+      result = MPLS_ERHOP_IPV6_FIXLEN;
+      break;
+    case MPLS_ERHOP_AS_TLVTYPE:
+      result = MPLS_ERHOP_AS_FIXLEN;
+      break;
+    case MPLS_ERHOP_LSPID_TLVTYPE:
+      result = MPLS_ERHOP_LSPID_FIXLEN;
+      break;
+  }
+  return result + MPLS_TLVFIXLEN;
+}
+
+int setupErHopTlv(mplsLdpErTlv_t * erHopTlv)
+{
+  erHopTlv->baseTlv.flags.flags.tBit = MPLS_ERHOP_IPV4_TLVTYPE;
+  erHopTlv->baseTlv.flags.flags.uBit = 0;
+  erHopTlv->baseTlv.flags.flags.fBit = 0;
+  erHopTlv->baseTlv.length = 0;
+  return MPLS_TLVFIXLEN;
+}
+
+int setupTrAddrTlv(mplsLdpTrAdrTlv_t * trAddrTlv, unsigned int trAddr)
+{
+  trAddrTlv->baseTlv.flags.flags.tBit = MPLS_TRADR_TLVTYPE;
+  trAddrTlv->baseTlv.flags.flags.uBit = 0;
+  trAddrTlv->baseTlv.flags.flags.fBit = 0;
+  trAddrTlv->baseTlv.length = MPLS_TRADRFIXLEN;
+  trAddrTlv->address = trAddr;
+  return MPLS_TRADRFIXLEN + MPLS_TLVFIXLEN;
+}
+
+int setupCsnTlv(mplsLdpCsnTlv_t * csnTlv, unsigned int confSeqNum)
+{
+  csnTlv->baseTlv.flags.flags.tBit = MPLS_CSN_TLVTYPE;
+  csnTlv->baseTlv.flags.flags.uBit = 0;
+  csnTlv->baseTlv.flags.flags.fBit = 0;
+  csnTlv->baseTlv.length = MPLS_CSNFIXLEN;
+  csnTlv->seqNumber = confSeqNum;
+  return MPLS_CSNFIXLEN + MPLS_TLVFIXLEN;
+}
+
+int setupCspTlv(mplsLdpCspTlv_t * cspTlv, uint16_t keepalive,
+  uint8_t adv_discp, uint8_t loop, uint8_t pvl, uint16_t mtu,
+  uint32_t remote_lsraddr, uint16_t remote_labelspace, uint32_t res)
+{
+  cspTlv->baseTlv.flags.flags.tBit = MPLS_CSP_TLVTYPE;
+  cspTlv->baseTlv.flags.flags.uBit = 0;
+  cspTlv->baseTlv.flags.flags.fBit = 0;
+  cspTlv->baseTlv.length = MPLS_CSPFIXLEN;
+  cspTlv->protocolVersion = 1;
+  cspTlv->holdTime = keepalive;
+  cspTlv->flags.flags.lad = adv_discp;
+  cspTlv->flags.flags.ld = loop;
+  cspTlv->flags.flags.res = res;
+  cspTlv->flags.flags.pvl = pvl;
+  cspTlv->maxPduLen = mtu;
+  cspTlv->rcvLsrAddress = remote_lsraddr;
+  cspTlv->rcvLsId = remote_labelspace;
+  return MPLS_CSPFIXLEN + MPLS_TLVFIXLEN;
+}
+
+int addLblRng2AspTlv(mplsLdpAspTlv_t * aspTlv, unsigned int minvpi,
+  unsigned int minvci, unsigned int maxvpi, unsigned int maxvci)
+{
+  int num = aspTlv->baseTlv.length / MPLS_ASPFIXLEN;
+
+  aspTlv->baseTlv.length += MPLS_ASPFIXLEN;
+  aspTlv->lblRngList[num].flags.flags.res1 = 0;
+  aspTlv->lblRngList[num].flags.flags.minVpi = minvpi;
+  aspTlv->lblRngList[num].flags.flags.minVci = minvci;
+  aspTlv->lblRngList[num].flags.flags.res2 = 0;
+  aspTlv->lblRngList[num].flags.flags.maxVpi = maxvpi;
+  aspTlv->lblRngList[num].flags.flags.maxVci = maxvci;
+  return MPLS_ASPFIXLEN;
+}
+
+int addLblRng2FspTlv(mplsLdpFspTlv_t * fspTlv, unsigned int resmin,
+  unsigned int len, unsigned int mindlci, unsigned int resmax,
+  unsigned int maxdlci)
+{
+  int num = fspTlv->baseTlv.length / MPLS_FSPFIXLEN;
+
+  fspTlv->baseTlv.length += MPLS_FSPFIXLEN;
+  fspTlv->lblRngList[num].flags.flags.res_min = resmin;
+  fspTlv->lblRngList[num].flags.flags.len = len;
+  fspTlv->lblRngList[num].flags.flags.minDlci = mindlci;
+  fspTlv->lblRngList[num].flags.flags.res_max = resmax;
+  fspTlv->lblRngList[num].flags.flags.maxDlci = maxdlci;
+  return MPLS_FSPFIXLEN;
+}
+
+int setupAspTlv(mplsLdpAspTlv_t * aspTlv, uint8_t merge, uint8_t direction)
+{
+  aspTlv->baseTlv.flags.flags.tBit = MPLS_ASP_TLVTYPE;
+  aspTlv->baseTlv.flags.flags.uBit = 0;
+  aspTlv->baseTlv.flags.flags.fBit = 0;
+  aspTlv->flags.flags.dir = direction;
+  aspTlv->flags.flags.mergeType = merge;
+  aspTlv->baseTlv.length = 0;
+  return MPLS_TLVFIXLEN;
+}
+
+int setupFspTlv(mplsLdpFspTlv_t * fspTlv, uint8_t merge, uint8_t direction)
+{
+  fspTlv->baseTlv.flags.flags.tBit = MPLS_FSP_TLVTYPE;
+  fspTlv->baseTlv.flags.flags.uBit = 0;
+  fspTlv->baseTlv.flags.flags.fBit = 0;
+  fspTlv->flags.flags.dir = direction;
+  fspTlv->flags.flags.mergeType = merge;
+  fspTlv->baseTlv.length = 0;
+  return MPLS_TLVFIXLEN;
+}
+
+int setupFecTlv(mplsLdpFecTlv_t * fecTlv)
+{
+  fecTlv->baseTlv.flags.flags.tBit = MPLS_FEC_TLVTYPE;
+  fecTlv->baseTlv.flags.flags.uBit = 0;
+  fecTlv->baseTlv.flags.flags.fBit = 0;
+  fecTlv->baseTlv.length = 0;
+  fecTlv->wcElemExists = 0;
+  fecTlv->numberFecElements = 0;
+  return MPLS_TLVFIXLEN;
+}
+
+
+#if 0
+  mplsFecElement_t * createFecElemFromFecType(struct mpls_fec * fec)
+{
+  mplsFecElement_t * fecElem =
+    (mplsFecElement_t *) malloc(sizeof(mplsFecElement_t));
+  fecElem->addressEl.type = MPLS_PREFIX_FEC;
+  fecElem->addressEl.addressFam = 1;
+  fecElem->addressEl.preLen = fec->len;
+  fecElem->addressEl.address = fec->prefix;
+  return fecElem;
+}
+
+mplsFecElement_t * createFecElemFromRoute(routeT * r)
+{
+  mplsFecElement_t * fecElem = 
+    (mplsFecElement_t *) malloc(sizeof(mplsFecElement_t));
+  memset(fecElem, 0, sizeof(mplsFecElement_t));
+  fecElem->addressEl.type = MPLS_PREFIX_FEC;
+  fecElem->addressEl.addressFam = 1;
+  fecElem->addressEl.preLen = r->len;
+  fecElem->addressEl.address = r->prefix;
+  return fecElem;
+}
+
+
+#endif /*  */
+int addFecElem2FecTlv(mplsLdpFecTlv_t * fecTlv, mplsFecElement_t * elem)
+{
+  int num = fecTlv->numberFecElements;
+  int size = 0;
+
+  switch (elem->addressEl.type) {
+    case MPLS_PREFIX_FEC:
+    case MPLS_HOSTADR_FEC:
+      size = elem->addressEl.preLen / 8;
+      if (elem->addressEl.preLen % 8)
+        size++;
+      size += 4;
+      break;
+    case MPLS_CRLSP_FEC:
+      size = 4;
+      break;
+  }
+  fecTlv->baseTlv.length += size;
+  memcpy(&(fecTlv->fecElArray[num]), elem, sizeof(mplsFecElement_t));
+  fecTlv->fecElemTypes[num] = elem->addressEl.type;
+  fecTlv->numberFecElements++;
+  return size;
+}
+
+
+#if 0
+void copyLabelType2MapLabelTlv(struct mpls_label *label,
+  mplsLdpLblMapMsg_t * lblMap)
+{
+  switch (label->ml_type) {
+    case MPLS_LABEL_ATM:
+      lblMap->baseMsg.msgLength +=
+        setupAtmLblTlv(&(lblMap->atmLblTlv), 0, 0, label->u.ml_atm.mla_vpi,
+        label->u.ml_atm.mla_vci); lblMap->atmLblTlvExists = 1;
+      lblMap->genLblTlvExists = 0;
+      lblMap->frLblTlvExists = 0;
+      break;
+    case MPLS_LABEL_GEN:
+      lblMap->baseMsg.msgLength +=
+        setupGenLblTlv(&(lblMap->genLblTlv), label->u.ml_gen);
+      lblMap->atmLblTlvExists = 0;
+      lblMap->genLblTlvExists = 1;
+      lblMap->frLblTlvExists = 0;
+      break;
+    case MPLS_LABEL_FR:
+      lblMap->baseMsg.msgLength +=
+        setupFrLblTlv(&(lblMap->frLblTlv), 0, 0, label->u.ml_fr);
+      lblMap->atmLblTlvExists = 0;
+      lblMap->genLblTlvExists = 0;
+      lblMap->frLblTlvExists = 1;
+      break;
+    default:
+      LDP_PRINT(g->user_data, "invalid label type\n");
+      break;
+  }
+}
+void copyAtmLblTlv2MplsLabel(mplsLdpAtmLblTlv_t * atmLblTlv,
+  struct mpls_label *label)
+{
+  label->ml_type = MPLS_LABEL_ATM;
+  label->u.ml_atm.mla_vpi = atmLblTlv->flags.flags.vpi;
+  label->u.ml_atm.mla_vci = atmLblTlv->vci;
+}
+
+
+#endif /*  */
+
+int setupAtmLblTlv(mplsLdpAtmLblTlv_t * atmLblTlv, int res, int v,
+  unsigned int vpi, unsigned int vci)
+{
+  atmLblTlv->baseTlv.flags.flags.tBit = MPLS_ATMLBL_TLVTYPE;
+  atmLblTlv->baseTlv.flags.flags.uBit = 0;
+  atmLblTlv->baseTlv.flags.flags.fBit = 0;
+  atmLblTlv->baseTlv.length = MPLS_LBLFIXLEN;
+  atmLblTlv->flags.flags.res = res;
+  atmLblTlv->flags.flags.v = v;
+  atmLblTlv->flags.flags.vpi = vpi;
+  atmLblTlv->vci = vci;
+  return MPLS_LBLFIXLEN + MPLS_TLVFIXLEN;
+}
+
+
+#if 0
+void copyFrLblTlv2MplsLabel(mplsLdpFrLblTlv_t * frLblTlv,
+  struct mpls_label *label)
+{
+  label->ml_type = MPLS_LABEL_FR;
+  label->u.ml_fr = frLblTlv->flags.flags.dlci;
+}
+
+
+#endif /*  */
+
+int setupFrLblTlv(mplsLdpFrLblTlv_t * frLblTlv, int res, int len,
+  unsigned int dlci)
+{
+  frLblTlv->baseTlv.flags.flags.tBit = MPLS_FRLBL_TLVTYPE;
+  frLblTlv->baseTlv.flags.flags.uBit = 0;
+  frLblTlv->baseTlv.flags.flags.fBit = 0;
+  frLblTlv->baseTlv.length = MPLS_LBLFIXLEN;
+  frLblTlv->flags.flags.res = res;
+  frLblTlv->flags.flags.len = len;
+  frLblTlv->flags.flags.dlci = dlci;
+  return MPLS_LBLFIXLEN + MPLS_TLVFIXLEN;
+}
+
+
+#if 0
+void copyGenLblTlv2MplsLabel(mplsLdpGenLblTlv_t * genLblTlv,
+  struct mpls_label *label)
+{
+  label->ml_type = MPLS_LABEL_GEN;
+  label->u.ml_gen = genLblTlv->label;
+}
+
+
+#endif /*  */
+
+int setupGenLblTlv(mplsLdpGenLblTlv_t * genLblTlv, int label)
+{
+  genLblTlv->baseTlv.flags.flags.tBit = MPLS_GENLBL_TLVTYPE;
+  genLblTlv->baseTlv.flags.flags.uBit = 0;
+  genLblTlv->baseTlv.flags.flags.fBit = 0;
+  genLblTlv->baseTlv.length = MPLS_LBLFIXLEN;
+  genLblTlv->label = label;
+  return MPLS_LBLFIXLEN + MPLS_TLVFIXLEN;
+}
+
+int setupHopCountTlv(mplsLdpHopTlv_t * hopCountTlv, unsigned int hopCount)
+{
+  hopCountTlv->baseTlv.flags.flags.tBit = MPLS_HOPCOUNT_TLVTYPE;
+  hopCountTlv->baseTlv.flags.flags.uBit = 0;
+  hopCountTlv->baseTlv.flags.flags.fBit = 0;
+  hopCountTlv->baseTlv.length = MPLS_HOPCOUNTFIXLEN;
+  hopCountTlv->hcValue = hopCount;
+  return MPLS_HOPCOUNTFIXLEN + MPLS_TLVFIXLEN;
+}
+
+int setupPathTlv(mplsLdpPathTlv_t * pathTlv)
+{
+  pathTlv->baseTlv.flags.flags.tBit = MPLS_PATH_TLVTYPE;
+  pathTlv->baseTlv.flags.flags.uBit = 0;
+  pathTlv->baseTlv.flags.flags.fBit = 0;
+  pathTlv->baseTlv.length = 0;
+  return MPLS_TLVFIXLEN;
+}
+
+int addLsrId2PathTlv(mplsLdpPathTlv_t * pathTlv, unsigned int lsrId)
+{
+  int num = pathTlv->baseTlv.length / sizeof(unsigned int);
+  pathTlv->baseTlv.length += sizeof(unsigned int);
+
+  pathTlv->lsrId[num] = lsrId;
+  return sizeof(unsigned int);
+}
+
+int setupAddrTlv(mplsLdpAdrTlv_t * addrTlv)
+{
+  addrTlv->baseTlv.flags.flags.tBit = MPLS_ADDRLIST_TLVTYPE;
+  addrTlv->baseTlv.flags.flags.uBit = 0;
+  addrTlv->baseTlv.flags.flags.fBit = 0;
+  addrTlv->baseTlv.length = MPLS_ADDFAMFIXLEN;
+  addrTlv->addrFamily = 1;
+  return MPLS_TLVFIXLEN + MPLS_ADDFAMFIXLEN;
+}
+
+int addAddrElem2AddrTlv(mplsLdpAdrTlv_t * addrTlv, unsigned int addr)
+{
+  int num = (addrTlv->baseTlv.length - MPLS_ADDFAMFIXLEN) / MPLS_IPv4LEN;
+
+  addrTlv->address[num] = addr;
+  addrTlv->baseTlv.length += MPLS_IPv4LEN;
+  return MPLS_IPv4LEN;
+}
+
+int setupStatusTlv(mplsLdpStatusTlv_t * statTlv, int fatal, int forward,
+  int status, unsigned int msgId, int msgType)
+{
+  statTlv->baseTlv.flags.flags.tBit = MPLS_NOT_ST_TLVTYPE;
+  statTlv->baseTlv.flags.flags.uBit = 0;
+  statTlv->baseTlv.flags.flags.fBit = 0;
+  statTlv->baseTlv.length = MPLS_STATUSFIXLEN;
+  statTlv->flags.flags.error = fatal;
+  statTlv->flags.flags.forward = forward;
+  statTlv->flags.flags.status = status;
+  statTlv->msgId = msgId;
+  statTlv->msgType = msgType;
+  return MPLS_STATUSFIXLEN + MPLS_TLVFIXLEN;
+}
+
+int setupExStatusTlv(mplsLdpExStatusTlv_t * exStatus, unsigned int value)
+{
+  exStatus->baseTlv.flags.flags.tBit = MPLS_NOT_ES_TLVTYPE;
+  exStatus->baseTlv.flags.flags.uBit = 0;
+  exStatus->baseTlv.flags.flags.fBit = 0;
+  exStatus->baseTlv.length = MPLS_EXSTATUSLEN;
+  exStatus->value = value;
+  return MPLS_EXSTATUSLEN + MPLS_TLVFIXLEN;
+}
+
+int setupRetPduTlv(mplsLdpRetPduTlv_t * retPduTvl, unsigned int len,
+  mplsLdpHeader_t * hdr, void *data)
+{
+  retPduTvl->baseTlv.flags.flags.tBit = MPLS_NOT_RP_TLVTYPE;
+  retPduTvl->baseTlv.flags.flags.uBit = 0;
+  retPduTvl->baseTlv.flags.flags.fBit = 0;
+  retPduTvl->baseTlv.length = MPLS_LDP_HDRSIZE + len;
+  memcpy(&(retPduTvl->headerTlv), hdr, MPLS_LDP_HDRSIZE);
+  memcpy(retPduTvl->data, data, len);
+  return MPLS_LDP_HDRSIZE + len + MPLS_TLVFIXLEN;
+}
+
+int setupRetMsgTlv(mplsLdpRetMsgTlv_t * retMsgTlv, unsigned type,
+  unsigned len, void *data)
+{
+  retMsgTlv->baseTlv.flags.flags.tBit = MPLS_NOT_RM_TLVTYPE;
+  retMsgTlv->baseTlv.flags.flags.uBit = 0;
+  retMsgTlv->baseTlv.flags.flags.fBit = 0;
+  retMsgTlv->baseTlv.length = len;
+  retMsgTlv->msgType = type;
+  retMsgTlv->msgLength = 4 + len;
+  memcpy(retMsgTlv->data, data, len);
+  return 4 + len + MPLS_TLVFIXLEN;
+}
+
+int setupLspidTlv(mplsLdpLspIdTlv_t * lspidTlv, int res,
+  unsigned int localCrlspId, unsigned int routerId)
+{
+  lspidTlv->baseTlv.flags.flags.tBit = MPLS_LSPID_TLVTYPE;
+  lspidTlv->baseTlv.flags.flags.uBit = 0;
+  lspidTlv->baseTlv.flags.flags.fBit = 0;
+  lspidTlv->baseTlv.length = MPLS_LSPIDTLV_FIXLEN;
+  lspidTlv->res = res;
+  lspidTlv->localCrlspId = localCrlspId;
+  lspidTlv->routerId = routerId;
+  return MPLS_LSPIDTLV_FIXLEN + MPLS_TLVFIXLEN;
+}
+
+int setupTrafficTlv(mplsLdpTrafficTlv_t * trafficTlv, unsigned char freq,
+  unsigned char res, unsigned char weight, float pdr, float pbs, float cdr,
+  float cbs, float ebs)
+{
+  trafficTlv->baseTlv.flags.flags.tBit = MPLS_TRAFFIC_TLVTYPE;
+  trafficTlv->baseTlv.flags.flags.uBit = 0;
+  trafficTlv->baseTlv.flags.flags.fBit = 0;
+  trafficTlv->baseTlv.length = 0;
+  trafficTlv->flags.flags.res = 0;
+  trafficTlv->flags.flags.f6Bit = 0;
+  trafficTlv->flags.flags.f5Bit = 0;
+  trafficTlv->flags.flags.f4Bit = 0;
+  trafficTlv->flags.flags.f3Bit = 0;
+  trafficTlv->flags.flags.f2Bit = 0;
+  trafficTlv->flags.flags.f1Bit = 0;
+  trafficTlv->freq = freq;
+  trafficTlv->res = res;
+  trafficTlv->weight = weight;
+  trafficTlv->pdr.pdr = pdr;
+  trafficTlv->pbs.pbs = pbs;
+  trafficTlv->cdr.cdr = cdr;
+  trafficTlv->cbs.cbs = cbs;
+  trafficTlv->ebs.ebs = ebs;
+  return MPLS_TLVFIXLEN;
+}
+
+int setupLblMsgIdTlv(mplsLdpLblMsgIdTlv_t * lblMsgIdTlv, unsigned int msgId)
+{
+  lblMsgIdTlv->baseTlv.flags.flags.tBit = MPLS_REQMSGID_TLVTYPE;
+  lblMsgIdTlv->baseTlv.flags.flags.uBit = 0;
+  lblMsgIdTlv->baseTlv.flags.flags.fBit = 0;
+  lblMsgIdTlv->baseTlv.length = MPLS_MSGIDFIXLEN;
+  lblMsgIdTlv->msgId = msgId;
+  return MPLS_MSGIDFIXLEN + MPLS_TLVFIXLEN;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_pdu_setup.h quagga-mpls/ldpd/ldp_pdu_setup.h
--- quagga-0.99.10/ldpd/ldp_pdu_setup.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_pdu_setup.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,89 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */  
+  
+#ifndef _PDU_SETUP_
+#define _PDU_SETUP_
+  
+#include "ldp_struct.h"
+#include "ldp_nortel.h"
+void setBaseMsgId(mplsLdpMsg_t * baseMsg, unsigned int msgId);
+void setupBaseMsg(mplsLdpMsg_t * baseMsg, unsigned int type, int uBit,
+
+  unsigned int msgId);
+int setupChpTlv(mplsLdpChpTlv_t * chpTlv, int target, int request, int res,
+
+  int holdTime);
+int setupPinningTlv(mplsLdpPinningTlv_t * pinningTlv, int pBit, int res);
+int setupResClassTlv(mplsLdpResClsTlv_t * resClsTlv, unsigned int rsCls);
+int setupPreemptTlv(mplsLdpPreemptTlv_t * preemptTlv, unsigned char setPrio,
+  unsigned char holdPrio, unsigned short res);
+int addErHop2ErHopTvl(mplsLdpErTlv_t * erHopTlv, mplsLdpErHop_t * erHop,
+  unsigned short type); int setupErHopTlv(mplsLdpErTlv_t * erHopTlv);
+int setupTrAddrTlv(mplsLdpTrAdrTlv_t * trAddrTlv, unsigned int trAddr);
+int setupCsnTlv(mplsLdpCsnTlv_t * csnTlv, unsigned int confSeqNum);
+int setupCspTlv(mplsLdpCspTlv_t * cspTlv, uint16_t keepalive,
+  uint8_t adv_discp, uint8_t loop, uint8_t pvl, uint16_t mtu,
+  uint32_t remote_lsraddr, uint16_t remote_labelspace, uint32_t res);
+int addLblRng2AspTlv(mplsLdpAspTlv_t * aspTlv, unsigned int minvpi,
+  unsigned int minvci, unsigned int maxvpi, unsigned int maxvci);
+int addLblRng2FspTlv(mplsLdpFspTlv_t * fspTlv, unsigned int resmin,
+  unsigned int len, unsigned int mindlci, unsigned int resmax,
+
+  unsigned int maxdlci);
+int setupAspTlv(mplsLdpAspTlv_t * aspTlv, uint8_t merge, uint8_t direction);
+int setupFspTlv(mplsLdpFspTlv_t * fspTlv, uint8_t merge, uint8_t direction);
+int setupFecTlv(mplsLdpFecTlv_t * fecTlv);
+
+
+#if 0
+  mplsFecElement_t * createFecElemFromFecType(struct mpls_fec *fec);
+
+mplsFecElement_t * createFecElemFromRoute(routeT * r);
+void copyLabelType2MapLabelTlv(struct mpls_label *label,
+
+  mplsLdpLblMapMsg_t * lblMap);
+void copyAtmLblTlv2MplsLabel(mplsLdpAtmLblTlv_t * atmLblTlv,
+
+  struct mpls_label *label);
+void copyFrLblTlv2MplsLabel(mplsLdpFrLblTlv_t * frLblTlv,
+
+  struct mpls_label *label);
+void copyGenLblTlv2MplsLabel(mplsLdpGenLblTlv_t * genLblTlv,
+
+  struct mpls_label *label); 
+#endif /*  */
+int addFecElem2FecTlv(mplsLdpFecTlv_t * fecTlv, mplsFecElement_t * elem);
+int setupAtmLblTlv(mplsLdpAtmLblTlv_t * atmLblTlv, int res, int v,
+  unsigned int vpi, unsigned int vci);
+int setupFrLblTlv(mplsLdpFrLblTlv_t * frLblTlv, int res, int len,
+
+  unsigned int dlci);
+int setupGenLblTlv(mplsLdpGenLblTlv_t * genLblTlv, int label);
+int setupHopCountTlv(mplsLdpHopTlv_t * hopCountTlv, unsigned int hopCount);
+int setupPathTlv(mplsLdpPathTlv_t * pathTlv);
+int addLsrId2PathTlv(mplsLdpPathTlv_t * pathTlv, unsigned int lsrId);
+int setupAddrTlv(mplsLdpAdrTlv_t * addrTlv);
+int addAddrElem2AddrTlv(mplsLdpAdrTlv_t * addrTlv, unsigned int addr);
+int setupStatusTlv(mplsLdpStatusTlv_t * statTlv, int fatal, int forward,
+  int status, unsigned int msgId, int msgType);
+int setupExStatusTlv(mplsLdpExStatusTlv_t * exStatus, unsigned int value);
+int setupRetPduTlv(mplsLdpRetPduTlv_t * retPduTvl, unsigned int len,
+  mplsLdpHeader_t * hdr, void *data);
+int setupRetMsgTlv(mplsLdpRetMsgTlv_t * retMsgTlv, unsigned type, unsigned len,
+
+  void *data);
+int setupLspidTlv(mplsLdpLspIdTlv_t * lspidTlv, int res,
+  unsigned int localCrlspId, unsigned int routerId);
+int setupTrafficTlv(mplsLdpTrafficTlv_t * trafficTlv, unsigned char freq,
+  unsigned char res, unsigned char weight, float pdr, float pbs, float cdr,
+  float cbs, float ebs);
+int setupLblMsgIdTlv(mplsLdpLblMsgIdTlv_t * lblMsgIdTlv, unsigned int msgId);
+
+
+#endif /*  */
diff -Naur quagga-0.99.10/ldpd/ldp_peer.c quagga-mpls/ldpd/ldp_peer.c
--- quagga-0.99.10/ldpd/ldp_peer.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_peer.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,222 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdlib.h>
+#include <sys/socket.h>
+#include "ldp_struct.h"
+#include "ldp_entity.h"
+#include "ldp_peer.h"
+#include "ldp_hello.h"
+#include "ldp_buf.h"
+#include "ldp_mesg.h"
+
+#include "mpls_assert.h"
+#include "mpls_fib_impl.h"
+#include "mpls_ifmgr_impl.h"
+#include "mpls_lock_impl.h"
+#include "mpls_timer_impl.h"
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+
+uint32_t _ldp_sub_entity_next_index = 1;
+
+void ldp_peer_retry_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle handle)
+{
+  ldp_peer *p = (ldp_peer *) extra;
+  ldp_global *g = (ldp_global*)handle;
+
+  LDP_ENTER(g->user_data, "ldp_peer_retry_callback");
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_TIMER,
+    "Peer Retry Timer fired: peer(%d)\n", p->index);
+
+  mpls_lock_get(g->global_lock);
+
+  /* JLEU: should I hold a copy to make sure this doens't fail? */
+  ldp_peer_retry_stop(g, p);
+  if (ldp_peer_startup(g, p) == MPLS_FAILURE) {
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+      "Peer startup retry failure: peer (%d)\n", p->index);
+  }
+
+  mpls_lock_release(g->global_lock);
+
+  LDP_EXIT(g->user_data, "ldp_peer_retry_callback");
+}
+
+ldp_peer *ldp_peer_create()
+{
+  ldp_peer *p = (ldp_peer *) mpls_malloc(sizeof(ldp_peer));
+
+  if (p) {
+    memset(p, 0, sizeof(ldp_peer));
+    MPLS_REFCNT_INIT(p, 0);
+    MPLS_LIST_ELEM_INIT(p, _global);
+    p->label_space = -1;
+    p->tx_buffer = ldp_buf_create(MPLS_PDUMAXLEN);
+    p->tx_message = ldp_mesg_create();
+    p->index = _ldp_peer_get_next_index();
+
+    p->oper_state = MPLS_OPER_DOWN;
+    p->target_role = LDP_ACTIVE;
+  }
+  return p;
+}
+
+void ldp_peer_delete(ldp_peer * p)
+{
+  // LDP_PRINT(g->user_data,"peer delete\n");
+  MPLS_REFCNT_ASSERT(p, 0);
+  mpls_free(p->tx_buffer);
+  mpls_free(p->tx_message);
+  mpls_free(p);
+}
+
+mpls_return_enum ldp_peer_startup(ldp_global * g, ldp_peer * p)
+{
+  ldp_entity *e = NULL;
+
+  MPLS_ASSERT(p != NULL && ((e = p->entity) != NULL));
+
+  LDP_ENTER(g->user_data, "ldp_peer_startup");
+
+  p->dest.port = e->remote_udp_port;
+
+  if (p->target_role == LDP_ACTIVE) {
+    if (ldp_hello_send(g, e) == MPLS_FAILURE) {
+      goto ldp_peer_startup_retry;
+    }
+  }
+
+  p->oper_state = MPLS_OPER_UP;
+
+  LDP_EXIT(g->user_data, "ldp_peer_startup");
+
+  return MPLS_SUCCESS;
+
+ldp_peer_startup_retry:
+
+  /* start a timer which will retry peer startup */
+  MPLS_REFCNT_HOLD(p);
+  p->oper_state = MPLS_OPER_DOWN;
+  p->no_route_to_peer_timer = mpls_timer_create(g->timer_handle, MPLS_UNIT_SEC,
+    g->no_route_to_peer_time, (void *)p, g, ldp_peer_retry_callback);
+
+  if (mpls_timer_handle_verify(g->timer_handle, p->no_route_to_peer_timer) ==
+    MPLS_BOOL_FALSE) {
+    MPLS_REFCNT_RELEASE(p, ldp_peer_delete);
+    LDP_EXIT(g->user_data, "ldp_peer_startup-error");
+    return MPLS_FAILURE;
+  }
+  mpls_timer_start(g->timer_handle, p->no_route_to_peer_timer, MPLS_TIMER_ONESHOT);
+
+  LDP_EXIT(g->user_data, "ldp_peer_startup");
+
+  return MPLS_SUCCESS;
+}
+
+void ldp_peer_retry_stop(ldp_global * g, ldp_peer * p)
+{
+  MPLS_ASSERT(p != NULL);
+
+  LDP_ENTER(g->user_data, "ldp_peer_retry_stop");
+
+  if (mpls_timer_handle_verify(g->timer_handle, p->no_route_to_peer_timer) ==
+    MPLS_BOOL_TRUE) {
+    mpls_timer_stop(g->timer_handle, p->no_route_to_peer_timer);
+    mpls_timer_delete(g->timer_handle, p->no_route_to_peer_timer);
+    p->no_route_to_peer_timer = 0;
+    MPLS_REFCNT_RELEASE(p, ldp_peer_delete);
+    MPLS_ASSERT(p != NULL);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_peer_retry_stop");
+}
+
+void ldp_peer_send_stop(ldp_global * g, ldp_peer * p)
+{
+  ldp_entity *e = NULL;
+
+  MPLS_ASSERT(p != NULL && (e = p->entity) != NULL);
+
+  LDP_ENTER(g->user_data, "ldp_peer_send_stop");
+
+  if (mpls_timer_handle_verify(g->timer_handle, p->hellotime_send_timer) ==
+    MPLS_BOOL_TRUE) {
+    mpls_timer_stop(g->timer_handle, p->hellotime_send_timer);
+    mpls_timer_delete(g->timer_handle, p->hellotime_send_timer);
+    p->hellotime_send_timer_duration = 0;
+    p->hellotime_send_timer = 0;
+    MPLS_REFCNT_RELEASE(e, ldp_entity_delete);
+    MPLS_ASSERT(e != NULL);
+  }
+  if (p->hello != NULL) {
+    ldp_mesg_delete(p->hello);
+    p->hello = NULL;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_peer_send_stop");
+}
+
+mpls_return_enum ldp_peer_shutdown(ldp_global * g, ldp_peer * p)
+{
+  LDP_ENTER(g->user_data, "ldp_peer_shutdown");
+
+  p->oper_state = MPLS_OPER_DOWN;
+  ldp_peer_send_stop(g, p);
+  ldp_peer_retry_stop(g, p);
+
+  LDP_EXIT(g->user_data, "ldp_peer_shutdown");
+  return MPLS_SUCCESS;
+}
+
+mpls_bool ldp_peer_is_active(ldp_peer * p)
+{
+  if (p && p->entity && p->entity->admin_state == MPLS_ADMIN_ENABLE)
+    return MPLS_BOOL_TRUE;
+
+  return MPLS_BOOL_FALSE;
+}
+
+mpls_return_enum _ldp_peer_add_entity(ldp_peer * p, ldp_entity * e)
+{
+  if (p && e) {
+    MPLS_REFCNT_HOLD(e);
+    p->entity = e;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum _ldp_peer_del_entity(ldp_peer * p)
+{
+  if (p && p->entity) {
+    MPLS_REFCNT_RELEASE(p->entity, ldp_entity_delete);
+    p->entity = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+ldp_entity *ldp_peer_get_entity(ldp_peer * p)
+{
+  return p->entity;
+}
+
+uint32_t _ldp_peer_get_next_index()
+{
+  uint32_t retval = _ldp_sub_entity_next_index;
+
+  _ldp_sub_entity_next_index++;
+  if (retval > _ldp_sub_entity_next_index) {
+    _ldp_sub_entity_next_index = 1;
+  }
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_peer.h quagga-mpls/ldpd/ldp_peer.h
--- quagga-0.99.10/ldpd/ldp_peer.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_peer.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,29 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_PEER_H_
+#define _LDP_PEER_H_
+
+#include "ldp_struct.h"
+
+extern ldp_peer *ldp_peer_create();
+extern void ldp_peer_delete(ldp_peer * p);
+extern mpls_return_enum ldp_peer_startup(ldp_global * g, ldp_peer * p);
+extern mpls_return_enum ldp_peer_shutdown(ldp_global * g, ldp_peer * p);
+extern mpls_bool ldp_peer_is_active(ldp_peer * p);
+extern mpls_return_enum _ldp_peer_add_entity(ldp_peer * p, ldp_entity * e);
+extern mpls_return_enum _ldp_peer_del_entity(ldp_peer * p);
+extern ldp_entity *ldp_peer_get_entity(ldp_peer * p);
+extern uint32_t _ldp_peer_get_next_index();
+extern void ldp_peer_retry_stop(ldp_global * g, ldp_peer * p);
+extern void ldp_peer_send_stop(ldp_global * g, ldp_peer * p);
+extern void ldp_peer_retry_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle g);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_remote_peer.c quagga-mpls/ldpd/ldp_remote_peer.c
--- quagga-0.99.10/ldpd/ldp_remote_peer.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_remote_peer.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,129 @@
+#include <zebra.h>
+#include "memory.h"
+
+#include "ldp.h"
+#include "ldp_cfg.h"
+#include "ldp_struct.h"
+#include "mpls_compare.h"
+#include "ldp_remote_peer.h"
+
+struct ldp_remote_peer *ldp_remote_peer_find(struct ldp *ldp,
+  struct mpls_dest *dest) {
+  struct ldp_remote_peer *rp;
+  struct listnode *ln;
+
+  for(ALL_LIST_ELEMENTS_RO(ldp->peer_list,ln, rp)) {
+    rp->peer.dest.if_handle = 0;
+    dest->if_handle = 0;
+    if (!mpls_dest_compare(&rp->peer.dest,dest)) {
+      return rp;
+    }
+  }
+  return NULL;
+}
+
+struct ldp_remote_peer *ldp_remote_peer_new(struct ldp *ldp) {
+    struct ldp_remote_peer *rp;
+
+    rp = XMALLOC(MTYPE_LDP, sizeof(struct ldp_remote_peer));
+    memset(rp, 0, sizeof(struct ldp_remote_peer));
+    rp->ldp = ldp;
+
+    rp->admin_up = MPLS_BOOL_TRUE;
+    ldp_entity_set_defaults(&rp->entity);
+
+    return rp;
+}
+
+void ldp_remote_peer_free(struct ldp_remote_peer *rp) {
+    XFREE(MTYPE_LDP, rp);
+}
+
+void ldp_remote_peer_create(struct ldp_remote_peer *rp,
+  struct mpls_dest *dest) {
+    struct in_addr addr;
+    char *dest_name;
+
+    addr.s_addr = htonl(dest->addr.u.ipv4);
+    dest_name = inet_ntoa(addr);
+    strncpy(rp->peer.peer_name,dest_name,IFNAMSIZ);
+    rp->peer.label_space = 0;
+    memcpy(&rp->peer.dest,dest,sizeof(struct mpls_dest));
+
+    ldp_cfg_peer_set(rp->ldp->h, &rp->peer, LDP_CFG_ADD |
+      LDP_IF_CFG_LABEL_SPACE | LDP_PEER_CFG_DEST_ADDR | LDP_PEER_CFG_PEER_NAME);
+
+    rp->entity.sub_index = rp->peer.index;
+    rp->entity.entity_type = LDP_INDIRECT;
+    rp->entity.admin_state = MPLS_OPER_DOWN;
+    rp->entity.transport_address.type = MPLS_FAMILY_NONE;
+
+    ldp_cfg_entity_set(rp->ldp->h, &rp->entity,
+	LDP_CFG_ADD | LDP_ENTITY_CFG_SUB_INDEX |
+	LDP_ENTITY_CFG_ADMIN_STATE | LDP_ENTITY_CFG_TRANS_ADDR);
+
+    ldp_cfg_entity_get(rp->ldp->h, &rp->entity, 0xFFFFFFFF);
+    ldp_cfg_peer_get(rp->ldp->h, &rp->peer, 0xFFFFFFFF);
+
+    ldp_remote_peer_admin_state_finish(rp);
+}
+
+void ldp_remote_peer_delete(struct ldp_remote_peer *rp) {
+    rp->entity.admin_state = MPLS_OPER_DOWN;
+
+    if (rp->ldp) {
+	ldp_remote_peer_admin_state_start(rp);
+	ldp_cfg_entity_set(rp->ldp->h, &rp->entity, LDP_CFG_DEL);
+	ldp_cfg_peer_set(rp->ldp->h, &rp->peer, LDP_CFG_DEL);
+    }
+    rp->entity.index = 0;
+    rp->peer.index = 0;
+}
+
+int ldp_remote_peer_startup(struct ldp_remote_peer *rp) {
+    if (!rp->peer.index) {
+	return MPLS_FAILURE;
+    }
+
+    rp->entity.admin_state = MPLS_OPER_UP;
+    ldp_cfg_entity_set(rp->ldp->h, &rp->entity, LDP_ENTITY_CFG_ADMIN_STATE);
+
+    return MPLS_SUCCESS;
+}
+
+int ldp_remote_peer_shutdown(struct ldp_remote_peer *rp) {
+    if (!rp->peer.index) {
+	return MPLS_FAILURE;
+    }
+
+    rp->entity.admin_state = MPLS_ADMIN_DISABLE;
+    ldp_cfg_entity_set(rp->ldp->h, &rp->entity, LDP_ENTITY_CFG_ADMIN_STATE);
+
+    return MPLS_SUCCESS;
+}
+
+int ldp_remote_peer_admin_state_start(struct ldp_remote_peer *rp) {
+  if (rp->admin_up == MPLS_BOOL_TRUE) {
+    return ldp_remote_peer_shutdown(rp);
+  }
+  return MPLS_SUCCESS;
+}
+
+int ldp_remote_peer_admin_state_finish(struct ldp_remote_peer *rp) {
+  if (rp->admin_up == MPLS_BOOL_TRUE) {
+    return ldp_remote_peer_startup(rp);
+  }
+  return MPLS_SUCCESS;
+}
+
+void ldp_remote_peer_up(struct ldp_remote_peer *rp) {
+    if (rp->ldp && rp->admin_up == MPLS_BOOL_TRUE) {
+	ldp_remote_peer_startup(rp);
+    }
+}
+
+void ldp_remote_peer_down(struct ldp_remote_peer *rp) {
+    if (rp->ldp && rp->admin_up == MPLS_BOOL_TRUE) {
+	ldp_remote_peer_shutdown(rp);
+    }
+}
diff -Naur quagga-0.99.10/ldpd/ldp_remote_peer.h quagga-mpls/ldpd/ldp_remote_peer.h
--- quagga-0.99.10/ldpd/ldp_remote_peer.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_remote_peer.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,28 @@
+#ifndef LDP_REMOTE_PEER_H
+#define LDP_REMOTE_PEER_H
+
+#include "ldp_struct.h"
+
+struct ldp_remote_peer {
+    struct ldp *ldp;
+    ldp_entity entity;
+    ldp_peer peer;
+    mpls_bool admin_up;
+};
+
+struct ldp_remote_peer *ldp_remote_peer_find(struct ldp*, struct mpls_dest*);
+struct ldp_remote_peer *ldp_remote_peer_new(struct ldp *ldp);
+void ldp_remote_peer_free(struct ldp_remote_peer *rp);
+
+void ldp_remote_peer_up(struct ldp_remote_peer *rp);
+void ldp_remote_peer_down(struct ldp_remote_peer *rp);
+
+int ldp_remote_peer_startup(struct ldp_remote_peer *rp);
+int ldp_remote_peer_shutdown(struct ldp_remote_peer *rp);
+
+void ldp_remote_peer_create(struct ldp_remote_peer*, struct mpls_dest*);
+void ldp_remote_peer_delete(struct ldp_remote_peer *rp);
+int ldp_remote_peer_admin_state_start(struct ldp_remote_peer *rp);
+int ldp_remote_peer_admin_state_finish(struct ldp_remote_peer *rp);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_resource.c quagga-mpls/ldpd/ldp_resource.c
--- quagga-0.99.10/ldpd/ldp_resource.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_resource.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,78 @@
+
+/*
+ *  Copyright (C) James R. Leu 2001
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_resource.h"
+#include "ldp_tunnel.h"
+
+#include "mpls_assert.h"
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+
+static uint32_t _ldp_resource_next_index = 1;
+
+ldp_resource *ldp_resource_create()
+{
+  ldp_resource *r = (ldp_resource *) mpls_malloc(sizeof(ldp_resource));
+
+  if (r) {
+    memset(r, 0, sizeof(ldp_resource));
+    MPLS_REFCNT_INIT(r, 0);
+    MPLS_LIST_ELEM_INIT(r, _global);
+
+    r->index = _ldp_resource_get_next_index();
+  }
+  return r;
+}
+
+void ldp_resource_delete(ldp_resource * r)
+{
+  // LDP_PRINT(g->user_data,"resource delete\n");
+  MPLS_REFCNT_ASSERT(r, 0);
+  mpls_free(r);
+}
+
+uint32_t _ldp_resource_get_next_index()
+{
+  uint32_t retval = _ldp_resource_next_index;
+
+  _ldp_resource_next_index++;
+  if (retval > _ldp_resource_next_index) {
+    _ldp_resource_next_index = 1;
+  }
+  return retval;
+}
+
+mpls_return_enum _ldp_resource_add_tunnel(ldp_resource * r, ldp_tunnel * t)
+{
+  if (r && t) {
+    MPLS_REFCNT_HOLD(t);
+    r->tunnel = t;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum _ldp_resource_del_tunnel(ldp_resource * r)
+{
+  if (r && r->tunnel) {
+    MPLS_REFCNT_RELEASE(r->tunnel, ldp_tunnel_delete);
+    r->tunnel = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_bool ldp_resource_in_use(ldp_resource * r)
+{
+  if (r->tunnel && (r->tunnel->admin_state == MPLS_ADMIN_ENABLE)) {
+    return MPLS_BOOL_TRUE;
+  }
+  return MPLS_BOOL_FALSE;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_resource.h quagga-mpls/ldpd/ldp_resource.h
--- quagga-0.99.10/ldpd/ldp_resource.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_resource.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,26 @@
+
+/*
+ *  Copyright (C) James R. Leu 2001
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_RESOURCE_H_
+#define _LDP_RESOURCE_H_
+
+#include "ldp_struct.h"
+
+extern ldp_resource *ldp_resource_create();
+extern void ldp_resource_delete(ldp_resource * r);
+extern uint32_t _ldp_resource_get_next_index();
+
+extern mpls_return_enum _ldp_resource_add_tunnel(ldp_resource * r,
+
+  ldp_tunnel * t);
+extern mpls_return_enum _ldp_resource_del_tunnel(ldp_resource * r);
+
+extern mpls_bool ldp_resource_in_use(ldp_resource * r);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_session.c quagga-mpls/ldpd/ldp_session.c
--- quagga-0.99.10/ldpd/ldp_session.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_session.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,751 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <stdlib.h>
+#include "ldp_struct.h"
+#include "ldp_outlabel.h"
+#include "ldp_session.h"
+#include "ldp_entity.h"
+#include "ldp_inlabel.h"
+#include "ldp_outlabel.h"
+#include "ldp_addr.h"
+#include "ldp_attr.h"
+#include "ldp_adj.h"
+#include "ldp_mesg.h"
+#include "ldp_buf.h"
+#include "ldp_inet_addr.h"
+#include "ldp_global.h"
+#include "ldp_state_machine.h"
+#include "ldp_label_rel_with.h"
+#include "ldp_label_request.h"
+#include "ldp_label_mapping.h"
+
+#include "mpls_refcnt.h"
+#include "mpls_assert.h"
+#include "mpls_mm_impl.h"
+#include "mpls_timer_impl.h"
+#include "mpls_socket_impl.h"
+#include "mpls_trace_impl.h"
+#include "mpls_ifmgr_impl.h"
+#include "mpls_policy_impl.h"
+#include "mpls_lock_impl.h"
+
+static uint32_t _ldp_session_next_index = 1;
+
+mpls_return_enum ldp_session_attempt_setup(ldp_global *g, ldp_session *s);
+mpls_return_enum ldp_session_backoff_stop(ldp_global * g, ldp_session * s);
+
+static void ldp_session_backoff_callback(mpls_timer_handle timer, void *extra,
+  mpls_cfg_handle handle)
+{
+  ldp_session *s = (ldp_session *)extra;
+  ldp_global *g = (ldp_global*)handle;
+
+  LDP_ENTER(g->user_data, "ldp_session_backoff");
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_TIMER,
+    "Session Backoff Timer fired: session(%s)\n", s->session_name);
+
+  mpls_lock_get(g->global_lock);
+
+  s->backoff_timer = 0;
+
+  if (s->oper_role == LDP_ACTIVE) {
+    if (ldp_session_attempt_setup(g, s) != MPLS_SUCCESS) {
+      s->backoff += g->backoff_step;
+      s->backoff_timer = timer;
+      mpls_timer_start(g->timer_handle, timer, MPLS_TIMER_ONESHOT);
+
+      LDP_EXIT(g->user_data, "ldp_session_backoff-error");
+
+      goto ldp_session_backoff_end;
+    }
+  } else if (s->oper_role == LDP_PASSIVE) {
+    /* this is a passive session that never received an init, kill it
+     * session current on the global list and the timer holds a refcnt.
+     * shutdown takes this session off of the global list, so when the
+     * timer refcnt is released the session will be deleted */
+    ldp_session_shutdown(g, s, MPLS_BOOL_TRUE);
+  } else {
+    MPLS_ASSERT(0);
+  }
+
+  mpls_timer_stop(g->timer_handle, timer);
+  mpls_timer_delete(g->timer_handle, timer);
+  MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+
+ldp_session_backoff_end:
+
+  mpls_lock_release(g->global_lock);
+
+  LDP_EXIT(g->user_data, "ldp_session_backoff");
+}
+
+ldp_session *ldp_session_create()
+{
+  ldp_session *s = (ldp_session *) mpls_malloc(sizeof(ldp_session));
+
+  if (s) {
+    memset(s, 0, sizeof(ldp_session));
+    MPLS_REFCNT_INIT(s, 0);
+    MPLS_LIST_ELEM_INIT(s, _global);
+    MPLS_LIST_INIT(&s->outlabel_root, ldp_outlabel);
+    MPLS_LIST_INIT(&s->attr_root, ldp_attr);
+    MPLS_LIST_INIT(&s->adj_root, ldp_adj);
+    mpls_link_list_init(&s->inlabel_root);
+    mpls_link_list_init(&s->addr_root);
+
+    s->on_global = MPLS_BOOL_FALSE;
+    s->tx_buffer = ldp_buf_create(MPLS_PDUMAXLEN);
+    s->tx_message = ldp_mesg_create();
+    s->index = _ldp_session_get_next_index();
+    s->oper_role = LDP_NONE;
+  }
+  return s;
+}
+
+mpls_return_enum ldp_session_attempt_setup(ldp_global *g, ldp_session *s) {
+  mpls_socket_handle socket = mpls_socket_create_tcp(g->socket_handle);
+  mpls_return_enum retval;
+
+  LDP_ENTER(g->user_data, "ldp_session_attempt_setup");
+
+  if (mpls_socket_handle_verify(g->socket_handle, socket) == MPLS_BOOL_FALSE) {
+    return MPLS_FAILURE;
+  }
+  if (mpls_socket_options(g->socket_handle, socket, MPLS_SOCKOP_NONBLOCK) ==
+    MPLS_FAILURE) {
+    goto ldp_session_attempt_setup_error;
+  }
+
+  retval = mpls_socket_tcp_connect(g->socket_handle, socket, &s->remote_dest);
+
+  switch (retval) {
+    case MPLS_NON_BLOCKING:
+      {
+	LDP_TRACE_OUT(g->user_data,
+	  "ldp_session_attempt_setup: MPLS_NON_BLOCKING\n");
+        mpls_socket_writelist_add(g->socket_handle, socket, (void *)s,
+          MPLS_SOCKET_TCP_CONNECT);
+        break;
+      }
+    case MPLS_SUCCESS:
+      {
+	LDP_TRACE_OUT(g->user_data,
+	  "ldp_session_attempt_setup: MPLS_SUCCESS\n");
+        if (ldp_state_machine(g, s, NULL, NULL, LDP_EVENT_CONNECT, NULL,
+            NULL) == MPLS_FAILURE) {
+          goto ldp_session_attempt_setup_error;
+        }
+        break;
+      }
+    default:
+      {
+	LDP_TRACE_OUT(g->user_data,
+	  "ldp_session_attempt_setup: MPLS_FAILURE\n");
+        goto ldp_session_attempt_setup_error;
+      }
+      break;
+  }
+
+  s->socket = socket;
+  LDP_EXIT(g->user_data, "ldp_session_attempt_setup");
+  return MPLS_SUCCESS;
+
+ldp_session_attempt_setup_error:
+
+  mpls_socket_close(g->socket_handle, socket);
+  LDP_EXIT(g->user_data, "ldp_session_attempt_setup");
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_session_create_active(ldp_global * g, ldp_adj * a)
+{
+  mpls_return_enum retval = MPLS_FAILURE;
+  mpls_inet_addr *addr = NULL;
+  ldp_session *s = NULL;
+  ldp_adj* ap;
+
+  MPLS_ASSERT(g && a && (!a->session));
+
+  LDP_ENTER(g->user_data, "ldp_session_create_active");
+
+  ap = MPLS_LIST_HEAD(&g->adj);
+  while (ap) {
+    if ((!mpls_inet_addr_compare(&ap->remote_lsr_address,
+      &a->remote_lsr_address)) &&
+      ap->remote_label_space == a->remote_label_space &&
+      a->index != ap->index && ap->session) {
+      ldp_adj_add_session(a, ap->session);
+      retval = MPLS_SUCCESS;
+      goto ldp_session_create_active;
+    }
+    ap = MPLS_LIST_NEXT(&g->adj, ap, _global);
+  }
+
+  if ((s = ldp_session_create())) {
+    if (a->remote_transport_address.type != MPLS_FAMILY_NONE) {
+      addr = &a->remote_transport_address;
+    } else {
+      addr = &a->remote_source_address;
+    }
+
+    _ldp_global_add_session(g, s);
+    ldp_adj_add_session(a, s);
+    s->state = LDP_STATE_NON_EXIST;
+
+    memcpy(&s->remote_dest.addr, addr, sizeof(mpls_inet_addr));
+    s->remote_dest.port = s->cfg_peer_tcp_port;
+
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_session_create_active: (%d) changed to NON_EXIST\n", s->index);
+
+    if (ldp_session_attempt_setup(g, s) != MPLS_SUCCESS) {
+      /* go into backoff */
+      ldp_session_backoff_start(g, s);
+    }
+    retval = MPLS_SUCCESS;
+  }
+
+ldp_session_create_active:
+
+  LDP_EXIT(g->user_data, "ldp_session_create_active");
+  return retval;
+}
+
+ldp_session *ldp_session_create_passive(ldp_global * g,
+  mpls_socket_handle socket, mpls_dest * from)
+{
+  ldp_session *s = NULL;
+
+  MPLS_ASSERT(g);
+
+  LDP_ENTER(g->user_data, "ldp_session_create_passive");
+
+  if ((s = ldp_session_create())) {
+    s->socket = socket;
+    s->state = LDP_STATE_NON_EXIST;
+
+    if (mpls_socket_options(g->socket_handle, socket, MPLS_SOCKOP_NONBLOCK) ==
+      MPLS_SUCCESS) {
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+        "ldp_session_create_passive: (%d) changed to NON_EXIST\n", s->index);
+      _ldp_global_add_session(g, s);
+    } else {
+      ldp_session_delete(s);
+      s = NULL;
+    }
+  }
+
+  LDP_EXIT(g->user_data, "ldp_session_create_passive (%p)", s);
+
+  return s;
+}
+
+void ldp_session_delete(ldp_session * s)
+{
+  LDP_PRINT(NULL, "session delete");
+  MPLS_REFCNT_ASSERT(s, 0);
+  mpls_free(s);
+}
+
+mpls_return_enum ldp_session_startup(ldp_global * g, ldp_session * s)
+{
+  mpls_return_enum retval = MPLS_FAILURE;
+  ldp_addr *addr;
+
+  void (*callback) (mpls_timer_handle timer, void *extra, mpls_cfg_handle g);
+
+  MPLS_ASSERT(s && g && (s->oper_role != LDP_NONE));
+
+  LDP_ENTER(g->user_data, "ldp_session_startup");
+
+  /* when we make it to operational, get rid of any backoff timers */
+  ldp_session_backoff_stop(g, s);
+  s->state = LDP_STATE_OPERATIONAL;
+  s->oper_up = time(NULL);
+
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+    "ldp_session_startup: (%d) changed to OPERATIONAL\n", s->index);
+
+  /*
+   * if configured to distribute addr messages walk the if table
+   * and send an addr message for each
+   */
+  if (g->send_address_messages) {
+    addr = MPLS_LIST_HEAD(&g->addr);
+    while (addr) {
+      /* only locally attached addrs will have a valid iff */
+      if (addr->iff) {
+        if (ldp_addr_send(g, s, &addr->address) != MPLS_SUCCESS)
+          goto ldp_session_startup_end;
+      }
+      addr = MPLS_LIST_NEXT(&g->addr, addr, _global);
+    }
+  }
+
+  /* depending on the mode, grab a pointer to the correct callback */
+  switch (s->oper_distribution_mode) {
+    case LDP_DISTRIBUTION_ONDEMAND:
+      callback = ldp_label_request_initial_callback;
+      break;
+    case LDP_DISTRIBUTION_UNSOLICITED:
+      callback = ldp_label_mapping_initial_callback;
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+
+  /*
+   * create a timer which will go about "chunking" the initial
+   * set of requests or mappings
+   */
+  MPLS_REFCNT_HOLD(s);
+  s->initial_distribution_timer = mpls_timer_create(g->timer_handle,
+    MPLS_UNIT_SEC, LDP_REQUEST_CHUNK, (void *)s, g, callback);
+
+  if (mpls_timer_handle_verify(g->timer_handle,
+      s->initial_distribution_timer) == MPLS_BOOL_FALSE) {
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+
+    LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+      "ldp_session_startup: initial distrib error(%d)\n", s->index);
+
+    /* timer error, we might as well shutdown the session, it's usless */
+    s->shutdown_notif = LDP_NOTIF_INTERNAL_ERROR;
+    s->shutdown_fatal = MPLS_BOOL_TRUE;
+    retval = MPLS_FAILURE;
+  } else {
+    mpls_timer_start(g->timer_handle, s->initial_distribution_timer,
+      MPLS_TIMER_ONESHOT);
+    retval = MPLS_SUCCESS;
+  }
+
+ldp_session_startup_end:
+
+  LDP_EXIT(g->user_data, "ldp_session_startup");
+
+  return retval;
+}
+
+void ldp_session_shutdown(ldp_global * g, ldp_session * s, mpls_bool complete)
+{
+  ldp_addr *a = NULL;
+  ldp_attr *attr = NULL;
+  ldp_attr *nattr = NULL;
+  ldp_adj* ap;
+
+  MPLS_ASSERT(s);
+
+  LDP_ENTER(g->user_data, "ldp_session_shutdown");
+
+  /*
+   * hold a refcount so this session doesn't disappear on us
+   * while cleaning up
+   */
+  MPLS_REFCNT_HOLD(s);
+
+  s->state = LDP_STATE_NONE;
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+    "ldp_session_shutdown: (%d) changed to NONE\n", s->index);
+
+  /*
+   * kill the timers for the session
+   */
+  if (mpls_timer_handle_verify(g->timer_handle, s->keepalive_recv_timer) ==
+    MPLS_BOOL_TRUE) {
+    mpls_timer_stop(g->timer_handle, s->keepalive_recv_timer);
+    mpls_timer_delete(g->timer_handle, s->keepalive_recv_timer);
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+    s->keepalive_recv_timer = (mpls_timer_handle) 0;
+  }
+  if (mpls_timer_handle_verify(g->timer_handle, s->keepalive_send_timer) ==
+    MPLS_BOOL_TRUE) {
+    mpls_timer_stop(g->timer_handle, s->keepalive_send_timer);
+    mpls_timer_delete(g->timer_handle, s->keepalive_send_timer);
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+    s->keepalive_send_timer = (mpls_timer_handle) 0;
+  }
+  if (mpls_timer_handle_verify(g->timer_handle,s->initial_distribution_timer) ==
+    MPLS_BOOL_TRUE) {
+    mpls_timer_stop(g->timer_handle, s->initial_distribution_timer);
+    mpls_timer_delete(g->timer_handle, s->initial_distribution_timer);
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+    s->initial_distribution_timer = (mpls_timer_handle) 0;
+  }
+
+  /*
+   * get rid of the socket
+   */
+  if (mpls_socket_handle_verify(g->socket_handle, s->socket) ==
+    MPLS_BOOL_TRUE) {
+    mpls_socket_readlist_del(g->socket_handle, s->socket);
+    mpls_socket_close(g->socket_handle, s->socket);
+  }
+
+  /*
+   * get rid of out cached keepalive
+   */
+  if (s->keepalive != NULL) {
+    ldp_mesg_delete(s->keepalive);
+    s->keepalive = NULL;
+  }
+
+  ldp_session_backoff_stop(g,s);
+
+  attr = MPLS_LIST_HEAD(&g->attr);
+  while (attr != NULL) {
+    nattr = MPLS_LIST_NEXT(&g->attr, attr, _global);
+    if (attr->session && attr->session->index == s->index) {
+      /*
+       * ldp_attr_remove_complete removed everythig associated with the attr.
+       * in and out labels, and cross connects as well
+       */
+      ldp_attr_remove_complete(g, attr, complete);
+    }
+    attr = nattr;
+  }
+
+  /*
+   * clean up the addrs we created
+   */
+  while ((a = (ldp_addr*)mpls_link_list_head_data(&s->addr_root))) {
+    ldp_session_del_addr(g, s, a);
+  }
+
+  /*
+   * if we have an adj AND we are shuting down for a protocol reason, start a
+   * backoff timer, so we can try again in the near future
+   */
+  if ((complete == MPLS_BOOL_TRUE) || (s->oper_role != LDP_ACTIVE)) {
+    while ((ap = MPLS_LIST_HEAD(&s->adj_root))) {
+      ldp_adj_del_session(ap, s);
+    }
+
+    if (s->on_global == MPLS_BOOL_TRUE) {
+      _ldp_global_del_session(g, s);
+    }
+  } else {
+    if (s->oper_role == LDP_ACTIVE) {
+      ldp_session_backoff_start(g, s);
+    }
+  }
+
+  /*
+   * it is safe to release this refcnt now, if it is the last one, the
+   * session will be deleted (this will be the last one in the case of
+   * 'complete' == MPLS_BOOL_TRUE
+   */
+  MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+
+  LDP_EXIT(g->user_data, "ldp_session_shutdown");
+}
+
+mpls_return_enum ldp_session_maintain_timer(ldp_global * g, ldp_session * s,
+  int flag)
+{
+  mpls_return_enum result = MPLS_FAILURE;
+
+  LDP_ENTER(g->user_data, "ldp_session_maintain_timer");
+
+  /*
+   * all session keepalive maintainance comes through here (SEND and RECV)
+   */
+  if (flag == LDP_KEEPALIVE_RECV) {
+    mpls_timer_stop(g->timer_handle, s->keepalive_recv_timer);
+    result = mpls_timer_start(g->timer_handle, s->keepalive_recv_timer,
+      MPLS_TIMER_ONESHOT);
+  } else {
+    mpls_timer_stop(g->timer_handle, s->keepalive_send_timer);
+    result = mpls_timer_start(g->timer_handle, s->keepalive_send_timer,
+      MPLS_TIMER_REOCCURRING);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_session_maintain_timer");
+
+  return result;
+}
+
+void ldp_session_add_outlabel(ldp_session * s, ldp_outlabel * o)
+{
+  MPLS_ASSERT(s && o);
+  MPLS_REFCNT_HOLD(o);
+  MPLS_LIST_ADD_HEAD(&s->outlabel_root, o, _session, ldp_outlabel);
+  _ldp_outlabel_add_session(o, s);
+}
+
+void ldp_session_del_outlabel(ldp_global * g,ldp_session * s, ldp_outlabel * o)
+{
+  MPLS_ASSERT(s && o);
+  MPLS_LIST_REMOVE(&s->outlabel_root, o, _session);
+  _ldp_outlabel_del_session(o);
+  MPLS_REFCNT_RELEASE2(g, o, ldp_outlabel_delete);
+}
+
+mpls_return_enum ldp_session_add_inlabel(ldp_global * g,ldp_session * s, ldp_inlabel * i)
+{
+  MPLS_ASSERT(s && i);
+  MPLS_REFCNT_HOLD(i);
+  if (mpls_link_list_add_tail(&s->inlabel_root, i) == MPLS_SUCCESS) {
+    if (_ldp_inlabel_add_session(i, s) == MPLS_SUCCESS) {
+      return MPLS_SUCCESS;
+    }
+    mpls_link_list_remove_data(&s->inlabel_root, i);
+  }
+  MPLS_REFCNT_RELEASE2(g, i, ldp_inlabel_delete);
+  return MPLS_FAILURE;
+}
+
+void ldp_session_del_inlabel(ldp_global * g,ldp_session * s, ldp_inlabel * i)
+{
+  MPLS_ASSERT(s && i);
+  mpls_link_list_remove_data(&s->inlabel_root, i);
+  _ldp_inlabel_del_session(i, s);
+  MPLS_REFCNT_RELEASE2(g, i, ldp_inlabel_delete)
+}
+
+void _ldp_session_add_attr(ldp_session * s, ldp_attr * a)
+{
+  MPLS_ASSERT(s && a);
+  MPLS_REFCNT_HOLD(a);
+  MPLS_LIST_ADD_HEAD(&s->attr_root, a, _session, ldp_attr);
+}
+
+void _ldp_session_del_attr(ldp_global *g, ldp_session * s, ldp_attr * a)
+{
+  MPLS_ASSERT(s && a);
+  MPLS_LIST_REMOVE(&s->attr_root, a, _session);
+  MPLS_REFCNT_RELEASE2(g, a, ldp_attr_delete);
+}
+
+mpls_return_enum ldp_session_add_addr(ldp_global *g, ldp_session * s,
+  ldp_addr * a)
+{
+  struct mpls_link_list_node *lln;
+  struct mpls_link_list_node *llnp;
+  ldp_addr *data;
+
+  MPLS_ASSERT(s && a);
+
+  MPLS_REFCNT_HOLD(a);
+  lln = mpls_link_list_node_create(a);
+  if (lln) {
+    if (_ldp_addr_add_session(a, s) == MPLS_SUCCESS) {
+      MPLS_LINK_LIST_LOOP(&s->addr_root, data, llnp) {
+        if (data->index > a->index) {
+          mpls_link_list_add_node_before(&s->addr_root, llnp, lln);
+          return MPLS_SUCCESS;
+        }
+      }
+
+      mpls_link_list_add_node_tail(&s->addr_root, lln);
+      return MPLS_SUCCESS;
+    }
+    mpls_link_list_node_delete(lln);
+  }
+  MPLS_REFCNT_RELEASE2(g, a, ldp_addr_delete);
+  return MPLS_FAILURE;
+}
+
+void ldp_session_del_addr(ldp_global *g, ldp_session * s, ldp_addr * a) {
+  MPLS_ASSERT(s && a);
+  mpls_link_list_remove_data(&s->addr_root, a);
+  _ldp_addr_del_session(a, s);
+  MPLS_REFCNT_RELEASE2(g, a, ldp_addr_delete);
+}
+
+void _ldp_session_add_adj(ldp_session * s, ldp_adj * a)
+{
+  ldp_adj *ap = NULL;
+  struct in_addr lsr_address;
+
+  MPLS_ASSERT(s && a);
+  MPLS_REFCNT_HOLD(a);
+
+  s->cfg_remote_in_ttl_less_domain = a->entity->remote_in_ttl_less_domain;
+  s->cfg_distribution_mode = a->entity->label_distribution_mode;
+  s->cfg_loop_detection_mode = a->entity->loop_detection_mode;
+  s->cfg_label_request_count = a->entity->label_request_count;
+  s->cfg_label_request_timer = a->entity->label_request_timer;
+  s->cfg_label_space = ldp_entity_label_space(a->entity);
+  s->cfg_path_vector_limit = a->entity->path_vector_limit;
+  s->cfg_hop_count_limit = a->entity->hop_count_limit;
+  s->cfg_peer_tcp_port = a->entity->remote_tcp_port;
+  s->cfg_keepalive = a->entity->keepalive_timer;
+  s->cfg_max_pdu = a->entity->max_pdu;
+
+  lsr_address.s_addr = htonl(a->remote_lsr_address.u.ipv4);
+  sprintf(s->session_name, "%s:%d", inet_ntoa(lsr_address),
+    a->remote_label_space);
+  s->oper_role = a->role;
+
+  ap = MPLS_LIST_HEAD(&s->adj_root);
+  while (ap) {
+    if (ap->index > a->index) {
+      MPLS_LIST_INSERT_BEFORE(&s->adj_root, ap, a, _session);
+      return;
+    }
+    ap = MPLS_LIST_NEXT(&s->adj_root, ap, _session);
+  }
+  MPLS_LIST_ADD_TAIL(&s->adj_root, a, _session, ldp_adj);
+}
+
+void _ldp_session_del_adj(ldp_session * s, ldp_adj * a)
+{
+  MPLS_ASSERT(s && a);
+  MPLS_LIST_REMOVE(&s->adj_root, a, _session);
+  MPLS_REFCNT_RELEASE(a, ldp_adj_delete);
+}
+
+uint32_t _ldp_session_get_next_index()
+{
+  uint32_t retval = _ldp_session_next_index;
+
+  _ldp_session_next_index++;
+  if (retval > _ldp_session_next_index) {
+    _ldp_session_next_index = 1;
+  }
+  return retval;
+}
+
+mpls_return_enum ldp_session_find_raddr_index(ldp_session * s, uint32_t index,
+  ldp_addr ** addr)
+{
+  struct mpls_link_list_node *lln;
+  ldp_addr *a = NULL;
+
+  if (s && index > 0) {
+    /* because we sort our inserts by index, this lets us know
+       if we've "walked" past the end of the list */
+
+    if (mpls_link_list_isempty(&s->addr_root)) {
+      *addr = NULL;
+      return MPLS_END_OF_LIST;
+    }
+
+    if ((a = (ldp_addr*)mpls_link_list_tail_data(&s->addr_root))) {
+      if (a->index < index) {
+        *addr = NULL;
+        return MPLS_END_OF_LIST;
+      }
+    }
+
+    MPLS_LINK_LIST_LOOP(&s->addr_root, a, lln) {
+      if (a->index == index) {
+        *addr = a;
+        return MPLS_SUCCESS;
+      }
+    }
+  }
+  *addr = NULL;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_session_backoff_stop(ldp_global * g, ldp_session * s)
+{
+
+  LDP_ENTER(g->user_data, "ldp_session_backoff_stop");
+
+  s->backoff = 0;
+  if (mpls_timer_handle_verify(g->timer_handle, s->backoff_timer) ==
+    MPLS_BOOL_TRUE) {
+
+    mpls_timer_stop(g->timer_handle, s->backoff_timer);
+    mpls_timer_delete(g->timer_handle, s->backoff_timer);
+    s->backoff_timer = (mpls_timer_handle) 0;
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_session_backoff_stop");
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_session_backoff_start(ldp_global * g, ldp_session * s)
+{
+  mpls_bool valid;
+
+  MPLS_ASSERT(s);
+
+  LDP_ENTER(g->user_data, "ldp_session_backoff_start");
+
+  valid = mpls_timer_handle_verify(g->timer_handle,s->backoff_timer);
+
+  MPLS_ASSERT(valid == MPLS_BOOL_FALSE);
+
+  s->backoff += g->backoff_step;
+
+#if 0 /* if the above assert shouldn't be made this code should be executed */
+  {
+    /* this should never happen, but if so */
+    mpls_timer_stop(g->timer_handle, s->backoff_timer);
+    mpls_timer_delete(g->timer_handle, s->backoff_timer);
+    s->backoff_timer = (mpls_timer_handle) 0;
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+  }
+
+  if (!s) {              /* if we deleted session due to the above RELEASE */
+    LDP_EXIT(g->user_data, "ldp_session_backoff_start-error");
+    return MPLS_FAILURE;
+  }
+#endif
+
+  MPLS_REFCNT_HOLD(s);
+  s->backoff_timer = mpls_timer_create(g->timer_handle, MPLS_UNIT_SEC,
+    s->backoff, (void *)s, g, ldp_session_backoff_callback);
+  if (mpls_timer_handle_verify(g->timer_handle, s->backoff_timer) ==
+    MPLS_BOOL_FALSE) {
+
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+    LDP_EXIT(g->user_data, "ldp_session_backoff_start-error");
+    return MPLS_FAILURE;
+  }
+
+  if (mpls_timer_start(g->timer_handle, s->backoff_timer,
+    MPLS_TIMER_ONESHOT) != MPLS_SUCCESS) {
+
+    mpls_timer_delete(g->timer_handle, s->backoff_timer);
+    MPLS_REFCNT_RELEASE(s, ldp_session_delete);
+    LDP_EXIT(g->user_data, "ldp_session_backoff_start-error");
+    return MPLS_FAILURE;
+  }
+
+  LDP_EXIT(g->user_data, "ldp_session_backoff_start");
+
+  return MPLS_SUCCESS;
+}
+
+ldp_session *ldp_session_for_nexthop(ldp_nexthop *nh)
+{
+  MPLS_ASSERT(nh);
+
+  LDP_ENTER(g->user_data, "ldp_session_for_nexthop: 0x%04d", nh->info.type);
+
+  if (nh->info.type & MPLS_NH_IP) {
+    LDP_PRINT(g->user_data, "ldp_session_for_nexthop-addr: %p %p %p\n",
+      nh, nh->addr, nh->addr->session);
+    if (nh->addr->session) {
+      LDP_EXIT(g->user_data, "ldp_session_for_nexthop-addr: %p",
+	nh->addr->session);
+      return nh->addr->session;
+    }
+  }
+  if (nh->info.type & MPLS_NH_IF) {
+    ldp_session *s = NULL;
+    if (nh->iff && (s = mpls_link_list_head_data(&nh->iff->session_root))) {
+      LDP_EXIT(g->user_data, "ldp_session_for_nexthop-iff");
+      return s;
+    }
+  }
+  if (nh->info.type & MPLS_NH_OUTSEGMENT) {
+    MPLS_ASSERT(0);
+  }
+  LDP_EXIT(g->user_data, "ldp_session_for_nexthop-none");
+  return NULL;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_session.h quagga-mpls/ldpd/ldp_session.h
--- quagga-0.99.10/ldpd/ldp_session.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_session.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,52 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_SESSION_H_
+#define _LDP_SESSION_H_
+
+#include "ldp_struct.h"
+
+extern mpls_return_enum ldp_session_backoff_start(ldp_global * g,
+  ldp_session * s);
+extern mpls_return_enum ldp_session_backoff_stop(ldp_global * g,
+  ldp_session * s);
+extern mpls_return_enum ldp_session_create_active(ldp_global * g, ldp_adj * a);
+extern ldp_session *ldp_session_create_passive(ldp_global * g,
+  mpls_socket_handle socket, mpls_dest * from);
+extern ldp_session *ldp_session_create();
+extern void ldp_session_delete(ldp_session * s);
+extern mpls_return_enum ldp_session_startup(ldp_global * g, ldp_session * s);
+extern void ldp_session_shutdown(ldp_global * g, ldp_session * s, mpls_bool);
+
+extern void _ldp_session_add_attr(ldp_session * s, ldp_attr * a);
+extern void _ldp_session_del_attr(ldp_global *g, ldp_session * s, ldp_attr * a);
+
+extern void ldp_session_add_outlabel(ldp_session * s, ldp_outlabel * o);
+extern void ldp_session_del_outlabel(ldp_global * g, ldp_session * s, ldp_outlabel * o);
+
+extern mpls_return_enum ldp_session_add_inlabel(ldp_global * g, ldp_session * s,
+  ldp_inlabel * i);
+extern void ldp_session_del_inlabel(ldp_global *g, ldp_session * s, ldp_inlabel * i);
+
+extern mpls_return_enum ldp_session_add_addr(ldp_global *g, ldp_session * s, ldp_addr * a);
+extern void ldp_session_del_addr(ldp_global *g, ldp_session * s, ldp_addr * a);
+
+extern void _ldp_session_add_adj(ldp_session * s, ldp_adj * a);
+extern void _ldp_session_del_adj(ldp_session * s, ldp_adj * a);
+
+extern uint32_t _ldp_session_get_next_index();
+extern mpls_return_enum ldp_session_maintain_timer(ldp_global * g,
+  ldp_session * s, int flag);
+
+extern mpls_return_enum ldp_session_find_raddr_index(ldp_session * s,
+  uint32_t index, ldp_addr ** addr);
+
+extern ldp_session *ldp_session_for_nexthop(ldp_nexthop *nh);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_state_funcs.c quagga-mpls/ldpd/ldp_state_funcs.c
--- quagga-0.99.10/ldpd/ldp_state_funcs.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_state_funcs.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,514 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include <sys/socket.h>
+#include "ldp_struct.h"
+#include "ldp_global.h"
+#include "ldp_session.h"
+#include "ldp_entity.h"
+#include "ldp_fec.h"
+#include "ldp_adj.h"
+#include "ldp_attr.h"
+#include "ldp_mesg.h"
+#include "ldp_hello.h"
+#include "ldp_init.h"
+#include "ldp_label_rel_with.h"
+#include "ldp_label_mapping.h"
+#include "ldp_label_request.h"
+#include "ldp_addr.h"
+#include "ldp_keepalive.h"
+#include "ldp_label_request.h"
+#include "ldp_label_mapping.h"
+#include "ldp_notif.h"
+#include "ldp_label_abort.h"
+#include "ldp_inet_addr.h"
+
+#include "mpls_assert.h"
+#include "mpls_tree_impl.h"
+#include "mpls_trace_impl.h"
+#include "mpls_socket_impl.h"
+
+mpls_return_enum ldp_state_new_adjacency(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, uint32_t event, ldp_mesg * msg, mpls_dest * from)
+{
+  mpls_inet_addr traddr, lsraddr, *addr;
+  ldp_adj *local_a = NULL;
+  int labelspace;
+  int hellotime;
+  int request = 0;
+  int target = 0;
+  uint32_t csn = 0;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  MPLS_ASSERT(msg && e);
+
+  LDP_ENTER(g->user_data, "ldp_state_new_adjacency");
+
+  ldp_mesg_hdr_get_labelspace(msg, &labelspace);
+  ldp_mesg_hdr_get_lsraddr(msg, &lsraddr);
+  ldp_mesg_hello_get_hellotime(msg, &hellotime);
+  ldp_mesg_hello_get_request(msg, &request);
+  ldp_mesg_hello_get_targeted(msg, &target);
+  ldp_mesg_hello_get_csn(msg, &csn);
+
+  if (ldp_mesg_hello_get_traddr(msg, &traddr) == MPLS_FAILURE) {
+    addr = NULL;
+  } else {
+    addr = &traddr;
+  }
+
+  e->mesg_rx++;
+
+  if ((local_a = ldp_adj_create(&from->addr, &lsraddr, labelspace,
+    hellotime, addr, csn)) == NULL) {
+    goto ldp_state_new_adjacency_end;
+  }
+  ldp_entity_add_adj(e, local_a);
+  _ldp_global_add_adj(g, local_a);
+  if (ldp_hello_process(g, local_a, e, hellotime, csn, addr, target,
+    request) != MPLS_SUCCESS) {
+    /* this can fail if we could not create an active session, or
+     * we're getting errored hellos, 
+     * if this fails then undo the e<->a linking (which will delete a) */
+    ldp_entity_del_adj(e, local_a);
+    _ldp_global_del_adj(g, local_a);
+  } else if (ldp_adj_startup(g, local_a, request) != MPLS_SUCCESS) {
+    /* the only way this fail is if a timer could not be created
+     * if this fails then undo the e<->a linking (which will delete a) */
+    ldp_entity_del_adj(e, local_a);
+    _ldp_global_del_adj(g, local_a);
+  } else {
+    /* by this time, we will have a e<->a binding, and some timers,
+     * if we're active, there will also be an active session */
+    retval = MPLS_SUCCESS;
+  }
+
+ldp_state_new_adjacency_end:
+
+  LDP_EXIT(g->user_data, "ldp_state_new_adjacency");
+  return retval;
+}
+
+mpls_return_enum ldp_state_maintainance(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, uint32_t event, ldp_mesg * msg, mpls_dest * from)
+{
+  mpls_inet_addr traddr, *addr;
+  int hellotime;
+  int request = 0;
+  int target = 0;
+  uint32_t csn = 0;
+  mpls_return_enum retval = MPLS_SUCCESS;
+
+  MPLS_ASSERT(msg && e);
+
+  LDP_ENTER(g->user_data, "ldp_state_maintainance");
+
+  if (ldp_mesg_hello_get_hellotime(msg, &hellotime) != MPLS_SUCCESS) {
+    retval = MPLS_FAILURE;
+    goto ldp_state_maintainance_end;
+  }
+
+  ldp_mesg_hello_get_request(msg, &request);
+  ldp_mesg_hello_get_targeted(msg, &target);
+  /* if there isn't a csn in the msg, then csn stays 0 */
+  ldp_mesg_hello_get_csn(msg, &csn);
+  if (ldp_mesg_hello_get_traddr(msg, &traddr) != MPLS_SUCCESS) {
+    addr = NULL;
+  } else {
+    addr = &traddr;
+  }
+
+  if (ldp_hello_process(g, a, e, hellotime, csn, addr, target,
+      request) != MPLS_SUCCESS) {
+    retval = MPLS_FAILURE;
+    goto ldp_state_maintainance_end;
+  }
+  retval = ldp_adj_maintain_timer(g, a);
+  e->mesg_rx++;
+
+ldp_state_maintainance_end:
+
+  LDP_EXIT(g->user_data, "ldp_state_maintainance");
+
+  return retval;
+}
+
+mpls_return_enum ldp_state_recv_init(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, uint32_t event, ldp_mesg * msg, mpls_dest * from)
+{
+  mpls_inet_addr lsraddr;
+  ldp_adj* ap;
+  int labelspace = 0;
+  mpls_bool match = MPLS_BOOL_FALSE;
+
+  MPLS_ASSERT(msg && s);
+
+  LDP_ENTER(g->user_data, "ldp_state_recv_init");
+
+  /* we haven't tied this session to an adj yet, at a minimum we can
+   * now stop the backoff timer we started while waiting for this
+   * init to arrive */
+  ldp_session_backoff_stop(g, s);
+
+  ldp_mesg_hdr_get_lsraddr(msg, &lsraddr);
+  ldp_mesg_hdr_get_labelspace(msg, &labelspace);
+
+  if (s->oper_role != LDP_ACTIVE) {
+    /* sessions being created from the ACTIVE side of an ADJ have already
+     * bound to the session */
+    /* there may be multiple ADJ that are matched! */
+    ap = MPLS_LIST_HEAD(&g->adj);
+    while (ap != NULL) {
+      if ((!mpls_inet_addr_compare(&lsraddr, &ap->remote_lsr_address)) &&
+        labelspace == ap->remote_label_space && !ap->session) {
+        ldp_adj_add_session(ap, s);
+        match = MPLS_BOOL_TRUE;
+      }
+      ap = MPLS_LIST_NEXT(&g->adj, ap, _global);
+    }
+
+    if (match == MPLS_BOOL_FALSE) {
+      LDP_PRINT(g->user_data, "ldp_state_recv_init: cannot find adj\n");
+      s->shutdown_notif = LDP_NOTIF_SESSION_REJECTED_NO_HELLO;
+      s->shutdown_fatal = MPLS_BOOL_FALSE;
+      goto ldp_state_recv_init_shutdown;
+    }
+  }
+
+  if (ldp_init_process(g, s, msg) == MPLS_FAILURE) {
+    LDP_PRINT(g->user_data, "ldp_state_recv_init: invalid INIT parameters\n");
+    /* session shutdown notif info set inside init_process */
+    goto ldp_state_recv_init_shutdown;
+  }
+
+  s->state = LDP_STATE_OPENREC;
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+    "ldp_state_recv_init: (%d) changed to OPENREC\n", s->index);
+
+  if (s->oper_role == LDP_PASSIVE) {
+    if (ldp_init_send(g, s) == MPLS_FAILURE) {
+      LDP_PRINT(g->user_data, "ldp_state_recv_init: unable to send INIT\n");
+      s->shutdown_notif = LDP_NOTIF_INTERNAL_ERROR;
+      s->shutdown_fatal = MPLS_BOOL_TRUE;
+      goto ldp_state_recv_init_shutdown;
+    }
+  }
+  ldp_keepalive_send(g, s);
+
+  LDP_EXIT(g->user_data, "ldp_state_recv_init");
+  return MPLS_SUCCESS;
+
+ldp_state_recv_init_shutdown:
+
+  LDP_EXIT(g->user_data, "ldp_state_recv_init-error");
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_state_connect(ldp_global * g, ldp_session * s, ldp_adj * a,
+  ldp_entity * e, uint32_t event, ldp_mesg * msg, mpls_dest * from)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+
+  LDP_ENTER(g->user_data, "ldp_state_connect");
+
+  mpls_socket_readlist_add(g->socket_handle, s->socket, (void *)s,
+    MPLS_SOCKET_TCP_DATA);
+  s->state = LDP_STATE_INITIALIZED;
+  LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+    "ldp_state_connect: (%d) changed to INITIALIZED\n", s->index);
+
+  /* even though as part of creating an active session, the remote_dest
+   * was filled in, it had port 646 specified. 'from' now contains the
+   * real port info that our TCP session is connected to */
+  if (from) {
+    memcpy(&s->remote_dest, from, sizeof(mpls_dest));
+  }
+
+  if (s->oper_role == LDP_ACTIVE) {
+    if (ldp_init_send(g, s) == MPLS_SUCCESS) {
+      s->state = LDP_STATE_OPENSENT;
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_DEBUG,
+        "ldp_state_connect: (%d) changed to OPENSENT\n", s->index);
+    } else {
+      s->shutdown_notif = LDP_NOTIF_INTERNAL_ERROR;
+      s->shutdown_fatal = MPLS_BOOL_TRUE;
+      retval = MPLS_FAILURE;
+    }
+  } else {
+    /* if this session is passive, we still are not associated with an
+     * adj.  That will happen when we receive an init. There are no timers
+     * running yet, so we need to create a timer, to clean this socket
+     * up, if we do not receive a Init mesg, we'll overload the backoff
+     * timer for this purpose */
+    retval = ldp_session_backoff_start(g, s);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_state_connect");
+
+  return retval;
+}
+
+mpls_return_enum ldp_state_finish_init(ldp_global * g, ldp_session * s,
+  ldp_adj * a, ldp_entity * e, uint32_t event, ldp_mesg * msg, mpls_dest * from)
+{
+  mpls_return_enum retval;
+  MPLS_ASSERT(s);
+
+  LDP_ENTER(g->user_data, "ldp_state_finish_init");
+
+  retval = ldp_session_startup(g, s);
+
+  LDP_EXIT(g->user_data, "ldp_state_finish_init");
+
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_state_process(ldp_global * g, ldp_session * s, ldp_adj * a,
+  ldp_entity * e, uint32_t event, ldp_mesg * msg, mpls_dest * from)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+  ldp_attr *r_attr;
+  mpls_fec fec;
+  int i;
+
+  MPLS_ASSERT(s && msg);
+
+  LDP_ENTER(g->user_data, "ldp_state_process");
+
+  switch (msg->u.generic.flags.flags.msgType) {
+    case MPLS_LBLWITH_MSGTYPE:
+      {
+        mplsLdpLbl_W_R_Msg_t *rw = &msg->u.release;
+	ldp_fec *f;
+
+        for (i = 0; i < rw->fecTlv.numberFecElements; i++) {
+          fec_tlv2mpls_fec(&rw->fecTlv, i, &fec);
+          if (!(r_attr = ldp_attr_create(g, &fec))) {
+            goto ldp_state_process_error;
+          }
+
+          MPLS_REFCNT_HOLD(r_attr);
+
+          rel_with2attr(rw, r_attr);
+	  f = ldp_fec_find2(g, &fec);
+	  MPLS_REFCNT_HOLD(f);
+
+          retval = ldp_label_withdraw_process(g, s, a, e, r_attr, f);
+
+	  MPLS_REFCNT_RELEASE2(g, f, ldp_fec_delete);
+          MPLS_REFCNT_RELEASE2(g, r_attr, ldp_attr_delete);
+          if (retval != MPLS_SUCCESS)
+            break;
+        }
+        break;
+      }
+    case MPLS_LBLREL_MSGTYPE:
+      {
+        mplsLdpLbl_W_R_Msg_t *rw = &msg->u.release;
+	ldp_fec *f;
+
+        for (i = 0; i < rw->fecTlv.numberFecElements; i++) {
+          fec_tlv2mpls_fec(&rw->fecTlv, i, &fec);
+          if (!(r_attr = ldp_attr_create(g, &fec))) {
+            goto ldp_state_process_error;
+          }
+
+          MPLS_REFCNT_HOLD(r_attr);
+
+          rel_with2attr(rw, r_attr);
+	  f = ldp_fec_find2(g, &fec);
+	  MPLS_REFCNT_HOLD(f);
+
+          retval = ldp_label_release_process(g, s, a, e, r_attr, f);
+
+	  MPLS_REFCNT_RELEASE2(g, f, ldp_fec_delete);
+          MPLS_REFCNT_RELEASE2(g, r_attr, ldp_attr_delete);
+          if (retval != MPLS_SUCCESS)
+            break;
+        }
+        break;
+      }
+    case MPLS_LBLREQ_MSGTYPE:
+      {
+        mplsLdpLblReqMsg_t *req = &msg->u.request;
+	ldp_fec *f;
+
+        MPLS_ASSERT(req->fecTlv.numberFecElements == 1);
+
+        for (i = 0; i < req->fecTlv.numberFecElements; i++) {
+          fec_tlv2mpls_fec(&req->fecTlv, i, &fec);
+          if (!(r_attr = ldp_attr_create(g, &fec))) {
+            goto ldp_state_process_error;
+          }
+
+          MPLS_REFCNT_HOLD(r_attr);
+
+          req2attr(req, r_attr, LDP_ATTR_ALL & ~LDP_ATTR_FEC);
+	  f = ldp_fec_find2(g, &fec);
+	  MPLS_REFCNT_HOLD(f);
+
+          retval = ldp_label_request_process(g, s, a, e, r_attr, f);
+
+	  MPLS_REFCNT_RELEASE2(g, f, ldp_fec_delete);
+          MPLS_REFCNT_RELEASE2(g, r_attr, ldp_attr_delete);
+          if (retval != MPLS_SUCCESS)
+            break;
+        }
+        break;
+      }
+    case MPLS_LBLMAP_MSGTYPE:
+      {
+        mplsLdpLblMapMsg_t *map = &msg->u.map;
+	ldp_fec *f;
+
+        for (i = 0; i < map->fecTlv.numberFecElements; i++) {
+          fec_tlv2mpls_fec(&map->fecTlv, i, &fec);
+          if (!(r_attr = ldp_attr_create(g, &fec))) {
+            goto ldp_state_process_error;
+          }
+
+          MPLS_REFCNT_HOLD(r_attr);
+
+          map2attr(map, r_attr, LDP_ATTR_ALL & ~LDP_ATTR_FEC);
+	  f = ldp_fec_find2(g, &fec);
+	  MPLS_REFCNT_HOLD(f);
+
+          retval = ldp_label_mapping_process(g, s, a, e, r_attr, f);
+
+	  MPLS_REFCNT_RELEASE2(g, f, ldp_fec_delete);
+          MPLS_REFCNT_RELEASE2(g, r_attr, ldp_attr_delete);
+          if (retval != MPLS_SUCCESS)
+            break;
+        }
+        break;
+      }
+    case MPLS_LBLABORT_MSGTYPE:
+      {
+        mplsLdpLblAbortMsg_t *abrt = &msg->u.abort;
+	ldp_fec *f;
+
+        for (i = 0; i < abrt->fecTlv.numberFecElements; i++) {
+          fec_tlv2mpls_fec(&abrt->fecTlv, i, &fec);
+          if (!(r_attr = ldp_attr_create(g, &fec))) {
+            goto ldp_state_process_error;
+          }
+
+          MPLS_REFCNT_HOLD(r_attr);
+
+          abort2attr(abrt, r_attr, LDP_ATTR_ALL & ~LDP_ATTR_FEC);
+	  f = ldp_fec_find2(g, &fec);
+	  MPLS_REFCNT_HOLD(f);
+
+          retval = ldp_label_abort_process(g, s, a, e, r_attr, f);
+
+	  MPLS_REFCNT_RELEASE2(g, f, ldp_fec_delete);
+          MPLS_REFCNT_RELEASE2(g, r_attr, ldp_attr_delete);
+          if (retval != MPLS_SUCCESS)
+            break;
+        }
+        break;
+      }
+    case MPLS_ADDRWITH_MSGTYPE:
+    case MPLS_ADDR_MSGTYPE:
+      {
+        retval = ldp_addr_process(g, s, e, msg);
+        break;
+      }
+    default:
+      {
+        MPLS_ASSERT(0);
+        break;
+      }
+  }
+
+  LDP_EXIT(g->user_data, "ldp_state_process");
+
+  return retval;
+
+ldp_state_process_error:
+
+  LDP_EXIT(g->user_data, "ldp_state_process");
+
+  s->shutdown_notif = LDP_NOTIF_INTERNAL_ERROR;
+  s->shutdown_fatal = MPLS_BOOL_TRUE;
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_state_ignore(ldp_global * g, ldp_session * session,
+  ldp_adj * adj, ldp_entity * entity, uint32_t event, ldp_mesg * msg,
+  mpls_dest * from)
+{
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_state_close(ldp_global * g, ldp_session * s, ldp_adj * a,
+  ldp_entity * e, uint32_t event, ldp_mesg * msg, mpls_dest * from)
+{
+
+  LDP_ENTER(g->user_data, "ldp_state_close: a = %p, e = %p s = %p",a,e,s);
+
+  /* JLEU: this need more work */
+  if (s) {
+    /* not sure why we got here but we should tear it completely down */
+    if (s->shutdown_fatal != MPLS_BOOL_TRUE) {
+      ldp_notif_send(g,s,NULL,s->shutdown_notif);
+    }
+    ldp_session_shutdown(g, s, MPLS_BOOL_TRUE);
+  }
+
+  LDP_EXIT(g->user_data, "ldp_state_close");
+  return MPLS_SUCCESS;
+}
+
+mpls_return_enum ldp_state_keepalive_maintainance(ldp_global * g,
+  ldp_session * s, ldp_adj * a, ldp_entity * e, uint32_t event, ldp_mesg * msg,
+  mpls_dest * from)
+{
+  mpls_return_enum result;
+
+  MPLS_ASSERT(s);
+
+  LDP_ENTER(g->user_data, "ldp_state_keepalive_maintainance");
+  result = ldp_session_maintain_timer(g, s, LDP_KEEPALIVE_RECV);
+
+  LDP_EXIT(g->user_data, "ldp_state_keepalive_maintainance");
+
+  return result;
+}
+
+mpls_return_enum ldp_state_notif(ldp_global * g, ldp_session * s, ldp_adj * adj,
+  ldp_entity * entity, uint32_t event, ldp_mesg * msg, mpls_dest * from)
+{
+
+  mpls_return_enum retval = MPLS_SUCCESS;
+  ldp_attr *r_attr = NULL;
+  mplsLdpNotifMsg_t *not = &msg->u.notif;
+
+  MPLS_ASSERT(s && msg);
+
+  LDP_ENTER(g->user_data, "ldp_state_notif");
+
+  if (!(r_attr = ldp_attr_create(g, NULL))) {
+    retval = MPLS_FAILURE;
+    goto ldp_state_notif_end;
+  }
+
+  MPLS_REFCNT_HOLD(r_attr);
+
+  not2attr(not, r_attr, LDP_ATTR_ALL);
+  retval = ldp_notif_process(g, s, adj, entity, r_attr);
+
+  MPLS_REFCNT_RELEASE2(g, r_attr, ldp_attr_delete);
+
+ldp_state_notif_end:
+
+  LDP_EXIT(g->user_data, "ldp_state_notif");
+
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_state_machine.c quagga-mpls/ldpd/ldp_state_machine.c
--- quagga-0.99.10/ldpd/ldp_state_machine.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_state_machine.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,480 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_global.h"
+#include "ldp_session.h"
+#include "ldp_entity.h"
+#include "ldp_peer.h"
+#include "ldp_if.h"
+#include "ldp_adj.h"
+#include "ldp_mesg.h"
+#include "ldp_buf.h"
+#include "ldp_state_machine.h"
+
+#include "mpls_assert.h"
+#include "mpls_socket_impl.h"
+#include "mpls_lock_impl.h"
+#include "mpls_trace_impl.h"
+
+/*                  HELLO CONNECT   INIT      KEEP   ADDR    LABEL   NOTIF   CLOSE  HTIMER KTIMER */
+/* SES_NONE         new   ignore    ignore    ignore ignore  ignore  ignore  close  ignore ignore */
+/* SES_NON_EXISTENT maint connect   close     close  close   close   close   close  close  ignore */
+/* SES_INITIALIZED  maint close     recv_init close  close   close   notif   close  close  ignore */
+/* SES_OPENSENT     maint close     recv_init close  close   close   notif   close  close  ignore */
+/* SES_OPENREC      maint close     close     finish close   close   notif   close  close  close  */
+/* SES_OPERATIONAL  maint close     kmaint    kmaint process process notif   close  close  close  */
+
+int ldp_state_table[LDP_STATE_NUM][LDP_EVENT_NUM] = {
+  {0, 6, 6, 6, 6, 6, 6, 7, 6, 6},
+  {1, 3, 7, 7, 7, 7, 7, 7, 7, 6},
+  {1, 7, 2, 7, 7, 7, 9, 7, 7, 6},
+  {1, 7, 2, 7, 7, 7, 9, 7, 7, 6},
+  {1, 7, 7, 4, 7, 7, 9, 7, 7, 7},
+  {1, 7, 8, 8, 5, 5, 9, 7, 7, 7}};
+
+mpls_return_enum ldp_buf_process(ldp_global * g, mpls_socket_handle socket,
+  ldp_buf * buf, void *extra, ldp_event_enum event, mpls_dest * from,
+  mpls_bool * more);
+
+mpls_return_enum(*ldp_state_func[LDP_FUNC_NUM]) (ldp_global *, ldp_session *,
+  ldp_adj *, ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *) = {
+  ldp_state_new_adjacency,		/* 0 */
+  ldp_state_maintainance,		/* 1 */
+  ldp_state_recv_init,			/* 2 */
+  ldp_state_connect,			/* 3 */
+  ldp_state_finish_init,		/* 4 */
+  ldp_state_process,			/* 5 */
+  ldp_state_ignore,			/* 6 */
+  ldp_state_close,			/* 7 */
+  ldp_state_keepalive_maintainance,	/* 8 */
+  ldp_state_notif			/* 9 */
+};
+
+#define LDP_FUNC_CLOSE 7
+
+mpls_return_enum ldp_event(mpls_cfg_handle handle, mpls_socket_handle socket,
+  void *extra, ldp_event_enum event)
+{
+  mpls_return_enum retval = MPLS_SUCCESS;
+  ldp_global *g = (ldp_global*)handle;
+
+  mpls_socket_handle socket_new = (mpls_socket_handle)0;
+  ldp_session *session = NULL;
+  ldp_entity *entity = NULL;
+  ldp_adj *adj = NULL;
+
+  uint8_t buffer[MPLS_PDUMAXLEN];
+  mpls_dest from;
+  ldp_mesg mesg;
+  ldp_buf buf;
+
+  LDP_ENTER(g->user_data, "ldp_event");
+
+  mpls_lock_get(g->global_lock);
+
+  switch (event) {
+    case LDP_EVENT_TCP_DATA:
+    case LDP_EVENT_UDP_DATA:
+    {
+      mpls_bool more;
+
+      buf.current = buffer;
+      buf.buffer = buffer;
+      buf.total = MPLS_PDUMAXLEN;
+      buf.size = 0;
+      buf.current_size = 0;
+      buf.want = 0;
+
+      /* do this so a failure will know which session caused it */
+      if (event == LDP_EVENT_TCP_DATA) {
+        session = extra;
+      }
+
+      do {
+        retval = ldp_buf_process(g, socket, &buf, extra, event, &from, &more);
+      } while (retval == MPLS_SUCCESS && more == MPLS_BOOL_TRUE);
+      break;
+    }
+    case LDP_EVENT_TCP_LISTEN:
+    {
+      socket_new = mpls_socket_tcp_accept(g->socket_handle, socket, &from);
+
+      if (mpls_socket_handle_verify(g->socket_handle, socket_new) ==
+        MPLS_BOOL_FALSE) {
+        LDP_PRINT(g->user_data, "Failed accepting socket\n");
+        retval = MPLS_FAILURE;
+      } else if (!(session = ldp_session_create_passive(g, socket_new,
+        &from))) {
+        mpls_socket_close(g->socket_handle, socket_new);
+        LDP_PRINT(g->user_data, "Failure creating passive session\n");
+        retval = MPLS_FATAL;
+      } else {
+        retval = ldp_state_machine(g, session, NULL, NULL,
+          LDP_EVENT_CONNECT, &mesg, &from);
+      }
+      break;
+    }
+    case LDP_EVENT_TCP_CONNECT:
+    {
+      retval = mpls_socket_connect_status(g->socket_handle, socket);
+      session = (ldp_session *)extra;
+
+      if (retval == MPLS_SUCCESS) {
+        /* only get this case if we did a non-block connect */
+        mpls_socket_writelist_del(g->socket_handle, socket);
+        retval = ldp_state_machine(g, session, NULL, NULL,
+          LDP_EVENT_CONNECT, &mesg, &from);
+      } else if (retval != MPLS_NON_BLOCKING) {
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+          "ldp_event: LDP_EVENT_TCP_CONNECT errno = %d\n",
+          mpls_socket_get_errno(g->socket_handle, socket));
+      } else {
+	/* non-blocking connect is still blocking, we'll try again in a bit */
+	retval = MPLS_SUCCESS;
+      }
+      break;
+    }
+    case LDP_EVENT_CLOSE:
+    {
+      retval = ldp_state_machine(g, session, adj, entity,
+        LDP_EVENT_CLOSE, &mesg, &from);
+      break;
+    }
+    default:
+    {
+      MPLS_ASSERT(0);
+    }
+  }
+
+  /* ldp_state_machine return MPLS_SUCCESS when it has handled the event
+     to completion. If the handling off the event results in the session
+     needing to be shutdown MPLS_FAILURE is returned.  If the handling of
+     the event requires the LDP be shutdown LD_FATAL is returned, and
+     passed back to the user.  other values are invalid */
+
+  switch (retval) {
+    case MPLS_FAILURE:
+    {
+      /* if shutting down the session results in LDP_FATAL, then pass it
+       * back to the user */
+
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+        "ldp_event: FAILURE executing a CLOSE\n");
+
+      retval = ldp_state_machine(g, session, adj, entity, LDP_EVENT_CLOSE,
+        NULL, &from);
+
+      if (retval == MPLS_FATAL) {
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+          "ldp_event: CLOSE failed: FATAL propogated to the environemnt\n");
+      }
+      break;
+    }
+    case MPLS_FATAL:
+    {
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+        "ldp_event: FATAL propogated to the environemnt\n");
+      break;
+    }
+    case MPLS_SUCCESS:
+    {
+      break;
+    }
+    default:
+    {
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_ERROR,
+        "ldp_event: invalid return value of %d\n", retval);
+      break;
+    }
+  }
+
+  mpls_lock_release(g->global_lock);
+
+  LDP_EXIT(g->user_data, "ldp_event");
+
+  return retval;
+}
+
+mpls_return_enum ldp_state_machine(ldp_global * g, ldp_session * session,
+  ldp_adj * adj, ldp_entity * entity, uint32_t event, ldp_mesg * msg,
+  mpls_dest * from)
+{
+  int state = LDP_STATE_NONE;
+  int func = 0;
+  mpls_return_enum retval = MPLS_FAILURE;
+
+  LDP_ENTER(g->user_data, "ldp_state_machine");
+
+  if (session) {
+    state = session->state;
+  } else if (adj) {
+    state = LDP_STATE_NON_EXIST;
+  }
+
+  if (state >= LDP_STATE_NONE && state <= LDP_STATE_OPERATIONAL) {
+    if (event <= LDP_EVENT_KTIMER) {
+      LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL, LDP_TRACE_FLAG_STATE,
+        "FSM: state %d, event %d\n", state, event);
+      func = ldp_state_table[state][event];
+      retval = ldp_state_func[func] (g, session, adj, entity, event, msg, from);
+    }
+  }
+
+  LDP_EXIT(g->user_data, "ldp_state_machine");
+  return retval;
+}
+
+mpls_return_enum ldp_buf_process(ldp_global * g, mpls_socket_handle socket,
+  ldp_buf * buf, void *extra, ldp_event_enum event, mpls_dest * from,
+  mpls_bool * more)
+{
+
+  mpls_return_enum retval = MPLS_SUCCESS;
+  ldp_session *session = NULL;
+  ldp_entity *entity = NULL;
+  ldp_adj *adj = NULL;
+  ldp_mesg mesg;
+
+  int size = 0;
+
+  LDP_ENTER(g->user_data, "ldp_buf_process");
+
+  *more = MPLS_BOOL_TRUE;
+
+  memset(&mesg, 0, sizeof(mesg));
+  if (!buf->want) {
+    buf->want = MPLS_LDP_HDRSIZE;
+  }
+
+read_again:
+
+  switch (event) {
+    case LDP_EVENT_TCP_DATA:
+    {
+      session = (ldp_session *) extra;
+      MPLS_ASSERT(session);
+      session->mesg_rx++;
+
+      size = mpls_socket_tcp_read(g->socket_handle, socket,
+        buf->buffer + buf->size, buf->want - buf->size);
+
+      if (!size) {
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+        LDP_TRACE_FLAG_ERROR, "ldp_event: LDP_EVENT_TCP_DATA errno = %d\n",
+          mpls_socket_get_errno(g->socket_handle, socket));
+
+        retval = MPLS_FAILURE;
+        session->shutdown_notif = LDP_NOTIF_SHUTDOWN;
+        session->shutdown_fatal = MPLS_BOOL_TRUE;
+        goto ldp_event_end;
+      } 
+
+      if (size < 0) {
+        retval = MPLS_SUCCESS;
+        *more = MPLS_BOOL_FALSE;
+        goto ldp_event_end;
+      }
+      break;
+    }
+    case LDP_EVENT_UDP_DATA:
+    {
+      size = mpls_socket_udp_recvfrom(g->socket_handle, socket,
+        buf->buffer + buf->size, buf->total - buf->size, from);
+
+      if (!size) {
+        LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+          LDP_TRACE_FLAG_ERROR, "ldp_event: LDP_EVENT_UDP_DATA errno = %d\n",
+        mpls_socket_get_errno(g->socket_handle, socket));
+        retval = MPLS_FAILURE;
+        goto ldp_event_end;
+      }
+
+      if (size < 0) {
+        retval = MPLS_SUCCESS;
+        *more = MPLS_BOOL_FALSE;
+        goto ldp_event_end;
+      }
+      break;
+    }
+    default:
+    {
+      MPLS_ASSERT(0);
+      break;
+    }
+  }
+
+  buf->current_size += size;
+  buf->size += size;
+
+decode_again:
+
+  if (buf->size < buf->want) {
+    retval = MPLS_SUCCESS;
+    *more = MPLS_BOOL_FALSE;
+    goto ldp_event_end;
+  }
+
+  /* upon succesful decode the pduLength will be non 0 */
+  if (!mesg.header.pduLength) {
+    if (ldp_decode_header(g, buf, &mesg) != MPLS_SUCCESS) {
+      retval = MPLS_FAILURE;
+
+      if (session) {
+        session->shutdown_notif = LDP_NOTIF_BAD_MESG_LEN;
+      }
+      goto ldp_event_end;
+    }
+
+    /* -buf->size is already 10 (the size of the full header
+     * -pduLength include 6 bytes of the header
+     *
+     * therefore add 4 so we can compare buf->want to buf->size and
+     * not have to adjust
+     */
+    buf->want = mesg.header.pduLength + 4;
+    if (buf->size < buf->want) {
+      goto read_again;
+    }
+    if (buf->size > buf->want) {
+      buf->current_size = buf->want - MPLS_LDP_HDRSIZE;
+    }
+  }
+
+  do {
+    if (ldp_decode_one_mesg(g, buf, &mesg) != MPLS_SUCCESS) {
+      retval = MPLS_FAILURE;
+
+      if (session) {
+        session->shutdown_notif = LDP_NOTIF_BAD_MESG_LEN;
+      }
+      goto ldp_event_end_loop;
+    }
+
+    switch (ldp_mesg_get_type(&mesg)) {
+      case MPLS_HELLO_MSGTYPE:
+      {
+        mpls_oper_state_enum oper_state = MPLS_OPER_DOWN;
+        mpls_inet_addr addr;
+        int labelspace = 0;
+        int targeted;
+
+        event = LDP_EVENT_HELLO;
+
+        targeted = 0;
+        ldp_mesg_hello_get_targeted(&mesg, &targeted);
+        ldp_mesg_hdr_get_lsraddr(&mesg, &addr);
+        ldp_mesg_hdr_get_labelspace(&mesg, &labelspace);
+
+        if (targeted) {
+          ldp_peer *peer = NULL;
+          if ((peer = ldp_global_find_peer_addr(g, &addr))) {
+            entity = ldp_peer_get_entity(peer);
+            oper_state = peer->oper_state;
+          }
+        } else {
+          ldp_if *iff = NULL;
+          if ((iff = ldp_global_find_if_handle(g, from->if_handle))) {
+            entity = ldp_if_get_entity(iff);
+            oper_state = iff->oper_state;
+          }
+        }
+
+        if (!entity) {
+          /* No entity! No choice but to ignore this packet */
+          LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+            LDP_TRACE_FLAG_NORMAL, "ldp_event: unknown entity\n");
+          goto ldp_event_end_loop;
+        } else if (entity->admin_state == MPLS_ADMIN_DISABLE) {
+          LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+            LDP_TRACE_FLAG_NORMAL, "ldp_event: entity is disabled\n");
+          goto ldp_event_end_loop;
+        } else if (oper_state == MPLS_OPER_DOWN) {
+          LDP_TRACE_LOG(g->user_data, MPLS_TRACE_STATE_ALL,
+            LDP_TRACE_FLAG_NORMAL, "ldp_event: entity is down\n");
+          goto ldp_event_end_loop;
+        }
+
+        
+	if ((adj = ldp_entity_find_adj(entity, &mesg))) {
+	  session = adj->session;
+	} else {
+	  session = NULL;
+	}
+        /* if we don't have an adj one will be create by state machine */
+        break;
+      }
+      case MPLS_INIT_MSGTYPE:
+      {
+        event = LDP_EVENT_INIT;
+        break;
+      }
+      case MPLS_NOT_MSGTYPE:
+      {
+        event = LDP_EVENT_NOTIF;
+        break;
+      }
+      case MPLS_KEEPAL_MSGTYPE:
+      {
+        event = LDP_EVENT_KEEP;
+        break;
+      }
+      case MPLS_LBLWITH_MSGTYPE:
+      case MPLS_LBLREL_MSGTYPE:
+      case MPLS_LBLREQ_MSGTYPE:
+      case MPLS_LBLMAP_MSGTYPE:
+      case MPLS_LBLABORT_MSGTYPE:
+      {
+        event = LDP_EVENT_LABEL;
+        break;
+      }
+      case MPLS_ADDR_MSGTYPE:
+      case MPLS_ADDRWITH_MSGTYPE:
+      {
+        event = LDP_EVENT_ADDR;
+        break;
+      }
+      default:
+      {
+        MPLS_ASSERT(0);
+      }
+    }
+
+    retval =
+      ldp_state_machine(g, session, adj, entity, event, &mesg, from);
+
+ldp_event_end_loop:
+
+    if (retval != MPLS_SUCCESS) {
+      break;
+    }
+  } while ((buf->current_size > 0) && (*more == MPLS_BOOL_TRUE));
+
+  if (buf->want < buf->size) {
+    buf->current_size = buf->size - buf->want;
+    buf->size = buf->current_size;
+    memmove(buf->buffer, buf->current, buf->current_size);
+  } else {
+    buf->size = 0;
+  }
+
+  buf->current = buf->buffer;
+  memset(&mesg, 0, sizeof(mesg));
+  buf->want = MPLS_LDP_HDRSIZE;
+
+  if (buf->current_size) {
+    goto decode_again;
+  }
+
+ldp_event_end:
+
+  LDP_EXIT(g->user_data, "ldp_buf_process");
+
+  return retval;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_state_machine.h quagga-mpls/ldpd/ldp_state_machine.h
--- quagga-0.99.10/ldpd/ldp_state_machine.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_state_machine.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,42 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_STATE_MACHINE_H_
+#define _LDP_STATE_MACHINE_H_
+
+#include "ldp_struct.h"
+
+extern mpls_return_enum ldp_event(mpls_cfg_handle g, mpls_socket_handle socket,
+  void *extra, ldp_event_enum event);
+
+extern mpls_return_enum ldp_state_machine(ldp_global *, ldp_session *,
+  ldp_adj *, ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+
+extern mpls_return_enum ldp_state_new_adjacency(ldp_global *, ldp_session *,
+  ldp_adj *, ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+extern mpls_return_enum ldp_state_maintainance(ldp_global *, ldp_session *,
+  ldp_adj *, ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+extern mpls_return_enum ldp_state_recv_init(ldp_global *, ldp_session *,
+  ldp_adj *, ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+extern mpls_return_enum ldp_state_connect(ldp_global *, ldp_session *,
+  ldp_adj *, ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+extern mpls_return_enum ldp_state_finish_init(ldp_global *, ldp_session *,
+  ldp_adj *, ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+extern mpls_return_enum ldp_state_process(ldp_global *, ldp_session *,
+  ldp_adj *, ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+extern mpls_return_enum ldp_state_ignore(ldp_global *, ldp_session *, ldp_adj *,
+  ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+extern mpls_return_enum ldp_state_close(ldp_global *, ldp_session *, ldp_adj *,
+  ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+extern mpls_return_enum ldp_state_keepalive_maintainance(ldp_global *,
+  ldp_session *, ldp_adj *, ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+extern mpls_return_enum ldp_state_notif(ldp_global *, ldp_session *, ldp_adj *,
+  ldp_entity *, uint32_t, ldp_mesg *, mpls_dest *);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_struct.h quagga-mpls/ldpd/ldp_struct.h
--- quagga-0.99.10/ldpd/ldp_struct.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_struct.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,702 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_STRUCT_H_
+#define _LDP_STRUCT_H_
+
+#include "mpls_struct.h"
+#include "mpls_list.h"
+#include "mpls_refcnt.h"
+
+MPLS_LIST_ROOT(ldp_outlabel_list, ldp_outlabel);
+MPLS_LIST_ROOT(ldp_resource_list, ldp_resource);
+MPLS_LIST_ROOT(ldp_hop_list_list, ldp_hop_list);
+MPLS_LIST_ROOT(ldp_inlabel_list, ldp_inlabel);
+MPLS_LIST_ROOT(ldp_session_list, ldp_session);
+MPLS_LIST_ROOT(ldp_nexthop_list, ldp_nexthop);
+MPLS_LIST_ROOT(ldp_entity_list, ldp_entity);
+MPLS_LIST_ROOT(ldp_tunnel_list, ldp_tunnel);
+MPLS_LIST_ROOT(ldp_addr_list, ldp_addr);
+MPLS_LIST_ROOT(ldp_attr_list, ldp_attr);
+MPLS_LIST_ROOT(ldp_peer_list, ldp_peer);
+MPLS_LIST_ROOT(_ldp_hop_list, ldp_hop);
+MPLS_LIST_ROOT(ldp_adj_list, ldp_adj);
+MPLS_LIST_ROOT(ldp_fec_list, ldp_fec);
+MPLS_LIST_ROOT(ldp_fs_list, ldp_fs);
+MPLS_LIST_ROOT(ldp_if_list, ldp_if);
+
+typedef struct ldp_attr_list ldp_attr_list;
+
+typedef enum {
+  LDP_UNKNOWN = 0,
+  LDP_DIRECT,
+  LDP_INDIRECT,
+} ldp_entity_type_enum;
+
+typedef enum {
+  LDP_CONTROL_INDEPENDENT = 1,
+  LDP_CONTROL_ORDERED
+} ldp_control_mode;
+
+typedef enum {
+  LDP_RETENTION_LIBERAL = 1,
+  LDP_RETENTION_CONSERVATIVE
+} ldp_retention_mode;
+
+typedef enum {
+  LDP_REPAIR_LOCAL = 1,
+  LDP_REPAIR_GLOBAL
+} ldp_repaire_mode;
+
+typedef enum {
+  LDP_LOOP_NONE = 0,
+  LDP_LOOP_HOPCOUNT,
+  LDP_LOOP_PATHVECTOR,
+  LDP_LOOP_HOPCOUNT_PATHVECTOR,
+  LDP_LOOP_OTHER,
+} ldp_loop_detection_mode;
+
+typedef enum {
+  LDP_DISTRIBUTION_UNSOLICITED = 0,
+  LDP_DISTRIBUTION_ONDEMAND = 1,
+} ldp_distribution_mode;
+
+typedef enum {
+  LDP_INFINIT = 0,
+} ldp_count;
+
+typedef enum {
+  LDP_NONE,
+  LDP_PASSIVE,
+  LDP_ACTIVE
+} ldp_role_enum;
+
+typedef enum {
+  LDP_EVENT_HELLO = 0,
+  LDP_EVENT_CONNECT,
+  LDP_EVENT_INIT,
+  LDP_EVENT_KEEP,
+  LDP_EVENT_ADDR,
+  LDP_EVENT_LABEL,
+  LDP_EVENT_NOTIF,
+  LDP_EVENT_CLOSE,
+  LDP_EVENT_HTIMER,
+  LDP_EVENT_KTIMER,
+  LDP_EVENT_TCP_LISTEN,
+  LDP_EVENT_TCP_CONNECT,
+  LDP_EVENT_UDP_DATA,
+  LDP_EVENT_TCP_DATA,
+} ldp_event_enum;
+
+typedef enum {
+  LDP_STATE_NONE = 0,
+  LDP_STATE_NON_EXIST,
+  LDP_STATE_INITIALIZED,
+  LDP_STATE_OPENSENT,
+  LDP_STATE_OPENREC,
+  LDP_STATE_OPERATIONAL
+} ldp_state_enum;
+
+typedef enum {
+  LDP_KEEPALIVE_RECV = 1,
+  LDP_KEEPALIVE_SEND
+} ldp_keepalive_type;
+
+typedef enum {
+  LDP_LSP_STATE_REQ_RECV,
+  LDP_LSP_STATE_REQ_SENT,
+  LDP_LSP_STATE_MAP_RECV,
+  LDP_LSP_STATE_MAP_SENT,
+  LDP_LSP_STATE_WITH_SENT,
+  LDP_LSP_STATE_WITH_RECV,
+  LDP_LSP_STATE_NO_LABEL_RESOURCE_SENT,
+  LDP_LSP_STATE_NO_LABEL_RESOURCE_RECV,
+  LDP_LSP_STATE_ABORT_SENT,
+  LDP_LSP_STATE_ABORT_RECV,
+  LDP_LSP_STATE_NOTIF_SENT,
+  LDP_LSP_STATE_NOTIF_RECV
+} ldp_lsp_state;
+
+typedef enum {
+  LDP_TRACE_FLAG_ADDRESS = 0x00000001,
+  LDP_TRACE_FLAG_BINDING = 0x00000002,
+  LDP_TRACE_FLAG_DEBUG = 0x00000004,
+  LDP_TRACE_FLAG_ERROR = 0x00000008,
+  LDP_TRACE_FLAG_EVENT = 0x00000010,
+  LDP_TRACE_FLAG_GENERAL = 0x00000020,
+  LDP_TRACE_FLAG_INIT = 0x00000040,
+  LDP_TRACE_FLAG_LABEL = 0x00000080,
+  LDP_TRACE_FLAG_NORMAL = 0x00000100,
+  LDP_TRACE_FLAG_NOTIF = 0x00000200,
+  LDP_TRACE_FLAG_PACKET_DUMP = 0x00000400,
+  LDP_TRACE_FLAG_PACKET = 0x00000800,
+  LDP_TRACE_FLAG_PATH = 0x00001000,
+  LDP_TRACE_FLAG_PERIODIC = 0x00002000,
+  LDP_TRACE_FLAG_POLICY = 0x00004000,
+  LDP_TRACE_FLAG_ROUTE = 0x00008000,
+  LDP_TRACE_FLAG_STATE = 0x00010000,
+  LDP_TRACE_FLAG_TASK = 0x00020000,
+  LDP_TRACE_FLAG_TIMER = 0x00040000,
+  LDP_TRACE_FLAG_ALL = 0xFFFFFFFF
+} ldp_trace_flags;
+
+typedef enum {
+  LDP_NOTIF_NONE = 0,
+  LDP_NOTIF_SUCCESS,
+  LDP_NOTIF_BAD_LDP_ID,
+  LDP_NOTIF_BAD_PROTO,
+  LDP_NOTIF_BAD_PDU_LEN,
+  LDP_NOTIF_UNKNOWN_MESG,
+  LDP_NOTIF_BAD_MESG_LEN,
+  LDP_NOTIF_UNKNOWN_TVL,
+  LDP_NOTIF_BAD_TLV_LEN,
+  LDP_NOTIF_MALFORMED_TLV,
+  LDP_NOTIF_HOLD_TIMER_EXPIRED,
+  LDP_NOTIF_SHUTDOWN,
+  LDP_NOTIF_LOOP_DETECTED,
+  LDP_NOTIF_UNKNOWN_FEC,
+  LDP_NOTIF_NO_ROUTE,
+  LDP_NOTIF_NO_LABEL_RESOURCES_AVAILABLE,
+  LDP_NOTIF_LABEL_RESOURCES_AVAILABLE,
+  LDP_NOTIF_SESSION_REJECTED_NO_HELLO,
+  LDP_NOTIF_SESSION_REJECTED_PARAMETERS_ADVERTISEMENT_MODE,
+  LDP_NOTIF_SESSION_REJECTED_PARAMETERS_MAX_PDU_LEN,
+  LDP_NOTIF_SESSION_REJECTED_PARAMETERS_LABEL_RANGE,
+  LDP_NOTIF_KEEPALIVE_TIMER_EXPIRED,
+  LDP_NOTIF_LABEL_ABORT,
+  LDP_NOTIF_MISSING_MSG_PARAMS,
+  LDP_NOTIF_UNSUPORTED_AF,
+  LDP_NOTIF_SESSION_REJECTED_BAD_KEEPALIVE_TIME,
+  LDP_NOTIF_INTERNAL_ERROR
+} ldp_notif_status;
+
+#define LDP_STATE_NUM 6
+#define LDP_EVENT_NUM 10
+#define LDP_FUNC_NUM 10
+
+#include "ldp_defaults.h"
+#include "mpls_handle_type.h"
+#include "ldp_nortel.h"
+
+typedef struct ldp_mesg {
+  mplsLdpHeader_t header;
+  union {
+    mplsLdpMsg_t generic;
+    mplsLdpInitMsg_t init;
+    mplsLdpNotifMsg_t notif;
+    mplsLdpHelloMsg_t hello;
+    mplsLdpKeepAlMsg_t keep;
+    mplsLdpAdrMsg_t addr;
+    mplsLdpLblMapMsg_t map;
+    mplsLdpLblReqMsg_t request;
+    mplsLdpLbl_W_R_Msg_t release;
+    mplsLdpLblAbortMsg_t abort;
+  } u;
+} ldp_mesg;
+
+typedef struct ldp_buf {
+  uint8_t *buffer;
+  uint8_t *current;
+  int current_size;
+  int size;
+  int total;
+  int want;
+} ldp_buf;
+
+typedef struct ldp_global {
+  struct ldp_outlabel_list outlabel;
+  struct ldp_resource_list resource;
+  struct ldp_hop_list_list hop_list;
+  struct ldp_inlabel_list inlabel;
+  struct ldp_nexthop_list nexthop;
+  struct ldp_session_list session;
+  struct ldp_tunnel_list tunnel;
+  struct ldp_entity_list entity;
+  struct ldp_peer_list peer;
+  struct ldp_attr_list attr;
+  struct ldp_addr_list addr;
+  struct ldp_adj_list adj;
+  struct ldp_if_list iff;
+  struct ldp_fec_list fec;
+
+  mpls_lock_handle global_lock;
+  mpls_instance_handle user_data;
+
+  mpls_tree_handle addr_tree;
+  mpls_tree_handle fec_tree;
+
+  mpls_socket_handle hello_socket;
+  mpls_socket_handle listen_socket;
+
+  mpls_timer_mgr_handle timer_handle;
+  mpls_socket_mgr_handle socket_handle;
+  mpls_fib_handle fib_handle;
+  mpls_ifmgr_handle ifmgr_handle;
+
+#if MPLS_USE_LSR
+  mpls_cfg_handle lsr_handle;
+#else
+  mpls_mpls_handle mpls_handle;
+#endif
+
+  /*
+   * CSN changes with every MIB set, BUT only when a entity goes through
+   * shutdown/startup cycle will it grab the new CSN and use it in hellos
+   */
+  uint32_t configuration_sequence_number;
+
+  /*
+   * Message ID increaments with EVERY message, this means it will roll over
+   */
+  uint32_t message_identifier;
+
+  struct mpls_inet_addr lsr_identifier;
+  mpls_bool send_address_messages;
+  mpls_bool send_lsrid_mapping;
+  ldp_control_mode lsp_control_mode;
+  ldp_retention_mode label_retention_mode;
+  ldp_repaire_mode lsp_repair_mode;
+  mpls_bool propagate_release;
+  mpls_bool label_merge;
+  ldp_loop_detection_mode loop_detection_mode;
+  mpls_bool ttl_less_domain;
+  uint16_t local_tcp_port;
+  uint16_t local_udp_port;
+  uint16_t backoff_step;
+  int no_route_to_peer_time;
+
+  /*
+   * some global defaults, entities will inherit these values unless
+   * instructed otherwise
+   */
+  struct mpls_inet_addr transport_address;
+  uint16_t keepalive_timer;
+  uint16_t keepalive_interval;
+  uint16_t hellotime_timer;
+  uint16_t hellotime_interval;
+
+  mpls_admin_state_enum admin_state;
+} ldp_global;
+
+typedef struct ldp_entity {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_entity) _global;
+  struct ldp_adj_list adj_root;
+
+  ldp_entity_type_enum entity_type;
+  union {
+    struct ldp_peer *peer;
+    struct ldp_if *iff;
+  } p;
+
+  ldp_state_enum state;
+  uint32_t inherit_flag;
+  uint32_t sub_index;
+  uint32_t index;
+  struct mpls_inet_addr transport_address;
+  uint8_t protocol_version;
+  uint16_t remote_tcp_port;
+  uint16_t remote_udp_port;
+  uint16_t max_pdu;
+  uint16_t keepalive_timer;
+  uint16_t keepalive_interval;
+  uint16_t hellotime_timer;
+  uint16_t hellotime_interval;
+  uint16_t session_setup_count;
+  uint16_t session_backoff_timer;
+  ldp_distribution_mode label_distribution_mode;
+  uint8_t path_vector_limit;
+  uint8_t hop_count_limit;
+  uint8_t label_request_count;
+  uint16_t label_request_timer;
+  ldp_loop_detection_mode loop_detection_mode;
+  mpls_admin_state_enum admin_state;
+  mpls_bool remote_in_ttl_less_domain;
+  mpls_bool request_retry;
+
+  /* mesg counters */
+  uint32_t mesg_tx;
+  uint32_t mesg_rx;
+
+  /* only used for cfg gets */
+  int adj_index;
+  int adj_count;
+} ldp_entity;
+
+typedef struct ldp_if {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_if) _global;
+  struct mpls_link_list session_root;
+  struct ldp_nexthop_list nh_root;
+  struct ldp_addr_list addr_root;
+  struct ldp_entity *entity;
+  mpls_timer_handle hellotime_send_timer;
+  int hellotime_send_timer_duration;
+  int label_space;
+  uint32_t index;
+  mpls_if_handle handle;
+
+  struct ldp_mesg *tx_message;
+  struct ldp_buf *tx_buffer;
+  struct ldp_mesg *hello;
+
+  /* YES this is a dest, it is what we use for sendto */
+  struct mpls_dest dest;
+
+  mpls_oper_state_enum oper_state;
+  mpls_bool is_p2p;
+
+  /* only used for cfg gets */
+  uint32_t entity_index;
+} ldp_if;
+
+typedef struct ldp_peer {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_peer) _global;
+  struct ldp_entity *entity;
+  mpls_timer_handle no_route_to_peer_timer;
+  mpls_timer_handle hellotime_send_timer;
+  int hellotime_send_timer_duration;
+  int label_space;
+  uint32_t index;
+
+  struct ldp_mesg *tx_message;
+  struct ldp_buf *tx_buffer;
+  struct ldp_mesg *hello;
+
+  /* YES this is a dest, it is what we use for sendto */
+  struct mpls_dest dest;
+  ldp_role_enum target_role;
+
+  char peer_name[MPLS_MAX_IF_NAME];
+  mpls_oper_state_enum oper_state;
+
+  /* only used for cfg gets */
+  uint32_t entity_index;
+} ldp_peer;
+
+typedef struct ldp_session {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_session) _global;
+  struct ldp_outlabel_list outlabel_root;
+  struct mpls_link_list inlabel_root;
+  struct mpls_link_list addr_root;
+  struct ldp_attr_list attr_root;
+  struct ldp_adj_list adj_root;
+  mpls_timer_handle initial_distribution_timer;
+  mpls_timer_handle keepalive_recv_timer;
+  mpls_timer_handle keepalive_send_timer;
+  uint32_t index;
+  ldp_state_enum state;
+  uint32_t oper_up;
+  ldp_notif_status shutdown_notif;
+  mpls_bool shutdown_fatal;
+  mpls_socket_handle socket;
+  mpls_timer_handle backoff_timer;
+  int backoff;
+
+  /* operational values learned from initialization */
+  int oper_max_pdu;
+  int oper_keepalive;
+  int oper_keepalive_interval;
+  int oper_path_vector_limit;
+  ldp_distribution_mode oper_distribution_mode;
+  ldp_loop_detection_mode oper_loop_detection;
+
+  /* these values are learned form the remote peer */
+  ldp_distribution_mode remote_distribution_mode;
+  mpls_bool remote_loop_detection;
+  int remote_path_vector_limit;
+  int remote_keepalive;
+  int remote_max_pdu;
+  mpls_dest remote_dest;
+  uint8_t session_name[20]; /* xxx.xxx.xxx.xxx:yyy\0 */
+
+  mpls_bool no_label_resource_sent;
+  mpls_bool no_label_resource_recv;
+  mpls_bool on_global;
+
+  /* various message and buffers used for tx and rx */
+  struct ldp_mesg *keepalive;
+  struct ldp_mesg *tx_message;
+  struct ldp_buf *tx_buffer;
+
+  /* cached from adj's */ 
+  ldp_role_enum oper_role;
+
+  /* these are config values come from entity */
+  ldp_loop_detection_mode cfg_loop_detection_mode;
+  ldp_distribution_mode cfg_distribution_mode;
+  mpls_bool cfg_remote_in_ttl_less_domain;
+  int cfg_label_request_count;
+  int cfg_label_request_timer;
+  uint16_t cfg_peer_tcp_port;
+  int cfg_path_vector_limit;
+  int cfg_hop_count_limit;
+  int cfg_label_space;
+  int cfg_keepalive;
+  int cfg_max_pdu;
+
+  /* mesg counters */
+  uint32_t mesg_tx;
+  uint32_t mesg_rx;
+
+  /* only used by cfg gets */
+  uint32_t adj_index;
+
+  mpls_dest local_name;
+  mpls_dest remote_name;
+} ldp_session;
+
+typedef struct ldp_adj {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_adj) _global;
+  MPLS_LIST_ELEM(ldp_adj) _session;
+  MPLS_LIST_ELEM(ldp_adj) _entity;
+  struct ldp_session *session;
+  struct ldp_entity *entity;
+  mpls_timer_handle hellotime_recv_timer;
+  mpls_oper_state_enum state;
+  ldp_role_enum role;
+  uint32_t index;
+
+  /* these values are learned form the remote peer */
+  struct mpls_inet_addr remote_transport_address;
+  struct mpls_inet_addr remote_source_address;
+  struct mpls_inet_addr remote_lsr_address;
+  int remote_label_space;
+  int remote_hellotime;
+  uint32_t remote_csn;
+
+  /* only used by cfg gets */
+  uint32_t session_index;
+  uint32_t entity_index;
+} ldp_adj;
+
+typedef struct ldp_addr {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_addr) _global;
+  MPLS_LIST_ELEM(ldp_addr) _if;
+  struct ldp_session *session;
+  struct ldp_nexthop_list nh_root;
+  struct mpls_inet_addr address;
+  struct ldp_if *iff;
+
+  /*
+   * if an address has a if_handle it is locally attached
+   */
+  mpls_if_handle if_handle;
+  uint32_t index;
+
+  /*
+   * only used durring gets
+   */
+  uint32_t session_index;
+  uint32_t nexthop_index;
+  uint32_t if_index;
+} ldp_addr;
+
+struct ldp_outlabel;
+
+typedef struct ldp_nexthop {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_nexthop) _global;
+  MPLS_LIST_ELEM(ldp_nexthop) _fec;
+  MPLS_LIST_ELEM(ldp_nexthop) _addr;
+  MPLS_LIST_ELEM(ldp_nexthop) _if;
+  MPLS_LIST_ELEM(ldp_nexthop) _outlabel;
+  struct ldp_outlabel_list outlabel_root;
+  struct ldp_fec *fec;
+  struct ldp_addr *addr;
+  struct ldp_if *iff;
+  struct ldp_outlabel *outlabel;
+  struct mpls_nexthop info;
+
+  uint32_t index;
+} ldp_nexthop;
+
+typedef struct ldp_outlabel {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_outlabel) _global;
+  MPLS_LIST_ELEM(ldp_outlabel) _session;
+  MPLS_LIST_ELEM(ldp_outlabel) _nexthop;
+  struct ldp_inlabel_list inlabel_root;
+  struct ldp_tunnel_list tunnel_root;
+  struct ldp_nexthop_list nh_root;
+  uint32_t merge_count;
+  struct ldp_attr *attr;
+  struct ldp_session *session;
+  struct ldp_nexthop *nh;
+  struct mpls_outsegment info;
+  uint32_t index;
+  mpls_bool switching;
+
+  /* only used by get() */
+  uint32_t session_index;
+  uint32_t nh_index;
+  uint32_t attr_index;
+} ldp_outlabel;
+
+typedef struct ldp_inlabel {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_inlabel) _global;
+  MPLS_LIST_ELEM(ldp_inlabel) _outlabel;
+  struct mpls_link_list session_root;
+  struct mpls_link_list attr_root;
+  struct ldp_outlabel *outlabel;
+  uint32_t reuse_count;
+  uint32_t index;
+  struct mpls_insegment info;
+
+  /* only used by get() */
+  uint32_t outlabel_index;
+} ldp_inlabel;
+
+typedef struct ldp_fec {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_fec) _global;
+  MPLS_LIST_ELEM(ldp_fec) _inlabel;
+  MPLS_LIST_ELEM(ldp_fec) _outlabel;
+  MPLS_LIST_ELEM(ldp_fec) _tree;
+  MPLS_LIST_ELEM(ldp_fec) _addr;
+  MPLS_LIST_ELEM(ldp_fec) _fec;
+  MPLS_LIST_ELEM(ldp_fec) _if;
+  struct ldp_fs_list fs_root_us;
+  struct ldp_fs_list fs_root_ds;
+  /* ECMP */
+  struct ldp_nexthop_list nh_root;
+  struct mpls_fec info;
+  mpls_bool is_route;
+  uint32_t index;
+} ldp_fec;
+
+typedef struct ldp_fs {
+  struct ldp_attr_list attr_root;
+  MPLS_LIST_ELEM(ldp_fs) _fec;
+  struct ldp_session *session;
+} ldp_fs;
+
+typedef struct ldp_attr {
+  MPLS_REFCNT_FIELD;
+  uint32_t index;
+  uint32_t msg_id;
+  struct ldp_attr_list us_attr_root;
+  struct ldp_attr *ds_attr;
+  ldp_lsp_state state;
+  mpls_bool ingress;
+  mpls_bool filtered;
+  mpls_bool in_tree;
+  struct ldp_session *session;
+  uint32_t attempt_count;
+  mpls_timer_handle action_timer;
+  ldp_lsp_state action;
+  ldp_fec *fec;
+
+  MPLS_LIST_ELEM(ldp_attr) _session;
+  MPLS_LIST_ELEM(ldp_attr) _global;
+  MPLS_LIST_ELEM(ldp_attr) _ds_attr;
+  MPLS_LIST_ELEM(ldp_attr) _fs;
+
+  mplsLdpFecTlv_t fecTlv;
+  mplsLdpGenLblTlv_t genLblTlv;
+  mplsLdpAtmLblTlv_t atmLblTlv;
+  mplsLdpFrLblTlv_t frLblTlv;
+  mplsLdpHopTlv_t hopCountTlv;
+  mplsLdpPathTlv_t pathVecTlv;
+  mplsLdpLblMsgIdTlv_t lblMsgIdTlv;
+  mplsLdpLspIdTlv_t lspidTlv;
+  mplsLdpTrafficTlv_t trafficTlv;
+  mplsLdpStatusTlv_t statusTlv;
+  mplsLdpRetMsgTlv_t retMsgTlv;
+
+  uint8_t fecTlvExists:1;
+  uint8_t genLblTlvExists:1;
+  uint8_t atmLblTlvExists:1;
+  uint8_t frLblTlvExists:1;
+  uint8_t hopCountTlvExists:1;
+  uint8_t pathVecTlvExists:1;
+  uint8_t lblMsgIdTlvExists:1;
+  uint8_t lspidTlvExists:1;
+  uint8_t trafficTlvExists:1;
+  uint8_t statusTlvExists:1;
+  uint8_t retMsgTlvExists:1;
+
+  struct ldp_outlabel *outlabel;
+  struct ldp_inlabel *inlabel;
+
+  /* only used for get() */
+  uint32_t inlabel_index;
+  uint32_t outlabel_index;
+  uint32_t session_index;
+} ldp_attr;
+
+typedef struct ldp_resource {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_resource) _global;
+  struct ldp_tunnel *tunnel;
+  uint32_t index;
+  uint32_t max_rate;
+  uint32_t mean_rate;
+  uint32_t burst_size;
+} ldp_resource;
+
+typedef struct ldp_hop {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_hop) _hop_list;
+  struct ldp_hop_list *hop_list;
+  uint32_t index;
+  uint32_t hop_list_index;
+  uint32_t path_option;
+  mpls_inet_addr addr;
+  uint32_t type;
+} ldp_hop;
+
+typedef struct ldp_hop_list {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_hop_list) _global;
+  struct _ldp_hop_list hop;
+  struct ldp_tunnel *tunnel;
+  uint32_t index;
+} ldp_hop_list;
+
+typedef struct ldp_tunnel {
+  MPLS_REFCNT_FIELD;
+  MPLS_LIST_ELEM(ldp_tunnel) _global;
+  MPLS_LIST_ELEM(ldp_tunnel) _outlabel;
+  uint32_t index;
+  mpls_inet_addr ingress_lsrid;
+  ldp_addr egress_lsrid;
+  char name[MPLS_MAX_IF_NAME];
+  mpls_bool is_interface;
+  uint32_t outlabel_index;
+  struct ldp_outlabel *outlabel;
+  uint32_t setup_prio;
+  uint32_t hold_prio;
+  uint32_t instance_prio;
+  uint32_t resource_index;
+  struct ldp_resource *resource;
+  uint32_t hop_list_index;
+  struct ldp_hop_list *hop_list;
+  ldp_fec fec;
+  mpls_admin_state_enum admin_state;
+
+  uint32_t primary_instance;
+  uint32_t any_affinity;
+  uint32_t all_affinity;
+  uint32_t no_all_affinity;
+  uint32_t path_in_use;
+  uint32_t protocol;
+  mpls_bool local_protect;
+  uint32_t session_attr;
+  uint32_t owner;
+} ldp_tunnel;
+
+typedef void (*ldp_tree_callback) (void *);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_tunnel.c quagga-mpls/ldpd/ldp_tunnel.c
--- quagga-0.99.10/ldpd/ldp_tunnel.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_tunnel.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,146 @@
+
+/*
+ *  Copyright (C) James R. Leu 2001
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#include "ldp_struct.h"
+#include "ldp_tunnel.h"
+#include "ldp_hop_list.h"
+#include "ldp_resource.h"
+#include "ldp_outlabel.h"
+
+#include "mpls_assert.h"
+#include "mpls_mm_impl.h"
+#include "mpls_trace_impl.h"
+
+static uint32_t _ldp_tunnel_next_index = 1;
+
+ldp_tunnel *ldp_tunnel_create()
+{
+  ldp_tunnel *t = (ldp_tunnel *) mpls_malloc(sizeof(ldp_tunnel));
+
+  if (t) {
+    memset(t, 0, sizeof(ldp_tunnel));
+    MPLS_REFCNT_INIT(t, 0);
+    MPLS_LIST_ELEM_INIT(t, _global);
+    MPLS_LIST_ELEM_INIT(t, _outlabel);
+
+    t->index = _ldp_tunnel_get_next_index();
+  }
+  return t;
+}
+
+void ldp_tunnel_delete(ldp_tunnel * t)
+{
+  // LDP_PRINT(g->user_data,"tunnel delete\n");
+  MPLS_REFCNT_ASSERT(t, 0);
+  mpls_free(t);
+}
+
+uint32_t _ldp_tunnel_get_next_index()
+{
+  uint32_t retval = _ldp_tunnel_next_index;
+
+  _ldp_tunnel_next_index++;
+  if (retval > _ldp_tunnel_next_index) {
+    _ldp_tunnel_next_index = 1;
+  }
+  return retval;
+}
+
+mpls_bool ldp_tunnel_is_active(ldp_tunnel * t)
+{
+  if (t->admin_state == MPLS_ADMIN_ENABLE) {
+    return MPLS_BOOL_TRUE;
+  }
+  return MPLS_BOOL_FALSE;
+}
+
+mpls_bool ldp_tunnel_is_ready(ldp_tunnel * t)
+{
+  return MPLS_BOOL_TRUE;
+}
+
+mpls_return_enum ldp_tunnel_add_resource(ldp_tunnel * t, ldp_resource * r)
+{
+  if (t && r) {
+    MPLS_REFCNT_HOLD(r);
+    MPLS_ASSERT(t->resource == NULL);
+    t->resource = r;
+    _ldp_resource_add_tunnel(r, t);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_tunnel_del_resource(ldp_tunnel * t)
+{
+  if (t && t->resource) {
+    _ldp_resource_del_tunnel(t->resource);
+    MPLS_REFCNT_RELEASE(t->resource, ldp_resource_delete);
+    t->resource = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_tunnel_add_hop_list(ldp_tunnel * t, ldp_hop_list * h)
+{
+  if (t && h) {
+    MPLS_REFCNT_HOLD(h);
+    MPLS_ASSERT(t->hop_list == NULL);
+    t->hop_list = h;
+    _ldp_hop_list_add_tunnel(h, t);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_tunnel_del_hop_list(ldp_tunnel * t)
+{
+  if (t && t->hop_list) {
+    _ldp_hop_list_del_tunnel(t->hop_list);
+    MPLS_REFCNT_RELEASE(t->hop_list, ldp_hop_list_delete);
+    t->hop_list = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_tunnel_add_outlabel(ldp_tunnel * t, ldp_outlabel * o)
+{
+  if (t && o) {
+    MPLS_REFCNT_HOLD(o);
+    MPLS_ASSERT(t->outlabel == NULL);
+    t->outlabel = o;
+    _ldp_outlabel_add_tunnel(o, t);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_tunnel_del_outlabel(ldp_global * g, ldp_tunnel * t)
+{
+  if (t && t->outlabel) {
+    _ldp_outlabel_del_tunnel(t->outlabel, t);
+    MPLS_REFCNT_RELEASE2(g, t->outlabel, ldp_outlabel_delete);
+    t->outlabel = NULL;
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_tunnel_startup(ldp_global * global, ldp_tunnel * tunnel)
+{
+  return MPLS_FAILURE;
+}
+
+mpls_return_enum ldp_tunnel_shutdown(ldp_global * global, ldp_tunnel * tunnel,
+  int flag)
+{
+  return MPLS_SUCCESS;
+}
diff -Naur quagga-0.99.10/ldpd/ldp_tunnel.h quagga-mpls/ldpd/ldp_tunnel.h
--- quagga-0.99.10/ldpd/ldp_tunnel.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_tunnel.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,43 @@
+
+/*
+ *  Copyright (C) James R. Leu 2001
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _LDP_TUNNEL_H_
+#define _LDP_TUNNEL_H_
+
+#include "ldp_struct.h"
+
+extern ldp_tunnel *ldp_tunnel_create();
+extern void ldp_tunnel_delete(ldp_tunnel * t);
+extern uint32_t _ldp_tunnel_get_next_index();
+
+extern mpls_return_enum ldp_tunnel_add_resource(ldp_tunnel * t,
+
+  ldp_resource * r);
+extern mpls_return_enum ldp_tunnel_del_resource(ldp_tunnel * t);
+
+extern mpls_return_enum ldp_tunnel_add_hop_list(ldp_tunnel * t,
+
+  ldp_hop_list * h);
+extern mpls_return_enum ldp_tunnel_del_hop_list(ldp_tunnel * t);
+
+extern mpls_return_enum ldp_tunnel_add_outlabel(ldp_tunnel * t,
+
+  ldp_outlabel * o);
+extern mpls_return_enum ldp_tunnel_del_outlabel(ldp_global * g, ldp_tunnel * t);
+
+extern mpls_bool ldp_tunnel_is_active(ldp_tunnel * t);
+extern mpls_bool ldp_tunnel_is_ready(ldp_tunnel * t);
+
+extern mpls_return_enum ldp_tunnel_startup(ldp_global * global,
+
+  ldp_tunnel * tunnel);
+extern mpls_return_enum ldp_tunnel_shutdown(ldp_global * global,
+  ldp_tunnel * tunnel, int flag);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_vty.c quagga-mpls/ldpd/ldp_vty.c
--- quagga-0.99.10/ldpd/ldp_vty.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_vty.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,2602 @@
+#include <zebra.h>
+
+#include "zclient.h"
+#include "vty.h"
+#include "command.h"
+#include "table.h"
+
+#include "ldp.h"
+#include "ldp_cfg.h"
+#include "ldp_vty.h"
+#include "ldp_interface.h"
+#include "ldp_struct.h"
+#include "ldp_remote_peer.h"
+#include "ldp_zebra.h"
+
+#include "impl_mpls.h"
+
+uint32_t ldp_traceflags = 0;
+uint8_t trace_buffer[16834];
+int trace_buffer_len = 0;
+
+static const char *session_state[6] = { "NONE", "NON-EXIST", "INIT",
+                           "OPENSENT", "OPENRECV", "OPERATIONAL" };
+// static char *adj_role[3] = { "INVALID", "PASSIVE", "ACTIVE" };
+static const char *attr_state[12] = { "REQ_RECV", "REQ_SENT", "MAP_RECV",
+			 "MAP_SENT", "WITH_SENT", "WITH_RECV",
+			 "NO_LABEL_RESOURCE_SENT", "NO_LABEL_RESOURCE_RECV",
+			 "ABORT_SENT", "ABORT_RECV", "NOTIF_SENT",
+			 "NOTIF_RECV" };
+// static char *oper_state[2] = { "UP", "DOWN" };
+static const char *control_mode[3] = { "UNKNOWN", "INDEPENDENT", "ORDERED" };
+static const char *retention_mode[3] = { "UNKNOWN", "LIBERAL", "CONSERVATIVE" };
+static const char *repair_mode[3] = { "UNKNOWN", "LOCAL", "GLOBAL" };
+static const char *loop_detect_mode[5] = { "NONE", "HOPCOUNT", "PATHVECTOR",
+                              "HOPCOUNT PATHVECTOR", "OTHER" };
+const char *bool[2] = { "FALSE", "TRUE" };
+static const char *admin_state[3] = { "NONE", "ENABLED", "DISABLED" };
+static const char *distribution_mode[2] = { "UNSOLICITED", "ONDEMAND" };
+
+extern struct zclient *zclient;
+
+#if 0
+DEFUN (mpls_vfi,
+       mpls_vfi_cmd,
+       "l2 vfi WORD manual",
+       "Global VPLS configuration\n"
+       "VFI Configuration\n"
+       "VFI NAME\n"
+       "Manual Peer Discovery\n")
+{
+}
+
+DEFUN (vfi_vpn_id,
+       vfi_vpn_id_cmd,
+       "vpn id NUMBER",
+       "VPLS VPN Configuration\n"
+       "VPN Identifier\n"
+       "<1-4096>\n")
+{
+}
+
+DEFUN (vfi_neighbor,
+       vfi_neighbor_cmd,
+       "neighbor IPADDRESS",
+       "VPLS Neighbor Configuration\n"
+       "IP address of Neighbor\n")
+{
+}
+
+DEFUN (no_mpls_vfi,
+       no_mpls_vfi_cmd,
+       "no l2 vfi WORD manual",
+       NO_STR
+       "Global VPLS configuration\n"
+       "VFI Configuration\n"
+       "VFI NAME\n"
+       "Manual Peer Discovery\n")
+{
+}
+
+DEFUN (no_vfi_vpn_id,
+       no_vfi_vpn_id_cmd,
+       "no vpn id NUMBER",
+       NO_STR
+       "VPLS VPN Configuration\n"
+       "VPN Identifier\n"
+       "<1-4096>\n")
+{
+}
+
+DEFUN (no_vfi_neighbor,
+       no_vfi_neighbor_cmd,
+       "no neighbor IPADDRESS",
+       NO_STR
+       "VPLS Neighbor Configuration\n"
+       "IP address of Neighbor\n")
+{
+}
+
+show mpls l2transport vc vcid 200 detail
+Local interface: Vi1 up, line protocol up, VFI
+ Destination address: 22.22.22.22, VC ID: 200 VC status: up
+  Tunnel label: imp-null, next hop point2point
+  Output interface: PO2/1, imposed label stack {16}
+  MPLS VC labels: local 18, remote 16
+  Group ID: local 200, remote 200
+  MTU: local 1500, remote 1500
+  Remote interface description:
+ Sequencing: received disabled, send disabled
+ VC statistics:
+  packet totals: receive 0, send 0
+  byte totals: receive 0, send 0
+  packet drops: receive 0, send 0
+
+DEFUN (show_mpls_l2transport_vc,
+       show_mpls_l2transport_vc_cmd,
+       "show mpls l2transport vc",
+       "Show Commands",
+       "Multiprotocol Label Switching show commands\n"
+       "Layer 2 over MPLS show commands\n"
+       "Virtual Circuit status\n")
+{
+Local Intf  Local Circuit  Dest Address  VC ID Status
+----------  -------------  ------------  ----- ------
+Vi1         VFI            22.22.22.22   100   DOWN
+Vi1         VFI            33.33.33.33   100   UP
+
+}
+
+DEFUN (show_vfi,
+       show_vfi_cmd,
+       "show vfi WORD",
+       "Show Commands",
+       "Virtual Private LAN Service show commands\n"
+       "VFI Name\n")
+{
+VFI name: VPLSA, state: up
+ Local attachment circuits:
+  Vlan100
+ Neighbors connected via pseudowires:
+  22.22.22.22 33.33.33.33
+}
+#endif
+
+DEFUN (mpls_ldp,
+       mpls_ldp_cmd,
+       "mpls ldp",
+       "Global MPLS configuration\n"
+       "Dynamic Label distribution via LDP\n")
+{
+    vty->node = LDP_NODE;
+    vty->index = ldp_get();
+    if (!vty->index) {
+	if (!(vty->index = ldp_new())) {
+	    vty_out (vty, "Unable to create LDP instance.%s", VTY_NEWLINE);
+	    return CMD_WARNING;
+	}
+    }
+    return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_ldp,
+       no_mpls_ldp_cmd,
+       "no mpls ldp",
+       NO_STR
+       "MPLS configuration\n"
+       "Dynamic Label distribution via LDP\n")
+{
+    struct ldp *ldp = ldp_get();
+
+    if (!ldp) {
+	vty_out (vty, "There isn't active an LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+    ldp_finish(ldp);
+    return CMD_SUCCESS;
+}
+
+DEFUN (ldp_lsrid,
+       ldp_lsrid_cmd,
+       "lsr-id A.B.C.D",
+       "LDP Label Switch Router Identifier\n"
+       "IP Address\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+
+  ldp->lsr_id_is_static = MPLS_BOOL_TRUE;
+
+  ldp_admin_state_start(ldp);
+  do_ldp_router_id_update(ldp, ntohl(inet_addr(argv[0])));
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_lsrid,
+       no_ldp_lsrid_cmd,
+       "no lsr-id",
+       NO_STR
+       "LDP LSRID\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+
+  ldp->lsr_id_is_static = MPLS_BOOL_FALSE;
+
+  ldp_admin_state_start(ldp);
+  do_ldp_router_id_update(ldp, ntohl(router_id.u.prefix4.s_addr));
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_disable,
+       ldp_disable_cmd,
+       "disable",
+       "Disable\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+
+  ldp_admin_state_start(ldp);
+  ldp->admin_up = MPLS_BOOL_FALSE;
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_disable,
+       no_ldp_disable_cmd,
+       "no disable",
+       NO_STR
+       "Disable\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+
+  ldp_admin_state_start(ldp);
+  ldp->admin_up = MPLS_BOOL_TRUE;
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_transport_address,
+       ldp_transport_address_cmd,
+       "transport-address (interface|lsr-id|IPADDRESS|NAME)",
+       "global transport address\n"
+       "use the IP address on configured interfaces\n"
+       "use the LSR-ID\n"
+       "specify an IP address\n"
+       "name of interface from which to use the primary IP address\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  struct ldp_interface *li;
+  struct listnode *node;
+  struct interface *ifp;
+  unsigned int addr = 0;
+  ldp_entity e;
+  ldp_global g;
+
+  g.transport_address.type = MPLS_FAMILY_NONE;
+  g.transport_address.u.ipv4 = 0;
+
+  if (!strncmp(argv[0], "interface", 9)) {
+    ldp->trans_addr = LDP_TRANS_ADDR_INTERFACE;
+  } else if (!strncmp(argv[0], "lsr-id", 6)) {
+    ldp->trans_addr = LDP_TRANS_ADDR_LSRID;
+    g.transport_address.type = MPLS_FAMILY_IPV4;
+    g.transport_address.u.ipv4 = ntohl(router_id.u.prefix4.s_addr);
+  } else if ((addr = inet_addr(argv[0])) != INADDR_NONE) {
+    ldp->trans_addr = LDP_TRANS_ADDR_STATIC_IP;
+    g.transport_address.type = MPLS_FAMILY_IPV4;
+    g.transport_address.u.ipv4 = ntohl(addr);
+  } else {
+    ifp = if_lookup_by_name(argv[0]);
+    ldp->trans_addr = LDP_TRANS_ADDR_STATIC_INTERFACE;
+    strncpy(ldp->trans_addr_ifname, argv[0], IFNAMSIZ + 1);
+    if (ifp) {
+      g.transport_address.type = MPLS_FAMILY_IPV4;
+      g.transport_address.u.ipv4 = ntohl(if_ipv4_src_address (ifp));
+    }
+  }
+
+  for (ALL_LIST_ELEMENTS_RO(iflist, node, ifp)) {
+    li = ifp->info;
+
+    if (ldp->trans_addr == LDP_TRANS_ADDR_INTERFACE) {
+      li->entity.transport_address.u.ipv4 = ntohl(if_ipv4_src_address (ifp));
+    } else {
+      li->entity.transport_address.u.ipv4 = 0;
+    }
+    li->entity.transport_address.type =
+	li->entity.transport_address.u.ipv4 ?
+	MPLS_FAMILY_IPV4 : MPLS_FAMILY_NONE;
+
+    if (li->entity.index) {
+      ldp_interface_admin_state_start(li);
+      ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_TRANS_ADDR);
+      ldp_interface_admin_state_finish(li);
+    }
+  }
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_TRANS_ADDR);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_transport_address,
+       no_ldp_transport_address_cmd,
+       "no transport-address",
+       NO_STR
+       "No globally specified transport address\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+  struct ldp_interface *li;
+  struct listnode *node;
+  struct interface *ifp;
+
+  ldp->trans_addr = LDP_TRANS_ADDR_NONE;
+   memset(ldp->trans_addr_ifname, 0, IFNAMSIZ + 1);
+
+  g.transport_address.type = MPLS_FAMILY_NONE;
+  g.transport_address.u.ipv4 = 0;
+
+  for (ALL_LIST_ELEMENTS_RO(iflist, node, ifp)) {
+    li = ifp->info;
+
+    li->entity.transport_address.u.ipv4 = 0;
+    li->entity.transport_address.type = MPLS_FAMILY_NONE;
+
+    if (li->entity.index) {
+      ldp_interface_admin_state_start(li);
+      ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_TRANS_ADDR);
+      ldp_interface_admin_state_finish(li);
+    }
+  }
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_TRANS_ADDR);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_lsp_control_mode,
+       ldp_lsp_control_mode_cmd,
+       "lsp-control-mode (independent|ordered)",
+       "control mode\n"
+       "independent or ordered control mode\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  if (!strcmp(argv[0],"independent")) {
+    g.lsp_control_mode = LDP_CONTROL_INDEPENDENT;
+  } else if (!strcmp(argv[0],"ordered")) {
+    g.lsp_control_mode = LDP_CONTROL_ORDERED;
+  } else {
+    return CMD_WARNING;
+  }
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_CONTROL_MODE);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_lsp_control_mode,
+       no_ldp_lsp_control_mode_cmd,
+       "no lsp-control-mode",
+       NO_STR
+       "control mode\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.lsp_control_mode = LDP_GLOBAL_DEF_CONTROL_MODE;
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_CONTROL_MODE);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_label_retention_mode,
+       ldp_label_retention_mode_cmd,
+       "label-retention-mode (liberal|conservative)",
+       "label retention mode\n"
+       "liberal or conservative retention mode\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  if (!strcmp(argv[0],"liberal")) {
+    g.label_retention_mode = LDP_RETENTION_LIBERAL;
+  } else if (!strcmp(argv[0],"conservative")) {
+    g.label_retention_mode = LDP_RETENTION_CONSERVATIVE;
+  } else {
+    return CMD_WARNING;
+  }
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_RETENTION_MODE);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_label_retention_mode,
+       no_ldp_label_retention_mode_cmd,
+       "no label-retention-mode",
+       NO_STR
+       "label retiontion mode\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.label_retention_mode = LDP_GLOBAL_DEF_RETENTION_MODE;
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_RETENTION_MODE);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_lsp_repair_mode,
+       ldp_lsp_repair_mode_cmd,
+       "lsp-repair-mode (local|global)",
+       "repair mode\n"
+       "local or global repair mode\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  if (!strcmp(argv[0],"local")) {
+    g.lsp_repair_mode = LDP_REPAIR_LOCAL;
+  } else if (!strcmp(argv[0],"global")) {
+    g.lsp_repair_mode = LDP_REPAIR_GLOBAL;
+  } else {
+    return CMD_WARNING;
+  }
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_REPAIR_MODE);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_lsp_repair_mode,
+       no_ldp_lsp_repair_mode_cmd,
+       "no lsp-repair-mode",
+       NO_STR
+       "repair mode\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.lsp_repair_mode = LDP_GLOBAL_DEF_REPAIR_MODE;
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_REPAIR_MODE);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_propogate_release,
+       ldp_propogate_release_cmd,
+       "propagate-release",
+       "propagate release\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.propagate_release = MPLS_BOOL_TRUE;
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_PROPOGATE_RELEASE);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_propogate_release,
+       no_ldp_propogate_release_cmd,
+       "no propagate-release",
+       NO_STR
+       "propagate release\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.propagate_release = MPLS_BOOL_FALSE;
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_PROPOGATE_RELEASE);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_label_merge,
+       ldp_label_merge_cmd,
+       "label-merge",
+       "label merge\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.label_merge = MPLS_BOOL_TRUE;
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_LABEL_MERGE);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_label_merge,
+       no_ldp_label_merge_cmd,
+       "no label-merge",
+       NO_STR
+       "label merge\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.label_merge = MPLS_BOOL_FALSE;
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_LABEL_MERGE);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_global_loop_detection_mode,
+       ldp_global_loop_detection_mode_cmd,
+       "loop-detection-mode (hop|path|both)",
+       "loop detection\n"
+       "Path Vector, Hop Count, or both\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  if (!strncmp(argv[0],"hop",3)) {
+    g.loop_detection_mode = LDP_LOOP_HOPCOUNT;
+  } else if (!strncmp(argv[0],"path",4)) {
+    g.loop_detection_mode = LDP_LOOP_PATHVECTOR;
+  } else if (!strncmp(argv[0],"both",4)) {
+    g.loop_detection_mode = LDP_LOOP_HOPCOUNT_PATHVECTOR;
+  } else {
+    return CMD_WARNING;
+  }
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_LOOP_DETECTION_MODE);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_loop_detection_mode,
+       no_ldp_loop_detection_mode_cmd,
+       "no loop-detection-mode (path|hop|both)",
+       NO_STR
+       "loop detection\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.loop_detection_mode = LDP_LOOP_NONE;
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_LOOP_DETECTION_MODE);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_ttl_less_domain,
+       ldp_ttl_less_domain_cmd,
+       "ttl-less-domain",
+       "TTL-less domain\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.ttl_less_domain = MPLS_BOOL_TRUE;
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_TTLLESS_DOMAIN);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_ttl_less_domain,
+       no_ldp_ttl_less_domain_cmd,
+       "no ttl-less-domain",
+       NO_STR
+       "TTL-less domain\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.ttl_less_domain = MPLS_BOOL_FALSE;
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_TTLLESS_DOMAIN);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_local_tcp_port,
+       ldp_local_tcp_port_cmd,
+       "local-tcp-port <1-65535>",
+       "local TCP port\n"
+       "TCP port number\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.local_tcp_port = atoi(argv[0]);
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_LOCAL_TCP_PORT);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_local_tcp_port,
+       no_ldp_local_tcp_port_cmd,
+       "no local-tcp-port",
+       NO_STR
+       "local TCP port\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.local_tcp_port = LDP_GLOBAL_DEF_LOCAL_TCP_PORT;
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_LOCAL_TCP_PORT);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_local_udp_port,
+       ldp_local_udp_port_cmd,
+       "local-udp-port <1-65535>",
+       "local UDP port\n"
+       "UDP port number\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.local_udp_port = atoi(argv[0]);
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_LOCAL_UDP_PORT);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_local_udp_port,
+       no_ldp_local_udp_port_cmd,
+       "no local-udp-port",
+       NO_STR
+       "local UDP port\n")
+{
+  struct ldp *ldp = (struct ldp*)vty->index;
+  ldp_global g;
+
+  g.local_udp_port = LDP_GLOBAL_DEF_LOCAL_UDP_PORT;
+
+  ldp_admin_state_start(ldp);
+  ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_LOCAL_UDP_PORT);
+  ldp_admin_state_finish(ldp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_address,
+       ldp_trace_address_cmd,
+       "trace address",
+       "LDP debugging\n"
+       "Address PDUs\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_ADDRESS;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_binding,
+       ldp_trace_binding_cmd,
+       "trace binding",
+       "LDP debugging\n"
+       "Label Bindings\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_BINDING;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_debug,
+       ldp_trace_debug_cmd,
+       "trace debug",
+       "LDP debugging\n"
+       "Debug Messages\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_DEBUG;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_error,
+       ldp_trace_error_cmd,
+       "trace error",
+       "LDP debugging\n"
+       "Error Conditions\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_ERROR;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_event,
+       ldp_trace_event_cmd,
+       "trace event",
+       "LDP debugging\n"
+       "LDP Events\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_EVENT;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_general,
+       ldp_trace_general_cmd,
+       "trace general",
+       "LDP debugging\n"
+       "General Messages\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_GENERAL;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_init,
+       ldp_trace_init_cmd,
+       "trace init",
+       "LDP debugging\n"
+       "Init PDUs\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_INIT;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_label,
+       ldp_trace_label_cmd,
+       "trace label",
+       "LDP debugging\n"
+       "Label PDUs\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_LABEL;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_normal,
+       ldp_trace_normal_cmd,
+       "trace normal",
+       "LDP debugging\n"
+       "Normal Messages\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_NORMAL;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_notif,
+       ldp_trace_notif_cmd,
+       "trace notification",
+       "LDP debugging\n"
+       "Notification PDUs\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_NOTIF;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_packet_dump,
+       ldp_trace_packet_dump_cmd,
+       "trace packet-dump",
+       "LDP debugging\n"
+       "Packet Dump\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_PACKET_DUMP;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_packet,
+       ldp_trace_packet_cmd,
+       "trace packet",
+       "LDP debugging\n"
+       "Packet tracing\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_PACKET;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_path,
+       ldp_trace_path_cmd,
+       "trace path",
+       "LDP debugging\n"
+       "PATH Info\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_PATH;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_periodic,
+       ldp_trace_periodic_cmd,
+       "trace periodic",
+       "LDP debugging\n"
+       "Periodic PDUs\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_PERIODIC;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_policy,
+       ldp_trace_policy_cmd,
+       "trace policy",
+       "LDP debugging\n"
+       "Policy tracing\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_POLICY;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_route,
+       ldp_trace_route_cmd,
+       "trace route",
+       "LDP debugging\n"
+       "Route Lookup tracing\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_ROUTE;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_state,
+       ldp_trace_state_cmd,
+       "trace state",
+       "LDP debugging\n"
+       "State transitions\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_STATE;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_task,
+       ldp_trace_task_cmd,
+       "trace task",
+       "LDP debugging\n"
+       "Task tracing\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_TASK;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_timer,
+       ldp_trace_timer_cmd,
+       "trace timer",
+       "LDP debugging\n"
+       "Timer tracing\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_TIMER;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_all,
+       ldp_trace_all_cmd,
+       "trace all",
+       "LDP debugging\n"
+       "All tracing\n")
+{
+  ldp_traceflags |= LDP_TRACE_FLAG_ALL;
+  return CMD_SUCCESS;
+}
+
+DEFUN (ldp_trace_none,
+       ldp_trace_none_cmd,
+       "trace none",
+       "LDP debugging\n"
+       "Turn off all tracing\n")
+{
+  ldp_traceflags = 0;
+  return CMD_SUCCESS;
+}
+
+/* address and egress changes should result in an event which goes through
+   all of the existing FECs/addresses and decides which to withdrawl and then
+   ask the system for which additional FECs/addresses should be sent */
+
+DEFUN (ldp_address,
+       ldp_address_cmd,
+       "address-mode (lsr-id|ldp)",
+       "Addresses this LSR will announce\n"
+       "LSR-ID only\n"
+       "Only LDP interfaces\n")
+{
+    struct ldp *ldp = (struct ldp*)vty->index;
+    if (!strncmp(argv[0], "lsr-id",6)) {
+	ldp->address = LDP_ADDRESS_LSRID;
+    } else if (!strncmp(argv[0], "ldp",3)) {
+	ldp->address = LDP_ADDRESS_LDP;
+    } else {
+	return CMD_WARNING;
+    }
+    return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_address,
+       no_ldp_address_cmd,
+       "no address-mode",
+       NO_STR
+       "Addresses this LSR will announce\n")
+{
+    struct ldp *ldp = (struct ldp*)vty->index;
+    ldp->address = LDP_ADDRESS_ALL;
+    return CMD_SUCCESS;
+}
+
+DEFUN (ldp_egress,
+       ldp_egress_cmd,
+       "egress (lsr-id|connected)",
+       "Filter FECs this LSR will send mappings for\n"
+       "LSR-ID only\n"
+       "All connected subnets\n")
+{
+    struct ldp *ldp = (struct ldp*)vty->index;
+    if (!strncmp(argv[0], "lsr-id",6)) {
+	ldp->egress = LDP_EGRESS_LSRID;
+    } else if (!strncmp(argv[0], "connected", 9)) {
+	ldp->egress = LDP_EGRESS_CONNECTED;
+    } else {
+	return CMD_WARNING;
+    }
+    return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_egress,
+       no_ldp_egress_cmd,
+       "no egress",
+       NO_STR
+       "Filter FECs this LSR will send mappings for\n")
+{
+    struct ldp *ldp = (struct ldp*)vty->index;
+    ldp->egress = LDP_EGRESS_ALL;
+    return CMD_SUCCESS;
+}
+
+#if 0
+DEFUN (ldp_egress_list,
+       ldp_egress_list_cmd,
+       "egress access-list (<1-199>|<1300-2699>|WORD)",
+       "Filter FECs this LSR will send mappings for\n"
+       "IP access-list number\n"
+       "IP access-list number (expanded range)\n"
+       "IP Access-list name\n")
+{
+    return CMD_SUCCESS;
+}
+
+DEFUN (no_ldp_egress_list,
+       no_ldp_egress_list_cmd,
+       "no egress access-list (<1-199>|<1300-2699>|WORD)",
+       NO_STR
+       "Filter FECs this LSR will send mappings for\n"
+       "IP access-list number\n"
+       "IP access-list number (expanded range)\n"
+       "IP Access-list name\n")
+{
+    return CMD_SUCCESS;
+}
+#endif
+
+DEFUN (mpls_show_ldp_attr, mpls_show_ldp_attr_cmd,
+       "show ldp attr",
+       SHOW_STR
+       "LDP"
+       "ATTR\n")
+{
+    struct ldp *ldp = ldp_get();
+
+    if (!ldp) {
+	vty_out (vty, "There isn't an active LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+    ldp_cfg_global_attr(ldp->h);
+    return CMD_SUCCESS;
+}
+
+DEFUN (mpls_show_ldp_fec, mpls_show_ldp_fec_cmd,
+       "show ldp fec",
+       SHOW_STR
+       "LDP"
+       "FEC\n")
+{
+    struct ldp *ldp = ldp_get();
+    struct mpls_fec fec;
+    struct mpls_nexthop nh;
+    struct in_addr addr;
+
+    if (!ldp) {
+	vty_out (vty, "There isn't an active LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+    fec.index = 0;
+    while (ldp_cfg_fec_getnext(ldp->h, &fec, 0xFFFFFFFF) == MPLS_SUCCESS) {
+	addr.s_addr = htonl(fec.u.prefix.network.u.ipv4);
+	vty_out(vty, "FEC: %d %s/%d%s", fec.index, inet_ntoa(addr),
+	    fec.u.prefix.length, VTY_NEWLINE);
+	nh.index = 0;
+	while (ldp_cfg_fec_nexthop_getnext(ldp->h, &fec, &nh,
+	    0xFFFFFFFF) == MPLS_SUCCESS) {
+	    addr.s_addr = htonl(nh.ip.u.ipv4);
+	    vty_out(vty, "\t%d %s %d%s", nh.index, inet_ntoa(addr),
+		nh.attached, VTY_NEWLINE);
+	}
+    }
+    return CMD_SUCCESS;
+}
+
+DEFUN (mpls_show_ldp_interface, mpls_show_ldp_interface_cmd,
+       "show ldp interface",
+       SHOW_STR
+       "LDP"
+       "interface\n")
+{
+    struct ldp *ldp = ldp_get();
+    struct ldp_if iff;
+    struct ldp_addr addr;
+
+    if (!ldp) {
+	vty_out (vty, "There isn't an active LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+    iff.index = 0;
+    while (ldp_cfg_if_getnext(ldp->h, &iff, LDP_IF_CFG_BY_INDEX) ==
+	MPLS_SUCCESS) {
+	vty_out(vty, "INTF: %d%s", iff.index, VTY_NEWLINE);
+	addr.index = 0;
+	while (ldp_cfg_if_addr_getnext(ldp->h, &iff, &addr,
+	    LDP_IF_ADDR_CFG_BY_INDEX | LDP_IF_CFG_BY_INDEX) == MPLS_SUCCESS) {
+	    vty_out(vty, "\t%d%s", addr.index, VTY_NEWLINE);
+	}
+    }
+    return CMD_SUCCESS;
+}
+
+DEFUN (mpls_show_ldp_addr, mpls_show_ldp_addr_cmd,
+       "show ldp addr",
+       SHOW_STR
+       "LDP"
+       "addrs\n")
+{
+    struct ldp *ldp = ldp_get();
+    struct ldp_addr addr;
+
+    if (!ldp) {
+	vty_out (vty, "There isn't an active LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+    memset(&addr, 0, sizeof(addr));
+    while (ldp_cfg_addr_getnext(ldp->h, &addr, 0) == MPLS_SUCCESS) {
+	vty_out(vty, "Addr: %d %08x%s", addr.index, addr.address.u.ipv4,
+	    VTY_NEWLINE);
+	vty_out(vty, "\t%d%s", addr.session_index, VTY_NEWLINE);
+	vty_out(vty, "\t%d%s", addr.nexthop_index, VTY_NEWLINE);
+	vty_out(vty, "\t%d%s", addr.if_index, VTY_NEWLINE);
+
+	addr.session_index = 0;
+	addr.nexthop_index = 0;
+	addr.if_index = 0;
+    }
+    return CMD_SUCCESS;
+}
+
+DEFUN (mpls_show_ldp, mpls_show_ldp_cmd,
+       "show ldp",
+       SHOW_STR
+       "LDP global setting\n")
+{
+    struct ldp *ldp = ldp_get();
+    struct in_addr lsr;
+    ldp_global g;
+
+    if (!ldp) {
+	vty_out (vty, "There isn't an active LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+    ldp_cfg_global_get(ldp->h,&g,0xFFFFFFFF);
+
+    lsr.s_addr = htonl(g.lsr_identifier.u.ipv4);
+    vty_out(vty, "LSR-ID: %-15s Admin State: %s%s", inet_ntoa(lsr),
+	admin_state[g.admin_state], VTY_NEWLINE);
+    lsr.s_addr = htonl(g.transport_address.u.ipv4);
+    vty_out(vty, "Transport Address: %-15s%s", inet_ntoa(lsr),
+      VTY_NEWLINE);
+    vty_out(vty, "Control Mode: %s\tRepair Mode: %s%s",
+      control_mode[g.lsp_control_mode], repair_mode[g.lsp_repair_mode],
+      VTY_NEWLINE);
+    vty_out(vty, "Propogate Release: %s\tLabel Merge: %s%s",
+      bool[g.propagate_release], bool[g.label_merge], VTY_NEWLINE);
+    vty_out(vty, "Retention Mode: %s\tLoop Detection Mode: %s%s",
+      retention_mode[g.label_retention_mode],
+      loop_detect_mode[g.loop_detection_mode], VTY_NEWLINE);
+    vty_out(vty, "TTL-less-domain: %s%s", bool[g.ttl_less_domain],
+      VTY_NEWLINE);
+    vty_out(vty, "Local TCP Port: %d\tLocal UDP Port: %d%s",
+      g.local_tcp_port, g.local_udp_port, VTY_NEWLINE);
+    vty_out(vty, "Keep-alive Time: %d\tKeep-alive Interval: %d%s",
+      g.keepalive_timer, g.keepalive_interval, VTY_NEWLINE);
+    vty_out(vty, "Hello Time: %d\tHello Interval: %d%s",
+      g.hellotime_timer, g.hellotime_interval, VTY_NEWLINE);
+
+    return CMD_SUCCESS;
+}
+
+void convert_seconds_to_string(uint32_t secs, char* buf) {
+  div_t mins;
+  div_t hours;
+  div_t days;
+  int h = 0;
+  int m = 0;
+  int s = 0;
+
+  if (secs >= 60) {
+    mins = div(secs, 60);
+    if (mins.quot >= 60) {
+      hours = div(mins.quot, 60);
+      if (hours.quot >= 24) {
+        days = div(hours.quot, 24);
+        h = days.rem;
+        m = hours.rem;
+        s = mins.rem;
+        sprintf(buf, "%dd %02d:%02d:%02d", days.quot, h, m, s);
+        return;
+      } else {
+        h = hours.quot;
+        m = hours.rem;
+        s = mins.rem;
+      }
+    } else {
+      h = 0;
+      m = mins.quot;
+      s = mins.rem;
+    }
+  } else {
+    h = 0;
+    m = 0;
+    s = secs;
+  }
+  sprintf(buf,"%02d:%02d:%02d", h, m, s);
+}
+
+DEFUN (mpls_show_ldp_neighbor, mpls_show_ldp_neighbor_cmd,
+       "show ldp neighbor",
+       SHOW_STR
+       "LDP related commands\n"
+       "Discovered neighbors\n"
+       "LDP identifier\n")
+{
+  struct ldp *ldp = ldp_get();
+  ldp_adj adj;
+  ldp_addr addr;
+  ldp_entity e;
+  ldp_global g;
+  ldp_session s;
+  int count;
+  int addr_count;
+  uint32_t time_now;
+  char time_buf[13];
+  struct in_addr lsr;
+  struct in_addr src;
+  struct in_addr tr;
+  int label_space = 0;
+  ldp_if iff;
+  ldp_peer peer;
+
+#if 0
+
+Peer LDP Ident: 7.1.1.1:0; Local LDP Ident 8.1.1.1:0
+        TCP connection: 7.1.1.1.646 - 8.1.1.1.11006
+        State: Oper; Msgs sent/rcvd: 4/411; Downstream
+        Up time: 00:00:52
+        LDP discovery sources:
+          Ethernet1/0/0
+        Addresses bound to peer LDP Ident:
+          2.0.0.29        7.1.1.1         59.0.0.199      212.10.1.1
+          10.205.0.9
+
+#endif
+
+    if (!ldp) {
+	vty_out (vty, "There isn't an active LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+    ldp_cfg_global_get(ldp->h,&g,0xFFFFFFFF);
+
+    count = 0;
+    adj.index = 0;
+    while (ldp_cfg_adj_getnext(ldp->h, &adj, 0xFFFFFFFF) ==
+      MPLS_SUCCESS) {
+      count++;
+
+      if (adj.entity_index) {
+        e.index = adj.entity_index;
+        ldp_cfg_entity_get(ldp->h,&e,0xFFFFFFFF);
+        if (e.entity_type == LDP_DIRECT) {
+          iff.index = e.sub_index;
+          ldp_cfg_if_get(ldp->h,&iff,0xFFFFFFFF);
+          label_space = iff.label_space;
+        } else {
+          peer.index = e.sub_index;
+          ldp_cfg_peer_get(ldp->h,&peer,0xFFFFFFFF);
+          label_space = peer.label_space;
+        }
+      }
+
+      lsr.s_addr = htonl(adj.remote_lsr_address.u.ipv4);
+      vty_out(vty, "Peer LDP Ident: %s:%d; Local LDP Ident: ", inet_ntoa(lsr),
+        adj.remote_label_space);
+      lsr.s_addr = htonl(g.lsr_identifier.u.ipv4);
+      vty_out(vty, "%s:%d%s", inet_ntoa(lsr), label_space, VTY_NEWLINE);
+
+      if (adj.session_index) {
+        s.index = adj.session_index;
+
+        if (ldp_cfg_session_get(ldp->h,&s,0xFFFFFFFF) != MPLS_SUCCESS) {
+	  continue;
+        }
+
+        tr.s_addr = htonl(s.local_name.addr.u.ipv4);
+        vty_out(vty, "\tTCP connection: %s.%d", inet_ntoa(tr),
+          s.local_name.port);
+
+        src.s_addr = htonl(s.remote_name.addr.u.ipv4);
+        vty_out(vty, " - %s.%d%s", inet_ntoa(src), s.remote_name.port,
+          VTY_NEWLINE);
+
+        vty_out(vty, "\tState: %s; Msgs sent/recv: %d/%d; %s%s",
+          session_state[s.state], s.mesg_tx, s.mesg_rx,
+          distribution_mode[s.oper_distribution_mode], VTY_NEWLINE);
+        time_now = time(NULL);
+        convert_seconds_to_string(time_now - s.oper_up, time_buf);
+        vty_out(vty, "\tUp time: %s%s", time_buf, VTY_NEWLINE);
+
+        vty_out(vty, "\tLDP discovery sources:%s", VTY_NEWLINE);
+      } else {
+        vty_out(vty, "\tTCP connection: %s%s", "n/a", VTY_NEWLINE);
+        vty_out(vty, "\tState: discovery; Msgs sent/recv: -/-;%s",VTY_NEWLINE);
+        vty_out(vty, "\tUp time: %s%s", "-", VTY_NEWLINE);
+        vty_out(vty, "\tLDP discovery sources:%s", VTY_NEWLINE);
+      }
+      vty_out(vty, "\t  ");
+
+      if (e.entity_type == LDP_DIRECT) {
+        vty_out(vty, "%s ", iff.handle->name);
+      } else {
+        vty_out(vty, "%s ", peer.peer_name);
+      }
+      vty_out(vty, "%s", VTY_NEWLINE);
+
+      if (adj.session_index) {
+        vty_out(vty, "\tAddresses bound to peer:%s", VTY_NEWLINE);
+
+        addr.index = 0;
+        addr_count = 0;
+        while (ldp_cfg_session_raddr_getnext(ldp->h, &s, &addr, 0xFFFFFFFF) ==
+          MPLS_SUCCESS) {
+          lsr.s_addr = htonl(addr.address.u.ipv4);
+          vty_out(vty, "\t");
+          if (!addr_count) {
+            vty_out(vty, "  ");
+          }
+
+          vty_out(vty, "%s",inet_ntoa(lsr));
+          addr_count++;
+
+          if (addr_count == 4) {
+            vty_out(vty, "%s", VTY_NEWLINE);
+            addr_count = 0;
+          }
+        }
+        vty_out(vty, "%s", VTY_NEWLINE);
+      }
+    }
+    vty_out(vty, "%s", VTY_NEWLINE);
+    if (count == 0) {
+      vty_out(vty, "\tNo discovered neighbors%s", VTY_NEWLINE);
+    }
+  vty_out(vty, "%s", VTY_NEWLINE);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_show_ldp_session, mpls_show_ldp_session_cmd,
+       "show ldp session [A.B.C.D:E]",
+       SHOW_STR
+       "LDP related commands\n"
+       "Session information\n"
+       "LDP identifier\n")
+{
+  struct ldp *ldp = ldp_get();
+  ldp_session session;
+  ldp_addr addr;
+  struct in_addr in;
+  int count = 0;
+
+    if (!ldp) {
+	vty_out (vty, "There isn't active LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+    session.index = 0;
+    while (ldp_cfg_session_getnext(ldp->h, &session, 0xFFFFFFFF) ==
+      MPLS_SUCCESS) {
+      count++;
+      in.s_addr = htonl(session.remote_dest.addr.u.ipv4);
+      vty_out(vty, "%-2d %s %-3d %s%s", session.index,
+        inet_ntoa(in), session.oper_keepalive,
+        session_state[session.state], VTY_NEWLINE);
+      addr.index = 0;
+      while (ldp_cfg_session_raddr_getnext(ldp->h, &session,
+        &addr, 0xFFFFFFFF) == MPLS_SUCCESS) {
+        in.s_addr = htonl(addr.address.u.ipv4);
+        vty_out(vty, "\t%s%s",inet_ntoa(in), VTY_NEWLINE);
+      }
+    }
+    if (count == 0) {
+      vty_out(vty, "    no established sessions%s", VTY_NEWLINE);
+    }
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_show_ldp_discovery, mpls_show_ldp_discovery_cmd,
+       "show ldp discovery",
+       SHOW_STR
+       "LDP related commands\n"
+       "Discovery information\n")
+{
+  struct ldp *ldp = ldp_get();
+  struct ldp_interface *li;
+  ldp_if iff;
+  int count;
+  ldp_global g;
+  ldp_adj adj;
+  ldp_entity entity;
+  ldp_peer peer;
+  struct in_addr dst;
+  int first;
+
+    if (!ldp) {
+	vty_out (vty, "There isn't an active LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+  vty_out(vty, "%s", VTY_NEWLINE);
+
+    ldp_cfg_global_get(ldp->h,&g,0xFFFFFFFF);
+    dst.s_addr = htonl(g.lsr_identifier.u.ipv4);
+    vty_out(vty, "Local LSR Identifier: %s%s", inet_ntoa(dst), VTY_NEWLINE);
+    vty_out(vty, "%s", VTY_NEWLINE);
+    vty_out(vty, "Interface Discovery Sources:%s", VTY_NEWLINE);
+
+    count = 0;
+    iff.index = 0;
+    while (ldp_cfg_if_getnext(ldp->h, &iff, 0xFFFFFFFF) == MPLS_SUCCESS) {
+      li = iff.handle->info;
+      if (li->configured == MPLS_BOOL_FALSE) {
+	continue;
+      }
+      first = 1;
+      count++;
+      vty_out(vty, "\t%s: ", iff.handle->name);
+      if (iff.oper_state != MPLS_OPER_UP) {
+        vty_out(vty, "down");
+      } else {
+        vty_out(vty, "xmit");
+        entity.index = iff.entity_index;
+	if (ldp_cfg_entity_get(ldp->h, &entity, 0xFFFFFFFF) != MPLS_SUCCESS) {
+          continue;
+	}
+        do {
+          adj.index = entity.adj_index;
+          if (ldp_cfg_adj_get(ldp->h, &adj, 0xFFFFFFFF) == MPLS_SUCCESS) {
+            if (first) {
+              vty_out(vty, "/recv%s", VTY_NEWLINE);
+              first = 0;
+            }
+            dst.s_addr = htonl(adj.remote_lsr_address.u.ipv4);
+            vty_out(vty, "\t    LDP Id: %s:%d%s ", inet_ntoa(dst),
+              adj.remote_label_space, VTY_NEWLINE);
+          }
+        } while (ldp_cfg_entity_adj_getnext(ldp->h, &entity) == MPLS_SUCCESS);
+      }
+      if (first) {
+        vty_out(vty, "%s", VTY_NEWLINE);
+      }
+    }
+    if (count == 0) {
+      vty_out(vty, "\tNo configured interfaces%s", VTY_NEWLINE);
+    }
+
+    vty_out(vty, "%s", VTY_NEWLINE);
+    vty_out(vty, "Targeted Discovery Sources:%s", VTY_NEWLINE);
+
+    count = 0;
+    peer.index = 0;
+    while (ldp_cfg_peer_getnext(ldp->h, &peer, 0xFFFFFFFF) ==
+      MPLS_SUCCESS) {
+      first = 1;
+      count++;
+      dst.s_addr = htonl(peer.dest.addr.u.ipv4);
+      vty_out(vty, "\t%s: xmit ", inet_ntoa(dst));
+      while (ldp_cfg_adj_getnext(ldp->h, &adj, 0xFFFFFFFF) == MPLS_SUCCESS) {
+        if (peer.entity_index == adj.entity_index) {
+          if (first) {
+            vty_out(vty, "/recv%s", VTY_NEWLINE);
+            first = 0;
+          }
+          dst.s_addr = htonl(adj.remote_lsr_address.u.ipv4);
+          vty_out(vty, "\t    LDP Id: %s:%d%s ", inet_ntoa(dst),
+            adj.remote_label_space, VTY_NEWLINE);
+        }
+      }
+      if (first) {
+        vty_out(vty, "%s", VTY_NEWLINE);
+      }
+    }
+    if (count == 0) {
+      vty_out(vty, "\tNo configured peers%s", VTY_NEWLINE);
+    }
+  vty_out(vty, "%s", VTY_NEWLINE);
+
+  return CMD_SUCCESS;
+}
+
+void ldp_print_label(struct vty *vty, mpls_label_struct *l) {
+  switch(l->type) {
+    case MPLS_LABEL_TYPE_NONE:
+      vty_out(vty, "label: unknown");
+      break;
+    case MPLS_LABEL_TYPE_GENERIC:
+      vty_out(vty, "label: gen %d",l->u.gen);
+      break;
+    case MPLS_LABEL_TYPE_ATM:
+      vty_out(vty, "label: atm %d/%d",l->u.atm.vpi,l->u.atm.vci);
+      break;
+    case MPLS_LABEL_TYPE_FR:
+      vty_out(vty, "label: dlci %d",l->u.fr.dlci);
+      break;
+  }
+}
+
+DEFUN (mpls_show_ldp_database, mpls_show_ldp_database_cmd,
+       "show ldp database [A.B.C.D:E]",
+       SHOW_STR
+       "LDP related commands\n"
+       "Labeling information\n"
+       "LDP identifier\n")
+{
+  struct ldp *ldp = ldp_get();
+  ldp_session session;
+  ldp_outlabel out;
+  ldp_inlabel in;
+  ldp_attr attr;
+  ldp_adj adj;
+  int count = 0;
+  struct in_addr fec;
+
+    if (!ldp) {
+	vty_out (vty, "There isn't an active LDP instance.%s", VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+    attr.index = 0;
+    while (ldp_cfg_attr_getnext(ldp->h, &attr, 0xFFFFFFFF) == MPLS_SUCCESS) {
+      count++;
+
+      fec.s_addr = htonl(attr.fecTlv.fecElArray[0].addressEl.address);
+
+      vty_out(vty, "  %s/%d  ", inet_ntoa(fec),
+        attr.fecTlv.fecElArray[0].addressEl.preLen);
+
+      session.index = attr.session_index;
+      if (ldp_cfg_session_get(ldp->h, &session, 0xFFFFFFFF) != MPLS_SUCCESS) {
+        vty_out(vty, "no session%s",VTY_NEWLINE);
+        continue;
+      }
+
+      adj.index = session.adj_index;
+      if (ldp_cfg_adj_get(ldp->h, &adj, 0xFFFFFFFF) != MPLS_SUCCESS) {
+        vty_out(vty, "no adj%s",VTY_NEWLINE);
+        continue;
+      }
+
+      switch(attr.state) {
+        case LDP_LSP_STATE_MAP_RECV:
+          vty_out(vty, "remote binding:  ");
+          out.index = attr.outlabel_index;
+          if (ldp_cfg_outlabel_get(ldp->h, &out, 0xFFFFFFFF) != MPLS_SUCCESS) {
+            vty_out(vty, "no outlabel");
+          } else {
+            ldp_print_label(vty,&out.info.label);
+          }
+          fec.s_addr = htonl(adj.remote_lsr_address.u.ipv4);
+          vty_out(vty, " lsr: %s:%d ", inet_ntoa(fec), adj.remote_label_space);
+          if (attr.ingress == MPLS_BOOL_TRUE) {
+            vty_out(vty, "ingress");
+          }
+          break;
+        case LDP_LSP_STATE_MAP_SENT:
+          in.index = attr.inlabel_index;
+          if (ldp_cfg_inlabel_get(ldp->h, &in, 0xFFFFFFFF) != MPLS_SUCCESS) {
+            vty_out(vty, "no inlabel%s", VTY_NEWLINE);
+            continue;
+          }
+          vty_out(vty, "local binding:   ");
+          ldp_print_label(vty,&in.info.label);
+          break;
+        case LDP_LSP_STATE_WITH_SENT:
+        case LDP_LSP_STATE_WITH_RECV:
+        case LDP_LSP_STATE_NO_LABEL_RESOURCE_SENT:
+        case LDP_LSP_STATE_NO_LABEL_RESOURCE_RECV:
+        case LDP_LSP_STATE_ABORT_SENT:
+        case LDP_LSP_STATE_ABORT_RECV:
+        case LDP_LSP_STATE_NOTIF_SENT:
+        case LDP_LSP_STATE_NOTIF_RECV:
+        case LDP_LSP_STATE_REQ_RECV:
+        case LDP_LSP_STATE_REQ_SENT:
+          vty_out(vty, "%s:\t", attr_state[attr.state]);
+          fec.s_addr = htonl(adj.remote_lsr_address.u.ipv4);
+          vty_out(vty, "lsr: %s:%d", inet_ntoa(fec), adj.remote_label_space);
+          break;
+        default:
+	  break;
+      }
+      vty_out(vty, "%s", VTY_NEWLINE);
+    }
+    if (count == 0) {
+      vty_out(vty, "    no labeling info has been exchanged%s", VTY_NEWLINE);
+    }
+
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_intf,
+      ldp_intf_cmd,
+      "mpls ip",
+      "MPLS interface configuration\n"
+      "Dynamic label distribution via LDP\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li;
+
+  MPLS_ASSERT(ifp->info);
+
+  li = ifp->info;
+
+  /* 
+   * only configure ldp-portable the first time mpls ip is called
+   */
+  if (li->configured == MPLS_BOOL_FALSE) {
+    li->configured = MPLS_BOOL_TRUE;
+    li->admin_up = MPLS_BOOL_TRUE;
+
+    ldp_interface_create2(li);
+  }
+  vty->node = LDP_IF_NODE;
+
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_intf,
+      no_ldp_intf_cmd,
+      "no mpls ip",
+      NO_STR
+      "MPLS interface configuration\n"
+      "remove LDP\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li;
+
+  MPLS_ASSERT(ifp->info);
+
+  li = ifp->info;
+  ldp_interface_delete2(li);
+
+  li->configured = MPLS_BOOL_FALSE;
+  li->admin_up = MPLS_BOOL_FALSE;
+  
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_xconnect_intf,
+      ldp_xconnect_intf_cmd,
+      "xconnect IPADDR VCID",
+      "Create a Layer 2 over MPLS Cross Connect\n"
+      "IP Address Remote Peer\n"
+      "VC-ID <0-255>\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct mpls_dest dest;
+  int vcid = 0;
+  int gid = -1;
+  struct ldp_remote_peer *rp;
+  struct ldp *ldp = ldp_get();
+
+#if 0
+
+  if (!li->l2cc) {
+    /* user is trying to create a new L2CC interface */
+    li->l2cc = l2cc_if_new(li);
+  }
+#endif
+
+  dest.addr.type = MPLS_FAMILY_IPV4;
+  VTY_GET_IPV4_ADDRESS("IPADDR",dest.addr.u.ipv4,argv[0]);
+  dest.addr.u.ipv4 = ntohl(dest.addr.u.ipv4);
+  dest.port = 646;
+
+  VTY_GET_UINT32_RANGE("VCID",vcid,argv[1],0,255);
+
+  if (ldp_remote_peer_find(ldp, &dest)) {
+    return CMD_WARNING;
+  }
+
+  rp = ldp_remote_peer_new(ldp);
+  listnode_add(ldp->peer_list, rp);
+  ldp_remote_peer_create(rp, &dest);
+
+#if 0
+  l2cc_interface_create(li);
+#endif
+
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_xconnect_intf,
+      no_ldp_xconnect_intf_cmd,
+      "no xconnect IPADDR VCID",
+      NO_STR
+      "Delete a Layer 2 over MPLS Cross Connect\n"
+      "IP Address Remote Peer\n"
+      "VC-ID <0-255>\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct mpls_dest dest;
+  int vcid = 0;
+  int gid = -1;
+  struct ldp *ldp = ldp_get();
+  struct ldp_remote_peer *rp;
+
+  dest.addr.type = MPLS_FAMILY_IPV4;
+  VTY_GET_IPV4_ADDRESS("IPADDR",dest.addr.u.ipv4,argv[0]);
+  dest.port = 646;
+
+  VTY_GET_UINT32_RANGE("VCID",vcid,argv[1],0,255);
+
+  if ((rp = ldp_remote_peer_find(ldp,&dest))) {
+    listnode_delete(ldp->peer_list, rp);
+    ldp_remote_peer_delete(rp);
+    ldp_remote_peer_free(rp);
+  }
+
+#if 0
+  if (li->l2cc) {
+    l2cc_interface_delete(li);
+    l2cc_if_free(li->l2cc);
+    li->l2cc = NULL;
+  }
+#endif
+  return CMD_SUCCESS;
+}
+
+#if 0
+DEFUN(ldp_xconnect_vfi_intf,
+      ldp_xconnect_vfi_intf_cmd,
+      "xconnect vfi WORD",
+      "Add interface to a VPLS\n"
+      "VFI Name\n")
+{
+}
+
+DEFUN(no_ldp_xconnect_vfi_intf,
+      no_ldp_xconnect_vfi_intf_cmd,
+      "no xconnect vfi WORD",
+      NO_STR
+      "Remove interface from a VPLS\n"
+      "VFI Name\n")
+{
+}
+#endif
+
+DEFUN(ldp_if_distribution_mode,
+      ldp_if_distribution_mode_cmd,
+      "distribution-mode (dod|du)",
+      "MPLS interface configuration\n"
+      "distribution mode\n"
+      "Downstream on Demand or Downstream unsolicited\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  if (!strncmp(argv[0],"dod",3)) {
+    li->entity.label_distribution_mode = LDP_DISTRIBUTION_ONDEMAND;
+  } else if (!strncmp(argv[0],"du",2)) {
+    li->entity.label_distribution_mode = LDP_DISTRIBUTION_UNSOLICITED;
+  } else {
+    return CMD_WARNING;
+  }
+
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+  ldp_interface_admin_state_start(li);
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_DISTRIBUTION_MODE);
+  ldp_interface_admin_state_finish(li);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_distribution_mode,
+      no_ldp_if_distribution_mode_cmd,
+      "no distribution-mode",
+      NO_STR
+      "MPLS interface configuration\n"
+      "distribution mode\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.label_distribution_mode = LDP_ENTITY_DEF_DISTRIBUTION_MODE;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_DISTRIBUTION_MODE);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_remote_tcp_port,
+      ldp_if_remote_tcp_port_cmd,
+      "remote-tcp-port <1-65535>",
+      "MPLS interface configuration\n"
+      "remote LDP port\n"
+      "port number\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.remote_tcp_port = atoi(argv[0]);
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_REMOTE_TCP);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_remote_tcp_port,
+      no_ldp_if_remote_tcp_port_cmd,
+      "no remote-tcp-port",
+      NO_STR
+      "MPLS interface configuration\n"
+      "remote LDP port\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.remote_tcp_port = LDP_ENTITY_DEF_REMOTE_TCP;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_REMOTE_TCP);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_remote_udp_port,
+      ldp_if_remote_udp_port_cmd,
+      "remote-udp-port <1-65535>",
+      "MPLS interface configuration\n"
+      "remote LDP port\n"
+      "port number\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.remote_udp_port = atoi(argv[0]);
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_REMOTE_UDP);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_remote_udp_port,
+      no_ldp_if_remote_udp_port_cmd,
+      "no remote-udp-port",
+      NO_STR
+      "MPLS interface configuration\n"
+      "remote LDP port\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.remote_udp_port = LDP_ENTITY_DEF_REMOTE_UDP;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_REMOTE_UDP);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_max_pdu,
+      ldp_if_max_pdu_cmd,
+      "max-pdu <64-9182>",
+      "MPLS interface configuration\n"
+      "maximum LDP PDU size\n"
+      "PDU size\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.max_pdu = atoi(argv[0]);
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_MAX_PDU);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_max_pdu,
+      no_ldp_if_max_pdu_cmd,
+      "no max-pdu",
+      NO_STR
+      "MPLS interface configuration\n"
+      "maximum LDP pdu size\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.max_pdu = LDP_ENTITY_DEF_MAX_PDU;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_MAX_PDU);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_hello_interval,
+      ldp_if_hello_interval_cmd,
+      "hello-interval <1-60>",
+      "MPLS interface configuration\n"
+      "hello interval\n"
+      "interval in seconds\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.hellotime_interval = atoi(argv[0]);
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_HELLOTIME_INTERVAL);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_hello_interval,
+      no_ldp_if_hello_interval_cmd,
+      "no hello-interval",
+      NO_STR
+      "MPLS interface configuration\n"
+      "hello interval\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.hellotime_interval = LDP_ENTITY_DEF_HELLOTIME_INTERVAL;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_HELLOTIME_INTERVAL);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_keepalive_interval,
+      ldp_if_keepalive_interval_cmd,
+      "keepalive-interval <1-60>",
+      "MPLS interface configuration\n"
+      "keepalive interval\n"
+      "interval in seconds\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.keepalive_interval = atoi(argv[0]);
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_KEEPALIVE_INTERVAL);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_keepalive_interval,
+      no_ldp_if_keepalive_interval_cmd,
+      "no keepalive-interval",
+      NO_STR
+      "MPLS interface configuration\n"
+      "keepalive interval\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.keepalive_interval = LDP_ENTITY_DEF_KEEPALIVE_INTERVAL;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_KEEPALIVE_INTERVAL);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_max_session_attempt,
+      ldp_if_max_session_attempt_cmd,
+      "max-session-attempt <0-1024>",
+      "MPLS interface configuration\n"
+      "maximum LDP session setup attempt\n"
+      "Number of attempts (0 means keep trying)\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.session_setup_count = atoi(argv[0]);
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_SESSION_SETUP_COUNT);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_max_session_attempt,
+      no_ldp_if_max_session_attempt_cmd,
+      "no max-session-attempt\n",
+      NO_STR
+      "MPLS interface configuration\n"
+      "maximum LDP session setup attempt\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.session_setup_count = LDP_ENTITY_DEF_SESSIONSETUP_COUNT;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_SESSION_SETUP_COUNT);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_max_path_vector,
+      ldp_if_max_path_vector_cmd,
+      "max-path-vector <1-255>",
+      "MPLS interface configuration\n"
+      "maximum path vector\n"
+      "number of entries\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.path_vector_limit = atoi(argv[0]);
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_PATHVECTOR_LIMIT);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_max_path_vector,
+      no_ldp_if_max_path_vector_cmd,
+      "no max-path-vector",
+      NO_STR
+      "MPLS interface configuration\n"
+      "maximum path vector\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.path_vector_limit = LDP_ENTITY_DEF_PATHVECTOR_LIMIT;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_PATHVECTOR_LIMIT);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_max_hop_count,
+      ldp_if_max_hop_count_cmd,
+      "max-hop-count <1-1024>",
+      "MPLS interface configuration\n"
+      "maximum hop count\n"
+      "number of hops\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.hop_count_limit = atoi(argv[0]);
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_HOPCOUNT_LIMIT);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_max_hop_count,
+      no_ldp_if_max_hop_count_cmd,
+      "no max-hop-count",
+      NO_STR
+      "MPLS interface configuration\n"
+      "maximum hop count\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.hop_count_limit = LDP_ENTITY_DEF_HOPCOUNT_LIMIT;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_HOPCOUNT_LIMIT);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_max_label_requests,
+      ldp_if_max_label_requests_cmd,
+      "max-label-requests <0-1024>",
+      "MPLS interface configuration\n"
+      "maximum times to make a request for a FEC\n"
+      "Number of attempts (0 means keep trying)\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.label_request_count = atoi(argv[0]);
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_REQUEST_COUNT);
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_max_label_requests,
+      no_ldp_if_max_label_requests_cmd,
+      "no max-label-requests",
+      NO_STR
+      "MPLS interface configuration\n"
+      "maximum times to make a request for a FEC\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.label_request_count = LDP_ENTITY_DEF_REQUEST_COUNT;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  ldp_cfg_entity_set(ldp->h, &li->entity, LDP_ENTITY_CFG_REQUEST_COUNT);
+  return CMD_SUCCESS;
+}
+
+DEFUN(ldp_if_ttl_less_domain,
+      ldp_if_ttl_less_domain_cmd,
+      "ttl-less-domain",
+      "MPLS interface configuration\n"
+      "TTL less domain\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.remote_in_ttl_less_domain = MPLS_BOOL_TRUE;
+  if (!ldp) {
+    li->create_on_hold = MPLS_BOOL_TRUE;
+    return CMD_SUCCESS;
+  }
+
+  return CMD_SUCCESS;
+}
+
+DEFUN(no_ldp_if_ttl_less_domain,
+      no_ldp_if_ttl_less_domain_cmd,
+      "no ttl-less-domain",
+      NO_STR
+      "MPLS interface configuration\n"
+      "TTL less domain\n")
+{
+  struct interface *ifp = vty->index;
+  struct ldp_interface *li = (struct ldp_interface*)ifp->info;
+  struct ldp *ldp = ldp_get();
+
+  li->entity.remote_in_ttl_less_domain = MPLS_BOOL_FALSE;
+  if (!ldp) {
+    return CMD_SUCCESS;
+  }
+
+  return CMD_SUCCESS;
+}
+
+static int ldp_if_config_write (struct vty *vty) {
+  return 0;
+}
+
+static int ldp_config_write (struct vty *vty) {
+  struct ldp *ldp = ldp_get();
+  ldp_global g;
+  int write = 0;
+  struct in_addr addr;
+
+  if (ldp) {
+    vty_out (vty, "!%s", VTY_NEWLINE);
+    vty_out (vty, "mpls ldp%s", VTY_NEWLINE);
+    write++;
+
+    if (ldp_traceflags & LDP_TRACE_FLAG_ADDRESS)
+      vty_out (vty, " trace address%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_BINDING)
+      vty_out (vty, " trace binding%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_DEBUG)
+      vty_out (vty, " trace debug%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_ERROR)
+      vty_out (vty, " trace error%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_EVENT)
+      vty_out (vty, " trace event%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_GENERAL)
+      vty_out (vty, " trace general%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_INIT)
+      vty_out (vty, " trace init%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_LABEL)
+      vty_out (vty, " trace label%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_NORMAL)
+      vty_out (vty, " trace normal%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_NOTIF)
+      vty_out (vty, " trace notification%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_PACKET_DUMP)
+      vty_out (vty, " trace packet-dump%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_PACKET)
+      vty_out (vty, " trace packet%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_PATH)
+      vty_out (vty, " trace path%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_PERIODIC)
+      vty_out (vty, " trace periodic%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_POLICY)
+      vty_out (vty, " trace policy%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_ROUTE)
+      vty_out (vty, " trace route%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_STATE)
+      vty_out (vty, " trace state%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_TASK)
+      vty_out (vty, " trace task%s", VTY_NEWLINE);
+    if (ldp_traceflags & LDP_TRACE_FLAG_TIMER)
+      vty_out (vty, " trace timer%s", VTY_NEWLINE);
+
+    ldp_cfg_global_get(ldp->h,&g, 0xFFFFFFFF);
+
+    if (g.lsp_control_mode != LDP_GLOBAL_DEF_CONTROL_MODE) {
+      vty_out (vty, " lsp-control-mode ");
+      if (g.lsp_control_mode == LDP_CONTROL_INDEPENDENT) {
+        vty_out (vty, "independent%s", VTY_NEWLINE);
+      } else {
+        vty_out (vty, "ordered%s", VTY_NEWLINE);
+      }
+    }
+    if (g.label_retention_mode != LDP_GLOBAL_DEF_RETENTION_MODE) {
+      vty_out (vty, " label-retention-mode ");
+      if (g.label_retention_mode == LDP_RETENTION_LIBERAL) {
+        vty_out (vty, "liberal%s", VTY_NEWLINE);
+      } else {
+        vty_out (vty, "conservative%s", VTY_NEWLINE);
+      }
+    }
+    if (g.lsp_repair_mode != LDP_GLOBAL_DEF_REPAIR_MODE) {
+      vty_out (vty, " lsp-repair-mode ");
+      if (g.lsp_repair_mode == LDP_REPAIR_LOCAL) {
+        vty_out (vty, "local%s", VTY_NEWLINE);
+      } else {
+        vty_out (vty, "global%s", VTY_NEWLINE);
+      }
+    }
+    if (g.propagate_release != LDP_GLOBAL_DEF_PROPOGATE_RELEASE) {
+      if (g.propagate_release == MPLS_BOOL_TRUE) {
+        vty_out (vty, " propagate-release%s", VTY_NEWLINE);
+      } else {
+        vty_out (vty, " no propagate-release%s", VTY_NEWLINE);
+      }
+    }
+    if (g.label_merge != LDP_GLOBAL_DEF_LABEL_MERGE) {
+      if (g.label_merge == MPLS_BOOL_TRUE) {
+        vty_out (vty, " label-merge%s", VTY_NEWLINE);
+      } else {
+        vty_out (vty, " no label-merge%s", VTY_NEWLINE);
+      }
+    }
+    if (g.loop_detection_mode != LDP_GLOBAL_DEF_LOOP_DETECTION_MODE) {
+      if (g.loop_detection_mode == LDP_LOOP_HOPCOUNT) {
+        vty_out (vty, " loop-detection-mode hop%s", VTY_NEWLINE);
+      } else if (g.loop_detection_mode == LDP_LOOP_PATHVECTOR) {
+        vty_out (vty, " loop-detection-mode path%s", VTY_NEWLINE);
+      } else if (g.loop_detection_mode == LDP_LOOP_HOPCOUNT_PATHVECTOR) {
+        vty_out (vty, " loop-detection-mode both%s", VTY_NEWLINE);
+      } else {
+        vty_out (vty, " no loop-detection-mode%s", VTY_NEWLINE);
+      }
+    }
+    if (g.ttl_less_domain != MPLS_BOOL_FALSE) {
+      vty_out (vty, " ttl-less-domain%s", VTY_NEWLINE);
+    }
+    if (g.local_tcp_port != LDP_GLOBAL_DEF_LOCAL_TCP_PORT) {
+      vty_out (vty, " local-tcp-port %d%s", g.local_tcp_port, VTY_NEWLINE);
+    }
+    if (g.local_udp_port != LDP_GLOBAL_DEF_LOCAL_UDP_PORT) {
+      vty_out (vty, " local-udp-port %d%s", g.local_udp_port, VTY_NEWLINE);
+    }
+
+    switch (ldp->egress) {
+      case LDP_EGRESS_LSRID:
+        vty_out (vty, " egress lsr-id%s", VTY_NEWLINE);
+        break;
+      case LDP_EGRESS_CONNECTED:
+        vty_out (vty, " egress connected%s", VTY_NEWLINE);
+        break;
+      default:
+	break;
+    }
+
+    switch (ldp->address) {
+      case LDP_ADDRESS_LSRID:
+        vty_out (vty, " address-mode lsr-id%s", VTY_NEWLINE);
+        break;
+      case LDP_ADDRESS_LDP:
+        vty_out (vty, " address-mode ldp%s", VTY_NEWLINE);
+        break;
+      default:
+	break;
+    }
+
+    switch (ldp->trans_addr) {
+      case LDP_TRANS_ADDR_LSRID:
+        vty_out (vty, " transport-address lsr-id%s", VTY_NEWLINE);
+        break;
+      case LDP_TRANS_ADDR_INTERFACE:
+        vty_out (vty, " transport-address interface%s", VTY_NEWLINE);
+        break;
+      case LDP_TRANS_ADDR_STATIC_IP:
+        addr.s_addr = htonl(g.transport_address.u.ipv4);
+        vty_out (vty, " transport-address %s%s", inet_ntoa(addr), VTY_NEWLINE);
+        break;
+      case LDP_TRANS_ADDR_STATIC_INTERFACE:
+        vty_out (vty, " transport-address %s%s", ldp->trans_addr_ifname,
+	  VTY_NEWLINE);
+        break;
+      default:
+	break;
+    }
+  }
+  return write;
+}
+
+#if 0
+int ldp_interface_config_write(struct vty *vty) {
+    struct ldp *ldp = ldp_get();
+    struct listnode* node;
+    struct interface *ifp;
+
+    ldp_entity e;
+    mpls_fec l;
+    int write = 0;
+
+    if (li && li->ldp) {
+    } else if (li && li->l2cc) {
+//	struct in_addr tmp;
+	l2 = li->l2cc;
+	ldp = ldp_get();
+
+        write++;
+
+	if (l2->l2cc.index) {
+          l.index = l2->l2cc.index;
+	  ldp_cfg_fec_get(ldp->h, &l, 0xFFFFFFFF);
+	} else {
+	  memcpy(&l,&l2->l2cc,sizeof(ldp_fec));
+	}
+#if 0
+	tmp.s_addr = htonl(l.info.nh.ip.u.ipv4);
+        vty_out(vty, " mpls l2cc peer %s",inet_ntoa(tmp));
+	vty_out(vty, " vcid %d",l.info.u.l2cc.connection_id);
+	if (l.info.u.l2cc.group_id) {
+	  vty_out(vty, " groupid %d", l.info.u.l2cc.group_id);
+	}
+#endif
+	vty_out(vty, "%s", VTY_NEWLINE);
+
+        vty_out(vty, " !%s",VTY_NEWLINE);
+    }
+
+
+    return write;
+}
+#endif
+
+void ldp_vty_show_init() {
+
+  install_element (VIEW_NODE, &mpls_show_ldp_cmd);
+  install_element (ENABLE_NODE, &mpls_show_ldp_cmd);
+
+  install_element (VIEW_NODE, &mpls_show_ldp_fec_cmd);
+  install_element (ENABLE_NODE, &mpls_show_ldp_fec_cmd);
+
+  install_element (VIEW_NODE, &mpls_show_ldp_attr_cmd);
+  install_element (ENABLE_NODE, &mpls_show_ldp_attr_cmd);
+
+  install_element (VIEW_NODE, &mpls_show_ldp_addr_cmd);
+  install_element (ENABLE_NODE, &mpls_show_ldp_addr_cmd);
+
+  install_element (VIEW_NODE, &mpls_show_ldp_interface_cmd);
+  install_element (ENABLE_NODE, &mpls_show_ldp_interface_cmd);
+
+  install_element (VIEW_NODE, &mpls_show_ldp_neighbor_cmd);
+  install_element (ENABLE_NODE, &mpls_show_ldp_neighbor_cmd);
+
+  install_element (VIEW_NODE, &mpls_show_ldp_session_cmd);
+  install_element (ENABLE_NODE, &mpls_show_ldp_session_cmd);
+
+  install_element (VIEW_NODE, &mpls_show_ldp_discovery_cmd);
+  install_element (ENABLE_NODE, &mpls_show_ldp_discovery_cmd);
+
+  install_element (VIEW_NODE, &mpls_show_ldp_database_cmd);
+  install_element (ENABLE_NODE, &mpls_show_ldp_database_cmd);
+}
+
+extern void dump_mpls_node(struct vty*,struct route_node*);
+
+static int ldp_interface_config_write(struct vty *vty) {
+  struct ldp *ldp = ldp_get();
+  struct listnode* node;
+  struct interface *ifp;
+  struct ldp_interface *li;
+  ldp_entity e;
+
+  for (ALL_LIST_ELEMENTS_RO(iflist, node, ifp)) {
+
+    vty_out(vty, "interface %s%s", ifp->name, VTY_NEWLINE);
+
+    if (ifp->desc) {
+      vty_out(vty, " description %s%s", ifp->desc, VTY_NEWLINE);
+    }
+
+    li = ifp->info;
+    if (li) {
+      if (li->configured == MPLS_BOOL_TRUE) {
+	vty_out(vty, " mpls ip%s", VTY_NEWLINE);
+      }
+
+	if (li->entity.index && ldp) {
+          e.index = li->entity.index;
+	  ldp_cfg_entity_get(ldp->h, &e, 0xFFFFFFFF);
+	} else {
+	  memcpy(&e,&li->entity,sizeof(ldp_entity));
+	}
+
+        if (e.label_distribution_mode != LDP_ENTITY_DEF_DISTRIBUTION_MODE) {
+          vty_out(vty, "   distribution-mode ");
+          if (e.label_distribution_mode == LDP_DISTRIBUTION_ONDEMAND) {
+            vty_out(vty, "dod%s", VTY_NEWLINE);
+          } else {
+            vty_out(vty, "du%s", VTY_NEWLINE);
+          }
+        }
+        if (e.remote_tcp_port != LDP_ENTITY_DEF_REMOTE_TCP) {
+          vty_out(vty, "   remote-tcp-port %d%s", e.remote_tcp_port,
+            VTY_NEWLINE);
+        }
+        if (e.remote_udp_port != LDP_ENTITY_DEF_REMOTE_UDP) {
+          vty_out(vty, "   remote-udp-port %d%s", e.remote_udp_port,
+            VTY_NEWLINE);
+        }
+        if (e.max_pdu != LDP_ENTITY_DEF_MAX_PDU) {
+          vty_out(vty, "   max-pdu %d%s", e.max_pdu, VTY_NEWLINE);
+        }
+        if (e.hellotime_interval != LDP_ENTITY_DEF_HELLOTIME_INTERVAL) {
+          vty_out(vty, "   hello-interval %d%s", e.hellotime_interval,
+            VTY_NEWLINE);
+        }
+        if (e.keepalive_interval != LDP_ENTITY_DEF_KEEPALIVE_INTERVAL) {
+          vty_out(vty, "   keepalive-interval %d%s",
+            e.keepalive_interval, VTY_NEWLINE);
+        }
+        if (e.session_setup_count != LDP_ENTITY_DEF_SESSIONSETUP_COUNT) {
+          vty_out(vty, "   max-session-attempt %d%s",
+            e.session_setup_count, VTY_NEWLINE);
+        }
+        if (e.path_vector_limit != LDP_ENTITY_DEF_PATHVECTOR_LIMIT) {
+          vty_out(vty, "   max-path-vector %d%s",
+            e.path_vector_limit, VTY_NEWLINE);
+        }
+        if (e.hop_count_limit != LDP_ENTITY_DEF_HOPCOUNT_LIMIT) {
+          vty_out(vty, "   max-hop-count %d%s",
+            e.hop_count_limit, VTY_NEWLINE);
+        }
+        if (e.label_request_count != LDP_ENTITY_DEF_REQUEST_COUNT) {
+          vty_out(vty, "   max-label-requests %d%s",
+            e.label_request_count, VTY_NEWLINE);
+        }
+    }
+    vty_out(vty, "!%s", VTY_NEWLINE);
+  }
+  return 0;
+}
+
+static struct cmd_node ldp_node = {LDP_NODE,"%s(config-ldp)# ",1};
+static struct cmd_node interface_node = {INTERFACE_NODE,"%s(config-if)# ",1};
+static struct cmd_node ldp_if_node = {LDP_IF_NODE,"%s(config-if-ldp)# ",1};
+
+void ldp_vty_init () {
+
+  install_node (&ldp_node, ldp_config_write);
+
+  install_default (LDP_NODE);
+
+  install_element (CONFIG_NODE, &mpls_ldp_cmd);
+  install_element (CONFIG_NODE, &no_mpls_ldp_cmd);
+
+  install_element (LDP_NODE, &ldp_lsrid_cmd);
+  install_element (LDP_NODE, &no_ldp_lsrid_cmd);
+
+  install_element (LDP_NODE, &ldp_disable_cmd);
+  install_element (LDP_NODE, &no_ldp_disable_cmd);
+
+  install_element (LDP_NODE, &ldp_transport_address_cmd);
+  install_element (LDP_NODE, &no_ldp_transport_address_cmd);
+
+  install_element (LDP_NODE, &ldp_lsp_control_mode_cmd);
+  install_element (LDP_NODE, &no_ldp_lsp_control_mode_cmd);
+
+  install_element (LDP_NODE, &ldp_label_retention_mode_cmd);
+  install_element (LDP_NODE, &no_ldp_label_retention_mode_cmd);
+
+  install_element (LDP_NODE, &ldp_lsp_repair_mode_cmd);
+  install_element (LDP_NODE, &no_ldp_lsp_repair_mode_cmd);
+
+  install_element (LDP_NODE, &ldp_propogate_release_cmd);
+  install_element (LDP_NODE, &no_ldp_propogate_release_cmd);
+
+  install_element (LDP_NODE, &ldp_label_merge_cmd);
+  install_element (LDP_NODE, &no_ldp_label_merge_cmd);
+
+  install_element (LDP_NODE, &ldp_global_loop_detection_mode_cmd);
+  install_element (LDP_NODE, &no_ldp_loop_detection_mode_cmd);
+
+  install_element (LDP_NODE, &ldp_ttl_less_domain_cmd);
+  install_element (LDP_NODE, &no_ldp_ttl_less_domain_cmd);
+
+  install_element (LDP_NODE, &ldp_local_tcp_port_cmd);
+  install_element (LDP_NODE, &no_ldp_local_tcp_port_cmd);
+
+  install_element (LDP_NODE, &ldp_local_udp_port_cmd);
+  install_element (LDP_NODE, &no_ldp_local_udp_port_cmd);
+
+  install_element (LDP_NODE, &ldp_trace_address_cmd);
+  install_element (LDP_NODE, &ldp_trace_binding_cmd);
+  install_element (LDP_NODE, &ldp_trace_debug_cmd);
+  install_element (LDP_NODE, &ldp_trace_error_cmd);
+  install_element (LDP_NODE, &ldp_trace_event_cmd);
+  install_element (LDP_NODE, &ldp_trace_general_cmd);
+  install_element (LDP_NODE, &ldp_trace_init_cmd);
+  install_element (LDP_NODE, &ldp_trace_label_cmd);
+  install_element (LDP_NODE, &ldp_trace_normal_cmd);
+  install_element (LDP_NODE, &ldp_trace_notif_cmd);
+  install_element (LDP_NODE, &ldp_trace_packet_dump_cmd);
+  install_element (LDP_NODE, &ldp_trace_packet_cmd);
+  install_element (LDP_NODE, &ldp_trace_path_cmd);
+  install_element (LDP_NODE, &ldp_trace_periodic_cmd);
+  install_element (LDP_NODE, &ldp_trace_policy_cmd);
+  install_element (LDP_NODE, &ldp_trace_route_cmd);
+  install_element (LDP_NODE, &ldp_trace_state_cmd);
+  install_element (LDP_NODE, &ldp_trace_task_cmd);
+  install_element (LDP_NODE, &ldp_trace_timer_cmd);
+  install_element (LDP_NODE, &ldp_trace_all_cmd);
+  install_element (LDP_NODE, &ldp_trace_none_cmd);
+
+  install_element (LDP_NODE, &ldp_egress_cmd);
+  install_element (LDP_NODE, &no_ldp_egress_cmd);
+  install_element (LDP_NODE, &ldp_address_cmd);
+  install_element (LDP_NODE, &no_ldp_address_cmd);
+
+  install_node(&interface_node, ldp_interface_config_write);
+
+  install_element(CONFIG_NODE, &interface_cmd);
+  install_default(INTERFACE_NODE);
+
+  install_element(INTERFACE_NODE,&interface_desc_cmd);
+  install_element(INTERFACE_NODE,&no_interface_desc_cmd);
+
+  install_node (&ldp_if_node, ldp_if_config_write);
+  install_default (LDP_IF_NODE);
+
+  install_element (INTERFACE_NODE, &ldp_intf_cmd);
+  install_element (INTERFACE_NODE, &no_ldp_intf_cmd);
+
+#if 0
+  install_element (INTERFACE_NODE, &ldp_xconnect_intf_cmd);
+  install_element (INTERFACE_NODE, &no_ldp_xconnect_intf_cmd);
+#endif
+
+  install_element (LDP_IF_NODE, &ldp_if_remote_tcp_port_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_remote_tcp_port_cmd);
+
+  install_element (LDP_IF_NODE, &ldp_if_remote_udp_port_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_remote_udp_port_cmd);
+
+  install_element (LDP_IF_NODE, &ldp_if_max_pdu_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_max_pdu_cmd);
+
+  install_element (LDP_IF_NODE, &ldp_if_hello_interval_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_hello_interval_cmd);
+
+  install_element (LDP_IF_NODE, &ldp_if_keepalive_interval_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_keepalive_interval_cmd);
+
+#if 0
+  install_element (LDP_IF_NODE, &ldp_if_loop_detect_mode_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_loop_detect_mode_cmd);
+#endif
+
+  install_element (LDP_IF_NODE, &ldp_if_max_session_attempt_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_max_session_attempt_cmd);
+
+  install_element (LDP_IF_NODE, &ldp_if_max_path_vector_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_max_path_vector_cmd);
+
+  install_element (LDP_IF_NODE, &ldp_if_max_hop_count_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_max_hop_count_cmd);
+
+  install_element (LDP_IF_NODE, &ldp_if_max_label_requests_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_max_label_requests_cmd);
+
+  install_element (LDP_IF_NODE, &ldp_if_distribution_mode_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_distribution_mode_cmd);
+
+  install_element (LDP_IF_NODE, &ldp_if_ttl_less_domain_cmd);
+  install_element (LDP_IF_NODE, &no_ldp_if_ttl_less_domain_cmd);
+}
diff -Naur quagga-0.99.10/ldpd/ldp_vty.h quagga-mpls/ldpd/ldp_vty.h
--- quagga-0.99.10/ldpd/ldp_vty.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_vty.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,31 @@
+#ifndef LDP_VTY_H
+#define LDP_VTY_H
+
+#include "ldp_interface.h"
+
+void ldp_vty_show_init();
+void ldp_vty_if_init();
+void ldp_vty_init();
+
+#define VTY_GET_UINT32(NAME,V,STR)                                            \
+{                                                                             \
+  char *endptr = NULL;                                                        \
+  (V) = strtoul ((STR), &endptr, 10);                                         \
+  if (*endptr != '\0' || ((V) == ULONG_MAX && errno == ERANGE))               \
+    {                                                                         \
+      vty_out (vty, "%% Invalid %s value%s", NAME, VTY_NEWLINE);              \
+      return CMD_WARNING;                                                     \
+    }                                                                         \
+}
+
+#define VTY_GET_UINT32_RANGE(NAME,V,STR,IMIN,IMAX)                            \
+{                                                                             \
+  VTY_GET_UINT32(NAME,V,STR);                                                 \
+  if (((V) < IMIN) || ((V) > IMAX))                                           \
+    {                                                                         \
+      vty_out (vty, "%% Invalid %s value.  Valid range is (%d ... %d)%s",     \
+         NAME, IMIN, IMAX, VTY_NEWLINE);                                      \
+      return CMD_WARNING;                                                     \
+    }                                                                         \
+}
+#endif
diff -Naur quagga-0.99.10/ldpd/ldp_zebra.c quagga-mpls/ldpd/ldp_zebra.c
--- quagga-0.99.10/ldpd/ldp_zebra.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_zebra.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,577 @@
+#include <zebra.h>
+
+#include "command.h"
+#include "prefix.h"
+#include "stream.h"
+#include "table.h"
+#include "memory.h"
+#include "zclient.h"
+#include "linklist.h"
+#include "log.h"
+
+#include "ldp_cfg.h"
+#include "mpls_compare.h"
+
+#include "ldp.h"
+#include "impl_fib.h"
+#include "impl_ifmgr.h"
+#include "impl_mpls.h"
+#include "ldp_interface.h"
+#include "mpls_mpls_impl.h"
+
+/* All information about zebra. */
+struct zclient *zclient = NULL;
+struct list *pending_out_segment = NULL;
+struct list *pending_ftn = NULL;
+struct list *pending_xc = NULL;
+
+/* For registering threads. */
+extern struct thread_master *master;
+
+struct prefix router_id;
+
+/* Router-id update message from zebra. */
+static int ldp_router_id_update_zebra(int command, struct zclient *zclient,
+    zebra_size_t length) {
+    struct ldp *ldp = ldp_get();
+
+    zebra_router_id_update_read(zclient->ibuf,&router_id);
+
+    zlog_info("router-id change %s",
+	inet_ntoa(router_id.u.prefix4));
+
+    if (ldp && ldp->lsr_id_is_static != MPLS_BOOL_TRUE) 
+	ldp_router_id_update(ldp, &router_id);
+    return 0;
+}
+
+/* Inteface addition message from zebra. */
+static int ldp_interface_add(int command, struct zclient *zclient,
+    zebra_size_t length) {
+    struct interface *ifp;
+
+    if (!(ifp = zebra_interface_add_read(zclient->ibuf))) {
+	return 1;
+    }
+
+    zlog_info("interface add %s index %d flags %ld metric %d mtu %d",
+	       ifp->name, ifp->ifindex, ifp->flags, ifp->metric, ifp->mtu);
+
+    return 0;
+}
+
+/* this is not the same as ldp_interface_delete() which is found in
+ * ldp_interface.c
+ */
+static int ldp_interface_deletez(int command, struct zclient *zclient,
+    zebra_size_t length) {
+    struct interface *ifp;
+    struct stream *s;
+
+    s = zclient->ibuf;
+    /* zebra_interface_state_read() updates interface structure in iflist */
+    ifp = zebra_interface_state_read(s);
+
+    if (ifp == NULL) {
+	return 0;
+    }
+
+    if (if_is_up(ifp)) {
+	zlog_warn("got delete of %s, but interface is still up",
+	    ifp->name);
+    }
+
+    zlog_info("interface delete %s index %d flags %ld metric %d mtu %d",
+       ifp->name, ifp->ifindex, ifp->flags, ifp->metric, ifp->mtu);
+
+    return 0;
+}
+
+struct interface * zebra_interface_if_lookup(struct stream *s) {
+    struct interface *ifp;
+    u_char ifname_tmp[INTERFACE_NAMSIZ];
+
+    /* Read interface name. */
+    stream_get(ifname_tmp, s, INTERFACE_NAMSIZ);
+
+    /* Lookup this by interface index. */
+    ifp = if_lookup_by_name(ifname_tmp);
+
+    /* If such interface does not exist, indicate an error */
+    if (!ifp) {
+	return NULL;
+    }
+
+    return ifp;
+}
+
+static int ldp_interface_state_up(int command, struct zclient *zclient,
+    zebra_size_t length) {
+    struct interface *ifp;
+    struct interface if_tmp;
+
+    ifp = zebra_interface_if_lookup(zclient->ibuf);
+    if (ifp == NULL) {
+	return 0;
+    }
+
+    /* Interface is already up. */
+    if (if_is_up (ifp)) {
+	/* Temporarily keep ifp values. */
+	memcpy (&if_tmp, ifp, sizeof (struct interface));
+
+	zebra_interface_if_set_value (zclient->ibuf, ifp);
+
+	zlog_info ("Interface[%s] state update.", ifp->name);
+
+	return 0;
+    }
+
+    zebra_interface_if_set_value(zclient->ibuf, ifp);
+
+    zlog_info ("Interface[%s] state change to up.", ifp->name);
+
+    ldp_interface_up(ifp->info);
+
+    return 0;
+}
+
+static int ldp_interface_state_down(int command, struct zclient *zclient,
+    zebra_size_t length) {
+    struct interface *ifp;
+
+    ifp = zebra_interface_state_read (zclient->ibuf);
+    if (ifp == NULL) {
+	return 0;
+    }
+
+    zlog_info ("Interface[%s] state change to down.", ifp->name);
+
+    ldp_interface_down(ifp->info);
+
+    return 0;
+}
+
+void prefix2mpls_inet_addr(struct prefix *p, struct mpls_inet_addr *a)
+{
+    a->type = MPLS_FAMILY_IPV4;
+    a->u.ipv4 = (uint32_t)ntohl(p->u.prefix4.s_addr);
+}
+
+void zebra_prefix2mpls_fec(struct prefix *p, mpls_fec *fec)
+{
+  fec->u.prefix.length = p->prefixlen;
+  fec->type = MPLS_FEC_PREFIX;
+  fec->u.prefix.network.type = MPLS_FAMILY_IPV4;
+  fec->u.prefix.network.u.ipv4 = ntohl(p->u.prefix4.s_addr);
+}
+
+void mpls_fec2zebra_prefix(mpls_fec *lp, struct prefix *p)
+{
+  p->family = AF_INET;
+  switch(lp->type) {
+    case MPLS_FEC_PREFIX:
+      p->prefixlen = lp->u.prefix.length;
+      p->u.prefix4.s_addr = htonl(lp->u.prefix.network.u.ipv4);
+      break;
+    case MPLS_FEC_HOST:
+      p->prefixlen = 32;
+      p->u.prefix4.s_addr = htonl(lp->u.host.u.ipv4);
+      break;
+    default:
+      MPLS_ASSERT(0);
+      break;
+  }
+}
+
+static int ldp_interface_address_add(int command, struct zclient *zclient,
+    zebra_size_t length) {
+    struct ldp *ldp = ldp_get();
+    struct connected *c;
+    struct interface *ifp;
+    struct prefix *p;
+    struct ldp_addr addr;
+    struct ldp_if iff;
+    struct ldp_interface *li;
+
+    c = zebra_interface_address_read(command, zclient->ibuf);
+    if (c == NULL || c->address->family != AF_INET) {
+	return 0;
+    }
+
+    ifp = c->ifp;
+    p = c->address;
+
+    /* Don't register addresses connected to the loopback interface */
+    if (if_is_loopback(ifp))
+	return 0;
+
+    zlog_info("address add %s to interface %s(%p)",inet_ntoa(p->u.prefix4),
+	ifp->name, ifp);
+
+    if (ldp) {
+	prefix2mpls_inet_addr(p, &addr.address);
+	iff.handle = ifp;
+	ldp_cfg_if_addr_set(ldp->h, &iff, &addr, LDP_CFG_ADD);
+
+	li = ifp->info;
+	if (ldp->trans_addr == LDP_TRANS_ADDR_STATIC_INTERFACE &&
+	    !strncmp(ldp->trans_addr_ifname,ifp->name,IFNAMSIZ + 1)) {
+	    ldp_global g;
+
+	    zlog_info("updating global transport address");
+	    g.transport_address.u.ipv4 = ntohl(if_ipv4_src_address (ifp));
+	    g.transport_address.type =
+		(g.transport_address.u.ipv4)?MPLS_FAMILY_IPV4:MPLS_FAMILY_NONE;
+	    ldp_admin_state_start(ldp);
+	    ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_TRANS_ADDR);
+	    ldp_admin_state_finish(ldp);
+	}
+	if (ldp->trans_addr == LDP_TRANS_ADDR_INTERFACE) {
+	    zlog_info("updating entity transport address");
+	    li->entity.transport_address.u.ipv4 =
+		ntohl(if_ipv4_src_address (ifp));
+
+	    li->entity.transport_address.type =
+		li->entity.transport_address.u.ipv4 ?
+		MPLS_FAMILY_IPV4 : MPLS_FAMILY_NONE;
+
+	    if (li->entity.index) {
+		ldp_interface_admin_state_start(li);
+		ldp_cfg_entity_set(ldp->h, &li->entity,
+		    LDP_ENTITY_CFG_TRANS_ADDR);
+		ldp_interface_admin_state_finish(li);
+	    }
+	}
+    }
+
+    return 0;
+}
+
+static int ldp_interface_address_delete(int command, struct zclient *zclient,
+    zebra_size_t length) {
+    struct ldp *ldp = ldp_get();
+    struct connected *c;
+    struct interface *ifp;
+    struct prefix *p;
+    struct ldp_addr addr;
+    struct ldp_if iff;
+    struct ldp_interface *li;
+
+    c = zebra_interface_address_read(command, zclient->ibuf);
+    if (c == NULL || c->address->family != AF_INET) {
+	return 0;
+    }
+
+    ifp = c->ifp;
+    p = c->address;
+
+    zlog_info("address delete %s from interface %s",
+	inet_ntoa(p->u.prefix4), ifp->name);
+
+    if (ldp) {
+	prefix2mpls_inet_addr(p, &addr.address);
+	iff.handle = ifp;
+	ldp_cfg_if_addr_set(ldp->h, &iff, &addr, LDP_CFG_DEL);
+
+	li = ifp->info;
+	if (ldp->trans_addr == LDP_TRANS_ADDR_STATIC_INTERFACE &&
+	    !strncmp(ldp->trans_addr_ifname,ifp->name,IFNAMSIZ + 1)) {
+	    ldp_global g;
+
+	    zlog_info("updating global transport address");
+	    g.transport_address.u.ipv4 = ntohl(if_ipv4_src_address (ifp));
+	    g.transport_address.type =
+		(g.transport_address.u.ipv4)?MPLS_FAMILY_IPV4:MPLS_FAMILY_NONE;
+	    ldp_admin_state_start(ldp);
+	    ldp_cfg_global_set(ldp->h,&g, LDP_GLOBAL_CFG_TRANS_ADDR);
+	    ldp_admin_state_finish(ldp);
+	}
+	if (ldp->trans_addr == LDP_TRANS_ADDR_INTERFACE) {
+	    zlog_info("updating entity transport address");
+	    li->entity.transport_address.u.ipv4 =
+		ntohl(if_ipv4_src_address (ifp));
+
+	    li->entity.transport_address.type =
+		li->entity.transport_address.u.ipv4 ?
+		MPLS_FAMILY_IPV4 : MPLS_FAMILY_NONE;
+
+	    if (li->entity.index) {
+		ldp_interface_admin_state_start(li);
+		ldp_cfg_entity_set(ldp->h, &li->entity,
+		    LDP_ENTITY_CFG_TRANS_ADDR);
+		ldp_interface_admin_state_finish(li);
+	    }
+	}
+    }
+
+    connected_free(c);
+
+    return 0;
+}
+
+static int ldp_zebra_read_ipv4(int cmd, struct zclient *client,
+  zebra_size_t length) {
+  struct prefix_ipv4 prefix;
+  struct zapi_ipv4 api;
+  int i = 0;
+  int j;
+
+  struct mpls_nexthop nexthop[8];
+  struct ldp *ldp = ldp_get();
+  struct mpls_fec fec;
+  struct stream *s;
+  struct in_addr tmp;
+
+  memset(&api,0,sizeof(api));
+  memset(nexthop,0,sizeof(nexthop));
+
+  s = client->ibuf;
+  zapi_ipv4_read (s, length, &api, &prefix);
+
+  zlog_info("route %s/%d", inet_ntoa(prefix.prefix), prefix.prefixlen);
+
+  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
+    {
+      for (i = 0; i < api.nexthop_num; i++)
+        {
+          if (api.type == ZEBRA_ROUTE_CONNECT)
+            {
+	      nexthop[i].attached = MPLS_BOOL_TRUE;
+	      zlog_info("\tattached");
+            }
+          nexthop[i].ip.type = MPLS_FAMILY_IPV4;
+          if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
+            nexthop[i].distance = api.message;
+          if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
+            nexthop[i].metric = api.metric;
+          if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IPV4))
+            {
+              nexthop[i].ip.u.ipv4 = ntohl(api.nexthop[i].gw.ipv4.s_addr);
+              nexthop[i].type |= MPLS_NH_IP;
+              tmp.s_addr = htonl(nexthop[i].ip.u.ipv4);
+              zlog_info("\tnexthop %s", inet_ntoa(tmp));
+            }
+          if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IFINDEX))
+            {
+              nexthop[i].if_handle =
+                  if_lookup_by_index(api.nexthop[i].intf.index);
+              if (nexthop[i].if_handle)
+                {
+	          nexthop[i].type |= MPLS_NH_IF;
+	          zlog_info("\tifindex %d", nexthop[i].if_handle->ifindex);
+                }
+            }
+        }
+    }
+
+  zebra_prefix2mpls_fec((struct prefix*)&prefix, &fec);
+  for (j = 0; j < i; j++) {
+    if (cmd == ZEBRA_IPV4_ROUTE_ADD) {
+      zlog_info("\tadd");
+      if ((ldp_cfg_fec_get(ldp->h, &fec, 0) != MPLS_SUCCESS) ||
+	  (fec.is_route == MPLS_BOOL_FALSE)) {
+        if (ldp_cfg_fec_set(ldp->h, &fec, LDP_CFG_ADD) != MPLS_SUCCESS) {
+          MPLS_ASSERT(0);
+        }
+      }
+      if (ldp_cfg_fec_nexthop_get(ldp->h, &fec, &nexthop[j],
+        LDP_FEC_CFG_BY_INDEX) != MPLS_SUCCESS) {
+        if (ldp_cfg_fec_nexthop_set(ldp->h, &fec, &nexthop[j],
+          LDP_CFG_ADD|LDP_FEC_CFG_BY_INDEX) != MPLS_SUCCESS) {
+          MPLS_ASSERT(0);
+        }
+      } else {
+	/*
+	 * already exists ... looks like we can get the same route sent
+	 * to us twice ... multiple protocols?
+        MPLS_ASSERT(0);
+	 */
+      }
+    } else {
+      zlog_info("\tdelete");
+      if ((ldp_cfg_fec_get(ldp->h, &fec, 0) == MPLS_SUCCESS) &&
+	  (fec.is_route == MPLS_BOOL_TRUE)) {
+        if (ldp_cfg_fec_nexthop_get(ldp->h, &fec, &nexthop[j],
+          LDP_FEC_CFG_BY_INDEX) == MPLS_SUCCESS) {
+          if (ldp_cfg_fec_nexthop_set(ldp->h, &fec, &nexthop[j],
+            LDP_FEC_CFG_BY_INDEX|LDP_CFG_DEL|
+            LDP_FEC_NEXTHOP_CFG_BY_INDEX) != MPLS_SUCCESS) {
+            MPLS_ASSERT(0);
+          }
+        } else {
+          MPLS_ASSERT(0);
+        }
+        if (ldp_cfg_fec_set(ldp->h, &fec, LDP_CFG_DEL|LDP_FEC_CFG_BY_INDEX) !=
+          MPLS_SUCCESS) {
+          MPLS_ASSERT(0);
+        }
+      } else {
+        MPLS_ASSERT(0);
+      }
+    }
+  }
+  return 0;
+}
+
+static int ldp_zebra_read_ipv6(int cmd, struct zclient *client,
+    zebra_size_t length) {
+    struct prefix_ipv6 prefix;
+    struct zapi_ipv6 api;
+
+    memset(&api,0,sizeof(api));
+    zapi_ipv6_route_read (client, length, &api, &prefix);
+
+    return 0;
+}
+
+static int ldp_xc_read(int cmd, struct zclient *client, zebra_size_t size) {
+    struct zapi_mpls_xc api;
+    mpls_xc_stream_read(client->ibuf, &api);
+    return 0;
+}
+
+static int ldp_in_segment_read(int cmd, struct zclient *client,
+    zebra_size_t size) {
+    struct zapi_mpls_in_segment api;
+    mpls_in_segment_stream_read(client->ibuf, &api);
+    return 0;
+}
+
+static int ldp_out_segment_read(int cmd, struct zclient *client,
+    zebra_size_t size) {
+    struct zapi_mpls_out_segment api;
+    struct listnode *n;
+    struct listnode *nn;
+    mpls_outsegment *o;
+    struct pending_ftn_data *fn;
+    struct pending_xc_data *x;
+
+    mpls_out_segment_stream_read(client->ibuf, &api);
+
+    for (ALL_LIST_ELEMENTS(pending_out_segment, n, nn, o)) {
+	if (api.req == o->handle) {
+	    zlog_info("found pending NHLFE: %p", o);
+	    o->handle = api.index;
+	    list_delete_node(pending_out_segment,n);
+	    goto ftn;
+	}
+    }
+    zlog_info("requested out segment %d not in list", api.req);
+    return 0;
+
+ftn:
+    /* if we've gotten this for then the o->handle is not the proper index */
+    for (ALL_LIST_ELEMENTS(pending_ftn, n, nn, fn)) {
+	if (api.index == fn->o->handle) {
+	    mpls_mpls_fec2out_add(fn->h, fn->f, fn->o);
+	    list_delete_node(pending_ftn,n);
+	    break;
+	}
+    }
+    for (ALL_LIST_ELEMENTS(pending_xc, n, nn, x)) {
+	if (api.index == x->o->handle) {
+	    mpls_mpls_xconnect_add(x->h, x->i, x->o);
+	    list_delete_node(pending_xc,n);
+	    break;
+	}
+    }
+    return 0;
+}
+
+static int ldp_labelspace_read(int cmd, struct zclient *client,
+    zebra_size_t size) {
+    struct zapi_mpls_labelspace api;
+    struct interface *ifp;
+    struct ldp_interface *li;
+    int labelspace;
+
+    mpls_labelspace_stream_read(client->ibuf, &api);
+    ifp = if_lookup_by_name(api.ifname);
+
+    if (ifp) {
+	labelspace = ifp->mpls_labelspace;
+	ifp->mpls_labelspace = api.labelspace;
+
+	if (ifp->info) {
+	    li = ifp->info;
+
+	    if (api.labelspace < 0) {
+		if (li->configured == MPLS_BOOL_TRUE)
+		    ldp_interface_shutdown (li);
+	    } else {
+		if (labelspace >= 0) {
+		    if (li->configured == MPLS_BOOL_TRUE)
+			ldp_interface_shutdown (li);
+		}
+		if (li->configured == MPLS_BOOL_TRUE)
+		    ldp_interface_startup (li);
+	    }
+	}
+    }
+    return 0;
+}
+
+static int ldp_ftn_read(int cmd, struct zclient *client, zebra_size_t size) {
+    struct zapi_mpls_ftn api;
+    mpls_ftn_stream_read(client->ibuf, &api);
+    return 0;
+}
+
+void ldp_zebra_startup() {
+  int i;
+  for (i = 0;i < ZEBRA_ROUTE_MAX;i++) {
+	if (i != ZEBRA_ROUTE_LDP)
+	    zclient_redistribute(ZEBRA_REDISTRIBUTE_ADD, zclient,i);
+  }
+}
+
+void ldp_zebra_shutdown() {
+  int i;
+  for (i = 0;i < ZEBRA_ROUTE_MAX;i++) {
+	if (i != ZEBRA_ROUTE_LDP)
+	    zclient_redistribute(ZEBRA_REDISTRIBUTE_DELETE, zclient,i);
+  }
+}
+
+void pending_delete(void *m) {
+    XFREE(MTYPE_TMP, m);
+}
+
+void ldp_zebra_init() {
+
+  pending_out_segment = list_new();
+  pending_ftn = list_new();
+  pending_ftn->del = pending_delete;
+  pending_xc = list_new();
+  pending_xc->del = pending_delete;
+
+  /* Allocate zebra structure. */
+  zclient = zclient_new();
+  zclient_init(zclient, ZEBRA_ROUTE_LDP);
+  zclient->router_id_update = ldp_router_id_update_zebra;
+  zclient->interface_add = ldp_interface_add;
+  zclient->interface_delete = ldp_interface_deletez;
+  zclient->interface_up = ldp_interface_state_up;
+  zclient->interface_down = ldp_interface_state_down;
+  zclient->interface_address_add = ldp_interface_address_add;
+  zclient->interface_address_delete = ldp_interface_address_delete;
+  zclient->ipv4_route_add = ldp_zebra_read_ipv4;
+  zclient->ipv4_route_delete = ldp_zebra_read_ipv4;
+/*
+ *zclient->ipv6_route_add = ldp_zebra_read_ipv6;
+ *zclient->ipv6_route_delete = ldp_zebra_read_ipv6;
+ */
+  zclient->mpls_xc_add = ldp_xc_read;
+  zclient->mpls_xc_delete = ldp_xc_read;
+  zclient->mpls_in_segment_add = ldp_in_segment_read;
+  zclient->mpls_in_segment_delete = ldp_in_segment_read;
+  zclient->mpls_out_segment_add = ldp_out_segment_read;
+  zclient->mpls_out_segment_delete = ldp_out_segment_read;
+  zclient->mpls_labelspace_add = ldp_labelspace_read;
+  zclient->mpls_labelspace_delete = ldp_labelspace_read;
+  zclient->mpls_ftn_add = ldp_ftn_read;
+  zclient->mpls_ftn_delete = ldp_ftn_read;
+
+  memset(&router_id, 0, sizeof(router_id));
+}
diff -Naur quagga-0.99.10/ldpd/ldp_zebra.h quagga-mpls/ldpd/ldp_zebra.h
--- quagga-0.99.10/ldpd/ldp_zebra.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/ldp_zebra.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,17 @@
+#ifndef _ZEBRA_LDP_ZEBRA_H
+#define _ZEBRA_LDP_ZEBRA_H
+
+#include "prefix.h"
+
+#include "ldp_struct.h"
+
+extern struct prefix router_id;
+
+void ldp_zebra_init();
+void prefix2mpls_inet_addr(struct prefix *p, struct mpls_inet_addr *a);
+void zebra_prefix2mpls_fec(struct prefix *p, mpls_fec *fec);
+void mpls_fec2zebra_prefix(mpls_fec *fec, struct prefix *p);
+void ldp_zebra_startup();
+void ldp_zebra_shutdown();
+
+#endif
diff -Naur quagga-0.99.10/ldpd/Makefile.am quagga-mpls/ldpd/Makefile.am
--- quagga-0.99.10/ldpd/Makefile.am	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/Makefile.am	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,60 @@
+# Process this file with automake to produce Makefile.in.
+
+INCLUDES = @INCLUDES@ -I.. -I$(top_srcdir) -I$(top_srcdir)/lib
+DEFS = @DEFS@ $(LOCAL_OPTS) -DSYSCONFDIR=\"$(sysconfdir)/\"
+INSTALL_SDATA=@INSTALL@ -m 600
+
+sbin_PROGRAMS = ldpd
+
+ldpd_SOURCES = \
+impl_fib.c impl_ifmgr.c impl_lock.c impl_mm.c impl_mpls.c \
+impl_policy.c impl_socket.c impl_timer.c impl_tree.c \
+ldp_zebra.c ldp_main.c \
+ldp.c ldp_interface.c ldp_vty.c ldp_remote_peer.c l2cc_interface.c \
+ldp_addr.c ldp_adj.c \
+ldp_attr.c ldp_buf.c ldp_cfg.c ldp_entity.c ldp_fec.c ldp_global.c \
+ldp_hello.c ldp_hop.c ldp_hop_list.c ldp_if.c ldp_inet_addr.c \
+ldp_init.c ldp_inlabel.c ldp_keepalive.c ldp_label_abort.c \
+ldp_label_mapping.c ldp_label_rel_with.c ldp_label_request.c \
+ldp_mesg.c ldp_nortel.c ldp_notif.c ldp_outlabel.c \
+ldp_pdu_setup.c ldp_peer.c \
+ldp_resource.c ldp_session.c ldp_state_funcs.c \
+ldp_state_machine.c ldp_tunnel.c ldp_nexthop.c\
+mpls_compare.c
+
+
+noinst_HEADERS = \
+ldp_zebra.h \
+ldp.h ldp_interface.h ldp_vty.h ldp_remote_peer.h l2cc_interface.h \
+ldp_addr.h ldp_adj.h ldp_attr.h ldp_buf.h ldp_cfg.h \
+ldp_defaults.h ldp_entity.h ldp_fec.h \
+ldp_global.h mpls_handle_type.h ldp_hello.h ldp_hop.h \
+ldp_hop_list.h ldp_if.h ldp_inet_addr.h \
+ldp_init.h ldp_inlabel.h ldp_keepalive.h ldp_label_abort.h \
+ldp_label_mapping.h ldp_label_rel_with.h ldp_label_request.h \
+ldp_mesg.h ldp_nortel.h ldp_notif.h ldp_outlabel.h ldp_pdu.h ldp_nexthop.h \
+ldp_pdu_setup.h ldp_peer.h mpls_refcnt.h ldp_resource.h \
+ldp_session.h ldp_state_machine.h ldp_struct.h ldp_tunnel.h \
+mpls_tree_impl.h mpls_mm_impl.h mpls_mpls_impl.h mpls_trace_impl.h \
+mpls_assert.h mpls_fib_impl.h mpls_ifmgr_impl.h mpls_list.h mpls_lock_impl.h \
+mpls_policy_impl.h mpls_socket_impl.h mpls_timer_impl.h mpls_trace.h \
+mpls_struct.h mpls_compare.h mpls_bitfield.h
+
+ldpd_LDADD = -L../lib -lzebra @LIBCAP@
+
+sysconf_DATA = ldpd.conf.sample
+
+EXTRA_DIST = $(sysconf_DATA)
+
+install-sysconfDATA: $(sysconf_DATA)
+	@$(NORMAL_INSTALL)
+	$(mkinstalldirs) $(DESTDIR)$(sysconfdir)
+	@list='$(sysconf_DATA)'; for p in $$list; do \
+	  if test -f $(srcdir)/$$p; then \
+	    echo " $(INSTALL_SDATA) $(srcdir)/$$p $(DESTDIR)$(sysconfdir)/$$p"; \
+	    $(INSTALL_SDATA) $(srcdir)/$$p $(DESTDIR)$(sysconfdir)/$$p; \
+	  else if test -f $$p; then \
+	    echo " $(INSTALL_SDATA) $$p $(DESTDIR)$(sysconfdir)/$$p"; \
+	    $(INSTALL_SDATA) $$p $(DESTDIR)$(sysconfdir)/$$p; \
+	  fi; fi; \
+	done
diff -Naur quagga-0.99.10/ldpd/mpls_assert.h quagga-mpls/ldpd/mpls_assert.h
--- quagga-0.99.10/ldpd/mpls_assert.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_assert.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,17 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_ASSERT_H_
+#define _MPLS_ASSERT_H_
+
+#include <assert.h>
+
+#define MPLS_ASSERT(x) assert(x)
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_bitfield.h quagga-mpls/ldpd/mpls_bitfield.h
--- quagga-0.99.10/ldpd/mpls_bitfield.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_bitfield.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,31 @@
+/*
+ *  Copyright (C) James R. Leu 2003
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef MPLS_BITFIELD_H
+#define MPLS_BITFILED_H
+
+#include <endian.h>
+
+#if (__BYTE_ORDER == __LITTLE_ENDIAN)
+#define LITTLE_ENDIAN_BYTE_ORDER 1
+#endif
+
+/* macros to handle different byte orders (little endian or big endian) */
+#ifdef LITTLE_ENDIAN_BYTE_ORDER
+#define BITFIELDS_ASCENDING_2(X, Y)                Y; X;
+#define BITFIELDS_ASCENDING_3(X, Y, Z)             Z; Y; X;
+#define BITFIELDS_ASCENDING_4(X, Y, Z, W)          W; Z; Y; X;
+#define BITFIELDS_ASCENDING_7(X, Y, Z, W, U, A, B) B; A; U; W; Z; Y; X;
+# else
+#define BITFIELDS_ASCENDING_2(X, Y)                X; Y;
+#define BITFIELDS_ASCENDING_3(X, Y, Z)             X; Y; Z;
+#define BITFIELDS_ASCENDING_4(X, Y, Z, W)          X; Y; Z; W;
+#define BITFIELDS_ASCENDING_7(X, Y, Z, W, U, A, B) X; Y; Z; W; U; A; B;
+#endif /* LITTLE_ENDIAN_BYTE_ORDER */
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_compare.c quagga-mpls/ldpd/mpls_compare.c
--- quagga-0.99.10/ldpd/mpls_compare.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_compare.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,148 @@
+#include "mpls_struct.h"
+#include "mpls_assert.h"
+
+int mpls_inet_addr_compare(struct mpls_inet_addr *addr1,
+		struct mpls_inet_addr *addr2) {
+  if (addr1->type != addr2->type) {
+    return 1;
+  }
+  switch(addr1->type) {
+    case MPLS_FAMILY_IPV4:
+      if (addr1->u.ipv4 != addr2->u.ipv4) {
+	return addr1->u.ipv4 > addr2->u.ipv4 ? 1 : -1;
+      }
+      break;
+    case MPLS_FAMILY_IPV6:
+      return memcmp(addr1->u.ipv6, addr2->u.ipv6, 16);
+    default:
+      MPLS_ASSERT(0);
+  }
+  return 0;
+}
+
+int mpls_nexthop_compare(struct mpls_nexthop *nh1, struct mpls_nexthop *nh2) {
+  int retval = 0;
+  int match = 0;
+
+  if (nh1->type != nh2->type) {
+    return 1;
+  }
+  if (nh1->type & MPLS_NH_IP) {
+    match++;
+    if ((retval = mpls_inet_addr_compare(&nh1->ip, &nh2->ip))) {
+      return retval;
+    }
+  }
+  if (nh1->type & MPLS_NH_IF) {
+    match++;
+    if ((retval = mpls_if_handle_compare(nh1->if_handle, nh2->if_handle))) {
+      return retval;
+    }
+  }
+  if (nh1->type & MPLS_NH_OUTSEGMENT) {
+    match++;
+    if ((retval = mpls_outsegment_handle_compare(nh1->outsegment_handle,
+      nh2->outsegment_handle))) {
+      return retval;
+    }
+  }
+
+  if (!match) {
+    return 1;
+  }
+  return 0;
+}
+
+int mpls_label_struct_compare(struct mpls_label_struct* l1,
+		struct mpls_label_struct* l2) {
+  if (l1->type != l2->type) {
+    return 1;
+  }
+  switch(l1->type) {
+    case MPLS_LABEL_TYPE_GENERIC:
+      if (l1->u.gen != l2->u.gen) {
+	return (l1->u.gen > l2->u.gen) ? 1 : -1;
+      }
+      break;
+    case MPLS_LABEL_TYPE_ATM:
+      if (l1->u.atm.vpi != l2->u.atm.vpi) {
+	return (l1->u.atm.vpi > l2->u.atm.vpi) ? 1 : -1;
+      }
+      if (l1->u.atm.vci != l2->u.atm.vci) {
+	return (l1->u.atm.vci > l2->u.atm.vci) ? 1 : -1;
+      }
+      break;
+    case MPLS_LABEL_TYPE_FR:
+      if (l1->u.fr.len != l2->u.fr.len) {
+	return (l1->u.fr.dlci > l2->u.fr.dlci) ? 1 : -1;
+      }
+      if (l1->u.fr.dlci != l2->u.fr.dlci) {
+	return (l1->u.fr.len > l2->u.fr.len) ? 1 : -1;
+      }
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+  return 0;
+}
+
+int mpls_dest_compare(struct mpls_dest* d1, struct mpls_dest* d2) {
+  int retval;
+  if ((retval = mpls_inet_addr_compare(&d1->addr, &d2->addr))) {
+    return retval;
+  }
+  if (d1->port != d2->port) {
+    return (d1->port > d2->port) ? 1 : -1;
+  }
+  if ((retval = mpls_if_handle_compare(d1->if_handle, d2->if_handle))) {
+    return retval;
+  }
+  return 0;
+}
+
+int mpls_range_compare(struct mpls_range* r1, struct mpls_range* r2) {
+  int retval;
+  if ((retval = mpls_label_struct_compare(&r1->min, &r2->min))) {
+    return retval;
+  }
+  if ((retval = mpls_label_struct_compare(&r1->max, &r2->max))) {
+    return retval;
+  }
+  return 0;
+}
+
+int mpls_fec_compare(struct mpls_fec* f1, struct mpls_fec* f2) {
+  int retval;
+
+  if (f1->type != f2->type) {
+    return 1;
+  }
+
+  switch(f1->type) {
+    case MPLS_FEC_PREFIX:
+      if ((retval = mpls_inet_addr_compare(&f1->u.prefix.network,
+        &f2->u.prefix.network))) {
+        return retval;
+      }
+      if (f1->u.prefix.length > f2->u.prefix.length) {
+	return (f1->u.prefix.length != f2->u.prefix.length) ? 1 : -1;
+      }
+      break;
+    case MPLS_FEC_HOST:
+      return mpls_inet_addr_compare(&f1->u.host, &f2->u.host);
+    case MPLS_FEC_L2CC:
+      if (f1->u.l2cc.connection_id != f2->u.l2cc.connection_id) {
+	return (f1->u.l2cc.connection_id>f2->u.l2cc.connection_id) ? 1 : -1;
+      }
+      if (f1->u.l2cc.group_id != f2->u.l2cc.group_id) {
+	return (f1->u.l2cc.group_id > f2->u.l2cc.group_id) ? 1 : -1;
+      }
+      if (f1->u.l2cc.type != f2->u.l2cc.type) {
+	return 1;
+      }
+      break;
+    default:
+      MPLS_ASSERT(0);
+  }
+  return 0;
+}
diff -Naur quagga-0.99.10/ldpd/mpls_compare.h quagga-mpls/ldpd/mpls_compare.h
--- quagga-0.99.10/ldpd/mpls_compare.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_compare.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,14 @@
+#ifndef MPLS_COMPARE_H
+#define MPLS_COMPARE_H
+
+#include "mpls_struct.h"
+
+int mpls_inet_addr_compare(struct mpls_inet_addr*, struct mpls_inet_addr*);
+int mpls_nexthop_compare(struct mpls_nexthop*, struct mpls_nexthop*);
+int mpls_dest_compare(struct mpls_dest*, struct mpls_dest*);
+int mpls_label_struct_compare(struct mpls_label_struct*,
+		struct mpls_label_struct*);
+int mpls_range_compare(struct mpls_range*, struct mpls_range*);
+int mpls_fec_compare(struct mpls_fec*, struct mpls_fec*);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_fib_impl.h quagga-mpls/ldpd/mpls_fib_impl.h
--- quagga-0.99.10/ldpd/mpls_fib_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_fib_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,75 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_FIB_IMPL_H_
+#define _MPLS_FIB_IMPL_H_
+
+#include "mpls_struct.h"
+
+/*
+ * in: handle, cfg, callback, 
+ * return: mpls_fib_handle
+ */
+extern mpls_fib_handle mpls_fib_open(const mpls_instance_handle handle,
+  const mpls_cfg_handle cfg);
+
+/*
+ * in: handle
+ */
+extern void mpls_fib_close(mpls_fib_handle handle);
+
+/*
+ * in: handle,num_entry,dest,entry
+ * out: entry
+ * return: int (number of routes returned in entry)
+ */
+extern int mpls_fib_get_route(const mpls_fib_handle handle, const int num_entry,
+  const mpls_fec * dest, mpls_fec * entry);
+
+/*
+ * in: handle,num_entry,dest,entry
+ * out: entry
+ * return: int (number of routes returned in entry)
+ */
+extern int mpls_fib_get_best_route(const mpls_fib_handle handle,
+  const int num_entry, const mpls_fec * dest, mpls_fec * entry);
+
+/*
+ * in: handle
+ * out: fec, nexthop
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_fib_getfirst_route(const mpls_fib_handle handle,
+  mpls_fec * fec, mpls_nexthop *nexthop);
+
+/*
+ * in: handle, fec, nexthop
+ * out: fec, nexthop
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_fib_getnext_route(const mpls_fib_handle handle,
+  mpls_fec * fec, mpls_nexthop *nexthop);
+
+/*
+ * in: handle, fec, owner, data
+ * out:
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_fib_set_data(mpls_fib_handle handle, mpls_fec *fec,
+  mpls_owners_enum owner, void *data);
+
+/*
+ * in: handle, fec, owner
+ * out: data
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_fib_get_data(mpls_fib_handle handle, mpls_fec *fec,
+  mpls_owners_enum owner, void **data);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_handle_type.h quagga-mpls/ldpd/mpls_handle_type.h
--- quagga-0.99.10/ldpd/mpls_handle_type.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_handle_type.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,94 @@
+#ifndef _LDP_HANDLE_TYPE_H_
+#define _LDP_HANDLE_TYPE_H_
+
+#define MPLS_USE_LSR 0
+
+#if (__GLIBC__ < 2) || ((__GLIBC__ == 2) && (__GLIBC_MINOR__ == 0))
+#if 0
+typedef unsigned char uint8_t;
+typedef unsigned short uint16_t;
+typedef unsigned int uint32_t;
+#endif
+#else
+#include <stdint.h>
+#endif
+
+#include <zebra.h>
+#include "if.h"
+
+struct ldp;
+struct ldp_timer;
+struct ldp_socket;
+
+#define ptr_verify(x) (x ? MPLS_BOOL_TRUE : MPLS_BOOL_FALSE)
+
+typedef void *mpls_tree_handle;
+#define mpls_tree_handle_compare(x,y) (x != y)
+#define mpls_tree_handle_verify(x) ptr_verify(x)
+
+typedef void *mpls_instance_handle;
+#define mpls_instance_handle_compare(x,y) (x != y)
+#define mpls_instance_handle_verify(x) ptr_verify(x)
+
+typedef struct ldp* mpls_fib_handle;
+#define mpls_fib_handle_compare(x,y) (x != y)
+#define mpls_fib_handle_verify(x) ptr_verify(x)
+
+typedef int mpls_ifmgr_handle;
+#define mpls_ifmgr_handle_compare(x,y) (x != y)
+#define mpls_ifmgr_handle_verify(x) ptr_verify(x)
+
+typedef struct interface* mpls_if_handle;
+#define mpls_if_handle_compare(x,y) \
+	((x->ifindex <= 0 && y->ifindex <= 0) ? (x != y) : ((x->ifindex == y->ifindex) ? 0 : (x->ifindex > y->ifindex ? 1 : -1)))
+#define mpls_if_handle_verify(m,x) ptr_verify(x)
+
+typedef int mpls_timer_mgr_handle;
+#define mpls_timer_mgr_handle_compare(x,y) (x != y)
+#define mpls_timer_mgr_handle_verify(x) ptr_verify(x)
+
+typedef struct mpls_timer* mpls_timer_handle;
+#define mpls_timer_handle_compare(x,y) (x != y)
+#define mpls_timer_handle_verify(m,x) ptr_verify(x)
+
+typedef int mpls_socket_mgr_handle;
+#define mpls_socket_mgr_handle_compare(x,y) (x != y)
+#define mpls_socket_mgr_handle_verify(x) MPLS_BOOL_TRUE
+
+typedef struct mpls_socket* mpls_socket_handle;
+#define mpls_socket_handle_compare(x,y) (x->fd != y->fd)
+#define mpls_socket_handle_verify(m,x) ptr_verify(x)
+
+typedef int mpls_mpls_handle;
+#define mpls_mpls_handle_compare(x,y) (x != y)
+#define mpls_mpls_handle_verify(x) ptr_verify(x)
+
+typedef int mpls_insegment_handle;
+#define mpls_insegment_handle_compare(x,y) (x != y)
+#define mpls_insegment_handle_verify(m,x) ptr_verify(x)
+
+typedef int mpls_outsegment_handle;
+#define mpls_outsegment_handle_compare(x,y) (x != y)
+#define mpls_outsegment_handle_verify(m,x) ptr_verify(x)
+
+typedef int mpls_xconnect_handle;
+#define mpls_xconnect_handle_compare(x,y) (x != y)
+#define mpls_xconnect_handle_verify(m,x) ptr_verify(x)
+
+typedef int *mpls_lock_handle;
+#define mpls_lock_handle_compare(x,y) (x != y)
+#define mpls_lock_handle_verify(x) ptr_verify(x)
+
+typedef int mpls_tunnel_handle;
+#define mpls_tunnel_handle_compare(x,y) (x != y)
+
+typedef int mpls_policy_handle;
+#define mpls_policy_handle_compare(x,y) (x != y)
+
+typedef int mpls_trace_handle;
+#define mpls_trace_handle_compare(x,y) (x != y)
+
+typedef char *mpls_lock_key_type;
+typedef int mpls_size_type;
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_ifmgr_impl.h quagga-mpls/ldpd/mpls_ifmgr_impl.h
--- quagga-0.99.10/ldpd/mpls_ifmgr_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_ifmgr_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,58 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_IFMGR_IMPL_H_
+#define _MPLS_IFMGR_IMPL_H_
+
+#include "mpls_struct.h"
+#include "mpls_handle_type.h"
+
+/*
+ * in: handle,cfg
+ * return: mpls_ifmgr_handle
+ */
+extern mpls_ifmgr_handle mpls_ifmgr_open(const mpls_instance_handle handle,
+  const mpls_cfg_handle cfg);
+
+/*
+ * in: handle
+ */
+extern void mpls_ifmgr_close(const mpls_ifmgr_handle handle);
+
+/*
+ * in: handle,iff,mtu
+ * out: mtu
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_ifmgr_get_mtu(const mpls_ifmgr_handle,
+  const mpls_if_handle iff, int *mtu);
+
+/*
+ * in: handle,iff,name,size
+ * out: name
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_ifmgr_get_name(const mpls_ifmgr_handle,
+  const mpls_if_handle iff, char *name, int len);
+
+/*
+ * in: handle, handle, addr
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_ifmgr_getfirst_address(const mpls_ifmgr_handle,
+  mpls_if_handle*, mpls_inet_addr*);
+
+/*
+ * in: handle, handle, addr
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_ifmgr_getnext_address(const mpls_ifmgr_handle,
+  mpls_if_handle*, mpls_inet_addr*);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_list.h quagga-mpls/ldpd/mpls_list.h
--- quagga-0.99.10/ldpd/mpls_list.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_list.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,309 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_LIST_H_
+#define _MPLS_LIST_H_
+
+#include "mpls_mm_impl.h"
+
+/* Endo list, the prev,next ptrs are part of the element in the list */
+/* No addition memory allocations are done when inserting into the list */
+
+#define MPLS_LIST_ROOT(name,type)	\
+struct name {				\
+  struct type *llh_first;		\
+  struct type *llh_last;		\
+  int count;				\
+}
+
+#define MPLS_LIST_ELEM(type)		\
+struct {				\
+  struct type *lle_next;		\
+  struct type *lle_prev;		\
+}
+
+#define MPLS_LIST_REMOVE(head, elm, field) {				\
+  if((elm)->field.lle_next == (void *)(head))				\
+    (head)->llh_last = (elm)->field.lle_prev;				\
+  else									\
+    (elm)->field.lle_next->field.lle_prev = (elm)->field.lle_prev;	\
+  if((elm)->field.lle_prev == (void *)(head))				\
+    (head)->llh_first = (elm)->field.lle_next;				\
+  else									\
+    (elm)->field.lle_prev->field.lle_next = (elm)->field.lle_next;	\
+  (head)->count--;							\
+}
+
+#define MPLS_LIST_INSERT_BEFORE(head,listelm,elm,field) {	\
+  (elm)->field.lle_next = (listelm);				\
+  (elm)->field.lle_prev = (listelm)->field.lle_prev;		\
+  if((listelm)->field.lle_prev == (void *)(head))		\
+    (head)->llh_first = (elm);					\
+  else								\
+    (listelm)->field.lle_prev->field.lle_next = (elm);		\
+  (listelm)->field.lle_prev = (elm);				\
+  (head)->count++;						\
+}
+
+#define MPLS_LIST_INIT(head,type) {		\
+  (head)->llh_first = (struct type *)(head);	\
+  (head)->llh_last = (struct type *)(head);	\
+  (head)->count = 0;				\
+}
+
+#define MPLS_LIST_IN_LIST(elm,field) ((elm)->field.lle_next && (elm)->field.lle_prev)
+
+#define MPLS_LIST_ADD_HEAD(head, elm, field, type) {	\
+  (elm)->field.lle_next = (head)->llh_first;		\
+  (elm)->field.lle_prev = (struct type *)(head);	\
+  if ((head)->llh_last == (struct type *)(head))	\
+    (head)->llh_last = (elm);				\
+  else							\
+    (head)->llh_first->field.lle_prev = (elm);		\
+  (head)->llh_first = (elm);				\
+  (head)->count++;					\
+}
+
+#define MPLS_LIST_ADD_TAIL(head, elm, field, type) {	\
+  (elm)->field.lle_next = (struct type *)(head);	\
+  (elm)->field.lle_prev = (head)->llh_last;		\
+  if ((head)->llh_first == (struct type *)(head))	\
+    (head)->llh_first = (elm);				\
+  else							\
+    (head)->llh_last->field.lle_next = (elm);		\
+  (head)->llh_last = (elm);				\
+  (head)->count++;					\
+}
+
+#define MPLS_LIST_REMOVE_TAIL(root,elem,field) {	\
+  (elem) = (root)->llh_last;			\
+  if((elem) && (elem) != (void*)(root)) {	\
+    MPLS_LIST_REMOVE(root,elem,field);		\
+  } else {					\
+    (elem) = NULL;				\
+  }						\
+  (root)->count--;				\
+}
+
+#define MPLS_LIST_REMOVE_HEAD(root,elem,field) {	\
+  (elem) = (root)->llh_first;			\
+  if((elem) && (elem) != (void*)(root)) {	\
+    MPLS_LIST_REMOVE(root,elem,field);		\
+  } else {					\
+    (elem) = NULL;				\
+  }						\
+  (root)->count--;				\
+}
+
+#define MPLS_LIST_ELEM_INIT(elem,field) {	\
+  (elem)->field.lle_next = NULL;		\
+  (elem)->field.lle_prev = NULL;		\
+}
+
+#define MPLS_LIST_HEAD(root)		(((root)->llh_first == (void*)(root))?(NULL):((root)->llh_first))
+#define MPLS_LIST_NEXT(root,elem,field)	((((elem)->field.lle_next) == (void*)(root))?(NULL):((elem)->field.lle_next))
+#define MPLS_LIST_PREV(root,elem,field)	((((elem)->field.lle_prev) == (void*)(root))?(NULL):((elem)->field.lle_prev))
+#define MPLS_LIST_TAIL(root)		(((root)->llh_last == (void*)(root))?(NULL):((root)->llh_last))
+
+#define MPLS_LIST_EMPTY(root) ((root)->count ? MPLS_BOOL_FALSE : MPLS_BOOL_TRUE)
+
+/* non Endo list, the list node has the next,prev pointers and a pointer to */
+/* the data being stored, a memory allocation has to occur for each insert */
+
+typedef struct mpls_link_list_node {
+  struct mpls_link_list_node *next;
+  struct mpls_link_list_node *prev;
+  void *data;
+} mpls_link_list_node;
+
+typedef struct mpls_link_list {
+  struct mpls_link_list_node *head;
+  struct mpls_link_list_node *tail;
+  int count;
+} mpls_link_list;
+
+#define mpls_link_list_head(X) ((X)->head)
+#define mpls_link_list_head_data(X) ((X)->head ? (X)->head->data : NULL)
+#define mpls_link_list_tail(X) ((X)->tail)
+#define mpls_link_list_tail_data(X) ((X)->tail ? (X)->tail->data : NULL)
+#define mpls_link_list_count(X) ((X)->count)
+#define mpls_link_list_isempty(X) ((X)->head == NULL && (X)->tail == NULL)
+
+#define MPLS_LINK_LIST_LOOP(LIST,DATA,NODE)			\
+  for ((NODE) = (LIST)->head; (NODE); (NODE) = (NODE)->next)	\
+    if (((DATA) = (NODE)->data) != NULL)
+
+static inline void mpls_link_list_init(struct mpls_link_list *list) {
+  memset(list, 0, sizeof(*list));
+}
+
+static inline struct mpls_link_list *mpls_link_list_create() {
+  struct mpls_link_list *list;
+
+  if ((list = mpls_malloc(sizeof(*list)))) {
+    mpls_link_list_init(list);
+  }
+  return list;
+}
+
+static inline void mpls_link_list_delete(struct mpls_link_list *list) {
+  mpls_free(list);
+}
+
+static inline struct mpls_link_list_node *mpls_link_list_node_create(void *data)
+{
+  struct mpls_link_list_node *node;
+
+  if ((node = mpls_malloc(sizeof(*node)))) {
+    memset(node, 0, sizeof(*node));
+    node->data = data;
+  }
+  return node;
+}
+
+static inline void mpls_link_list_node_delete(struct mpls_link_list_node *node)
+{
+  mpls_free(node);
+}
+
+static inline void mpls_link_list_add_node_head(struct mpls_link_list *list,
+  struct mpls_link_list_node *node) {
+  node->next = list->head;
+    
+  if (list->tail == NULL) {
+    list->tail = node; 
+  } else {
+    list->head->prev = node;
+    node->next = list->head;
+  }
+  list->head = node;
+  list->count++;
+}
+
+static inline mpls_return_enum mpls_link_list_add_head(
+  struct mpls_link_list *list, void * data) {
+  struct mpls_link_list_node *node;
+
+  if ((node = mpls_link_list_node_create(data))) {
+    mpls_link_list_add_node_head(list,node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FATAL;
+}
+
+static inline void mpls_link_list_add_node_tail(
+  struct mpls_link_list *list, struct mpls_link_list_node *node) {
+  node->prev = list->tail;
+
+  if (list->head == NULL) {
+    list->head = node; 
+  } else {
+    node->prev = list->tail;
+    list->tail->next = node;
+  }
+  list->tail = node;
+  list->count++;
+}
+
+static inline mpls_return_enum mpls_link_list_add_tail(
+  struct mpls_link_list *list, void *data) {
+  struct mpls_link_list_node *node;
+
+  if ((node = mpls_link_list_node_create(data))) {
+    mpls_link_list_add_node_tail(list, node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FATAL;
+}
+
+static inline void mpls_link_list_add_node_before(struct mpls_link_list *list,
+  struct mpls_link_list_node *ptr, struct mpls_link_list_node *node) {
+  if (list->head == ptr) {
+    node->next = ptr;
+    ptr->prev = node;
+    list->head = node;
+  } else {
+    node->prev = ptr->prev;
+    node->next = ptr;
+    ptr->prev->next = node;
+    ptr->prev = node;
+  }
+  list->count++;
+}
+
+static inline mpls_return_enum mpls_link_list_add_data_before(
+  struct mpls_link_list *list, struct mpls_link_list_node *ptr, void *data) {
+  struct mpls_link_list_node *node;
+
+  if ((node = mpls_link_list_node_create(data))) {
+    mpls_link_list_add_node_before(list,ptr,node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FATAL;
+}
+
+static inline void mpls_link_list_add_node_after(struct mpls_link_list *list,
+  struct mpls_link_list_node *ptr, struct mpls_link_list_node *node) {
+  if (list->tail == ptr) {
+    ptr->next = node;
+    node->prev = ptr; 
+    list->tail = node;
+  } else {
+    node->prev = ptr;
+    node->next = ptr->next;
+    ptr->next = node;
+    ptr->next->prev = node;
+  }
+  list->count++;
+}
+
+static inline mpls_return_enum mpls_link_list_add_data_after(
+  struct mpls_link_list *list, struct mpls_link_list_node *ptr, void *data) {
+  struct mpls_link_list_node *node;
+
+  if ((node = mpls_link_list_node_create(data))) {
+    mpls_link_list_add_node_after(list, ptr, node);
+    return MPLS_SUCCESS;
+  }
+  return MPLS_FATAL;
+}
+
+static inline void mpls_link_list_remove_node(struct mpls_link_list *list,
+  struct mpls_link_list_node *node) {
+
+  if (node->prev) {
+    node->prev->next = node->next;
+  } else {
+    list->head = node->next;
+  }
+
+  if (node->next) {
+    node->next->prev = node->prev;
+  } else {
+    list->tail = node->prev;
+  }
+
+  list->count--;
+}
+
+static inline void mpls_link_list_remove_data(struct mpls_link_list* list,
+  void *val)
+{
+  struct mpls_link_list_node *node;
+
+  for (node = list->head; node; node = node->next) {
+    if (node->data == val) {
+      mpls_link_list_remove_node(list,node);
+      mpls_link_list_node_delete(node);
+      break;
+    }
+  }
+}
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_lock_impl.h quagga-mpls/ldpd/mpls_lock_impl.h
--- quagga-0.99.10/ldpd/mpls_lock_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_lock_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,36 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_LOCK_IMPL_H_
+#define _MPLS_LOCK_IMPL_H_
+
+#include "mpls_struct.h"
+
+/*
+ * in: key
+ * return: mpls_lock_handle
+ */
+extern mpls_lock_handle mpls_lock_create(const mpls_lock_key_type key);
+
+/*
+ * in: handle
+ */
+extern void mpls_lock_get(mpls_lock_handle handle);
+
+/*
+ * in: handle
+ */
+extern void mpls_lock_release(mpls_lock_handle handle);
+
+/*
+ * in: handle
+ */
+extern void mpls_lock_delete(mpls_lock_handle handle);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_mm_impl.h quagga-mpls/ldpd/mpls_mm_impl.h
--- quagga-0.99.10/ldpd/mpls_mm_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_mm_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,26 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_MM_IMPL_H_
+#define _MPLS_MM_IMPL_H_
+
+#include "mpls_struct.h"
+
+/*
+ * in: size
+ * return: void*
+ */
+extern void *mpls_malloc(const mpls_size_type size);
+
+/*
+ * in: mem
+ */
+extern void mpls_free(void *mem);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_mpls_impl.h quagga-mpls/ldpd/mpls_mpls_impl.h
--- quagga-0.99.10/ldpd/mpls_mpls_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_mpls_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,82 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_MPLS_IMPL_H_
+#define _MPLS_MPLS_IMPL_H_
+
+#include "mpls_struct.h"
+
+struct ldp_inlabel;
+struct ldp_outlabel;
+
+/*
+ * in: handle
+ * return: mpls_mpls_handle
+ */
+extern mpls_mpls_handle mpls_mpls_open(mpls_instance_handle handle);
+
+/*
+ * in: handle
+ */
+extern void mpls_mpls_close(mpls_mpls_handle handle);
+
+/*
+ * in: handle, o
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_mpls_outsegment_add(mpls_mpls_handle handle,
+  struct mpls_outsegment * o);
+
+/*
+ * in: handle, o
+ */
+extern void mpls_mpls_outsegment_del(mpls_mpls_handle handle, struct mpls_outsegment * o);
+
+/*
+ * in: handle, i
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_mpls_insegment_add(mpls_mpls_handle handle,
+  struct mpls_insegment * i);
+
+/*
+ * in: handle, i
+ */
+extern void mpls_mpls_insegment_del(mpls_mpls_handle handle, struct mpls_insegment * i);
+
+/*
+ * in: handle, i, o
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_mpls_xconnect_add(mpls_mpls_handle handle,
+  struct mpls_insegment * i, struct mpls_outsegment * o);
+
+/*
+ * in: handle, i, o
+ */
+extern void mpls_mpls_xconnect_del(mpls_mpls_handle handle,
+  struct mpls_insegment * i, struct mpls_outsegment * o);
+
+/*
+ * in: handle, f, o
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_mpls_fec2out_add(mpls_mpls_handle handle,
+  mpls_fec * f, struct mpls_outsegment * o);
+
+/*
+ * in: handle, f, o
+ */
+extern void mpls_mpls_fec2out_del(mpls_mpls_handle handle,
+  mpls_fec * f, struct mpls_outsegment * o);
+
+extern mpls_return_enum mpls_mpls_get_label_space_range(mpls_mpls_handle handle,
+  mpls_range *range);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_policy_impl.h quagga-mpls/ldpd/mpls_policy_impl.h
--- quagga-0.99.10/ldpd/mpls_policy_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_policy_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,24 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_POLICY_IMPL_H_
+#define _MPLS_POLICY_IMPL_H_
+
+extern mpls_bool mpls_policy_import_check(mpls_instance_handle handle,
+  mpls_fec * f, mpls_nexthop * nh);
+extern mpls_bool mpls_policy_ingress_check(mpls_instance_handle handle,
+  mpls_fec * f, mpls_nexthop * nh);
+extern mpls_bool mpls_policy_egress_check(mpls_instance_handle handle,
+  mpls_fec * p, mpls_nexthop *nh);
+extern mpls_bool mpls_policy_export_check(mpls_instance_handle handle,
+  mpls_fec * p, mpls_nexthop * nh);
+extern mpls_bool mpls_policy_address_export_check(mpls_instance_handle handle,
+  mpls_inet_addr * addr);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_refcnt.h quagga-mpls/ldpd/mpls_refcnt.h
--- quagga-0.99.10/ldpd/mpls_refcnt.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_refcnt.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,69 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_REFCNT_H_
+#define _MPLS_REFCNT_H_
+
+#include "mpls_assert.h"
+
+#define MPLS_REFCNT_FIELD  uint32_t	_refcnt
+
+#define MPLS_REFCNT_VALUE(obj) (obj)?((obj)->_refcnt):(-1)
+
+#define MPLS_REFCNT_INIT(obj,count) {		\
+  (obj)->_refcnt = count;			\
+}
+
+#define MPLS_REFCNT_HOLD(obj) {			\
+  if((obj) != NULL) {				\
+    (obj)->_refcnt++;				\
+  }						\
+}
+
+#define MPLS_REFCNT_RELEASE(obj,dstry) {		\
+  if((obj) != NULL) {				\
+    (obj)->_refcnt--;				\
+    if((obj)->_refcnt <= 0) {			\
+      dstry(obj);				\
+      obj = NULL;				\
+    }						\
+  }						\
+}
+
+#define MPLS_REFCNT_RELEASE2(global,obj,dstry) { \
+  if((obj) != NULL) {				\
+    (obj)->_refcnt--;				\
+    if((obj)->_refcnt <= 0) {			\
+      dstry(global,obj);			\
+      obj = NULL;				\
+    }						\
+  }						\
+}
+
+#define MPLS_REFCNT_ASSERT(obj,count) {		\
+  if((obj) != NULL) {				\
+    MPLS_ASSERT((obj)->_refcnt == count);	\
+  }						\
+}
+
+#define MPLS_REFCNT_PTR_TYPE  uint32_t*
+#define MPLS_REFCNT_PTR(obj) (((obj) != NULL)?(&((obj)->_refcnt)):(NULL))
+
+#define MPLS_REFCNT_PTR_HOLD(ptr) {		\
+  if((ptr) != NULL) {				\
+    ((*(ptr))++);				\
+  }						\
+}
+#define MPLS_REFCNT_PTR_RELEASE(ptr) {		\
+  if((ptr) != NULL) {				\
+    ((*(ptr))--);				\
+  }						\
+}
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_socket_impl.h quagga-mpls/ldpd/mpls_socket_impl.h
--- quagga-0.99.10/ldpd/mpls_socket_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_socket_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,195 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_SOCKET_IMPL_H_
+#define _MPLS_SOCKET_IMPL_H_
+
+#include "ldp_struct.h"
+#include "mpls_struct.h"
+
+/*
+ * in: handle
+ * return: mpls_socket_mgr_handle
+ */
+extern mpls_socket_mgr_handle mpls_socket_mgr_open(const mpls_instance_handle
+  handle);
+
+/*
+ * in: handle
+ */
+extern void mpls_socket_mgr_close(const mpls_socket_mgr_handle handle);
+
+/*
+ * in: handle
+ * return: mpls_socket_handle
+ */
+extern mpls_socket_handle mpls_socket_create_tcp(const mpls_socket_mgr_handle
+  handle);
+
+/*
+ * in: handle
+ * return: mpls_socket_handle
+ */
+extern mpls_socket_handle mpls_socket_create_udp(const mpls_socket_mgr_handle
+  handle);
+
+/*
+ * in: handle
+ * return: mpls_socket_handle
+ */
+extern mpls_socket_handle mpls_socket_create_raw(const mpls_socket_mgr_handle
+  handle, int proto);
+
+/*
+ * in: handle,socket,from
+ * out: from
+ * return: mpls_socket_handle
+ */
+extern mpls_socket_handle mpls_socket_tcp_accept(const mpls_socket_mgr_handle
+  handle, const mpls_socket_handle socket, mpls_dest * from);
+
+/*
+ * in: handle,socket
+ */
+extern void mpls_socket_close(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket);
+
+/*
+ * in: handle,socket,local
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_bind(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, const mpls_dest * local);
+
+/*
+ * in: handle, socket, flag
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_options(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, const uint32_t flag);
+
+/*
+ * in: handle, socket, depth
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_tcp_listen(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, const int depth);
+
+/*
+ * in: handle, socket, to
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_tcp_connect(const mpls_socket_mgr_handle
+  handle, mpls_socket_handle socket, const mpls_dest * to);
+
+/*
+ * in: handle, socket
+ * return: int
+ */
+extern int mpls_socket_get_errno(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket);
+
+/*
+ * in: handle, socket
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_connect_status(const mpls_socket_mgr_handle
+  handle, mpls_socket_handle socket);
+
+/*
+ * in: handle, socket, ttl, loop
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_multicast_options(const mpls_socket_mgr_handle handle, mpls_socket_handle socket, const int ttl, const int loop);
+
+/*
+ * in: handle, socket, iff
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_multicast_if_tx(const mpls_socket_mgr_handle
+  handle, mpls_socket_handle socket, const ldp_if * iff);
+
+/*
+ * in: handle, socket, iff, mult
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_multicast_if_join(const mpls_socket_mgr_handle handle, mpls_socket_handle socket, const ldp_if * iff,
+  const mpls_inet_addr * mult);
+
+/*
+ * in: handle, socket, iff, mult
+ */
+extern void mpls_socket_multicast_if_drop(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, const ldp_if * iff, const mpls_inet_addr * mult);
+
+/*
+ * in: handle, socket, object, type
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_readlist_add(const mpls_socket_mgr_handle
+  handle, mpls_socket_handle socket, void *object, const mpls_socket_enum type);
+
+/*
+ * in: handle, socket
+ */
+extern void mpls_socket_readlist_del(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket);
+
+/*
+ * in: handle, socket, object, type
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_socket_writelist_add(const mpls_socket_mgr_handle
+  handle, mpls_socket_handle socket, void *object, const mpls_socket_enum type);
+
+/*
+ * in: handle, socket
+ */
+extern void mpls_socket_writelist_del(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket);
+
+/*
+ * in: handle, o
+ * return: int
+ */
+extern int mpls_socket_tcp_read(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, uint8_t * buffer, const int size);
+
+/*
+ * in: handle, o
+ * return: int
+ */
+extern int mpls_socket_tcp_write(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, uint8_t * buffer, const int size);
+
+/*
+ * in: handle, o
+ * return: int
+ */
+extern int mpls_socket_udp_sendto(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, uint8_t * buffer,
+
+  const int size, const mpls_dest * to);
+
+/*
+ * in: handle, o
+ * return: int
+ */
+extern int mpls_socket_udp_recvfrom(const mpls_socket_mgr_handle handle,
+  mpls_socket_handle socket, uint8_t * buffer, const int size, mpls_dest * from);
+
+extern mpls_return_enum
+mpls_socket_get_local_name(const mpls_socket_mgr_handle handle,
+    mpls_socket_handle socket, mpls_dest *name);
+
+extern mpls_return_enum
+mpls_socket_get_remote_name(const mpls_socket_mgr_handle handle,
+    mpls_socket_handle socket, mpls_dest *name);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_struct.h quagga-mpls/ldpd/mpls_struct.h
--- quagga-0.99.10/ldpd/mpls_struct.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_struct.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,242 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_STRUCT_H_
+#define _MPLS_STRUCT_H_
+
+#define MPLS_MAX_IF_NAME 16
+#define MPLS_MAX_LABELSTACK 4
+
+#include "mpls_handle_type.h"
+#include "mpls_bitfield.h"
+
+typedef enum {
+  MPLS_SUCCESS = 1,
+  MPLS_FAILURE,
+  MPLS_FATAL,
+  MPLS_CLOSED,
+  MPLS_NON_BLOCKING,
+  MPLS_END_OF_LIST,
+  MPLS_NO_ROUTE,
+} mpls_return_enum;
+
+typedef enum {
+  MPLS_UPDATE_ADD,
+  MPLS_UPDATE_DEL,
+  MPLS_UPDATE_MODIFY
+} mpls_update_enum;
+
+typedef enum {
+  MPLS_OPER_UP = 1,
+  MPLS_OPER_DOWN,
+} mpls_oper_state_enum;
+
+typedef enum {
+  MPLS_TIMER_ONESHOT = 1,
+  MPLS_TIMER_REOCCURRING,
+} mpls_timer_type_enum;
+
+typedef enum {
+  MPLS_UNIT_MICRO = 1,
+  MPLS_UNIT_SEC,
+  MPLS_UNIT_MIN,
+  MPLS_UNIT_HOUR
+} mpls_time_unit_enum;
+
+typedef enum {
+  MPLS_ADMIN_ENABLE = 1,
+  MPLS_ADMIN_DISABLE
+} mpls_admin_state_enum;
+
+typedef enum {
+  MPLS_LABEL_RANGE_GENERIC = 1,
+  MPLS_LABEL_RANGE_ATM_VP,
+  MPLS_LABEL_RANGE_ATM_VC,
+  MPLS_LABEL_RANGE_ATM_VP_VC,
+  MPLS_LABEL_RANGE_FR_10,
+  MPLS_LABEL_RANGE_FR_24
+} mpls_label_range_type;
+
+typedef enum {
+  MPLS_LABEL_TYPE_NONE,
+  MPLS_LABEL_TYPE_GENERIC,
+  MPLS_LABEL_TYPE_ATM,
+  MPLS_LABEL_TYPE_FR
+} mpls_label_type;
+
+typedef enum {
+  MPLS_BOOL_FALSE = 0,
+  MPLS_BOOL_TRUE = 1
+} mpls_bool;
+
+typedef enum {
+  MPLS_SOCKET_UDP_DATA = 1,
+  MPLS_SOCKET_TCP_LISTEN,
+  MPLS_SOCKET_TCP_CONNECT,
+  MPLS_SOCKET_TCP_DATA,
+  MPLS_SOCKET_ROUTE_UPDATE,
+} mpls_socket_enum;
+
+typedef enum {
+  MPLS_SOCKOP_NONBLOCK = 0x1,
+  MPLS_SOCKOP_REUSE = 0x2,
+  MPLS_SOCKOP_ROUTERALERT = 0x4,
+  MPLS_SOCKOP_HDRINCL = 0x8
+} mpls_socket_option_type;
+
+typedef enum {
+  MPLS_TRACE_STATE_SEND,
+  MPLS_TRACE_STATE_RECV,
+  MPLS_TRACE_STATE_ALL
+} mpls_trace_states;
+
+typedef enum {
+  MPLS_OWNER_LDP,
+  MPLS_OWNER_CRLDP,
+  MPLS_OWNER_STATIC,
+  MPLS_OWNER_RSVP_TE
+} mpls_owners_enum;
+
+/* this structure is slurped from GNU header files */
+typedef struct mpls_iphdr {
+  BITFIELDS_ASCENDING_2(unsigned int ihl:4,
+			unsigned int version:4);
+  u_int8_t tos;
+  u_int16_t tot_len;
+  u_int16_t id;
+  u_int16_t frag_off;
+  u_int8_t ttl;
+  u_int8_t protocol;
+  u_int16_t check;
+  u_int32_t saddr;
+  u_int32_t daddr;
+  /*The options start here. */
+} mpls_iphdr;
+
+typedef struct mpls_label_struct {
+  mpls_label_type type;
+  union {
+    int gen;
+    struct {
+      int vpi;
+      int vci;
+    } atm;
+    struct {
+      int len;
+      int dlci;
+    } fr;
+  } u;
+} mpls_label_struct;
+
+typedef enum mpls_family_enum {
+  MPLS_FAMILY_NONE,
+  MPLS_FAMILY_IPV4,
+  MPLS_FAMILY_IPV6,
+} mpls_family_enum;
+
+typedef struct mpls_inet_addr {
+  enum mpls_family_enum type;
+  union {
+    uint8_t ipv6[16];
+    uint32_t ipv4;
+  } u;
+} mpls_inet_addr;
+
+typedef struct mpls_dest {
+  struct mpls_inet_addr addr;
+  uint16_t port;
+  mpls_if_handle if_handle;
+} mpls_dest;
+
+typedef struct mpls_range {
+  int label_space;
+  mpls_label_range_type type;
+  struct mpls_label_struct min, max;
+} mpls_range;
+
+typedef enum mpls_nexthop_enum {
+  MPLS_NH_NONE	= 0x0,
+  MPLS_NH_IP	= 0x1,
+  MPLS_NH_IF	= 0x2,
+  MPLS_NH_OUTSEGMENT	= 0x4
+} mpls_nexthop_enum;
+
+typedef enum mpls_fec_enum {
+  MPLS_FEC_NONE,
+  MPLS_FEC_PREFIX,
+  MPLS_FEC_HOST,
+  MPLS_FEC_L2CC,
+} mpls_fec_enum;
+
+struct mpls_fec;
+
+typedef struct mpls_nexthop {
+  short distance;
+  short metric;
+  mpls_bool attached;
+
+  unsigned char type;
+  struct mpls_inet_addr ip;  
+  mpls_if_handle if_handle;
+  mpls_outsegment_handle outsegment_handle;
+
+  /* only used during gets */
+  uint32_t index;
+} mpls_nexthop;
+
+typedef struct mpls_fec {
+  enum mpls_fec_enum type;
+  union {
+    struct {
+      struct mpls_inet_addr network;
+      uint8_t length;
+    } prefix;
+    struct mpls_inet_addr host;
+    struct {
+      mpls_if_handle interface;
+      uint32_t connection_id;
+      uint32_t group_id;
+      uint8_t type;
+    } l2cc;
+  } u;
+
+  /* only used during gets */
+  mpls_bool is_route;
+  uint32_t index;
+} mpls_fec;
+
+typedef struct mpls_insegment {
+  struct mpls_label_struct label;
+  uint32_t npop;
+  uint32_t labelspace;
+  uint16_t family;
+  mpls_insegment_handle handle;
+  mpls_owners_enum owner;
+} mpls_insegment;
+
+typedef struct mpls_outsegment {
+  struct mpls_label_struct label;
+  mpls_bool push_label;
+  struct mpls_nexthop nexthop;
+  mpls_outsegment_handle handle;
+  mpls_owners_enum owner;
+} mpls_outsegment;
+
+typedef struct mpls_xconnect {
+  uint32_t lspid;
+  uint8_t stack_size;
+  struct mpls_label_struct stack[MPLS_MAX_LABELSTACK];
+  mpls_bool is_persistent;
+  mpls_xconnect_handle handle;
+  mpls_owners_enum owner;
+} mpls_xconnect;
+
+typedef void *mpls_cfg_handle;
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_timer_impl.h quagga-mpls/ldpd/mpls_timer_impl.h
--- quagga-0.99.10/ldpd/mpls_timer_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_timer_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,61 @@
+
+/*
+ *  Copyright (C) James R. Leu 2000
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_TIMER_IMPL_H_
+#define _MPLS_TIMER_IMPL_H_
+
+#include "mpls_struct.h"
+
+/*
+ * in: handle
+ * return: mpls_timer_mgr_handle
+ */
+extern mpls_timer_mgr_handle mpls_timer_open(mpls_instance_handle handle);
+
+/*
+ * in: handle
+ */
+extern void mpls_timer_close(mpls_timer_mgr_handle handle);
+
+/*
+ * in: handle, unit, duration, object, cfg, callback
+ * return: mpls_timer_handle
+ */
+extern mpls_timer_handle mpls_timer_create(const mpls_timer_mgr_handle handle,
+  const mpls_time_unit_enum unit, const int duration, void *object,
+  const mpls_cfg_handle cfg, void (*callback) (mpls_timer_handle timer,
+    void *object, mpls_cfg_handle cfg));
+
+/*
+ * in: handle, timer
+ */
+extern void mpls_timer_delete(const mpls_timer_mgr_handle handle,
+  const mpls_timer_handle timer);
+
+/*
+ * in: handle, timer, unit, duration, object, cfg, callback
+ * out: mpls_return_enum
+ */
+extern mpls_return_enum mpls_timer_modify(const mpls_timer_mgr_handle handle,
+  const mpls_timer_handle timer, const int duration);
+
+/*
+ * in: handle, timer, type
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_timer_start(const mpls_timer_mgr_handle handle,
+  const mpls_timer_handle timer, const mpls_timer_type_enum type);
+
+/*
+ * in: handle, timer
+ */
+extern void mpls_timer_stop(const mpls_timer_mgr_handle handle,
+  const mpls_timer_handle timer);
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_trace.h quagga-mpls/ldpd/mpls_trace.h
--- quagga-0.99.10/ldpd/mpls_trace.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_trace.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,60 @@
+#ifndef _LDP_TRACE_H_
+#define _LDP_TRACE_H_
+
+#include <stdio.h>
+#include <log.h>
+#include "ldp_struct.h"
+
+extern uint32_t ldp_traceflags;
+extern uint8_t trace_buffer[16834];
+extern int trace_buffer_len;
+
+#if 0
+1 2 3 4 5 6 7 8
+  12345678901234567890123456789012345678901234567890123456789012345678901234567890
+#endif
+#define LDP_TRACE_OUT(handle,args...) {				\
+    if(trace_buffer_len == 0) {					\
+      trace_buffer_len += sprintf(trace_buffer,"OUT: " args);\
+    } else {							\
+      trace_buffer_len += sprintf(trace_buffer+trace_buffer_len,args);\
+    }								\
+    if(trace_buffer[strlen(trace_buffer)-1] == '\n') {		\
+      trace_buffer[strlen(trace_buffer)-1] = '\0';		\
+      zlog_debug("%s",trace_buffer);				\
+      trace_buffer_len = 0;					\
+    }								\
+}
+#define LDP_TRACE_LOG(handle,class,type,args...) {		\
+  if(type & ldp_traceflags) {					\
+    LDP_TRACE_OUT(handle,args);					\
+  }								\
+}
+#define LDP_TRACE_PKT(handle,class,type,header,body) {		\
+  if(type & ldp_traceflags) {					\
+    header;							\
+    body;							\
+  }								\
+}
+#define LDP_DUMP_PKT(handle,class,type,func) {			\
+  if(type & ldp_traceflags) {					\
+    func;							\
+  }								\
+}
+#define LDP_PRINT(data,args...) {				\
+  if(ldp_traceflags & LDP_TRACE_FLAG_DEBUG) {			\
+    zlog_debug("PRT: " args);					\
+  }								\
+}
+#define LDP_ENTER(data,args...) {				\
+  if(ldp_traceflags & LDP_TRACE_FLAG_DEBUG) {			\
+    zlog_debug("ENTER: " args);					\
+  }								\
+}
+#define LDP_EXIT(data,args...) {				\
+  if(ldp_traceflags & LDP_TRACE_FLAG_DEBUG) {			\
+    zlog_debug("EXIT: " args);					\
+  }								\
+}
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_trace_impl.h quagga-mpls/ldpd/mpls_trace_impl.h
--- quagga-0.99.10/ldpd/mpls_trace_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_trace_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,15 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_TRACE_IMPL_H_
+#define _MPLS_TRACE_IMPL_H_
+
+#include "mpls_trace.h"
+
+#endif
diff -Naur quagga-0.99.10/ldpd/mpls_tree_impl.h quagga-mpls/ldpd/mpls_tree_impl.h
--- quagga-0.99.10/ldpd/mpls_tree_impl.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/ldpd/mpls_tree_impl.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,64 @@
+
+/*
+ *  Copyright (C) James R. Leu 2002
+ *  jleu@mindspring.com
+ *
+ *  This software is covered under the LGPL, for more
+ *  info check out http://www.gnu.org/copyleft/lgpl.html
+ */
+
+#ifndef _MPLS_TREE_IMPL_H_
+#define _MPLS_TREE_IMPL_H_
+
+#include "mpls_struct.h"
+
+/*
+ * in: depth
+ * return: mpls_tree_handle
+ */
+extern mpls_tree_handle mpls_tree_create(const int depth);
+
+/*
+ * in: tree
+ */
+extern void mpls_tree_delete(const mpls_tree_handle tree);
+
+/*
+ * in: tree,key, length, node
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_tree_insert(const mpls_tree_handle tree,
+  const uint32_t key, const int length, void *node);
+
+/*
+ * in: tree, key, length, node
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_tree_remove(const mpls_tree_handle tree,
+  const uint32_t key, const int length, void **node);
+
+/*
+ * in: tree, key, length, nnode, onode
+ * return: mpls_return_enum, onode
+ */
+extern mpls_return_enum mpls_tree_replace(const mpls_tree_handle tree,
+  const uint32_t key, const int length, void *nnode, void **onode);
+
+/*
+ * in: tree, key, length, node
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_tree_get(const mpls_tree_handle tree,
+  const uint32_t key, const int length, void **node);
+
+/*
+ * in: tree, key, length, node
+ * return: mpls_return_enum
+ */
+extern mpls_return_enum mpls_tree_get_longest(const mpls_tree_handle tree,
+  const uint32_t key, void **node);
+
+extern void mpls_tree_dump(const mpls_tree_handle tree,
+  ldp_tree_callback callback);
+
+#endif
diff -Naur quagga-0.99.10/lib/command.c quagga-mpls/lib/command.c
--- quagga-0.99.10/lib/command.c	2007-04-29 00:14:10.000000000 +0200
+++ quagga-mpls/lib/command.c	2008-11-25 12:30:18.000000000 +0100
@@ -2385,9 +2385,15 @@
       vty->node = ENABLE_NODE;
       vty_config_unlock (vty);
       break;
+    case MPLS_LABELSPACE_NODE:
     case INTERFACE_NODE:
+    case TUNNEL_NODE:
+    case MPLS_TUNNEL_NODE:
+    case MPLS_TE_TUNNEL_NODE:
+    case MPLS_TE_TUNNEL_CONF_NODE:
     case ZEBRA_NODE:
     case BGP_NODE:
+    case LDP_NODE:
     case RIP_NODE:
     case RIPNG_NODE:
     case OSPF_NODE:
@@ -2409,6 +2415,9 @@
     case KEYCHAIN_KEY_NODE:
       vty->node = KEYCHAIN_NODE;
       break;
+    case LDP_IF_NODE:
+      vty->node = INTERFACE_NODE;
+      break;
     default:
       break;
     }
@@ -2434,10 +2443,17 @@
       /* Nothing to do. */
       break;
     case CONFIG_NODE:
+    case MPLS_LABELSPACE_NODE:
     case INTERFACE_NODE:
+    case TUNNEL_NODE:
+    case MPLS_TUNNEL_NODE:
+    case MPLS_TE_TUNNEL_NODE:
+    case MPLS_TE_TUNNEL_CONF_NODE:
     case ZEBRA_NODE:
     case RIP_NODE:
     case RIPNG_NODE:
+    case LDP_NODE:
+    case LDP_IF_NODE:
     case BGP_NODE:
     case BGP_VPNV4_NODE:
     case BGP_IPV4_NODE:
diff -Naur quagga-0.99.10/lib/command.h quagga-mpls/lib/command.h
--- quagga-0.99.10/lib/command.h	2007-05-02 18:05:35.000000000 +0200
+++ quagga-mpls/lib/command.h	2008-11-25 12:30:18.000000000 +0100
@@ -72,11 +72,18 @@
   AAA_NODE,			/* AAA node. */
   KEYCHAIN_NODE,		/* Key-chain node. */
   KEYCHAIN_KEY_NODE,		/* Key-chain key node. */
+  MPLS_LABELSPACE_NODE,		/* MPLS Labelspace node. */
   INTERFACE_NODE,		/* Interface mode node. */
+  TUNNEL_NODE,			/* Tunnel config node. */
+  MPLS_TUNNEL_NODE,		/* MPLS Tunnel config node. */
+  MPLS_TE_TUNNEL_NODE,
+  MPLS_TE_TUNNEL_CONF_NODE,
   ZEBRA_NODE,			/* zebra connection node. */
   TABLE_NODE,			/* rtm_table selection node. */
   RIP_NODE,			/* RIP protocol mode node. */ 
   RIPNG_NODE,			/* RIPng protocol mode node. */
+  LDP_NODE,			/* LDP protocol mode */
+  LDP_IF_NODE,			/* LDP interface mode */
   BGP_NODE,			/* BGP protocol mode which includes BGP4+ */
   BGP_VPNV4_NODE,		/* BGP MPLS-VPN PE exchange. */
   BGP_IPV4_NODE,		/* BGP IPv4 unicast address family.  */
diff -Naur quagga-0.99.10/lib/if.c quagga-mpls/lib/if.c
--- quagga-0.99.10/lib/if.c	2006-12-12 20:18:21.000000000 +0100
+++ quagga-mpls/lib/if.c	2008-11-25 12:30:18.000000000 +0100
@@ -131,6 +131,7 @@
 	     "name exists already!", ifp->name);
   ifp->connected = list_new ();
   ifp->connected->del = (void (*) (void *)) connected_free;
+  ifp->mpls_labelspace = -1;
 
   if (if_master.if_new_hook)
     (*if_master.if_new_hook) (ifp);
@@ -770,6 +771,30 @@
 }
 #endif
 
+struct interface *if_getfirst()
+{
+  struct listnode *node = listhead(iflist);
+  return listgetdata(node);
+}
+
+struct interface *if_getnext(struct interface *old)
+{
+  struct interface *ifp;
+  struct listnode *node;
+  int flag = 0;
+
+  for (node = listhead(iflist); node; listnextnode(node)) {
+    ifp = listgetdata(node);
+    if (flag) {
+      return ifp;
+    }
+    if (ifp->ifindex == old->ifindex) {
+      flag = 1;
+    }
+  }
+  return NULL;
+}
+
 #ifndef HAVE_IF_INDEXTONAME
 char *
 if_indextoname (unsigned int ifindex, char *name)
diff -Naur quagga-0.99.10/lib/if.h quagga-mpls/lib/if.h
--- quagga-0.99.10/lib/if.h	2007-05-10 04:38:51.000000000 +0200
+++ quagga-mpls/lib/if.h	2008-11-25 12:30:18.000000000 +0100
@@ -133,6 +133,7 @@
 #ifdef HAVE_NET_RT_IFLIST
   struct if_data stats;
 #endif /* HAVE_NET_RT_IFLIST */
+  int mpls_labelspace;
 };
 
 /* Connected address structure. */
@@ -291,6 +292,9 @@
 extern struct connected  *connected_lookup_address (struct interface *, 
                                              struct in_addr);
 
+extern struct interface *if_getfirst();
+extern struct interface *if_getnext(struct interface*);
+
 #ifndef HAVE_IF_NAMETOINDEX
 extern unsigned int if_nametoindex (const char *);
 #endif
diff -Naur quagga-0.99.10/lib/log.c quagga-mpls/lib/log.c
--- quagga-0.99.10/lib/log.c	2008-02-29 00:26:02.000000000 +0100
+++ quagga-mpls/lib/log.c	2008-11-25 12:30:18.000000000 +0100
@@ -42,6 +42,8 @@
   "ZEBRA",
   "RIP",
   "BGP",
+  "LDP",
+  "RSVP",
   "OSPF",
   "RIPNG",
   "OSPF6",
@@ -820,6 +822,9 @@
   DESC_ENTRY	(ZEBRA_ROUTE_ISIS,	"isis",		'I' ),
   DESC_ENTRY	(ZEBRA_ROUTE_BGP,	"bgp",		'B' ),
   DESC_ENTRY	(ZEBRA_ROUTE_HSLS,	"hsls",		'H' ),
+  DESC_ENTRY	(ZEBRA_ROUTE_LDP,	"ldp",		'L' ),
+  DESC_ENTRY	(ZEBRA_ROUTE_RSVP,	"rsvp",		'r' ),
+  DESC_ENTRY	(ZEBRA_ROUTE_TE,	"te",		't' ),
 };
 #undef DESC_ENTRY
 
@@ -847,6 +852,16 @@
   DESC_ENTRY	(ZEBRA_ROUTER_ID_ADD),
   DESC_ENTRY	(ZEBRA_ROUTER_ID_DELETE),
   DESC_ENTRY	(ZEBRA_ROUTER_ID_UPDATE),
+  DESC_ENTRY	(ZEBRA_MPLS_XC_ADD),
+  DESC_ENTRY	(ZEBRA_MPLS_XC_DELETE),
+  DESC_ENTRY	(ZEBRA_MPLS_IN_SEGMENT_ADD),
+  DESC_ENTRY	(ZEBRA_MPLS_IN_SEGMENT_DELETE),
+  DESC_ENTRY	(ZEBRA_MPLS_OUT_SEGMENT_ADD),
+  DESC_ENTRY	(ZEBRA_MPLS_OUT_SEGMENT_DELETE),
+  DESC_ENTRY	(ZEBRA_MPLS_LABELSPACE_ADD),
+  DESC_ENTRY	(ZEBRA_MPLS_LABELSPACE_DELETE),
+  DESC_ENTRY	(ZEBRA_MPLS_FTN_ADD),
+  DESC_ENTRY	(ZEBRA_MPLS_FTN_DELETE),
 };
 #undef DESC_ENTRY
 
diff -Naur quagga-0.99.10/lib/log.h quagga-mpls/lib/log.h
--- quagga-0.99.10/lib/log.h	2008-02-29 00:26:02.000000000 +0100
+++ quagga-mpls/lib/log.h	2008-11-25 12:30:18.000000000 +0100
@@ -50,6 +50,8 @@
   ZLOG_ZEBRA,
   ZLOG_RIP,
   ZLOG_BGP,
+  ZLOG_LDP,
+  ZLOG_RSVP,
   ZLOG_OSPF,
   ZLOG_RIPNG,  
   ZLOG_OSPF6,
diff -Naur quagga-0.99.10/lib/memtypes.c quagga-mpls/lib/memtypes.c
--- quagga-0.99.10/lib/memtypes.c	2007-05-04 22:15:47.000000000 +0200
+++ quagga-mpls/lib/memtypes.c	2008-11-25 12:30:18.000000000 +0100
@@ -83,8 +83,8 @@
   { MTYPE_NEXTHOP,		"Nexthop"			},
   { MTYPE_RIB,			"RIB"				},
   { MTYPE_RIB_QUEUE,		"RIB process work queue"	},
-  { MTYPE_STATIC_IPV4,		"Static IPv4 route"		},
-  { MTYPE_STATIC_IPV6,		"Static IPv6 route"		},
+  { MTYPE_STATIC_ROUTE,		"Static route"			},
+  { MTYPE_TE,			"Traffic Engineering"		},
   { -1, NULL },
 };
 
@@ -242,6 +242,18 @@
   { -1, NULL },
 };
 
+struct memory_list memory_list_ldp[] =
+{
+  { MTYPE_LDP,                "LDP"				},
+  { -1, NULL },
+};
+
+struct memory_list memory_list_rsvp[] =
+{
+  { MTYPE_RSVP,               "RSVP"				},
+  { -1, NULL },
+};
+
 struct memory_list memory_list_vtysh[] =
 {
   { MTYPE_VTYSH_CONFIG,		"Vtysh configuration",		},
@@ -258,5 +270,7 @@
   { memory_list_ospf6,	"OSPF6"	},
   { memory_list_isis,	"ISIS"	},
   { memory_list_bgp,	"BGP"	},
+  { memory_list_ldp,	"LDP"	},
+  { memory_list_rsvp,	"RSVP"	},
   { NULL, NULL},
 };
diff -Naur quagga-0.99.10/lib/memtypes.h quagga-mpls/lib/memtypes.h
--- quagga-0.99.10/lib/memtypes.h	2008-05-29 20:17:40.000000000 +0200
+++ quagga-mpls/lib/memtypes.h	2008-11-25 12:30:18.000000000 +0100
@@ -70,8 +70,8 @@
   MTYPE_NEXTHOP,
   MTYPE_RIB,
   MTYPE_RIB_QUEUE,
-  MTYPE_STATIC_IPV4,
-  MTYPE_STATIC_IPV6,
+  MTYPE_STATIC_ROUTE,
+  MTYPE_TE,
   MTYPE_BGP,
   MTYPE_BGP_PEER,
   MTYPE_BGP_PEER_HOST,
@@ -187,8 +187,10 @@
   MTYPE_ISIS_ROUTE_INFO,
   MTYPE_ISIS_NEXTHOP,
   MTYPE_ISIS_NEXTHOP6,
+  MTYPE_LDP,
   MTYPE_VTYSH_CONFIG,
   MTYPE_VTYSH_CONFIG_LINE,
+  MTYPE_RSVP,
   MTYPE_MAX,
 };
 
@@ -200,6 +202,7 @@
 extern struct memory_list memory_list_ospf[];
 extern struct memory_list memory_list_ospf6[];
 extern struct memory_list memory_list_isis[];
+extern struct memory_list memory_list_ldp[];
 extern struct memory_list memory_list_vtysh[];
 
 #endif /* _QUAGGA_MEMTYPES_H */
diff -Naur quagga-0.99.10/lib/route_types.h quagga-mpls/lib/route_types.h
--- quagga-0.99.10/lib/route_types.h	2008-05-29 20:17:40.000000000 +0200
+++ quagga-mpls/lib/route_types.h	1970-01-01 01:00:00.000000000 +0100
@@ -1,88 +0,0 @@
-/* Auto-generated from route_types.txt by gawk. */
-/* Do not edit! */
-
-#ifndef _QUAGGA_ROUTE_TYPES_H
-#define _QUAGGA_ROUTE_TYPES_H
-
-/* zebra */
-#define QUAGGA_REDIST_STR_ZEBRA \
-"(rip|ripng|ospf|ospf6|isis|bgp)"
-#define QUAGGA_REDIST_HELP_STR_ZEBRA \
-  "Routing Information Protocol (RIP)\n" \
-  "Routing Information Protocol next-generation (IPv6) (RIPng)\n" \
-  "Open Shortest Path First (OSPFv2)\n" \
-  "Open Shortest Path First (IPv6) (OSPFv3)\n" \
-  "Intermediate System to Intermediate System (IS-IS)\n" \
-  "Border Gateway Protocol (BGP)\n"
-
-/* ripd */
-#define QUAGGA_REDIST_STR_RIPD \
-"(kernel|connected|static|ospf|isis|bgp)"
-#define QUAGGA_REDIST_HELP_STR_RIPD \
-  "Kernel routes (not installed via the zebra RIB)\n" \
-  "Connected routes (directly attached subnet or host)\n" \
-  "Statically configured routes\n" \
-  "Open Shortest Path First (OSPFv2)\n" \
-  "Intermediate System to Intermediate System (IS-IS)\n" \
-  "Border Gateway Protocol (BGP)\n"
-
-/* ripngd */
-#define QUAGGA_REDIST_STR_RIPNGD \
-"(kernel|connected|static|ospf6|isis|bgp)"
-#define QUAGGA_REDIST_HELP_STR_RIPNGD \
-  "Kernel routes (not installed via the zebra RIB)\n" \
-  "Connected routes (directly attached subnet or host)\n" \
-  "Statically configured routes\n" \
-  "Open Shortest Path First (IPv6) (OSPFv3)\n" \
-  "Intermediate System to Intermediate System (IS-IS)\n" \
-  "Border Gateway Protocol (BGP)\n"
-
-/* ospfd */
-#define QUAGGA_REDIST_STR_OSPFD \
-"(kernel|connected|static|rip|isis|bgp)"
-#define QUAGGA_REDIST_HELP_STR_OSPFD \
-  "Kernel routes (not installed via the zebra RIB)\n" \
-  "Connected routes (directly attached subnet or host)\n" \
-  "Statically configured routes\n" \
-  "Routing Information Protocol (RIP)\n" \
-  "Intermediate System to Intermediate System (IS-IS)\n" \
-  "Border Gateway Protocol (BGP)\n"
-
-/* ospf6d */
-#define QUAGGA_REDIST_STR_OSPF6D \
-"(kernel|connected|static|ripng|isis|bgp)"
-#define QUAGGA_REDIST_HELP_STR_OSPF6D \
-  "Kernel routes (not installed via the zebra RIB)\n" \
-  "Connected routes (directly attached subnet or host)\n" \
-  "Statically configured routes\n" \
-  "Routing Information Protocol next-generation (IPv6) (RIPng)\n" \
-  "Intermediate System to Intermediate System (IS-IS)\n" \
-  "Border Gateway Protocol (BGP)\n"
-
-/* isisd */
-#define QUAGGA_REDIST_STR_ISISD \
-"(kernel|connected|static|rip|ripng|ospf|ospf6|bgp)"
-#define QUAGGA_REDIST_HELP_STR_ISISD \
-  "Kernel routes (not installed via the zebra RIB)\n" \
-  "Connected routes (directly attached subnet or host)\n" \
-  "Statically configured routes\n" \
-  "Routing Information Protocol (RIP)\n" \
-  "Routing Information Protocol next-generation (IPv6) (RIPng)\n" \
-  "Open Shortest Path First (OSPFv2)\n" \
-  "Open Shortest Path First (IPv6) (OSPFv3)\n" \
-  "Border Gateway Protocol (BGP)\n"
-
-/* bgpd */
-#define QUAGGA_REDIST_STR_BGPD \
-"(kernel|connected|static|rip|ripng|ospf|ospf6|isis)"
-#define QUAGGA_REDIST_HELP_STR_BGPD \
-  "Kernel routes (not installed via the zebra RIB)\n" \
-  "Connected routes (directly attached subnet or host)\n" \
-  "Statically configured routes\n" \
-  "Routing Information Protocol (RIP)\n" \
-  "Routing Information Protocol next-generation (IPv6) (RIPng)\n" \
-  "Open Shortest Path First (OSPFv2)\n" \
-  "Open Shortest Path First (IPv6) (OSPFv3)\n" \
-  "Intermediate System to Intermediate System (IS-IS)\n"
-
-#endif /* _QUAGGA_ROUTE_TYPES_H */
diff -Naur quagga-0.99.10/lib/stream.c quagga-mpls/lib/stream.c
--- quagga-0.99.10/lib/stream.c	2008-06-07 22:26:26.000000000 +0200
+++ quagga-mpls/lib/stream.c	2008-11-25 12:30:18.000000000 +0100
@@ -449,6 +449,25 @@
 
   return l;
 }
+
+/* Get next float from the stream. */
+float
+stream_getf_from (struct stream *s, size_t from)
+{
+  u_int32_t l = stream_getl_from (s, from);
+  float f;
+  ntohf ((float*)&l, &f);
+  return f;
+}
+
+float
+stream_getf (struct stream *s)
+{
+  u_int32_t l = stream_getl (s);
+  float f;
+  ntohf ((float*)&l, &f);
+  return f;
+}
 
 /* Copy to source to stream.
  *
@@ -688,6 +707,24 @@
   
   return psize;
 }
+
+int
+stream_putf (struct stream *s, float f)
+{
+  u_int32_t l;
+  htonf(&f, (float *)&l);
+  stream_putl (s, l);
+  return 4;
+}
+
+int
+stream_putf_at (struct stream *s, size_t putp, float f)
+{
+  u_int32_t l;
+  htonf(&f, (float *)&l);
+  stream_putl_at (s, putp, l);
+  return 4;
+}
 
 /* Read size from fd. */
 int
@@ -969,3 +1006,25 @@
   stream_fifo_clean (fifo);
   XFREE (MTYPE_STREAM_FIFO, fifo);
 }
+
+void
+htonf (float *src, float *dst)
+{
+  u_int32_t lu1, lu2;
+
+  memcpy (&lu1, src, sizeof (u_int32_t));
+  lu2 = htonl (lu1);
+  memcpy (dst, &lu2, sizeof (u_int32_t));
+  return;
+}
+
+void
+ntohf (float *src, float *dst)
+{
+  u_int32_t lu1, lu2;
+
+  memcpy (&lu1, src, sizeof (u_int32_t));
+  lu2 = ntohl (lu1);
+  memcpy (dst, &lu2, sizeof (u_int32_t));
+  return;
+}
diff -Naur quagga-0.99.10/lib/stream.h quagga-mpls/lib/stream.h
--- quagga-0.99.10/lib/stream.h	2008-06-07 22:26:34.000000000 +0200
+++ quagga-mpls/lib/stream.h	2008-11-25 12:30:18.000000000 +0100
@@ -162,6 +162,8 @@
 extern int stream_put_ipv4 (struct stream *, u_int32_t);
 extern int stream_put_in_addr (struct stream *, struct in_addr *);
 extern int stream_put_prefix (struct stream *, struct prefix *);
+extern int stream_putf (struct stream *, float);
+extern int stream_putf_at (struct stream *, size_t, float);
 
 extern void stream_get (void *, struct stream *, size_t);
 extern u_char stream_getc (struct stream *);
@@ -173,6 +175,8 @@
 extern uint64_t stream_getq (struct stream *);
 extern uint64_t stream_getq_from (struct stream *, size_t);
 extern u_int32_t stream_get_ipv4 (struct stream *);
+extern float stream_getf (struct stream *);
+extern float stream_getf_from (struct stream *, size_t);
 
 #undef stream_read
 #undef stream_write
@@ -218,4 +222,7 @@
 extern void stream_fifo_clean (struct stream_fifo *fifo);
 extern void stream_fifo_free (struct stream_fifo *fifo);
 
+extern void htonf (float *src, float *dst);
+extern void ntohf (float *src, float *dst);
+
 #endif /* _ZEBRA_STREAM_H */
diff -Naur quagga-0.99.10/lib/table.c quagga-mpls/lib/table.c
--- quagga-0.99.10/lib/table.c	2005-05-06 23:25:49.000000000 +0200
+++ quagga-mpls/lib/table.c	2008-11-25 12:30:18.000000000 +0100
@@ -311,6 +311,37 @@
   return NULL;
 }
 
+struct route_node *
+route_node_lookup2 (struct route_table *table, struct prefix *p)
+{
+  struct route_node *rn_in, *rn_tmp;
+
+  if (!(rn_in = route_node_lookup(table,p))) {
+fprintf(stderr,"lookup2 is doing work\n");
+    /* walk as far down the tree as we can */
+    rn_in = table->top;
+    while (rn_in && rn_in->p.prefixlen <= p->prefixlen &&
+      prefix_match(&rn_in->p, p)) {
+      rn_tmp = rn_in->link[check_bit(&p->u.prefix, rn_in->p.prefixlen)];
+      if (!rn_tmp) {
+        break;
+      }
+      rn_in = rn_tmp;
+    }
+    route_lock_node(rn_in);
+
+    /* rn_in is either the actual node of the furthest node in the tree */
+    /* so get the 'next' one with 'info' */
+    rn_in = route_next2(rn_in);
+  }
+
+  if (rn_in && !rn_in->info) {
+    route_unlock_node(rn_in);
+    rn_in = NULL;
+  }
+  return rn_in;
+}
+
 /* Add node to routing table. */
 struct route_node *
 route_node_get (struct route_table *table, struct prefix *p)
@@ -461,6 +492,22 @@
   return NULL;
 }
 
+struct route_node *
+route_next2 (struct route_node *rn_in)
+{
+  struct route_node *rn = rn_in;
+  struct route_node *rn2;
+  do {
+    rn2 = route_next(rn);
+    rn = rn2;
+  } while(rn && !rn->info);
+
+  if (rn && rn->info) {
+    return rn;
+  }
+  return NULL;
+}
+
 /* Unlock current node and lock next node until limit. */
 struct route_node *
 route_next_until (struct route_node *node, struct route_node *limit)
diff -Naur quagga-0.99.10/lib/table.h quagga-mpls/lib/table.h
--- quagga-0.99.10/lib/table.h	2005-05-06 23:25:49.000000000 +0200
+++ quagga-mpls/lib/table.h	2008-11-25 12:30:18.000000000 +0100
@@ -59,12 +59,15 @@
 extern void route_node_delete (struct route_node *node);
 extern struct route_node *route_top (struct route_table *);
 extern struct route_node *route_next (struct route_node *);
+extern struct route_node *route_next2 (struct route_node *);
 extern struct route_node *route_next_until (struct route_node *,
                                             struct route_node *);
 extern struct route_node *route_node_get (struct route_table *,
                                           struct prefix *);
 extern struct route_node *route_node_lookup (struct route_table *,
                                              struct prefix *);
+extern struct route_node *route_node_lookup2 (struct route_table *,
+                                              struct prefix *);
 extern struct route_node *route_lock_node (struct route_node *node);
 extern struct route_node *route_node_match (struct route_table *, 
                                             struct prefix *);
diff -Naur quagga-0.99.10/lib/thread.c quagga-mpls/lib/thread.c
--- quagga-0.99.10/lib/thread.c	2006-08-27 08:44:02.000000000 +0200
+++ quagga-mpls/lib/thread.c	2008-11-25 12:30:18.000000000 +0100
@@ -416,10 +416,26 @@
 					   sizeof (struct thread_master));
 }
 
+static int thread_in_list(struct thread_list *list, struct thread *thread)
+{
+  struct thread *tt;
+
+  for (tt = list->head; tt; tt = tt->next)
+  {
+    if (tt == thread)
+    {
+      return 1;
+    }
+  }
+  return 0;
+}
+
 /* Add a new thread to the list.  */
 static void
 thread_list_add (struct thread_list *list, struct thread *thread)
 {
+  assert(!thread_in_list(list,thread));
+
   thread->next = NULL;
   thread->prev = list->tail;
   if (list->tail)
@@ -436,6 +452,8 @@
 			struct thread *point, 
 			struct thread *thread)
 {
+  assert(!thread_in_list(list,thread));
+
   thread->next = point;
   thread->prev = point->prev;
   if (point->prev)
@@ -450,6 +468,8 @@
 static struct thread *
 thread_list_delete (struct thread_list *list, struct thread *thread)
 {
+  assert(thread_in_list(list,thread));
+
   if (thread->next)
     thread->next->prev = thread->prev;
   else
diff -Naur quagga-0.99.10/lib/vty.c quagga-mpls/lib/vty.c
--- quagga-0.99.10/lib/vty.c	2007-05-10 04:38:51.000000000 +0200
+++ quagga-mpls/lib/vty.c	2008-11-25 12:30:18.000000000 +0100
@@ -690,10 +690,17 @@
       /* Nothing to do. */
       break;
     case CONFIG_NODE:
+    case MPLS_LABELSPACE_NODE:
     case INTERFACE_NODE:
+    case TUNNEL_NODE:
+    case MPLS_TUNNEL_NODE:
+    case MPLS_TE_TUNNEL_NODE:
+    case MPLS_TE_TUNNEL_CONF_NODE:
     case ZEBRA_NODE:
     case RIP_NODE:
     case RIPNG_NODE:
+    case LDP_NODE:
+    case LDP_IF_NODE:
     case BGP_NODE:
     case BGP_VPNV4_NODE:
     case BGP_IPV4_NODE:
@@ -1097,10 +1104,17 @@
       /* Nothing to do. */
       break;
     case CONFIG_NODE:
+    case MPLS_LABELSPACE_NODE:
     case INTERFACE_NODE:
+    case TUNNEL_NODE:
+    case MPLS_TUNNEL_NODE:
+    case MPLS_TE_TUNNEL_NODE:
+    case MPLS_TE_TUNNEL_CONF_NODE:
     case ZEBRA_NODE:
     case RIP_NODE:
     case RIPNG_NODE:
+    case LDP_NODE:
+    case LDP_IF_NODE:
     case BGP_NODE:
     case RMAP_NODE:
     case OSPF_NODE:
diff -Naur quagga-0.99.10/lib/zclient.c quagga-mpls/lib/zclient.c
--- quagga-0.99.10/lib/zclient.c	2007-05-10 04:38:51.000000000 +0200
+++ quagga-mpls/lib/zclient.c	2008-11-25 12:30:18.000000000 +0100
@@ -39,6 +39,11 @@
 /* Prototype for event manager. */
 static void zclient_event (enum event, struct zclient *);
 
+#ifdef HAVE_MPLS
+static void mpls_label_stream_write (struct stream *s, struct zmpls_label *label);
+static int mpls_label_stream_read (struct stream *s, struct zmpls_label *label);
+#endif
+
 extern struct thread_master *master;
 
 /* This file local debug flag. */
@@ -399,19 +404,52 @@
   * +-+-+-+-+-+-+-+-+
   *
   * 
-  * A number of IPv4 nexthop(s) or nexthop interface index(es) are then 
-  * described, as per the Nexthop count. Each nexthop described as:
+  * A number of nexthop(s) are then  described, as per the Nexthop count.
+  * Each nexthop described as:
+  *
+  * +-+-+-+-+-+-+-+-+
+  * | Nexthop Flags |  Set to bitwise combination of ZEBRA_NEXTHOP_*
+  * +-+-+-+-+-+-+-+-+
+  *
+  * For each bit in "Nexthop Flags" one of the following is written
+  *
+  * +-+-+-+-+-+-+-+-+
+  * | NEXTHOP_IPV4  |
+  * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  * |       IPv4 Nexthop address                                    |
+  * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  *
+  * +-+-+-+-+-+-+-+-+
+  * | NEXTHOP_IPV6  |
+  * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  * |       IPv6 Nexthop address                                    |
+  * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  *   ....
   *
   * +-+-+-+-+-+-+-+-+
-  * | Nexthop Type  |  Set to one of ZEBRA_NEXTHOP_*
+  * |NEXTHOP_IFINDEX|
   * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-  * |       IPv4 Nexthop address or Interface Index number          |
+  * |       Interface Index                                         |
   * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   *
-  * Alternatively, if the flags field has ZEBRA_FLAG_BLACKHOLE or
-  * ZEBRA_FLAG_REJECT is set then Nexthop count is set to 1, then _no_ 
-  * nexthop information is provided, and the message describes a prefix
-  * to blackhole or reject route.
+  * +-+-+-+-+-+-+-+-+
+  * |NEXTHOP_IFNAME |
+  * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  * |       Interface Name                                          |
+  * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  *   ....
+  *
+  * +-+-+-+-+-+-+-+-+
+  * | NEXTHOP_DROP  |
+  * +-+-+-+-+-+-+-+-+
+  * |  DROP type    |
+  * +-+-+-+-+-+-+-+-+
+  *
+  * +-+-+-+-+-+-+-+-+
+  * |NEXTHOP_MPLS   |
+  * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+  * |       MPLS value                                              |
+  * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   *
   * If ZAPI_MESSAGE_DISTANCE is set, the distance value is written as a 1
   * byte value.
@@ -421,16 +459,106 @@
   *
   * XXX: No attention paid to alignment.
   */ 
+
+void
+zapi_nexthop_write(struct stream *s, struct zapi_nexthop *nh)
+{
+  stream_putc (s, nh->type);    
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_DROP))
+    {
+      stream_putc (s, ZEBRA_NEXTHOP_DROP);
+      stream_putc (s, nh->gw.drop);
+      return;
+    }
+
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_IPV4))
+    {
+      stream_putc (s, ZEBRA_NEXTHOP_IPV4);
+      stream_put_in_addr (s, &nh->gw.ipv4);
+    }
+#ifdef HAVE_IPV6
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_IPV6))
+    {
+      stream_putc (s, ZEBRA_NEXTHOP_IPV6);
+      stream_write (s, (u_char *)&nh->gw.ipv6, 16);
+    }
+#endif
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_IFINDEX))
+    {
+      stream_putc (s, ZEBRA_NEXTHOP_IFINDEX);
+      stream_putl (s, nh->intf.index);
+    }
+
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_IFNAME))
+    {
+      stream_putc (s, ZEBRA_NEXTHOP_IFNAME);
+      stream_put (s, nh->intf.name, INTERFACE_NAMSIZ);
+    }
+
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_SRC_IPV4))
+    {
+      stream_putc (s, ZEBRA_NEXTHOP_SRC_IPV4);
+      stream_put_in_addr (s, &nh->src.ipv4);
+    }
+#ifdef HAVE_IPV6
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_SRC_IPV6))
+    {
+      stream_putc (s, ZEBRA_NEXTHOP_SRC_IPV6);
+      stream_write (s, (u_char *)&nh->src.ipv6, 16);
+    }
+#endif
+
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_MPLS))
+    {
+      stream_putc (s, ZEBRA_NEXTHOP_MPLS);
+      mpls_label_stream_write (s, &nh->mpls);
+    }
+#endif
+}
+
+void
+zapi_nexthop_read(struct stream *s, struct zapi_nexthop *nh)
+{
+  char type = stream_getc (s);
+  nh->type = type;  
+  while (type != 0)
+    {
+      char ntype = stream_getc(s);
+      UNSET_FLAG (type, ntype);
+      if (CHECK_FLAG (ntype, ZEBRA_NEXTHOP_DROP))
+        nh->gw.drop = stream_getc(s);
+      else if (CHECK_FLAG (ntype, ZEBRA_NEXTHOP_IPV4))
+        nh->gw.ipv4.s_addr = stream_get_ipv4 (s);
+#ifdef HAVE_IPV6
+      else if (CHECK_FLAG (ntype, ZEBRA_NEXTHOP_IPV6))
+        stream_get (&nh->gw.ipv6, s, 16);
+#endif
+      else if (CHECK_FLAG (ntype, ZEBRA_NEXTHOP_IFINDEX))
+        nh->intf.index = stream_getl (s);
+      else if (CHECK_FLAG (ntype, ZEBRA_NEXTHOP_IFNAME))
+        stream_get (nh->intf.name, s, INTERFACE_NAMSIZ);
+      else if (CHECK_FLAG (ntype, ZEBRA_NEXTHOP_SRC_IPV4))
+        nh->src.ipv4.s_addr = stream_get_ipv4 (s);
+#ifdef HAVE_IPV6
+      else if (CHECK_FLAG (ntype, ZEBRA_NEXTHOP_SRC_IPV6))
+        stream_get (&nh->src.ipv6, s, 16);
+#endif
+#ifdef HAVE_MPLS
+      else if (CHECK_FLAG (ntype, ZEBRA_NEXTHOP_MPLS))
+        mpls_label_stream_read(s, &nh->mpls);
+#endif
+    }
+}
+
 int
-zapi_ipv4_route (u_char cmd, struct zclient *zclient, struct prefix_ipv4 *p,
+zapi_ipv4_write (u_char cmd, struct stream *s, struct prefix_ipv4 *p,
                  struct zapi_ipv4 *api)
 {
   int i;
   int psize;
-  struct stream *s;
 
   /* Reset stream. */
-  s = zclient->obuf;
   stream_reset (s);
   
   zclient_create_header (s, cmd);
@@ -445,31 +573,15 @@
   stream_putc (s, p->prefixlen);
   stream_write (s, (u_char *) & p->prefix, psize);
 
-  /* Nexthop, ifindex, distance and metric information. */
+  /* Nexthop information. */
   if (CHECK_FLAG (api->message, ZAPI_MESSAGE_NEXTHOP))
     {
-      if (CHECK_FLAG (api->flags, ZEBRA_FLAG_BLACKHOLE))
-        {
-          stream_putc (s, 1);
-          stream_putc (s, ZEBRA_NEXTHOP_BLACKHOLE);
-          /* XXX assert(api->nexthop_num == 0); */
-          /* XXX assert(api->ifindex_num == 0); */
-        }
-      else
-        stream_putc (s, api->nexthop_num + api->ifindex_num);
-
+      stream_putc (s, api->nexthop_num);
       for (i = 0; i < api->nexthop_num; i++)
-        {
-          stream_putc (s, ZEBRA_NEXTHOP_IPV4);
-          stream_put_in_addr (s, api->nexthop[i]);
-        }
-      for (i = 0; i < api->ifindex_num; i++)
-        {
-          stream_putc (s, ZEBRA_NEXTHOP_IFINDEX);
-          stream_putl (s, api->ifindex[i]);
-        }
+        zapi_nexthop_write(s, &api->nexthop[i]);
     }
 
+  /* distance and metric information. */
   if (CHECK_FLAG (api->message, ZAPI_MESSAGE_DISTANCE))
     stream_putc (s, api->distance);
   if (CHECK_FLAG (api->message, ZAPI_MESSAGE_METRIC))
@@ -478,20 +590,75 @@
   /* Put length at the first point of the stream. */
   stream_putw_at (s, 0, stream_get_endp (s));
 
+  return 0;
+}
+
+int
+zapi_ipv4_read (struct stream *s, zebra_size_t length,
+                struct zapi_ipv4 *api, struct prefix_ipv4 *p)
+{
+  /* Type, flags, message. */
+  api->type = stream_getc (s);
+  api->flags = stream_getc (s);
+  api->message = stream_getc (s);
+
+  /* IPv4 prefix. */
+  memset (p, 0, sizeof (struct prefix_ipv4));
+  p->family = AF_INET;
+  p->prefixlen = stream_getc (s);
+  stream_get (&p->prefix, s, PSIZE (p->prefixlen));
+
+  /* Nexthop, ifindex, distance and metric information. */
+  if (CHECK_FLAG (api->message, ZAPI_MESSAGE_NEXTHOP))
+    {
+      int count = 0;
+      int i = 0;
+
+      count = stream_getc (s);
+      while (count > 0)
+        {
+           zapi_nexthop_read (s, &api->nexthop[i]);
+           count--;
+           i++;
+        }
+
+      api->nexthop_num = i;
+    }
+
+  if (CHECK_FLAG (api->message, ZAPI_MESSAGE_DISTANCE))
+    api->distance = stream_getc (s);
+  if (CHECK_FLAG (api->message, ZAPI_MESSAGE_METRIC))
+    api->metric = stream_getl (s);
+
+  return 0;
+}
+
+int
+zapi_ipv4_route (u_char cmd, struct zclient *zclient, struct prefix_ipv4 *p,
+                 struct zapi_ipv4 *api)
+{
+  struct stream *s = zclient->obuf;
+  zapi_ipv4_write(cmd, s, p, api);
   return zclient_send_message(zclient);
 }
 
+int
+zapi_ipv4_route_read (struct zclient *zclient, zebra_size_t length,
+                      struct zapi_ipv4 *api, struct prefix_ipv4 *p)
+{
+  struct stream *s = zclient->ibuf;
+  return zapi_ipv4_read(s, length, api, p);
+}
+
 #ifdef HAVE_IPV6
 int
-zapi_ipv6_route (u_char cmd, struct zclient *zclient, struct prefix_ipv6 *p,
-	       struct zapi_ipv6 *api)
+zapi_ipv6_write (u_char cmd, struct stream *s, struct prefix_ipv6 *p,
+                 struct zapi_ipv6 *api)
 {
   int i;
   int psize;
-  struct stream *s;
 
   /* Reset stream. */
-  s = zclient->obuf;
   stream_reset (s);
 
   zclient_create_header (s, cmd);
@@ -506,23 +673,15 @@
   stream_putc (s, p->prefixlen);
   stream_write (s, (u_char *)&p->prefix, psize);
 
-  /* Nexthop, ifindex, distance and metric information. */
+  /* Nexthop information. */
   if (CHECK_FLAG (api->message, ZAPI_MESSAGE_NEXTHOP))
     {
-      stream_putc (s, api->nexthop_num + api->ifindex_num);
-
+      stream_putc (s, api->nexthop_num);
       for (i = 0; i < api->nexthop_num; i++)
-	{
-	  stream_putc (s, ZEBRA_NEXTHOP_IPV6);
-	  stream_write (s, (u_char *)api->nexthop[i], 16);
-	}
-      for (i = 0; i < api->ifindex_num; i++)
-	{
-	  stream_putc (s, ZEBRA_NEXTHOP_IFINDEX);
-	  stream_putl (s, api->ifindex[i]);
-	}
+        zapi_nexthop_write(s, &api->nexthop[i]);
     }
 
+  /* distance and metric information. */
   if (CHECK_FLAG (api->message, ZAPI_MESSAGE_DISTANCE))
     stream_putc (s, api->distance);
   if (CHECK_FLAG (api->message, ZAPI_MESSAGE_METRIC))
@@ -531,8 +690,65 @@
   /* Put length at the first point of the stream. */
   stream_putw_at (s, 0, stream_get_endp (s));
 
+  return 0;
+}
+
+int
+zapi_ipv6_read (struct stream *s, zebra_size_t length,
+                struct zapi_ipv6 *api, struct prefix_ipv6 *p)
+{
+  /* Type, flags, message. */
+  api->type = stream_getc (s);
+  api->flags = stream_getc (s);
+  api->message = stream_getc (s);
+
+  /* IPv4 prefix. */
+  memset (p, 0, sizeof (struct prefix_ipv6));
+  p->family = AF_INET6;
+  p->prefixlen = stream_getc (s);
+  stream_get (&p->prefix, s, PSIZE (p->prefixlen));
+
+  /* Nexthop, ifindex, distance and metric information. */
+  if (CHECK_FLAG (api->message, ZAPI_MESSAGE_NEXTHOP))
+    {
+      int count = 0;
+      int i = 0;
+
+      count = stream_getc (s);
+      while (count > 0)
+        {
+           zapi_nexthop_read (s, &api->nexthop[i]);
+           count--;
+           i++;
+        }
+
+      api->nexthop_num = i;
+    }
+
+  if (CHECK_FLAG (api->message, ZAPI_MESSAGE_DISTANCE))
+    api->distance = stream_getc (s);
+  if (CHECK_FLAG (api->message, ZAPI_MESSAGE_METRIC))
+    api->metric = stream_getl (s);
+
+  return 0;
+}
+
+int
+zapi_ipv6_route (u_char cmd, struct zclient *zclient, struct prefix_ipv6 *p,
+                 struct zapi_ipv6 *api)
+{
+  struct stream *s = zclient->obuf;
+  zapi_ipv6_write(cmd, s, p, api);
   return zclient_send_message(zclient);
 }
+
+int
+zapi_ipv6_route_read (struct zclient *zclient, zebra_size_t length,
+                      struct zapi_ipv6 *api, struct prefix_ipv6 *p)
+{
+  struct stream *s = zclient->ibuf;
+  return zapi_ipv6_read (s, length, api, p);
+}
 #endif /* HAVE_IPV6 */
 
 /* 
@@ -541,6 +757,545 @@
  * then set/unset redist[type] in the client handle (a struct zserv) for the 
  * sending client
  */
+
+#ifdef HAVE_MPLS
+
+static void
+mpls_label_stream_write (struct stream *s, struct zmpls_label *label)
+{
+  /* Put label type. */
+  stream_putc (s, label->type);
+
+  /* put the label value */
+  switch (label->type)
+  {
+    case ZEBRA_MPLS_LABEL_GEN:
+      stream_putl (s, label->u.gen);
+      break;
+    case ZEBRA_MPLS_LABEL_ATM:
+      stream_putw (s, label->u.atm.vci);
+      stream_putw (s, label->u.atm.vpi);
+      break;
+    case ZEBRA_MPLS_LABEL_FR:
+      stream_putl (s, label->u.fr);
+      break;
+    default:
+      assert(0);
+  }
+}
+
+int
+mpls_label_stream_read (struct stream *s, struct zmpls_label *label)
+{
+  /* get the label type */
+  label->type = stream_getc (s);
+
+  /* get the label value */
+  switch (label->type)
+  {
+    case ZEBRA_MPLS_LABEL_GEN:
+      label->u.gen = stream_getl (s);
+      break;
+    case ZEBRA_MPLS_LABEL_ATM:
+      label->u.atm.vci = stream_getw (s);
+      label->u.atm.vpi = stream_getw (s);
+      break;
+    case ZEBRA_MPLS_LABEL_FR:
+      label->u.fr = stream_getl (s);
+      break;
+    default:
+      assert(0);
+  }
+  return 0;
+}
+
+static void
+mpls_fec_stream_write (struct stream *s, struct zmpls_fec *fec)
+{
+  int psize;
+
+  /* Put FEC type. */
+  stream_putc (s, fec->type);
+  stream_putc (s, fec->owner);
+
+  /* put the label value */
+  switch (fec->type)
+  {
+    case ZEBRA_MPLS_FEC_IPV4:
+    case ZEBRA_MPLS_FEC_IPV6:
+      /* Put prefix information. */
+      psize = PSIZE (fec->u.p.prefixlen);
+      stream_putc (s, fec->u.p.prefixlen);
+      stream_write (s, (u_char *)&fec->u.p.u.prefix, psize);
+      break;
+    case ZEBRA_MPLS_FEC_L2:
+      stream_put (s, fec->u.l2_ifname, INTERFACE_NAMSIZ);
+      break;
+    default:
+      assert(0);
+  }
+}
+
+static int
+mpls_fec_stream_read (struct stream *s, struct zmpls_fec *fec)
+{
+  /* get the fec type */
+  fec->type = stream_getc (s);
+  fec->owner = stream_getc (s);
+
+  /* get the fec value */
+  switch (fec->type)
+  {
+    case ZEBRA_MPLS_FEC_IPV4:
+    case ZEBRA_MPLS_FEC_IPV6:
+      memset (&fec->u.p, 0, sizeof (struct prefix));
+
+      if (fec->type == ZEBRA_MPLS_FEC_IPV4)
+        fec->u.p.family = AF_INET;
+      else
+        fec->u.p.family = AF_INET6;
+
+      fec->u.p.prefixlen = stream_getc (s);
+      stream_get (&fec->u.p.u.prefix, s, PSIZE (fec->u.p.prefixlen));
+      break;
+    case ZEBRA_MPLS_FEC_L2:
+      stream_get (fec->u.l2_ifname, s, INTERFACE_NAMSIZ);
+      break;
+    default:
+      assert(0);
+  }
+
+  return 0;
+}
+
+void
+mpls_ftn_stream_write (struct stream *s, struct zapi_mpls_ftn *api)
+{
+  stream_putc (s, api->owner);
+
+  /* the FEC we're binding to */
+  mpls_fec_stream_write (s, &api->fec);
+
+  /* out-segment index */
+  stream_putl (s, api->out_index);
+}
+
+int
+mpls_ftn_stream_read (struct stream *s, struct zapi_mpls_ftn *api)
+{
+  api->owner = stream_getc (s);
+
+  mpls_fec_stream_read (s, &api->fec);
+
+  api->out_index = stream_getl (s);
+  return 0;
+}
+
+void
+mpls_xc_stream_write (struct stream *s, struct zapi_mpls_xc *api)
+{
+  stream_putc (s, api->owner);
+
+  stream_putc (s, api->in_labelspace);
+  mpls_label_stream_write (s, &api->in_label);
+
+  stream_putl (s, api->out_index);
+}
+
+int
+mpls_xc_stream_read (struct stream *s, struct zapi_mpls_xc *api)
+{
+  api->owner = stream_getc (s);
+  api->in_labelspace = stream_getc (s);
+  mpls_label_stream_read (s, &api->in_label);
+
+  api->out_index = stream_getl (s);
+  return 0;
+}
+
+void
+mpls_in_segment_stream_write (struct stream *s,
+  struct zapi_mpls_in_segment *api)
+{
+  stream_putc (s, api->owner);
+  stream_putc (s, api->labelspace);
+  stream_putw (s, api->protocol);
+  stream_putc (s, api->pop);
+
+  mpls_label_stream_write (s, &api->label);
+}
+
+int
+mpls_in_segment_stream_read (struct stream *s,
+  struct zapi_mpls_in_segment *api)
+{
+  api->owner = stream_getc (s);
+  api->labelspace = stream_getc (s);
+  api->protocol = stream_getw (s);
+  api->pop = stream_getc (s);
+
+  mpls_label_stream_read (s, &api->label);
+  return 0;
+}
+
+void
+mpls_out_segment_stream_write (struct stream *s,
+  struct zapi_mpls_out_segment *api)
+{
+  stream_putc (s, api->owner);
+  zapi_nexthop_write(s, &api->nh);
+  stream_putl (s, api->index);
+  stream_putl (s, api->req);
+}
+
+int
+mpls_out_segment_stream_read (struct stream *s,
+  struct zapi_mpls_out_segment *api)
+{
+  api->owner = stream_getc (s);
+  zapi_nexthop_read(s, &api->nh);
+  api->index = stream_getl (s);
+  api->req = stream_getl (s);
+  return 0;
+}
+
+void
+mpls_labelspace_stream_write (struct stream *s,
+  struct zapi_mpls_labelspace *api)
+{
+  stream_putc (s, api->owner);
+  stream_putc (s, api->labelspace);
+  stream_put (s, api->ifname, INTERFACE_NAMSIZ);
+}
+
+int
+mpls_labelspace_stream_read (struct stream *s,
+  struct zapi_mpls_labelspace *api)
+{
+  api->owner = stream_getc (s);
+  api->labelspace = stream_getc (s);
+  stream_get (api->ifname, s, INTERFACE_NAMSIZ);
+
+  return 0;
+}
+
+static int
+zapi_mpls_xc (struct zclient *zclient, struct zapi_mpls_xc *api, u_char cmd)
+{
+  struct stream *s;
+
+  /* Reset stream. */
+  s = zclient->obuf;
+  stream_reset (s);
+
+  zclient_create_header (s, cmd);
+
+  mpls_xc_stream_write(s, api);
+
+  /* Put length at the first point of the stream. */
+  stream_putw_at (s, 0, stream_get_endp (s));
+
+  return zclient_send_message(zclient);
+}
+
+int
+zapi_mpls_xc_add (struct zclient *zclient, struct zapi_mpls_xc *api)
+{
+  return zapi_mpls_xc (zclient, api, ZEBRA_MPLS_XC_ADD);
+}
+
+int
+zapi_mpls_xc_delete (struct zclient *zclient, struct zapi_mpls_xc *api)
+{
+  return zapi_mpls_xc (zclient, api, ZEBRA_MPLS_XC_DELETE);
+}
+
+static int
+zapi_mpls_in_segment (struct zclient *zclient,
+  struct zapi_mpls_in_segment *api, u_char cmd)
+{
+  struct stream *s;
+
+  /* Reset stream. */
+  s = zclient->obuf;
+  stream_reset (s);
+
+  zclient_create_header (s, cmd);
+
+  mpls_in_segment_stream_write(s, api);
+
+  /* Put length at the first point of the stream. */
+  stream_putw_at (s, 0, stream_get_endp (s));
+
+  return zclient_send_message(zclient);
+}
+
+int
+zapi_mpls_in_segment_add (struct zclient *zclient,
+  struct zapi_mpls_in_segment *api)
+{
+  return zapi_mpls_in_segment (zclient, api, ZEBRA_MPLS_IN_SEGMENT_ADD);
+}
+
+int
+zapi_mpls_in_segment_delete (struct zclient *zclient,
+  struct zapi_mpls_in_segment *api)
+{
+  return zapi_mpls_in_segment (zclient, api, ZEBRA_MPLS_IN_SEGMENT_DELETE);
+}
+
+static int
+zapi_mpls_out_segment (struct zclient *zclient,
+  struct zapi_mpls_out_segment *api, u_char cmd)
+{
+  struct stream *s;
+
+  /* Reset stream. */
+  s = zclient->obuf;
+  stream_reset (s);
+
+  zclient_create_header (s, cmd);
+
+  mpls_out_segment_stream_write(s, api);
+
+  /* Put length at the first point of the stream. */
+  stream_putw_at (s, 0, stream_get_endp (s));
+
+  return zclient_send_message(zclient);
+}
+
+int
+zapi_mpls_out_segment_add (struct zclient *zclient,
+  struct zapi_mpls_out_segment *api)
+{
+  return zapi_mpls_out_segment (zclient, api, ZEBRA_MPLS_OUT_SEGMENT_ADD);
+}
+
+int
+zapi_mpls_out_segment_delete (struct zclient *zclient,
+  struct zapi_mpls_out_segment *api)
+{
+  return zapi_mpls_out_segment (zclient, api, ZEBRA_MPLS_OUT_SEGMENT_DELETE);
+}
+
+static int
+zapi_mpls_labelspace (struct zclient *zclient,
+  struct zapi_mpls_labelspace *api, u_char cmd)
+{
+  struct stream *s;
+
+  /* Reset stream. */
+  s = zclient->obuf;
+  stream_reset (s);
+
+  zclient_create_header (s, cmd);
+
+  mpls_labelspace_stream_write(s, api);
+
+  /* Put length at the first point of the stream. */
+  stream_putw_at (s, 0, stream_get_endp (s));
+
+  return zclient_send_message(zclient);
+}
+
+int
+zapi_mpls_labelspace_add (struct zclient *zclient,
+  struct zapi_mpls_labelspace *api)
+{
+  return zapi_mpls_labelspace (zclient, api, ZEBRA_MPLS_LABELSPACE_ADD);
+}
+
+int
+zapi_mpls_labelspace_delete (struct zclient *zclient,
+  struct zapi_mpls_labelspace *api)
+{
+  return zapi_mpls_labelspace (zclient, api, ZEBRA_MPLS_LABELSPACE_DELETE);
+}
+
+static int
+zapi_mpls_ftn (struct zclient *zclient, struct zapi_mpls_ftn *api, u_char cmd)
+{
+  struct stream *s;
+
+  /* Reset stream. */
+  s = zclient->obuf;
+  stream_reset (s);
+
+  zclient_create_header (s, cmd);
+
+  mpls_ftn_stream_write(s, api);
+
+  /* Put length at the first point of the stream. */
+  stream_putw_at (s, 0, stream_get_endp (s));
+
+  return zclient_send_message(zclient);
+}
+
+int
+zapi_mpls_ftn_add (struct zclient *zclient, struct zapi_mpls_ftn *api)
+{
+  return zapi_mpls_ftn (zclient, api, ZEBRA_MPLS_FTN_ADD);
+}
+
+int
+zapi_mpls_ftn_delete (struct zclient *zclient, struct zapi_mpls_ftn *api)
+{
+  return zapi_mpls_ftn (zclient, api, ZEBRA_MPLS_FTN_DELETE);
+}
+
+int
+mpls_label_match (struct zmpls_label *a, struct zmpls_label *b)
+{
+  if (a->type != b->type)
+    return 0;
+
+  switch (a->type)
+  {
+    case ZEBRA_MPLS_LABEL_GEN:
+      if (a->u.gen != b->u.gen)
+        return 0;
+      break;
+    case ZEBRA_MPLS_LABEL_ATM:
+      if (a->u.atm.vci != b->u.atm.vci &&
+          a->u.atm.vpi != b->u.atm.vpi)
+        return 0;
+      break;
+    case ZEBRA_MPLS_LABEL_FR:
+      if (a->u.fr != b->u.fr)
+        return 0;
+      break;
+    default:
+      assert(0);
+  }
+  return 1;
+}
+
+int
+mpls_fec_match(struct zmpls_fec *a, struct zmpls_fec *b)
+{
+  if (a->type != b->type)
+    return 0;
+
+  switch (a->type)
+  {
+    case ZEBRA_MPLS_FEC_IPV4:
+    case ZEBRA_MPLS_FEC_IPV6:
+      if (!prefix_same(&a->u.p, &b->u.p))
+      {
+	return 0;
+      }
+      break;
+    case ZEBRA_MPLS_FEC_L2:
+      if (strncmp(a->u.l2_ifname, b->u.l2_ifname, INTERFACE_NAMSIZ))
+      {
+	return 0;
+      }
+      break;
+    default:
+      assert(0);
+  }
+  return 1;
+}
+
+#endif
+/*
+ * NOTE when doing nexthop comparison, some IPv4 nexthop have ifindex
+ * and some do not. We only need to check the ifindex if this is not a
+ * IPv4 nexthop or if the both have ifindices
+ */
+
+int
+zapi_nexthop_match(struct zapi_nexthop *a, struct zapi_nexthop *b, int mask)
+{
+  int either = (a->type | b->type) & mask;
+  int both = (a->type & b->type) & mask;
+  int try = 0;
+  int match = 0;
+  int v4_gate_match = 0;
+
+  try++;
+  if (a->advmss == b->advmss)
+    match++;
+    
+  if (CHECK_FLAG (either, ZEBRA_NEXTHOP_DROP))
+    {
+      try++;
+      if (CHECK_FLAG (both, ZEBRA_NEXTHOP_DROP) &&
+	  a->gw.drop == b->gw.drop)
+        match++;
+    }
+  else if (CHECK_FLAG (either, ZEBRA_NEXTHOP_IPV4))
+    {
+      try++;
+      if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IPV4) &&
+          IPV4_ADDR_SAME (&a->gw.ipv4, &b->gw.ipv4))
+	{
+	  match++;
+	  v4_gate_match = 1;
+	}
+    }
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG (either, ZEBRA_NEXTHOP_IPV6))
+    {
+      try++;
+      if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IPV6) &&
+          IPV6_ADDR_SAME (&a->gw.ipv6, &b->gw.ipv6))
+        match++;
+    }
+#endif
+
+  if (CHECK_FLAG(either, ZEBRA_NEXTHOP_SRC_IPV4))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_SRC_IPV4) &&
+          IPV4_ADDR_SAME (&a->src.ipv4, &b->src.ipv4))
+        match++;
+    }
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG(either, ZEBRA_NEXTHOP_SRC_IPV6))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_SRC_IPV6) &&
+          IPV6_ADDR_SAME (&a->src.ipv6, &b->src.ipv6))
+        match++;
+    }
+#endif
+
+  if (CHECK_FLAG (either, ZEBRA_NEXTHOP_IFNAME))
+    {
+      try++;
+      if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IFNAME) &&
+          strcmp (&a->intf.name, &b->intf.name) == 0)
+        match++;
+    }
+  else if (CHECK_FLAG (either, ZEBRA_NEXTHOP_IFINDEX))
+    {
+      if (!v4_gate_match)
+        {
+          try++;
+          if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IFINDEX) &&
+            (a->intf.index == b->intf.index))
+            match++;
+        }
+      else if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IFINDEX))
+        {
+            try++;
+            if (a->intf.index == b->intf.index)
+              match++;
+        }
+    }
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG (either, ZEBRA_NEXTHOP_MPLS))
+    {
+      try++;
+      if (CHECK_FLAG (both, ZEBRA_NEXTHOP_MPLS) &&
+          mpls_label_match(&a->mpls, &b->mpls))
+        match++;
+    }
+#endif
+  return (try && try == match) ? 1 : 0;
+}
+
 int
 zebra_redistribute_send (int command, struct zclient *zclient, int type)
 {
@@ -937,6 +1692,46 @@
       if (zclient->ipv6_route_delete)
 	ret = (*zclient->ipv6_route_delete) (command, zclient, length);
       break;
+    case ZEBRA_MPLS_XC_ADD:
+      if (zclient->mpls_xc_add)
+	ret = (*zclient->mpls_xc_add) (command, zclient, length);
+      break;
+    case ZEBRA_MPLS_XC_DELETE:
+      if (zclient->mpls_xc_delete)
+	ret = (*zclient->mpls_xc_delete) (command, zclient, length);
+      break;
+    case ZEBRA_MPLS_IN_SEGMENT_ADD:
+      if (zclient->mpls_in_segment_add)
+	ret = (*zclient->mpls_in_segment_add) (command, zclient, length);
+      break;
+    case ZEBRA_MPLS_IN_SEGMENT_DELETE:
+      if (zclient->mpls_in_segment_delete)
+	ret = (*zclient->mpls_in_segment_delete) (command, zclient, length);
+      break;
+    case ZEBRA_MPLS_OUT_SEGMENT_ADD:
+      if (zclient->mpls_out_segment_add)
+	ret = (*zclient->mpls_out_segment_add) (command, zclient, length);
+      break;
+    case ZEBRA_MPLS_OUT_SEGMENT_DELETE:
+      if (zclient->mpls_out_segment_delete)
+	ret = (*zclient->mpls_out_segment_delete) (command, zclient, length);
+      break;
+    case ZEBRA_MPLS_LABELSPACE_ADD:
+      if (zclient->mpls_labelspace_add)
+	ret = (*zclient->mpls_labelspace_add) (command, zclient, length);
+      break;
+    case ZEBRA_MPLS_LABELSPACE_DELETE:
+      if (zclient->mpls_labelspace_delete)
+	ret = (*zclient->mpls_labelspace_delete) (command, zclient, length);
+      break;
+    case ZEBRA_MPLS_FTN_ADD:
+      if (zclient->mpls_ftn_add)
+	ret = (*zclient->mpls_ftn_add) (command, zclient, length);
+      break;
+    case ZEBRA_MPLS_FTN_DELETE:
+      if (zclient->mpls_ftn_delete)
+	ret = (*zclient->mpls_ftn_delete) (command, zclient, length);
+      break;
     default:
       break;
     }
diff -Naur quagga-0.99.10/lib/zclient.h quagga-mpls/lib/zclient.h
--- quagga-0.99.10/lib/zclient.h	2006-01-17 18:43:18.000000000 +0100
+++ quagga-mpls/lib/zclient.h	2008-11-25 12:30:18.000000000 +0100
@@ -24,6 +24,7 @@
 
 /* For struct interface and struct connected. */
 #include "if.h"
+#include "prefix.h"
 
 /* For input/output buffer to zebra. */
 #define ZEBRA_MAX_PACKET_SIZ          4096
@@ -31,6 +32,9 @@
 /* Zebra header size. */
 #define ZEBRA_HEADER_SIZE             6
 
+/* Zebra maximum number of nexthops per API struct */
+#define ZEBRA_MAX_NEXTHOP                8
+
 /* Structure for the zebra client. */
 struct zclient
 {
@@ -67,6 +71,9 @@
   /* Redistribute defauilt. */
   u_char default_information;
 
+  /* Router-id information. */
+  u_char ridinfo;
+
   /* Pointer to the callback functions. */
   int (*router_id_update) (int, struct zclient *, uint16_t);
   int (*interface_add) (int, struct zclient *, uint16_t);
@@ -79,6 +86,16 @@
   int (*ipv4_route_delete) (int, struct zclient *, uint16_t);
   int (*ipv6_route_add) (int, struct zclient *, uint16_t);
   int (*ipv6_route_delete) (int, struct zclient *, uint16_t);
+  int (*mpls_xc_add) (int, struct zclient *, uint16_t);
+  int (*mpls_xc_delete) (int, struct zclient *, uint16_t);
+  int (*mpls_in_segment_add) (int, struct zclient *, uint16_t);
+  int (*mpls_in_segment_delete) (int, struct zclient *, uint16_t);
+  int (*mpls_out_segment_add) (int, struct zclient *, uint16_t);
+  int (*mpls_out_segment_delete) (int, struct zclient *, uint16_t);
+  int (*mpls_labelspace_add) (int, struct zclient *, uint16_t);
+  int (*mpls_labelspace_delete) (int, struct zclient *, uint16_t);
+  int (*mpls_ftn_add) (int, struct zclient *, uint16_t);
+  int (*mpls_ftn_delete) (int, struct zclient *, uint16_t);
 };
 
 /* Zebra API message flag. */
@@ -95,10 +112,58 @@
                          * always set to 255 in new zserv.
                          */
   uint8_t version;
-#define ZSERV_VERSION	1
+#define ZSERV_VERSION	2
   uint16_t command;
 };
 
+#ifdef HAVE_MPLS
+
+#define ZEBRA_MPLS_LABEL_GEN 1
+#define ZEBRA_MPLS_LABEL_ATM 2
+#define ZEBRA_MPLS_LABEL_FR  3
+
+struct zmpls_label
+{
+  u_char type;
+  union {
+    u_int32_t gen;
+    u_int32_t fr;
+    struct {
+      u_int16_t  vpi;
+      u_int16_t  vci;
+    } atm;
+  } u;
+};
+#endif
+
+struct zapi_nexthop {
+  u_char type;
+  union
+    {
+      char name[INTERFACE_NAMSIZ + 1];
+      unsigned int index;
+    } intf;
+  union
+    {
+      struct in_addr ipv4;
+#ifdef HAVE_IPV6
+      struct in6_addr ipv6;
+#endif
+      u_char drop;
+    } gw;
+  union
+    {
+      struct in_addr ipv4;
+      struct in6_addr ipv6;
+    } src;
+
+  /* Advertised MSS */
+  int advmss;
+#ifdef HAVE_MPLS
+  struct zmpls_label mpls;
+#endif
+};
+
 /* Zebra IPv4 route message API. */
 struct zapi_ipv4
 {
@@ -109,10 +174,7 @@
   u_char message;
 
   u_char nexthop_num;
-  struct in_addr **nexthop;
-
-  u_char ifindex_num;
-  unsigned int *ifindex;
+  struct zapi_nexthop nexthop[8];
 
   u_char distance;
 
@@ -153,8 +215,19 @@
 extern struct connected *zebra_interface_address_read (int, struct stream *);
 extern void zebra_interface_if_set_value (struct stream *, struct interface *);
 extern void zebra_router_id_update_read (struct stream *s, struct prefix *rid);
+
+extern void zapi_nexthop_write(struct stream *s, struct zapi_nexthop *nh);
+extern void zapi_nexthop_read(struct stream *s, struct zapi_nexthop *nh);
+
+extern int zapi_ipv4_write (u_char cmd, struct stream *s, struct prefix_ipv4 *p,
+                            struct zapi_ipv4 *api);
+extern int zapi_ipv4_read (struct stream *, zebra_size_t, struct zapi_ipv4 *,
+                           struct prefix_ipv4 *);
+
 extern int zapi_ipv4_route (u_char, struct zclient *, struct prefix_ipv4 *, 
                             struct zapi_ipv4 *);
+extern int zapi_ipv4_route_read (struct zclient *, zebra_size_t, struct zapi_ipv4 *,
+                                 struct prefix_ipv4 *);
 
 #ifdef HAVE_IPV6
 /* IPv6 prefix add and delete function prototype. */
@@ -168,18 +241,162 @@
   u_char message;
 
   u_char nexthop_num;
-  struct in6_addr **nexthop;
-
-  u_char ifindex_num;
-  unsigned int *ifindex;
+  struct zapi_nexthop nexthop[8];
 
   u_char distance;
 
   u_int32_t metric;
 };
 
+extern int zapi_ipv6_write (u_char cmd, struct stream *s, struct prefix_ipv6 *p,
+                            struct zapi_ipv6 *api);
+extern int zapi_ipv6_read (struct stream *, zebra_size_t, struct zapi_ipv6 *,
+                           struct prefix_ipv6 *);
+
 extern int zapi_ipv6_route (u_char cmd, struct zclient *zclient, 
-                     struct prefix_ipv6 *p, struct zapi_ipv6 *api);
+                            struct prefix_ipv6 *p, struct zapi_ipv6 *api);
+extern int zapi_ipv6_route_read (struct zclient *, zebra_size_t, struct zapi_ipv6 *,
+                                 struct prefix_ipv6 *);
 #endif /* HAVE_IPV6 */
 
+#ifdef HAVE_MPLS
+
+#define ZEBRA_MPLS_FEC_IPV4 1
+#define ZEBRA_MPLS_FEC_IPV6 2
+#define ZEBRA_MPLS_FEC_L2  3
+
+struct zmpls_fec
+{
+  u_char type;
+  char owner;
+  union {
+    struct prefix p;
+    char l2_ifname[INTERFACE_NAMSIZ + 1];
+  } u;
+};
+
+/* structures used by clients */
+
+struct zapi_mpls_xc
+{
+  u_int index;
+  u_char owner;
+  u_char in_labelspace;
+  struct zmpls_label in_label;
+  u_int out_index;
+};
+
+struct zapi_mpls_in_segment
+{
+  u_char owner;
+  u_char labelspace;
+  u_short protocol;
+  u_char pop;
+  struct zmpls_label label;
+};
+
+struct zapi_mpls_out_segment
+{
+  u_char owner;
+  /* label is embeded in zapi_nexthop */
+  struct zapi_nexthop nh;
+  u_int index;
+  int req;
+};
+
+struct zapi_mpls_labelspace
+{
+  u_char owner;
+  char labelspace;
+  char ifname[INTERFACE_NAMSIZ + 1];
+};
+
+struct zapi_mpls_ftn
+{
+  u_char owner;
+  struct zmpls_fec fec;
+  u_int out_index;
+};
+
+int
+mpls_label_match (struct zmpls_label *a, struct zmpls_label *b);
+
+int
+mpls_fec_match (struct zmpls_fec *a, struct zmpls_fec *b);
+
+int
+zapi_nexthop_match(struct zapi_nexthop *a, struct zapi_nexthop *b, int mask);
+
+void
+mpls_xc_stream_write (struct stream *s, struct zapi_mpls_xc *api);
+
+int
+mpls_xc_stream_read (struct stream *s, struct zapi_mpls_xc *api);
+
+void
+mpls_in_segment_stream_write (struct stream *s,
+                              struct zapi_mpls_in_segment *api);
+int
+mpls_in_segment_stream_read (struct stream *s,
+                             struct zapi_mpls_in_segment *api);
+
+void
+mpls_out_segment_stream_write (struct stream *s,
+                               struct zapi_mpls_out_segment *api);
+int
+mpls_out_segment_stream_read (struct stream *s,
+                              struct zapi_mpls_out_segment *api);
+
+void
+mpls_labelspace_stream_write (struct stream *s,
+                              struct zapi_mpls_labelspace *api);
+int
+mpls_labelspace_stream_read (struct stream *s,
+                             struct zapi_mpls_labelspace *api);
+
+void
+mpls_ftn_stream_write (struct stream *s,
+                              struct zapi_mpls_ftn *api);
+int
+mpls_ftn_stream_read (struct stream *s,
+                             struct zapi_mpls_ftn *api);
+
+int
+zapi_mpls_xc_add (struct zclient *zclient, struct zapi_mpls_xc *api);
+
+int
+zapi_mpls_xc_delete (struct zclient *zclient, struct zapi_mpls_xc *api);
+
+int
+zapi_mpls_in_segment_add (struct zclient *zclient,
+                          struct zapi_mpls_in_segment *api);
+
+int
+zapi_mpls_in_segment_delete (struct zclient *zclient,
+                             struct zapi_mpls_in_segment *api);
+
+int
+zapi_mpls_out_segment_add (struct zclient *zclient,
+                           struct zapi_mpls_out_segment *api);
+
+int
+zapi_mpls_out_segment_delete (struct zclient *zclient,
+                              struct zapi_mpls_out_segment *api);
+
+int
+zapi_mpls_labelspace_add (struct zclient *zclient,
+                          struct zapi_mpls_labelspace *api);
+
+int
+zapi_mpls_labelspace_delete (struct zclient *zclient,
+                             struct zapi_mpls_labelspace *api);
+
+int
+zapi_mpls_ftn_add (struct zclient *zclient, struct zapi_mpls_ftn *api);
+
+int
+zapi_mpls_ftn_delete (struct zclient *zclient,
+                      struct zapi_mpls_ftn *api);
+
+#endif /* HAVE_MPLS */
 #endif /* _ZEBRA_ZCLIENT_H */
diff -Naur quagga-0.99.10/lib/zebra.h quagga-mpls/lib/zebra.h
--- quagga-0.99.10/lib/zebra.h	2008-05-29 19:55:55.000000000 +0200
+++ quagga-mpls/lib/zebra.h	2008-11-25 12:30:18.000000000 +0100
@@ -159,11 +159,16 @@
 #include <net/route.h>
 #endif /* HAVE_NET_ROUTE_H */
 
+#undef __STRICT_ANSI__
+
 #ifdef HAVE_NETLINK
 #include <linux/netlink.h>
 #include <linux/rtnetlink.h>
 #include <linux/filter.h>
 #include <stddef.h>
+#if defined(HAVE_MPLS) && defined(LINUX_MPLS)
+#include <linux/genetlink.h>
+#endif
 #else
 #define RT_TABLE_MAIN		0
 #endif /* HAVE_NETLINK */
@@ -413,7 +418,17 @@
 #define ZEBRA_ROUTER_ID_ADD               20
 #define ZEBRA_ROUTER_ID_DELETE            21
 #define ZEBRA_ROUTER_ID_UPDATE            22
-#define ZEBRA_MESSAGE_MAX                 23
+#define ZEBRA_MPLS_XC_ADD                 23
+#define ZEBRA_MPLS_XC_DELETE              24
+#define ZEBRA_MPLS_IN_SEGMENT_ADD         25
+#define ZEBRA_MPLS_IN_SEGMENT_DELETE      26
+#define ZEBRA_MPLS_OUT_SEGMENT_ADD        27
+#define ZEBRA_MPLS_OUT_SEGMENT_DELETE     28
+#define ZEBRA_MPLS_LABELSPACE_ADD         29
+#define ZEBRA_MPLS_LABELSPACE_DELETE      30
+#define ZEBRA_MPLS_FTN_ADD                31
+#define ZEBRA_MPLS_FTN_DELETE             32
+#define ZEBRA_MESSAGE_MAX                 33
 
 /* Marker value used in new Zserv, in the byte location corresponding
  * the command value in the old zserv header. To allow old and new
@@ -433,7 +448,10 @@
 #define ZEBRA_ROUTE_ISIS                 8
 #define ZEBRA_ROUTE_BGP                  9
 #define ZEBRA_ROUTE_HSLS		 10
-#define ZEBRA_ROUTE_MAX                  11
+#define ZEBRA_ROUTE_LDP                  11
+#define ZEBRA_ROUTE_RSVP                 12
+#define ZEBRA_ROUTE_TE                   13
+#define ZEBRA_ROUTE_MAX                  14
 
 /* Note: whenever a new route-type or zserv-command is added the
  * corresponding {command,route}_types[] table in lib/log.c MUST be
@@ -472,17 +490,29 @@
 #define ZEBRA_FLAG_CHANGED            0x20
 #define ZEBRA_FLAG_STATIC             0x40
 #define ZEBRA_FLAG_REJECT             0x80
+#define ZEBRA_FLAG_CHANGED_MPLS      0x100
+
+/*
+ * REJECT and BLACKHOLE flags should never be set by
+ * anything except nexthop_active_check(), instead create
+ * a nexthop * with flag ZEBRA_NEXTHOP_DROP and set the
+ * drop field to one of the ZEBRA_DROP_* values below.
+ */
 
 /* Zebra nexthop flags. */
-#define ZEBRA_NEXTHOP_IFINDEX            1
-#define ZEBRA_NEXTHOP_IFNAME             2
-#define ZEBRA_NEXTHOP_IPV4               3
-#define ZEBRA_NEXTHOP_IPV4_IFINDEX       4
-#define ZEBRA_NEXTHOP_IPV4_IFNAME        5
-#define ZEBRA_NEXTHOP_IPV6               6
-#define ZEBRA_NEXTHOP_IPV6_IFINDEX       7
-#define ZEBRA_NEXTHOP_IPV6_IFNAME        8
-#define ZEBRA_NEXTHOP_BLACKHOLE          9
+#define ZEBRA_NEXTHOP_IFINDEX            0x01
+#define ZEBRA_NEXTHOP_IFNAME             0x02
+#define ZEBRA_NEXTHOP_IPV4               0x04
+#define ZEBRA_NEXTHOP_IPV6               0x08
+#define ZEBRA_NEXTHOP_DROP               0x10
+#define ZEBRA_NEXTHOP_SRC_IPV4           0x20
+#define ZEBRA_NEXTHOP_SRC_IPV6           0x40
+#define ZEBRA_NEXTHOP_MPLS               0x80
+#define ZEBRA_NEXTHOP_ALL                0xFF
+
+#define ZEBRA_DROP_BLACKHOLE             1
+#define ZEBRA_DROP_REJECT                2
+#define ZEBRA_DROP_NULL                  3
 
 #ifndef INADDR_LOOPBACK
 #define	INADDR_LOOPBACK	0x7f000001	/* Internet address 127.0.0.1.  */
diff -Naur quagga-0.99.10/Makefile.am quagga-mpls/Makefile.am
--- quagga-0.99.10/Makefile.am	2007-08-02 15:36:56.000000000 +0200
+++ quagga-mpls/Makefile.am	2008-11-25 12:30:18.000000000 +0100
@@ -2,10 +2,10 @@
 
 SUBDIRS = lib @ZEBRA@ @BGPD@ @RIPD@ @RIPNGD@ @OSPFD@ @OSPF6D@ \
          @ISISD@ @WATCHQUAGGA@ @VTYSH@ @OSPFCLIENT@ doc m4 @pkgsrcdir@ \
-         redhat @SOLARIS@
+         redhat @SOLARIS@ @LDPD@ @RSVPD@
 
-DIST_SUBDIRS = lib zebra bgpd ripd ripngd ospfd ospf6d \
-	  isisd watchquagga vtysh ospfclient doc m4 pkgsrc redhat tests \
+DIST_SUBDIRS = lib zebra bgpd ripd ripngd ospfd ospf6d ldpd rsvpd \
+	  isisd watchquagga vtysh ospfclient ldpd doc m4 pkgsrc redhat tests \
 	  solaris
 
 EXTRA_DIST = aclocal.m4 SERVICES TODO REPORTING-BUGS INSTALL.quagga.txt \
diff -Naur quagga-0.99.10/ospf6d/ospf6_zebra.c quagga-mpls/ospf6d/ospf6_zebra.c
--- quagga-0.99.10/ospf6d/ospf6_zebra.c	2005-10-01 19:38:07.000000000 +0200
+++ quagga-mpls/ospf6d/ospf6_zebra.c	2008-11-25 12:30:18.000000000 +0100
@@ -195,74 +195,50 @@
   struct zapi_ipv6 api;
   unsigned long ifindex;
   struct prefix_ipv6 p;
-  struct in6_addr *nexthop;
+  struct in6_addr nexthop;
+  int i;
 
   s = zclient->ibuf;
-  ifindex = 0;
-  nexthop = NULL;
   memset (&api, 0, sizeof (api));
 
-  /* Type, flags, message. */
-  api.type = stream_getc (s);
-  api.flags = stream_getc (s);
-  api.message = stream_getc (s);
-
-  /* IPv6 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv6));
-  p.family = AF_INET6;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
-
-  /* Nexthop, ifindex, distance, metric. */
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
-    {
-      api.nexthop_num = stream_getc (s);
-      nexthop = (struct in6_addr *)
-        malloc (api.nexthop_num * sizeof (struct in6_addr));
-      stream_get (nexthop, s, api.nexthop_num * sizeof (struct in6_addr));
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_IFINDEX))
-    {
-      api.ifindex_num = stream_getc (s);
-      ifindex = stream_getl (s);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (s);
-  else
-    api.distance = 0;
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (s);
-  else
-    api.metric = 0;
+  zapi_ipv6_read (s, length, &api, &p);
 
-  if (IS_OSPF6_DEBUG_ZEBRA (RECV))
-    {
-      char prefixstr[128], nexthopstr[128];
-      prefix2str ((struct prefix *)&p, prefixstr, sizeof (prefixstr));
-      if (nexthop)
-        inet_ntop (AF_INET6, nexthop, nexthopstr, sizeof (nexthopstr));
-      else
-        snprintf (nexthopstr, sizeof (nexthopstr), "::");
+  for (i = 0; i < api.nexthop_num; i++)
+    { 
+      ifindex = 0;
+      memset (&nexthop, 0, sizeof (nexthop));
 
-      zlog_debug ("Zebra Receive route %s: %s %s nexthop %s ifindex %ld",
-		  (command == ZEBRA_IPV6_ROUTE_ADD ? "add" : "delete"),
-		  zebra_route_string(api.type), prefixstr, nexthopstr, ifindex);
-    }
- 
-  if (command == ZEBRA_IPV6_ROUTE_ADD)
-    ospf6_asbr_redistribute_add (api.type, ifindex, (struct prefix *) &p,
-                                 api.nexthop_num, nexthop);
-  else
-    ospf6_asbr_redistribute_remove (api.type, ifindex, (struct prefix *) &p);
+      if (api.nexthop[i].type & ZEBRA_NEXTHOP_IFINDEX)
+        ifindex = api.nexthop[i].intf.index;
+
+      if (api.nexthop[i].type & ZEBRA_NEXTHOP_IPV6)
+        memcpy(&nexthop, &api.nexthop[i].gw.ipv6, sizeof (nexthop));
 
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
-    free (nexthop);
+      if (IS_OSPF6_DEBUG_ZEBRA (RECV))
+        {
+          char prefixstr[128], nexthopstr[128];
+          prefix2str ((struct prefix *)&p, prefixstr, sizeof (prefixstr));
+          if (api.nexthop[i].type & ZEBRA_NEXTHOP_IPV6)
+            inet_ntop (AF_INET6, &nexthop, nexthopstr, sizeof (nexthopstr));
+          else
+            snprintf (nexthopstr, sizeof (nexthopstr), "::");
+
+          zlog_debug ("Zebra Receive route %s: %s %s nexthop %s ifindex %ld",
+		      (command == ZEBRA_IPV6_ROUTE_ADD ? "add" : "delete"),
+		      zebra_route_string(api.type), prefixstr,
+                      nexthopstr, ifindex);
+        }
+
+      if (command == ZEBRA_IPV6_ROUTE_ADD)
+        ospf6_asbr_redistribute_add (api.type, ifindex, (struct prefix *) &p,
+                                     api.nexthop_num, &nexthop);
+      else
+        ospf6_asbr_redistribute_remove (api.type, ifindex,
+                                        (struct prefix *) &p);
+    }
 
   return 0;
 }
-
-
-
 
 DEFUN (show_zebra,
        show_zebra_cmd,
@@ -349,8 +325,6 @@
   struct zapi_ipv6 api;
   char buf[64];
   int nhcount;
-  struct in6_addr **nexthops;
-  unsigned int *ifindexes;
   int i, ret = 0;
   struct prefix_ipv6 *dest;
 
@@ -409,24 +383,9 @@
       return;
     }
 
-  /* allocate memory for nexthop_list */
-  nexthops = XCALLOC (MTYPE_OSPF6_OTHER,
-                      nhcount * sizeof (struct in6_addr *));
-  if (nexthops == NULL)
-    {
-      zlog_warn ("Can't send route to zebra: malloc failed");
-      return;
-    }
-
-  /* allocate memory for ifindex_list */
-  ifindexes = XCALLOC (MTYPE_OSPF6_OTHER,
-                       nhcount * sizeof (unsigned int));
-  if (ifindexes == NULL)
-    {
-      zlog_warn ("Can't send route to zebra: malloc failed");
-      XFREE (MTYPE_OSPF6_OTHER, nexthops);
-      return;
-    }
+  api.type = ZEBRA_ROUTE_OSPF6;
+  api.flags = 0;
+  api.message = 0;
 
   for (i = 0; i < nhcount; i++)
     {
@@ -440,19 +399,14 @@
 	  zlog_debug ("  nexthop: %s%%%.*s(%d)", buf, IFNAMSIZ, ifname,
 		      request->nexthop[i].ifindex);
 	}
-      nexthops[i] = &request->nexthop[i].address;
-      ifindexes[i] = request->nexthop[i].ifindex;
+
+      SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
+      api.nexthop[i].type = ZEBRA_NEXTHOP_IPV6|ZEBRA_NEXTHOP_IFINDEX;
+      memcpy (&api.nexthop[i].gw.ipv6, &request->nexthop[i].address, 16);
+      api.nexthop[i].intf.index = request->nexthop[i].ifindex;
     }
 
-  api.type = ZEBRA_ROUTE_OSPF6;
-  api.flags = 0;
-  api.message = 0;
-  SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
-  api.nexthop_num = nhcount;
-  api.nexthop = nexthops;
-  SET_FLAG (api.message, ZAPI_MESSAGE_IFINDEX);
-  api.ifindex_num = nhcount;
-  api.ifindex = ifindexes;
+  api.nexthop_num = i;
   SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
   api.metric = (request->path.metric_type == 2 ?
                 request->path.cost_e2 : request->path.cost);
@@ -467,9 +421,6 @@
     zlog_err ("zapi_ipv6_route() %s failed: %s",
               (type == REM ? "delete" : "add"), safe_strerror (errno));
 
-  XFREE (MTYPE_OSPF6_OTHER, nexthops);
-  XFREE (MTYPE_OSPF6_OTHER, ifindexes);
-
   return;
 }
 
diff -Naur quagga-0.99.10/ospfd/ospf_zebra.c quagga-mpls/ospfd/ospf_zebra.c
--- quagga-0.99.10/ospfd/ospf_zebra.c	2007-03-14 21:21:43.000000000 +0100
+++ quagga-mpls/ospfd/ospf_zebra.c	2008-11-25 12:30:18.000000000 +0100
@@ -339,59 +339,37 @@
 {
   u_char message;
   u_char distance;
-  u_char flags;
-  int psize;
-  struct stream *s;
   struct ospf_path *path;
   struct listnode *node;
+  struct zapi_ipv4 api;
+  int count;
 
   if (zclient->redist[ZEBRA_ROUTE_OSPF])
     {
-      message = 0;
-      flags = 0;
-
-      /* OSPF pass nexthop and metric */
-      SET_FLAG (message, ZAPI_MESSAGE_NEXTHOP);
-      SET_FLAG (message, ZAPI_MESSAGE_METRIC);
-
-      /* Distance value. */
-      distance = ospf_distance_apply (p, or);
-      if (distance)
-        SET_FLAG (message, ZAPI_MESSAGE_DISTANCE);
+      memset (&api, 0, sizeof (api));
 
-      /* Make packet. */
-      s = zclient->obuf;
-      stream_reset (s);
-
-      /* Put command, type, flags, message. */
-      zclient_create_header (s, ZEBRA_IPV4_ROUTE_ADD);
-      stream_putc (s, ZEBRA_ROUTE_OSPF);
-      stream_putc (s, flags);
-      stream_putc (s, message);
-
-      /* Put prefix information. */
-      psize = PSIZE (p->prefixlen);
-      stream_putc (s, p->prefixlen);
-      stream_write (s, (u_char *) & p->prefix, psize);
+      api.flags = 0;
+      api.type = ZEBRA_ROUTE_OSPF;
 
-      /* Nexthop count. */
-      stream_putc (s, or->paths->count);
+      count = 0;
 
       /* Nexthop, ifindex, distance and metric information. */
       for (ALL_LIST_ELEMENTS_RO (or->paths, node, path))
         {
           if (path->nexthop.s_addr != INADDR_ANY)
             {
-              stream_putc (s, ZEBRA_NEXTHOP_IPV4);
-              stream_put_in_addr (s, &path->nexthop);
+              SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
+              api.nexthop[count].type = ZEBRA_NEXTHOP_IPV4;
+              api.nexthop[count].gw.ipv4.s_addr = path->nexthop.s_addr;
             }
           else
             {
-              stream_putc (s, ZEBRA_NEXTHOP_IFINDEX);
+              SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
+              api.nexthop[count].type = ZEBRA_NEXTHOP_IFINDEX;
               if (path->oi)
-                stream_putl (s, path->oi->ifp->ifindex);
+                api.nexthop[count].intf.index = path->oi->ifp->ifindex;
               else
-                stream_putl (s, 0);
+                api.nexthop[count].intf.index = 0;
             }
 
           if (IS_DEBUG_OSPF (zebra, ZEBRA_REDISTRIBUTE))
@@ -404,23 +382,29 @@
 			 inet_ntop(AF_INET, &path->nexthop,
 				   buf[1], sizeof(buf[1])));
             }
+          count++;
         }
 
-      if (CHECK_FLAG (message, ZAPI_MESSAGE_DISTANCE))
-        stream_putc (s, distance);
-      if (CHECK_FLAG (message, ZAPI_MESSAGE_METRIC))
-        {
-          if (or->path_type == OSPF_PATH_TYPE1_EXTERNAL)
-            stream_putl (s, or->cost + or->u.ext.type2_cost);
-          else if (or->path_type == OSPF_PATH_TYPE2_EXTERNAL)
-            stream_putl (s, or->u.ext.type2_cost);
-          else
-            stream_putl (s, or->cost);
+      api.nexthop_num = count;
+
+      /* Distance value. */
+      distance = ospf_distance_apply (p, or);
+      if (distance)
+        {
+          SET_FLAG (api.message, ZAPI_MESSAGE_DISTANCE);
+          api.distance = distance;
         }
 
-      stream_putw_at (s, 0, stream_get_endp (s));
+      /* OSPF pass metric */
+      SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
+      if (or->path_type == OSPF_PATH_TYPE1_EXTERNAL)
+        api.metric = or->cost + or->u.ext.type2_cost;
+      else if (or->path_type == OSPF_PATH_TYPE2_EXTERNAL)
+        api.metric = or->u.ext.type2_cost;
+      else
+        api.metric = or->cost;
 
-      zclient_send_message(zclient);
+      zapi_ipv4_route(ZEBRA_IPV4_ROUTE_ADD, zclient, p, &api);
     }
 }
 
@@ -429,31 +413,32 @@
 {
   struct zapi_ipv4 api;
   struct ospf_path *path;
-  struct in_addr *nexthop;
   struct listnode *node, *nnode;
+  int count;
 
   if (zclient->redist[ZEBRA_ROUTE_OSPF])
     {
       api.type = ZEBRA_ROUTE_OSPF;
       api.flags = 0;
       api.message = 0;
-      api.ifindex_num = 0;
-      api.nexthop_num = 0;
+      count = 0;
 
       for (ALL_LIST_ELEMENTS (or->paths, node, nnode, path))
         {
           if (path->nexthop.s_addr != INADDR_ANY)
             {
               SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
-              api.nexthop_num = 1;
-              nexthop = &path->nexthop;
-              api.nexthop = &nexthop;
+              api.nexthop[count].type = ZEBRA_NEXTHOP_IPV4;
+              api.nexthop[count].gw.ipv4.s_addr = path->nexthop.s_addr;
             }
           else if (ospf_if_exists(path->oi) && (path->oi->ifp))
             {
               SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
-              api.ifindex_num = 1;
-              api.ifindex = &path->oi->ifp->ifindex;
+              api.nexthop[count].type = ZEBRA_NEXTHOP_IFINDEX;
+              if (path->oi)
+                api.nexthop[count].intf.index = path->oi->ifp->ifindex;
+              else
+                api.nexthop[count].intf.index = 0;
             }
           else if ( IS_DEBUG_OSPF(zebra,ZEBRA_REDISTRIBUTE) )
             {
@@ -462,24 +447,25 @@
                          p->prefixlen);
             }
 
-          zapi_ipv4_route (ZEBRA_IPV4_ROUTE_DELETE, zclient, p, &api);
-
-          if (IS_DEBUG_OSPF (zebra, ZEBRA_REDISTRIBUTE) && api.nexthop_num)
+          if (IS_DEBUG_OSPF (zebra, ZEBRA_REDISTRIBUTE))
             {
 	      char buf[2][INET_ADDRSTRLEN];
-	      zlog_debug("Zebra: Route delete %s/%d nexthop %s",
-			 inet_ntop(AF_INET, &p->prefix, buf[0], sizeof(buf[0])),
-			 p->prefixlen,
-			 inet_ntop(AF_INET, *api.nexthop,
-				   buf[1], sizeof(buf[1])));
-            }
-          if (IS_DEBUG_OSPF (zebra, ZEBRA_REDISTRIBUTE) && api.ifindex_num)
-            {
-              zlog_debug ("Zebra: Route delete %s/%d ifindex %d",
-                         inet_ntoa (p->prefix),
-                         p->prefixlen, *api.ifindex);
+	      zlog_debug("Zebra: Route delete %s/%d",
+			 inet_ntop(AF_INET, &p->prefix, buf[0],
+			 sizeof(buf[0])), p->prefixlen);
+
+              if (CHECK_FLAG (api.nexthop[count].type, ZEBRA_NEXTHOP_IPV4))
+		  zlog_debug("\tnexthop %s", inet_ntop(AF_INET,
+			     &api.nexthop[count].gw.ipv4,
+			     buf[1], sizeof(buf[1])));
+
+              if (CHECK_FLAG (api.nexthop[count].type, ZEBRA_NEXTHOP_IFINDEX))
+                zlog_debug ("\tifindex %d", api.nexthop[count].intf.index);
             }
+          count++;
         }
+      api.nexthop_num = count;
+      zapi_ipv4_route (ZEBRA_IPV4_ROUTE_DELETE, zclient, p, &api);
     }
 }
 
@@ -491,11 +477,11 @@
   if (zclient->redist[ZEBRA_ROUTE_OSPF])
     {
       api.type = ZEBRA_ROUTE_OSPF;
-      api.flags = ZEBRA_FLAG_BLACKHOLE;
-      api.message = 0;
-      SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
-      api.nexthop_num = 0;
-      api.ifindex_num = 0;
+      api.flags = 0;
+      api.message = ZAPI_MESSAGE_NEXTHOP;
+      api.nexthop_num = 1;
+      api.nexthop[0].type = ZEBRA_NEXTHOP_DROP;
+      api.nexthop[0].gw.drop = ZEBRA_DROP_BLACKHOLE;
 
       zapi_ipv4_route (ZEBRA_IPV4_ROUTE_ADD, zclient, p, &api);
 
@@ -513,11 +499,11 @@
   if (zclient->redist[ZEBRA_ROUTE_OSPF])
     {
       api.type = ZEBRA_ROUTE_OSPF;
-      api.flags = ZEBRA_FLAG_BLACKHOLE;
-      api.message = 0;
-      SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
-      api.nexthop_num = 0;
-      api.ifindex_num = 0;
+      api.flags = 0;
+      api.message = ZAPI_MESSAGE_NEXTHOP;
+      api.nexthop_num = 1;
+      api.nexthop[0].type = ZEBRA_NEXTHOP_DROP;
+      api.nexthop[0].gw.drop = ZEBRA_DROP_BLACKHOLE;
 
       zapi_ipv4_route (ZEBRA_IPV4_ROUTE_DELETE, zclient, p, &api);
 
@@ -800,96 +786,85 @@
   struct prefix_ipv4 p;
   struct external_info *ei;
   struct ospf *ospf;
+  int i;
 
   s = zclient->ibuf;
-  ifindex = 0;
-  nexthop.s_addr = 0;
 
-  /* Type, flags, message. */
-  api.type = stream_getc (s);
-  api.flags = stream_getc (s);
-  api.message = stream_getc (s);
-
-  /* IPv4 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv4));
-  p.family = AF_INET;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
+  zapi_ipv4_read (s, length, &api, &p);
 
   if (IPV4_NET127(ntohl(p.prefix.s_addr)))
     return 0;
 
-  /* Nexthop, ifindex, distance, metric. */
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
-    {
-      api.nexthop_num = stream_getc (s);
-      nexthop.s_addr = stream_get_ipv4 (s);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_IFINDEX))
-    {
-      api.ifindex_num = stream_getc (s);
-      /* XXX assert(api.ifindex_num == 1); */
-      ifindex = stream_getl (s);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (s);
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (s);
-
   ospf = ospf_lookup ();
   if (ospf == NULL)
     return 0;
 
-  if (command == ZEBRA_IPV4_ROUTE_ADD)
+  /* Nexthop, ifindex, distance, metric. */
+  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
     {
-      /* XXX|HACK|TODO|FIXME:
-       * Maybe we should ignore reject/blackhole routes? Testing shows that
-       * there is no problems though and this is only way to "summarize"
-       * routes in ASBR at the moment. Maybe we need just a better generalised
-       * solution for these types?
-       *
-       * if ( CHECK_FLAG (api.flags, ZEBRA_FLAG_BLACKHOLE)
-       *     || CHECK_FLAG (api.flags, ZEBRA_FLAG_REJECT))
-       * return 0;
-       */
+      for (i = 0; i < api.nexthop_num; i++)
+        {
+          nexthop.s_addr = 0;
+          ifindex = 0;
+
+          if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IPV4))
+            nexthop.s_addr = api.nexthop[i].gw.ipv4.s_addr;
+
+          if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IFINDEX))
+            ifindex = api.nexthop[i].intf.index;
+
+          if (command == ZEBRA_IPV4_ROUTE_ADD)
+            {
+              /* XXX|HACK|TODO|FIXME:
+               * Maybe we should ignore reject/blackhole routes? Testing shows that
+               * there is no problems though and this is only way to "summarize"
+               * routes in ASBR at the moment. Maybe we need just a better generalised
+               * solution for these types?
+               *
+               * if ( CHECK_FLAG (api.flags, ZEBRA_FLAG_BLACKHOLE)
+               *     || CHECK_FLAG (api.flags, ZEBRA_FLAG_REJECT))
+               * return 0;
+               */
         
-      ei = ospf_external_info_add (api.type, p, ifindex, nexthop);
+              ei = ospf_external_info_add (api.type, p, ifindex, nexthop);
 
-      if (ospf->router_id.s_addr == 0)
-        /* Set flags to generate AS-external-LSA originate event
-           for each redistributed protocols later. */
-        ospf->external_origin |= (1 << api.type);
-      else
-        {
-          if (ei)
+              if (ospf->router_id.s_addr == 0)
+                /* Set flags to generate AS-external-LSA originate event
+                   for each redistributed protocols later. */
+                ospf->external_origin |= (1 << api.type);
+              else
+                {
+                  if (ei)
+                    {
+                      if (is_prefix_default (&p))
+                        ospf_external_lsa_refresh_default (ospf);
+                      else
+                        {
+                          struct ospf_lsa *current;
+
+                          current = ospf_external_info_find_lsa (ospf, &ei->p);
+                          if (!current)
+                            ospf_external_lsa_originate (ospf, ei);
+                          else if (IS_LSA_MAXAGE (current))
+                            ospf_external_lsa_refresh (ospf, current,
+                                                       ei, LSA_REFRESH_FORCE);
+                          else
+                            zlog_warn ("ospf_zebra_read_ipv4() : %s already exists",
+                                       inet_ntoa (p.prefix));
+                        }
+                    }
+                }
+            }
+          else                          /* if (command == ZEBRA_IPV4_ROUTE_DELETE) */
             {
+              ospf_external_info_delete (api.type, p);
               if (is_prefix_default (&p))
                 ospf_external_lsa_refresh_default (ospf);
               else
-                {
-                  struct ospf_lsa *current;
-
-                  current = ospf_external_info_find_lsa (ospf, &ei->p);
-                  if (!current)
-                    ospf_external_lsa_originate (ospf, ei);
-                  else if (IS_LSA_MAXAGE (current))
-                    ospf_external_lsa_refresh (ospf, current,
-                                               ei, LSA_REFRESH_FORCE);
-                  else
-                    zlog_warn ("ospf_zebra_read_ipv4() : %s already exists",
-                               inet_ntoa (p.prefix));
-                }
+                ospf_external_lsa_flush (ospf, api.type, &p, ifindex /*, nexthop */);
             }
         }
     }
-  else                          /* if (command == ZEBRA_IPV4_ROUTE_DELETE) */
-    {
-      ospf_external_info_delete (api.type, p);
-      if (is_prefix_default (&p))
-        ospf_external_lsa_refresh_default (ospf);
-      else
-        ospf_external_lsa_flush (ospf, api.type, &p, ifindex /*, nexthop */);
-    }
 
   return 0;
 }
diff -Naur quagga-0.99.10/redhat/ldpd.init quagga-mpls/redhat/ldpd.init
--- quagga-0.99.10/redhat/ldpd.init	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/redhat/ldpd.init	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,64 @@
+#!/bin/bash
+#
+# chkconfig: 2345 17 83
+# description: An LDP signaling engine for use with Zebra
+#
+# processname: ldpd
+# config: /etc/quagga/ldpd.conf
+
+# source function library
+. /etc/rc.d/init.d/functions
+
+# Get network config
+. /etc/sysconfig/network
+
+# quagga command line options
+. /etc/sysconfig/quagga
+
+# Check that networking is up.
+[ "${NETWORKING}" = "no" ] && exit 0
+
+# The process must be configured first.
+[ -f /etc/quagga/ldpd.conf ] || exit 0
+
+RETVAL=0
+
+prog="ldpd"
+
+case "$1" in
+  start)
+	echo -n $"Starting $prog: "
+        daemon /usr/sbin/ldpd -d $LDPD_OPTS
+	RETVAL=$?
+	[ $RETVAL -eq 0 ] && touch /var/lock/subsys/ldpd
+	echo
+	;;
+  stop)
+	echo -n $"Shutting down $prog: "
+	killproc ldpd
+	RETVAL=$?
+	[ $RETVAL -eq 0 ] && rm -f /var/lock/subsys/ldpd
+	echo
+	;;
+  restart|reload)
+        $0 stop
+        $0 start
+	RETVAL=$?
+        ;;
+  condrestart)
+        if [ -f /var/lock/subsys/ldpd ]; then
+                $0 stop
+		$0 start
+        fi
+	RETVAL=$?
+        ;;
+  status)
+        status ldpd
+	RETVAL=$?
+        ;;
+  *)
+	echo $"Usage: $0 {start|stop|restart|reload|condrestart|status}"
+	exit 1
+esac
+
+exit $RETVAL
diff -Naur quagga-0.99.10/redhat/Makefile.am quagga-mpls/redhat/Makefile.am
--- quagga-0.99.10/redhat/Makefile.am	2005-11-05 17:29:54.000000000 +0100
+++ quagga-mpls/redhat/Makefile.am	2008-11-25 12:30:18.000000000 +0100
@@ -1,4 +1,4 @@
 
 EXTRA_DIST = quagga.pam quagga.sysconfig quagga.spec quagga.logrotate \
 	zebra.init ripd.init ospfd.init ripngd.init ospf6d.init bgpd.init \
-	isisd.init watchquagga.init quagga.pam.stack
+	isisd.init ldpd.init watchquagga.init quagga.pam.stack
diff -Naur quagga-0.99.10/redhat/quagga.spec quagga-mpls/redhat/quagga.spec
--- quagga-0.99.10/redhat/quagga.spec	2008-06-10 22:57:39.000000000 +0200
+++ quagga-mpls/redhat/quagga.spec	1970-01-01 01:00:00.000000000 +0100
@@ -1,595 +0,0 @@
-# configure options
-#
-# Some can be overriden on rpmbuild commandline with:
-# rpmbuild --define 'variable value'
-#
-
-####################### Quagga configure options #########################
-# with-feature options
-%{!?with_snmp:		%define with_snmp	1 }
-%{!?with_vtysh:		%define	with_vtysh	1 }
-%{!?with_ospf_te:	%define	with_ospf_te	1 }
-%{!?with_nssa:		%define	with_nssa	1 }
-%{!?with_opaque_lsa:	%define	with_opaque_lsa 1 }
-%{!?with_tcp_zebra:	%define	with_tcp_zebra	0 }
-%{!?with_vtysh:		%define	with_vtysh	1 }
-%{!?with_pam:		%define	with_pam	1 }
-%{!?with_ipv6:		%define	with_ipv6	1 }
-%{!?with_ospfclient:	%define	with_ospfclient 1 }
-%{!?with_ospfapi:	%define	with_ospfapi	1 }
-%{!?with_irdp:		%define	with_irdp	1 }
-%{!?with_rtadv:		%define	with_rtadv	1 }
-%{!?with_isisd:		%define	with_isisd	1 }
-%{!?with_shared:	%define	with_shared	1 }
-%{!?with_multipath:	%define	with_multipath	64 }
-%{!?quagga_user:	%define	quagga_user	quagga }
-%{!?vty_group:		%define	vty_group	quaggavty }
-
-# path defines
-%define		_sysconfdir	/etc/quagga
-%define		zeb_src		%{_builddir}/%{name}-%{version}
-%define		zeb_rh_src	%{zeb_src}/redhat
-%define		zeb_docs	%{zeb_src}/doc
-
-# defines for configure
-%define		_libexecdir	%{_exec_prefix}/libexec/quagga
-%define		_libdir		%{_exec_prefix}/%{_lib}/quagga
-%define		_includedir	%{_prefix}/include
-%define		_localstatedir	/var/run/quagga
-############################################################################
-
-####################### distro specific tweaks #############################
-# default distro. Override with rpmbuild -D "dist XXX" 
-%{expand: %%define default_dist %(rpm -q --qf 'fc%%{VERSION}' fedora-release | grep -v 'not installed')}
-%{!?dist:		%define		dist	%{default_dist}}
-
-# as distros change packages we depend on, our Requires have to change, sadly.
-%define quagga_buildreqs texinfo tetex autoconf pam-devel
-%define quagga_buildreqs %{quagga_buildreqs} patch libcap-devel
-
-# FC4 and 5 split texi2html out of tetex package.
-%if "%dist" == "fc4" || "%dist" == "fc5"
-%define  quagga_buildreqs %{quagga_buildreqs} texi2html
-%endif
-
-# pam_stack is deprecated in FC5
-# default to pam_stack, default should be changed later.
-%if "%dist" == "fc5"
-%define	quagga_pam_source quagga.pam
-%else
-%define	quagga_pam_source quagga.pam.stack
-%endif
-############################################################################
-
-
-# misc internal defines
-%{!?quagga_uid:		%define         quagga_uid      92 }
-%{!?quagga_gid:		%define         quagga_gid      92 }
-%define		daemon_list	zebra ripd ospfd bgpd
-
-%if %{with_ipv6}
-%define		daemonv6_list	ripngd ospf6d
-%else
-%define		daemonv6_list	""
-%endif
-
-%if %{with_isisd}
-%define		daemon_other	isisd
-%else
-%define		daemon_other	""
-%endif
-
-%define		all_daemons	%{daemon_list} %{daemonv6_list} %{daemon_other} watchquagga
-
-# allow build dir to be kept
-%{!?keep_build:		%define		keep_build	0 }
-
-#release sub-revision (the two digits after the CONFDATE)
-%{!?release_rev:	%define		release_rev	01 }
-
-Summary: Routing daemon
-Name:		quagga
-Version:	0.99.10
-Release:	20080610%{release_rev}
-License:	GPL
-Group: System Environment/Daemons
-Source0:	http://www.quagga.net/snapshots/cvs/%{name}-%{version}.tar.gz
-URL:		http://www.quagga.net
-%if %{with_snmp}
-BuildRequires:	net-snmp-devel
-Prereq:		net-snmp
-%endif
-%if %{with_vtysh}
-BuildRequires:	readline readline-devel ncurses ncurses-devel
-Prereq:		ncurses
-%endif
-BuildRequires:	texinfo tetex autoconf pam-devel patch libcap-devel tetex
-# Initscripts > 5.60 is required for IPv6 support
-Prereq:		initscripts >= 5.60
-Prereq:		ncurses pam
-Prereq:		/sbin/install-info
-Provides:	routingdaemon
-BuildRoot:	%{_tmppath}/%{name}-%{version}-root
-Obsoletes:	bird gated mrt zebra
-
-%description
-Quagga is a free software that manages TCP/IP based routing
-protocol. It takes multi-server and multi-thread approach to resolve
-the current complexity of the Internet.
-
-Quagga supports BGP4, BGP4+, OSPFv2, OSPFv3, RIPv1, RIPv2, and RIPng.
-
-Quagga is intended to be used as a Route Server and a Route Reflector. It is
-not a toolkit, it provides full routing power under a new architecture.
-Quagga by design has a process for each protocol.
-
-Quagga is a fork of GNU Zebra.
-
-%package contrib
-Summary: contrib tools for quagga
-Group: System Environment/Daemons
-
-%description contrib
-Contributed/3rd party tools which may be of use with quagga.
-
-%package devel
-Summary: Header and object files for quagga development
-Group: System Environment/Daemons
-
-%description devel
-The quagga-devel package contains the header and object files neccessary for
-developing OSPF-API and quagga applications.
-
-%prep
-%setup  -q
-
-%build
-
-# For standard gcc verbosity, uncomment these lines:
-#CFLAGS="%{optflags} -Wall -Wsign-compare -Wpointer-arith"
-#CFLAGS="${CFLAGS} -Wbad-function-cast -Wwrite-strings"
-
-# For ultra gcc verbosity, uncomment these lines also:
-#CFLAGS="${CFLAGS} -W -Wcast-qual -Wstrict-prototypes"
-#CFLAGS="${CFLAGS} -Wmissing-declarations -Wmissing-noreturn"
-#CFLAGS="${CFLAGS} -Wmissing-format-attribute -Wunreachable-code"
-#CFLAGS="${CFLAGS} -Wpacked -Wpadded"
-
-%configure \
-%if !%{with_shared}
-	--disable-shared \
-%endif
-%if %{with_ipv6}
-	--enable-ipv6 \
-%endif
-%if %{with_snmp}
-	--enable-snmp \
-%endif
-%if %{with_multipath}
-	--enable-multipath=%{with_multipath} \
-%endif
-%if %{with_tcp_zebra}
-	--enable-tcp-zebra \
-%endif
-%if %{with_nssa}
-	--enable-nssa \
-%endif
-%if %{with_opaque_lsa}
-	--enable-opaque-lsa \
-%endif
-%if %{with_ospf_te}
-	--enable-ospf-te \
-%endif
-%if %{with_vtysh}
-	--enable-vtysh \
-%endif
-%if %{with_ospfclient}
-	--enable-ospfclient=yes \
-%else
-	--enable-ospfclient=no\
-%endif
-%if %{with_ospfapi}
-	--enable-ospfapi=yes \
-%else
-	--enable-ospfapi=no \
-%endif
-%if %{with_irdp}
-	--enable-irdp=yes \
-%else
-	--enable-irdp=no \
-%endif
-%if %{with_rtadv}
-	--enable-rtadv=yes \
-%else
-	--enable-rtadv=no \
-%endif
-%if %{with_isisd}
-	--enable-isisd \
-%else
-	--disable-isisd \
-%endif
-%if %{with_pam}
-	--with-libpam \
-%endif
-%if %quagga_user
-	--enable-user=%quagga_user \
-	--enable-group=%quagga_user \
-%endif
-%if %vty_group
-	--enable-vty-group=%vty_group \
-%endif
---enable-netlink --enable-gcc-rdynamic
-
-make %{?_smp_mflags} MAKEINFO="makeinfo --no-split"
-
-pushd doc
-texi2html -number quagga.texi
-popd
-
-%install
-rm -rf $RPM_BUILD_ROOT
-
-install -d $RPM_BUILD_ROOT/etc/{rc.d/init.d,sysconfig,logrotate.d,pam.d} \
-	$RPM_BUILD_ROOT/var/log/quagga $RPM_BUILD_ROOT%{_infodir}
-
-make install \
-	DESTDIR=$RPM_BUILD_ROOT
-
-# Remove this file, as it is uninstalled and causes errors when building on RH9
-rm -rf $RPM_BUILD_ROOT/usr/share/info/dir
-
-# install etc sources
-for daemon in %{all_daemons} ; do
-	if [ x"${daemon}" != x"" ] ; then
-		install %{zeb_rh_src}/${daemon}.init \
-			$RPM_BUILD_ROOT/etc/rc.d/init.d/${daemon}
-	fi
-done
-install -m644 %{zeb_rh_src}/%{quagga_pam_source} \
-	$RPM_BUILD_ROOT/etc/pam.d/quagga
-install -m644 %{zeb_rh_src}/quagga.logrotate \
-	$RPM_BUILD_ROOT/etc/logrotate.d/quagga
-install -m644 %{zeb_rh_src}/quagga.sysconfig \
-	$RPM_BUILD_ROOT/etc/sysconfig/quagga
-install -d -m750  $RPM_BUILD_ROOT/var/run/quagga
-
-%pre
-# add vty_group
-%if %vty_group
-if getent group %vty_group > /dev/null ; then : ; else \
- /usr/sbin/groupadd -r %vty_group > /dev/null || : ; fi
-%endif
-
-# add quagga user and group
-%if %quagga_user
-# Ensure that quagga_gid gets correctly allocated
-if getent group %quagga_user >/dev/null; then : ; else \
- /usr/sbin/groupadd -g %quagga_gid %quagga_user > /dev/null || : ; \
-fi
-if getent passwd %quagga_user >/dev/null ; then : ; else \
- /usr/sbin/useradd  -u %quagga_uid -g %quagga_gid \
-  -M -r -s /sbin/nologin -c "Quagga routing suite" \
-  -d %_localstatedir %quagga_user 2> /dev/null || : ; \
-fi
-%endif
-
-%post
-# zebra_spec_add_service <service name> <port/proto> <comment>
-# e.g. zebra_spec_add_service zebrasrv 2600/tcp "zebra service"
-
-zebra_spec_add_service ()
-{
-  # Add port /etc/services entry if it isn't already there 
-  if [ -f /etc/services ] && \
-      ! %__sed -e 's/#.*$//' /etc/services | %__grep -wq $1 ; then
-    echo "$1		$2			# $3"  >> /etc/services
-  fi
-}
-
-zebra_spec_add_service zebrasrv 2600/tcp "zebra service"
-zebra_spec_add_service zebra    2601/tcp "zebra vty"
-zebra_spec_add_service ripd     2602/tcp "RIPd vty"
-%if %{with_ipv6}
-zebra_spec_add_service ripngd   2603/tcp "RIPngd vty"
-%endif
-zebra_spec_add_service ospfd    2604/tcp "OSPFd vty"
-zebra_spec_add_service bgpd     2605/tcp "BGPd vty"
-%if %{with_ipv6}
-zebra_spec_add_service ospf6d   2606/tcp "OSPF6d vty"
-%endif
-%if %{with_ospfapi}
-zebra_spec_add_service ospfapi  2607/tcp "OSPF-API"
-%endif
-%if %{with_isisd}
-zebra_spec_add_service isisd    2608/tcp "ISISd vty"
-%endif
-
-for daemon in %daemon_list ; do
-	/sbin/chkconfig --add ${daemon}
-done
-
-/sbin/install-info %{_infodir}/quagga.info.gz %{_infodir}/dir
-
-# Create dummy files if they don't exist so basic functions can be used.
-if [ ! -e %{_sysconfdir}/zebra.conf ]; then
-	echo "hostname `hostname`" > %{_sysconfdir}/zebra.conf
-%if %{quagga_user}
-	chown %quagga_user:%quagga_user %{_sysconfdir}/zebra.conf
-%endif
-	chmod 640 %{_sysconfdir}/zebra.conf
-fi
-if [ ! -e %{_sysconfdir}/vtysh.conf ]; then
-	touch %{_sysconfdir}/vtysh.conf
-	chmod 640 %{_sysconfdir}/vtysh.conf
-fi
-
-%postun
-if [ "$1" -ge 1 ]; then
-	# Find out which daemons need to be restarted.
-	for daemon in %all_daemons ; do
-		if [ -f /var/lock/subsys/$daemon ]; then
-			eval restart_$daemon=yes
-		else
-			eval restart_$daemon=no
-		fi
-	done
-	# Rename restart flags for daemons handled specially.
-	running_zebra="$restart_zebra"
-	restart_zebra=no
-	running_watchquagga="$restart_watchquagga"
-	restart_watchquagga=no
-	# Stop watchquagga first.
-	[ "$running_watchquagga" = yes ] && \
-		/etc/rc.d/init.d/watchquagga stop >/dev/null 2>&1
-	# Stop all daemons other than zebra and watchquagga.
-	for daemon in %all_daemons ; do
-		eval restart=\$restart_${daemon}
-		[ "$restart" = yes ] && \
-			/etc/rc.d/init.d/$daemon stop >/dev/null 2>&1
-	done
-	# Restart zebra.
-	[ "$running_zebra" = yes ] && \
-		/etc/rc.d/init.d/zebra restart >/dev/null 2>&1
-	# Start all daemons other than zebra and watchquagga.
-	for daemon in %all_daemons ; do
-		eval restart=\$restart_${daemon}
-		[ "$restart" = yes ] && \
-			/etc/rc.d/init.d/$daemon start >/dev/null 2>&1
-	done
-	# Start watchquagga last.
-	# Avoid postun scriptlet error if watchquagga is not running. 
-	[ "$running_watchquagga" = yes ] && \
-		/etc/rc.d/init.d/watchquagga start >/dev/null 2>&1 || :
-fi
-/sbin/install-info --delete %{_infodir}/quagga.info.gz %{_infodir}/dir
-
-%preun
-if [ "$1" = "0" ]; then
-	for daemon in %all_daemons ; do
-		/etc/rc.d/init.d/${daemon} stop  >/dev/null 2>&1
-		/sbin/chkconfig --del ${daemon}
-	done
-	/sbin/install-info --delete %{_infodir}/quagga.info.gz %{_infodir}/dir
-fi
-
-%clean
-%if !%{keep_build}
-rm -rf $RPM_BUILD_ROOT
-%endif
-
-%files
-%defattr(-,root,root)
-%doc */*.sample* AUTHORS COPYING
-%doc doc/quagga.html
-%doc doc/mpls
-%doc ChangeLog INSTALL NEWS README REPORTING-BUGS SERVICES TODO
-%if %{quagga_user}
-%dir %attr(751,%quagga_user,%quagga_user) %{_sysconfdir}
-%dir %attr(750,%quagga_user,%quagga_user) /var/log/quagga 
-%dir %attr(751,%quagga_user,%quagga_user) /var/run/quagga
-%else
-%dir %attr(750,root,root) %{_sysconfdir}
-%dir %attr(750,root,root) /var/log/quagga
-%dir %attr(755,root,root) /usr/share/info
-%dir %attr(750,root,root) /var/run/quagga
-%endif
-%if %{vty_group}
-%attr(750,%quagga_user,%vty_group) %{_sysconfdir}/vtysh.conf.sample
-%endif
-%{_infodir}/*info*
-%{_mandir}/man*/*
-%{_sbindir}/zebra
-%{_sbindir}/ospfd
-%{_sbindir}/ripd
-%{_sbindir}/bgpd
-%{_sbindir}/watchquagga
-%if %{with_ipv6}
-%{_sbindir}/ripngd
-%{_sbindir}/ospf6d
-%endif
-%if %{with_isisd}
-%{_sbindir}/isisd
-%endif
-%dir %attr(755,root,root) %{_libdir}
-%if %{with_shared}
-%dir %{_libdir}
-%{_libdir}/lib*.so
-%{_libdir}/lib*.so.*
-%endif
-%if %{with_vtysh}
-%{_bindir}/*
-%endif
-%config /etc/quagga/[!v]*
-%config /etc/rc.d/init.d/*
-%config(noreplace) /etc/sysconfig/quagga
-%config(noreplace) /etc/pam.d/quagga
-%config(noreplace) %attr(640,root,root) /etc/logrotate.d/*
-
-%files contrib
-%defattr(-,root,root)
-%doc tools
-
-%files devel
-%defattr(-,root,root)
-%if %{with_ospfclient}
-%{_sbindir}/ospfclient
-%endif
-%{_libdir}/*.a
-%{_libdir}/*.la
-%dir %attr(755,root,root) %{_includedir}/%{name}
-%{_includedir}/%name/*.h
-%dir %attr(755,root,root) %{_includedir}/%{name}/ospfd
-%{_includedir}/%name/ospfd/*.h
-%if %{with_ospfapi}
-%dir %attr(755,root,root) %{_includedir}/%{name}/ospfapi
-%{_includedir}/%name/ospfapi/*.h
-%endif
-
-%changelog
-* Thu Sep 12 2005 Paul Jakma <paul@dishone.st>
-- Steal some changes from Fedora spec file:
-- Add with_rtadv variable
-- Test for groups/users with getent before group/user adding
-- Readline need not be an explicit prerequisite
-- install-info delete should be postun, not preun
-
-* Wed Jan 12 2005 Andrew J. Schorr <ajschorr@alumni.princeton.edu>
-- on package upgrade, implement careful, phased restart logic
-- use gcc -rdynamic flag when linking for better backtraces
-
-* Wed Dec 22 2004 Andrew J. Schorr <ajschorr@alumni.princeton.edu>
-- daemonv6_list should contain only IPv6 daemons
-
-* Wed Dec 22 2004 Andrew J. Schorr <ajschorr@alumni.princeton.edu>
-- watchquagga added
-- on upgrade, all daemons should be condrestart'ed
-- on removal, all daemons should be stopped
-
-* Mon Nov 08 2004 Paul Jakma <paul@dishone.st>
-- Use makeinfo --html to generate quagga.html
-
-* Sun Nov 07 2004 Paul Jakma <paul@dishone.st>
-- Fix with_ipv6 set to 0 build
-
-* Sat Oct 23 2004 Paul Jakma <paul@dishone.st>
-- Update to 0.97.2
-
-* Sat Oct 23 2004 Andrew J. Schorr <aschorr@telemetry-investments.com>
-- Make directories be owned by the packages concerned
-- Update logrotate scripts to use correct path to killall and use pid files
-
-* Fri Oct 08 2004 Paul Jakma <paul@dishone.st>
-- Update to 0.97.0
-
-* Wed Sep 15 2004 Paul Jakma <paul@dishone.st>
-- build snmp support by default
-- build irdp support
-- build with shared libs
-- devel subpackage for archives and headers
-
-* Thu Jan 08 2004 Paul Jakma <paul@dishone.st>
-- updated sysconfig files to specify local dir
-- added ospf_dump.c crash quick fix patch
-- added ospfd persistent interface configuration patch
-
-* Tue Dec 30 2003 Paul Jakma <paul@dishone.st>
-- sync to CVS
-- integrate RH sysconfig patch to specify daemon options (RH)
-- default to have vty listen only to 127.1 (RH)
-- add user with fixed UID/GID (RH)
-- create user with shell /sbin/nologin rather than /bin/false (RH)
-- stop daemons on uninstall (RH)
-- delete info file on %preun, not %postun to avoid deletion on upgrade. (RH)
-- isisd added
-- cleanup tasks carried out for every daemon
-
-* Sun Nov 2 2003 Paul Jakma <paul@dishone.st>
-- Fix -devel package to include all files
-- Sync to 0.96.4
-
-* Tue Aug 12 2003 Paul Jakma <paul@dishone.st>
-- Renamed to Quagga
-- Sync to Quagga release 0.96
-
-* Tue Mar 20 2003 Paul Jakma <paul@dishone.st>
-- zebra privileges support
-
-* Mon Mar 18 2003 Paul Jakma <paul@dishone.st>
-- Fix mem leak in 'show thread cpu'
-- Ralph Keller's OSPF-API
-- Amir: Fix configure.ac for net-snmp
-
-* Sat Mar 1 2003 Paul Jakma <paul@dishone.st>
-- ospfd IOS prefix to interface matching for 'network' statement
-- temporary fix for PtP and IPv6
-- sync to zebra.org CVS
-
-* Mon Jan 20 2003 Paul Jakma <paul@dishone.st>
-- update to latest cvs
-- Yon's "show thread cpu" patch - 17217
-- walk up tree - 17218
-- ospfd NSSA fixes - 16681
-- ospfd nsm fixes - 16824
-- ospfd OLSA fixes and new feature - 16823 
-- KAME and ifindex fixes - 16525
-- spec file changes to allow redhat files to be in tree
-
-* Sat Dec 28 2002 Alexander Hoogerhuis <alexh@ihatent.com>
-- Added conditionals for building with(out) IPv6, vtysh, RIP, BGP
-- Fixed up some build requirements (patch)
-- Added conditional build requirements for vtysh / snmp
-- Added conditional to %files for %_bindir depending on vtysh
-
-* Mon Nov 11 2002 Paul Jakma <paulj@alphyra.ie>
-- update to latest CVS
-- add Greg Troxel's md5 buffer copy/dup fix
-- add RIPv1 fix
-- add Frank's multicast flag fix
-
-* Wed Oct 09 2002 Paul Jakma <paulj@alphyra.ie>
-- update to latest CVS
-- timestamped crypt_seqnum patch
-- oi->on_write_q fix
-
-* Mon Sep 30 2002 Paul Jakma <paulj@alphyra.ie>
-- update to latest CVS
-- add vtysh 'write-config (integrated|daemon)' patch
-- always 'make rebuild' in vtysh/ to catch new commands
-
-* Fri Sep 13 2002 Paul Jakma <paulj@alphyra.ie>
-- update to 0.93b
-
-* Wed Sep 11 2002 Paul Jakma <paulj@alphyra.ie>
-- update to latest CVS
-- add "/sbin/ip route flush proto zebra" to zebra RH init on startup
-
-* Sat Aug 24 2002 Paul Jakma <paulj@alphyra.ie>
-- update to current CVS
-- add OSPF point to multipoint patch
-- add OSPF bugfixes
-- add BGP hash optimisation patch
-
-* Fri Jun 14 2002 Paul Jakma <paulj@alphyra.ie>
-- update to 0.93-pre1 / CVS
-- add link state detection support
-- add generic PtP and RFC3021 support
-- various bug fixes
-
-* Thu Aug 09 2001 Elliot Lee <sopwith@redhat.com> 0.91a-6
-- Fix bug #51336
-
-* Wed Aug  1 2001 Trond Eivind Glomsrd <teg@redhat.com> 0.91a-5
-- Use generic initscript strings instead of initscript specific
-  ( "Starting foo: " -> "Starting $prog:" )
-
-* Fri Jul 27 2001 Elliot Lee <sopwith@redhat.com> 0.91a-4
-- Bump the release when rebuilding into the dist.
-
-* Tue Feb  6 2001 Tim Powers <timp@redhat.com>
-- built for Powertools
-
-* Sun Feb  4 2001 Pekka Savola <pekkas@netcore.fi> 
-- Hacked up from PLD Linux 0.90-1, Mandrake 0.90-1mdk and one from zebra.org.
-- Update to 0.91a
-- Very heavy modifications to init.d/*, .spec, pam, i18n, logrotate, etc.
-- Should be quite Red Hat'isque now.
diff -Naur quagga-0.99.10/redhat/quagga.spec.in quagga-mpls/redhat/quagga.spec.in
--- quagga-0.99.10/redhat/quagga.spec.in	2006-06-16 00:31:39.000000000 +0200
+++ quagga-mpls/redhat/quagga.spec.in	2008-11-25 12:30:18.000000000 +0100
@@ -6,7 +6,7 @@
 
 ####################### Quagga configure options #########################
 # with-feature options
-%{!?with_snmp:		%define with_snmp	1 }
+%{!?with_snmp:		%define with_snmp	0 }
 %{!?with_vtysh:		%define	with_vtysh	1 }
 %{!?with_ospf_te:	%define	with_ospf_te	1 }
 %{!?with_nssa:		%define	with_nssa	1 }
@@ -15,6 +15,7 @@
 %{!?with_vtysh:		%define	with_vtysh	1 }
 %{!?with_pam:		%define	with_pam	1 }
 %{!?with_ipv6:		%define	with_ipv6	1 }
+%{!?with_mpls:		%define	with_mpls	1 }
 %{!?with_ospfclient:	%define	with_ospfclient 1 }
 %{!?with_ospfapi:	%define	with_ospfapi	1 }
 %{!?with_irdp:		%define	with_irdp	1 }
@@ -79,21 +80,27 @@
 %define		daemon_other	""
 %endif
 
-%define		all_daemons	%{daemon_list} %{daemonv6_list} %{daemon_other} watchquagga
+%if %{with_mpls}
+%define		daemon_mpls	ldpd rsvpd
+%else
+%define		daemon_mpls	""
+%endif
+
+%define		all_daemons	%{daemon_list} %{daemonv6_list} %{daemon_other} %{daemon_mpls} watchquagga
 
 # allow build dir to be kept
 %{!?keep_build:		%define		keep_build	0 }
 
-#release sub-revision (the two digits after the CONFDATE)
-%{!?release_rev:	%define		release_rev	01 }
+#release
+%{!?release_rev:	%define		release_rev	1 }
 
 Summary: Routing daemon
 Name:		quagga
 Version:	@VERSION@
-Release:	@CONFDATE@%{release_rev}
+Release:	%{release_rev}%{dist}.mpls.%{subver}
 License:	GPL
 Group: System Environment/Daemons
-Source0:	http://www.quagga.net/snapshots/cvs/%{name}-%{version}.tar.gz
+Source0:	http://www.quagga.net/download/%{name}-%{version}.tar.gz
 URL:		http://www.quagga.net
 %if %{with_snmp}
 BuildRequires:	net-snmp-devel
@@ -144,7 +151,6 @@
 %setup  -q
 
 %build
-
 # For standard gcc verbosity, uncomment these lines:
 #CFLAGS="%{optflags} -Wall -Wsign-compare -Wpointer-arith"
 #CFLAGS="${CFLAGS} -Wbad-function-cast -Wwrite-strings"
@@ -154,6 +160,7 @@
 #CFLAGS="${CFLAGS} -Wmissing-declarations -Wmissing-noreturn"
 #CFLAGS="${CFLAGS} -Wmissing-format-attribute -Wunreachable-code"
 #CFLAGS="${CFLAGS} -Wpacked -Wpadded"
+export CPPFLAGS="-I %{zeb_src}/include ${CPPFLAGS}"
 
 %configure \
 %if !%{with_shared}
@@ -162,6 +169,9 @@
 %if %{with_ipv6}
 	--enable-ipv6 \
 %endif
+%if %{with_mpls}
+	--enable-mpls=%{with_mpls} \
+%endif
 %if %{with_snmp}
 	--enable-snmp \
 %endif
@@ -303,6 +313,10 @@
 %if %{with_isisd}
 zebra_spec_add_service isisd    2608/tcp "ISISd vty"
 %endif
+%if %{with_mpls}
+zebra_spec_add_service ldpd    2610/tcp "LDPd vty"
+zebra_spec_add_service rsvpd   2611/tcp "RSVPd vty"
+%endif
 
 for daemon in %daemon_list ; do
 	/sbin/chkconfig --add ${daemon}
@@ -410,6 +424,10 @@
 %if %{with_isisd}
 %{_sbindir}/isisd
 %endif
+%if %{with_mpls}
+%{_sbindir}/ldpd
+%{_sbindir}/rsvpd
+%endif
 %dir %attr(755,root,root) %{_libdir}
 %if %{with_shared}
 %dir %{_libdir}
diff -Naur quagga-0.99.10/redhat/quagga.sysconfig quagga-mpls/redhat/quagga.sysconfig
--- quagga-0.99.10/redhat/quagga.sysconfig	2004-12-22 17:18:53.000000000 +0100
+++ quagga-mpls/redhat/quagga.sysconfig	2008-11-25 12:30:18.000000000 +0100
@@ -9,6 +9,8 @@
 RIPNGD_OPTS="-A ::1 -f ${QCONFDIR}/ripngd.conf"
 ZEBRA_OPTS="-A 127.0.0.1 -f ${QCONFDIR}/zebra.conf"
 ISISD_OPTS="-A ::1 -f ${QCONFDIR}/isisd.conf"
+LDPD_OPTS="-A 127.0.0.1 -f ${QCONFDIR}/ldpd.conf"
+RSVPD_OPTS="-A 127.0.0.1 -f ${QCONFDIR}/ldpd.conf"
 
 # Watchquagga configuration (please check timer values before using):
 WATCH_OPTS=""
diff -Naur quagga-0.99.10/redhat/rsvpd.init quagga-mpls/redhat/rsvpd.init
--- quagga-0.99.10/redhat/rsvpd.init	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/redhat/rsvpd.init	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,64 @@
+#!/bin/bash
+#
+# chkconfig: 2345 17 83
+# description: An RSVP signaling engine for use with Zebra
+#
+# processname: rsvpd
+# config: /etc/quagga/rsvpd.conf
+
+# source function library
+. /etc/rc.d/init.d/functions
+
+# Get network config
+. /etc/sysconfig/network
+
+# quagga command line options
+. /etc/sysconfig/quagga
+
+# Check that networking is up.
+[ "${NETWORKING}" = "no" ] && exit 0
+
+# The process must be configured first.
+[ -f /etc/quagga/rsvpd.conf ] || exit 0
+
+RETVAL=0
+
+prog="rsvpd"
+
+case "$1" in
+  start)
+	echo -n $"Starting $prog: "
+        daemon /usr/sbin/rsvpd -d $RSVPD_OPTS
+	RETVAL=$?
+	[ $RETVAL -eq 0 ] && touch /var/lock/subsys/rsvpd
+	echo
+	;;
+  stop)
+	echo -n $"Shutting down $prog: "
+	killproc rsvpd
+	RETVAL=$?
+	[ $RETVAL -eq 0 ] && rm -f /var/lock/subsys/rsvpd
+	echo
+	;;
+  restart|reload)
+        $0 stop
+        $0 start
+	RETVAL=$?
+        ;;
+  condrestart)
+        if [ -f /var/lock/subsys/rsvpd ]; then
+                $0 stop
+		$0 start
+        fi
+	RETVAL=$?
+        ;;
+  status)
+        status rsvpd
+	RETVAL=$?
+        ;;
+  *)
+	echo $"Usage: $0 {start|stop|restart|reload|condrestart|status}"
+	exit 1
+esac
+
+exit $RETVAL
diff -Naur quagga-0.99.10/ripd/rip_zebra.c quagga-mpls/ripd/rip_zebra.c
--- quagga-0.99.10/ripd/rip_zebra.c	2006-06-30 18:58:53.000000000 +0200
+++ quagga-mpls/ripd/rip_zebra.c	2008-11-25 12:30:18.000000000 +0100
@@ -48,8 +48,8 @@
       api.message = 0;
       SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
       api.nexthop_num = 1;
-      api.nexthop = &nexthop;
-      api.ifindex_num = 0;
+      api.nexthop[0].type = ZEBRA_NEXTHOP_IPV4;
+      api.nexthop[0].gw.ipv4.s_addr = nexthop->s_addr;
       SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
       api.metric = metric;
 
@@ -78,8 +78,8 @@
       api.message = 0;
       SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
       api.nexthop_num = 1;
-      api.nexthop = &nexthop;
-      api.ifindex_num = 0;
+      api.nexthop[0].type = ZEBRA_NEXTHOP_IPV4;
+      api.nexthop[0].gw.ipv4.s_addr = nexthop->s_addr;
       SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
       api.metric = metric;
 
@@ -98,48 +98,38 @@
   unsigned long ifindex;
   struct in_addr nexthop;
   struct prefix_ipv4 p;
+  int i;
   
   s = zclient->ibuf;
-  ifindex = 0;
-  nexthop.s_addr = 0;
 
-  /* Type, flags, message. */
-  api.type = stream_getc (s);
-  api.flags = stream_getc (s);
-  api.message = stream_getc (s);
-
-  /* IPv4 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv4));
-  p.family = AF_INET;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
+  zapi_ipv4_read(s, length, &api, &p);
+
+  if (!CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
+    api.distance = 255;
 
   /* Nexthop, ifindex, distance, metric. */
   if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
     {
-      api.nexthop_num = stream_getc (s);
-      nexthop.s_addr = stream_get_ipv4 (s);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_IFINDEX))
-    {
-      api.ifindex_num = stream_getc (s);
-      ifindex = stream_getl (s);
+      for (i = 0; i < api.nexthop_num; i++)
+        {
+          ifindex = 0;
+          nexthop.s_addr = 0;
+
+          if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IPV4))
+            nexthop.s_addr = api.nexthop[i].gw.ipv4.s_addr;
+
+          if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IFINDEX))
+            ifindex = api.nexthop[i].intf.index;
+
+          /* Then fetch IPv4 prefixes. */
+          if (command == ZEBRA_IPV4_ROUTE_ADD)
+            rip_redistribute_add (api.type, RIP_ROUTE_REDISTRIBUTE, &p,
+                                  ifindex, &nexthop, api.metric, api.distance);
+          else 
+            rip_redistribute_delete (api.type, RIP_ROUTE_REDISTRIBUTE,
+                                     &p, ifindex);
+        }
     }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (s);
-  else
-    api.distance = 255;
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (s);
-  else
-    api.metric = 0;
-
-  /* Then fetch IPv4 prefixes. */
-  if (command == ZEBRA_IPV4_ROUTE_ADD)
-    rip_redistribute_add (api.type, RIP_ROUTE_REDISTRIBUTE, &p, ifindex, 
-                          &nexthop, api.metric, api.distance);
-  else 
-    rip_redistribute_delete (api.type, RIP_ROUTE_REDISTRIBUTE, &p, ifindex);
 
   return 0;
 }
diff -Naur quagga-0.99.10/ripngd/ripng_zebra.c quagga-mpls/ripngd/ripng_zebra.c
--- quagga-0.99.10/ripngd/ripng_zebra.c	2005-10-01 19:38:08.000000000 +0200
+++ quagga-mpls/ripngd/ripng_zebra.c	2008-11-25 12:30:18.000000000 +0100
@@ -52,13 +52,11 @@
     {
       api.type = ZEBRA_ROUTE_RIPNG;
       api.flags = 0;
-      api.message = 0;
-      SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
+      api.message = ZAPI_MESSAGE_NEXTHOP;
       api.nexthop_num = 1;
-      api.nexthop = &nexthop;
-      SET_FLAG (api.message, ZAPI_MESSAGE_IFINDEX);
-      api.ifindex_num = 1;
-      api.ifindex = &ifindex;
+      api.nexthop[0].type = ZEBRA_NEXTHOP_IPV6|ZEBRA_NEXTHOP_IFINDEX;
+      memcpy (&api.nexthop[0].gw.ipv6, nexthop, sizeof (*nexthop));
+      api.nexthop[0].intf.index = ifindex;
       SET_FLAG (api.message, ZAPI_MESSAGE_METRIC);
       api.metric = metric;
       
@@ -76,14 +74,12 @@
     {
       api.type = ZEBRA_ROUTE_RIPNG;
       api.flags = 0;
-      api.message = 0;
-      SET_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP);
+      api.message = ZAPI_MESSAGE_NEXTHOP;
       api.nexthop_num = 1;
-      api.nexthop = &nexthop;
-      SET_FLAG (api.message, ZAPI_MESSAGE_IFINDEX);
-      api.ifindex_num = 1;
-      api.ifindex = &ifindex;
-
+      api.nexthop[0].type = ZEBRA_NEXTHOP_IPV6|ZEBRA_NEXTHOP_IFINDEX;
+      memcpy (&api.nexthop[0].gw.ipv6, nexthop, sizeof (*nexthop));
+      api.nexthop[0].intf.index = ifindex;
+      
       zapi_ipv6_route (ZEBRA_IPV6_ROUTE_DELETE, zclient, p, &api);
     }
 }
@@ -98,46 +94,35 @@
   unsigned long ifindex;
   struct in6_addr nexthop;
   struct prefix_ipv6 p;
+  int i;
 
   s = zclient->ibuf;
-  ifindex = 0;
-  memset (&nexthop, 0, sizeof (struct in6_addr));
 
-  /* Type, flags, message. */
-  api.type = stream_getc (s);
-  api.flags = stream_getc (s);
-  api.message = stream_getc (s);
-
-  /* IPv6 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv6));
-  p.family = AF_INET6;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
+  zapi_ipv6_read (s, length, &api, &p);
 
   /* Nexthop, ifindex, distance, metric. */
   if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
     {
-      api.nexthop_num = stream_getc (s);
-      stream_get (&nexthop, s, 16);
-    }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_IFINDEX))
-    {
-      api.ifindex_num = stream_getc (s);
-      ifindex = stream_getl (s);
+      for (i = 0; i < api.nexthop_num; i++)
+        {
+          ifindex = 0;
+          memset (&nexthop, 0, sizeof (struct in6_addr));
+
+          if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IPV4))
+            memcpy(&nexthop, &api.nexthop[i].gw.ipv6, sizeof (nexthop));
+
+          if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IFINDEX))
+            ifindex = api.nexthop[i].intf.index;
+
+          if (command == ZEBRA_IPV6_ROUTE_ADD)
+            ripng_redistribute_add (api.type, RIPNG_ROUTE_REDISTRIBUTE,
+                                    &p, ifindex, &nexthop);
+          else
+            ripng_redistribute_delete (api.type, RIPNG_ROUTE_REDISTRIBUTE,
+                                       &p, ifindex);
+
+        }
     }
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (s);
-  else
-    api.distance = 0;
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (s);
-  else
-    api.metric = 0;
-
-  if (command == ZEBRA_IPV6_ROUTE_ADD)
-    ripng_redistribute_add (api.type, RIPNG_ROUTE_REDISTRIBUTE, &p, ifindex, &nexthop);
-  else
-    ripng_redistribute_delete (api.type, RIPNG_ROUTE_REDISTRIBUTE, &p, ifindex);
 
   return 0;
 }
diff -Naur quagga-0.99.10/rsvpd/general.h quagga-mpls/rsvpd/general.h
--- quagga-0.99.10/rsvpd/general.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/general.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,41 @@
+
+#ifndef __GENERAL_H__
+#define __GENERAL_H__
+
+typedef unsigned long HANDLE;
+
+typedef unsigned char BOOL;
+
+typedef unsigned char uns8;
+typedef unsigned short uns16;
+typedef unsigned int uns32;
+
+#define FALSE 0
+#define TRUE  1
+
+typedef unsigned int IPV4_ADDR;
+typedef struct
+{
+  IPV4_ADDR IpAddr;
+  uns8 PrefixLength;
+  uns8 Loose;
+} ER_HOP;
+
+typedef enum
+{
+  E_OK,
+  E_ERR
+} E_RC;
+
+
+#define LOCAL_ADDRESS       "127.0.0.1"
+#define RSVP_CONSOLE_PORT   2002
+#define RSVP_TE_PORT        2003
+#define TE_SIM_PORT         2004
+#define TE_APP_PORT         2004
+#define TE_APP_PORT2        2012
+#define TE_APP_PORT3        2013
+#define TE_APP_CONSOLE_PORT 2011
+#define HAS_TE_SIM 1
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/Makefile.am quagga-mpls/rsvpd/Makefile.am
--- quagga-0.99.10/rsvpd/Makefile.am	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/Makefile.am	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,34 @@
+## Process this file with automake to produce Makefile.in.
+
+INCLUDES = @INCLUDES@ -I.. -I$(top_srcdir) -I$(top_srcdir)/lib @SNMP_INCLUDES@
+DEFS = @DEFS@ $(LOCAL_OPTS) -DSYSCONFDIR=\"$(sysconfdir)/\"
+INSTALL_SDATA=@INSTALL@ -m 600
+
+sbin_PROGRAMS = rsvpd
+
+rsvpd_SOURCES = rsvp_main.c \
+	rsvp_decode.c  rsvp_path.c    rsvp_utilities.c \
+	rsvp_encode.c  rsvp_resv.c    rsvp_vty.c \
+	rsvp_socket.c  rsvp_zebra.c   rsvp_api.c \
+	te_api.c te_bw_man.c te_common.c \
+	te_lib.c te_crr.c    te_lsp.c \
+	te_rdb.c te_tr.c \
+	patricia.c messages.c
+
+rsvpdheaderdir = $(pkgincludedir)/rsvpd
+
+noinst_HEADERS =
+	rsvp_encode.h    rsvp_socket.h  rsvp.h  te_lib.h \
+	rsvp_api.h       rsvp_packet.h  rsvp_utilities.h \
+	rsvp_psb.h       rsvp_vty.h     rsvp_decode.h    rsvp_rsb.h \
+	rsvp_zebra.h \
+	general.h        messages.h     patricia.h \
+	te_api.h te_bw_man.h te_common.h te_crr.h te_cspf.h \
+	te_frr.h te.h        te_lsp.h    te_rdb.h te_tr.h
+
+rsvpd_LDADD = ../lib/libzebra.la @LIBCAP@
+
+EXTRA_DIST =
+
+examplesdir = $(exampledir)
+dist_examples_DATA =
diff -Naur quagga-0.99.10/rsvpd/messages.c quagga-mpls/rsvpd/messages.c
--- quagga-0.99.10/rsvpd/messages.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/messages.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,353 @@
+#include <zebra.h>
+#include <stdlib.h>
+
+#include "general.h"
+#include "thread.h"
+#include "workqueue.h"
+#include "memory.h"
+#include "log.h"
+
+#include "rsvp.h"
+#include "te.h"
+
+struct mesg_block
+{
+  void *data;
+  int size;
+};
+
+extern struct thread_master *master;
+
+static struct work_queue *rsvp2te = NULL;
+static struct work_queue *te2rsvp = NULL;
+static struct work_queue *te2te = NULL;
+
+static int
+RSVP_ProcessTeMsg (void *data, int Length)
+{
+  TE_API_MSG Msg, *pMsg = data;
+  int ret = 0;
+
+  switch (pMsg->NotificationType)
+    {
+    case PATH_MSG_NOTIFICATION:
+      ret = ProcessTEMsgUponPath (pMsg);
+      break;
+    case RESV_MSG_NOTIFICATION:
+      ret = ResvTeMsgProc (pMsg);
+      break;
+    case PATH_SEND_CMD:
+      RsvpPathSendCmd (pMsg);
+      break;
+    case PATH_TEAR_CMD:
+      RsvpPathTearCmd (pMsg);
+      break;
+    case PREEMPT_FLOW_CMD:
+      PreemptFlow (pMsg);
+      break;
+    case DEBUG_SEND_RESV_TEAR_CMD:
+      ret = DebugSendResvTear (pMsg);
+      break;
+    default:
+      printf ("TE-->RSVP: unknown message type %d %s %d\n",
+	      pMsg->NotificationType, __FILE__, __LINE__);
+    }
+  return ret;
+}
+
+static int
+TE_ProcessTeMsg (void *data, int Len)
+{
+  void *pBuf = data;
+  EVENTS_E *pEvent = data;
+  TE_MSG *pMsg;
+
+  switch (*pEvent)
+    {
+    case EVENT_TE_SM:
+      pMsg = pBuf;
+      sm_call (pMsg->u.te_sm_event.data);
+      break;
+    case EVENT_CREATE_TE_PATH:
+      TE_IGP_API_PathAdd (pBuf, Len);
+      break;
+    case EVENT_READ_PATH_CASH:
+      TE_IGP_API_ReadPathCash (pBuf, Len);
+      break;
+#if FRR_SM_DEFINED
+    case EVENT_RRO_CHANGED:
+      RRO_ChangedMsg (&dmsg->u.rro_changed_hook);
+      break;
+    case EVENT_BYPASS_TUNNEL_RETRY_EXPIRY:
+      BypassTunnelRetryExpiry (dmsg);
+      break;
+    case EVENT_FRR_INFO_SET:
+      SetFrrData (dmsg);
+      break;
+#endif
+    default:
+      zlog_err ("\nBUG: Default case %s %d", __FILE__, __LINE__);
+    }
+}
+
+static int
+TE_ProcessRsvpMsg (void *data, int Len)
+{
+  TE_API_MSG *pTeApiMsg = data;
+  char *buffer = data;
+
+  switch (pTeApiMsg->NotificationType)
+    {
+    case PATH_MSG_NOTIFICATION:
+      TE_RSVPTE_API_TransitReqAPI (pTeApiMsg);
+      break;
+    case RESV_MSG_NOTIFICATION:
+      if (pTeApiMsg->u.ResvNotification.Ingress)
+	{
+	  PSB_KEY key;
+	  float MaximumPossibleBW = 0;
+	  memset (&key, 0, sizeof (PSB_KEY));
+	  key.Session = pTeApiMsg->u.ResvNotification.RsbKey.Session;
+	  if (pTeApiMsg->u.ResvNotification.SharedExplicit)
+	    {
+	      if (TE_RSVPTE_API_DoAllocation (&key,
+					      pTeApiMsg->u.ResvNotification.u.
+					      FilterDataSE.
+					      IfIndex /* temporary */ ,
+					      pTeApiMsg->u.ResvNotification.u.
+					      FilterDataSE.IfIndex,
+					      pTeApiMsg->u.ResvNotification.u.
+					      FilterDataSE.BW,
+					      pTeApiMsg->u.ResvNotification.u.
+					      FilterDataSE.SetupPrio,
+					      pTeApiMsg->u.ResvNotification.u.
+					      FilterDataSE.HoldPrio,
+					      &MaximumPossibleBW) != E_OK)
+		{
+		  zlog_info ("\nBW allocation failed %s %d", __FILE__,
+			     __LINE__);
+		  pTeApiMsg->u.ResvNotification.u.FilterDataSE.BW =
+		    MaximumPossibleBW;
+		  pTeApiMsg->u.ResvNotification.rc = FALSE;
+		}
+	      else
+		{
+		  pTeApiMsg->u.ResvNotification.rc = TRUE;
+		  TE_RSVPTE_API_RsvpTunnelEstablished (&pTeApiMsg->u.
+						       ResvNotification);
+		}
+	    }
+	  else
+	    {
+	      key.SenderTemplate =
+		pTeApiMsg->u.ResvNotification.u.FilterDataFF.FilterSpec;
+	      if (TE_RSVPTE_API_DoAllocation
+		  (&key,
+		   pTeApiMsg->u.ResvNotification.u.FilterDataFF.
+		   IfIndex /* temporary */ ,
+		   pTeApiMsg->u.ResvNotification.u.FilterDataFF.IfIndex,
+		   pTeApiMsg->u.ResvNotification.u.FilterDataFF.BW,
+		   pTeApiMsg->u.ResvNotification.u.FilterDataFF.SetupPrio,
+		   pTeApiMsg->u.ResvNotification.u.FilterDataFF.HoldPrio,
+		   &MaximumPossibleBW) != E_OK)
+		{
+		  zlog_info ("\nBW allocation failed %s %d", __FILE__,
+			     __LINE__);
+		  pTeApiMsg->u.ResvNotification.u.FilterDataFF.BW =
+		    MaximumPossibleBW;
+		  pTeApiMsg->u.ResvNotification.rc = FALSE;
+		}
+	      else
+		{
+		  pTeApiMsg->u.ResvNotification.rc = TRUE;
+		  TE_RSVPTE_API_RsvpTunnelEstablished (&pTeApiMsg->u.
+						       ResvNotification);
+		}
+
+	    }
+	  if (pTeApiMsg->u.ResvNotification.PleaseReply)
+	    {
+	      te_send_msg (pTeApiMsg, sizeof (TE_API_MSG));
+	    }
+	}
+      else
+	TE_RSVPTE_API_TransitResv (pTeApiMsg);
+      break;
+    case BW_RELEASE_NOTIFICATION:
+      TE_RSVPTE_API_BwReleaseMessage (pTeApiMsg);
+      break;
+    case LABEL_RELEASE_NOTIFICATION:
+      TE_RSVPTE_API_LabelRelease (pTeApiMsg);
+      break;
+    case RESV_TEAR_NOTIFICATION:
+      TE_RSVPTE_API_RsvpResvTear (&pTeApiMsg->u.ResvTearNotification);
+      break;
+    case PATH_ERR_NOTIFICATION:
+      TE_RSVPTE_API_RsvpPathErr (&pTeApiMsg->u.PathErrNotification);
+      break;
+    default:
+      zlog_err ("\ndefault case (%d) reached %s %d",
+		pTeApiMsg->NotificationType, __FILE__, __LINE__);
+      {
+	int i;
+	for (i = 0; i < 40; i++)
+	  {
+	    if (!(i % 8))
+	      {
+		zlog_info ("\n");
+	      }
+	    zlog_info ("%x  ", buffer[i]);
+	  }
+      }
+    }
+  return 0;
+}
+
+void
+SetFrrData (TE_MSG * pMsg)
+{
+#if 0
+  PSB_KEY psb_key;
+  PSB *pUpPsb;
+
+  memset (&psb_key, '\0', sizeof (psb_key));
+  psb_key.Session.Dest = htonl (pMsg->u.frr_data_set.PsbKey.Session.Dest);
+  psb_key.Session.TunnelId = pMsg->u.frr_data_set.PsbKey.Session.TunnelId;
+  psb_key.Session.ExtTunelId = pMsg->u.frr_data_set.PsbKey.Session.ExtTunelId;
+  psb_key.SenderTemplate.LspId =
+    pMsg->u.frr_data_set.PsbKey.SenderTemplate.LspId;
+  psb_key.SenderTemplate.IpAddr =
+    pMsg->u.frr_data_set.PsbKey.SenderTemplate.IpAddr;
+
+  if ((pUpPsb =
+       (RSVP_UP_PSB *) patricia_tree_getnext (&intf->info.lms.UpPsbToIntfTree,
+					      (const uns8 *) &psb_key)) !=
+      NULL)
+    {
+      zlog_info ("\nsetting FRR data %x %x %x for %x %x %x %x %x on IF#%x",
+		 pMsg->u.frr_data_set.BackupOutIf,
+		 pMsg->u.frr_data_set.BackupVcardId,
+		 pMsg->u.frr_data_set.MergeNodeIp,
+		 psb_key.Session.Dest,
+		 psb_key.Session.TunnelId,
+		 psb_key.Session.ExtTunelId,
+		 psb_key.SenderTemplate.LspId,
+		 psb_key.SenderTemplate.IpAddr, pMsg->u.frr_data_set.IfIndex);
+      /* set here the FRR data */
+    }
+  else
+    {
+      zlog_info ("\ncannot find PSB by key %x %x %x %x %x %s %d",
+		 psb_key.Session.Dest,
+		 psb_key.Session.TunnelId,
+		 psb_key.Session.ExtTunelId,
+		 psb_key.SenderTemplate.LspId,
+		 psb_key.SenderTemplate.IpAddr, __FILE__, __LINE__);
+    }
+#endif
+}
+
+static wq_item_status
+rsvp_te_process (struct work_queue *wq, void *data)
+{
+  struct mesg_block *blk = data;
+  TE_ProcessRsvpMsg(blk->data, blk->size);
+  XFREE (MTYPE_TMP, data);
+  return WQ_SUCCESS;
+}
+
+static wq_item_status
+te_rsvp_process (struct work_queue *wq, void *data)
+{
+  struct mesg_block *blk = data;
+  RSVP_ProcessTeMsg(blk->data, blk->size);
+  XFREE (MTYPE_TMP, data);
+  return WQ_SUCCESS;
+}
+
+static wq_item_status
+te_te_process (struct work_queue *wq, void *data)
+{
+  struct mesg_block *blk = data;
+  TE_ProcessTeMsg(blk->data, blk->size);
+  XFREE (MTYPE_TMP, data);
+  return WQ_SUCCESS;
+}
+
+void
+rsvp_te_comm_init()
+{
+  if (! (rsvp2te = work_queue_new (master, "rsvp->te mesg passing")))
+    {
+      zlog_err ("%s: could not initialise work queue!", __func__);
+      return;
+    }
+
+  if (! (te2rsvp = work_queue_new (master, "te->rsvp mesg passing")))
+    {
+      zlog_err ("%s: could not initialise work queue!", __func__);
+      return;
+    }
+
+  if (! (te2te = work_queue_new (master, "te->te mesg passing")))
+    {
+      zlog_err ("%s: could not initialise work queue!", __func__);
+      return;
+    }
+
+  rsvp2te->spec.workfunc = &rsvp_te_process;
+  rsvp2te->spec.errorfunc = NULL;
+  rsvp2te->spec.max_retries = 3;
+  rsvp2te->spec.hold = 1;
+
+  te2rsvp->spec.workfunc = &te_rsvp_process;
+  te2rsvp->spec.errorfunc = NULL;
+  te2rsvp->spec.max_retries = 3;
+  te2rsvp->spec.hold = 1;
+
+  te2te->spec.workfunc = &te_te_process;
+  te2te->spec.errorfunc = NULL;
+  te2te->spec.max_retries = 3;
+  te2te->spec.hold = 1;
+
+  return;
+}
+
+E_RC
+rsvp_send_msg (void *pMsg, int size)
+{
+  struct mesg_block *blk = NULL;
+  blk = XMALLOC (MTYPE_TMP, sizeof(struct mesg_block) + size);
+  blk->data = &blk[1];
+  blk->size = size;
+  memcpy(blk->data, pMsg, size);
+
+  work_queue_add (rsvp2te, blk);
+  return E_OK;
+}
+
+E_RC
+te_send_msg (void *pMsg, int size)
+{
+  struct mesg_block *blk = NULL;
+  blk = XMALLOC (MTYPE_TMP, sizeof(struct mesg_block) + size);
+  blk->data = &blk[1];
+  blk->size = size;
+  memcpy(blk->data, pMsg, size);
+
+  work_queue_add (te2rsvp, blk);
+  return E_OK;
+}
+
+E_RC
+te2te_send_msg (void *pMsg, int size)
+{
+  struct mesg_block *blk = NULL;
+  blk = XMALLOC (MTYPE_TMP, sizeof(struct mesg_block) + size);
+  blk->data = &blk[1];
+  blk->size = size;
+  memcpy(blk->data, pMsg, size);
+
+  work_queue_add (te2te, blk);
+  return E_OK;
+}
diff -Naur quagga-0.99.10/rsvpd/messages.h quagga-mpls/rsvpd/messages.h
--- quagga-0.99.10/rsvpd/messages.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/messages.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,712 @@
+#ifndef _RSVP_API_STRUCT_H_
+#define _RSVP_API_STRUCT_H_
+
+#include "rsvp_packet.h"
+
+typedef struct
+{
+  SESSION_OBJ Session;
+  SENDER_TEMPLATE_OBJ SenderTemplate;
+} PSB_KEY;
+
+typedef struct
+{
+  SESSION_OBJ Session;
+} RSB_KEY;
+
+#define TE_PATH_RESPONSE 1
+#define TE_RESV_RESPONSE 2
+
+typedef enum
+{
+  PATH_MSG_NOTIFICATION,
+  RESV_MSG_NOTIFICATION,
+  PATH_ERR_NOTIFICATION,
+  RESV_TEAR_NOTIFICATION,
+  RRO_CHANGED_NOTIFICATION,
+  LABEL_RELEASE_NOTIFICATION,
+  BW_RELEASE_NOTIFICATION,
+  PREEMPT_FLOW_CMD,
+  ENABLE_RSVP_ON_IF,
+  DISABLE_RSVP_ON_IF,
+  SET_PEER,
+  IP_ADDR_ADD,
+  IP_ADDR_DEL,
+  PATH_SEND_CMD,
+  PATH_TEAR_CMD,
+  DEBUG_SEND_RESV_TEAR_CMD
+} TE_NOTIFICATION_E;
+
+typedef enum
+{
+  PATH_PROC_OK,
+  BW_UNAVAIL,
+  NO_ROUTE,
+  LABEL_ALLOC_FAILURE,
+  UNSUP_L3PID
+} PATH_PROC_E;
+
+
+typedef struct
+{
+  PSB_KEY PsbKey;
+  /* resource affinity info valid, if set to 1 */
+  uns8 RA_Valid;
+  uns32 ExcludeAny;
+  uns32 IncludeAll;
+  uns32 IncludeAny;
+  /* set to default if received PATH does not contain SESSION_ATTRIBUTES */
+  uns8 HoldPrio;
+  /* set to default if received PATH does not contain SESSION_ATTRIBUTES */
+  uns8 SetupPrio;
+  /* RSVP-TE -> TE-APP: received ER HOPS, TE-APP -> RSVP-TE - inserted ER HOPS */
+  /*(if first - loose, before first, otherwise - after the last */
+  uns16 ErHopNumber;
+  /* if set to 1 - first ER HOP is strict */
+  uns8 FirstErHopStrict;
+  IPV4_ADDR ErHops[100];
+  /* if set to 1, local protection desired */
+  uns8 LocalProtection;
+  /* shared explicit style, if set to 1 */
+  uns8 SharedExplicit;
+  /* allocated label */
+  uns32 Label;
+  /* requested BW */
+  float BW;
+  /* TE output - OutIfIndex and Next Hop */
+  uns32 OutIfIndex;
+  IPV4_ADDR NextHop;
+  uns8 LabelRecordingDesired;
+  PATH_PROC_E rc;
+} PATH_NOTIFICATION;
+
+typedef struct
+{
+  FILTER_SPEC_OBJ FilterSpec;
+
+  uns32 IfIndex;		/* where BW should be allocated. */
+  /* extracted from PSB */
+  uns8 HoldPrio;
+  /* extracted from PSB */
+  uns8 SetupPrio;
+  /* received label */
+  uns32 ReceivedLabel;
+  /* allocated label */
+  uns32 AllocatedLabel;
+  /* requested BW */
+  float BW;			/* could be different for each FILTER_SPEC if FF, same for each FILTER_SPEC if SE */
+} FILTER_DATA_FF;
+
+typedef struct
+{
+  FILTER_SPEC_OBJ FilterSpec;
+  /* received label */
+  uns32 ReceivedLabel;
+  /* allocated label */
+  uns32 AllocatedLabel;
+} FILTER_DATA_ARRAY_SE;
+
+typedef struct
+{
+  /* requested BW */
+  float BW;			/* could be different for each FILTER_SPEC if FF, same for each FILTER_SPEC if SE */
+  /* extracted from PSB */
+  uns8 HoldPrio;
+  /* extracted from PSB */
+  uns8 SetupPrio;
+  /* Where to allocate */
+  uns32 IfIndex;
+  uns16 FilterSpecNumber;
+  FILTER_DATA_ARRAY_SE FilterDataArraySE[100];
+} FILTER_DATA_SE;
+
+typedef struct
+{
+  RSB_KEY RsbKey;
+  /* If set, Ingress is reached */
+  uns8 Ingress;
+  uns8 PleaseReply;
+  uns8 rc;			/* FALSE or TRUE */
+  /* if set to 1, shared explicit reservation style */
+  uns8 SharedExplicit;
+
+  union
+  {
+    FILTER_DATA_SE FilterDataSE;
+    FILTER_DATA_FF FilterDataFF;
+  } u;
+} RESV_NOTIFICATION;
+
+
+typedef struct
+{
+  RSB_KEY RsbKey;
+  uns16 FilterSpecNumber;
+  FILTER_SPEC_OBJ FilterSpecs[100];
+} DEBUG_SEND_RESV_TEAR;
+
+typedef struct
+{
+  PSB_KEY PsbKey;
+  uns32 Label;
+} LABEL_RELEASE;
+
+typedef struct
+{
+  PSB_KEY PsbKey;
+  uns32 IfIndex;
+  uns8 HoldPrio;
+} BW_RELEASE;
+
+typedef struct
+{
+  RSB_KEY RsbKey;
+  FILTER_SPEC_OBJ FilterSpec;
+} RESV_TEAR_NOTIF;
+
+typedef struct
+{
+  PSB_KEY PsbKey;
+  ERR_SPEC_OBJ ErrSpec;
+} PATH_ERR_NOTIF;
+
+typedef struct
+{
+  RSB_KEY RsbKey;
+  uns8 FilterSpecValid;
+  FILTER_SPEC_OBJ FilterSpec;
+} PREEMPT_FLOW;
+
+typedef struct
+{
+  uns32 IfIndex;
+} IF_CMD;
+
+typedef struct
+{
+  char IfName[20];
+  IPV4_ADDR PeerAddr;
+} SET_PEER_CMD;
+
+typedef struct
+{
+  IPV4_ADDR IpAddress;
+  uns8 PrefixLen;
+  uns32 IfIndex;
+} IP_ADDR_ADD_DEL_CMD;
+
+typedef struct
+{
+  IPV4_ADDR Egress;
+  uns16 TunnelId;
+  uns16 LspId;
+  uns8 RaValid;
+  uns32 ExcludeAny;
+  uns32 IncludeAny;
+  uns32 IncludeAll;
+  uns8 HoldPrio;
+  uns8 SetPrio;
+  uns8 Shared;
+  uns8 FrrDesired;
+  uns8 LabelRecordingDesired;
+  uns16 HopNum;
+  ER_HOP Path[100];
+  float BW;
+  IPV4_ADDR NextHop;
+  uns32 OutIfIndex;
+  IPV4_ADDR src_ip;
+  uns32 sm_handle;
+  IPV4_ADDR ErHops2Exclude[10];
+} INGRESS_API;
+
+typedef struct _te_api_msg_
+{
+  TE_NOTIFICATION_E NotificationType;
+  union
+  {
+    PATH_NOTIFICATION PathNotification;
+    RESV_NOTIFICATION ResvNotification;
+    LABEL_RELEASE LabelRelease;
+    BW_RELEASE BwRelease;
+    RESV_TEAR_NOTIF ResvTearNotification;
+    PATH_ERR_NOTIF PathErrNotification;
+    PREEMPT_FLOW PreemptFlow;
+    IF_CMD IfCmd;
+    SET_PEER_CMD SetPeer;
+    IP_ADDR_ADD_DEL_CMD IpAddrAddDel;
+    INGRESS_API IngressApi;
+    DEBUG_SEND_RESV_TEAR DebugSendResvTear;
+  } u;
+} TE_API_MSG;
+
+#endif
+#ifndef __LIB_API_MSG_H_
+#define __LIB_API_MSG_H_
+
+void rsvp_te_comm_init ();
+E_RC rsvp_send_msg (void *pBuf, int pSize);
+E_RC te_send_msg (void *pBuf, int pSize);
+
+#endif
+
+#ifndef __TE_API_STRUCT_H__
+#define __TE_API_STRUCT_H__
+
+#include "thread.h"
+
+#define LSP_NAME_TYPE                 1
+#define LSP_DEST_TYPE                 2
+#define LSP_SRC_TYPE                  3
+#define LSP_REMOVE_TYPE               4
+#define ADAPTIVITY_TYPE               5
+#define BW_TYPE                       6
+#define COS_TYPE                      7
+#define HOP_LIMIT_TYPE                8
+#define OPTIMIZE_TIMER_TYPE           9
+#define PREFERENCE_TYPE               10
+#define PRIO_TYPE                     11
+#define RECORD_TYPE                   12
+#define STANDBY_TYPE                  13
+#define FRR_TYPE                      14
+#define METRIC_TYPE                   15
+#define NO_DECREMENT_TTL_TYPE         16
+#define BW_POLICY_TYPE                17
+#define RETRY_TIMER_TYPE              18
+#define RETRY_LIMIT_TYPE              19
+#define PRIMARY_PATH_NAME_TYPE        20
+#define SECONDARY_PATH_NAME_TYPE      21
+#define EXPLICIT_PATH_NAME            22
+#define NH_INDEX                      23
+#define NH_LOOSE                      24
+#define NH_IP_ADDRESS                 25
+#define NO_FORM                       26
+#define AFFINITY_TYPE                 27
+
+typedef struct
+{
+  int Type;
+  int Length;
+} TL_HEADER;
+
+typedef struct
+{
+  TL_HEADER tl_header;
+  char data[1];
+} TLV;
+
+typedef enum
+{
+  EVENT_NEXT_HOP_ADD,
+  EVENT_NEXT_HOP_DEL,
+  EVENT_NEXT_HOP_DUMP,
+  EVENT_TE_LINK_ADD,
+  EVENT_TE_LINK_DEL,
+  EVENT_TE_LINK_STATUS_CHANGE,
+  EVENT_TE_LINK_DUMP,
+  EVENT_CREATE_TE_PATH,
+  EVENT_REMOTE_LS_UPDATE,
+  EVENT_CONNECTIVITY_BROKEN,
+  EVENT_OPEN_RSVP_LSP,
+  EVENT_LSP_USER_SETUP,
+  EVENT_CLOSE_RSVP_LSP,
+  EVENT_ADD_IF_ADDR,
+  EVENT_ENABLE_RSVP,
+  EVENT_DISABLE_RSVP,
+  EVENT_TE_LOG_CFG,
+  EVENT_RSVP_LOG_CFG,
+  EVENT_TE_SM,
+  EVENT_RRO_CHANGED,
+  EVENT_FRR_INFO_SET,
+  EVENT_SET_ROUTER_ID,
+  EVENT_READ_PATH_CASH,
+  EVENT_CSPF_RETRY_EXPIRY,
+  EVENT_LINK_2_RTR_ID_MAPPING,
+  EVENT_LINK_2_RTR_ID_WITHDRAW,
+  EVENT_IGP_HELLO,
+  EVENT_DEL_IF_ADDR,
+  EVENT_MAX = EVENT_DEL_IF_ADDR
+} EVENTS_E;
+
+typedef struct
+{
+  uns32 IfIndex;
+  uns32 BackupOutIf;
+//    V_CARD_ID    BackupVcardId;
+  IPV4_ADDR MergeNodeIp;
+  PSB_KEY PsbKey;
+} FRR_DATA_SET;
+
+typedef struct
+{
+  PSB_KEY PsbKey;
+  uns32 IfIndex;
+} BUMP_TUNNEL_T;
+
+typedef struct
+{
+  IPV4_ADDR merge_node;
+  uns32 OutIfIndex;
+  IPV4_ADDR protected_node;
+  IPV4_ADDR prohibited_penultimate_node;
+} FRR_SM_KEY;
+
+typedef struct _tunnel_id_list_
+{
+  IPV4_ADDR dest;
+  uns16 tunnel_id;
+  IPV4_ADDR source;
+  struct _tunnel_id_list_ *next;
+} TUNNEL_ID_LIST;
+
+typedef struct _lsp_path_shared_params_
+{
+  BOOL disable;
+  float BW;
+  uns32 class_of_service;
+  uns32 affinity_properties;
+  uns32 affinity_mask;
+  uns32 hop_limit;
+  uns32 optimize_timer;
+  uns32 preference;
+  uns8 setup_priority;
+  uns8 hold_priority;
+  BOOL record;
+  BOOL standby;
+} LSP_PATH_SHARED_PARAMS;
+
+typedef struct
+{
+  float BW;
+  uns32 hop_limit;
+  /* admin group */
+} FAST_REROUTE;
+
+typedef struct _secondary_path_list_
+{
+  char Secondary[16];
+  LSP_PATH_SHARED_PARAMS *SecondaryPathParams;
+  struct _secondary_path_list_ *next;
+} SECONDARY_PATH_LIST;
+
+typedef struct
+{
+  char LspName[32];
+  IPV4_ADDR to;
+  IPV4_ADDR from;
+  LSP_PATH_SHARED_PARAMS lsp_params;
+#if 0				/* Juniper's style */
+  FAST_REROUTE *FastReroute;
+#else
+  BOOL FastReRoute;
+#endif
+  uns32 metric;
+  BOOL no_decrement_ttl;
+  uns32 bw_policy;
+  uns32 retry_timer;
+  uns32 retry_limit;
+  uns32 retry_count;		/* NOT a User's parameter!!! */
+  char Primary[16];
+  LSP_PATH_SHARED_PARAMS *PrimaryPathParams;
+  SECONDARY_PATH_LIST *SecondaryPaths;
+  char PolicyName[32];
+} USER_LSP_PARAMS;
+
+typedef struct
+{
+  IPV4_ADDR dest_ip;
+  float BW;
+  uns16 sla_id;
+} SLA_DATA;
+
+typedef struct
+{
+  void *data;
+} TE_SM_EVENT;
+
+typedef struct
+{
+  uns32 IfIndex;
+  uns32 IpAddr;
+} INTERFACE_2_DESTINATION_T;
+
+typedef struct
+{
+  uns32 OutIf;			/* Protected I/F */
+  PSB_KEY PsbKey;		/* for Ingress LSPs */
+  unsigned int Label;		/* IN label (0 if Ingress, use then PSB_KEY) */
+  RR_SUBOBJ *pRro;
+} RRO_CHANGED_HOOK;
+
+typedef struct
+{
+  PSB_KEY key;
+  uns32 handle;
+  uns32 TeLinkId;
+  uns32 OutIf;
+  float BW;
+  uns8 Priority;
+} BW_HOLD_TIMER_DATA;
+
+typedef struct
+{
+  PSB_KEY key;
+} LSP_SETUP_TIMER_DATA;
+
+typedef struct
+{
+  PSB_KEY key;
+} ADAPTIVITY_TIMER_DATA;
+
+typedef struct
+{
+  PSB_KEY key;
+} LSP_SETUP_RETRY_TIMER_DATA;
+
+typedef struct
+{
+  PSB_KEY key;
+} CSPF_RETRY_TIMER_DATA;
+
+typedef enum
+{
+  BW_HOLD_EXPIRY,
+  LSP_SETUP_EXPIRY,
+  ADAPTIVITY_EXPIRY,
+  LSP_SETUP_RETRY_EXPIRY,
+  BYPASS_TUNNEL_RETRY_EXPIRY,
+  CSPF_RETRY_EXPIRY,
+  MAX_TE_TMR
+} TE_TMR_E;
+
+typedef struct
+{
+  struct thread *thread;
+  union
+  {
+    BW_HOLD_TIMER_DATA bw_hold_data;
+    LSP_SETUP_TIMER_DATA lsp_setup_data;
+    ADAPTIVITY_TIMER_DATA adaptivity_timer_data;
+    LSP_SETUP_RETRY_TIMER_DATA lsp_setup_retry_data;
+    FRR_SM_KEY bypass_retry_data;
+    CSPF_RETRY_TIMER_DATA cspf_retry_data;
+  } data;
+  uns32 period;
+  uns16 is_active;
+  TE_TMR_E type;
+} TE_TMR;
+
+typedef struct
+{
+  IPV4_ADDR Dest;
+  uns32 EgressIfId;
+} TRUNK_KEY;
+
+typedef struct
+{
+  unsigned int BypassTunnelsLabel;
+  unsigned int MergeNodeLabel;
+  uns32 OutIf;
+  BOOL MergeNodeLabelValid;	/* In case of Merge Node is an Egress, MergeNodeLabel can be 0 */
+  FRR_SM_KEY frr_key;		/* Who is FRR SM for this label/session */
+  PSB_KEY PsbKey;		/* for searching the PSB on the LCC */
+  IPV4_ADDR MergeNode;		/* for updating ERO */
+} BACKUP_FORWARDING_INFORMATION;
+
+typedef struct _rsvp_lsp_properties_
+{
+  float RequestedBW;		/* valid during modification */
+  uns16 LspId;
+//  uns32                        card;
+  uns32 oIfIndex;
+  uns32 Label;
+  BOOL tunneled;
+  union
+  {
+    struct
+    {
+      uns32 HopCount;
+      IPV4_ADDR *pErHopsList;
+      BACKUP_FORWARDING_INFORMATION BackupForwardingInformation;
+    } path;
+    PSB_KEY tunnel;
+  } forw_info;
+  uns8 SetupPriority;
+  uns8 HoldPriority;
+  uns32 ExcludeAny;
+  uns32 IncludeAny;
+  uns32 IncludeAll;
+  uns8 FrrDesired;
+  uns8 LabelRecordingDesired;
+  struct _rsvp_lsp_properties_ *next;
+} RSVP_LSP_PROPERTIES;
+
+typedef struct _rsvp_tunnel_properties_
+{
+  uns16 TunnelId;
+  uns16 LspId;			/* currrently used */
+  float AllocatedBW;
+  float RequiredBW;		/* for LSP modification */
+  float ReservableBW;		/* for Tunnels & FA */
+  void *sm_handle;		/* new ingress lsp or modified ingress lsp sm */
+  uns32 Cost;			/* FA */
+  uns32 ColorMask;		/* FA */
+  BOOL ReRoute;			/* During recovery, to prevent multiple recovery */
+  BOOL AdjustmentRequired;	/* For secondary tunnels only */
+  uns16 LastInvokedLspId;	/* to pick up new RSVP LSP ID */
+  struct _tunnel_id_list_ *pSecondaryTunnels;
+  char UserLspName[32];
+  char StaticPathName[16];
+  TE_TMR lsp_setup_timer;
+  TE_TMR adaptivity_timer;
+  TE_TMR lsp_setup_retry_timer;
+  TE_TMR cspf_retry_timer;
+  void *up_sm_handle;
+  void *pCrArgs;
+  void *pOpenLspParams;
+  RSVP_LSP_PROPERTIES *properties;
+  struct _rsvp_tunnel_properties_ *next;
+  struct _rsvp_tunnel_properties_ *next_user_lsp_tunnel;
+} RSVP_TUNNEL_PROPERTIES;
+
+
+typedef struct _user_lsp_
+{
+  USER_LSP_PARAMS params;
+  char CurrentSecondaryPathName[16];
+  uns16 BackupTunnelId;
+  //TUNNEL_ID_LIST  *TunnelIdList;
+  RSVP_TUNNEL_PROPERTIES *pUserLspTunnels;
+} USER_LSP;
+
+typedef struct _user_lsp_list_
+{
+  USER_LSP *lsp;
+  struct _user_lsp_list_ *next;
+} USER_LSP_LIST;
+
+typedef struct
+{
+  IPV4_ADDR dest;
+  uns16 sla_id;
+} SLA_KEY;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  SLA_KEY sla_key;
+  float BW;
+  struct _tunnels_list_ /*TUNNELS_LIST */ *pTunnelsList;
+} SLA_ENTRY;
+
+typedef struct
+{
+  float RequiredBW;
+  float ActualBW;
+  float UserRequiredBW;
+  uns32 sm_handle;		/* adaptivity sm */
+} TRUNK_DATA;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  TRUNK_KEY trunk_key;
+  RSVP_TUNNEL_PROPERTIES *Lsps;
+  TRUNK_DATA *pTrunkData;
+  uns32 TunnelsCounter;
+} TRUNK_ENTRY;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  unsigned int label;
+  uns32 OutIf;
+  unsigned int ReceivedOutLabel;
+  //V_CARD_ID                     allocator; /* needed for FRR */
+  uns32 IfIndex;		/* needed for FRR */
+  BACKUP_FORWARDING_INFORMATION BackupForwardingInformation;
+} LABEL_ENTRY;
+
+typedef struct _bw_owner_data_
+{
+  uns32 TeLinkId;
+  uns32 OutIf;
+  //V_CARD_ID        vcard;
+  float BW;
+  float PreAllocBW;
+  TE_TMR BwHoldTimer;
+  struct _bw_owner_data_ *next;
+} BW_OWNER_DATA;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  PSB_KEY key;
+  BW_OWNER_DATA *pBwOwnerData;
+} BW_OWNER_ENTRY;
+
+/**************************************************************************
+ *                                                                        *
+ *                                                                        *
+ *            ANSI Function Prototypes for internal functions             *
+ *                                                                        *
+ *                                                                        *
+ *                                                                        *
+ *************************************************************************/
+
+extern int ExitFlag;
+extern int VcardId;
+
+#ifdef FATAL_ERROR
+#undef FATAL_ERROR
+#endif
+
+#define FATAL_ERROR(x)  if(x == NULL) \
+{\
+   LogMsg(ERROR_OUTPUT,"fatal error at %s %d",__FILE__,__LINE__);\
+   return -1;\
+}
+extern char if_ip_addr_str[4][16];
+extern char peer_ip_addr_str[5][16];
+extern IPV4_ADDR peer_ip_addr[5];
+extern int lsr_id_ifc;
+
+typedef struct ip_addr_ll
+{
+  char *ip_addr;
+  struct ip_addr_ll *next;
+} tIpAddrLl;
+
+typedef enum
+{
+  SEPARATE_NON_ADAPTIVE,
+  SEPARATE_ADAPTIVE,
+  NON_SEPARATE_SERVICE,
+  NON_SEPARATE_SERVICE_BW_ADAPTIVE,
+  NON_SEPARATE_TUNNELS,
+  ALL_TRUNKS
+} TRUNK_TYPE;
+
+typedef struct
+{
+  EVENTS_E event;
+  union
+  {
+    USER_LSP user_lsp;
+    SLA_DATA sla_data;
+    BW_HOLD_TIMER_DATA bw_hold_timer_expiry;
+    LSP_SETUP_TIMER_DATA lsp_setup_timer_expiry;
+    ADAPTIVITY_TIMER_DATA adaptivity_timer_expiry;
+    LSP_SETUP_RETRY_TIMER_DATA lsp_setup_retry_timer_expiry;
+    TE_SM_EVENT te_sm_event;
+    INTERFACE_2_DESTINATION_T interface_2_destination;
+//       FRR_SM_KEY bypass_retry_expiry;
+    FRR_DATA_SET frr_data_set;
+    CSPF_RETRY_TIMER_DATA cspf_retry_data;
+  } u;
+} TE_MSG;
+
+#define DATA_PLANE 1
+#define MPLS_TE_DB 1
+
+#endif
+
diff -Naur quagga-0.99.10/rsvpd/patricia.c quagga-mpls/rsvpd/patricia.c
--- quagga-0.99.10/rsvpd/patricia.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/patricia.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,578 @@
+#include "general.h"
+#include <zebra.h>
+#include "patricia.h"
+#include "memory.h"
+
+const static uns8 BitMasks[9] = {
+  0x00, 0x80, 0xc0, 0xe0, 0xf0, 0xf8, 0xfc, 0xfe, 0xff
+};
+
+static int
+KeyBitMatch (const uns8 * p1, const uns8 * p2, unsigned int bitcount)
+{
+  while (bitcount > 8)
+    {
+      if (*p1 != *p2)
+	{
+	  return (((int) *p1) - ((int) *p2));
+	}
+      p1++;
+      p2++;
+      bitcount -= 8;
+    }
+
+  return (((int) (*p1 & BitMasks[bitcount])) -
+	  ((int) (*p2 & BitMasks[bitcount])));
+
+}
+
+static PATRICIA_NODE *
+search (const PATRICIA_TREE * const pTree, const uns8 * const key)
+{
+  PATRICIA_NODE *pNode;
+  PATRICIA_NODE *pPrevNode;
+
+  pNode = (PATRICIA_NODE *) & pTree->root_node;
+
+  do
+    {
+      pPrevNode = pNode;
+
+      if (m_GET_BIT (key, pNode->bit) == 0)
+	{
+	  pNode = pNode->left;
+	}
+      else
+	{
+	  pNode = pNode->right;
+	}
+
+    }
+  while (pNode->bit > pPrevNode->bit);
+
+  return pNode;
+}
+
+unsigned int
+patricia_tree_init (PATRICIA_TREE * const pTree,
+		    const PATRICIA_PARAMS * const pParams)
+{
+  if (pParams == NULL)
+    return E_ERR;
+
+  if ((pParams->key_size < 1) || (pParams->key_size > PATRICIA_MAX_KEY_SIZE))
+    return E_ERR;
+
+  pTree->params = *pParams;
+
+  /* Initialize the root node, which is actually part of the tree structure. */
+  pTree->root_node.key_info = (uns8 *) 0;
+  pTree->root_node.bit = -1;
+  pTree->root_node.left = pTree->root_node.right = &pTree->root_node;
+  if ((pTree->root_node.key_info =
+       (uns8 *) XMALLOC (0, pTree->params.key_size)) == NULL)
+    {
+      return E_ERR;
+    }
+
+  memset (pTree->root_node.key_info, '\0', (uns32) pTree->params.key_size);
+  pTree->n_nodes = 0;
+
+  return E_OK;
+}
+
+
+unsigned int
+patricia_tree_destroy (PATRICIA_TREE * const pTree)
+{
+  patricia_tree_clear (pTree);
+  XFREE (0, pTree->root_node.key_info);
+  return E_OK;
+}
+
+
+void
+patricia_tree_clear (PATRICIA_TREE * const pTree)
+{
+
+  pTree->root_node.left = pTree->root_node.right = &pTree->root_node;
+  pTree->n_nodes = 0;
+
+}
+
+unsigned int
+patricia_tree_add (PATRICIA_TREE * const pTree, PATRICIA_NODE * const pNode)
+{
+  PATRICIA_NODE *pSrch;
+  PATRICIA_NODE *pTmpNode;
+  PATRICIA_NODE *pPrevNode;
+  int bit;
+
+  pTmpNode = search (pTree, pNode->key_info);
+  if (m_KEY_CMP (pTree, pNode->key_info, pTmpNode->key_info) == 0)
+    {
+      return E_ERR;		/* duplicate!. */
+    }
+
+  bit = 0;
+
+  while (m_GET_BIT (pNode->key_info, bit) ==
+	 ((pTmpNode->bit < 0) ? 0 : m_GET_BIT (pTmpNode->key_info, bit)))
+    {
+      bit++;
+    }
+
+  pSrch = &pTree->root_node;
+
+  do
+    {
+      pPrevNode = pSrch;
+      if (m_GET_BIT (pNode->key_info, pSrch->bit) == 0)
+	pSrch = pSrch->left;
+      else
+	pSrch = pSrch->right;
+    }
+  while ((pSrch->bit < bit) && (pSrch->bit > pPrevNode->bit));
+
+  pNode->bit = bit;
+
+  if (m_GET_BIT (pNode->key_info, bit) == 0)
+    {
+      pNode->left = pNode;
+      pNode->right = pSrch;
+    }
+  else
+    {
+      pNode->left = pSrch;
+      pNode->right = pNode;
+    }
+
+  if (m_GET_BIT (pNode->key_info, pPrevNode->bit) == 0)
+    {
+      pPrevNode->left = pNode;
+    }
+  else
+    {
+      pPrevNode->right = pNode;
+    }
+
+  pTree->n_nodes++;
+  return E_OK;
+}
+
+
+unsigned int
+patricia_tree_del (PATRICIA_TREE * const pTree, PATRICIA_NODE * const pNode)
+{
+  PATRICIA_NODE *pNextNode;
+  PATRICIA_NODE **pLegDownToNode;
+  PATRICIA_NODE *pDelNode;
+  PATRICIA_NODE **pPrevLeg;
+  PATRICIA_NODE **pNextLeg;
+  int UpWentRight;
+
+  UpWentRight = 0;
+
+
+  /* Start left of root (there is no right). */
+  pNextNode = &pTree->root_node;
+  pLegDownToNode = &pNextNode->left;
+
+  while ((pDelNode = *pLegDownToNode) != pNode)
+    {
+      if (pDelNode->bit <= pNextNode->bit)
+	{
+	  return E_ERR;		/* Key not found. */
+	}
+
+      pNextNode = pDelNode;
+      pLegDownToNode = ((m_GET_BIT (pNode->key_info, pNextNode->bit) != 0) ?
+			&pNextNode->right : &pNextNode->left);
+
+    }
+
+  /* pDelNode points to the one to delete.
+   * pLegDownToNode points to the down-pointer which points to it.
+   */
+
+  pPrevLeg = pLegDownToNode;
+  pNextNode = pNode;
+
+  /* keep going 'down' until we find the one which 
+   * points back to pNode as an up-pointer. 
+   */
+
+  while (1)
+    {
+      UpWentRight = (m_GET_BIT (pNode->key_info, pNextNode->bit) != 0);
+      pNextLeg = ((UpWentRight) ? &pNextNode->right : &pNextNode->left);
+      pDelNode = *pNextLeg;
+
+      if (pDelNode == pNode)
+	break;
+
+      if (pDelNode->bit <= pNextNode->bit)
+	{
+	  return E_ERR;		/* panic??? */
+	}
+
+      /* loop around again. */
+      pNextNode = pDelNode;
+      pPrevLeg = pNextLeg;
+    }
+
+  /* At this point, 
+   * pNextNode is the one pointing UP to the one to delete. 
+   * pPrevLeg points to the down-leg which points to pNextNode
+   * UpWentRight is the direction which pNextNode took (in the UP
+   *      direction) to get to the one to delete.)
+   */
+
+  /* We need to rearrange the tree.
+   * BE CAREFUL.  The order of the following statements
+   * is critical.
+   */
+  pNextNode->bit = pNode->bit;	/* it gets the 'bit' value of the evacuee. */
+  *pLegDownToNode = pNextNode;
+
+  *pPrevLeg = ((UpWentRight) ? pNextNode->left : pNextNode->right);
+  pNextNode->right = pNode->right;
+  pNextNode->left = pNode->left;
+
+  pTree->n_nodes--;
+
+  return E_OK;
+}
+
+
+PATRICIA_NODE *
+patricia_tree_get (const PATRICIA_TREE * const pTree, const uns8 * const pKey)
+{
+  PATRICIA_NODE *pNode;
+
+  /*
+   * See if last getNext happened to be same key.
+   *
+   * Important assumtion: lastNode will be set to NULL if any
+   * nodes are deleted from the tree.
+   */
+
+  pNode = search (pTree, pKey);
+
+  if ((pNode == &pTree->root_node) ||
+      (m_KEY_CMP (pTree, pNode->key_info, pKey) != 0))
+    {
+      pNode = PATRICIA_NODE_NULL;
+    }
+
+  return pNode;
+}
+
+
+PATRICIA_NODE *
+patricia_tree_getnext (PATRICIA_TREE * const pTree, const uns8 * const pKey)
+{
+  uns8 Target[PATRICIA_MAX_KEY_SIZE];
+  PATRICIA_NODE *pSrch;
+  PATRICIA_NODE *pPrev;
+  register uns8 *p1;
+  register uns8 *p2;
+  register int bit;
+
+  if (pKey == (const uns8 *) 0)
+    {
+      /* Start at root of tree. */
+      memset (Target, '\0', pTree->params.key_size);
+    }
+  else
+    {
+      memcpy (Target, pKey, pTree->params.key_size);
+    }
+
+  p1 = Target + pTree->params.key_size - 1;	/* point to last byte of key */
+  while (p1 >= Target)
+    {
+      *p1 += 1;
+      if (*p1 != '\0')
+	{
+	  break;
+	}
+      p1--;
+    }
+  if (p1 < Target)
+    {
+      return PATRICIA_NODE_NULL;
+    }
+
+  pSrch = &pTree->root_node;
+
+  do
+    {
+      pPrev = pSrch;
+
+      if (m_GET_BIT (Target, pSrch->bit) == 0)
+	{
+	  pSrch = pSrch->left;
+	}
+      else
+	{
+	  pSrch = pSrch->right;
+	}
+
+      if (pSrch->bit <= pPrev->bit)
+	{
+	  if ((memcmp (Target, pSrch->key_info, pTree->params.key_size) <= 0)
+	      && (KeyBitMatch (Target, pSrch->key_info, 1 + pPrev->bit) == 0))
+	    {
+	      return pSrch;
+	    }
+
+	  do
+	    {
+	      if (pSrch == pPrev->left)
+		{
+		  /* We went left to get here */
+		  if (pPrev->bit < 0)
+		    {
+		      return PATRICIA_NODE_NULL;
+		    }
+		  pSrch = pPrev;
+
+		  p1 = pSrch->key_info;
+		  p2 = Target;
+
+		  for (bit = pSrch->bit; bit >= 8; bit -= 8)
+		    {
+		      *p2++ = *p1++;
+		    }
+		  /* Bring over SOME of the bits from pSrch. */
+		  *p2 = (uns8) (*p1 & ((uns8) (BitMasks[bit])));
+
+		  *p2 |= (uns8) (0x80 >> bit);
+
+		  p2++;
+
+		  while (p2 < (Target + pTree->params.key_size))
+		    {
+		      *p2++ = '\0';
+		    }
+		  break;
+		}
+	      else
+		{
+		  /* We went right to get here */
+		  if (pPrev->bit <= 0)
+		    {
+		      return PATRICIA_NODE_NULL;
+		    }
+
+		  p1 = pPrev->key_info;
+		  p2 = Target;
+
+		  for (bit = pPrev->bit; bit >= 8; bit -= 8)
+		    {
+		      *p2++ = *p1++;
+		    }
+		  if (bit > 0)
+		    {
+		      *p2 = (uns8) (*p1 & BitMasks[bit]);
+		    }
+		  *p2 |= (uns8) (0xff >> bit);
+		  for (p1 = p2 + 1; p1 < (Target + pTree->params.key_size);
+		       p1++)
+		    {
+		      *p1 = '\0';
+		    }
+		  do
+		    {
+		      ++*p2;
+		      if (*p2 != '\0')
+			{
+			  break;
+			}
+		    }
+		  while (--p2 >= Target);
+
+		  if (p2 < Target)
+		    {
+		      return PATRICIA_NODE_NULL;
+		    }
+
+		  pSrch = pPrev;
+
+		  pPrev = &pTree->root_node;
+		  do
+		    {
+		      if (m_GET_BIT (pSrch->key_info, pPrev->bit) == 0)
+			{
+			  if (pPrev->left == pSrch)
+			    {
+			      break;
+			    }
+			  pPrev = pPrev->left;
+			}
+		      else
+			{
+			  if (pPrev->right == pSrch)
+			    {
+			      break;
+			    }
+			  pPrev = pPrev->right;
+			}
+
+		    }
+		  while (TRUE);
+
+		  if (KeyBitMatch (Target, pSrch->key_info, 1 + pSrch->bit) ==
+		      0)
+		    {
+		      break;
+		    }
+		}
+
+	    }
+	  while (TRUE);
+
+	}			/* if (pSrch->bit <= pPrev->bit) */
+      else
+	{
+	  /* We're still going 'down'... but make sure we haven't gone down too far. */
+	  bit = KeyBitMatch (Target, pSrch->key_info, pSrch->bit);
+
+	  if (bit < 0)
+	    {
+	      p1 = pSrch->key_info;
+	      p2 = Target;
+	      for (bit = pSrch->bit; bit >= 8; bit -= 8)
+		{
+		  *p2++ = *p1++;
+		}
+	      if (bit != 0)
+		{
+		  *p2++ = ((uns8) (*p1 & BitMasks[bit]));
+		}
+	      while (p2 < Target + pTree->params.key_size)
+		{
+		  *p2++ = '\0';
+		}
+	    }
+	  else if (bit > 0)
+	    {
+
+	      do
+		{
+		  if (pSrch == pPrev->left)
+		    {
+		      /* We went left to get here */
+		      if (pPrev->bit < 0)
+			{
+			  return PATRICIA_NODE_NULL;
+			}
+		      pSrch = pPrev;
+
+		      p1 = pSrch->key_info;
+		      p2 = Target;
+
+		      for (bit = pSrch->bit; bit >= 8; bit -= 8)
+			{
+			  *p2++ = *p1++;
+			}
+		      /* Bring over SOME of the bits from pSrch. */
+		      *p2 = (uns8) (*p1 & ((uns8) (BitMasks[bit])));
+
+		      *p2 |= (uns8) (0x80 >> bit);
+
+		      p2++;
+
+		      while (p2 < (Target + pTree->params.key_size))
+			{
+			  *p2++ = '\0';
+			}
+		      break;
+		    }
+		  else
+		    {
+		      /* We went right to get here */
+		      if (pPrev->bit <= 0)
+			{
+			  return PATRICIA_NODE_NULL;
+			}
+
+		      p1 = pPrev->key_info;
+		      p2 = Target;
+
+		      for (bit = pPrev->bit; bit >= 8; bit -= 8)
+			{
+			  *p2++ = *p1++;
+			}
+		      if (bit > 0)
+			{
+			  *p2 = (uns8) (*p1 & BitMasks[bit]);
+			}
+		      *p2 |= (uns8) (0xff >> bit);
+		      for (p1 = p2 + 1;
+			   p1 < (Target + pTree->params.key_size); p1++)
+			{
+			  *p1 = '\0';
+			}
+		      do
+			{
+			  ++*p2;
+			  if (*p2 != '\0')
+			    {
+			      break;
+			    }
+			}
+		      while (--p2 >= Target);
+
+		      if (p2 < Target)
+			{
+			  return PATRICIA_NODE_NULL;
+			}
+
+		      pSrch = pPrev;
+
+		      pPrev = &pTree->root_node;
+		      do
+			{
+			  if (m_GET_BIT (pSrch->key_info, pPrev->bit) == 0)
+			    {
+			      if (pPrev->left == pSrch)
+				{
+				  break;
+				}
+			      pPrev = pPrev->left;
+			    }
+			  else
+			    {
+			      if (pPrev->right == pSrch)
+				{
+				  break;
+				}
+			      pPrev = pPrev->right;
+			    }
+
+			}
+		      while (TRUE);
+
+		      if (KeyBitMatch
+			  (Target, pSrch->key_info, 1 + pSrch->bit) == 0)
+			{
+			  break;
+			}
+		    }
+
+		}
+	      while (TRUE);
+	    }
+	}
+    }
+  while (TRUE);
+}
+
+
+int
+patricia_tree_size (const PATRICIA_TREE * const pTree)
+{
+  return pTree->n_nodes;
+}
diff -Naur quagga-0.99.10/rsvpd/patricia.h quagga-mpls/rsvpd/patricia.h
--- quagga-0.99.10/rsvpd/patricia.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/patricia.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,56 @@
+
+#ifndef _PATRICIA_H_
+#define _PATRICIA_H_
+
+#include "general.h"
+
+typedef struct patricia_params
+{
+  int key_size;			/* 1..PATRICIA_MAX_KEY_SIZE - in OCTETS */
+  int info_size;		/* NOT USED!  Present for backward-compatibility only! */
+  int actual_key_size;		/* NOT USED!  Present for backward-compatibility only! */
+  int node_size;		/* NOT USED!  Present for backward compatibitity only! */
+} PATRICIA_PARAMS;
+
+#define PATRICIA_MAX_KEY_SIZE	256	/* # octets */
+
+
+typedef struct patricia_node
+{
+  int bit;			/* must be signed type (bits start at -1) */
+  struct patricia_node *left;
+  struct patricia_node *right;
+  uns8 *key_info;
+} PATRICIA_NODE;
+
+#define PATRICIA_NODE_NULL ((PATRICIA_NODE *)0)
+
+typedef uns8 PATRICIA_LEXICAL_STACK;	/* ancient history... */
+
+typedef struct patricia_tree
+{
+  PATRICIA_NODE root_node;	/* A tree always has a root node. */
+  PATRICIA_PARAMS params;
+  unsigned int n_nodes;
+} PATRICIA_TREE;
+
+
+#define m_KEY_CMP(t, k1, k2) memcmp(k1, k2, (size_t)(t)->params.key_size)
+#define m_GET_BIT(key, bit)  ((bit < 0) ? 0 : ((int)((*((key) + (bit >> 3))) >> (7 - (bit & 0x07))) & 0x01))
+
+unsigned int patricia_tree_init (PATRICIA_TREE * const pTree,
+				 const PATRICIA_PARAMS * const pParams);
+unsigned int patricia_tree_destroy (PATRICIA_TREE * const pTree);
+void patricia_tree_clear (PATRICIA_TREE * const pTree);
+unsigned int patricia_tree_add (PATRICIA_TREE * const pTree,
+				PATRICIA_NODE * const pNode);
+unsigned int patricia_tree_del (PATRICIA_TREE * const pTree,
+				PATRICIA_NODE * const pNode);
+PATRICIA_NODE *patricia_tree_get (const PATRICIA_TREE * const pTree,
+				  const uns8 * const pKey);
+PATRICIA_NODE *patricia_tree_get_best (const PATRICIA_TREE * const pTree, const uns8 * const pKey, uns16 KeyLen);	/* Length of key (in BITS) */
+PATRICIA_NODE *patricia_tree_getnext (PATRICIA_TREE * const pTree, const uns8 * const pKey);	/* NULL means get 1st */
+
+int patricia_tree_size (const PATRICIA_TREE * const pTree);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvp_api.c quagga-mpls/rsvpd/rsvp_api.c
--- quagga-0.99.10/rsvpd/rsvp_api.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_api.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,239 @@
+/* Module:   rsvp_api.c
+   Contains: RSVP in-process API functions
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+
+#include "rsvp.h"
+
+void
+RsvpPathSendCmd (TE_API_MSG * pMsg)
+{
+  if (IngressPathSend (&pMsg->u.IngressApi) != E_OK)
+    {
+      zlog_err ("Cannot invoke PATH");
+    }
+}
+
+void
+RsvpPathTearCmd (TE_API_MSG * pMsg)
+{
+  if (IngressPathTear (&pMsg->u.IngressApi) != E_OK)
+    {
+      zlog_err ("Cannot invoke PATH_TEAR");
+    }
+}
+extern uns32 PathRefreshInterval;
+E_RC
+IngressPathSend (INGRESS_API * pIngressApi)
+{
+  PSB_KEY PsbKey;
+  PSB *pPsb;
+  RSVP_PKT *pRsvpPkt;
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+  PsbKey.Session.Dest = pIngressApi->Egress;
+  PsbKey.Session.TunnelId = pIngressApi->TunnelId;
+  PsbKey.Session.ExtTunelId = pIngressApi->src_ip;
+  PsbKey.SenderTemplate.IpAddr = PsbKey.Session.ExtTunelId;
+  PsbKey.SenderTemplate.LspId = pIngressApi->LspId;
+  if ((pPsb = FindPsb (&PsbKey)) != NULL)
+    {
+      zlog_err ("RSVP LSP exists in this tunnel");
+      return E_ERR;
+    }
+  if ((pPsb = NewPsb (&PsbKey)) == NULL)
+    {
+      zlog_err ("Cannot create PSB");
+    }
+  pRsvpPkt = &pPsb->OldPacket;
+  pRsvpPkt->Session = PsbKey.Session;
+  pRsvpPkt->SenderTemplate = PsbKey.SenderTemplate;
+  pRsvpPkt->SentRsvpHop.LIH = pIngressApi->OutIfIndex;
+  pPsb->NextHop = pIngressApi->NextHop;
+  pPsb->OutIfIndex = pIngressApi->OutIfIndex;
+  pPsb->RefreshValue = PathRefreshInterval;
+  pPsb->ttl = 255;
+  if (IpAddrGetByIfIndex (pPsb->OutIfIndex, &pRsvpPkt->SentRsvpHop.PHop) !=
+      E_OK)
+    {
+      zlog_err ("Cannot get IP address by IfIndex %x", pPsb->OutIfIndex);
+      return E_ERR;
+    }
+  else
+    {
+      pPsb->OldPacket.SentRsvpHop.PHop = pPsb->OldPacket.SentRsvpHop.PHop;
+      zlog_info ("NHOP %x", pPsb->NextHop);
+    }
+  pRsvpPkt->LabelRequest.L3Pid = 0x800;
+  pRsvpPkt->TimeValues.TimeValues = PathRefreshInterval * 1000;
+  pRsvpPkt->SenderTSpec.MessageHdr.VersionResvd = 0;
+  pRsvpPkt->SenderTSpec.MessageHdr.MessageLength = 7;
+  pRsvpPkt->SenderTSpec.ServHdr.ServHdr = 1;
+  pRsvpPkt->SenderTSpec.ServHdr.ServLength = 6;
+  pRsvpPkt->SenderTSpec.ParamHdr.ParamID = 127;
+  pRsvpPkt->SenderTSpec.ParamHdr.ParamLength = 5;
+  pRsvpPkt->SenderTSpec.MaxPacketSize = 1500;
+  pRsvpPkt->SenderTSpec.PeakDataRate = pIngressApi->BW;
+  pRsvpPkt->SenderTSpec.MinPolicedUnit = 40;
+  pRsvpPkt->SenderTSpec.TockenBucketRate = pIngressApi->BW;
+  pRsvpPkt->SenderTSpec.TockenBucketSize = 1;
+  if (pIngressApi->HopNum > 0)
+    {
+      zlog_info ("calling InsertERO %d", pIngressApi->HopNum);
+      if (InsertERO
+	  (&pRsvpPkt->SentEro, pIngressApi->Path,
+	   pIngressApi->HopNum) != E_OK)
+	{
+	  FreeERO (&pRsvpPkt->SentEro);
+	  zlog_err ("Cannot allocate ERO");
+	  return E_ERR;
+	}
+    }
+
+  if (pIngressApi->LabelRecordingDesired)
+    {
+      if (InsertRRO (pRsvpPkt) != E_OK)
+	{
+	  FreeRRO (&pRsvpPkt->AddedRro);
+	  zlog_err ("Cannot allocate RRO");
+	  return E_ERR;
+	}
+    }
+
+  if (pIngressApi->RaValid)
+    {
+      pRsvpPkt->SessionAttributes.CType = SESSION_ATTRIBUTES_RA_IPV4_CTYPE;
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.ExcludeAny =
+	pIngressApi->ExcludeAny;
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAll =
+	pIngressApi->IncludeAll;
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAny =
+	pIngressApi->IncludeAny;
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.SetPrio = pIngressApi->SetPrio;
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.HoldPrio =
+	pIngressApi->HoldPrio;
+      if (pIngressApi->Shared)
+	pRsvpPkt->SessionAttributes.u.SessAttrRa.Flags |= SE_STYLE_DESIRED;
+      if (pIngressApi->FrrDesired)
+	pRsvpPkt->SessionAttributes.u.SessAttrRa.Flags |=
+	  LOCAL_PROTECTION_DESIRED;
+      if (pIngressApi->LabelRecordingDesired)
+	pRsvpPkt->SessionAttributes.u.SessAttrRa.Flags |=
+	  LABEL_RECORDING_DESIRED;
+      if ((pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName =
+	   (char *) XMALLOC (MTYPE_RSVP, strlen ("VADIM SURAEV   "))) != NULL)
+	{
+	  strcpy (pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName,
+		  "VADIM SURAEV   ");
+	  pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength =
+	    strlen ("VADIM SURAEV   ");
+	}
+    }
+  else
+    {
+      pRsvpPkt->SessionAttributes.CType = SESSION_ATTRIBUTES_IPV4_CTYPE;
+      pRsvpPkt->SessionAttributes.u.SessAttr.SetPrio = pIngressApi->SetPrio;
+      pRsvpPkt->SessionAttributes.u.SessAttr.HoldPrio = pIngressApi->HoldPrio;
+
+      if (pIngressApi->Shared)
+	pRsvpPkt->SessionAttributes.u.SessAttr.Flags |= SE_STYLE_DESIRED;
+      if (pIngressApi->FrrDesired)
+	pRsvpPkt->SessionAttributes.u.SessAttr.Flags |=
+	  LOCAL_PROTECTION_DESIRED;
+      if (pIngressApi->LabelRecordingDesired)
+	pRsvpPkt->SessionAttributes.u.SessAttr.Flags |=
+	  LABEL_RECORDING_DESIRED;
+      if ((pRsvpPkt->SessionAttributes.u.SessAttr.SessionName =
+	   (char *) XMALLOC (MTYPE_RSVP,
+			     strlen ("VADIM SURAEV    ") + 1)) != NULL)
+	{
+	  strcpy (pRsvpPkt->SessionAttributes.u.SessAttr.SessionName,
+		  "VADIM SURAEV    ");
+	  pRsvpPkt->SessionAttributes.u.SessAttr.NameLength =
+	    strlen ("VADIM SURAEV    ");
+	}
+    }
+
+  return RsvpPathRefresh (pPsb);
+}
+
+E_RC
+IngressPathTear (INGRESS_API * pIngressApi)
+{
+  PSB_KEY PsbKey;
+  PSB *pPsb;
+
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+  PsbKey.Session.Dest = pIngressApi->Egress;
+  PsbKey.Session.TunnelId = pIngressApi->TunnelId;
+  PsbKey.Session.ExtTunelId = pIngressApi->src_ip;
+  PsbKey.SenderTemplate.IpAddr = PsbKey.Session.ExtTunelId;
+  PsbKey.SenderTemplate.LspId = pIngressApi->LspId;
+  if ((pPsb = FindPsb (&PsbKey)) == NULL)
+    {
+      zlog_err ("RSVP LSP %x does not exist in this tunnel %x %x %x",
+		pIngressApi->LspId, pIngressApi->Egress,
+		pIngressApi->TunnelId, pIngressApi->src_ip);
+      return E_ERR;
+    }
+  if (EncodeAndSendRsvpPathTearMessage
+      (&pPsb->OldPacket, pPsb->NextHop, pPsb->OutIfIndex,
+       pPsb->ttl - 1) != E_OK)
+    {
+      zlog_err ("Cannot encode/send RSVP PathTear %s %d", __FILE__, __LINE__);
+    }
+  if (DeleteSender (pPsb) != E_OK)
+    {
+      zlog_err ("An error on DeleteSender %s %d", __FILE__, __LINE__);
+    }
+  return E_OK;
+}
+
+E_RC
+DebugSendResvTear (TE_API_MSG * pMsg)
+{
+  DEBUG_SEND_RESV_TEAR *pDbgResvTear = &pMsg->u.DebugSendResvTear;
+  RSB *pRsb;
+  RSB_KEY RsbKey;
+  RSVP_PKT *pRsvpPkt;
+  int i;
+
+  RsbKey = pDbgResvTear->RsbKey;
+  if ((pRsb = FindRsb (&RsbKey)) == NULL)
+    {
+      zlog_err ("Cannot find RSB %x %x %x %s %d",
+		RsbKey.Session.Dest,
+		RsbKey.Session.TunnelId,
+		RsbKey.Session.ExtTunelId, __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if ((pRsvpPkt =
+       (RSVP_PKT *) XMALLOC (MTYPE_RSVP, sizeof (RSVP_PKT))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  memset (pRsvpPkt, 0, sizeof (RSVP_PKT));
+  pRsvpPkt->Session = RsbKey.Session;
+  pRsvpPkt->Style = pRsb->OldPacket.Style;
+  for (i = 0; i < pDbgResvTear->FilterSpecNumber; i++)
+    {
+      FILTER_SPEC_DATA *pFilterSpecData;
+      if ((pFilterSpecData =
+	   (FILTER_SPEC_DATA *) XMALLOC (MTYPE_RSVP,
+					 sizeof (FILTER_SPEC_DATA))) == NULL)
+	{
+	  zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	  FreeRsvpPkt (pRsvpPkt);
+	  return E_ERR;
+	}
+      memset (pFilterSpecData, 0, sizeof (FILTER_SPEC_DATA));
+      pFilterSpecData->FilterSpec = pDbgResvTear->FilterSpecs[i];
+      if (NewFilterListNode (&pRsvpPkt->pFilterList, pFilterSpecData) != E_OK)
+	{
+	  zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	  FreeRsvpPkt (pRsvpPkt);
+	  return E_ERR;
+	}
+    }
+  return ProcessRsvpResvTearMessage (pRsvpPkt);
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_api.h quagga-mpls/rsvpd/rsvp_api.h
--- quagga-0.99.10/rsvpd/rsvp_api.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_api.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,9 @@
+#ifndef _RSVP_API_H_
+#define _RSVP_API_H_
+
+E_RC IngressPathSend (INGRESS_API * pIngressApi);
+E_RC IngressPathTear (INGRESS_API * pIngressApi);
+E_RC DebugSendResvTear (TE_API_MSG * pMsg);
+void RsvpPathSendCmd (TE_API_MSG * pMsg);
+void RsvpPathTearCmd (TE_API_MSG * pMsg);
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvpd.conf.sample quagga-mpls/rsvpd/rsvpd.conf.sample
--- quagga-0.99.10/rsvpd/rsvpd.conf.sample	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvpd.conf.sample	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,16 @@
+!
+! Zebra configuration saved from vty
+!   2004/05/31 00:43:53
+!
+hostname mpls_te
+password zebra
+!
+line vty
+!
+interface tunnel Cisco1
+  tunnel destination 10.13.163.170
+  tunnel mpls traffic-eng bandwidth 1000
+  exit
+interface tunnel Cisco0
+  tunnel destination 10.13.163.170
+  exit
diff -Naur quagga-0.99.10/rsvpd/rsvp_decode.c quagga-mpls/rsvpd/rsvp_decode.c
--- quagga-0.99.10/rsvpd/rsvp_decode.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_decode.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,1005 @@
+/* Module:   rsvp_decode.c
+   Contains: RSVP packet decoding functions which parse
+   the received packet.
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "rsvp.h"
+
+uns32
+decode_24bit (uns8 ** stream)
+{
+
+  uns32 val = 0;		/* Accumulator */
+
+
+  val = (uns32) * (*stream)++ << 16;
+  val |= (uns32) * (*stream)++ << 8;
+  val |= (uns32) * (*stream)++;
+
+  return (val & 0x00FFFFFF);
+
+}
+
+uns32
+decode_32bit (uns8 ** stream)
+{
+
+  uns32 val = 0;		/* Accumulator */
+
+
+  val = (uns32) * (*stream)++ << 24;
+  val |= (uns32) * (*stream)++ << 16;
+  val |= (uns32) * (*stream)++ << 8;
+  val |= (uns32) * (*stream)++;
+
+  return val;
+}
+
+uns16
+decode_16bit (uns8 ** stream)
+{
+
+  uns32 val = 0;		/* Accumulator */
+
+
+  val = (uns32) * (*stream)++ << 8;
+  val |= (uns32) * (*stream)++;
+
+  return (uns16) (val & 0x0000FFFF);
+}
+
+uns8
+decode_8bit (uns8 ** stream)
+{
+
+  uns32 val = 0;		/* Accumulator */
+
+  val = (uns32) * (*stream)++;
+
+  return (uns8) (val & 0x000000FF);
+}
+
+#define DECODE_FLOAT(n, dec) {\
+                                                            *((uns32 *) (dec)) = (n); \
+                                                         }
+
+float
+decode_float (uns8 ** stream)
+{
+  uns32 val;
+  float ret_val;
+
+  val = (uns32) * (*stream)++ << 24;
+  val |= (uns32) * (*stream)++ << 16;
+  val |= (uns32) * (*stream)++ << 8;
+  val |= (uns32) * (*stream)++;
+  DECODE_FLOAT (val, &ret_val) return ret_val;
+}
+
+#define DECODE_COMMON_HDR \
+{\
+    RsvpCommonHdr.VersionFlags = decode_8bit((uns8 **)&pData);\
+    RsvpCommonHdr.MsgType = decode_8bit((uns8 **)&pData);\
+    RsvpCommonHdr.CheckSum = decode_16bit((uns8 **)&pData);\
+    RsvpCommonHdr.SendTTL = decode_8bit((uns8 **)&pData);\
+    RsvpCommonHdr.Resvd = decode_8bit((uns8 **)&pData);\
+    RsvpCommonHdr.RsvpLength = decode_16bit((uns8 **)&pData);\
+}
+
+#define DECODE_OBJ_HDR \
+{\
+    pObjHdr = *ppData;\
+    pObjHdr->Length = decode_16bit((uns8 **)ppData);\
+    pObjHdr->ClassNum = decode_8bit((uns8 **)ppData);\
+    pObjHdr->CType = decode_8bit((uns8 **)ppData);\
+}
+
+typedef struct
+{
+  E_RC (*pObjDecoder) (void **, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		       uns32 RemainingLen);
+} DECODE_HANDLER;
+
+#define MAX_OBJS 300
+
+DECODE_HANDLER DecodeHandlers[MAX_OBJS];
+
+E_RC
+SessionDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		uns32 RemainingLen)
+{
+  pRsvpPkt->Session.Dest = decode_32bit ((uns8 **) ppData);
+  pRsvpPkt->Session.Resvd = decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->Session.TunnelId = decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->Session.ExtTunelId = decode_32bit ((uns8 **) ppData);
+  zlog_info ("Dest %x TunnelId %x ExtTunnelId %x",
+	     pRsvpPkt->Session.Dest,
+	     pRsvpPkt->Session.TunnelId, pRsvpPkt->Session.ExtTunelId);
+  return E_OK;
+}
+
+E_RC
+RsvpHopDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		uns32 RemainingLen)
+{
+  pRsvpPkt->ReceivedRsvpHop.PHop = decode_32bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedRsvpHop.LIH = decode_32bit ((uns8 **) ppData);
+  zlog_info ("RSVP HOP %x %x", pRsvpPkt->ReceivedRsvpHop.PHop,
+	     pRsvpPkt->ReceivedRsvpHop.LIH);
+  return E_OK;
+}
+
+E_RC
+TimeValuesDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		   uns32 RemainingLen)
+{
+  pRsvpPkt->TimeValues.TimeValues = decode_32bit ((uns8 **) ppData);
+  zlog_info ("Time Values %x", pRsvpPkt->TimeValues.TimeValues);
+  return E_OK;
+}
+
+E_RC
+SenderTemplateDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		       uns32 RemainingLen)
+{
+  pRsvpPkt->SenderTemplate.IpAddr = decode_32bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTemplate.Resvd = decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTemplate.LspId = decode_16bit ((uns8 **) ppData);
+  zlog_info ("IP %x LSP ID %x", pRsvpPkt->SenderTemplate.IpAddr,
+	     pRsvpPkt->SenderTemplate.LspId);
+  return E_OK;
+}
+
+E_RC
+LabelReqDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		 uns32 RemainingLen)
+{
+  pRsvpPkt->LabelRequest.Resvd = decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->LabelRequest.L3Pid = decode_16bit ((uns8 **) ppData);
+  zlog_info ("Label Request");
+  return E_OK;
+}
+
+E_RC
+ERO_Decoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+	     uns32 RemainingLen)
+{
+  int Count;
+  ER_SUBOBJ *pErSubObj, *pPrev = NULL;
+  int Len = pObjHdr->Length - sizeof (OBJ_HDR);
+  zlog_info ("entering ERO_Decoder");
+  if (Len % 8)
+    {
+      zlog_err (" the length is not 8-alligned");
+    }
+  Count = Len / 8;
+  while (Len > 0)
+    {
+      if ((pErSubObj =
+	   (ER_SUBOBJ *) XMALLOC (MTYPE_RSVP, sizeof (ER_SUBOBJ))) == NULL)
+	{
+	  zlog_err (" malloc failed ");
+	  return E_ERR;
+	}
+      memset (pErSubObj, 0, sizeof (ER_SUBOBJ));
+      if (pRsvpPkt->ReceivedEro.er == NULL)
+	{
+	  pRsvpPkt->ReceivedEro.er = pErSubObj;
+	}
+      else
+	{
+	  pPrev->next = pErSubObj;
+	}
+      pErSubObj->SubObjHdr.LType = decode_8bit ((uns8 **) ppData);
+      pErSubObj->SubObjHdr.Length = decode_8bit ((uns8 **) ppData);
+      Len -= 8;
+      if (pErSubObj->SubObjHdr.Length != 8)
+	{
+	  zlog_err (" the length of subobject is not 8!!!");
+	  return E_ERR;
+	}
+      switch (pErSubObj->SubObjHdr.LType & 0x7F)
+	{
+	case ERO_SUBTYPE_IPV4:
+	  pErSubObj->u.Ipv4.IpAddress = decode_32bit ((uns8 **) ppData);
+	  pErSubObj->u.Ipv4.PrefixLength = decode_8bit ((uns8 **) ppData);
+	  pErSubObj->u.Ipv4.Resvd = decode_8bit ((uns8 **) ppData);
+	  zlog_info ("ERO subobject: IP %x prefix length %x",
+		     pErSubObj->u.Ipv4.IpAddress,
+		     pErSubObj->u.Ipv4.PrefixLength);
+	  break;
+	default:
+	  zlog_err ("the type %d of subobject is unknown %s %d",
+		    (pErSubObj->SubObjHdr.LType & 0x7F), __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pPrev = pErSubObj;
+    }
+  zlog_info ("leaving ERO_Decoder");
+  return E_OK;
+}
+
+E_RC
+SessionAttrDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		    uns32 RemainingLen)
+{
+  char *pP;
+
+  pRsvpPkt->SessionAttributes.CType = pObjHdr->CType;
+  if (pObjHdr->CType == SESSION_ATTRIBUTES_CLASS_TYPE)
+    {
+      pRsvpPkt->SessionAttributes.u.SessAttr.SetPrio =
+	decode_8bit ((uns8 **) ppData);
+      pRsvpPkt->SessionAttributes.u.SessAttr.HoldPrio =
+	decode_8bit ((uns8 **) ppData);
+      pRsvpPkt->SessionAttributes.u.SessAttr.Flags =
+	decode_8bit ((uns8 **) ppData);
+      pRsvpPkt->SessionAttributes.u.SessAttr.NameLength =
+	decode_8bit ((uns8 **) ppData);
+      if ((pRsvpPkt->SessionAttributes.u.SessAttr.NameLength % 4)
+	  && (pRsvpPkt->SessionAttributes.u.SessAttr.NameLength))
+	{
+	  zlog_err ("Session name length is %d must be multiple of 4",
+		    pRsvpPkt->SessionAttributes.u.SessAttr.NameLength);
+	  return E_ERR;
+	}
+      if (pRsvpPkt->SessionAttributes.u.SessAttr.NameLength < 8)
+	{
+	  zlog_err ("Session name length is %d must be at least 8",
+		    pRsvpPkt->SessionAttributes.u.SessAttr.NameLength);
+	  //return E_ERR; currently, ignore
+	}
+      if (pRsvpPkt->SessionAttributes.u.SessAttr.NameLength != 0)
+	{
+	  pP = *ppData;
+	  if ((pRsvpPkt->SessionAttributes.u.SessAttr.SessionName =
+	       (char *) XMALLOC (MTYPE_RSVP,
+				 sizeof (char) *
+				 pRsvpPkt->SessionAttributes.u.SessAttr.
+				 NameLength)) == NULL)
+	    {
+	      zlog_err ("cannot allocate memory %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  memset (pRsvpPkt->SessionAttributes.u.SessAttr.SessionName, 0,
+		  sizeof (char) *
+		  pRsvpPkt->SessionAttributes.u.SessAttr.NameLength);
+	  strncpy (pRsvpPkt->SessionAttributes.u.SessAttr.SessionName, pP,
+		   pRsvpPkt->SessionAttributes.u.SessAttr.NameLength);
+	  pP += pRsvpPkt->SessionAttributes.u.SessAttr.NameLength;
+	  *ppData = pP;
+	}
+    }
+  else if (pObjHdr->CType == SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+    {
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.ExcludeAny =
+	decode_32bit ((uns8 **) ppData);
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAny =
+	decode_32bit ((uns8 **) ppData);
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAll =
+	decode_32bit ((uns8 **) ppData);
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.SetPrio =
+	decode_8bit ((uns8 **) ppData);
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.HoldPrio =
+	decode_8bit ((uns8 **) ppData);
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.Flags =
+	decode_8bit ((uns8 **) ppData);
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength =
+	decode_8bit ((uns8 **) ppData);
+      if (pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength % 4)
+	{
+	  zlog_err ("Session name length is %d must be multiple of 4",
+		    pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength);
+	  return E_ERR;
+	}
+      if (pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength < 8)
+	{
+	  zlog_err ("Session name length is %d must be at least 8",
+		    pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength);
+	  //return E_ERR;currently, ingnore
+	}
+      if (pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength != 0)
+	{
+	  pP = *ppData;
+	  if ((pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName =
+	       (char *) XMALLOC (MTYPE_RSVP,
+				 sizeof (char) *
+				 pRsvpPkt->SessionAttributes.u.SessAttrRa.
+				 NameLength)) == NULL)
+	    {
+	      zlog_err ("cannot allocate memory %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  memset (pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName, 0,
+		  sizeof (char) *
+		  pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength);
+	  strncpy (pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName, pP,
+		   pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength);
+	  pP += pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength;
+	  *ppData = pP;
+	}
+    }
+  else
+    {
+      zlog_err ("unknown session attributes object class type %d",
+		pObjHdr->CType);
+      return E_ERR;
+    }
+  zlog_debug ("Session Attributes");
+  return E_OK;
+}
+
+E_RC
+SenderTSpecDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		    uns32 RemainingLen)
+{
+  pRsvpPkt->SenderTSpec.MessageHdr.VersionResvd =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.MessageHdr.MessageLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.ServHdr.ServHdr = decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.ServHdr.Resvd = decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.ServHdr.ServLength = decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.ParamHdr.ParamID = decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.ParamHdr.ParamFlags = decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.ParamHdr.ParamLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.TockenBucketRate = decode_float ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.TockenBucketSize = decode_float ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.PeakDataRate = decode_float ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.MinPolicedUnit = decode_32bit ((uns8 **) ppData);
+  pRsvpPkt->SenderTSpec.MaxPacketSize = decode_32bit ((uns8 **) ppData);
+  zlog_info ("Sender TSPEC %f %f %f %x %x",
+	     pRsvpPkt->SenderTSpec.PeakDataRate,
+	     pRsvpPkt->SenderTSpec.TockenBucketRate,
+	     pRsvpPkt->SenderTSpec.TockenBucketSize,
+	     pRsvpPkt->SenderTSpec.MinPolicedUnit,
+	     pRsvpPkt->SenderTSpec.MaxPacketSize);
+  return E_OK;
+}
+
+E_RC
+RRO_Decoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+	     uns32 RemainingLen)
+{
+  int Count;
+  RR_SUBOBJ *pRrSubObj, *pPrev = NULL;
+  int Len = pObjHdr->Length - sizeof (OBJ_HDR);
+  if (Len % 8)
+    {
+      zlog_err (" the length is not 8-alligned");
+    }
+  Count = Len / 8;
+  while (Len > 0)
+    {
+      if ((pRrSubObj =
+	   (RR_SUBOBJ *) XMALLOC (MTYPE_RSVP, sizeof (RR_SUBOBJ))) == NULL)
+	{
+	  zlog_err (" malloc failed ");
+	  return E_ERR;
+	}
+      memset (pRrSubObj, 0, sizeof (RR_SUBOBJ));
+      if (pRsvpPkt->ReceivedRro.rr == NULL)
+	{
+	  pRsvpPkt->ReceivedRro.rr = pRrSubObj;
+	}
+      else
+	{
+	  pPrev->next = pRrSubObj;
+	}
+      pRrSubObj->SubObjHdr.Type = decode_8bit ((uns8 **) ppData);
+      pRrSubObj->SubObjHdr.Length = decode_8bit ((uns8 **) ppData);
+      Len -= 8;
+      if (pRrSubObj->SubObjHdr.Length != 8)
+	{
+	  zlog_err (" the length of subobject is not 8!!!");
+	  return E_ERR;
+	}
+      switch (pRrSubObj->SubObjHdr.Type)
+	{
+	case RRO_SUBTYPE_IPV4:
+	  pRrSubObj->u.Ipv4.IpAddr = decode_32bit ((uns8 **) ppData);
+	  pRrSubObj->u.Ipv4.PrefixLen = decode_8bit ((uns8 **) ppData);
+	  pRrSubObj->u.Ipv4.Flags = decode_8bit ((uns8 **) ppData);
+	  zlog_info ("RRO subobject: IP %x prefix length %x",
+		     pRrSubObj->u.Ipv4.IpAddr, pRrSubObj->u.Ipv4.PrefixLen);
+	  break;
+	case RRO_SUBTYPE_LABEL:
+	  pRrSubObj->u.Label.Flags = decode_8bit ((uns8 **) ppData);
+	  pRrSubObj->u.Label.CType = decode_8bit ((uns8 **) ppData);
+	  pRrSubObj->u.Label.Label = decode_32bit ((uns8 **) ppData);
+	  zlog_info ("RRO subobject: Flags %x CType %x Label %x",
+		     pRrSubObj->u.Label.Flags, pRrSubObj->u.Label.CType,
+		     pRrSubObj->u.Label.Label);
+	  break;
+	default:
+	  zlog_err ("the type %d of subobject is unknown %s %d",
+		    pRrSubObj->SubObjHdr.Type, __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pPrev = pRrSubObj;
+    }
+  return E_OK;
+}
+
+E_RC
+AdSpecDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+	       uns32 RemainingLen)
+{
+  pRsvpPkt->ReceivedAdSpec.Resvd = decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.MsgLen = decode_16bit ((uns8 **) ppData);
+
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.PerServHdr.PerServHdr =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.PerServHdr.BreakBitAndResvd =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.PerServHdr.Length =
+    decode_16bit ((uns8 **) ppData);
+
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param4Hdr.ParamID =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param4Hdr.ParamFlags =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param4Hdr.ParamLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.IS_HopCount =
+    decode_32bit ((uns8 **) ppData);
+
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param6Hdr.ParamID =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param6Hdr.ParamFlags =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param6Hdr.ParamLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.PathBW = decode_float ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param8Hdr.ParamID =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param8Hdr.ParamFlags =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param8Hdr.ParamLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.MinPathLatency =
+    decode_32bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param10Hdr.ParamID =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param10Hdr.ParamFlags =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param10Hdr.ParamLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.AdSpecGen.ComposedMTU =
+    decode_32bit ((uns8 **) ppData);
+
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.PerServHdr.PerServHdr =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.PerServHdr.BreakBitAndResvd =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.PerServHdr.Length =
+    decode_16bit ((uns8 **) ppData);
+
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param133Hdr.ParamID =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param133Hdr.ParamFlags =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param133Hdr.ParamLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Ctot = decode_32bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param134Hdr.ParamID =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param134Hdr.ParamFlags =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param134Hdr.ParamLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Dtot = decode_32bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param135Hdr.ParamID =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param135Hdr.ParamFlags =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param135Hdr.ParamLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Csum = decode_32bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param136Hdr.ParamID =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param136Hdr.ParamFlags =
+    decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param136Hdr.ParamLength =
+    decode_16bit ((uns8 **) ppData);
+  pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Dsum = decode_32bit ((uns8 **) ppData);
+  return E_OK;
+}
+
+E_RC
+OpaqueObjDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		  uns32 RemainingLen)
+{
+  zlog_warn ("inside of OpaqueObjDecoder");
+  if (pObjHdr->ClassNum == INTEGRITY_CLASS)
+    {
+      if ((pRsvpPkt->pIntegrityObj =
+	   (INTEGRITY_OBJ *) XMALLOC (MTYPE_RSVP,
+				      sizeof (OPAQUE_OBJ_LIST))) == NULL)
+	{
+	  return E_ERR;
+	}
+      memset (pRsvpPkt->pIntegrityObj, 0, sizeof (OPAQUE_OBJ_LIST));
+      pRsvpPkt->pIntegrityObj->ObjHdr = *pObjHdr;
+      if ((pRsvpPkt->pIntegrityObj->pData =
+	   (void *) XMALLOC (MTYPE_RSVP,
+			     pObjHdr->Length - sizeof (OBJ_HDR))) == NULL)
+	{
+	  XFREE (MTYPE_RSVP, pRsvpPkt->pIntegrityObj);
+	  return E_ERR;
+	}
+      memcpy (pRsvpPkt->pIntegrityObj->pData, *ppData,
+	      pObjHdr->Length - sizeof (OBJ_HDR));
+      (*((uns8 *) ppData)) += pObjHdr->Length - sizeof (OBJ_HDR);
+    }
+  else if (pObjHdr->ClassNum == POLICY_DATA_CLASS)
+    {
+      if ((pRsvpPkt->pPolicyDataObj =
+	   (POLICY_DATA_OBJ *) XMALLOC (MTYPE_RSVP,
+					sizeof (OPAQUE_OBJ_LIST))) == NULL)
+	{
+	  return E_ERR;
+	}
+      memset (pRsvpPkt->pPolicyDataObj, 0, sizeof (OPAQUE_OBJ_LIST));
+      pRsvpPkt->pPolicyDataObj->ObjHdr = *pObjHdr;
+      if ((pRsvpPkt->pPolicyDataObj->pData =
+	   (void *) XMALLOC (MTYPE_RSVP,
+			     pObjHdr->Length - sizeof (OBJ_HDR))) == NULL)
+	{
+	  XFREE (MTYPE_RSVP, pRsvpPkt->pPolicyDataObj);
+	  return E_ERR;
+	}
+      memcpy (pRsvpPkt->pPolicyDataObj->pData, *ppData,
+	      pObjHdr->Length - sizeof (OBJ_HDR));
+      ((*(uns8 *) ppData)) += pObjHdr->Length - sizeof (OBJ_HDR);
+    }
+  else if ((pObjHdr->ClassNum != 0) && (pObjHdr->Length != 0))
+    {
+      OPAQUE_OBJ_LIST *pOpaqueObjTail =
+	pRsvpPkt->pOpaqueObjList, *pOpaqueObjPrev = NULL;
+      if (pOpaqueObjTail != NULL)
+	{
+	  while (pOpaqueObjTail->next != NULL)
+	    {
+	      pOpaqueObjTail = pOpaqueObjTail->next;
+	    }
+	}
+      if (pOpaqueObjTail != NULL)
+	{
+	  if ((pOpaqueObjTail->next =
+	       (OPAQUE_OBJ_LIST *) XMALLOC (MTYPE_RSVP,
+					    sizeof (OPAQUE_OBJ_LIST))) ==
+	      NULL)
+	    {
+	      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  pOpaqueObjPrev = pOpaqueObjTail;
+	  pOpaqueObjTail = pOpaqueObjTail->next;
+	}
+      else
+	{
+	  pOpaqueObjTail = pRsvpPkt->pOpaqueObjList =
+	    (OPAQUE_OBJ_LIST *) XMALLOC (MTYPE_RSVP,
+					 sizeof (OPAQUE_OBJ_LIST));
+	  if (pOpaqueObjTail == NULL)
+	    {
+	      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	}
+      memset (pOpaqueObjTail, 0, sizeof (OPAQUE_OBJ_LIST));
+      pOpaqueObjTail->ObjHdr = *pObjHdr;
+      if ((pOpaqueObjTail->pData =
+	   (void *) XMALLOC (MTYPE_RSVP,
+			     pObjHdr->Length - sizeof (OBJ_HDR))) == NULL)
+	{
+	  if (pOpaqueObjPrev == NULL)
+	    {
+	      pRsvpPkt->pOpaqueObjList = NULL;
+	    }
+	  else
+	    {
+	      pOpaqueObjPrev->next = NULL;
+	    }
+	  zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	  XFREE (MTYPE_RSVP, pOpaqueObjTail);
+	  return E_ERR;
+	}
+      memcpy (pOpaqueObjTail->pData, *ppData,
+	      pObjHdr->Length - sizeof (OBJ_HDR));
+      ((*(uns8 *) ppData)) += pObjHdr->Length - sizeof (OBJ_HDR);
+    }
+  return E_OK;
+}
+
+E_RC
+FlowSpecDecoder (void **ppData, FLOW_SPEC_OBJ * pFlowSpec)
+{
+  pFlowSpec->MsgHdr.VersionResvd = decode_16bit ((uns8 **) ppData);
+  pFlowSpec->MsgHdr.MessageLength = decode_16bit ((uns8 **) ppData);
+  pFlowSpec->ServHdr.ServHdr = decode_8bit ((uns8 **) ppData);
+  pFlowSpec->ServHdr.Resvd = decode_8bit ((uns8 **) ppData);
+  pFlowSpec->ServHdr.ServLength = decode_16bit ((uns8 **) ppData);
+  pFlowSpec->ParamHdr.ParamID = decode_8bit ((uns8 **) ppData);
+  pFlowSpec->ParamHdr.ParamFlags = decode_8bit ((uns8 **) ppData);
+  pFlowSpec->ParamHdr.ParamLength = decode_16bit ((uns8 **) ppData);
+  if (pFlowSpec->ServHdr.ServHdr == FLOW_SPEC_CTRL_LOAD_SERV_NUMBER)
+    {
+      pFlowSpec->u.CtrlLoad.TockenBucketRate =
+	decode_float ((uns8 **) ppData);
+      pFlowSpec->u.CtrlLoad.TockenBucketSize =
+	decode_float ((uns8 **) ppData);
+      pFlowSpec->u.CtrlLoad.PeakDataRate = decode_float ((uns8 **) ppData);
+      zlog_info ("FLOW_SPEC - data rate %f",
+		 pFlowSpec->u.CtrlLoad.PeakDataRate);
+      pFlowSpec->u.CtrlLoad.MinPolicedUnit = decode_float ((uns8 **) ppData);
+      pFlowSpec->u.CtrlLoad.MaxPacketSize = decode_float ((uns8 **) ppData);
+    }
+  else if (pFlowSpec->ServHdr.ServHdr == FLOW_SPEC_GUAR_SERV_NUMBER)
+    {
+      pFlowSpec->u.Guar.CtrlLoad.TockenBucketRate =
+	decode_float ((uns8 **) ppData);
+      pFlowSpec->u.Guar.CtrlLoad.TockenBucketSize =
+	decode_float ((uns8 **) ppData);
+      pFlowSpec->u.Guar.CtrlLoad.PeakDataRate =
+	decode_float ((uns8 **) ppData);
+      zlog_info ("FLOW_SPEC1 - data rate %f",
+		 pFlowSpec->u.Guar.CtrlLoad.PeakDataRate);
+      pFlowSpec->u.Guar.CtrlLoad.MinPolicedUnit =
+	decode_float ((uns8 **) ppData);
+      pFlowSpec->u.Guar.CtrlLoad.MaxPacketSize =
+	decode_float ((uns8 **) ppData);
+      pFlowSpec->u.Guar.GuarSpecificParamHdr.ParamID =
+	decode_8bit ((uns8 **) ppData);
+      pFlowSpec->u.Guar.GuarSpecificParamHdr.ParamFlags =
+	decode_8bit ((uns8 **) ppData);
+      pFlowSpec->u.Guar.GuarSpecificParamHdr.ParamLength =
+	decode_16bit ((uns8 **) ppData);
+      pFlowSpec->u.Guar.Rate = decode_float ((uns8 **) ppData);
+      pFlowSpec->u.Guar.SlackTerm = decode_32bit ((uns8 **) ppData);
+    }
+  else
+    {
+      zlog_err ("Unknown FlowSpec %d", pFlowSpec->ServHdr.ServHdr);
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+E_RC
+FilterSpecDecoder (void **ppData, FILTER_SPEC_OBJ * pFilterSpec)
+{
+  pFilterSpec->IpAddr = decode_32bit ((uns8 **) ppData);
+  pFilterSpec->Resvd = decode_16bit ((uns8 **) ppData);
+  pFilterSpec->LspId = decode_16bit ((uns8 **) ppData);
+  zlog_info ("FILTER_SPEC %x %x", pFilterSpec->IpAddr, pFilterSpec->LspId);
+  return E_OK;
+}
+
+E_RC
+LabelDecoder (void **ppData, LABEL_OBJ * pLabelObj)
+{
+  pLabelObj->Label = decode_32bit ((uns8 **) ppData);
+  zlog_info ("label decoded %x", pLabelObj->Label);
+  return E_OK;
+}
+
+E_RC
+FlowDescriptorDecoder (void **ppData, RSVP_PKT * pRsvpPkt, uns32 RemainingLen)
+{
+  FLOW_SPEC_OBJ *pFlowSpecObj, FlowSpec;
+  FILTER_LIST *pFilterListTail = NULL, *pFilterListNew;
+  FILTER_SPEC_DATA *pFilterSpecData = NULL;
+  OBJ_HDR *pObjHdr;
+  enum FlowDescrDecodeStates
+  {
+    FLOW_SPEC_DECODED,
+    FILTER_SPEC_DECODED,
+    LABEL_DECODED,
+    OPAQ_DECODED
+  } State;
+
+  memset (&FlowSpec, 0, sizeof (FLOW_SPEC_OBJ));
+  pFlowSpecObj = &FlowSpec;
+
+  DECODE_OBJ_HDR if (pObjHdr->ClassNum != FLOW_SPEC_CLASS)
+    {
+      if (pObjHdr->ClassNum == FILTER_SPEC_CLASS)
+	{
+	  (*(char *) ppData) -= sizeof (OBJ_HDR);
+	  goto flow_spec_missing;
+	}
+      zlog_err ("Expected flowspec is not found");
+      return E_ERR;
+    }
+  if (FlowSpecDecoder (ppData, pFlowSpecObj) != E_OK)
+    {
+      zlog_err ("Cannot decode FlowSpec");
+      return E_ERR;
+    }
+flow_spec_missing:
+
+  State = FLOW_SPEC_DECODED;
+  RemainingLen -= pObjHdr->Length;
+  while (RemainingLen)
+    {
+      DECODE_OBJ_HDR switch (pObjHdr->ClassNum)
+	{
+	case FILTER_SPEC_CLASS:
+	  if (State == OPAQ_DECODED)
+	    {
+	      zlog_err ("FILTER_SPEC after OPAQ");
+	      return E_ERR;
+	    }
+	  if ((pFilterListNew =
+	       (FILTER_LIST *) XMALLOC (MTYPE_RSVP,
+					sizeof (FILTER_LIST))) == NULL)
+	    {
+	      zlog_err ("Memory allocation failed %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  if ((pFilterSpecData =
+	       (FILTER_SPEC_DATA *) XMALLOC (MTYPE_RSVP,
+					     sizeof (FILTER_SPEC_DATA))) ==
+	      NULL)
+	    {
+	      zlog_err ("Memory allocation failed %s %d", __FILE__, __LINE__);
+	      XFREE (MTYPE_RSVP, pFilterListNew);
+	      return E_ERR;
+	    }
+	  pFilterListNew->pFilterSpecData = pFilterSpecData;
+	  if (FilterSpecDecoder (ppData, &pFilterSpecData->FilterSpec) !=
+	      E_OK)
+	    {
+	      zlog_err ("Cannot decode filter spec");
+	      XFREE (MTYPE_RSVP, pFilterSpecData);
+	      XFREE (MTYPE_RSVP, pFilterListNew);
+	      return E_ERR;
+	    }
+	  memcpy (&pFilterSpecData->NewFlowSpec, pFlowSpecObj,
+		  sizeof (FLOW_SPEC_OBJ));
+	  pFilterSpecData->NewFlowSpecValid = 1;
+	  if (pFilterListTail == NULL)
+	    {
+	      pFilterListTail = pRsvpPkt->pFilterList = pFilterListNew;
+	    }
+	  else
+	    {
+	      pFilterListTail->next = pFilterListNew;
+	      pFilterListTail = pFilterListTail->next;
+	    }
+	  State = FILTER_SPEC_DECODED;
+	  break;
+	case LABEL_CLASS:
+	  if (State != FILTER_SPEC_DECODED)
+	    {
+	      zlog_err ("Label is not after FILTER_SPEC");
+	      return E_ERR;
+	    }
+	  if (LabelDecoder (ppData, &pFilterSpecData->ReceivedLabel) != E_OK)
+	    {
+	      zlog_err ("Cannot decode Label");
+	      return E_ERR;
+	    }
+	  State = LABEL_DECODED;
+	  break;
+	case RECORDED_ROUTE_CLASS:
+	  if (State != LABEL_DECODED)
+	    {
+	      zlog_err ("RRO is not after LABEL");
+	      return E_ERR;
+	    }
+	  if (RRO_Decoder (ppData, pRsvpPkt, pObjHdr, RemainingLen) != E_OK)
+	    {
+	      zlog_err ("Cannot decode RRO");
+	      return E_ERR;
+	    }
+	  pFilterSpecData->Rro.rr = pRsvpPkt->ReceivedRro.rr;
+	  pRsvpPkt->ReceivedRro.rr = NULL;
+	  break;
+	case FLOW_SPEC_CLASS:
+	  if (State == FLOW_SPEC_DECODED)
+	    {
+	      zlog_err ("FLOW_SPEC is after FLOW_SPEC");
+	      return E_ERR;
+	    }
+	  if (pRsvpPkt->Style.OptionVector2 != FF_STYLE_BITS)
+	    {
+	      zlog_err ("while SE style, FLOW_SPEC is already decoded");
+	      return E_ERR;
+	    }
+	  if (FlowSpecDecoder (ppData, pFlowSpecObj) != E_OK)
+	    {
+	      zlog_err ("Cannot decode FlowSpec");
+	      return E_ERR;
+	    }
+	  State = FLOW_SPEC_DECODED;
+	  break;
+	default:
+	  zlog_err ("object of unknown type %x %s %d", pObjHdr->ClassNum,
+		    __FILE__, __LINE__);
+	  (*(uns8 *) ppData) -= 4;
+	  return E_OK;
+	  /*if(OpaqueObjDecoder(ppData,pRsvpPkt,pObjHdr) != E_OK)
+	     {
+	     zlog_err("Cannot decode OPAQUE object");
+	     return E_ERR;
+	     }
+	     State = OPAQ_DECODED; */
+	}
+      RemainingLen -= pObjHdr->Length;
+    }
+  return E_OK;
+}
+
+E_RC
+StyleDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+	      uns32 RemainingLen)
+{
+  pRsvpPkt->Style.Flags = decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->Style.OptionVector1 = decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->Style.OptionVector2 = decode_16bit ((uns8 **) ppData);
+  zlog_info ("Style %x %x %x", pRsvpPkt->Style.Flags,
+	     pRsvpPkt->Style.OptionVector1, pRsvpPkt->Style.OptionVector2);
+  return FlowDescriptorDecoder (ppData, pRsvpPkt, RemainingLen - 4);
+}
+
+E_RC
+ErrSpecDecoder (void **ppData, RSVP_PKT * pRsvpPkt, OBJ_HDR * pObjHdr,
+		uns32 RemainingLen)
+{
+  pRsvpPkt->ErrorSpec.IpAddr = decode_32bit ((uns8 **) ppData);
+  pRsvpPkt->ErrorSpec.Flags = decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ErrorSpec.ErrCode = decode_8bit ((uns8 **) ppData);
+  pRsvpPkt->ErrorSpec.ErrVal = decode_16bit ((uns8 **) ppData);
+  return E_OK;
+}
+
+void
+InitRsvpDecoder ()
+{
+  memset (DecodeHandlers, 0, sizeof (DECODE_HANDLER) * (MAX_OBJS));
+  DecodeHandlers[SESSION_CLASS].pObjDecoder = SessionDecoder;
+  DecodeHandlers[RSVP_HOP_CLASS].pObjDecoder = RsvpHopDecoder;
+  DecodeHandlers[TIME_VALUES_CLASS].pObjDecoder = TimeValuesDecoder;
+  DecodeHandlers[SENDER_TEMPLATE_CLASS].pObjDecoder = SenderTemplateDecoder;
+  DecodeHandlers[LABEL_REQUEST_CLASS].pObjDecoder = LabelReqDecoder;
+  DecodeHandlers[EXPLICIT_ROUTE_CLASS].pObjDecoder = ERO_Decoder;
+  DecodeHandlers[SESSION_ATTRIBUTE_CLASS].pObjDecoder = SessionAttrDecoder;
+  DecodeHandlers[SENDER_TSPEC_CLASS].pObjDecoder = SenderTSpecDecoder;
+  DecodeHandlers[RECORDED_ROUTE_CLASS].pObjDecoder = RRO_Decoder;
+  DecodeHandlers[ADSPEC_CLASS].pObjDecoder = AdSpecDecoder;
+  DecodeHandlers[STYLE_CLASS].pObjDecoder = StyleDecoder;
+  DecodeHandlers[POLICY_DATA_CLASS].pObjDecoder = OpaqueObjDecoder;
+  DecodeHandlers[INTEGRITY_CLASS].pObjDecoder = OpaqueObjDecoder;
+  DecodeHandlers[ERR_SPEC_CLASS].pObjDecoder = ErrSpecDecoder;
+}
+
+E_RC
+DecodeAndProcessRsvpMsg (void *pPkt, int PktLen, uns32 IfIndex,
+			 IPV4_ADDR SrcIpAddr)
+{
+  RSVP_COMMON_HDR RsvpCommonHdr;
+  RSVP_PKT *pRsvpPkt;
+  uns8 *pData = pPkt;
+  void **ppData;
+  OBJ_HDR *pObjHdr;
+  uns32 InitialAddress = (uns32) pData;
+  uns16 CheckSum = 0;
+
+  if ((pRsvpPkt =
+       (RSVP_PKT *) XMALLOC (MTYPE_RSVP, sizeof (RSVP_PKT))) == NULL)
+    {
+      zlog_err ("memory allocation failed %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  memset (pRsvpPkt, 0, sizeof (RSVP_PKT));
+
+  DECODE_COMMON_HDR if ((RsvpCommonHdr.VersionFlags & 0xF0) != RSVP_VERSION)
+    {
+      zlog_err (" wrong RSVP version %d %d", RsvpCommonHdr.VersionFlags,
+		RsvpCommonHdr.MsgType);
+    }
+  else
+    {
+      zlog_debug ("RSVP message of right version");
+      rsvp_calc_pkt_cksum (pPkt, PktLen, &CheckSum);
+      if (RsvpCommonHdr.CheckSum != CheckSum)
+	{
+	  printf ("received checksum %x calculated %x\n",
+		  RsvpCommonHdr.CheckSum, CheckSum);
+	}
+      else
+	{
+	  //zlog_info("received checksum is OK");
+	}
+    }
+  //PktLen -= sizeof(RSVP_COMMON_HDR);
+
+  while (((uns32) pData - InitialAddress) < PktLen)
+    {
+      ppData = (void **) &pData;
+      DECODE_OBJ_HDR
+	if (DecodeHandlers[pObjHdr->ClassNum].pObjDecoder != NULL)
+	{
+	  if (DecodeHandlers[pObjHdr->ClassNum].pObjDecoder (ppData,
+							     pRsvpPkt,
+							     pObjHdr,
+							     (PktLen -
+							      ((uns32) pData -
+							       InitialAddress)))
+	      != E_OK)
+	    {
+	      zlog_err ("Object decoding failed");
+	    }
+	  else
+	    {
+	      //zlog_debug("Object decoded");
+	    }
+	}
+      else
+	{
+	  //zlog_warn("The object of class type %d is not supported %d",pObjHdr->ClassNum,pObjHdr->Length);
+	  //((char *)pData) += pObjHdr->Length;
+	  OpaqueObjDecoder (ppData, pRsvpPkt, pObjHdr,
+			    (PktLen - ((uns32) pData - InitialAddress)));
+	}
+    }
+  switch (RsvpCommonHdr.MsgType)
+    {
+    case PATH_MSG:
+      DumpPathMsg (pRsvpPkt, NULL);
+      if (ProcessRsvpPathMessage
+	  (pRsvpPkt, IfIndex, SrcIpAddr, RsvpCommonHdr.SendTTL) != E_OK)
+	{
+	  zlog_err ("RSVP PATH message processing failed");
+	}
+      break;
+    case RESV_MSG:
+      DumpResvMsg (pRsvpPkt, NULL);
+      if (ProcessRsvpResvMessage (pRsvpPkt) != E_OK)
+	{
+	  zlog_err ("An error on RESV processing");
+	}
+      break;
+    case PATH_ERR_MSG:
+      DumpPathErrMsg (pRsvpPkt, NULL);
+      if (ProcessRsvpPathErrMessage
+	  (pRsvpPkt, IfIndex, SrcIpAddr, RsvpCommonHdr.SendTTL) != E_OK)
+	{
+	  zlog_err ("An error on PATH_ERR processing");
+	}
+      break;
+    case RESV_ERR_MSG:
+      DumpResvErrMsg (pRsvpPkt, NULL);
+      if (ProcessRsvpResvErrMessage (pRsvpPkt) != E_OK)
+	{
+	  zlog_err ("An error on RESV ERR message processing");
+	}
+      break;
+    case PATH_TEAR_MSG:
+      DumpPathTearMsg (pRsvpPkt, NULL);
+      if (ProcessRsvpPathTearMessage
+	  (pRsvpPkt, IfIndex, SrcIpAddr, RsvpCommonHdr.SendTTL) != E_OK)
+	{
+	  zlog_err ("An error on PATH_TEAR processing");
+	}
+      break;
+    case RESV_TEAR_MSG:
+      DumpResvTearMsg (pRsvpPkt, NULL);
+      if (ProcessRsvpResvTearMessage (pRsvpPkt) != E_OK)
+	{
+	  zlog_err ("An error on RESV_TEAR processing");
+	}
+      break;
+    case RESV_CONF_MSG:
+      zlog_warn ("RESV Conf message is not supported");
+      break;
+    default:
+      zlog_err ("RSVP message of unknown type is received");
+    }
+  //FreeRsvpPkt(&RsvpPkt);
+  return E_OK;
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_decode.h quagga-mpls/rsvpd/rsvp_decode.h
--- quagga-0.99.10/rsvpd/rsvp_decode.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_decode.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,7 @@
+#ifndef __RSVP_DECODE_H_
+#define __RSVP_DECODE_H_
+
+E_RC DecodeAndProcessRsvpMsg (void *pPkt, int PktLen, uns32 IfIndex,
+			      IPV4_ADDR SrcIpAddr);
+void InitRsvpDecoder ();
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvp_encode.c quagga-mpls/rsvpd/rsvp_encode.c
--- quagga-0.99.10/rsvpd/rsvp_encode.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_encode.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,864 @@
+/* Module:   rsvp_encode.c
+   Contains: RSVP packet encoding functions which make
+   the packet ready to send.
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+
+#include "rsvp.h"
+
+void
+encode_32bit (uns8 ** stream, uns32 val)
+{
+  *(*stream)++ = (uns8) (val >> 24);
+  *(*stream)++ = (uns8) (val >> 16);
+  *(*stream)++ = (uns8) (val >> 8);
+  *(*stream)++ = (uns8) (val);
+}
+
+void
+encode_24bit (uns8 ** stream, uns32 val)
+{
+  *(*stream)++ = (uns8) (val >> 16);
+  *(*stream)++ = (uns8) (val >> 8);
+  *(*stream)++ = (uns8) (val);
+}
+
+
+void
+encode_16bit (uns8 ** stream, uns32 val)
+{
+  *(*stream)++ = (uns8) (val >> 8);
+  *(*stream)++ = (uns8) (val);
+}
+
+
+void
+encode_8bit (uns8 ** stream, uns32 val)
+{
+  *(*stream)++ = (uns8) (val);
+}
+
+void
+encode_float (uns8 ** stream, float f)
+{
+  *((uns32 *) (*stream)) = htonl (*((uns32 *) & (f)));
+  (*stream) += 4;
+}
+
+void
+rsvp_calc_pkt_cksum (char *u, unsigned int PktLen, uns16 * const pCksum)
+{
+  uns32 Cksum32;
+  unsigned int Offset;
+
+  uns8 *p8;
+
+  Cksum32 = 0;
+  Offset = 0;
+  while (PktLen > 1)
+    {
+      p8 = (uns8 *) (u + Offset);
+
+      if (Offset != 2)		/* Offset 2 is the checksum word.  We don't add this in */
+	{
+	  Cksum32 += (uns32) ntohs (*((uns16 *) p8));
+	  if ((Cksum32 & 0x80000000) != 0)
+	    Cksum32 = (Cksum32 & 0xFFFF) + (Cksum32 >> 16);
+	}
+      Offset += 2;
+      PktLen -= 2;
+    }
+
+  if (PktLen > 0)		/* Odd length? */
+    {
+      p8 = (uns8 *) (u + Offset);
+
+      Cksum32 += (uns32) * p8;
+    }
+
+  while ((Cksum32 >> 16) != 0)
+    Cksum32 = (Cksum32 & 0xFFFF) + (Cksum32 >> 16);
+
+  *pCksum = (uns16) (~Cksum32);
+}
+
+static char BigBuffer[1500];
+
+#define ENCODE_COMMON_HDR(VersionFlags,MsgType,CheckSum,SendTTL,Resvd,RsvpLength) \
+{\
+    encode_8bit((uns8 **)ppData,VersionFlags); /* VersionFlags */ \
+    encode_8bit((uns8 **)ppData,MsgType);/* MsgType */ \
+    pCheckSum = (uns16 *)(*ppData); \
+    encode_16bit((uns8 **)ppData,CheckSum);/* CheckSum */ \
+    encode_8bit((uns8 **)ppData,SendTTL);/* SendTTL */ \
+    encode_8bit((uns8 **)ppData,Resvd);/* Resvd */ \
+    pRsvpLength = (uns16*)(*ppData); \
+    encode_16bit((uns8 **)ppData,RsvpLength);/* RsvpLength */\
+    PktLen += 8; \
+}
+
+#define ENCODE_OBJ_HDR(Length,ClassNum,CType) \
+{\
+    pVariableLengthObj = (uns16 *)*ppData; \
+    encode_16bit((uns8 **)ppData,Length); /* Length */\
+    encode_8bit((uns8 **)ppData,ClassNum);/* ClassNum */\
+    encode_8bit((uns8 **)ppData,CType);/* CType */\
+    zlog_info("obj %d ctype %d len %d",ClassNum,CType,Length);\
+    PktLen += 4; \
+}
+
+#define ENCODE_SESSION \
+{\
+    encode_32bit((uns8 **)ppData,pRsvpPkt->Session.Dest);\
+    encode_16bit((uns8 **)ppData,pRsvpPkt->Session.Resvd);\
+    encode_16bit((uns8 **)ppData,pRsvpPkt->Session.TunnelId);\
+    encode_32bit((uns8 **)ppData,pRsvpPkt->Session.ExtTunelId);\
+    PktLen += 12; \
+}
+
+#define ENCODE_RSVP_HOP \
+{\
+    encode_32bit((uns8 **)ppData,pRsvpPkt->SentRsvpHop.PHop); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->SentRsvpHop.LIH); \
+    PktLen += 8; \
+}
+
+#define ENCODE_TIME_VALUES \
+{ \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->TimeValues.TimeValues); \
+    PktLen += 4; \
+}
+
+#define ENCODE_STYLE \
+{ \
+   encode_8bit((uns8 **)ppData,pRsvpPkt->Style.Flags); \
+   encode_8bit((uns8 **)ppData,pRsvpPkt->Style.OptionVector1); \
+   encode_16bit((uns8 **)ppData,pRsvpPkt->Style.OptionVector2); \
+   PktLen += 4; \
+}
+
+#define ENCODE_SENDER_TEMPLATE \
+{ \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->SenderTemplate.IpAddr); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->SenderTemplate.Resvd); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->SenderTemplate.LspId); \
+    PktLen += 8; \
+}
+
+#define ENCODE_LABEL_REQUEST \
+{ \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->LabelRequest.Resvd); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->LabelRequest.L3Pid); \
+    PktLen += 4; \
+}
+
+#define ENCODE_ERO \
+{ \
+    ER_SUBOBJ *pErSubObj = pRsvpPkt->ReceivedEro.er;\
+    VariableLengthObj = sizeof(OBJ_HDR); /* for obj header */ \
+    while(pErSubObj != NULL) \
+    { \
+        zlog_info("encoding of %x",pErSubObj->u.Ipv4.IpAddress);\
+        encode_8bit((uns8 **)ppData,pErSubObj->SubObjHdr.LType);\
+        encode_8bit((uns8 **)ppData,pErSubObj->SubObjHdr.Length);\
+        PktLen += 2; \
+        VariableLengthObj += 2; \
+        switch(pErSubObj->SubObjHdr.LType & 0x7F) \
+        {\
+        case ERO_SUBTYPE_IPV4:\
+            encode_32bit((uns8 **)ppData,pErSubObj->u.Ipv4.IpAddress);\
+            encode_8bit((uns8 **)ppData,pErSubObj->u.Ipv4.PrefixLength);\
+            encode_8bit((uns8 **)ppData,pErSubObj->u.Ipv4.Resvd);\
+            VariableLengthObj += 6; \
+            PktLen += 6; \
+            break;\
+        default:\
+            zlog_err("the type %d of subobject is unknown %s %d",(pErSubObj->SubObjHdr.LType & 0x7F),__FILE__,__LINE__);\
+            return E_ERR;\
+        }\
+        pErSubObj = pErSubObj->next; \
+    }\
+    pErSubObj = pRsvpPkt->SentEro.er;\
+    while(pErSubObj != NULL)\
+    {\
+        zlog_info("encoding2 of %x",pErSubObj->u.Ipv4.IpAddress);\
+        encode_8bit((uns8 **)ppData,pErSubObj->SubObjHdr.LType);\
+        encode_8bit((uns8 **)ppData,pErSubObj->SubObjHdr.Length);\
+        PktLen += 2; \
+        VariableLengthObj += 2; \
+        switch(pErSubObj->SubObjHdr.LType & 0x7F)\
+        {\
+        case ERO_SUBTYPE_IPV4:\
+            encode_32bit((uns8 **)ppData,pErSubObj->u.Ipv4.IpAddress);\
+            encode_8bit((uns8 **)ppData,pErSubObj->u.Ipv4.PrefixLength);\
+            encode_8bit((uns8 **)ppData,pErSubObj->u.Ipv4.Resvd);\
+            PktLen += 6; \
+            VariableLengthObj += 6; \
+            break;\
+        default:\
+            zlog_err("the type %d of subobject is unknown %s %d",(pErSubObj->SubObjHdr.LType & 0x7F),__FILE__,__LINE__);\
+            return E_ERR;\
+        }\
+        pErSubObj = pErSubObj->next; \
+    }\
+}
+
+#define ENCODE_SESSION_ATTRIBUTES \
+{ \
+    VariableLengthObj = sizeof(OBJ_HDR); /* for obj header */ \
+    if(pRsvpPkt->SessionAttributes.CType == SESSION_ATTRIBUTES_CLASS_TYPE) \
+    { \
+        encode_8bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttr.SetPrio); \
+        encode_8bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttr.HoldPrio); \
+        encode_8bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttr.Flags); \
+        encode_8bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttr.NameLength); \
+        PktLen += 4; \
+        VariableLengthObj += 4; \
+        if(pRsvpPkt->SessionAttributes.u.SessAttr.NameLength % 4) \
+        { \
+            zlog_err("Session name length is %d must be multiple of 4",pRsvpPkt->SessionAttributes.u.SessAttr.NameLength); \
+        } \
+        if(pRsvpPkt->SessionAttributes.u.SessAttr.NameLength < 8) \
+        { \
+            zlog_err("Session name length is %d must be at least 8",pRsvpPkt->SessionAttributes.u.SessAttr.NameLength); \
+        }\
+        if(pRsvpPkt->SessionAttributes.u.SessAttr.NameLength != 0) \
+        { \
+            char *pP = *ppData; \
+            strncpy(pP,pRsvpPkt->SessionAttributes.u.SessAttr.SessionName,pRsvpPkt->SessionAttributes.u.SessAttr.NameLength); \
+            PktLen += pRsvpPkt->SessionAttributes.u.SessAttr.NameLength; \
+            pP += pRsvpPkt->SessionAttributes.u.SessAttr.NameLength; \
+            *ppData = pP; \
+            VariableLengthObj += pRsvpPkt->SessionAttributes.u.SessAttr.NameLength; \
+        } \
+    } \
+    else if(pRsvpPkt->SessionAttributes.CType == SESSION_ATTRIBUTES_RA_CLASS_TYPE) \
+    { \
+        encode_32bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttrRa.ExcludeAny); \
+        encode_32bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAny); \
+        encode_32bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAll); \
+        encode_8bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttrRa.SetPrio); \
+        encode_8bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttrRa.HoldPrio); \
+        encode_8bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttrRa.Flags); \
+        encode_8bit((uns8 **)ppData,pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength); \
+        PktLen += 16; \
+        VariableLengthObj += 16; \
+        if(pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength % 4) \
+        { \
+            zlog_err("Session name length is %d must be multiple of 4",pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength); \
+        } \
+        if(pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength < 8) \
+        { \
+            zlog_err("Session name length is %d must be at least 8",pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength); \
+        } \
+        if(pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength != 0) \
+        { \
+            char *pP = *ppData; \
+            strncpy(pP,pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName,pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength); \
+            PktLen += pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength; \
+            pP += pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength; \
+            *ppData = pP; \
+            VariableLengthObj += pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength; \
+        } \
+    } \
+    else \
+    { \
+        zlog_err("unknown session attributes object class type %d",pRsvpPkt->SessionAttributes.CType); \
+    } \
+    zlog_debug("Session Attributes"); \
+}
+
+#define ENCODE_SENDER_TSPEC \
+{ \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.MessageHdr.VersionResvd); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.MessageHdr.MessageLength); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.ServHdr.ServHdr); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.ServHdr.Resvd); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.ServHdr.ServLength); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.ParamHdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.ParamHdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.ParamHdr.ParamLength); \
+    encode_float((uns8 **)ppData,pRsvpPkt->SenderTSpec.TockenBucketRate); \
+    encode_float((uns8 **)ppData,pRsvpPkt->SenderTSpec.TockenBucketSize); \
+    encode_float((uns8 **)ppData,pRsvpPkt->SenderTSpec.PeakDataRate); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.MinPolicedUnit); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->SenderTSpec.MaxPacketSize); \
+    PktLen += 32; \
+}
+
+#define ENCODE_RRO \
+{ \
+    RR_SUBOBJ *pRrSubObj = pRsvpPkt->ReceivedRro.rr; \
+    VariableLengthObj = sizeof(OBJ_HDR); /* for obj header */ \
+    while(pRrSubObj != NULL) \
+    { \
+        encode_8bit((uns8 **)ppData,pRrSubObj->SubObjHdr.Type); \
+        encode_8bit((uns8 **)ppData,pRrSubObj->SubObjHdr.Length); \
+        PktLen += 2; \
+        VariableLengthObj += 2; \
+        if(pRrSubObj->SubObjHdr.Length != 8) \
+        { \
+            zlog_err(" the length of subobject is not 8!!!"); \
+        } \
+        switch(pRrSubObj->SubObjHdr.Type) \
+        { \
+        case RRO_SUBTYPE_IPV4: \
+            encode_32bit((uns8 **)ppData,pRrSubObj->u.Ipv4.IpAddr); \
+            encode_8bit((uns8 **)ppData,pRrSubObj->u.Ipv4.PrefixLen); \
+            encode_8bit((uns8 **)ppData,pRrSubObj->u.Ipv4.Flags); \
+            zlog_info("RRO sub - IP: %x",pRrSubObj->u.Ipv4.IpAddr);\
+            PktLen += 6; \
+            VariableLengthObj += 6; \
+            break; \
+        case RRO_SUBTYPE_LABEL:\
+            encode_8bit((uns8 **)ppData,pRrSubObj->u.Label.Flags); \
+            encode_8bit((uns8 **)ppData,pRrSubObj->u.Label.CType); \
+            encode_32bit((uns8 **)ppData,pRrSubObj->u.Label.Label); \
+            zlog_info("RRO sub - Label: %x",pRrSubObj->u.Label.Label);\
+            PktLen += 6; \
+            VariableLengthObj += 6; \
+            break; \
+        default: \
+            zlog_err("the type %d of subobject is unknown %s %d",pRrSubObj->SubObjHdr.Type,__FILE__,__LINE__); \
+            return E_ERR;\
+        } \
+        pRrSubObj = pRrSubObj->next; \
+    } \
+    pRrSubObj = pRsvpPkt->AddedRro.rr; \
+    while(pRrSubObj != NULL) \
+    { \
+        encode_8bit((uns8 **)ppData,pRrSubObj->SubObjHdr.Type); \
+        encode_8bit((uns8 **)ppData,pRrSubObj->SubObjHdr.Length); \
+        PktLen += 2; \
+        VariableLengthObj += 2; \
+        if(pRrSubObj->SubObjHdr.Length != 8) \
+        { \
+            zlog_err(" the length of subobject is not 8!!!"); \
+        } \
+        switch(pRrSubObj->SubObjHdr.Type) \
+        { \
+        case RRO_SUBTYPE_IPV4: \
+            encode_32bit((uns8 **)ppData,pRrSubObj->u.Ipv4.IpAddr); \
+            encode_8bit((uns8 **)ppData,pRrSubObj->u.Ipv4.PrefixLen); \
+            encode_8bit((uns8 **)ppData,pRrSubObj->u.Ipv4.Flags); \
+            zlog_info(" RRO sub - IP: %x",pRrSubObj->u.Ipv4.IpAddr);\
+            PktLen += 6; \
+            VariableLengthObj += 6; \
+            break; \
+        case RRO_SUBTYPE_LABEL:\
+            encode_8bit((uns8 **)ppData,pRrSubObj->u.Label.Flags); \
+            encode_8bit((uns8 **)ppData,pRrSubObj->u.Label.CType); \
+            encode_32bit((uns8 **)ppData,pRrSubObj->u.Label.Label); \
+            zlog_info(" RRO sub - Label: %x",pRrSubObj->u.Label.Label);\
+            PktLen += 6; \
+            VariableLengthObj += 6; \
+            break; \
+        default: \
+            zlog_err("the type %d of subobject is unknown %s %d",pRrSubObj->SubObjHdr.Type,__FILE__,__LINE__); \
+            return E_ERR;\
+        } \
+        pRrSubObj = pRrSubObj->next; \
+    } \
+}
+
+#define ENCODE_ADSPEC \
+{ \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.Resvd); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.MsgLen); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.PerServHdr.PerServHdr); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.PerServHdr.BreakBitAndResvd); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.PerServHdr.Length); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param4Hdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param4Hdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param4Hdr.ParamLength); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.IS_HopCount); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param6Hdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param6Hdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param6Hdr.ParamLength); \
+    encode_float((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.PathBW); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param8Hdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param8Hdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param8Hdr.ParamLength); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.MinPathLatency); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param10Hdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param10Hdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.Param10Hdr.ParamLength); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.AdSpecGen.ComposedMTU); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.PerServHdr.PerServHdr); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.PerServHdr.BreakBitAndResvd); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.PerServHdr.Length); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param133Hdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param133Hdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param133Hdr.ParamLength); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Ctot); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param134Hdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param134Hdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param134Hdr.ParamLength); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Dtot); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param135Hdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param135Hdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param135Hdr.ParamLength); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Csum); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param136Hdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param136Hdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Param136Hdr.ParamLength); \
+    encode_32bit((uns8 **)ppData,pRsvpPkt->ReceivedAdSpec.GuarAdSpec.Dsum); \
+    PktLen += 76; \
+}
+
+#define ENCODE_ERR_SPEC \
+{ \
+   encode_32bit((uns8 **)ppData,pRsvpPkt->ErrorSpec.IpAddr); \
+   encode_8bit((uns8 **)ppData,pRsvpPkt->ErrorSpec.Flags); \
+   encode_8bit((uns8 **)ppData,pRsvpPkt->ErrorSpec.ErrCode); \
+   encode_16bit((uns8 **)ppData,pRsvpPkt->ErrorSpec.ErrVal); \
+}
+
+#define ENCODE_FLOW_SPEC \
+{ \
+    if(pFlowSpecObj->ServHdr.ServHdr == FLOW_SPEC_CTRL_LOAD_SERV_NUMBER) \
+    { \
+       ENCODE_OBJ_HDR(sizeof(MSG_HDR)+sizeof(SERV_HDR)+sizeof(PARAM_HDR)+sizeof(CTRL_LOAD_FLOW_SPEC)+sizeof(OBJ_HDR),\
+                      FLOW_SPEC_CLASS,\
+                      FLOW_SPEC_INTSERV_CTYPE)\
+    } \
+    else if(pFlowSpecObj->ServHdr.ServHdr == FLOW_SPEC_GUAR_SERV_NUMBER)\
+    { \
+       ENCODE_OBJ_HDR(sizeof(MSG_HDR)+sizeof(SERV_HDR)+sizeof(PARAM_HDR)+sizeof(GUAR_FLOW_SPEC)+sizeof(OBJ_HDR),\
+                      FLOW_SPEC_CLASS,\
+                      FLOW_SPEC_INTSERV_CTYPE) \
+    } \
+    else \
+    { \
+       zlog_err("FlowSpec of unknown type"); \
+    } \
+    encode_16bit((uns8 **)ppData,pFlowSpecObj->MsgHdr.VersionResvd); \
+    encode_16bit((uns8 **)ppData,pFlowSpecObj->MsgHdr.MessageLength); \
+    encode_8bit((uns8 **)ppData,pFlowSpecObj->ServHdr.ServHdr); \
+    encode_8bit((uns8 **)ppData,pFlowSpecObj->ServHdr.Resvd); \
+    encode_16bit((uns8 **)ppData,pFlowSpecObj->ServHdr.ServLength); \
+    encode_8bit((uns8 **)ppData,pFlowSpecObj->ParamHdr.ParamID); \
+    encode_8bit((uns8 **)ppData,pFlowSpecObj->ParamHdr.ParamFlags); \
+    encode_16bit((uns8 **)ppData,pFlowSpecObj->ParamHdr.ParamLength); \
+    PktLen += 12; \
+    if(pFlowSpecObj->ServHdr.ServHdr == FLOW_SPEC_CTRL_LOAD_SERV_NUMBER) \
+    { \
+       encode_float((uns8 **)ppData,pFlowSpecObj->u.CtrlLoad.TockenBucketRate);\
+       encode_float((uns8 **)ppData,pFlowSpecObj->u.CtrlLoad.TockenBucketSize);\
+       encode_float((uns8 **)ppData,pFlowSpecObj->u.CtrlLoad.PeakDataRate);\
+       encode_float((uns8 **)ppData,pFlowSpecObj->u.CtrlLoad.MinPolicedUnit);\
+       encode_float((uns8 **)ppData,pFlowSpecObj->u.CtrlLoad.MaxPacketSize);\
+       PktLen += 20;\
+    }\
+    else if(pFlowSpecObj->ServHdr.ServHdr == FLOW_SPEC_GUAR_SERV_NUMBER)\
+    {\
+      encode_float((uns8 **)ppData,pFlowSpecObj->u.Guar.CtrlLoad.TockenBucketRate);\
+      encode_float((uns8 **)ppData,pFlowSpecObj->u.Guar.CtrlLoad.TockenBucketSize);\
+      encode_float((uns8 **)ppData,pFlowSpecObj->u.Guar.CtrlLoad.PeakDataRate);\
+      encode_float((uns8 **)ppData,pFlowSpecObj->u.Guar.CtrlLoad.MinPolicedUnit);\
+      encode_float((uns8 **)ppData,pFlowSpecObj->u.Guar.CtrlLoad.MaxPacketSize);\
+      encode_8bit((uns8 **)ppData,pFlowSpecObj->u.Guar.GuarSpecificParamHdr.ParamID);\
+      encode_8bit((uns8 **)ppData,pFlowSpecObj->u.Guar.GuarSpecificParamHdr.ParamFlags);\
+      encode_16bit((uns8 **)ppData,pFlowSpecObj->u.Guar.GuarSpecificParamHdr.ParamLength);\
+      encode_float((uns8 **)ppData,pFlowSpecObj->u.Guar.Rate);\
+      encode_32bit((uns8 **)ppData,pFlowSpecObj->u.Guar.SlackTerm);\
+      PktLen += 32;\
+    }\
+}
+
+#define ENCODE_FILTER_SPEC \
+{\
+  pFilterSpecData = pFilterList->pFilterSpecData;\
+  ENCODE_OBJ_HDR(sizeof(FILTER_SPEC_OBJ)+sizeof(OBJ_HDR),FILTER_SPEC_CLASS,FILTER_SPEC_LSP_IPV4_CTYPE)\
+  encode_32bit((uns8 **)ppData,pFilterSpecData->FilterSpec.IpAddr);\
+  encode_16bit((uns8 **)ppData,pFilterSpecData->FilterSpec.Resvd);\
+  encode_16bit((uns8 **)ppData,pFilterSpecData->FilterSpec.LspId);\
+  zlog_info("encoding FILTER_SPEC %x %x",pFilterSpecData->FilterSpec.IpAddr,pFilterSpecData->FilterSpec.LspId);\
+  PktLen += 8;\
+  ENCODE_OBJ_HDR(sizeof(LABEL_OBJ)+sizeof(OBJ_HDR),LABEL_CLASS,COMMON_CTYPE)\
+  encode_32bit((uns8 **)ppData,pFilterSpecData->SentLabel.Label);\
+  PktLen += 4;\
+  pRsvpPkt->ReceivedRro.rr = pFilterSpecData->Rro.rr;\
+  if((pRsvpPkt->ReceivedRro.rr != NULL)||\
+     (pRsvpPkt->AddedRro.rr != NULL))\
+  {\
+     ENCODE_OBJ_HDR(0,RECORDED_ROUTE_CLASS,COMMON_CTYPE)\
+     ENCODE_RRO\
+     encode_16bit((uns8 **)&pVariableLengthObj,(uns32)VariableLengthObj);\
+  }\
+  pRsvpPkt->ReceivedRro.rr = NULL;\
+}
+
+
+E_RC
+EncodeAndSendRsvpPathMessage (RSVP_PKT * pRsvpPkt,
+			      IPV4_ADDR DestIpAddr,
+			      uns32 OutIf,
+			      uns8 ttl,
+			      char **ppSentBuffer, uns16 * pSentBufferLen)
+{
+  uns16 PktLen = 0;
+  uns8 VersionFlags = RSVP_VERSION;
+  uns16 *pCheckSum, CheckSum = 0;
+  uns16 *pRsvpLength;
+  uns8 *pData = BigBuffer;
+  uns8 **ppData = &pData;
+  uns16 *pVariableLengthObj;
+  uns16 VariableLengthObj;
+  zlog_info ("entering EncodeAndSendRsvpPathMessage");
+  memset (BigBuffer, 0, 1500);
+
+  ENCODE_COMMON_HDR (VersionFlags, PATH_MSG, 0 /* CheckSum */ , ttl,
+		     0 /* resvd */ , 0 /* RsvpLength */ )
+    ENCODE_OBJ_HDR (sizeof (SESSION_OBJ) + sizeof (OBJ_HDR), SESSION_CLASS,
+		    SESSION_CTYPE) ENCODE_SESSION
+    ENCODE_OBJ_HDR (sizeof (RSVP_HOP_OBJ) + sizeof (OBJ_HDR), RSVP_HOP_CLASS,
+		    COMMON_CTYPE) ENCODE_RSVP_HOP
+    ENCODE_OBJ_HDR (sizeof (TIME_VALUES_OBJ) + sizeof (OBJ_HDR),
+		    TIME_VALUES_CLASS,
+		    COMMON_CTYPE) ENCODE_TIME_VALUES if ((pRsvpPkt->
+							  ReceivedEro.er !=
+							  NULL)
+							 || (pRsvpPkt->
+							     SentEro.er !=
+							     NULL))
+    {
+      ENCODE_OBJ_HDR (0, EXPLICIT_ROUTE_CLASS, COMMON_CTYPE)
+	ENCODE_ERO
+	encode_16bit ((uns8 **) & pVariableLengthObj,
+		      (uns32) VariableLengthObj);
+    }
+  ENCODE_OBJ_HDR (sizeof (LABEL_REQUEST_OBJ) + sizeof (OBJ_HDR),
+		  LABEL_REQUEST_CLASS,
+		  COMMON_CTYPE) ENCODE_LABEL_REQUEST if (pRsvpPkt->
+							 SessionAttributes.
+							 CType ==
+							 SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+    {
+      ENCODE_OBJ_HDR (0, SESSION_ATTRIBUTE_CLASS,
+		      pRsvpPkt->SessionAttributes.
+		      CType) ENCODE_SESSION_ATTRIBUTES encode_16bit ((uns8 **)
+								     &
+								     pVariableLengthObj,
+								     (uns32)
+								     VariableLengthObj);
+    }
+  else if (pRsvpPkt->SessionAttributes.CType == SESSION_ATTRIBUTES_CLASS_TYPE)
+    {
+      ENCODE_OBJ_HDR (0, SESSION_ATTRIBUTE_CLASS,
+		      pRsvpPkt->SessionAttributes.
+		      CType) ENCODE_SESSION_ATTRIBUTES encode_16bit ((uns8 **)
+								     &
+								     pVariableLengthObj,
+								     (uns32)
+								     VariableLengthObj);
+    }
+  ENCODE_OBJ_HDR (sizeof (SENDER_TEMPLATE_OBJ) + sizeof (OBJ_HDR),
+		  SENDER_TEMPLATE_CLASS,
+		  SENDER_TEMPLATE_CTYPE) ENCODE_SENDER_TEMPLATE
+    ENCODE_OBJ_HDR (sizeof (SENDER_TSPEC_OBJ) + sizeof (OBJ_HDR),
+		    SENDER_TSPEC_CLASS,
+		    SENDER_TSPEC_CTYPE) ENCODE_SENDER_TSPEC if (pRsvpPkt->
+								SentAdSpec.
+								CType != 0)
+    {
+    ENCODE_OBJ_HDR (sizeof (ADSPEC_OBJ) + sizeof (OBJ_HDR), ADSPEC_CLASS,
+		      COMMON_CTYPE) ENCODE_ADSPEC}
+  if ((pRsvpPkt->ReceivedRro.rr != NULL) || (pRsvpPkt->AddedRro.rr != NULL))
+    {
+      ENCODE_OBJ_HDR (0, RECORDED_ROUTE_CLASS, COMMON_CTYPE)
+	ENCODE_RRO
+	encode_16bit ((uns8 **) & pVariableLengthObj,
+		      (uns32) VariableLengthObj);
+    }
+  encode_16bit ((uns8 **) & pRsvpLength, PktLen);
+  rsvp_calc_pkt_cksum (BigBuffer, PktLen, &CheckSum);
+  encode_16bit ((uns8 **) & pCheckSum, CheckSum);
+  if (((*ppSentBuffer) = (char *) XMALLOC (MTYPE_RSVP, PktLen)) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+    }
+  else
+    {
+      *pSentBufferLen = PktLen;
+      memcpy ((*ppSentBuffer), BigBuffer, *pSentBufferLen);
+    }
+  return SendRawData (BigBuffer, PktLen, DestIpAddr, OutIf, ttl, TRUE);
+}
+
+E_RC
+EncodeAndSendRsvpResvMessage (RSVP_PKT * pRsvpPkt,
+			      IPV4_ADDR DestIpAddr,
+			      uns32 OutIf,
+			      uns8 ttl,
+			      char **ppSentBuffer, uns16 * pSentBufferLen)
+{
+  uns16 PktLen = 0;
+  uns8 VersionFlags = RSVP_VERSION;
+  uns16 *pCheckSum, CheckSum = 0;
+  uns16 *pRsvpLength;
+  uns8 *pData = BigBuffer;
+  uns8 **ppData = &pData;
+  uns16 *pVariableLengthObj;
+  uns16 VariableLengthObj;
+  FILTER_LIST *pFilterList;
+  FILTER_SPEC_DATA *pFilterSpecData;
+  FLOW_SPEC_OBJ *pFlowSpecObj;
+
+  zlog_info ("entering EncodeAndSendRsvpResvMessage");
+  memset (BigBuffer, 0, 1500);
+
+  ENCODE_COMMON_HDR (VersionFlags, RESV_MSG, 0 /* CheckSum */ , ttl,
+		     0 /* resvd */ , 0 /* RsvpLength */ )
+    ENCODE_OBJ_HDR (sizeof (SESSION_OBJ) + sizeof (OBJ_HDR), SESSION_CLASS,
+		    SESSION_CTYPE) ENCODE_SESSION
+    ENCODE_OBJ_HDR (sizeof (RSVP_HOP_OBJ) + sizeof (OBJ_HDR), RSVP_HOP_CLASS,
+		    COMMON_CTYPE) ENCODE_RSVP_HOP
+    ENCODE_OBJ_HDR (sizeof (TIME_VALUES_OBJ) + sizeof (OBJ_HDR),
+		    TIME_VALUES_CLASS,
+		    COMMON_CTYPE) ENCODE_TIME_VALUES
+    ENCODE_OBJ_HDR (sizeof (STYLE_OBJ) + sizeof (OBJ_HDR), STYLE_CLASS,
+		    COMMON_CTYPE) ENCODE_STYLE pFilterList =
+    pRsvpPkt->pFilterList;
+  if (pRsvpPkt->Style.OptionVector2 == SE_STYLE_BITS)
+    {
+      if ((pFilterList == NULL) || (pFilterList->pFilterSpecData == NULL))
+	{
+	  zlog_err ("an error at %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pFilterSpecData = pFilterList->pFilterSpecData;
+      pFlowSpecObj = &pFilterSpecData->pPHopResvRefreshList->FwdFlowSpec;
+      ENCODE_FLOW_SPEC while (pFilterList != NULL)
+	{
+	  pFilterSpecData = pFilterList->pFilterSpecData;
+	  ENCODE_FILTER_SPEC pFilterList = pFilterList->next;
+	}
+    }
+  else
+    {
+      while (pFilterList != NULL)
+	{
+	  pFilterSpecData = pFilterList->pFilterSpecData;
+	  pFlowSpecObj = &pFilterSpecData->FlowSpec;
+	  ENCODE_FLOW_SPEC ENCODE_FILTER_SPEC pFilterList = pFilterList->next;
+	}
+    }
+#if 0
+  pRsvpPkt->AddedRro.rr = NULL;
+#endif
+
+  encode_16bit ((uns8 **) & pRsvpLength, PktLen);
+  rsvp_calc_pkt_cksum (BigBuffer, PktLen, &CheckSum);
+  encode_16bit ((uns8 **) & pCheckSum, CheckSum);
+  if (((*ppSentBuffer) = (char *) XMALLOC (MTYPE_RSVP, PktLen)) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+    }
+  else
+    {
+      *pSentBufferLen = PktLen;
+      memcpy ((*ppSentBuffer), BigBuffer, *pSentBufferLen);
+    }
+  return SendRawData (BigBuffer, PktLen, DestIpAddr, OutIf, ttl, FALSE);
+}
+
+E_RC
+EncodeAndSendRsvpPathErrMessage (RSVP_PKT * pRsvpPkt, IPV4_ADDR DestIpAddr,
+				 uns32 OutIf, uns8 ttl)
+{
+  uns16 PktLen = 0;
+  uns8 VersionFlags = RSVP_VERSION;
+  uns16 *pCheckSum, CheckSum = 0;
+  uns16 *pRsvpLength;
+  uns8 *pData = BigBuffer;
+  uns8 **ppData = &pData;
+  uns16 *pVariableLengthObj;
+
+  zlog_info ("entering EncodeAndSendRsvpPathErrMessage");
+  memset (BigBuffer, 0, 1500);
+
+  ENCODE_COMMON_HDR (VersionFlags, PATH_ERR_MSG, 0 /* CheckSum */ , ttl,
+		     0 /* resvd */ , 0 /* RsvpLength */ )
+    ENCODE_OBJ_HDR (sizeof (SESSION_OBJ) + sizeof (OBJ_HDR), SESSION_CLASS,
+		    SESSION_CTYPE) ENCODE_SESSION
+    ENCODE_OBJ_HDR (sizeof (ERR_SPEC_OBJ) + sizeof (OBJ_HDR), ERR_SPEC_CLASS,
+		    COMMON_CTYPE) ENCODE_ERR_SPEC
+    ENCODE_OBJ_HDR (sizeof (SENDER_TEMPLATE_OBJ) + sizeof (OBJ_HDR),
+		    SENDER_TEMPLATE_CLASS,
+		    SENDER_TEMPLATE_CTYPE) ENCODE_SENDER_TEMPLATE
+    ENCODE_OBJ_HDR (sizeof (SENDER_TSPEC_OBJ) + sizeof (OBJ_HDR),
+		    SENDER_TSPEC_CLASS,
+		    SENDER_TSPEC_CTYPE) ENCODE_SENDER_TSPEC if (pRsvpPkt->
+								SentAdSpec.
+								CType != 0)
+    {
+    ENCODE_OBJ_HDR (sizeof (ADSPEC_OBJ) + sizeof (OBJ_HDR), ADSPEC_CLASS,
+		      COMMON_CTYPE) ENCODE_ADSPEC}
+  encode_16bit ((uns8 **) & pRsvpLength, PktLen);
+  rsvp_calc_pkt_cksum (BigBuffer, PktLen, &CheckSum);
+  encode_16bit ((uns8 **) & pCheckSum, CheckSum);
+  return SendRawData (BigBuffer, PktLen, DestIpAddr, OutIf, ttl, TRUE);
+}
+
+E_RC
+EncodeAndSendRsvpPathTearMessage (RSVP_PKT * pRsvpPkt, IPV4_ADDR DestIpAddr,
+				  uns32 OutIf, uns8 ttl)
+{
+  uns16 PktLen = 0;
+  uns8 VersionFlags = RSVP_VERSION;
+  uns16 *pCheckSum, CheckSum = 0;
+  uns16 *pRsvpLength;
+  uns8 *pData = BigBuffer;
+  uns8 **ppData = &pData;
+  uns16 *pVariableLengthObj;
+
+  zlog_info ("entering EncodeAndSendRsvpPathTearMessage");
+  memset (BigBuffer, 0, 1500);
+
+  ENCODE_COMMON_HDR (VersionFlags, PATH_TEAR_MSG, 0 /* CheckSum */ , ttl,
+		     0 /* resvd */ , 0 /* RsvpLength */ )
+    ENCODE_OBJ_HDR (sizeof (SESSION_OBJ) + sizeof (OBJ_HDR), SESSION_CLASS,
+		    SESSION_CTYPE) ENCODE_SESSION
+    ENCODE_OBJ_HDR (sizeof (RSVP_HOP_OBJ) + sizeof (OBJ_HDR), RSVP_HOP_CLASS,
+		    COMMON_CTYPE) ENCODE_RSVP_HOP
+    ENCODE_OBJ_HDR (sizeof (SENDER_TEMPLATE_OBJ) + sizeof (OBJ_HDR),
+		    SENDER_TEMPLATE_CLASS,
+		    SENDER_TEMPLATE_CTYPE) ENCODE_SENDER_TEMPLATE
+    ENCODE_OBJ_HDR (sizeof (SENDER_TSPEC_OBJ) + sizeof (OBJ_HDR),
+		    SENDER_TSPEC_CLASS,
+		    SENDER_TSPEC_CTYPE) ENCODE_SENDER_TSPEC if (pRsvpPkt->
+								SentAdSpec.
+								CType != 0)
+    {
+    ENCODE_OBJ_HDR (sizeof (ADSPEC_OBJ) + sizeof (OBJ_HDR), ADSPEC_CLASS,
+		      COMMON_CTYPE) ENCODE_ADSPEC}
+  encode_16bit ((uns8 **) & pRsvpLength, PktLen);
+  rsvp_calc_pkt_cksum (BigBuffer, PktLen, &CheckSum);
+  encode_16bit ((uns8 **) & pCheckSum, CheckSum);
+  return SendRawData (BigBuffer, PktLen, DestIpAddr, OutIf, ttl, TRUE);
+}
+
+E_RC
+EncodeAndSendRsvpResvErrMessage (RSVP_PKT * pRsvpPkt, IPV4_ADDR DestIpAddr,
+				 uns32 OutIf, uns8 ttl)
+{
+  uns16 PktLen = 0;
+  uns8 VersionFlags = RSVP_VERSION;
+  uns16 *pCheckSum, CheckSum = 0;
+  uns16 *pRsvpLength;
+  uns8 *pData = BigBuffer;
+  uns8 **ppData = &pData;
+  uns16 *pVariableLengthObj;
+  uns16 VariableLengthObj;
+  FILTER_LIST *pFilterList;
+  FILTER_SPEC_DATA *pFilterSpecData;
+  FLOW_SPEC_OBJ *pFlowSpecObj;
+
+  zlog_info ("entering EncodeAndSendRsvpResvErrMessage");
+  memset (BigBuffer, 0, 1500);
+
+  ENCODE_COMMON_HDR (VersionFlags, RESV_ERR_MSG, 0 /* CheckSum */ , ttl,
+		     0 /* resvd */ , 0 /* RsvpLength */ )
+    ENCODE_OBJ_HDR (sizeof (SESSION_OBJ) + sizeof (OBJ_HDR), SESSION_CLASS,
+		    SESSION_CTYPE) ENCODE_SESSION
+    ENCODE_OBJ_HDR (sizeof (RSVP_HOP_OBJ) + sizeof (OBJ_HDR), RSVP_HOP_CLASS,
+		    COMMON_CTYPE) ENCODE_RSVP_HOP
+    ENCODE_OBJ_HDR (sizeof (ERR_SPEC_OBJ) + sizeof (OBJ_HDR), ERR_SPEC_CLASS,
+		    COMMON_CTYPE) ENCODE_ERR_SPEC
+    ENCODE_OBJ_HDR (sizeof (STYLE_OBJ) + sizeof (OBJ_HDR), STYLE_CLASS,
+		    COMMON_CTYPE) ENCODE_STYLE pFilterList =
+    pRsvpPkt->pFilterList;
+  if (pRsvpPkt->Style.OptionVector2 == SE_STYLE_BITS)
+    {
+      if ((pFilterList == NULL) || (pFilterList->pFilterSpecData == NULL))
+	{
+	  zlog_err ("an error at %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pFilterSpecData = pFilterList->pFilterSpecData;
+      pFlowSpecObj =
+	(pFilterSpecData->NewFlowSpecValid) ? &pFilterSpecData->
+	NewFlowSpec : &pFilterSpecData->FlowSpec;
+      ENCODE_FLOW_SPEC while (pFilterList != NULL)
+	{
+	  pFilterSpecData = pFilterList->pFilterSpecData;
+	  ENCODE_FILTER_SPEC pFilterList = pFilterList->next;
+	}
+    }
+  else
+    {
+      while (pFilterList != NULL)
+	{
+	  pFilterSpecData = pFilterList->pFilterSpecData;
+	  pFlowSpecObj = &pFilterSpecData->FlowSpec;
+	  ENCODE_FLOW_SPEC ENCODE_FILTER_SPEC pFilterList = pFilterList->next;
+	}
+    }
+  pRsvpPkt->AddedRro.rr = NULL;
+
+  encode_16bit ((uns8 **) & pRsvpLength, PktLen);
+  rsvp_calc_pkt_cksum (BigBuffer, PktLen, &CheckSum);
+  encode_16bit ((uns8 **) & pCheckSum, CheckSum);
+  return SendRawData (BigBuffer, PktLen, DestIpAddr, OutIf, ttl, TRUE);
+}
+
+E_RC
+EncodeAndSendRsvpResvTearMessage (RSVP_PKT * pRsvpPkt, IPV4_ADDR DestIpAddr,
+				  uns32 OutIf, uns8 ttl)
+{
+  uns16 PktLen = 0;
+  uns8 VersionFlags = RSVP_VERSION;
+  uns16 *pCheckSum, CheckSum = 0;
+  uns16 *pRsvpLength;
+  uns8 *pData = BigBuffer;
+  uns8 **ppData = &pData;
+  uns16 *pVariableLengthObj;
+  uns16 VariableLengthObj;
+  FILTER_LIST *pFilterList;
+  FILTER_SPEC_DATA *pFilterSpecData;
+  FLOW_SPEC_OBJ *pFlowSpecObj;
+
+  zlog_info ("entering EncodeAndSendRsvpResvTearMessage");
+  memset (BigBuffer, 0, 1500);
+
+  ENCODE_COMMON_HDR (VersionFlags, RESV_TEAR_MSG, 0 /* CheckSum */ , ttl,
+		     0 /* resvd */ , 0 /* RsvpLength */ )
+    ENCODE_OBJ_HDR (sizeof (SESSION_OBJ) + sizeof (OBJ_HDR), SESSION_CLASS,
+		    SESSION_CTYPE) ENCODE_SESSION
+    ENCODE_OBJ_HDR (sizeof (RSVP_HOP_OBJ) + sizeof (OBJ_HDR), RSVP_HOP_CLASS,
+		    COMMON_CTYPE) ENCODE_RSVP_HOP
+    ENCODE_OBJ_HDR (sizeof (STYLE_OBJ) + sizeof (OBJ_HDR), STYLE_CLASS,
+		    COMMON_CTYPE) ENCODE_STYLE pFilterList =
+    pRsvpPkt->pFilterList;
+  if (pRsvpPkt->Style.OptionVector2 == SE_STYLE_BITS)
+    {
+      if ((pFilterList == NULL) || (pFilterList->pFilterSpecData == NULL))
+	{
+	  zlog_err ("an error at %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pFilterSpecData = pFilterList->pFilterSpecData;
+      pFlowSpecObj = &pFilterSpecData->pPHopResvRefreshList->FwdFlowSpec;
+      ENCODE_FLOW_SPEC while (pFilterList != NULL)
+	{
+	  pFilterSpecData = pFilterList->pFilterSpecData;
+	  ENCODE_FILTER_SPEC pFilterList = pFilterList->next;
+	}
+    }
+  else
+    {
+      while (pFilterList != NULL)
+	{
+	  pFilterSpecData = pFilterList->pFilterSpecData;
+	  pFlowSpecObj = &pFilterSpecData->FlowSpec;
+	  ENCODE_FLOW_SPEC ENCODE_FILTER_SPEC pFilterList = pFilterList->next;
+	}
+    }
+  pRsvpPkt->AddedRro.rr = NULL;
+
+  encode_16bit ((uns8 **) & pRsvpLength, PktLen);
+  rsvp_calc_pkt_cksum (BigBuffer, PktLen, &CheckSum);
+  encode_16bit ((uns8 **) & pCheckSum, CheckSum);
+  return SendRawData (BigBuffer, PktLen, DestIpAddr, OutIf, ttl, TRUE);
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_encode.h quagga-mpls/rsvpd/rsvp_encode.h
--- quagga-0.99.10/rsvpd/rsvp_encode.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_encode.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,35 @@
+#ifndef __RSVP_ENCODE_H_
+#define __RSVP_ENCODE_H_
+
+E_RC EncodeAndSendRsvpPathTearMessage (RSVP_PKT * pRsvpPkt,
+				       IPV4_ADDR DestIpAddr,
+				       uns32 OutIf, uns8 ttl);
+E_RC EncodeAndSendRsvpPathErrMessage (RSVP_PKT * pRsvpPkt,
+				      IPV4_ADDR DestIpAddr,
+				      uns32 OutIf, uns8 ttl);
+
+E_RC EncodeAndSendRsvpPathMessage (RSVP_PKT * pRsvpPkt,
+				   IPV4_ADDR DestIpAddr,
+				   uns32 OutIf,
+				   uns8 ttl,
+				   char **ppSentBuffer,
+				   uns16 * pSentBufferLen);
+
+E_RC EncodeAndSendRsvpResvErrMessage (RSVP_PKT * pRsvpPkt,
+				      IPV4_ADDR DestIpAddr,
+				      uns32 OutIf, uns8 ttl);
+
+E_RC EncodeAndSendRsvpResvMessage (RSVP_PKT * pRsvpPkt,
+				   IPV4_ADDR DestIpAddr,
+				   uns32 OutIf,
+				   uns8 ttl,
+				   char **ppSentBuffer,
+				   uns16 * pSentBufferLen);
+
+E_RC EncodeAndSendRsvpResvTearMessage (RSVP_PKT * pRsvpPkt,
+				       IPV4_ADDR DestIpAddr,
+				       uns32 OutIf, uns8 ttl);
+
+void rsvp_calc_pkt_cksum (char *u, unsigned int PktLen, uns16 * const pCksum);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvp.h quagga-mpls/rsvpd/rsvp.h
--- quagga-0.99.10/rsvpd/rsvp.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,46 @@
+#ifndef __RSVP_INCLUDES__
+#define __RSVP_INCLUDES__
+
+#include<stdio.h>
+#include<stdlib.h>
+#include<string.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+#include <sys/ioctl.h>
+#include <net/if.h>
+#include <netinet/in.h>
+#include <netinet/ip.h>
+#include <unistd.h>
+#include <time.h>
+#include <sys/time.h>
+#include <sys/file.h>
+#include <sys/fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/uio.h>
+#include <ctype.h>
+#include<math.h>
+#include<errno.h>
+#include <zebra.h>
+#include "thread.h"
+#include "vty.h"
+#include "command.h"
+#include "log.h"
+#include "memory.h"
+#include "patricia.h"
+
+#include "general.h"
+#include "messages.h"
+#include "rsvp_packet.h"
+#include "te_lib.h"
+#include "rsvp_psb.h"
+#include "rsvp_rsb.h"
+#include "rsvp_socket.h"
+#include "rsvp_utilities.h"
+#include "rsvp_decode.h"
+#include "rsvp_encode.h"
+#include "rsvp_api.h"
+
+#define RSVP_VTY_PORT		2699
+#define RSVP_DEFAULT_CONFIG	"rsvpd.conf"
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvp_main.c quagga-mpls/rsvpd/rsvp_main.c
--- quagga-0.99.10/rsvpd/rsvp_main.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_main.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,276 @@
+/* Module:   rsvp_main.c
+   Contains: RSVP entry point
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+
+#include <zebra.h>
+#include <lib/version.h>
+#include "getopt.h"
+#include "thread.h"
+#include "vty.h"
+#include "log.h"
+#include "sigevent.h"
+#include "privs.h"
+#include "memory.h"
+
+#include "rsvp.h"
+#include "rsvp_vty.h"
+#include "rsvp_zebra.h"
+#include "rsvp_packet.h"
+
+/* rsvpd privileges */
+zebra_capabilities_t _caps_p[] = {
+  ZCAP_NET_RAW,
+  ZCAP_BIND,
+  ZCAP_NET_ADMIN,
+};
+
+struct zebra_privs_t rsvpd_privs = {
+#if defined(QUAGGA_USER) && defined(QUAGGA_GROUP)
+  .user = QUAGGA_USER,
+  .group = QUAGGA_GROUP,
+#endif
+#if defined(VTY_GROUP)
+  .vty_group = VTY_GROUP,
+#endif
+  .caps_p = _caps_p,
+  .cap_num_p = sizeof (_caps_p) / sizeof (_caps_p[0]),
+  .cap_num_i = 0
+};
+
+/* Configuration filename and directory. */
+char config_default[] = SYSCONFDIR RSVP_DEFAULT_CONFIG;
+
+/* RSVPd options. */
+struct option longopts[] = {
+  {"daemon", no_argument, NULL, 'd'},
+  {"config_file", required_argument, NULL, 'f'},
+  {"pid_file", required_argument, NULL, 'i'},
+  {"log_mode", no_argument, NULL, 'l'},
+  {"dryrun", no_argument, NULL, 'C'},
+  {"help", no_argument, NULL, 'h'},
+  {"vty_addr", required_argument, NULL, 'A'},
+  {"vty_port", required_argument, NULL, 'P'},
+  {"user", required_argument, NULL, 'u'},
+  {"group", required_argument, NULL, 'g'},
+  {"version", no_argument, NULL, 'v'},
+  {0}
+};
+
+struct thread_master *master;
+
+/* Process ID saved for use by init system */
+const char *pid_file = PATH_RSVPD_PID;
+
+/* Help information display. */
+static void __attribute__ ((noreturn)) usage (char *progname, int status)
+{
+  if (status != 0)
+    fprintf (stderr, "Try `%s --help' for more information.\n", progname);
+  else
+    {
+      printf ("Usage : %s [OPTION...]\n\
+Daemon which manages RSVP.\n\n\
+-d, --daemon       Runs in daemon mode\n\
+-f, --config_file  Set configuration file name\n\
+-i, --pid_file     Set process identifier file name\n\
+-A, --vty_addr     Set vty's bind address\n\
+-P, --vty_port     Set vty's port number\n\
+-u, --user         User to run as\n\
+-g, --group        Group to run as\n\
+-v, --version      Print program version\n\
+-C, --dryrun       Check configuration for validity and exit\n\
+-h, --help         Display this help and exit\n\
+\n\
+Report bugs to %s\n", progname, ZEBRA_BUG_ADDRESS);
+    }
+  exit (status);
+}
+
+/* SIGHUP handler. */
+static void
+sighup (void)
+{
+  zlog (NULL, LOG_INFO, "SIGHUP received");
+}
+
+/* SIGINT / SIGTERM handler. */
+static void
+sigint (void)
+{
+  zlog_notice ("Terminating on signal");
+}
+
+/* SIGUSR1 handler. */
+static void
+sigusr1 (void)
+{
+  zlog_rotate (NULL);
+}
+
+struct quagga_signal_t rsvp_signals[] = {
+  {
+   .signal = SIGHUP,
+   .handler = &sighup,
+   },
+  {
+   .signal = SIGUSR1,
+   .handler = &sigusr1,
+   },
+  {
+   .signal = SIGINT,
+   .handler = &sigint,
+   },
+  {
+   .signal = SIGTERM,
+   .handler = &sigint,
+   },
+};
+
+/* RSVPd main routine. */
+int
+main (int argc, char **argv)
+{
+  char *p;
+  char *vty_addr = NULL;
+  int vty_port = RSVP_VTY_PORT;
+  int daemon_mode = 0;
+  char *config_file = NULL;
+  char *progname;
+  struct thread thread;
+  int dryrun = 0;
+
+  /* Set umask before anything for security */
+  umask (0027);
+
+  /* get program name */
+  progname = ((p = strrchr (argv[0], '/')) ? ++p : argv[0]);
+
+  /* Invoked by a priviledged user? -- endo. */
+  if (geteuid () != 0)
+    {
+      errno = EPERM;
+      perror (progname);
+      exit (1);
+    }
+
+  zlog_default = openzlog (progname, ZLOG_RSVP,
+			   LOG_CONS | LOG_NDELAY | LOG_PID, LOG_DAEMON);
+
+  while (1)
+    {
+      int opt;
+
+      opt = getopt_long (argc, argv, "dlf:i:hA:P:u:g:vC", longopts, 0);
+
+      if (opt == EOF)
+	break;
+
+      switch (opt)
+	{
+	case 0:
+	  break;
+	case 'd':
+	  daemon_mode = 1;
+	  break;
+	case 'f':
+	  config_file = optarg;
+	  break;
+	case 'A':
+	  vty_addr = optarg;
+	  break;
+	case 'i':
+	  pid_file = optarg;
+	  break;
+	case 'P':
+	  /* Deal with atoi() returning 0 on failure, and rsvpd not
+	     listening on rsvpd port... */
+	  if (strcmp (optarg, "0") == 0)
+	    {
+	      vty_port = 0;
+	      break;
+	    }
+	  vty_port = atoi (optarg);
+	  vty_port = (vty_port ? vty_port : RSVP_VTY_PORT);
+	  break;
+	case 'u':
+	  rsvpd_privs.user = optarg;
+	  break;
+	case 'g':
+	  rsvpd_privs.group = optarg;
+	  break;
+	case 'v':
+	  print_version (progname);
+	  exit (0);
+	  break;
+	case 'C':
+	  dryrun = 1;
+	  break;
+	case 'h':
+	  usage (progname, 0);
+	  break;
+	default:
+	  usage (progname, 1);
+	  break;
+	}
+    }
+
+  /* Make master thread emulator. */
+  master = thread_master_create ();
+
+  /* Library inits. */
+  zprivs_init (&rsvpd_privs);
+  signal_init (master, Q_SIGC (rsvp_signals), rsvp_signals);
+  cmd_init (1);
+  vty_init (master);
+  memory_init ();
+  rsvp_vty ();
+
+  InitRsvpDecoder ();
+  InitRsvpPathMessageProcessing ();
+  InitResvProcessing ();
+  InitInterfaceIpAdressesDB ();
+
+  if (rdb_create () != E_OK)
+    {
+      zlog_err ("an error on RDB creation...");
+      return 0;
+    }
+  if (TeApplicationInit () != E_OK)
+    zlog_err ("TE application init failed");
+
+  if (InitInterfaceDB () != E_OK)
+    zlog_err ("cannot initiate I/F DB");
+
+  rsvp_zebra_init ();
+  rsvp_te_comm_init ();
+
+  sort_node ();
+
+  /* Get configuration file. */
+  vty_read_config (config_file, config_default);
+
+  /* Start execution only if not in dry-run mode */
+  if (dryrun)
+    return (0);
+
+  /* Change to the daemon program. */
+  if (daemon_mode)
+    daemon (0, 0);
+
+  /* Process id file create. */
+  pid_output (pid_file);
+
+  /* Create VTY socket */
+  vty_serv_sock (vty_addr, vty_port, RSVP_VTYSH_PATH);
+
+  /* Print banner. */
+  zlog_notice ("RSVPd %s starting: vty@%d", QUAGGA_VERSION, vty_port);
+
+  /* Fetch next active thread. */
+  while (thread_fetch (master, &thread))
+    thread_call (&thread);
+
+  /* Not reached. */
+  return (0);
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_packet.h quagga-mpls/rsvpd/rsvp_packet.h
--- quagga-0.99.10/rsvpd/rsvp_packet.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_packet.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,499 @@
+#ifndef _RSVP_PACKET_H_
+#define _RSVP_PACKET_H_
+
+#define RSVP_IP_PROTOCOL 46
+
+#define COMMON_CTYPE   1
+
+#define SESSION_CLASS             1
+#define RSVP_HOP_CLASS            3
+#define INTEGRITY_CLASS           4
+#define TIME_VALUES_CLASS         5
+#define ERR_SPEC_CLASS            6
+#define SCOPE_CLASS               7
+#define STYLE_CLASS               8
+#define FLOW_SPEC_CLASS           9
+#define FILTER_SPEC_CLASS         10
+#define SENDER_TEMPLATE_CLASS     11
+#define SENDER_TSPEC_CLASS        12
+#define ADSPEC_CLASS              13
+#define POLICY_DATA_CLASS         14
+#define RESV_CONF_CLASS           15
+#define LABEL_CLASS               16
+#define LABEL_REQUEST_CLASS       19
+#define EXPLICIT_ROUTE_CLASS      20
+#define RECORDED_ROUTE_CLASS      21
+#define SESSION_ATTRIBUTE_CLASS   207
+
+#define SESSION_CTYPE 7
+#define SENDER_TEMPLATE_CTYPE 7
+#define SENDER_TSPEC_CTYPE 2
+
+#define FLOW_SPEC_INTSERV_CTYPE 2
+
+#define SESSION_ATTRIBUTES_RA_CLASS_TYPE 1
+#define SESSION_ATTRIBUTES_CLASS_TYPE 7
+
+
+
+#define SESSION_LSP_IPV4_CTYPE             7
+#define SENDER_TEMPLATE_LSP_IPV4_CTYPE     7
+#define FILTER_SPEC_LSP_IPV4_CTYPE         7
+#define SESSION_ATTRIBUTES_IPV4_CTYPE      7
+#define SESSION_ATTRIBUTES_RA_IPV4_CTYPE   1
+
+#define RSVP_VERSION (1 << 4)
+
+#define LOCAL_PROTECTION_DESIRED   0x01
+#define LABEL_RECORDING_DESIRED    0x02
+#define SE_STYLE_DESIRED           0x04
+
+typedef struct
+{
+  uns8 VersionFlags;
+  uns8 MsgType;
+  uns16 CheckSum;
+  uns8 SendTTL;
+  uns8 Resvd;
+  uns16 RsvpLength;
+} RSVP_COMMON_HDR;
+
+#define PATH_MSG         1
+#define RESV_MSG         2
+#define PATH_ERR_MSG     3
+#define RESV_ERR_MSG     4
+#define PATH_TEAR_MSG    5
+#define RESV_TEAR_MSG    6
+#define RESV_CONF_MSG    7
+
+typedef struct
+{
+  uns16 Length;
+  uns8 ClassNum;
+  uns8 CType;
+} OBJ_HDR;
+
+
+typedef struct
+{
+  IPV4_ADDR Dest;
+  uns16 Resvd;
+  uns16 TunnelId;
+  IPV4_ADDR ExtTunelId;
+} SESSION_OBJ;
+
+typedef struct
+{
+  IPV4_ADDR PHop;
+  uns32 LIH;
+} RSVP_HOP_OBJ;
+
+typedef struct
+{
+  uns32 TimeValues;
+} TIME_VALUES_OBJ;
+
+typedef struct
+{
+  uns32 IpAddrNumber;
+  IPV4_ADDR *Addresses;
+} SCOPE_OBJ;
+
+
+typedef struct
+{
+  uns8 Flags;
+  uns8 OptionVector1;
+  uns16 OptionVector2;
+} STYLE_OBJ;
+
+#define SE_STYLE_BITS 0x12
+#define FF_STYLE_BITS 0x0A
+
+typedef struct
+{
+  uns16 VersionResvd;
+  uns16 MessageLength;
+} MSG_HDR;
+
+typedef struct
+{
+  uns8 ServHdr;
+  uns8 Resvd;
+  uns16 ServLength;
+} SERV_HDR;
+
+typedef struct
+{
+  uns8 ParamID;
+  uns8 ParamFlags;
+  uns16 ParamLength;
+} PARAM_HDR;
+
+typedef struct
+{
+  float TockenBucketRate;
+  float TockenBucketSize;
+  float PeakDataRate;
+  float MinPolicedUnit;
+  float MaxPacketSize;
+} CTRL_LOAD_FLOW_SPEC;
+
+typedef struct
+{
+  CTRL_LOAD_FLOW_SPEC CtrlLoad;
+  PARAM_HDR GuarSpecificParamHdr;
+  float Rate;
+  uns32 SlackTerm;
+} GUAR_FLOW_SPEC;
+
+typedef struct
+{
+  MSG_HDR MsgHdr;
+  SERV_HDR ServHdr;
+  PARAM_HDR ParamHdr;
+  union
+  {
+    CTRL_LOAD_FLOW_SPEC CtrlLoad;
+    GUAR_FLOW_SPEC Guar;
+  } u;
+} FLOW_SPEC_OBJ;
+
+typedef struct
+{
+  IPV4_ADDR IpAddr;
+  uns16 Resvd;
+  uns16 LspId;
+} SENDER_TEMPLATE_OBJ;
+
+typedef SENDER_TEMPLATE_OBJ FILTER_SPEC_OBJ;
+
+#define SENDER_TSPEC_MSG_FORMAT             0
+#define SENDER_TSPEC_MSG_LENGTH             7
+#define SENDER_TSPEC_SERV_NUMBER            5
+#define SENDER_TSPEC_DATA_LENGTH            6
+#define SENDER_TSPEC_TOCKEN_BUCKET_PARAM_ID 127
+#define SENDER_TSPEC_TOCKEN_BUCKET_PARAM_LENGTH 5
+
+#define FLOW_SPEC_MSG_FORMAT             0
+#define FLOW_SPEC_MSG_LENGTH             7
+#define FLOW_SPEC_GUAR_SERV_NUMBER       2
+#define FLOW_SPEC_CTRL_LOAD_SERV_NUMBER  5
+#define FLOW_SPEC_DATA_LENGTH            6
+#define FLOW_SPEC_TOCKEN_BUCKET_PARAM_ID 127
+#define FLOW_SPEC_TOCKEN_BUCKET_PARAM_LENGTH 5
+
+typedef struct
+{
+  MSG_HDR MessageHdr;
+  SERV_HDR ServHdr;
+  PARAM_HDR ParamHdr;
+  float TockenBucketRate;
+  float TockenBucketSize;
+  float PeakDataRate;
+  uns32 MinPolicedUnit;
+  uns32 MaxPacketSize;
+} SENDER_TSPEC_OBJ;
+
+typedef struct
+{
+  uns32 Label;
+} LABEL_OBJ;
+
+typedef struct
+{
+  uns16 Resvd;
+  uns16 L3Pid;
+} LABEL_REQUEST_OBJ;
+
+typedef struct
+{
+  uns8 LType;
+  uns8 Length;
+} ER_SUBOBJ_HDR;
+
+typedef struct
+{
+  IPV4_ADDR IpAddress;
+  uns8 PrefixLength;
+  uns8 Resvd;
+} ER_IPV4_SUBOBJ;
+
+typedef struct
+{
+  uns32 AsNumber;
+} ER_AS_SUBOBJ;
+
+typedef struct _er_subobj_
+{
+  ER_SUBOBJ_HDR SubObjHdr;
+  union
+  {
+    ER_IPV4_SUBOBJ Ipv4;
+    ER_AS_SUBOBJ AS;
+  } u;
+  struct _er_subobj_ *next;
+} ER_SUBOBJ;
+
+typedef struct
+{
+  uns8 SubObjNumber;
+  ER_SUBOBJ *er;
+} ER_OBJ;
+
+typedef struct
+{
+  uns8 Type;
+  uns8 Length;
+} RR_SUBOBJ_HDR;
+
+typedef struct
+{
+  IPV4_ADDR IpAddr;
+  uns8 PrefixLen;
+  uns8 Flags;
+} RR_IPV4_SUBOBJ;
+
+typedef struct
+{
+  uns8 Flags;
+  uns8 CType;
+  uns32 Label;
+} RR_LABEL_SUBOBJ;
+
+typedef struct _rr_subobj_
+{
+  RR_SUBOBJ_HDR SubObjHdr;
+  union
+  {
+    RR_IPV4_SUBOBJ Ipv4;
+    RR_LABEL_SUBOBJ Label;
+  } u;
+  struct _rr_subobj_ *next;
+} RR_SUBOBJ;
+
+typedef struct
+{
+  RR_SUBOBJ *rr;
+} RR_OBJ;
+
+typedef struct
+{
+  uns8 SetPrio;
+  uns8 HoldPrio;
+  uns8 Flags;
+  uns8 NameLength;
+  char *SessionName;
+} SESSION_ATTR;
+
+typedef struct
+{
+  uns32 ExcludeAny;
+  uns32 IncludeAny;
+  uns32 IncludeAll;
+  uns8 SetPrio;
+  uns8 HoldPrio;
+  uns8 Flags;
+  uns8 NameLength;
+  char *SessionName;
+} SESSION_ATTR_RA;
+
+typedef struct
+{
+  uns8 CType;
+  union
+  {
+    SESSION_ATTR SessAttr;
+    SESSION_ATTR_RA SessAttrRa;
+  } u;
+} SESSION_ATTRIBUTES_OBJ;
+
+typedef struct
+{
+  uns8 PerServHdr;
+  uns8 BreakBitAndResvd;
+  uns16 Length;
+} PER_SERV_HDR;
+
+typedef struct
+{
+  PER_SERV_HDR PerServHdr;
+  PARAM_HDR Param4Hdr;
+  uns32 IS_HopCount;
+  PARAM_HDR Param6Hdr;
+  float PathBW;
+  PARAM_HDR Param8Hdr;
+  uns32 MinPathLatency;
+  PARAM_HDR Param10Hdr;
+  uns32 ComposedMTU;
+} ADSPEC_GEN;
+
+typedef struct
+{
+  PER_SERV_HDR PerServHdr;
+  PARAM_HDR Param133Hdr;
+  uns32 Ctot;
+  PARAM_HDR Param134Hdr;
+  uns32 Dtot;
+  PARAM_HDR Param135Hdr;
+  uns32 Csum;
+  PARAM_HDR Param136Hdr;
+  uns32 Dsum;
+} GUAR_ADSPEC;
+
+typedef struct
+{
+  uns8 CType;
+  uns16 Resvd;
+  uns16 MsgLen;
+  ADSPEC_GEN AdSpecGen;
+  GUAR_ADSPEC GuarAdSpec;
+} ADSPEC_OBJ;
+
+typedef struct
+{
+  IPV4_ADDR IpAddr;
+} RESV_CONF_OBJ;
+
+typedef struct
+{
+  IPV4_ADDR IpAddr;
+  uns8 Flags;
+  uns8 ErrCode;
+  uns16 ErrVal;
+} ERR_SPEC_OBJ;
+
+#define  CONFIRMATION_ERR_CODE             0
+#define  ADMISSION_CTRL_FAILURE_ERR_CODE   1
+#define  POLICY_CTRL_FAILURE_ERR_CODE      2
+#define  NO_PATH_INFO_4_RESV_ERR_CODE      3
+#define  NO_SENDER_INFO_4_RESV             4
+#define  CONFLICTING_RESV_STYLES_ERR_CODE  5
+#define  UNKNOWN_RESV_STYLE_ERR_CODE       6
+#define  CONFLICTING_DEST_PORTS_ERR_CODE   7
+#define  CONFLICTING_SENDER_PORTS_ERR_CODE 8
+#define  SERVICE_PREEMPTED_ERR_CODE        12
+#define  UNKNOWN_OBJ_CLASS_ERR_CODE        13
+#define  UNKNOWN_OBJ_CTYPE_ERR_CODE        14
+#define  API_ERR_CODE                      20
+#define  TRAFFIC_CTRL_ERR_CODE             21
+#define  TRAFFIC_CTRL_SYSTEM_ERR_CODE      22
+#define  RSVP_SYSTEM_ERR_CODE              23
+#define  ROUTING_PROBLEM_ERR_CODE          24
+#define  NOTIFY_ERR_CODE                   25
+
+#define  GLB_DEFINED_SUB_CODE_FLAG         0x0000
+#define  ORG_SPECIFIC_SUB_CODE_FLAG        0x8000
+#define  SRV_SPECIFIC_SUB_CODE_FLAG        0xC000
+#define  LOCAL_STATE_MAY_BE_UPDATED_FLAG   0x1000
+
+#define  DELAY_BOUND_CANNOT_BE_MET         0x0001
+#define  BW_UNAVAILABLE                    0x0002
+#define  MTU_UNAVAILABLE                   0x0003
+
+#define  SERVICE_CONFLICT                  0x0001
+#define  SERVICE_UNSUPPORTED               0x0002
+#define  BAD_FLOW_SPEC_VAL                 0x0003
+#define  BAD_TSPEC_VAL                     0x0004
+#define  BAD_ADSPEC_VAL                    0x0005
+
+#define  BAD_EXPLICIT_ROUTE_OBJ            0x0001
+#define  BAD_STRICT_NODE                   0x0002
+#define  BAD_LOOSE_NODE                    0x0003
+#define  BAD_INITIAL_SUBOBJ                0x0004
+#define  NO_ROUTE_AVAILABLE                0x0005
+#define  UNACCEPTABLE_LABEL_VAL            0x0006
+#define  RRO_INIDICATED_ROUTING_LOOP       0x0007
+#define  NON_RSVP_ROUTER_IN_PATH           0x0008
+#define  LABEL_ALLOCATION_FAILURE          0x0009
+#define  UNSUPPORTED_L3PID                 0x000A
+
+#define  RRO_TOO_LARGE_4_MTU               0x0001
+#define  RRO_NOTIFICATION                  0x0002
+#define  TUNNEL_LOCALLY_REPAIRED           0x0003
+
+typedef struct _opaque_obj_list_
+{
+  OBJ_HDR ObjHdr;
+  void *pData;
+  struct _opaque_obj_list_ *next;
+} OPAQUE_OBJ_LIST;
+
+typedef OPAQUE_OBJ_LIST POLICY_DATA_OBJ;
+typedef OPAQUE_OBJ_LIST INTEGRITY_OBJ;
+
+//typedef SENDER_TEMPLATE_OBJ FILTER_SPEC_OBJ;
+//typedef struct SENDER_TSPEC FLOW_SPEC_OBJ;
+
+struct _phop_resv_refresh_list_;
+struct _rsb_;
+
+typedef struct
+{
+  FILTER_SPEC_OBJ FilterSpec;
+  LABEL_OBJ ReceivedLabel;	/* received with RESV */
+  LABEL_OBJ SentLabel;		/* sent with RESV (allocated upon PATH) */
+  RR_OBJ Rro;
+  uns32 AgeOutValue;
+  struct thread *AgeOutTimer;
+  FLOW_SPEC_OBJ FlowSpec;
+  uns8 NewFlowSpecValid;
+  FLOW_SPEC_OBJ NewFlowSpec;
+  FLOW_SPEC_OBJ BlockadeFlowSpec;
+  struct _phop_resv_refresh_list_ *pPHopResvRefreshList;
+  struct _effective_flow_ *pEffectiveFlow;	/* for SE only */
+  struct _psb_ *pPsb;
+  uns8 ToBeDeleted;
+  uns32 BlocadeValue;
+  struct thread *BlocadeTimer;
+  uns8 Blocked;
+} FILTER_SPEC_DATA;
+
+typedef struct _filter_list_
+{
+  FILTER_SPEC_DATA *pFilterSpecData;
+  struct _filter_list_ *next;
+} FILTER_LIST;
+
+typedef struct
+{
+  SESSION_OBJ Session;
+  RSVP_HOP_OBJ ReceivedRsvpHop;
+  RSVP_HOP_OBJ SentRsvpHop;
+  TIME_VALUES_OBJ TimeValues;
+  ER_OBJ ReceivedEro;
+  ER_OBJ SentEro;
+  LABEL_REQUEST_OBJ LabelRequest;
+  SESSION_ATTRIBUTES_OBJ SessionAttributes;
+  SENDER_TEMPLATE_OBJ SenderTemplate;
+  SENDER_TSPEC_OBJ SenderTSpec;
+  ADSPEC_OBJ ReceivedAdSpec;
+  ADSPEC_OBJ SentAdSpec;
+  RR_OBJ ReceivedRro;
+  RR_OBJ AddedRro;
+  RESV_CONF_OBJ ResvConf;
+  STYLE_OBJ Style;
+  FILTER_LIST *pFilterList;
+  INTEGRITY_OBJ *pIntegrityObj;
+  POLICY_DATA_OBJ *pPolicyDataObj;
+  OPAQUE_OBJ_LIST *pOpaqueObjList;
+  ERR_SPEC_OBJ ErrorSpec;
+} RSVP_PKT;
+
+#define ERO_SUBTYPE_IPV4 1
+#define ERO_SUBTYPE_AS   32
+
+#define RRO_SUBTYPE_IPV4  1
+#define RRO_SUBTYPE_LABEL 3
+
+typedef struct _rsvp_pkt_queue_
+{
+  uns8 MsgType;
+  RSVP_PKT *pRsvpPkt;
+  uns32 InIfIndex;
+  IPV4_ADDR SourceIp;
+  uns8 ttl;
+  struct _rsvp_pkt_queue_ *next;
+} RSVP_PKT_QUEUE;
+
+#endif /* !defined (_RSVP_PKT_H_) */
diff -Naur quagga-0.99.10/rsvpd/rsvp_path.c quagga-mpls/rsvpd/rsvp_path.c
--- quagga-0.99.10/rsvpd/rsvp_path.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_path.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,1225 @@
+/* Module:   rsvp_path.c
+   Contains: RSVP PATH, PATH TEAR and PATH ERROR message 
+   processing functions.
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "rsvp.h"
+#include "thread.h"
+
+uns32 PathRefreshInterval = 30;	/* sec */
+uns32 RefreshMultiple = /*3 */ 12;
+
+extern RSVP_STATISTICS RsvpStatistics;
+extern struct thread_master *master;
+
+static PATRICIA_TREE PsbTree;
+
+static void PrepareAndSendMsg2TE (PSB * pPsb);
+static E_RC StartPathAgeOutTimer (uns32 time, struct thread **pTimerId,
+				  void *data);
+static E_RC StopPathAgeOutTimer (struct thread **pTimerId);
+static E_RC StartPathRefreshTimer (uns32 time, struct thread **pTimerId,
+				   void *data);
+static E_RC StopPathRefreshTimer (struct thread **pTimerId);
+static void PrepareAndSendLabelReleaseMsg2TE (PSB * pPsb);
+static void PrepareAndSendPathErrNotificationMsg2TE (PSB * pPsb,
+						     ERR_SPEC_OBJ *
+						     pErrSpecObj);
+
+E_RC
+InitRsvpPathMessageProcessing ()
+{
+  PATRICIA_PARAMS params;
+
+  memset (&params, 0, sizeof (PATRICIA_PARAMS));
+  params.key_size = sizeof (PSB_KEY);
+  if (patricia_tree_init (&PsbTree, &params) != E_OK)
+    {
+      zlog_err ("Cannot initiate PSB tree");
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+PSB *
+GetNextPSB (PSB_KEY * pPsbKey)
+{
+  return (PSB *) patricia_tree_getnext (&PsbTree, (const uns8 *) pPsbKey);
+}
+
+PSB *
+FindPsb (PSB_KEY * pPsbKey)
+{
+  return (PSB *) patricia_tree_get (&PsbTree, (uns8 *) pPsbKey);
+}
+
+PSB *
+NewPsb (PSB_KEY * pPsbKey)
+{
+  PSB *pPsb = (PSB *) XMALLOC (MTYPE_RSVP, sizeof (PSB));
+
+  if (pPsb == NULL)
+    return NULL;
+  memset (pPsb, 0, sizeof (PSB));
+  pPsb->PsbKey = *pPsbKey;
+  pPsb->Node.key_info = (uns8 *) & pPsb->PsbKey;
+  if (patricia_tree_add (&PsbTree, &pPsb->Node) != E_OK)
+    {
+      XFREE (MTYPE_RSVP, pPsb);
+      zlog_err ("Cannot add node to patricia tree %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  RsvpStatistics.NewPsbCount++;
+  return pPsb;
+}
+
+E_RC
+RemovePsb (PSB_KEY * pPsbKey)
+{
+  PSB *pPsb = FindPsb (pPsbKey);
+
+  if (pPsb == NULL)
+    {
+      zlog_err ("Cannot get PSB %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if (patricia_tree_del (&PsbTree, &pPsb->Node) != E_OK)
+    {
+      zlog_err ("Cannot delete node from patricia %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+void
+PsbDequeueAndInvokeMessages (PSB * pPsb)
+{
+  RSVP_PKT_QUEUE *pQueuedItem;
+  if (!pPsb)
+    return;
+
+  while ((pPsb->TE_InProcess == FALSE) &&
+	 (((pPsb->pFilterSpecData != NULL) &&
+	   (pPsb->pFilterSpecData->pEffectiveFlow != NULL) &&
+	   (pPsb->pFilterSpecData->pEffectiveFlow->TE_InProcess == FALSE)) ||
+	  ((pPsb->pFilterSpecData != NULL)
+	   && (pPsb->pFilterSpecData->pEffectiveFlow == NULL))
+	  || (pPsb->pFilterSpecData == NULL))
+	 && ((pQueuedItem = DequeueRsvpPacket (&pPsb->packet_queue)) != NULL))
+    {
+      RSVP_PKT *pRsvpPkt;
+      uns8 MsgType;
+      uns32 InIfIndex = pQueuedItem->InIfIndex;
+      IPV4_ADDR SourceIp = pQueuedItem->SourceIp;
+      uns8 ttl = pQueuedItem->ttl;
+      pRsvpPkt = pQueuedItem->pRsvpPkt;
+      MsgType = pQueuedItem->MsgType;
+      XFREE (MTYPE_RSVP, pQueuedItem);
+      if (MsgType == PATH_MSG)
+	{
+	  ProcessRsvpPathMessage (pRsvpPkt, InIfIndex, SourceIp, ttl);
+	}
+      else if (MsgType == PATH_TEAR_MSG)
+	{
+	  ProcessRsvpPathTearMessage (pRsvpPkt, InIfIndex, SourceIp, ttl);
+	  return;
+	}
+      else if (MsgType == RESV_MSG)
+	{
+	  ProcessRsvpResvMessage (pRsvpPkt);
+	}
+      else if (MsgType == RESV_TEAR_MSG)
+	{
+	  ProcessRsvpResvTearMessage (pRsvpPkt);
+	}
+      else if (MsgType == RESV_ERR_MSG)
+	{
+	  ProcessRsvpResvErrMessage (pRsvpPkt);
+	}
+      else
+	zlog_err ("Unknown message type %d %s %d", MsgType, __FILE__,
+		  __LINE__);
+    }
+}
+
+static int RsvpPathRefreshTimer (struct thread *);
+
+E_RC
+RsvpPathRefresh (PSB * pPsb)
+{
+  E_RC rc = E_OK;
+  zlog_info ("entering RsvpPathRefresh");
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x .Src %x .LspId %x",
+	     pPsb->PsbKey.Session.Dest,
+	     pPsb->PsbKey.Session.TunnelId,
+	     pPsb->PsbKey.Session.ExtTunelId,
+	     pPsb->PsbKey.SenderTemplate.IpAddr,
+	     pPsb->PsbKey.SenderTemplate.LspId);
+  if ((pPsb->pSentBuffer == NULL) || (pPsb->SentBufferLen == 0))
+    {
+      if (EncodeAndSendRsvpPathMessage (&pPsb->OldPacket,
+					pPsb->NextHop,
+					pPsb->OutIfIndex,
+					pPsb->ttl - 1,
+					&pPsb->pSentBuffer,
+					&pPsb->SentBufferLen) != E_OK)
+	{
+	  zlog_err ("Cannot encode/send message");
+	  rc = E_ERR;
+	}
+    }
+  else
+    {
+      if (SendRawData
+	  (pPsb->pSentBuffer, pPsb->SentBufferLen, pPsb->NextHop,
+	   pPsb->OutIfIndex, pPsb->ttl - 1, TRUE) != E_OK)
+	{
+	  zlog_err ("Cannot send raw data %s %d", __FILE__, __LINE__);
+	  rc = E_ERR;
+	}
+    }
+  if (StopPathRefreshTimer (&pPsb->PathRefreshTimer) != E_OK)
+    {
+      zlog_err ("Cannot stop PathRefreshTimer %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if (StartPathRefreshTimer
+      (pPsb->RefreshValue, &pPsb->PathRefreshTimer, pPsb) != E_OK)
+    {
+      zlog_err ("Cannot add timer %s %d", __FILE__, __LINE__);
+      rc = E_ERR;
+    }
+  zlog_info ("leaving RsvpPathRefresh");
+  return rc;
+}
+
+static int
+RsvpPathRefreshTimer (struct thread *thread)
+{
+  PSB *pPsb = THREAD_ARG (thread);
+  if (pPsb == NULL)
+    {
+      zlog_err ("pPsb is NULL %s %d", __FILE__, __LINE__);
+      return;
+    }
+  zlog_info ("entering RsvpPathRefreshTimer");
+  memset (&pPsb->PathRefreshTimer, 0, sizeof (struct thread *));
+  if (RsvpPathRefresh (pPsb) != E_OK)
+    {
+      zlog_err ("an error o RsvpPathRefresh");
+    }
+  zlog_info ("leaving RsvpPathRefreshTimer");
+}
+
+E_RC
+RsvpPathPopERO (RSVP_PKT * pRsvpPkt)
+{
+  ER_SUBOBJ *pErSubObj, *pErSubObjPrev = NULL, *pErSubObjNext;
+  uns8 ExitFlag = FALSE;
+
+  pErSubObj = pRsvpPkt->ReceivedEro.er;
+  while (pErSubObj != NULL)
+    {
+      switch (pErSubObj->SubObjHdr.LType & 0x7F)
+	{
+	case ERO_SUBTYPE_IPV4:
+	  zlog_info ("checking for abstract node %x",
+		     pErSubObj->u.Ipv4.IpAddress);
+	  if (IsAbstractNode
+	      (pErSubObj->u.Ipv4.IpAddress,
+	       pErSubObj->u.Ipv4.PrefixLength) == TRUE)
+	    {
+	      zlog_info ("FOUND...");
+	      if (pErSubObjPrev == NULL)
+		{
+		  pRsvpPkt->ReceivedEro.er = pRsvpPkt->ReceivedEro.er->next;
+		  pErSubObjNext = pRsvpPkt->ReceivedEro.er;
+		}
+	      else
+		{
+		  pErSubObjPrev->next = pErSubObj->next;
+		  pErSubObjNext = pErSubObj->next;
+		}
+	      XFREE (MTYPE_RSVP, pErSubObj);
+	      pErSubObj = pErSubObjNext;
+	    }
+	  else
+	    ExitFlag = TRUE;
+	  break;
+	default:
+	  ExitFlag = TRUE;
+	}
+      if (ExitFlag == TRUE)
+	break;
+    }
+  return E_OK;
+}
+
+uns8
+CompareERO (ER_SUBOBJ * pErSubObj1, ER_SUBOBJ * pErSubObj2, uns16 HopsNum)
+{
+  while ((pErSubObj1 != NULL) && (pErSubObj2 != NULL))
+    {
+      if (memcmp (&pErSubObj1->SubObjHdr,
+		  &pErSubObj2->SubObjHdr, sizeof (ER_SUBOBJ_HDR)) == 0)
+	{
+	  switch (pErSubObj1->SubObjHdr.LType & 0x7F)
+	    {
+	    case ERO_SUBTYPE_IPV4:
+	      if (memcmp (&pErSubObj1->u.Ipv4,
+			  &pErSubObj2->u.Ipv4, sizeof (ER_IPV4_SUBOBJ)) != 0)
+		{
+		  zlog_info ("IP address differs %x %x...",
+			     pErSubObj1->u.Ipv4.IpAddress,
+			     pErSubObj2->u.Ipv4.IpAddress);
+		  return TRUE;
+		}
+	      break;
+	    case ERO_SUBTYPE_AS:
+	      if (memcmp (&pErSubObj1->u.AS,
+			  &pErSubObj2->u.AS, sizeof (ER_AS_SUBOBJ)) != 0)
+		{
+		  return TRUE;
+		}
+	      break;
+	    default:
+	      return FALSE;
+	    }
+	}
+      if (HopsNum == 1)
+	{
+	  return FALSE;
+	}
+      pErSubObj1 = pErSubObj1->next;
+      pErSubObj2 = pErSubObj2->next;
+    }
+
+  if (((pErSubObj1 == NULL) &&
+       (pErSubObj2 != NULL)) ||
+      ((pErSubObj1 != NULL) && (pErSubObj2 == NULL)))
+    {
+      zlog_info ("Number of elements differs...");
+      return TRUE;
+    }
+  return FALSE;
+}
+
+static int
+RsvpPathAgeOut (struct thread *thread)
+{
+  PSB *pPsb = THREAD_ARG (thread);
+
+  zlog_info ("entering RsvpPathAgeOut");
+
+  // jleu: timer is not rescheduled
+  memset (&pPsb->AgeOutTimer, 0, sizeof (struct thread *));
+
+  if (pPsb->OutIfIndex != 0)
+    {
+      if (EncodeAndSendRsvpPathTearMessage
+	  (&pPsb->OldPacket, pPsb->NextHop, pPsb->OutIfIndex,
+	   pPsb->ttl - 1) != E_OK)
+	{
+	  zlog_err ("an error on EncodeAndSendRsvpPathTearMessage %s %d",
+		    __FILE__, __LINE__);
+	}
+    }
+  if (DeleteSender (pPsb) != E_OK)
+    {
+      zlog_err ("an error on DeleteSender %s %d", __FILE__, __LINE__);
+    }
+  RsvpStatistics.PsbAgeOutCount++;
+  zlog_info ("leaving RsvpPathAgeOut");
+}
+
+uns8
+IsEgress (PSB * pPsb)
+{
+  return IsAbstractNode (pPsb->OldPacket.Session.Dest, 32);
+}
+
+E_RC
+ProcessRsvpPathMessage (RSVP_PKT * pRsvpPkt, uns32 IfIndex,
+			IPV4_ADDR SrcIpAddr, uns8 ttl)
+{
+  PSB *pPsb;
+  PSB_KEY PsbKey;
+  RSVP_PKT_QUEUE *pQueuedItem;
+  uns8 ApplicationTrapFlag = FALSE;
+  zlog_info ("entering ProcessRsvpPathMessage");
+  RsvpStatistics.PathMsgCount++;
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+
+  PsbKey.Session = pRsvpPkt->Session;
+  PsbKey.SenderTemplate = pRsvpPkt->SenderTemplate;
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x .Src %x .LspId %x",
+	     PsbKey.Session.Dest,
+	     PsbKey.Session.TunnelId,
+	     PsbKey.Session.ExtTunelId,
+	     PsbKey.SenderTemplate.IpAddr, PsbKey.SenderTemplate.LspId);
+  if ((pPsb = FindPsb (&PsbKey)) == NULL)
+    {
+      if ((pPsb = NewPsb (&PsbKey)) == NULL)
+	{
+	  zlog_err ("Cannot create PSB");
+	  FreeRsvpPkt (pRsvpPkt);
+	  return E_ERR;
+	}
+      ApplicationTrapFlag = TRUE;
+      memcpy (&pPsb->OldPacket.Session, &pRsvpPkt->Session,
+	      sizeof (SESSION_OBJ));
+      memcpy (&pPsb->OldPacket.SenderTemplate, &pRsvpPkt->SenderTemplate,
+	      sizeof (SENDER_TEMPLATE_OBJ));
+      memcpy (&pPsb->OldPacket.LabelRequest, &pRsvpPkt->LabelRequest,
+	      sizeof (LABEL_REQUEST_OBJ));
+      pPsb->RefreshValue =
+	PathRefreshInterval + RefreshRandomize (PathRefreshInterval);
+    }
+  else
+    {
+      if (StopPathAgeOutTimer (&pPsb->AgeOutTimer) != E_OK)
+	{
+	  zlog_err ("Cannot stop Ageout timer");
+	}
+      if (pPsb->TE_InProcess == TRUE)
+	{
+	  if ((pQueuedItem =
+	       (RSVP_PKT_QUEUE *) XMALLOC (MTYPE_RSVP,
+					   sizeof (RSVP_PKT_QUEUE))) == NULL)
+	    {
+	      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  pQueuedItem->MsgType = PATH_MSG;
+	  pQueuedItem->InIfIndex = IfIndex;
+	  pQueuedItem->pRsvpPkt = pRsvpPkt;
+	  pQueuedItem->SourceIp = SrcIpAddr;
+	  pQueuedItem->ttl = ttl;
+	  pQueuedItem->next = NULL;
+	  if (EnqueueRsvpPacket (pQueuedItem, &pPsb->packet_queue) != E_OK)
+	    {
+	      zlog_err ("Cannot enqueue Path");
+	    }
+	  return E_OK;
+	}
+    }
+  pPsb->InIfIndex = IfIndex;
+  pPsb->PrevHop = pRsvpPkt->ReceivedRsvpHop.PHop /*SrcIpAddr */ ;
+  pPsb->ttl = ttl;
+  if (CheckRRO4Loop (pRsvpPkt->ReceivedRro.rr) != E_OK)
+    {
+      zlog_err ("Loop detected");
+      if (GeneratePathErrMessage
+	  (pPsb, ROUTING_PROBLEM_ERR_CODE,
+	   RRO_INIDICATED_ROUTING_LOOP) != E_OK)
+	{
+	  zlog_err ("Cannot generate PAthErr message %s %d", __FILE__,
+		    __LINE__);
+	}
+      if (DeleteSender (pPsb) != E_OK)
+	{
+	  zlog_err ("An error on DeleteSender %s %d", __FILE__, __LINE__);
+	}
+      FreeRsvpPkt (pRsvpPkt);
+      return E_ERR;
+    }
+  if (memcmp
+      (&pRsvpPkt->TimeValues, &pPsb->OldPacket.TimeValues,
+       sizeof (TIME_VALUES_OBJ)) != 0)
+    {
+      uns32 val;
+      memcpy (&pPsb->OldPacket.TimeValues, &pRsvpPkt->TimeValues,
+	      sizeof (TIME_VALUES_OBJ));
+
+      val = (uns32) pPsb->OldPacket.TimeValues.TimeValues / 10000;
+      /* 3*R: */
+      val *= 3;
+      /* (2M+1) * (3*R): */
+      val = (2 * RefreshMultiple + 1) * val;
+      /* and divide by 4 to get (M + 0.5) * (1.5 * R) */
+      pPsb->AgeOutValue = val >> 2;
+      zlog_info ("AgeOut value %d", pPsb->AgeOutValue);
+    }
+
+  if (memcmp (&pRsvpPkt->ReceivedRsvpHop,
+	      &pPsb->OldPacket.ReceivedRsvpHop, sizeof (RSVP_HOP_OBJ)) != 0)
+    {
+      memcpy (&pPsb->OldPacket.ReceivedRsvpHop, &pRsvpPkt->ReceivedRsvpHop,
+	      sizeof (RSVP_HOP_OBJ));
+      pPsb->PathRefreshFlag = TRUE;
+      pPsb->ResvRefreshFlag = TRUE;
+    }
+  if (memcmp (&pRsvpPkt->SenderTSpec,
+	      &pPsb->OldPacket.SenderTSpec, sizeof (SENDER_TSPEC_OBJ)) != 0)
+    {
+      memcpy (&pPsb->OldPacket.SenderTSpec, &pRsvpPkt->SenderTSpec,
+	      sizeof (SENDER_TSPEC_OBJ));
+      ApplicationTrapFlag = TRUE;
+    }
+  zlog_info ("popping ERO...");
+  if (RsvpPathPopERO (pRsvpPkt) != E_OK)
+    {
+      zlog_err ("Cannot pop ERO");
+      FreeRsvpPkt (pRsvpPkt);
+      return E_ERR;
+    }
+  zlog_info ("comparing ERO...");
+  if (CompareERO (pPsb->OldPacket.ReceivedEro.er,
+		  pRsvpPkt->ReceivedEro.er, 0) == TRUE)
+    {
+      zlog_info ("not equal...");
+      pPsb->PathRefreshFlag = TRUE;
+    }
+  zlog_info ("comparing ERO...");
+  if (CompareERO (pPsb->OldPacket.ReceivedEro.er,
+		  pRsvpPkt->ReceivedEro.er, 1) == TRUE)
+    {
+      zlog_info ("not equal...");
+      ApplicationTrapFlag = TRUE;
+    }
+  if (pPsb->OldPacket.SessionAttributes.CType ==
+      SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+    {
+      if (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.SessionName != NULL)
+	{
+	  XFREE (MTYPE_RSVP,
+		 pPsb->OldPacket.SessionAttributes.u.SessAttrRa.SessionName);
+	  pPsb->OldPacket.SessionAttributes.u.SessAttrRa.SessionName = NULL;
+	  pPsb->OldPacket.SessionAttributes.u.SessAttrRa.NameLength = 0;
+	}
+    }
+  else if (pPsb->OldPacket.SessionAttributes.CType ==
+	   SESSION_ATTRIBUTES_CLASS_TYPE)
+    {
+      if (pPsb->OldPacket.SessionAttributes.u.SessAttr.SessionName != NULL)
+	{
+	  XFREE (MTYPE_RSVP,
+		 pPsb->OldPacket.SessionAttributes.u.SessAttr.SessionName);
+	  pPsb->OldPacket.SessionAttributes.u.SessAttr.SessionName = NULL;
+	  pPsb->OldPacket.SessionAttributes.u.SessAttr.NameLength = 0;
+	}
+    }
+  if (pPsb->OldPacket.SessionAttributes.CType !=
+      pRsvpPkt->SessionAttributes.CType)
+    {
+      memcpy (&pPsb->OldPacket.SessionAttributes,
+	      &pRsvpPkt->SessionAttributes, sizeof (SESSION_ATTRIBUTES_OBJ));
+      if (pRsvpPkt->SessionAttributes.CType ==
+	  SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+	{
+	  pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName = NULL;
+	  pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength = 0;
+	}
+      else if (pRsvpPkt->SessionAttributes.CType ==
+	       SESSION_ATTRIBUTES_CLASS_TYPE)
+	{
+	  pRsvpPkt->SessionAttributes.u.SessAttr.SessionName = NULL;
+	  pRsvpPkt->SessionAttributes.u.SessAttr.NameLength = 0;
+	}
+      ApplicationTrapFlag = TRUE;
+    }
+  else if (pPsb->OldPacket.SessionAttributes.CType ==
+	   SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+    {
+      pPsb->OldPacket.SessionAttributes.u.SessAttrRa.NameLength =
+	pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength;
+      pPsb->OldPacket.SessionAttributes.u.SessAttrRa.SessionName =
+	pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName;
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName = NULL;
+      pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength = 0;
+      if ((pPsb->OldPacket.SessionAttributes.u.SessAttrRa.Flags !=
+	   pRsvpPkt->SessionAttributes.u.SessAttrRa.Flags)
+	  || (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.SetPrio !=
+	      pRsvpPkt->SessionAttributes.u.SessAttrRa.SetPrio)
+	  || (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.HoldPrio !=
+	      pRsvpPkt->SessionAttributes.u.SessAttrRa.HoldPrio)
+	  || (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.ExcludeAny !=
+	      pRsvpPkt->SessionAttributes.u.SessAttrRa.ExcludeAny)
+	  || (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.IncludeAny !=
+	      pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAny)
+	  || (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.IncludeAll !=
+	      pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAll))
+	{
+	  pPsb->OldPacket.SessionAttributes.u.SessAttrRa.Flags =
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.Flags;
+	  pPsb->OldPacket.SessionAttributes.u.SessAttrRa.HoldPrio =
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.HoldPrio;
+	  pPsb->OldPacket.SessionAttributes.u.SessAttrRa.SetPrio =
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.SetPrio;
+
+	  pPsb->OldPacket.SessionAttributes.u.SessAttrRa.ExcludeAny =
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.ExcludeAny;
+	  pPsb->OldPacket.SessionAttributes.u.SessAttrRa.IncludeAny =
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAny;
+	  pPsb->OldPacket.SessionAttributes.u.SessAttrRa.IncludeAll =
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAll;
+	  ApplicationTrapFlag = TRUE;
+	}
+    }
+  else if (pPsb->OldPacket.SessionAttributes.CType ==
+	   SESSION_ATTRIBUTES_CLASS_TYPE)
+    {
+      pPsb->OldPacket.SessionAttributes.u.SessAttr.NameLength =
+	pRsvpPkt->SessionAttributes.u.SessAttr.NameLength;
+      pPsb->OldPacket.SessionAttributes.u.SessAttr.SessionName =
+	pRsvpPkt->SessionAttributes.u.SessAttr.SessionName;
+      pRsvpPkt->SessionAttributes.u.SessAttr.SessionName = NULL;
+      pRsvpPkt->SessionAttributes.u.SessAttr.NameLength = 0;
+      if ((pPsb->OldPacket.SessionAttributes.u.SessAttr.Flags !=
+	   pRsvpPkt->SessionAttributes.u.SessAttr.Flags)
+	  || (pPsb->OldPacket.SessionAttributes.u.SessAttr.SetPrio !=
+	      pRsvpPkt->SessionAttributes.u.SessAttr.SetPrio)
+	  || (pPsb->OldPacket.SessionAttributes.u.SessAttr.HoldPrio !=
+	      pRsvpPkt->SessionAttributes.u.SessAttr.HoldPrio))
+	{
+	  pPsb->OldPacket.SessionAttributes.u.SessAttr.Flags =
+	    pRsvpPkt->SessionAttributes.u.SessAttr.Flags;
+	  pPsb->OldPacket.SessionAttributes.u.SessAttr.HoldPrio =
+	    pRsvpPkt->SessionAttributes.u.SessAttr.HoldPrio;
+	  pPsb->OldPacket.SessionAttributes.u.SessAttr.SetPrio =
+	    pRsvpPkt->SessionAttributes.u.SessAttr.SetPrio;
+
+	  ApplicationTrapFlag = TRUE;
+	}
+    }
+  FreeERO (&pPsb->OldPacket.ReceivedEro);
+  pPsb->OldPacket.ReceivedEro = pRsvpPkt->ReceivedEro;
+  pRsvpPkt->ReceivedEro.er = NULL;
+  FreeRRO (&pPsb->OldPacket.ReceivedRro);
+  pPsb->OldPacket.ReceivedRro = pRsvpPkt->ReceivedRro;
+  pRsvpPkt->ReceivedRro.rr = NULL;
+  if ((ApplicationTrapFlag == TRUE) ||
+      ((IsEgress (pPsb) == TRUE) && (pPsb->pRsb == NULL)))
+    {
+      if (IsEgress (pPsb) == TRUE)
+	{
+	  if (pPsb->OldPacket.ReceivedEro.er != NULL)
+	    {
+	      zlog_err ("Reaching Egress with non-empty ERO!!!");
+	    }
+	  else
+	    {
+	      zlog_info ("Egress reached");
+	      if (StartPathAgeOutTimer
+		  (pPsb->AgeOutValue, &pPsb->AgeOutTimer, pPsb) != E_OK)
+		{
+		  zlog_err ("Cannot start AgeOut timer ");
+		}
+	      FreeRsvpPkt (pRsvpPkt);
+	      return NewModifiedPath (pPsb);
+	    }
+	}
+      else
+	{
+	  if (StopPathRefreshTimer (&pPsb->PathRefreshTimer) != E_OK)
+	    {
+	      zlog_err ("Cannot stop PathRefresh timer");
+	    }
+	  zlog_info ("Locking Flow %s %d", __FILE__, __LINE__);
+	  pPsb->TE_InProcess = TRUE;
+	  pPsb->PathRefreshFlag = FALSE;
+	  PrepareAndSendMsg2TE (pPsb);
+	}
+    }
+  else
+    {
+      if (StartPathAgeOutTimer (pPsb->AgeOutValue, &pPsb->AgeOutTimer, pPsb)
+	  != E_OK)
+	{
+	  zlog_err ("Cannot start AgeOut timer ");
+	}
+      if (pPsb->PathRefreshFlag == TRUE)
+	{
+	  if (pPsb->OutIfIndex != 0)
+	    {
+	      if (RsvpPathRefresh (pPsb) != E_OK)
+		{
+		  zlog_err ("an error on PathRefresh %s %d", __FILE__,
+			    __LINE__);
+		  FreeRsvpPkt (pRsvpPkt);
+		  return E_ERR;
+		}
+	    }
+	  pPsb->PathRefreshFlag = FALSE;
+	}
+    }
+  if (pPsb->ResvRefreshFlag == TRUE)
+    {
+      zlog_info ("RESV refresh will be called here");
+      pPsb->ResvRefreshFlag = FALSE;
+    }
+  FreeRsvpPkt (pRsvpPkt);
+  zlog_info ("leaving ProcessRsvpPathMessage");
+  return E_OK;
+}
+
+E_RC
+ProcessTEMsgUponPath (TE_API_MSG * pMsg)
+{
+  PSB_KEY PsbKey;
+  PSB *pPsb;
+
+  uns8 FrwChangeFlag = FALSE;
+  zlog_info ("entering ProcessTEMsgUponPath");
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+  PsbKey = pMsg->u.PathNotification.PsbKey;
+
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x .Src %x .LspId %x",
+	     PsbKey.Session.Dest,
+	     PsbKey.Session.TunnelId,
+	     PsbKey.Session.ExtTunelId,
+	     PsbKey.SenderTemplate.IpAddr, PsbKey.SenderTemplate.LspId);
+
+  if ((pPsb = FindPsb (&PsbKey)) != NULL)
+    {
+      zlog_info ("UnLocking Flow %s %d", __FILE__, __LINE__);
+      pPsb->TE_InProcess = FALSE;
+      if (pMsg->u.PathNotification.rc != PATH_PROC_OK)
+	{
+	  uns8 ErrCode;
+	  uns16 ErrVal = 0;
+	  switch (pMsg->u.PathNotification.rc)
+	    {
+	    case BW_UNAVAIL:
+	      ErrCode = POLICY_CTRL_FAILURE_ERR_CODE;
+	      break;
+	    case NO_ROUTE:
+	      ErrCode = ROUTING_PROBLEM_ERR_CODE;
+	      if (pPsb->OldPacket.ReceivedEro.er != NULL)
+		{
+		  if (pPsb->OldPacket.ReceivedEro.er->SubObjHdr.LType & 0x80)
+		    ErrVal = BAD_LOOSE_NODE;
+		  else
+		    ErrVal = BAD_STRICT_NODE;
+		}
+	      else
+		{
+		  ErrVal = NO_ROUTE_AVAILABLE;
+		}
+	      break;
+	    case LABEL_ALLOC_FAILURE:
+	      ErrCode = ROUTING_PROBLEM_ERR_CODE;
+	      ErrVal = LABEL_ALLOCATION_FAILURE;
+	      break;
+	    case UNSUP_L3PID:
+	      ErrCode = ROUTING_PROBLEM_ERR_CODE;
+	      ErrVal = UNSUPPORTED_L3PID;
+	      break;
+	    default:
+	      zlog_err ("Unknown return code, forcing to NO_ROUTE %s %d",
+			__FILE__, __LINE__);
+	      ErrCode = ROUTING_PROBLEM_ERR_CODE;
+	      ErrVal = NO_ROUTE_AVAILABLE;
+	    }
+	  if (GeneratePathErrMessage (pPsb, ErrCode, ErrVal) != E_OK)
+	    {
+	      zlog_err ("Cannot generate PathErr message");
+	    }
+
+	  if (DeleteSender (pPsb) != E_OK)
+	    {
+	      zlog_err ("An error on DeleteSender %s %d", __FILE__, __LINE__);
+	    }
+	  return E_OK;
+	}
+      pPsb->Label = pMsg->u.PathNotification.Label;
+      if (pPsb->NextHop != pMsg->u.PathNotification.NextHop)
+	{
+	  pPsb->NextHop = pMsg->u.PathNotification.NextHop;
+	  FrwChangeFlag = TRUE;
+	}
+      if (pPsb->OutIfIndex != pMsg->u.PathNotification.OutIfIndex)
+	{
+	  pPsb->OutIfIndex = pMsg->u.PathNotification.OutIfIndex;
+	  FrwChangeFlag = TRUE;
+	}
+      if (FrwChangeFlag == TRUE)
+	{
+	  if (pPsb->OldPacket.ReceivedRro.rr != NULL)
+	    {
+	      if (pPsb->OldPacket.AddedRro.rr == NULL)
+		{
+		  if ((pPsb->OldPacket.AddedRro.rr =
+		       (RR_SUBOBJ *) XMALLOC (MTYPE_RSVP,
+					      sizeof (RR_SUBOBJ))) == NULL)
+		    {
+		      zlog_err ("Cannotallocate memory %s %d", __FILE__,
+				__LINE__);
+		      return E_ERR;
+		    }
+		  memset (pPsb->OldPacket.AddedRro.rr, 0, sizeof (RR_SUBOBJ));
+		}
+	      pPsb->OldPacket.AddedRro.rr->SubObjHdr.Type = RRO_SUBTYPE_IPV4;
+	      pPsb->OldPacket.AddedRro.rr->SubObjHdr.Length = 8;
+	      if (IpAddrGetByIfIndex
+		  (pPsb->OutIfIndex,
+		   &pPsb->OldPacket.AddedRro.rr->u.Ipv4.IpAddr) == E_OK)
+		{
+		  pPsb->OldPacket.AddedRro.rr->u.Ipv4.PrefixLen = 32;
+		}
+	      else
+		{
+		  zlog_err ("Cannot get IP address by IfIndex");
+		  XFREE (MTYPE_RSVP, pPsb->OldPacket.AddedRro.rr);
+		  pPsb->OldPacket.AddedRro.rr = NULL;
+		}
+	    }
+	  pPsb->OldPacket.SentRsvpHop.LIH = pPsb->OutIfIndex;
+	  if (IpAddrGetByIfIndex
+	      (pPsb->OutIfIndex, &pPsb->OldPacket.SentRsvpHop.PHop) != E_OK)
+	    {
+	      zlog_err ("Cannot get IP address by IfIndex");
+	    }
+	  else
+	    {
+	      zlog_info ("NHOP %x", pPsb->OldPacket.SentRsvpHop.PHop);
+	    }
+	  if (pPsb->pSentBuffer)
+	    {
+	      XFREE (MTYPE_RSVP, pPsb->pSentBuffer);
+	      pPsb->pSentBuffer = NULL;
+	      pPsb->SentBufferLen = 0;
+	    }
+	  pPsb->Label = pMsg->u.PathNotification.Label;
+	}
+      if (StartPathAgeOutTimer (pPsb->AgeOutValue, &pPsb->AgeOutTimer, pPsb)
+	  != E_OK)
+	{
+	  zlog_err ("Cannot start AgeOut timer ");
+	}
+      RsvpPathRefresh (pPsb);
+      PsbDequeueAndInvokeMessages (pPsb);
+      zlog_info ("leaving ProcessTEMsgUponPath+");
+      return E_OK;
+    }
+  else
+    {
+      zlog_debug ("cannot find PSB");
+    }
+  zlog_info ("leaving ProcessTEMsgUponPath-");
+  return E_ERR;
+}
+
+uns16
+ErHopsCount (PSB * pPsb)
+{
+  ER_SUBOBJ *pErSubObj = pPsb->OldPacket.ReceivedEro.er;
+  uns16 Count = 0;
+  while (pErSubObj != NULL)
+    {
+      if (pErSubObj->SubObjHdr.LType != ERO_SUBTYPE_IPV4)
+	{
+	  break;
+	}
+      else if (pErSubObj->SubObjHdr.LType & 0x80)
+	{
+	  return (Count + 1);
+	}
+      Count++;
+      pErSubObj = pErSubObj->next;
+    }
+  return Count;
+}
+
+static void
+PrepareAndSendMsg2TE (PSB * pPsb)
+{
+  TE_API_MSG msg;
+  memset (&msg, 0, sizeof (msg));
+  msg.NotificationType = PATH_MSG_NOTIFICATION;
+  msg.u.PathNotification.PsbKey = pPsb->PsbKey;
+  msg.u.PathNotification.BW = pPsb->OldPacket.SenderTSpec.PeakDataRate;
+  if (pPsb->OldPacket.SessionAttributes.CType ==
+      SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+    {
+      msg.u.PathNotification.RA_Valid = 1;
+      msg.u.PathNotification.ExcludeAny =
+	pPsb->OldPacket.SessionAttributes.u.SessAttrRa.ExcludeAny;
+      msg.u.PathNotification.IncludeAny =
+	pPsb->OldPacket.SessionAttributes.u.SessAttrRa.IncludeAny;
+      msg.u.PathNotification.IncludeAll =
+	pPsb->OldPacket.SessionAttributes.u.SessAttrRa.IncludeAll;
+      msg.u.PathNotification.HoldPrio =
+	pPsb->OldPacket.SessionAttributes.u.SessAttrRa.HoldPrio;
+      msg.u.PathNotification.SetupPrio =
+	pPsb->OldPacket.SessionAttributes.u.SessAttrRa.SetPrio;
+      if (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.
+	  Flags & LOCAL_PROTECTION_DESIRED)
+	{
+	  msg.u.PathNotification.LocalProtection = 1;
+	}
+      if (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.
+	  Flags & SE_STYLE_DESIRED)
+	{
+	  msg.u.PathNotification.SharedExplicit = 1;
+	}
+    }
+  else if (pPsb->OldPacket.SessionAttributes.CType ==
+	   SESSION_ATTRIBUTES_CLASS_TYPE)
+    {
+      msg.u.PathNotification.HoldPrio =
+	pPsb->OldPacket.SessionAttributes.u.SessAttr.HoldPrio;
+      msg.u.PathNotification.SetupPrio =
+	pPsb->OldPacket.SessionAttributes.u.SessAttr.SetPrio;
+      if (pPsb->OldPacket.SessionAttributes.u.SessAttr.
+	  Flags & LOCAL_PROTECTION_DESIRED)
+	{
+	  msg.u.PathNotification.LocalProtection = 1;
+	}
+      if (pPsb->OldPacket.SessionAttributes.u.SessAttr.
+	  Flags & SE_STYLE_DESIRED)
+	{
+	  msg.u.PathNotification.SharedExplicit = 1;
+	}
+    }
+  else
+    {
+      msg.u.PathNotification.HoldPrio = 4;	/* default */
+      msg.u.PathNotification.SetupPrio = 4;
+    }
+  msg.u.PathNotification.ErHopNumber = ErHopsCount (pPsb);
+  if (msg.u.PathNotification.ErHopNumber > 0)
+    {
+      ER_SUBOBJ *pErSubObj = pPsb->OldPacket.ReceivedEro.er;
+      int i;
+      if (!(pErSubObj->SubObjHdr.LType & 0x80))
+	{
+	  msg.u.PathNotification.FirstErHopStrict = 1;
+	}
+      for (i = 0; i < msg.u.PathNotification.ErHopNumber;
+	   i++, pErSubObj = pErSubObj->next)
+	{
+	  msg.u.PathNotification.ErHops[i] = pErSubObj->u.Ipv4.IpAddress;
+	}
+    }
+  rsvp_send_msg (&msg, sizeof (msg));
+}
+
+E_RC
+DeletePsb (PSB * pPsb)
+{
+  if (StopPathAgeOutTimer (&pPsb->AgeOutTimer) != E_OK)
+    {
+      zlog_err ("Cannot stop Ageout timer");
+      return E_ERR;
+    }
+  if (StopPathRefreshTimer (&pPsb->PathRefreshTimer) != E_OK)
+    {
+      zlog_err ("Cannot stop PathRefresh timer");
+      return E_ERR;
+    }
+  if (pPsb->InIfIndex != 0)
+    {
+      PrepareAndSendLabelReleaseMsg2TE (pPsb);
+    }
+  FreePSB (pPsb);
+  return E_OK;
+}
+
+E_RC
+DeleteSender (PSB * pPsb)
+{
+  RSB *pRsb;
+  FILTER_LIST *pFilterList, *pFilterListPrev = NULL;
+  FILTER_SPEC_DATA *pFilterSpecData = NULL;
+  int Shared = 0;
+  zlog_info ("entering DeleteSender");
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x .Src %x .LspId %x",
+	     pPsb->PsbKey.Session.Dest,
+	     pPsb->PsbKey.Session.TunnelId,
+	     pPsb->PsbKey.Session.ExtTunelId,
+	     pPsb->PsbKey.SenderTemplate.IpAddr,
+	     pPsb->PsbKey.SenderTemplate.LspId);
+  zlog_info ("pPsb %x pRsb %x", pPsb, pPsb->pRsb);
+  if ((pRsb = pPsb->pRsb) == NULL)
+    {
+      RSB_KEY RsbKey;
+      memset (&RsbKey, 0, sizeof (RSB_KEY));
+      RsbKey.Session = pPsb->PsbKey.Session;
+      pRsb = FindRsb (&RsbKey);
+    }
+  if (pRsb != NULL)
+    {
+      if ((pRsb->OldPacket.Style.OptionVector2 & 0x001F) == SE_STYLE_BITS)
+	{
+	  Shared = 1;
+	  zlog_info ("Shared %s %d", __FILE__, __LINE__);
+	}
+      else
+	{
+	  zlog_info ("Not Shared %s %d", __FILE__, __LINE__);
+	}
+      pFilterList = pRsb->OldPacket.pFilterList;
+      zlog_info ("searching for filter data");
+      while (pFilterList != NULL)
+	{
+	  if ((pFilterSpecData = pFilterList->pFilterSpecData) != NULL)
+	    {
+	      zlog_info ("%x %x %x %x",
+			 pPsb->PsbKey.SenderTemplate.IpAddr,
+			 pPsb->PsbKey.SenderTemplate.LspId,
+			 pFilterSpecData->FilterSpec.IpAddr,
+			 pFilterSpecData->FilterSpec.LspId);
+	      if (memcmp (&pPsb->PsbKey.SenderTemplate,
+			  &pFilterSpecData->FilterSpec,
+			  sizeof (FILTER_SPEC_OBJ)) == 0)
+		{
+		  if (pFilterListPrev == NULL)
+		    {
+		      pRsb->OldPacket.pFilterList =
+			pRsb->OldPacket.pFilterList->next;
+		    }
+		  else
+		    {
+		      pFilterListPrev->next = pFilterList->next;
+		    }
+		  if (pPsb->InIfIndex != 0)
+		    {
+		      pFilterSpecData->ToBeDeleted = 1;
+		      if (pFilterSpecData->pPHopResvRefreshList != NULL)
+			pFilterSpecData->pPHopResvRefreshList->
+			  MustBeProcessed = 1;
+		    }
+		  XFREE (MTYPE_RSVP, pFilterList);
+		  break;
+		}
+	      pFilterSpecData = NULL;
+	    }
+	  pFilterListPrev = pFilterList;
+	  pFilterList = pFilterList->next;
+	}
+      if (ForwardResvTearMsg (pRsb) != E_OK)
+	{
+	  zlog_err ("An error on ForwardResvTearMsg");
+	}
+      if (FilterShutDown (pFilterSpecData, Shared) != E_OK)
+	{
+	  zlog_err ("An error on FilterShutDown");
+	}
+      if (ProcessEffectiveFlows (pRsb) != E_OK)
+	{
+	  zlog_err ("an error on ProcessEffectiveFlows %s %d", __FILE__,
+		    __LINE__);
+	}
+      if (pRsb->OldPacket.pFilterList != NULL)
+	{
+	  if (ProcessPHopFilterSpecLists (pRsb, Shared) != E_OK)
+	    {
+	      zlog_err ("an error on ProcessPHopFilterSpecLists %s %d",
+			__FILE__, __LINE__);
+	    }
+	}
+      else
+	{
+	  /* delete RSB */
+	  FreeRSB (pRsb);
+	}
+    }
+  if (DeletePsb (pPsb) != E_OK)
+    {
+      zlog_info ("Cannot delete PSB %s %d", __FILE__, __LINE__);
+      zlog_info ("leaving DeleteSender-");
+      return E_ERR;
+    }
+  zlog_info ("leaving DeleteSender+");
+  return E_OK;
+}
+
+E_RC
+ProcessRsvpPathTearMessage (RSVP_PKT * pRsvpPkt, uns32 IfIndex,
+			    IPV4_ADDR SrcIpAddr, uns8 ttl)
+{
+  PSB *pPsb;
+  PSB_KEY PsbKey;
+  RSVP_PKT_QUEUE *pQueuedItem;
+  zlog_info ("entering ProcessRsvpPathTearMessage");
+
+  RsvpStatistics.PathTearMsgCount++;
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+
+  PsbKey.Session = pRsvpPkt->Session;
+  PsbKey.SenderTemplate = pRsvpPkt->SenderTemplate;
+
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x .Src %x .LspId %x",
+	     PsbKey.Session.Dest,
+	     PsbKey.Session.TunnelId,
+	     PsbKey.Session.ExtTunelId,
+	     PsbKey.SenderTemplate.IpAddr, PsbKey.SenderTemplate.LspId);
+
+  if ((pPsb = FindPsb (&PsbKey)) == NULL)
+    {
+      zlog_info ("leaving ProcessRsvpPathTearMessage");
+      FreeRsvpPkt (pRsvpPkt);
+      return E_OK;
+    }
+  if (pPsb->OutIfIndex != 0)
+    {
+      if (EncodeAndSendRsvpPathTearMessage
+	  (pRsvpPkt, pPsb->NextHop, pPsb->OutIfIndex, pPsb->ttl - 1) != E_OK)
+	{
+	  zlog_err ("An error on EncodeAndSendRsvpPathTearMessage");
+	}
+    }
+  if ((pPsb->TE_InProcess == TRUE) ||
+      ((pPsb->pFilterSpecData != NULL) &&
+       (pPsb->pFilterSpecData->pEffectiveFlow != NULL) &&
+       (pPsb->pFilterSpecData->pEffectiveFlow->TE_InProcess == TRUE)))
+    {
+      if ((pQueuedItem =
+	   (RSVP_PKT_QUEUE *) XMALLOC (MTYPE_RSVP,
+				       sizeof (RSVP_PKT_QUEUE))) == NULL)
+	{
+	  zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	}
+      pQueuedItem->MsgType = PATH_TEAR_MSG;
+      pQueuedItem->InIfIndex = IfIndex;
+      pQueuedItem->pRsvpPkt = pRsvpPkt;
+      pQueuedItem->SourceIp = SrcIpAddr;
+      pQueuedItem->ttl = ttl;
+      pQueuedItem->next = NULL;
+      if (EnqueueRsvpPacket (pQueuedItem, &pPsb->packet_queue) != E_OK)
+	{
+	  zlog_err ("Cannot enqueue packet %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      return E_OK;
+    }
+  FreeRsvpPkt (pRsvpPkt);
+
+  if (DeleteSender (pPsb) != E_OK)
+    {
+      zlog_err ("an error on DeleteSender");
+    }
+  return E_OK;
+}
+
+E_RC
+ProcessRsvpPathErrMessage (RSVP_PKT * pRsvpPkt, uns32 IfIndex,
+			   IPV4_ADDR SrcIpAddr, uns8 ttl)
+{
+  PSB *pPsb;
+  PSB_KEY PsbKey;
+
+  zlog_info ("entering ProcessRsvpPathErrMessage");
+  RsvpStatistics.PathErrMsgCount++;
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+
+  PsbKey.Session = pRsvpPkt->Session;
+  PsbKey.SenderTemplate = pRsvpPkt->SenderTemplate;
+
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x .Src %x .LspId %x",
+	     PsbKey.Session.Dest,
+	     PsbKey.Session.TunnelId,
+	     PsbKey.Session.ExtTunelId,
+	     PsbKey.SenderTemplate.IpAddr, PsbKey.SenderTemplate.LspId);
+
+  if ((pPsb = FindPsb (&PsbKey)) == NULL)
+    {
+      FreeRsvpPkt (pRsvpPkt);
+      return E_ERR;
+    }
+  if (pPsb->InIfIndex == 0)
+    {
+      zlog_info ("Ingress: PathErr received");
+      PrepareAndSendPathErrNotificationMsg2TE (pPsb, &pRsvpPkt->ErrorSpec);
+    }
+  else
+    if (EncodeAndSendRsvpPathErrMessage
+	(pRsvpPkt, pPsb->PrevHop, pPsb->InIfIndex, pPsb->ttl - 1) != E_OK)
+    {
+      zlog_err ("An error in EncodeAndSendRsvpPathErrMessage %s %d", __FILE__,
+		__LINE__);
+      FreeRsvpPkt (pRsvpPkt);
+      return E_ERR;
+    }
+  FreeRsvpPkt (pRsvpPkt);
+  return E_OK;
+}
+
+static E_RC
+StartPathAgeOutTimer (uns32 time, struct thread **pTimerId, void *data)
+{
+  zlog_info ("entering StartPathAgeOutTimer");
+  *pTimerId = thread_add_timer (master, RsvpPathAgeOut, data, time);
+  THREAD_VAL (*pTimerId) = time;
+  zlog_info ("leaving StartPathAgeOutTimer");
+  return E_OK;
+}
+
+static E_RC
+StopPathAgeOutTimer (struct thread **pTimerId)
+{
+  zlog_info ("entering StopPathAgeOutTimer");
+  thread_cancel (*pTimerId);
+  *pTimerId = NULL;
+  zlog_info ("leaving StopPathAgeOutTimer");
+  return E_OK;
+}
+
+static E_RC
+StartPathRefreshTimer (uns32 time, struct thread **pTimerId, void *data)
+{
+  zlog_info ("entering StartPathRefreshTimer");
+  *pTimerId = thread_add_timer (master, RsvpPathRefreshTimer, data, time);
+  zlog_info ("leaving StartPathRefreshTimer");
+  return E_OK;
+}
+
+static E_RC
+StopPathRefreshTimer (struct thread **pTimerId)
+{
+  zlog_info ("entering StopPathRefreshTimer");
+  thread_cancel (*pTimerId);
+  *pTimerId = NULL;
+  zlog_info ("leaving StopPathRefreshTimer");
+  return E_OK;
+}
+
+static void
+PrepareAndSendLabelReleaseMsg2TE (PSB * pPsb)
+{
+  TE_API_MSG msg;
+
+  memset (&msg, 0, sizeof (msg));
+  msg.NotificationType = LABEL_RELEASE_NOTIFICATION;
+  msg.u.LabelRelease.PsbKey = pPsb->PsbKey;
+  msg.u.LabelRelease.Label = pPsb->Label;
+  zlog_info ("sending message to TE upon RESV");
+  rsvp_send_msg (&msg, sizeof (msg));
+}
+
+static void
+PrepareAndSendPathErrNotificationMsg2TE (PSB * pPsb,
+					 ERR_SPEC_OBJ * pErrSpecObj)
+{
+  TE_API_MSG msg;
+
+  memset (&msg, 0, sizeof (msg));
+  msg.NotificationType = PATH_ERR_NOTIFICATION;
+  msg.u.PathErrNotification.PsbKey = pPsb->PsbKey;
+  msg.u.PathErrNotification.ErrSpec = *pErrSpecObj;
+  zlog_info ("sending message to TE upon RESV");
+  rsvp_send_msg (&msg, sizeof (msg));
+}
+
+E_RC
+GeneratePathErrMessage (PSB * pPsb, uns8 ErrCode, uns16 ErrVal)
+{
+  RSVP_PKT RsvpPkt;
+  memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+  RsvpPkt.Session = pPsb->PsbKey.Session;
+  RsvpPkt.SenderTemplate = pPsb->PsbKey.SenderTemplate;
+  RsvpPkt.SenderTSpec = pPsb->OldPacket.SenderTSpec;
+  RsvpPkt.ErrorSpec.IpAddr = GetRouterId ();
+  RsvpPkt.ErrorSpec.ErrCode = ErrCode;
+  RsvpPkt.ErrorSpec.ErrVal = ErrVal;
+  if (EncodeAndSendRsvpPathErrMessage
+      (&RsvpPkt, pPsb->PrevHop, pPsb->InIfIndex, 255) != E_OK)
+    {
+      zlog_err ("Cannot encode/send PathErr message %s %d", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  return E_OK;
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_psb.h quagga-mpls/rsvpd/rsvp_psb.h
--- quagga-0.99.10/rsvpd/rsvp_psb.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_psb.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,49 @@
+#ifndef __RSVP_PSB__
+#define __RSVP_PSB__
+
+
+typedef struct _psb_
+{
+  PATRICIA_NODE Node;
+  PSB_KEY PsbKey;
+  RSVP_PKT OldPacket;
+  int InIfIndex;
+  IPV4_ADDR PrevHop;
+  uns8 ttl;
+  int OutIfIndex;
+  uns32 Label;
+  IPV4_ADDR NextHop;
+  uns32 RefreshValue;
+  struct thread *PathRefreshTimer;
+  uns32 AgeOutValue;
+  struct thread *AgeOutTimer;
+  uns8 PathRefreshFlag;
+  uns8 ResvRefreshFlag;
+  uns8 TE_InProcess;
+  char *pSentBuffer;
+  uns16 SentBufferLen;
+  struct _rsb_ *pRsb;
+  FILTER_SPEC_DATA *pFilterSpecData;
+  struct _rsvp_pkt_queue_ *packet_queue;
+} PSB;
+
+struct _te_api_msg_;
+
+E_RC DeleteSender (PSB * pPsb);
+E_RC ProcessRsvpPathMessage (RSVP_PKT * pRsvpPkt, uns32 IfIndex,
+			     IPV4_ADDR SrcIpAddr, uns8 ttl);
+E_RC ProcessRsvpPathErrMessage (RSVP_PKT * pRsvpPkt, uns32 IfIndex,
+				IPV4_ADDR SrcIpAddr, uns8 ttl);
+E_RC ProcessRsvpPathTearMessage (RSVP_PKT * pRsvpPkt, uns32 IfIndex,
+				 IPV4_ADDR SrcIpAddr, uns8 ttl);
+E_RC GeneratePathErrMessage (PSB * pPsb, uns8 ErrCode, uns16 ErrVal);
+PSB *GetNextPSB (PSB_KEY * pPsbKey);
+PSB *FindPsb (PSB_KEY * pPsbKey);
+PSB *NewPsb (PSB_KEY * pPsbKey);
+E_RC RsvpPathRefresh (PSB * pPsb);
+E_RC InitRsvpPathMessageProcessing ();
+E_RC ProcessTEMsgUponPath (struct _te_api_msg_ *pMsg);
+E_RC RemovePsb (PSB_KEY * pPsbKey);
+E_RC DeletePsb (PSB * pPsb);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvp_resv.c quagga-mpls/rsvpd/rsvp_resv.c
--- quagga-0.99.10/rsvpd/rsvp_resv.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_resv.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,3630 @@
+/* Module:   rsvp_resv.c
+   Contains: RSVP RESV, RESV TEAR and RESV ERROR message 
+   processing functions.
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "rsvp.h"
+#include "thread.h"
+
+uns32 ResvRefreshInterval = 30;	/* sec */
+uns32 ResvRefreshMultiple = /*3 */ 12;
+
+extern RSVP_STATISTICS RsvpStatistics;
+extern struct thread_master *master;
+
+PATRICIA_TREE ResbTree;
+
+static E_RC ResvRefreshProc (RSB * pRsb,
+			     PHOP_RESV_REFRESH_LIST * pPHopResvRefreshList);
+static E_RC BuildRRSubObj (FILTER_SPEC_DATA * pFilterSpecData);
+static void PrepareAndSendMsg2TE4SE (RSB * pRsb,
+				     EFFECTIVE_FLOW * pEffectiveFlow);
+static void PrepareAndSendMsg2TE4FF (RSB * pRsb,
+				     FILTER_SPEC_DATA * pFilterSpecData);
+static void PrepareAndSendBWReleaseMsg2TE (PSB * pPsb, uns8 Priority,
+					   uns32 IfIndex, uns8 Shared);
+static void PrepareAndSendResvTearNotificationMsg2TE (RSB * pRsb,
+						      FILTER_SPEC_OBJ *
+						      pFilterSpec);
+E_RC StartBlocadeTimer (uns32 time, struct thread **pTimerId, void *data);
+
+RSB *
+NewRSB (RSB_KEY * pRsbKey)
+{
+  RSB *pRsb = NULL;
+  if ((pRsb = (RSB *) XMALLOC (MTYPE_RSVP, sizeof (RSB))) != NULL)
+    {
+      memset (pRsb, 0, sizeof (RSB));
+      pRsb->RsbKey = *pRsbKey;
+      pRsb->Node.key_info = (uns8 *) & pRsb->RsbKey;
+      if (patricia_tree_add (&ResbTree, &pRsb->Node) != E_OK)
+	{
+	  XFREE (MTYPE_RSVP, pRsb);
+	  return NULL;
+	}
+    }
+  RsvpStatistics.NewRsbCount++;
+  return pRsb;
+}
+
+RSB *
+GetNextRSB (RSB_KEY * pRsbKey)
+{
+  return (RSB *) patricia_tree_getnext (&ResbTree, (const uns8 *) pRsbKey);
+}
+
+RSB *
+FindRsb (RSB_KEY * pRsbKey)
+{
+  return (RSB *) patricia_tree_get (&ResbTree, (const uns8 *) pRsbKey);
+}
+
+E_RC
+RemoveRSB (RSB_KEY * pRsbKey)
+{
+  RSB *pRsb = (RSB *) patricia_tree_get (&ResbTree, (const uns8 *) pRsbKey);
+  if (pRsb == NULL)
+    {
+      zlog_err ("RSB is not found in patricia %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  return patricia_tree_del (&ResbTree, &pRsb->Node);
+}
+
+E_RC
+GenerateResvErr4SingleFilterSpec (FILTER_SPEC_DATA * pFilterSpecData,
+				  RSB * pRsb,
+				  IPV4_ADDR Dest,
+				  uns32 OutIfIndex,
+				  uns8 ErrCode, uns16 ErrVal)
+{
+  FILTER_LIST *pFilterList;
+  RSVP_PKT RsvpPkt;
+
+  memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+  RsvpPkt.Session = pRsb->RsbKey.Session;
+  RsvpPkt.Style = pRsb->OldPacket.Style;
+  RsvpPkt.ErrorSpec.IpAddr = GetRouterId ();
+  RsvpPkt.ErrorSpec.ErrCode = ErrCode;
+  RsvpPkt.ErrorSpec.ErrVal = ErrVal;
+  RsvpPkt.SentRsvpHop.LIH = OutIfIndex;
+  if (IpAddrGetByIfIndex (OutIfIndex, &RsvpPkt.SentRsvpHop.PHop) != E_OK)
+    {
+      zlog_err ("Cannot get IP address by IfIndex");
+      return E_ERR;
+    }
+  if ((pFilterList =
+       (FILTER_LIST *) XMALLOC (MTYPE_RSVP, sizeof (FILTER_LIST))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  memset (pFilterList, 0, sizeof (FILTER_LIST));
+  pFilterList->pFilterSpecData = pFilterSpecData;
+  RsvpPkt.pFilterList = pFilterList;
+  if (EncodeAndSendRsvpResvErrMessage (&RsvpPkt, Dest, OutIfIndex, 200) !=
+      E_OK)
+    {
+      zlog_err ("An error on encode/send %s %d", __FILE__, __LINE__);
+      XFREE (MTYPE_RSVP, pFilterList);
+      return E_ERR;
+    }
+  XFREE (MTYPE_RSVP, pFilterList);
+  return E_OK;
+}
+
+E_RC
+InitResvProcessing ()
+{
+  PATRICIA_PARAMS params;
+  memset (&params, 0, sizeof (params));
+
+  params.key_size = sizeof (RSB_KEY);
+
+  if (patricia_tree_init (&ResbTree, &params) != E_OK)
+    {
+      zlog_err ("Cannot initiate patricia tree %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+PHOP_RESV_REFRESH_LIST *
+GetOrCreatePHopResvRefreshNode (RSB * pRsb,
+				IPV4_ADDR IpAddr, uns32 LIH, uns32 InIfIndex)
+{
+  PHOP_RESV_REFRESH_LIST *pPHopResvRefreshList =
+    pRsb->pPHopResvRefreshList, *pPHopResvRefreshListPrev =
+    NULL, *pPHopResvRefreshListNew;
+
+  while (pPHopResvRefreshList != NULL)
+    {
+      if ((pPHopResvRefreshList->PHop.PHop == IpAddr) &&
+	  (pPHopResvRefreshList->PHop.LIH == LIH))
+	{
+	  return pPHopResvRefreshList;
+	}
+      pPHopResvRefreshListPrev = pPHopResvRefreshList;
+      pPHopResvRefreshList = pPHopResvRefreshList->next;
+    }
+  if ((pPHopResvRefreshListNew =
+       (PHOP_RESV_REFRESH_LIST *) XMALLOC (MTYPE_RSVP,
+					   sizeof (PHOP_RESV_REFRESH_LIST)))
+      == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  memset (pPHopResvRefreshListNew, 0, sizeof (PHOP_RESV_REFRESH_LIST));
+  pPHopResvRefreshListNew->PHop.PHop = IpAddr;
+  pPHopResvRefreshListNew->PHop.LIH = LIH;
+  pPHopResvRefreshListNew->InIfIndex = InIfIndex;
+  pPHopResvRefreshListNew->RefreshValue =
+    ResvRefreshInterval + RefreshRandomize (ResvRefreshInterval);
+  if (pPHopResvRefreshListPrev == NULL)
+    {
+      pRsb->pPHopResvRefreshList = pPHopResvRefreshListNew;
+    }
+  else
+    {
+      pPHopResvRefreshListPrev->next = pPHopResvRefreshListNew;
+      pPHopResvRefreshListNew->next = pPHopResvRefreshList;
+    }
+  return pPHopResvRefreshListNew;
+}
+
+E_RC
+DeletePHopResvRefreshList (RSB * pRsb,
+			   PHOP_RESV_REFRESH_LIST * pPHopResvRefreshList)
+{
+  PHOP_RESV_REFRESH_LIST *pPHopResvRefreshList2 =
+    pRsb->pPHopResvRefreshList, *pPHopResvRefreshListPrev = NULL;
+  zlog_info ("entering DeletePHopResvRefreshList");
+  while (pPHopResvRefreshList2 != NULL)
+    {
+      if (pPHopResvRefreshList2 == pPHopResvRefreshList)
+	{
+	  if (pPHopResvRefreshListPrev == NULL)
+	    {
+	      pRsb->pPHopResvRefreshList = pRsb->pPHopResvRefreshList->next;
+	    }
+	  else
+	    {
+	      pPHopResvRefreshListPrev->next = pPHopResvRefreshList2->next;
+	    }
+	  if (pPHopResvRefreshList2->pAddedRro)
+	    XFREE (MTYPE_RSVP, pPHopResvRefreshList2->pAddedRro);
+	  if (pPHopResvRefreshList2->pSentBuffer)
+	    XFREE (MTYPE_RSVP, pPHopResvRefreshList2->pSentBuffer);
+	  XFREE (MTYPE_RSVP, pPHopResvRefreshList2);
+	  zlog_info ("leaving DeletePHopResvRefreshList+");
+	  return E_OK;
+	}
+      pPHopResvRefreshListPrev = pPHopResvRefreshList2;
+      pPHopResvRefreshList2 = pPHopResvRefreshList2->next;
+    }
+  zlog_info ("leaving DeletePHopResvRefreshList-");
+  return E_ERR;
+}
+
+EFFECTIVE_FLOW *
+GetOrCreateEffectiveFlow (RSB * pRsb, uns32 IfIndex)
+{
+  EFFECTIVE_FLOW *pEffectiveFlow, *pEffectiveFlowPrev = NULL;
+  zlog_info ("entering GetOrCreateEffectiveFlow");
+  pEffectiveFlow = pRsb->pEffectiveFlow;
+  while (pEffectiveFlow != NULL)
+    {
+      if (pEffectiveFlow->IfIndex == IfIndex)
+	{
+	  break;
+	}
+      pEffectiveFlow = pEffectiveFlow->next;
+    }
+  if (pEffectiveFlow != NULL)
+    {
+      zlog_info ("leaving GetOrCreateEffectiveFlow(1)");
+      return pEffectiveFlow;
+    }
+  if ((pEffectiveFlow =
+       (EFFECTIVE_FLOW *) XMALLOC (MTYPE_RSVP,
+				   sizeof (EFFECTIVE_FLOW))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  memset (pEffectiveFlow, 0, sizeof (EFFECTIVE_FLOW));
+  pEffectiveFlow->IfIndex = IfIndex;
+//    pEffectiveFlow->MustBeProcessed = 1;
+  if (pEffectiveFlowPrev == NULL)
+    {
+      pRsb->pEffectiveFlow = pEffectiveFlow;
+    }
+  else
+    {
+      pEffectiveFlowPrev->next = pEffectiveFlow;
+    }
+  zlog_info ("leaving GetOrCreateEffectiveFlow(2)");
+  return pEffectiveFlow;
+}
+
+E_RC
+DeleteEffectiveFlow (RSB * pRsb, EFFECTIVE_FLOW * pEffectiveFlow)
+{
+  EFFECTIVE_FLOW *pEffectiveFlow2 =
+    pRsb->pEffectiveFlow, *pEffectiveFlowPrev = NULL;
+  zlog_info ("entering DeleteEffectiveFlow");
+  while (pEffectiveFlow2 != NULL)
+    {
+      if (pEffectiveFlow2 == pEffectiveFlow)
+	{
+	  if (pEffectiveFlowPrev == NULL)
+	    {
+	      pRsb->pEffectiveFlow = pRsb->pEffectiveFlow->next;
+	    }
+	  else
+	    {
+	      pEffectiveFlowPrev->next = pEffectiveFlow2->next;
+	    }
+	  XFREE (MTYPE_RSVP, pEffectiveFlow2);
+	  zlog_info ("leaving DeleteEffectiveFlow+");
+	  return E_OK;
+	}
+      pEffectiveFlowPrev = pEffectiveFlow2;
+      pEffectiveFlow2 = pEffectiveFlow2->next;
+    }
+  zlog_info ("leaving DeleteEffectiveFlow-");
+  return E_ERR;
+}
+
+E_RC
+DeleteFilterListNode (FILTER_LIST ** ppFilterList,
+		      FILTER_SPEC_DATA * pFilterSpecData)
+{
+  FILTER_LIST *pFilterList, *pFilterListPrev = NULL;
+  zlog_info ("entering DeleteFilterListNode");
+  if (ppFilterList == NULL)
+    {
+      return E_OK;
+    }
+  pFilterList = *ppFilterList;
+  while (pFilterList != NULL)
+    {
+      if (pFilterList->pFilterSpecData == pFilterSpecData)
+	{
+	  break;
+	}
+      pFilterListPrev = pFilterList;
+      pFilterList = pFilterList->next;
+    }
+  if (pFilterList == NULL)
+    {
+      return E_ERR;
+    }
+  if (pFilterListPrev == NULL)
+    {
+      *ppFilterList = (*ppFilterList)->next;
+    }
+  else
+    {
+      pFilterListPrev->next = pFilterList->next;
+    }
+  XFREE (MTYPE_RSVP, pFilterList);
+  zlog_info ("leaving DeleteFilterListNode");
+  return E_OK;
+}
+
+E_RC
+NewFilterListNode (FILTER_LIST ** ppFilterListHead,
+		   FILTER_SPEC_DATA * pFilterSpecData)
+{
+  FILTER_LIST *pFilterList = *ppFilterListHead, *pFilterListPrev = NULL;
+  zlog_info ("entering NewFilterListNode");
+  while (pFilterList != NULL)
+    {
+      if (pFilterList->pFilterSpecData == pFilterSpecData)
+	{
+	  zlog_err ("Node already exists %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pFilterListPrev = pFilterList;
+      pFilterList = pFilterList->next;
+    }
+  if ((pFilterList =
+       (FILTER_LIST *) XMALLOC (MTYPE_RSVP, sizeof (FILTER_LIST))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  memset (pFilterList, 0, sizeof (FILTER_LIST));
+  pFilterList->pFilterSpecData = pFilterSpecData;
+  if (pFilterListPrev == NULL)
+    {
+      *ppFilterListHead = pFilterList;
+    }
+  else
+    {
+      pFilterListPrev->next = pFilterList;
+    }
+  zlog_info ("leaving NewFilterListNode");
+  return E_OK;
+}
+
+
+uns8
+AdSpecBWGreaterThanTSpecBW (PSB * pPsb)
+{
+  if (pPsb->OldPacket.SentAdSpec.CType != 0)
+    {
+      if (pPsb->OldPacket.SentAdSpec.AdSpecGen.PathBW >
+	  pPsb->OldPacket.SenderTSpec.PeakDataRate)
+	{
+	  return TRUE;
+	}
+    }
+  return FALSE;
+}
+
+uns8
+TSpecGreaterThanFlowSpecGuar (SENDER_TSPEC_OBJ * pSenderTSpec,
+			      FLOW_SPEC_OBJ * pFlowSpec)
+{
+  if (pSenderTSpec->PeakDataRate > pFlowSpec->u.Guar.CtrlLoad.PeakDataRate)
+    {
+      return TRUE;
+    }
+  return FALSE;
+}
+
+uns8
+TSpecGreaterThanFlowSpecCtrl (SENDER_TSPEC_OBJ * pSenderTSpec,
+			      FLOW_SPEC_OBJ * pFlowSpec)
+{
+  if (pSenderTSpec->PeakDataRate > pFlowSpec->u.CtrlLoad.PeakDataRate)
+    {
+      return TRUE;
+    }
+  return FALSE;
+}
+
+uns8
+FlowSpec1GreaterThanFlowSpec2 (FLOW_SPEC_OBJ * pFlowSpec1,
+			       FLOW_SPEC_OBJ * pFlowSpec2)
+{
+  if (pFlowSpec1->ServHdr.ServHdr == FLOW_SPEC_CTRL_LOAD_SERV_NUMBER)
+    {
+      if (pFlowSpec1->u.CtrlLoad.PeakDataRate >
+	  pFlowSpec2->u.CtrlLoad.PeakDataRate)
+	{
+	  return TRUE;
+	}
+    }
+  else if (pFlowSpec1->ServHdr.ServHdr == FLOW_SPEC_GUAR_SERV_NUMBER)
+    {
+      if (pFlowSpec1->u.Guar.CtrlLoad.PeakDataRate >
+	  pFlowSpec2->u.Guar.CtrlLoad.PeakDataRate)
+	{
+	  return TRUE;
+	}
+    }
+  return FALSE;
+}
+
+void
+ComposeFlowSpec (PSB * pPsb, FLOW_SPEC_OBJ * pFilterFlowSpec)
+{
+  pFilterFlowSpec->MsgHdr.VersionResvd = FLOW_SPEC_MSG_FORMAT;
+  pFilterFlowSpec->MsgHdr.MessageLength = FLOW_SPEC_MSG_LENGTH;
+  pFilterFlowSpec->ServHdr.ServHdr = FLOW_SPEC_CTRL_LOAD_SERV_NUMBER;	/* temp */
+  pFilterFlowSpec->ServHdr.Resvd = 0;
+  pFilterFlowSpec->ServHdr.ServLength = FLOW_SPEC_DATA_LENGTH;
+  pFilterFlowSpec->ParamHdr.ParamID = FLOW_SPEC_TOCKEN_BUCKET_PARAM_ID;
+  pFilterFlowSpec->ParamHdr.ParamFlags = 0;
+  pFilterFlowSpec->ParamHdr.ParamLength =
+    FLOW_SPEC_TOCKEN_BUCKET_PARAM_LENGTH;
+  pFilterFlowSpec->u.CtrlLoad.TockenBucketRate =
+    pPsb->OldPacket.SenderTSpec.TockenBucketRate;
+  pFilterFlowSpec->u.CtrlLoad.TockenBucketSize =
+    pPsb->OldPacket.SenderTSpec.TockenBucketSize;
+  pFilterFlowSpec->u.CtrlLoad.PeakDataRate =
+    pPsb->OldPacket.SenderTSpec.PeakDataRate;
+  pFilterFlowSpec->u.CtrlLoad.MinPolicedUnit =
+    pPsb->OldPacket.SenderTSpec.MinPolicedUnit;
+  pFilterFlowSpec->u.CtrlLoad.MaxPacketSize =
+    pPsb->OldPacket.SenderTSpec.MaxPacketSize;
+}
+
+void
+CheckAndSetFlowSpecObj (PSB * pPsb, FLOW_SPEC_OBJ * pFilterFlowSpec,
+			FLOW_SPEC_OBJ * pEffectiveFlowSpec)
+{
+  uns8 TSpecSelected = FALSE;
+
+  if (pFilterFlowSpec->ServHdr.ServHdr == FLOW_SPEC_CTRL_LOAD_SERV_NUMBER)
+    {
+      if (TSpecGreaterThanFlowSpecCtrl
+	  (&pPsb->OldPacket.SenderTSpec, pFilterFlowSpec) == FALSE)
+	{
+	  TSpecSelected = TRUE;
+	}
+    }
+  else if (pFilterFlowSpec->ServHdr.ServHdr == FLOW_SPEC_GUAR_SERV_NUMBER)
+    {
+      if (TSpecGreaterThanFlowSpecGuar
+	  (&pPsb->OldPacket.SenderTSpec, pFilterFlowSpec) == FALSE)
+	{
+	  TSpecSelected = TRUE;
+	}
+    }
+  if (pEffectiveFlowSpec->ServHdr.ServHdr == 0)
+    {
+      pEffectiveFlowSpec->MsgHdr.VersionResvd = FLOW_SPEC_MSG_FORMAT;
+      pEffectiveFlowSpec->MsgHdr.MessageLength = FLOW_SPEC_MSG_LENGTH;
+      pEffectiveFlowSpec->ServHdr.ServHdr = pFilterFlowSpec->ServHdr.ServHdr;	/* temp */
+      pEffectiveFlowSpec->ServHdr.Resvd = 0;
+      pEffectiveFlowSpec->ServHdr.ServLength = FLOW_SPEC_DATA_LENGTH;
+      pEffectiveFlowSpec->ParamHdr.ParamID = FLOW_SPEC_TOCKEN_BUCKET_PARAM_ID;
+      pEffectiveFlowSpec->ParamHdr.ParamFlags = 0;
+      pEffectiveFlowSpec->ParamHdr.ParamLength =
+	FLOW_SPEC_TOCKEN_BUCKET_PARAM_LENGTH;
+    }
+  if (TSpecSelected)
+    {
+      if (pEffectiveFlowSpec->ServHdr.ServHdr ==
+	  FLOW_SPEC_CTRL_LOAD_SERV_NUMBER)
+	{
+	  if (TSpecGreaterThanFlowSpecCtrl
+	      (&pPsb->OldPacket.SenderTSpec, pEffectiveFlowSpec) == TRUE)
+	    {
+	      pEffectiveFlowSpec->u.CtrlLoad.MaxPacketSize =
+		pPsb->OldPacket.SenderTSpec.MaxPacketSize;
+	      pEffectiveFlowSpec->u.CtrlLoad.MinPolicedUnit =
+		pPsb->OldPacket.SenderTSpec.MinPolicedUnit;
+	      pEffectiveFlowSpec->u.CtrlLoad.PeakDataRate =
+		pPsb->OldPacket.SenderTSpec.PeakDataRate;
+	      pEffectiveFlowSpec->u.CtrlLoad.TockenBucketRate =
+		pPsb->OldPacket.SenderTSpec.TockenBucketRate;
+	      pEffectiveFlowSpec->u.CtrlLoad.TockenBucketSize =
+		pPsb->OldPacket.SenderTSpec.TockenBucketSize;
+	    }
+	}
+      else if (pEffectiveFlowSpec->ServHdr.ServHdr ==
+	       FLOW_SPEC_GUAR_SERV_NUMBER)
+	{
+	  if (TSpecGreaterThanFlowSpecGuar
+	      (&pPsb->OldPacket.SenderTSpec, pEffectiveFlowSpec) == TRUE)
+	    {
+	      pEffectiveFlowSpec->u.Guar.CtrlLoad.MaxPacketSize =
+		pPsb->OldPacket.SenderTSpec.MaxPacketSize;
+	      pEffectiveFlowSpec->u.Guar.CtrlLoad.MinPolicedUnit =
+		pPsb->OldPacket.SenderTSpec.MinPolicedUnit;
+	      pEffectiveFlowSpec->u.Guar.CtrlLoad.PeakDataRate =
+		pPsb->OldPacket.SenderTSpec.PeakDataRate;
+	      pEffectiveFlowSpec->u.Guar.CtrlLoad.TockenBucketRate =
+		pPsb->OldPacket.SenderTSpec.TockenBucketRate;
+	      pEffectiveFlowSpec->u.Guar.CtrlLoad.TockenBucketSize =
+		pPsb->OldPacket.SenderTSpec.TockenBucketSize;
+	    }
+	}
+    }
+  else
+    {
+      if (FlowSpec1GreaterThanFlowSpec2 (pEffectiveFlowSpec, pFilterFlowSpec)
+	  == FALSE)
+	{
+	  *pEffectiveFlowSpec = *pFilterFlowSpec;
+	}
+    }
+}
+
+static int
+BlocadeTimerExpiry (struct thread *thread)
+{
+  FILTER_SPEC_DATA *pFilterSpecData = THREAD_ARG (thread);
+  memset (&pFilterSpecData->BlocadeTimer, 0, sizeof (struct thread *));
+  pFilterSpecData->Blocked = FALSE;
+  if ((pFilterSpecData->pPsb->pRsb->OldPacket.Style.OptionVector2 & 0x001F) ==
+      SE_STYLE_BITS)
+    {
+      if (ProcessEffectiveFlows (pFilterSpecData->pPsb->pRsb) != E_OK)
+	{
+	  zlog_err ("An error on ProcessEffectiveFlows");
+	}
+    }
+  else
+    {
+      if (pFilterSpecData->pPsb->TE_InProcess == TRUE)
+	{
+	  if (StartBlocadeTimer
+	      (1, &pFilterSpecData->BlocadeTimer, pFilterSpecData) != E_OK)
+	    {
+	      zlog_info ("Cannot run Blocade Timer %s %d", __FILE__,
+			 __LINE__);
+	    }
+	  return;
+	}
+      zlog_info ("Locking Flow %x %x %x %x %x %s %d",
+		 pFilterSpecData->pPsb->pRsb->RsbKey.Session.Dest,
+		 pFilterSpecData->pPsb->pRsb->RsbKey.Session.TunnelId,
+		 pFilterSpecData->pPsb->pRsb->RsbKey.Session.ExtTunelId,
+		 pFilterSpecData->FilterSpec.IpAddr,
+		 pFilterSpecData->FilterSpec.LspId, __FILE__, __LINE__);
+      pFilterSpecData->pPsb->TE_InProcess = TRUE;
+      PrepareAndSendMsg2TE4FF (pFilterSpecData->pPsb->pRsb, pFilterSpecData);
+    }
+}
+
+static int
+FilterAgeOut (struct thread *thread)
+{
+  FILTER_SPEC_DATA *pFilterSpecData = THREAD_ARG (thread);
+  RSB *pRsb;
+  PSB *pPsb;
+  uns8 Shared = 0;
+
+  zlog_info ("entering FilterAgeOut");
+  if (pFilterSpecData == NULL)
+    {
+      zlog_err ("pFilterSpecData == NULL %s %d", __FILE__, __LINE__);
+      return;
+    }
+  memset (&pFilterSpecData->AgeOutTimer, 0, sizeof (struct thread *));
+  if (pFilterSpecData->pPsb == NULL)
+    {
+      zlog_err ("pFilterSpecData->pPsb == NULL %s %d", __FILE__, __LINE__);
+      return;
+    }
+  if ((pRsb = pFilterSpecData->pPsb->pRsb) == NULL)
+    {
+      zlog_err ("pFilterSpecData->pPsb->pRsb == NULL %s %d", __FILE__,
+		__LINE__);
+      return;
+    }
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x Src %x LspId %x",
+	     pFilterSpecData->pPsb->pRsb->RsbKey.Session.Dest,
+	     pFilterSpecData->pPsb->pRsb->RsbKey.Session.TunnelId,
+	     pFilterSpecData->pPsb->pRsb->RsbKey.Session.ExtTunelId,
+	     pFilterSpecData->FilterSpec.IpAddr,
+	     pFilterSpecData->FilterSpec.LspId);
+  if ((pRsb->OldPacket.Style.OptionVector2 & 0x001F) == SE_STYLE_BITS)
+    {
+      Shared = 1;
+    }
+  if (DeleteFilterListNode (&pRsb->OldPacket.pFilterList, pFilterSpecData) !=
+      E_OK)
+    {
+      zlog_err ("Cannot delete filter from RSB's filter list %s %d", __FILE__,
+		__LINE__);
+      return;
+    }
+  pPsb = pFilterSpecData->pPsb;
+  if (FilterShutDown (pFilterSpecData, Shared) != E_OK)
+    {
+      zlog_err ("An error in FilterShutDown %s %d", __FILE__, __LINE__);
+      return;
+    }
+  if (pRsb->OldPacket.pFilterList != NULL)
+    {
+      if (Shared)
+	{
+	  if (ProcessEffectiveFlows (pRsb) != E_OK)
+	    {
+	      zlog_err ("An error in ProcessEffectiveFlows %s %d", __FILE__,
+			__LINE__);
+	    }
+	}
+      /* update TE (BW release) */
+      if (ProcessPHopFilterSpecLists (pRsb, Shared) != E_OK)
+	{
+	  zlog_err ("An error in ProcessPHopFilterSpecLists %s %d", __FILE__,
+		    __LINE__);
+	}
+    }
+  else
+    {
+      FreeRSB (pRsb);
+    }
+  RsvpStatistics.FilterAgeOutCount++;
+  zlog_info ("leaving FilterAgeOut");
+}
+
+static int
+PHopResvRefreshTimeOut (struct thread *thread)
+{
+  PHOP_RESV_REFRESH_LIST *pPhopResvRefreshList = THREAD_ARG (thread);
+  FILTER_LIST *pFilterList;
+  FILTER_SPEC_DATA *pFilterSpecData;
+  RSB *pRsb;
+  zlog_info ("entering PHopResvRefreshTimeOut");
+  if (pPhopResvRefreshList == NULL)
+    {
+      zlog_err ("pPhopResvRefreshList == NULL %s %d", __FILE__, __LINE__);
+      zlog_info ("leaving PHopResvRefreshTimeOut-");
+      return;
+    }
+  pFilterList = pPhopResvRefreshList->pFilterList;
+  memset (&pPhopResvRefreshList->ResvRefreshTimer, 0,
+	  sizeof (struct thread *));
+  if (pFilterList == NULL)
+    {
+      zlog_err ("pFilterList == NULL!!! %s %d", __FILE__, __LINE__);
+      return;
+    }
+  if ((pFilterSpecData = pFilterList->pFilterSpecData) == NULL)
+    {
+      zlog_err ("pFilterSpecData == NULL!!! %s %d", __FILE__, __LINE__);
+      return;
+    }
+  if (pFilterSpecData->pPsb == NULL)
+    {
+      zlog_err ("pFilterSpecData->pPsb == NULL!!! %s %d", __FILE__, __LINE__);
+      return;
+    }
+  if ((pRsb = pFilterSpecData->pPsb->pRsb) == NULL)
+    {
+      zlog_err ("pFilterSpecData->pPsb->pRsb == NULL!!! %s %d", __FILE__,
+		__LINE__);
+      return;
+    }
+  if (ResvRefreshProc (pRsb, pPhopResvRefreshList) != E_OK)
+    {
+      zlog_err ("An error on ResvRefreshProc %s %d", __FILE__, __LINE__);
+    }
+  zlog_info ("leaving PHopResvRefreshTimeOut+");
+}
+
+E_RC
+StartPHopResvRefreshTimer (uns32 time, struct thread **pTimerId, void *data)
+{
+  zlog_info ("entering StartPHopResvRefreshTimer");
+  *pTimerId = thread_add_timer (master, PHopResvRefreshTimeOut, data, time);
+  zlog_info ("leaving StartPHopResvRefreshTimer");
+  return E_OK;
+}
+
+E_RC
+StopPHopResvRefreshTimer (struct thread * *pTimerId)
+{
+  zlog_info ("entering StopPHopResvRefreshTimer");
+  thread_cancel (*pTimerId);
+  *pTimerId = NULL;
+  zlog_info ("leaving StopPHopResvRefreshTimer");
+  return E_OK;
+}
+
+E_RC
+StartFilterAgeOutTimer (uns32 time, struct thread * *pTimerId, void *data)
+{
+  zlog_info ("entering StartFilterAgeOutTimer");
+  *pTimerId = thread_add_timer (master, FilterAgeOut, data, time);
+  zlog_info ("leaving StartFilterAgeOutTimer");
+  return E_OK;
+}
+
+E_RC
+StopFilterAgeOutTimer (struct thread * *pTimerId)
+{
+  zlog_info ("entering StopFilterAgeOutTimer");
+  thread_cancel (*pTimerId);
+  *pTimerId = NULL;
+  zlog_info ("leaving StopFilterAgeOutTimer");
+  return E_OK;
+}
+
+E_RC
+StartBlocadeTimer (uns32 time, struct thread * *pTimerId, void *data)
+{
+  zlog_info ("entering StartBlocadeTimer");
+  *pTimerId = thread_add_timer (master, BlocadeTimerExpiry, data, time);
+  zlog_info ("leaving StartBlocadeTimer");
+  return E_OK;
+}
+
+E_RC
+StopBlocadeTimer (struct thread * *pTimerId)
+{
+  zlog_info ("entering StopBlocadeTimer");
+  thread_cancel (*pTimerId);
+  *pTimerId = NULL;
+  zlog_info ("leaving StopBlocadeTimer");
+  return E_OK;
+}
+
+static E_RC
+ResvRefreshProc (RSB * pRsb, PHOP_RESV_REFRESH_LIST * pPHopResvRefreshList)
+{
+  RSVP_PKT RsvpPkt;
+  zlog_info ("entering ResvRefreshProc");
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x",
+	     pRsb->RsbKey.Session.Dest,
+	     pRsb->RsbKey.Session.TunnelId, pRsb->RsbKey.Session.ExtTunelId);
+  if (pPHopResvRefreshList == NULL)
+    {
+      zlog_err ("ResvRefreshProc: pPHopResvRefreshList is NULL");
+      return E_ERR;
+    }
+  if ((pPHopResvRefreshList->pSentBuffer == NULL) ||
+      (pPHopResvRefreshList->SentBufferLen == 0))
+    {
+      memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+      RsvpPkt.Session = pRsb->RsbKey.Session;
+      RsvpPkt.TimeValues.TimeValues = ResvRefreshInterval * 1000;
+      RsvpPkt.SentRsvpHop.LIH = pPHopResvRefreshList->PHop.LIH;
+      RsvpPkt.Style = pRsb->OldPacket.Style;
+      RsvpPkt.pFilterList = pPHopResvRefreshList->pFilterList;
+
+      if (IpAddrGetByIfIndex
+	  (pPHopResvRefreshList->InIfIndex,
+	   &RsvpPkt.SentRsvpHop.PHop) != E_OK)
+	{
+	  zlog_err ("Cannot set RSVP HOP %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+
+      RsvpPkt.AddedRro.rr = pPHopResvRefreshList->pAddedRro;
+
+      if (EncodeAndSendRsvpResvMessage (&RsvpPkt,
+					ntohl (pPHopResvRefreshList->PHop.
+					       PHop),
+					pPHopResvRefreshList->InIfIndex, 255,
+					&pPHopResvRefreshList->pSentBuffer,
+					&pPHopResvRefreshList->
+					SentBufferLen) != E_OK)
+	{
+	  zlog_err ("Cannot encode or send RESV message");
+	  return E_ERR;
+	}
+    }
+  else
+    {
+      if (SendRawData (pPHopResvRefreshList->pSentBuffer,
+		       pPHopResvRefreshList->SentBufferLen,
+		       ntohl (pPHopResvRefreshList->PHop.PHop),
+		       pPHopResvRefreshList->pFilterList->pFilterSpecData->
+		       pPsb->InIfIndex, 2, FALSE) != E_OK)
+	{
+	  zlog_err ("Cannot send raw data %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+    }
+  if (StopPHopResvRefreshTimer (&pPHopResvRefreshList->ResvRefreshTimer) !=
+      E_OK)
+    {
+      zlog_err ("Cannot stop PHopResvRefreshTimer %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if (StartPHopResvRefreshTimer (pPHopResvRefreshList->RefreshValue,
+				 &pPHopResvRefreshList->ResvRefreshTimer,
+				 pPHopResvRefreshList) != E_OK)
+    {
+      zlog_err ("Cannot start timer %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  zlog_info ("leaving ResvRefreshProc");
+  return E_OK;
+}
+
+
+E_RC
+LinkFilter2PHopList (FILTER_SPEC_DATA * pFilterSpecData)
+{
+  PSB *pPsb;
+  RSB *pRsb;
+  uns8 AddRro = FALSE;
+
+  pPsb = pFilterSpecData->pPsb;
+  pRsb = pPsb->pRsb;
+
+  if (((pFilterSpecData->pPHopResvRefreshList != NULL) &&
+       (!((pFilterSpecData->pPHopResvRefreshList->PHop.PHop ==
+	   pPsb->OldPacket.ReceivedRsvpHop.PHop)
+	  && (pFilterSpecData->pPHopResvRefreshList->PHop.LIH ==
+	      pPsb->OldPacket.ReceivedRsvpHop.LIH))))
+      || (pFilterSpecData->pPHopResvRefreshList == NULL))
+    {
+      if (pFilterSpecData->pPHopResvRefreshList != NULL)
+	{
+	  if (DeleteFilterListNode
+	      (&pFilterSpecData->pPHopResvRefreshList->pFilterList,
+	       pFilterSpecData) != E_OK)
+	    {
+	      zlog_err ("Cannot delete filter list node %s %d", __FILE__,
+			__LINE__);
+	      return E_ERR;
+	    }
+	  pFilterSpecData->pPHopResvRefreshList->MustBeProcessed = 1;
+	  if (pFilterSpecData->pPHopResvRefreshList->pSentBuffer != NULL)
+	    {
+	      XFREE (MTYPE_RSVP,
+		     pFilterSpecData->pPHopResvRefreshList->pSentBuffer);
+	      pFilterSpecData->pPHopResvRefreshList->pSentBuffer = NULL;
+	      pFilterSpecData->pPHopResvRefreshList->SentBufferLen = 0;
+	    }
+	}
+      if ((pFilterSpecData->pPHopResvRefreshList =
+	   GetOrCreatePHopResvRefreshNode (pRsb,
+					   pPsb->OldPacket.ReceivedRsvpHop.
+					   PHop,
+					   pPsb->OldPacket.ReceivedRsvpHop.
+					   LIH, pPsb->InIfIndex)) == NULL)
+	{
+	  zlog_err ("Cannot create or get PHOP RESV refresh node");
+	  return E_ERR;
+	}
+      pFilterSpecData->pPHopResvRefreshList->MustBeProcessed = 1;
+      if (pFilterSpecData->pPHopResvRefreshList->pSentBuffer != NULL)
+	{
+	  XFREE (MTYPE_RSVP,
+		 pFilterSpecData->pPHopResvRefreshList->pSentBuffer);
+	  pFilterSpecData->pPHopResvRefreshList->pSentBuffer = NULL;
+	  pFilterSpecData->pPHopResvRefreshList->SentBufferLen = 0;
+	}
+      if (NewFilterListNode
+	  (&pFilterSpecData->pPHopResvRefreshList->pFilterList,
+	   pFilterSpecData) != E_OK)
+	{
+	  zlog_err ("Cannot create new FILTER LIST node");
+	  return E_ERR;
+	}
+      if (pPsb->OutIfIndex == 0)
+	{
+	  if (pPsb->OldPacket.ReceivedRro.rr != NULL)
+	    {
+	      AddRro = TRUE;
+	    }
+	}
+      else
+	{
+	  if (pFilterSpecData->Rro.rr != NULL)
+	    {
+	      AddRro = TRUE;
+	    }
+	}
+      if (AddRro)
+	{
+	  if (BuildRRSubObj (pFilterSpecData) != E_OK)
+	    {
+	      zlog_err ("an error on BuildRRSubObj %s %d", __FILE__,
+			__LINE__);
+	    }
+	}
+    }
+  return E_OK;
+}
+
+E_RC
+NewModifiedPath (PSB * pPsb)
+{
+  uns8 Shared = 0;
+  RSB *pRsb;
+  RSB_KEY RsbKey;
+  FILTER_LIST *pFilterList, *pFilterListPrev = NULL;
+  FILTER_SPEC_DATA *pFilterSpecData;
+
+  memset (&RsbKey, 0, sizeof (RSB_KEY));
+  RsbKey.Session = pPsb->PsbKey.Session;
+
+  /* First - get or create RSB */
+  if ((pRsb = FindRsb (&RsbKey)) == NULL)
+    {
+      if ((pRsb = NewRSB (&RsbKey)) == NULL)
+	{
+	  zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pRsb->OldPacket.Session = RsbKey.Session;
+    }
+  pFilterList = pRsb->OldPacket.pFilterList;
+
+  /* second - get or create filter list node */
+  while (pFilterList != NULL)
+    {
+      if (pFilterList->pFilterSpecData != NULL)
+	{
+	  if ((pFilterList->pFilterSpecData->FilterSpec.IpAddr ==
+	       pPsb->PsbKey.SenderTemplate.IpAddr)
+	      && (pFilterList->pFilterSpecData->FilterSpec.LspId ==
+		  pPsb->PsbKey.SenderTemplate.LspId))
+	    {
+	      break;
+	    }
+	}
+      else
+	{
+	  zlog_warn
+	    ("Warning!!! pFilterList->pFilterSpecData is NULL while node is in the list");
+	}
+      pFilterListPrev = pFilterList;
+      pFilterList = pFilterList->next;
+    }
+
+  /* create new, if required */
+  if (pFilterList == NULL)
+    {
+      if ((pFilterList =
+	   (FILTER_LIST *) XMALLOC (MTYPE_RSVP,
+				    sizeof (FILTER_LIST))) == NULL)
+	{
+	  zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	}
+      memset (pFilterList, 0, sizeof (FILTER_LIST));
+      if ((pFilterList->pFilterSpecData =
+	   (FILTER_SPEC_DATA *) XMALLOC (MTYPE_RSVP,
+					 sizeof (FILTER_SPEC_DATA))) == NULL)
+	{
+	  zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	  XFREE (MTYPE_RSVP, pFilterList);
+	  return E_ERR;
+	}
+      memset (pFilterList->pFilterSpecData, 0, sizeof (FILTER_SPEC_DATA));
+      pFilterList->pFilterSpecData->FilterSpec.IpAddr =
+	pPsb->PsbKey.SenderTemplate.IpAddr;
+      pFilterList->pFilterSpecData->FilterSpec.LspId =
+	pPsb->PsbKey.SenderTemplate.LspId;
+      pFilterList->pFilterSpecData->pPsb = pPsb;
+      pFilterList->pFilterSpecData->pPsb->pRsb = pRsb;
+      pFilterList->pFilterSpecData->SentLabel.Label =
+	pFilterList->pFilterSpecData->pPsb->Label;
+      pFilterList->next = pRsb->OldPacket.pFilterList;
+      pRsb->OldPacket.pFilterList = pFilterList;
+    }
+
+  pFilterSpecData = pFilterList->pFilterSpecData;
+
+  if (LinkFilter2PHopList (pFilterSpecData) != E_OK)
+    {
+      zlog_err ("An error on LinkFilter2PHopList %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if (pPsb->OldPacket.SessionAttributes.CType ==
+      SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+    {
+#if 0				/* temporary */
+      pPsb->OldPacket.SessionAttributes.u.SessAttrRa.Flags |=
+	SE_STYLE_DESIRED;
+#endif
+      if (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.
+	  Flags & SE_STYLE_DESIRED)
+	{
+	  Shared = 1;
+	  pRsb->OldPacket.Style.OptionVector2 = SE_STYLE_BITS;
+	}
+      else
+	{
+	  pRsb->OldPacket.Style.OptionVector2 = FF_STYLE_BITS;
+	}
+    }
+  else if (pPsb->OldPacket.SessionAttributes.CType ==
+	   SESSION_ATTRIBUTES_CLASS_TYPE)
+    {
+#if 0				/* temporary */
+      pPsb->OldPacket.SessionAttributes.u.SessAttr.Flags |= SE_STYLE_DESIRED;
+#endif
+      if (pPsb->OldPacket.SessionAttributes.u.SessAttr.
+	  Flags & SE_STYLE_DESIRED)
+	{
+	  Shared = 1;
+	  pRsb->OldPacket.Style.OptionVector2 = SE_STYLE_BITS;
+	}
+      else
+	{
+	  pRsb->OldPacket.Style.OptionVector2 = FF_STYLE_BITS;
+	}
+    }
+  else
+    {
+      Shared = 1;
+      pRsb->OldPacket.Style.OptionVector2 = SE_STYLE_BITS;
+    }
+
+  ComposeFlowSpec (pFilterSpecData->pPsb, &pFilterSpecData->FlowSpec);
+
+  return ProcessPHopFilterSpecLists (pRsb, Shared);
+}
+
+E_RC
+ProcessEffectiveFlows (RSB * pRsb)
+{
+  EFFECTIVE_FLOW *pEffectiveFlow = pRsb->pEffectiveFlow;
+  uns8 NewFlow;
+  zlog_info ("entering ProcessEffectiveFlows");
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x",
+	     pRsb->RsbKey.Session.Dest,
+	     pRsb->RsbKey.Session.TunnelId, pRsb->RsbKey.Session.ExtTunelId);
+  while (pEffectiveFlow != NULL)
+    {
+      if ((pEffectiveFlow->MustBeProcessed) &&
+	  (pEffectiveFlow->TE_InProcess == FALSE))
+	{
+	  FILTER_LIST *pFilterList = pEffectiveFlow->pFilterList;
+	  FLOW_SPEC_OBJ *pEffectiveFlowSpec;
+	  memset (&pEffectiveFlow->NewFlowSpec, 0, sizeof (FLOW_SPEC_OBJ));
+	  NewFlow = FALSE;
+	  pEffectiveFlowSpec = &pEffectiveFlow->NewFlowSpec;
+	  while (pFilterList != NULL)
+	    {
+	      FLOW_SPEC_OBJ *pFlowSpec;
+	      if (pFilterList->pFilterSpecData != NULL)
+		{
+		  zlog_info ("processing filter spec %x %x",
+			     pFilterList->pFilterSpecData->FilterSpec.IpAddr,
+			     pFilterList->pFilterSpecData->FilterSpec.LspId);
+
+		  if (pFilterList->pFilterSpecData->NewFlowSpecValid)
+		    {
+		      pFlowSpec = &pFilterList->pFilterSpecData->NewFlowSpec;
+		      NewFlow = TRUE;
+		      zlog_info ("New");
+		    }
+		  else
+		    {
+		      pFlowSpec = &pFilterList->pFilterSpecData->FlowSpec;
+		      zlog_info ("Not new");
+		    }
+
+		  if (pEffectiveFlowSpec->ServHdr.ServHdr == 0)
+		    {
+		      pEffectiveFlowSpec->ServHdr.ServHdr =
+			pFlowSpec->ServHdr.ServHdr;
+		    }
+		  if (FlowSpec1GreaterThanFlowSpec2
+		      (pFlowSpec, pEffectiveFlowSpec) == TRUE)
+		    {
+		      zlog_info ("Setting Effective flow's BW to %f",
+				 pFlowSpec->u.CtrlLoad.PeakDataRate);
+		      *pEffectiveFlowSpec = *pFlowSpec;
+		    }
+		}
+	      pFilterList = pFilterList->next;
+	    }
+	  if ((NewFlow == TRUE) || (memcmp (&pEffectiveFlow->CurrentFlowSpec,
+					    &pEffectiveFlow->NewFlowSpec,
+					    sizeof (FLOW_SPEC_OBJ))))
+	    {
+	      /* send notification to TE */
+	      if (FlowSpec1GreaterThanFlowSpec2
+		  (&pEffectiveFlow->CurrentFlowSpec,
+		   &pEffectiveFlow->NewFlowSpec) == TRUE)
+		{
+		  pEffectiveFlow->CurrentFlowSpec =
+		    pEffectiveFlow->NewFlowSpec;
+		}
+	      else
+		if (FlowSpec1GreaterThanFlowSpec2
+		    (&pEffectiveFlow->NewFlowSpec,
+		     &pEffectiveFlow->CurrentFlowSpec) == TRUE)
+		{
+		  pEffectiveFlow->TE_InProcess = TRUE;
+		}
+	      else if (NewFlow == TRUE)
+		{
+		  pEffectiveFlow->TE_InProcess = TRUE;
+		}
+	      PrepareAndSendMsg2TE4SE (pRsb, pEffectiveFlow);
+	    }
+	  else
+	    {
+	      zlog_info ("no change...");
+	    }
+	  pEffectiveFlow->MustBeProcessed = 0;
+	}
+      pEffectiveFlow = pEffectiveFlow->next;
+    }
+  zlog_info ("leaving ProcessEffectiveFlows");
+  return E_OK;
+}
+
+E_RC
+ProcessReceivedFilterSpecs (RSB * pRsb, RSVP_PKT * pRsvpPkt)
+{
+  PSB_KEY PsbKey;
+  FILTER_LIST *pFilterList, *pFilterListPrev = NULL, *pFilterListNext;
+  uns8 ItemExtracted;
+  int Shared = 0;
+  zlog_info ("entering ProcessReceivedFilterSpecs");
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x",
+	     pRsb->RsbKey.Session.Dest,
+	     pRsb->RsbKey.Session.TunnelId, pRsb->RsbKey.Session.ExtTunelId);
+  if ((pRsvpPkt->Style.OptionVector2 & 0x001F) == SE_STYLE_BITS)
+    {
+      Shared = 1;
+    }
+  else if (!((pRsvpPkt->Style.OptionVector2 & 0x001F) == FF_STYLE_BITS))
+    {
+      RSVP_PKT RsvpPkt;
+      zlog_err ("Unknown style %d", pRsvpPkt->Style.OptionVector2);
+      memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+      RsvpPkt.Session = pRsb->RsbKey.Session;
+      RsvpPkt.Style = pRsb->OldPacket.Style;
+      RsvpPkt.pFilterList = pRsvpPkt->pFilterList;
+      RsvpPkt.ErrorSpec.IpAddr = GetRouterId ();
+      RsvpPkt.ErrorSpec.ErrCode = UNKNOWN_RESV_STYLE_ERR_CODE;
+      RsvpPkt.SentRsvpHop.LIH = pRsvpPkt->SentRsvpHop.LIH;
+      if (IpAddrGetByIfIndex
+	  (RsvpPkt.SentRsvpHop.LIH, &RsvpPkt.SentRsvpHop.PHop) != E_OK)
+	{
+	  zlog_err ("Cannot get IP address by IfIndex");
+	  return E_ERR;
+	}
+      if (EncodeAndSendRsvpResvErrMessage
+	  (&RsvpPkt, pRsvpPkt->ReceivedRsvpHop.PHop, RsvpPkt.SentRsvpHop.LIH,
+	   255) != E_OK)
+	{
+	  zlog_err ("An error on encode/send %s %d", __FILE__, __LINE__);
+	}
+      return E_ERR;
+    }
+
+  pFilterList = pRsvpPkt->pFilterList;
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+  PsbKey.Session = pRsvpPkt->Session;
+  while (pFilterList != NULL)
+    {
+      FILTER_SPEC_DATA *pFilterSpecData = pFilterList->pFilterSpecData;
+
+      pFilterListNext = pFilterList->next;
+      ItemExtracted = FALSE;
+
+      if (pFilterSpecData != NULL)
+	{
+	  FILTER_LIST *pRsbFilterList = pRsb->OldPacket.pFilterList;
+	  uns8 Found = 0;
+
+	  /* First - update the reservations for the existing  filters */
+	  while (pRsbFilterList != NULL)
+	    {
+	      if (pRsbFilterList->pFilterSpecData != NULL)
+		{
+		  /* is that the same filter ? */
+		  if ((pRsbFilterList->pFilterSpecData->FilterSpec.IpAddr ==
+		       pFilterList->pFilterSpecData->FilterSpec.IpAddr)
+		      && (pRsbFilterList->pFilterSpecData->FilterSpec.LspId ==
+			  pFilterList->pFilterSpecData->FilterSpec.LspId))
+		    {
+		      zlog_info ("existing filter spec found");
+		      Found = 1;
+
+		      if ((pRsbFilterList->pFilterSpecData->pPsb)
+			  && (pRsbFilterList->pFilterSpecData->pPsb->
+			      TE_InProcess == TRUE))
+			{
+			  RSVP_PKT_QUEUE *pQueuedItem;
+			  RSVP_PKT *pSavedRsvpPkt;
+			  if (pFilterListPrev == NULL)
+			    {
+			      pRsvpPkt->pFilterList = pFilterListNext;
+			    }
+			  else
+			    {
+			      pFilterListPrev->next = pFilterListNext;
+			    }
+			  ItemExtracted = TRUE;
+			  if ((pSavedRsvpPkt =
+			       (RSVP_PKT *) XMALLOC (MTYPE_RSVP,
+						     sizeof (RSVP_PKT))) ==
+			      NULL)
+			    {
+			      zlog_err ("memory allocation failed %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+			  memcpy (pSavedRsvpPkt, pRsvpPkt, sizeof (RSVP_PKT));
+			  pSavedRsvpPkt->pFilterList = pFilterList;
+			  pSavedRsvpPkt->pFilterList->next = NULL;
+			  pSavedRsvpPkt->pIntegrityObj = NULL;	/* temp. */
+			  pSavedRsvpPkt->pPolicyDataObj = NULL;	/* temp. */
+			  pSavedRsvpPkt->pOpaqueObjList = NULL;	/* temp. */
+			  pSavedRsvpPkt->ReceivedRro.rr = NULL;	/* TEMP!!! */
+			  if ((pQueuedItem =
+			       (RSVP_PKT_QUEUE *) XMALLOC (MTYPE_RSVP,
+							   sizeof
+							   (RSVP_PKT_QUEUE)))
+			      == NULL)
+			    {
+			      zlog_err ("memory allocation failed %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+
+			  pQueuedItem->MsgType = RESV_MSG;
+			  pQueuedItem->pRsvpPkt = pSavedRsvpPkt;
+			  pQueuedItem->next = NULL;
+			  if (EnqueueRsvpPacket
+			      (pQueuedItem,
+			       &pRsbFilterList->pFilterSpecData->pPsb->
+			       packet_queue) != E_OK)
+			    {
+			      zlog_err ("Cannot enqueue packet %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+			  break;
+			}
+
+		      if (StopFilterAgeOutTimer
+			  (&pRsbFilterList->pFilterSpecData->AgeOutTimer) !=
+			  E_OK)
+			{
+			  zlog_err ("Cannot stop timer %s %d", __FILE__,
+				    __LINE__);
+			}
+
+		      if ((pRsbFilterList->pFilterSpecData->Blocked == TRUE)
+			  &&
+			  (FlowSpec1GreaterThanFlowSpec2
+			   (&pRsbFilterList->pFilterSpecData->
+			    BlockadeFlowSpec,
+			    &pFilterSpecData->NewFlowSpec) == FALSE))
+			{
+			  if (StartFilterAgeOutTimer
+			      (pRsbFilterList->pFilterSpecData->AgeOutValue,
+			       &pRsbFilterList->pFilterSpecData->AgeOutTimer,
+			       pRsbFilterList->pFilterSpecData) != E_OK)
+			    {
+			      zlog_err ("Cannot add timer %s %d", __FILE__,
+					__LINE__);
+			    }
+			  break;
+			}
+		      else if (pRsbFilterList->pFilterSpecData->Blocked ==
+			       TRUE)
+			{
+			  if (StopBlocadeTimer
+			      (&pRsbFilterList->pFilterSpecData->
+			       BlocadeTimer) != E_OK)
+			    {
+			      zlog_err ("Cannot delete timer %s %d", __FILE__,
+					__LINE__);
+			    }
+			  pRsbFilterList->pFilterSpecData->Blocked = FALSE;
+			}
+		      if (pRsbFilterList->pFilterSpecData->pPsb->OutIfIndex !=
+			  pRsvpPkt->ReceivedRsvpHop.LIH)
+			{
+			  zlog_err ("LIH does not match OutIf from PSB");
+			  break;
+			}
+
+		      if ((Shared) &&
+			  ((pFilterSpecData->pEffectiveFlow =
+			    GetOrCreateEffectiveFlow (pRsb,
+						      pRsbFilterList->
+						      pFilterSpecData->pPsb->
+						      OutIfIndex)) == NULL))
+			{
+			  zlog_err ("Cannot get/create effective flowspec");
+			  return E_ERR;
+			}
+		      if ((Shared) &&
+			  (pFilterSpecData->pEffectiveFlow !=
+			   pRsbFilterList->pFilterSpecData->pEffectiveFlow))
+			{
+			  zlog_info
+			    ("Deletion of filter_spec from effective_flow list .Src %x .LspId %x",
+			     pFilterSpecData->FilterSpec.IpAddr,
+			     pFilterSpecData->FilterSpec.LspId);
+
+			  if (DeleteFilterListNode
+			      (&pRsbFilterList->pFilterSpecData->
+			       pEffectiveFlow->pFilterList,
+			       pRsbFilterList->pFilterSpecData) != E_OK)
+			    {
+			      zlog_err
+				("Cannot delete filter spec from effective flow list");
+			    }
+			  if (pRsbFilterList->pFilterSpecData->
+			      pEffectiveFlow->pFilterList == NULL)
+			    {
+			      if (DeleteEffectiveFlow
+				  (pRsbFilterList->pFilterSpecData->pPsb->
+				   pRsb,
+				   pRsbFilterList->pFilterSpecData->
+				   pEffectiveFlow) != E_OK)
+				{
+				  zlog_err
+				    ("Cannot delete effective flow list item");
+				}
+			    }
+			  else
+			    {
+			      pRsbFilterList->pFilterSpecData->
+				pEffectiveFlow->MustBeProcessed = 1;
+			    }
+			  if (pFilterSpecData->pEffectiveFlow->TE_InProcess ==
+			      TRUE)
+			    {
+			      RSVP_PKT_QUEUE *pQueuedItem;
+			      RSVP_PKT *pSavedRsvpPkt;
+			      if (pFilterListPrev == NULL)
+				{
+				  pRsvpPkt->pFilterList = pFilterListNext;
+				}
+			      else
+				{
+				  pFilterListPrev->next = pFilterListNext;
+				}
+			      ItemExtracted = TRUE;
+			      if ((pSavedRsvpPkt =
+				   (RSVP_PKT *) XMALLOC (MTYPE_RSVP,
+							 sizeof (RSVP_PKT)))
+				  == NULL)
+				{
+				  zlog_err ("memory allocation failed %s %d",
+					    __FILE__, __LINE__);
+				  return E_ERR;
+				}
+			      memcpy (pSavedRsvpPkt, pRsvpPkt,
+				      sizeof (RSVP_PKT));
+			      pSavedRsvpPkt->pFilterList = pFilterList;
+			      pSavedRsvpPkt->pFilterList->next = NULL;
+			      pSavedRsvpPkt->pIntegrityObj = NULL;	/* temp. */
+			      pSavedRsvpPkt->pPolicyDataObj = NULL;	/* temp. */
+			      pSavedRsvpPkt->pOpaqueObjList = NULL;	/* temp. */
+			      pSavedRsvpPkt->ReceivedRro.rr = NULL;	/* TEMP!!! */
+			      if ((pQueuedItem =
+				   (RSVP_PKT_QUEUE *) XMALLOC (MTYPE_RSVP,
+							       sizeof
+							       (RSVP_PKT_QUEUE)))
+				  == NULL)
+				{
+				  zlog_err ("memory allocation failed %s %d",
+					    __FILE__, __LINE__);
+				  return E_ERR;
+				}
+
+			      pQueuedItem->MsgType = RESV_MSG;
+			      pQueuedItem->pRsvpPkt = pSavedRsvpPkt;
+			      pQueuedItem->next = NULL;
+			      if (EnqueueRsvpPacket
+				  (pQueuedItem,
+				   &pRsbFilterList->pFilterSpecData->pPsb->
+				   packet_queue) != E_OK)
+				{
+				  zlog_err ("Cannot enqueue packet %s %d",
+					    __FILE__, __LINE__);
+				  return E_ERR;
+				}
+			      break;
+			    }
+			  pRsbFilterList->pFilterSpecData->pEffectiveFlow =
+			    pFilterSpecData->pEffectiveFlow;
+			  pRsbFilterList->pFilterSpecData->pEffectiveFlow->
+			    MustBeProcessed = 1;
+			  pRsbFilterList->pFilterSpecData->NewFlowSpecValid =
+			    1;
+			  pRsbFilterList->pFilterSpecData->NewFlowSpec =
+			    pFilterList->pFilterSpecData->NewFlowSpec;
+			  zlog_info
+			    ("Adding filter_spec to effective_flow list .Src %x .LspId %x",
+			     pFilterSpecData->FilterSpec.IpAddr,
+			     pFilterSpecData->FilterSpec.LspId);
+
+			  if (NewFilterListNode
+			      (&pRsbFilterList->pFilterSpecData->
+			       pEffectiveFlow->pFilterList,
+			       pRsbFilterList->pFilterSpecData) != E_OK)
+			    {
+			      zlog_err ("Cannot create new FILTER LIST node");
+			      return E_ERR;
+			    }
+			}
+		      else if ((Shared)
+			       && (pFilterSpecData->pEffectiveFlow->
+				   TE_InProcess == TRUE))
+			{
+			  RSVP_PKT_QUEUE *pQueuedItem;
+			  RSVP_PKT *pSavedRsvpPkt;
+			  if (pFilterListPrev == NULL)
+			    {
+			      pRsvpPkt->pFilterList = pFilterListNext;
+			    }
+			  else
+			    {
+			      pFilterListPrev->next = pFilterListNext;
+			    }
+			  ItemExtracted = TRUE;
+			  if ((pSavedRsvpPkt =
+			       (RSVP_PKT *) XMALLOC (MTYPE_RSVP,
+						     sizeof (RSVP_PKT))) ==
+			      NULL)
+			    {
+			      zlog_err ("memory allocation failed %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+			  memcpy (pSavedRsvpPkt, pRsvpPkt, sizeof (RSVP_PKT));
+			  pSavedRsvpPkt->pFilterList = pFilterList;
+			  pSavedRsvpPkt->pFilterList->next = NULL;
+			  pSavedRsvpPkt->pIntegrityObj = NULL;	/* temp. */
+			  pSavedRsvpPkt->pPolicyDataObj = NULL;	/* temp. */
+			  pSavedRsvpPkt->pOpaqueObjList = NULL;	/* temp. */
+			  pSavedRsvpPkt->ReceivedRro.rr = NULL;	/* TEMP!!! */
+			  if ((pQueuedItem =
+			       (RSVP_PKT_QUEUE *) XMALLOC (MTYPE_RSVP,
+							   sizeof
+							   (RSVP_PKT_QUEUE)))
+			      == NULL)
+			    {
+			      zlog_err ("memory allocation failed %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+
+			  pQueuedItem->MsgType = RESV_MSG;
+			  pQueuedItem->pRsvpPkt = pSavedRsvpPkt;
+			  pQueuedItem->next = NULL;
+			  if (EnqueueRsvpPacket
+			      (pQueuedItem,
+			       &pRsbFilterList->pFilterSpecData->pPsb->
+			       packet_queue) != E_OK)
+			    {
+			      zlog_err ("Cannot enqueue packet %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+			  break;
+			}
+		      else
+			if (memcmp
+			    (&pRsbFilterList->pFilterSpecData->FlowSpec,
+			     &pFilterList->pFilterSpecData->NewFlowSpec,
+			     sizeof (FLOW_SPEC_OBJ)))
+			{
+			  /* if BW should be decreased/increased for the filter */
+			  pRsbFilterList->pFilterSpecData->NewFlowSpec =
+			    pFilterList->pFilterSpecData->NewFlowSpec;
+			  pRsbFilterList->pFilterSpecData->NewFlowSpecValid =
+			    1;
+			  if (Shared)
+			    {
+			      pRsbFilterList->pFilterSpecData->
+				pEffectiveFlow->MustBeProcessed = 1;
+			    }
+			  else
+			    {
+			      /* send notification to TE */
+			      if (FlowSpec1GreaterThanFlowSpec2
+				  (&pRsbFilterList->pFilterSpecData->
+				   NewFlowSpec,
+				   &pFilterList->pFilterSpecData->
+				   NewFlowSpec) == TRUE)
+				{
+				  zlog_info
+				    ("Locking Flow %x %x %x %x %x %s %d",
+				     pRsbFilterList->pFilterSpecData->pPsb->
+				     pRsb->RsbKey.Session.Dest,
+				     pRsbFilterList->pFilterSpecData->pPsb->
+				     pRsb->RsbKey.Session.TunnelId,
+				     pRsbFilterList->pFilterSpecData->pPsb->
+				     pRsb->RsbKey.Session.ExtTunelId,
+				     pRsbFilterList->pFilterSpecData->
+				     FilterSpec.IpAddr,
+				     pRsbFilterList->pFilterSpecData->
+				     FilterSpec.LspId, __FILE__, __LINE__);
+				  pRsbFilterList->pFilterSpecData->pPsb->
+				    TE_InProcess = TRUE;
+				}
+			      PrepareAndSendMsg2TE4FF (pRsb,
+						       pRsbFilterList->
+						       pFilterSpecData);
+			    }
+			}
+		      else
+			{
+			  if (StartFilterAgeOutTimer
+			      (pRsbFilterList->pFilterSpecData->AgeOutValue,
+			       &pRsbFilterList->pFilterSpecData->AgeOutTimer,
+			       pRsbFilterList->pFilterSpecData) != E_OK)
+			    {
+			      zlog_err ("Cannot add timer %s %d", __FILE__,
+					__LINE__);
+			    }
+			}
+		      Found = 1;
+		      break;
+		    }
+		}
+	      pRsbFilterList = pRsbFilterList->next;
+	    }
+
+	  if (Found == 0)
+	    {
+	      zlog_info ("the filter spec is new %x %x",
+			 pFilterSpecData, pFilterSpecData->pPsb);
+	      PsbKey.SenderTemplate.IpAddr =
+		pFilterSpecData->FilterSpec.IpAddr;
+	      PsbKey.SenderTemplate.LspId = pFilterSpecData->FilterSpec.LspId;
+	      zlog_info ("%x %x %x %x %x %s %d",
+			 PsbKey.Session.Dest,
+			 PsbKey.Session.TunnelId,
+			 PsbKey.Session.ExtTunelId,
+			 PsbKey.SenderTemplate.IpAddr,
+			 PsbKey.SenderTemplate.LspId, __FILE__, __LINE__);
+	      if ((pFilterSpecData->pPsb = FindPsb (&PsbKey)) == NULL)
+		{
+		  zlog_err ("cannot find PSB %s %d", __FILE__, __LINE__);
+		  zlog_err ("Generating ResvErr to %x on %x",
+			    pRsvpPkt->ReceivedRsvpHop.PHop,
+			    pRsvpPkt->ReceivedRsvpHop.LIH);
+		  if (GenerateResvErr4SingleFilterSpec
+		      (pFilterSpecData, pRsb, pRsvpPkt->ReceivedRsvpHop.PHop,
+		       pRsvpPkt->ReceivedRsvpHop.LIH,
+		       NO_PATH_INFO_4_RESV_ERR_CODE, 0) != E_OK)
+		    {
+		      zlog_err ("Cannot generate/send ResvErr message %s %d",
+				__FILE__, __LINE__);
+		    }
+		  goto outer_loop_cont;
+		}
+
+	      if (pFilterSpecData->pPsb->TE_InProcess == TRUE)
+		{
+		  RSVP_PKT_QUEUE *pQueuedItem;
+		  RSVP_PKT *pSavedRsvpPkt;
+		  if (pFilterListPrev == NULL)
+		    {
+		      pRsvpPkt->pFilterList = pFilterListNext;
+		    }
+		  else
+		    {
+		      pFilterListPrev->next = pFilterListNext;
+		    }
+		  ItemExtracted = TRUE;
+		  if ((pSavedRsvpPkt =
+		       (RSVP_PKT *) XMALLOC (MTYPE_RSVP,
+					     sizeof (RSVP_PKT))) == NULL)
+		    {
+		      zlog_err ("memory allocation failed %s %d", __FILE__,
+				__LINE__);
+		      return E_ERR;
+		    }
+		  memcpy (pSavedRsvpPkt, pRsvpPkt, sizeof (RSVP_PKT));
+		  pSavedRsvpPkt->pFilterList = pFilterList;
+		  pSavedRsvpPkt->pFilterList->next = NULL;
+		  pSavedRsvpPkt->pIntegrityObj = NULL;	/* temp. */
+		  pSavedRsvpPkt->pPolicyDataObj = NULL;	/* temp. */
+		  pSavedRsvpPkt->pOpaqueObjList = NULL;	/* temp. */
+		  pSavedRsvpPkt->ReceivedRro.rr = NULL;	/* TEMP!!! */
+		  if ((pQueuedItem =
+		       (RSVP_PKT_QUEUE *) XMALLOC (MTYPE_RSVP,
+						   sizeof (RSVP_PKT_QUEUE)))
+		      == NULL)
+		    {
+		      zlog_err ("memory allocation failed %s %d", __FILE__,
+				__LINE__);
+		      return E_ERR;
+		    }
+
+		  pQueuedItem->MsgType = RESV_MSG;
+		  pQueuedItem->pRsvpPkt = pSavedRsvpPkt;
+		  pQueuedItem->next = NULL;
+		  if (EnqueueRsvpPacket
+		      (pQueuedItem,
+		       &pFilterSpecData->pPsb->packet_queue) != E_OK)
+		    {
+		      zlog_err ("Cannot enqueue packet %s %d", __FILE__,
+				__LINE__);
+		      return E_ERR;
+		    }
+		  break;
+		}
+
+	      pFilterSpecData->pPsb->pRsb = pRsb;
+	      pFilterSpecData->pPsb->pFilterSpecData = pFilterSpecData;
+	      {
+		uns32 val;
+		zlog_info ("TimeValue %x", pRsvpPkt->TimeValues.TimeValues);
+		val = (uns32) pRsvpPkt->TimeValues.TimeValues / 10000;
+		zlog_info ("val %x", val);
+		/* 3*R: */
+		val *= 3;
+		zlog_info ("val %x", val);
+		/* (2M+1) * (3*R): */
+		val = (2 * ResvRefreshMultiple + 1) * val;
+		zlog_info ("val %x", val);
+		/* and divide by 4 to get (M + 0.5) * (1.5 * R) */
+		pFilterSpecData->AgeOutValue = val >> 2;
+		//pFilterSpecData->AgeOutValue = 1;
+		zlog_info ("AgeOut value %d", pFilterSpecData->AgeOutValue);
+	      }
+	      pFilterSpecData->SentLabel.Label = pFilterSpecData->pPsb->Label;
+
+	      if (Shared)
+		{
+		  zlog_info ("and shared...");
+		  if ((pFilterSpecData->pEffectiveFlow =
+		       GetOrCreateEffectiveFlow (pRsb,
+						 pFilterSpecData->pPsb->
+						 OutIfIndex)) == NULL)
+		    {
+		      zlog_err ("Cannot get/create effective flowspec");
+		      return E_ERR;
+		    }
+		  if (pFilterSpecData->pEffectiveFlow->TE_InProcess == TRUE)
+		    {
+		      RSVP_PKT_QUEUE *pQueuedItem;
+		      RSVP_PKT *pSavedRsvpPkt;
+
+		      pFilterSpecData->pPsb->pRsb = NULL;
+		      pFilterSpecData->pPsb->pFilterSpecData = NULL;
+
+		      if (pFilterListPrev == NULL)
+			{
+			  pRsvpPkt->pFilterList = pFilterListNext;
+			}
+		      else
+			{
+			  pFilterListPrev->next = pFilterListNext;
+			}
+		      ItemExtracted = TRUE;
+		      if ((pSavedRsvpPkt =
+			   (RSVP_PKT *) XMALLOC (MTYPE_RSVP,
+						 sizeof (RSVP_PKT))) == NULL)
+			{
+			  zlog_err ("memory allocation failed %s %d",
+				    __FILE__, __LINE__);
+			  return E_ERR;
+			}
+		      memcpy (pSavedRsvpPkt, pRsvpPkt, sizeof (RSVP_PKT));
+		      pSavedRsvpPkt->pFilterList = pFilterList;
+		      pSavedRsvpPkt->pFilterList->next = NULL;
+		      pSavedRsvpPkt->pIntegrityObj = NULL;	/* temp. */
+		      pSavedRsvpPkt->pPolicyDataObj = NULL;	/* temp. */
+		      pSavedRsvpPkt->pOpaqueObjList = NULL;	/* temp. */
+		      pSavedRsvpPkt->ReceivedRro.rr = NULL;	/* TEMP!!! */
+		      if ((pQueuedItem =
+			   (RSVP_PKT_QUEUE *) XMALLOC (MTYPE_RSVP,
+						       sizeof
+						       (RSVP_PKT_QUEUE))) ==
+			  NULL)
+			{
+			  zlog_err ("memory allocation failed %s %d",
+				    __FILE__, __LINE__);
+			  return E_ERR;
+			}
+
+		      pQueuedItem->MsgType = RESV_MSG;
+		      pQueuedItem->pRsvpPkt = pSavedRsvpPkt;
+		      pQueuedItem->next = NULL;
+		      if (EnqueueRsvpPacket
+			  (pQueuedItem,
+			   &pFilterSpecData->pPsb->packet_queue) != E_OK)
+			{
+			  zlog_err ("Cannot enqueue packet %s %d", __FILE__,
+				    __LINE__);
+			  return E_ERR;
+			}
+		      goto outer_loop_cont;
+		    }
+		  pFilterSpecData->pEffectiveFlow->MustBeProcessed = 1;
+		  zlog_info
+		    ("Adding filter_spec to effective_flow list .Src %x .LspId %x",
+		     pFilterSpecData->FilterSpec.IpAddr,
+		     pFilterSpecData->FilterSpec.LspId);
+		  if (NewFilterListNode
+		      (&pFilterSpecData->pEffectiveFlow->pFilterList,
+		       pFilterSpecData) != E_OK)
+		    {
+		      zlog_err ("Cannot create new FILTER LIST node");
+		      goto outer_loop_cont;
+		    }
+		  else
+		    {
+		      pFilterSpecData->NewFlowSpecValid = 1;
+		      pFilterSpecData->pEffectiveFlow->MustBeProcessed = 1;
+		      pFilterList->next = pRsb->OldPacket.pFilterList;
+		      pRsb->OldPacket.pFilterList = pFilterList;
+		    }
+		}
+	      else
+		{
+		  pFilterSpecData->NewFlowSpecValid = 1;
+		  pFilterList->next = pRsb->OldPacket.pFilterList;
+		  pRsb->OldPacket.pFilterList = pFilterList;
+		  /* send notification to TE */
+		  zlog_info ("Locking Flow %x %x %x %x %x %s %d",
+			     pFilterSpecData->pPsb->pRsb->RsbKey.Session.Dest,
+			     pFilterSpecData->pPsb->pRsb->RsbKey.Session.
+			     TunnelId,
+			     pFilterSpecData->pPsb->pRsb->RsbKey.Session.
+			     ExtTunelId, pFilterSpecData->FilterSpec.IpAddr,
+			     pFilterSpecData->FilterSpec.LspId, __FILE__,
+			     __LINE__);
+		  pFilterSpecData->pPsb->TE_InProcess = TRUE;
+		  PrepareAndSendMsg2TE4FF (pRsb,
+					   pFilterList->pFilterSpecData);
+		}
+	      if (pFilterListPrev == NULL)
+		{
+		  pRsvpPkt->pFilterList = pFilterListNext;
+		}
+	      else
+		{
+		  pFilterListPrev->next = pFilterListNext;
+		}
+	      ItemExtracted = TRUE;
+	      RsvpStatistics.NewFiltersCount++;
+	    }
+	}
+    outer_loop_cont:
+      if (ItemExtracted == FALSE)
+	{
+	  pFilterListPrev = pFilterList;
+	}
+      pFilterList = pFilterListNext;
+    }
+  if (Shared)
+    {
+      if (ProcessEffectiveFlows (pRsb) != E_OK)
+	{
+	  zlog_err ("an error on process effective flows");
+	  return E_ERR;
+	}
+    }
+  zlog_info ("leaving ProcessReceivedFilterSpecs");
+  return E_OK;
+}
+
+static E_RC
+BuildRRSubObj (FILTER_SPEC_DATA * pFilterSpecData)
+{
+  PSB *pPsb;
+
+
+  pPsb = pFilterSpecData->pPsb;
+  if ((pFilterSpecData->pPHopResvRefreshList->pAddedRro =
+       (RR_SUBOBJ *) XMALLOC (MTYPE_RSVP, sizeof (RR_SUBOBJ))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  else
+    {
+      IPV4_ADDR IpAddr;
+      uns8 LabelRecordingDesired = 0;
+      memset (pFilterSpecData->pPHopResvRefreshList->pAddedRro, 0,
+	      sizeof (RR_SUBOBJ));
+      pFilterSpecData->pPHopResvRefreshList->pAddedRro->SubObjHdr.Type =
+	RRO_SUBTYPE_IPV4;
+      pFilterSpecData->pPHopResvRefreshList->pAddedRro->SubObjHdr.Length = 8;
+      pFilterSpecData->pPHopResvRefreshList->pAddedRro->u.Ipv4.PrefixLen = 32;
+      zlog_info ("inside of BuildRRSubObj %s %d...", __FILE__, __LINE__);
+      if (IpAddrGetByIfIndex (pPsb->InIfIndex, &IpAddr) != E_OK)
+	{
+	  zlog_err ("Cannot set RSVP HOP %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pFilterSpecData->pPHopResvRefreshList->pAddedRro->u.Ipv4.IpAddr =
+	IpAddr;
+      if (pPsb->OldPacket.SessionAttributes.CType ==
+	  SESSION_ATTRIBUTES_RA_IPV4_CTYPE)
+	{
+	  if (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.
+	      Flags & LABEL_RECORDING_DESIRED)
+	    {
+	      LabelRecordingDesired = 1;
+	    }
+	}
+      else if (pPsb->OldPacket.SessionAttributes.CType ==
+	       SESSION_ATTRIBUTES_IPV4_CTYPE)
+	{
+	  if (pPsb->OldPacket.SessionAttributes.u.SessAttr.
+	      Flags & LABEL_RECORDING_DESIRED)
+	    {
+	      LabelRecordingDesired = 1;
+	    }
+	}
+      if (LabelRecordingDesired == 1)
+	{
+	  zlog_info ("inside of BuildRRSubObj %s %d...", __FILE__, __LINE__);
+	  if ((pFilterSpecData->pPHopResvRefreshList->pAddedRro->next =
+	       (RR_SUBOBJ *) XMALLOC (MTYPE_RSVP,
+				      sizeof (RR_SUBOBJ))) == NULL)
+	    {
+	      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  else
+	    {
+	      memset (pFilterSpecData->pPHopResvRefreshList->pAddedRro->next,
+		      0, sizeof (RR_SUBOBJ));
+	      pFilterSpecData->pPHopResvRefreshList->pAddedRro->next->
+		SubObjHdr.Type = RRO_SUBTYPE_LABEL;
+	      pFilterSpecData->pPHopResvRefreshList->pAddedRro->next->
+		SubObjHdr.Length = 8;
+	      pFilterSpecData->pPHopResvRefreshList->pAddedRro->next->u.Label.
+		CType = COMMON_CTYPE;
+	      pFilterSpecData->pPHopResvRefreshList->pAddedRro->next->u.Label.
+		Flags = 0x01;
+	      pFilterSpecData->pPHopResvRefreshList->pAddedRro->next->u.Label.
+		Label = pFilterSpecData->SentLabel.Label;
+	    }
+	}
+    }
+  return E_OK;
+}
+
+E_RC
+ProcessPHopFilterSpecLists (RSB * pRsb, uns8 Shared)
+{
+  PHOP_RESV_REFRESH_LIST *pPHopResvRefreshList;
+  FILTER_LIST *pFilterList;
+  int FlowCount = 0;
+  zlog_info ("entering ProcessPHopFilterSpecLists");
+  pPHopResvRefreshList = pRsb->pPHopResvRefreshList;
+  while (pPHopResvRefreshList != NULL)
+    {
+      if (pPHopResvRefreshList->MustBeProcessed)
+	{
+	  if (Shared)
+	    {
+	      memset (&pPHopResvRefreshList->FwdFlowSpec, 0,
+		      sizeof (FLOW_SPEC_OBJ));
+	    }
+
+	  pFilterList = pPHopResvRefreshList->pFilterList;
+
+	  while (pFilterList != NULL)
+	    {
+	      if ((pFilterList->pFilterSpecData->Blocked == TRUE) &&
+		  (FlowSpec1GreaterThanFlowSpec2
+		   (&pFilterList->pFilterSpecData->BlockadeFlowSpec,
+		    &pFilterList->pFilterSpecData->FlowSpec) == FALSE))
+		{
+		  pFilterList = pFilterList->next;
+		  continue;
+		}
+	      else if (pFilterList->pFilterSpecData->Blocked == TRUE)
+		{
+		  if (StopBlocadeTimer
+		      (&pFilterList->pFilterSpecData->BlocadeTimer) != E_OK)
+		    {
+		      zlog_err ("Cannot delete timer %s %d", __FILE__,
+				__LINE__);
+		    }
+		  pFilterList->pFilterSpecData->Blocked = FALSE;
+		}
+	      if (Shared)
+		{
+		  if (pPHopResvRefreshList->FwdFlowSpec.ServHdr.ServHdr == 0)
+		    {
+		      pPHopResvRefreshList->FwdFlowSpec.ServHdr.ServHdr =
+			pFilterList->pFilterSpecData->NewFlowSpec.ServHdr.
+			ServHdr;
+		    }
+
+		  CheckAndSetFlowSpecObj (pFilterList->pFilterSpecData->pPsb,
+					  &pFilterList->pFilterSpecData->
+					  FlowSpec,
+					  &pPHopResvRefreshList->FwdFlowSpec);
+		}
+	      FlowCount++;
+	      pFilterList = pFilterList->next;
+	    }
+	  if (FlowCount)
+	    {
+	      if (ResvRefreshProc (pRsb, pPHopResvRefreshList) != E_OK)
+		{
+		  zlog_err ("an error on resv refresh proc");
+		}
+	    }
+	  pPHopResvRefreshList->MustBeProcessed = 0;
+	}
+      pPHopResvRefreshList = pPHopResvRefreshList->next;
+    }
+
+  zlog_info ("leaving ProcessPHopFilterSpecLists");
+  return E_OK;
+}
+
+E_RC
+ProcessForwardedSEFilterSpecsByIfIndex (RSB * pRsb, uns32 IfIndex)
+{
+  FILTER_LIST *pFilterList;
+  PSB *pPsb;
+  uns8 Ingress = FALSE;
+  EFFECTIVE_FLOW *pEffectiveFlow = pRsb->pEffectiveFlow;
+  zlog_info ("entering ProcessForwardedSEFilterSpecsByIfIndex");
+  while (pEffectiveFlow != NULL)
+    {
+      if (pEffectiveFlow->IfIndex == IfIndex)
+	{
+	  break;
+	}
+      pEffectiveFlow = pEffectiveFlow->next;
+    }
+  if (pEffectiveFlow == NULL)
+    {
+      zlog_err ("Cannot find effective flow");
+      return E_ERR;
+    }
+  pEffectiveFlow->CurrentFlowSpec = pEffectiveFlow->NewFlowSpec;
+  pFilterList = pEffectiveFlow->pFilterList;
+  pEffectiveFlow->TE_InProcess = FALSE;
+  while (pFilterList != NULL)
+    {
+      FILTER_SPEC_DATA *pFilterSpecData = pFilterList->pFilterSpecData;
+
+      if (pFilterSpecData != NULL)
+	{
+	  if ((pFilterSpecData->Blocked == TRUE) &&
+	      (FlowSpec1GreaterThanFlowSpec2
+	       (&pFilterSpecData->BlockadeFlowSpec,
+		&pFilterSpecData->FlowSpec) == FALSE))
+	    {
+	      pFilterList = pFilterList->next;
+	      continue;
+	    }
+	  else if (pFilterSpecData->Blocked == TRUE)
+	    {
+	      if (StopBlocadeTimer (&pFilterSpecData->BlocadeTimer) != E_OK)
+		{
+		  zlog_err ("Cannot delete timer %s %d", __FILE__, __LINE__);
+		}
+	      pFilterSpecData->Blocked = FALSE;
+	    }
+	  pPsb = pFilterSpecData->pPsb;
+	  if (pFilterSpecData->NewFlowSpecValid)
+	    {
+	      pFilterSpecData->FlowSpec = pFilterSpecData->NewFlowSpec;
+	      pFilterSpecData->NewFlowSpecValid = 0;
+	      if (StartFilterAgeOutTimer (pFilterSpecData->AgeOutValue,
+					  &pFilterSpecData->AgeOutTimer,
+					  pFilterSpecData) != E_OK)
+		{
+		  zlog_err ("Cannot start timer %s %d", __FILE__, __LINE__);
+		}
+
+	      if (pFilterSpecData->pPsb->InIfIndex == 0)
+		{
+		  zlog_info ("Congratulations: RESV has reached Ingress!!");
+		  Ingress = TRUE;
+		}
+	    }
+
+	  if (pFilterSpecData->pPsb->InIfIndex == 0)
+	    {
+	      pFilterList = pFilterList->next;
+	      continue;
+	    }
+	  if (LinkFilter2PHopList (pFilterSpecData) != E_OK)
+	    {
+	      zlog_err ("An error on LinkFilter2PHopList %s %d", __FILE__,
+			__LINE__);
+	      goto outer_loop_cont;
+	    }
+	}
+    outer_loop_cont:
+      pFilterList = pFilterList->next;
+    }
+  if (Ingress == FALSE)
+    {
+      return ProcessPHopFilterSpecLists (pRsb, 1);
+    }
+  return E_OK;
+}
+
+E_RC
+ProcessFailedSEFilterSpecsByIfIndex (RSB * pRsb, uns32 IfIndex)
+{
+  FILTER_LIST *pFilterList;
+  uns8 Ingress = FALSE;
+  EFFECTIVE_FLOW *pEffectiveFlow = pRsb->pEffectiveFlow;
+  RSVP_PKT RsvpPkt;
+  IPV4_ADDR NHop = 0;
+  zlog_info ("entering ProcessFailedSEFilterSpecsByIfIndex");
+  memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+  RsvpPkt.Session = pRsb->RsbKey.Session;
+  RsvpPkt.Style = pRsb->OldPacket.Style;
+  RsvpPkt.ErrorSpec.IpAddr = GetRouterId ();
+  RsvpPkt.ErrorSpec.ErrCode = ADMISSION_CTRL_FAILURE_ERR_CODE;
+  RsvpPkt.ErrorSpec.ErrVal = BW_UNAVAILABLE;
+  RsvpPkt.SentRsvpHop.LIH = IfIndex;
+  RsvpPkt.SentRsvpHop.PHop = GetRouterId ();
+  while (pEffectiveFlow != NULL)
+    {
+      if (pEffectiveFlow->IfIndex == IfIndex)
+	{
+	  break;
+	}
+      pEffectiveFlow = pEffectiveFlow->next;
+    }
+  if (pEffectiveFlow == NULL)
+    {
+      zlog_err ("Cannot find effective flow");
+      return E_ERR;
+    }
+  pEffectiveFlow->CurrentFlowSpec = pEffectiveFlow->NewFlowSpec;
+  pFilterList = pEffectiveFlow->pFilterList;
+  pEffectiveFlow->TE_InProcess = FALSE;
+  while (pFilterList != NULL)
+    {
+      FILTER_SPEC_DATA *pFilterSpecData = pFilterList->pFilterSpecData;
+
+      if (pFilterSpecData != NULL)
+	{
+	  if (pFilterSpecData->NewFlowSpecValid)
+	    {
+	      if (StartBlocadeTimer (pFilterSpecData->BlocadeValue,
+				     &pFilterSpecData->BlocadeTimer,
+				     pFilterSpecData) != E_OK)
+		{
+		  zlog_err ("Cannot start blocade timer %s %d", __FILE__,
+			    __LINE__);
+		}
+	      else
+		{
+		  pFilterSpecData->Blocked = TRUE;
+		}
+	      memset (&pFilterSpecData->NewFlowSpec, 0,
+		      sizeof (FLOW_SPEC_OBJ));
+	      pFilterSpecData->NewFlowSpecValid = 0;
+	      if (StartFilterAgeOutTimer (pFilterSpecData->AgeOutValue,
+					  &pFilterSpecData->AgeOutTimer,
+					  pFilterSpecData) != E_OK)
+		{
+		  zlog_err ("Cannot start timer %s %d", __FILE__, __LINE__);
+		}
+
+	      if (pFilterSpecData->pPsb->InIfIndex == 0)
+		{
+		  Ingress = TRUE;
+		}
+	      NHop = pFilterSpecData->pPsb->NextHop;
+	      if (NewFilterListNode (&RsvpPkt.pFilterList, pFilterSpecData) !=
+		  E_OK)
+		{
+		  zlog_err ("Cannot add filter to filter list %s %d",
+			    __FILE__, __LINE__);
+		}
+
+	      if (pFilterSpecData->pPsb->InIfIndex == 0)
+		{
+		  pFilterList = pFilterList->next;
+		  continue;
+		}
+
+	      if (LinkFilter2PHopList (pFilterSpecData) != E_OK)
+		{
+		  zlog_err ("An error on LinkFilter2PHopList %s %d", __FILE__,
+			    __LINE__);
+		  goto outer_loop_cont;
+		}
+	    }
+	}
+    outer_loop_cont:
+      pFilterList = pFilterList->next;
+    }
+  if (EncodeAndSendRsvpResvErrMessage (&RsvpPkt, NHop, IfIndex, 255) != E_OK)
+    {
+      zlog_err ("Cannot encode/send ResvErr message %s %d", __FILE__,
+		__LINE__);
+    }
+  pFilterList = RsvpPkt.pFilterList;
+  while (pFilterList != NULL)
+    {
+      FILTER_LIST *pNext = pFilterList->next;
+      XFREE (MTYPE_RSVP, pFilterList);
+      pFilterList = pNext;
+    }
+  if (Ingress == FALSE)
+    {
+      return ProcessPHopFilterSpecLists (pRsb, 1);
+    }
+  return E_OK;
+}
+
+E_RC
+ProcessForwardedFFFilterSpec (RSB * pRsb, FILTER_SPEC_OBJ * pFilterSpecObj)
+{
+  PSB *pPsb;
+  FILTER_SPEC_DATA *pFilterSpecData = NULL;
+  FILTER_LIST *pFilterList = pRsb->OldPacket.pFilterList;
+  zlog_info ("entering ProcessForwardedFFFilterSpec");
+  while (pFilterList != NULL)
+    {
+      if ((pFilterSpecData = pFilterList->pFilterSpecData) != NULL)
+	{
+	  if (memcmp (&pFilterSpecData->FilterSpec,
+		      pFilterSpecObj, sizeof (FILTER_SPEC_OBJ)) == 0)
+	    {
+	      break;
+	    }
+	}
+      pFilterSpecData = NULL;
+      pFilterList = pFilterList->next;
+    }
+  if (pFilterSpecData != NULL)
+    {
+      pFilterSpecData->pPsb->TE_InProcess = FALSE;
+
+      if ((pFilterSpecData->Blocked == TRUE) &&
+	  (FlowSpec1GreaterThanFlowSpec2 (&pFilterSpecData->BlockadeFlowSpec,
+					  &pFilterSpecData->FlowSpec) ==
+	   FALSE))
+	{
+	  return E_OK;
+	}
+      else if (pFilterSpecData->Blocked == TRUE)
+	{
+	  if (StopBlocadeTimer (&pFilterSpecData->BlocadeTimer) != E_OK)
+	    {
+	      zlog_err ("Cannot delete timer %s %d", __FILE__, __LINE__);
+	    }
+	  pFilterSpecData->Blocked = FALSE;
+	}
+      pPsb = pFilterSpecData->pPsb;
+      if (pFilterSpecData->NewFlowSpecValid)
+	{
+	  pFilterSpecData->FlowSpec = pFilterSpecData->NewFlowSpec;
+	  pFilterSpecData->NewFlowSpecValid = 0;
+	  if (StartFilterAgeOutTimer (pFilterSpecData->AgeOutValue,
+				      &pFilterSpecData->AgeOutTimer,
+				      pFilterSpecData) != E_OK)
+	    {
+	      zlog_err ("Cannot start timer %s %d", __FILE__, __LINE__);
+	    }
+	}
+      if (pFilterSpecData->pPsb->InIfIndex == 0)
+	{
+	  return E_OK;
+	}
+      if (LinkFilter2PHopList (pFilterSpecData) != E_OK)
+	{
+	  zlog_err ("An error on LinkFilter2PHopList %s %d", __FILE__,
+		    __LINE__);
+	}
+      return ProcessPHopFilterSpecLists (pRsb, 0);
+    }
+  zlog_info ("leaving ProcessForwardedFFFilterSpec");
+  return E_ERR;
+}
+
+E_RC
+ProcessFailedFFFilterSpec (RSB * pRsb, FILTER_SPEC_OBJ * pFilterSpecObj)
+{
+  FILTER_SPEC_DATA *pFilterSpecData = NULL;
+  FILTER_LIST *pFilterList = pRsb->OldPacket.pFilterList;
+  zlog_info ("entering ProcessFailedFFFilterSpec");
+  while (pFilterList != NULL)
+    {
+      if ((pFilterSpecData = pFilterList->pFilterSpecData) != NULL)
+	{
+	  if (memcmp (&pFilterSpecData->FilterSpec,
+		      pFilterSpecObj, sizeof (FILTER_SPEC_OBJ)) == 0)
+	    {
+	      break;
+	    }
+	}
+      pFilterSpecData = NULL;
+      pFilterList = pFilterList->next;
+    }
+  if (pFilterSpecData != NULL)
+    {
+      pFilterSpecData->pPsb->TE_InProcess = FALSE;
+      if (StartBlocadeTimer (pFilterSpecData->BlocadeValue,
+			     &pFilterSpecData->BlocadeTimer,
+			     pFilterSpecData) != E_OK)
+	{
+	  zlog_err ("Cannot start blocade timer %s %d", __FILE__, __LINE__);
+	}
+      else
+	{
+	  pFilterSpecData->Blocked = TRUE;
+	}
+
+      if (pFilterSpecData->NewFlowSpecValid)
+	{
+	  memset (&pFilterSpecData->NewFlowSpec, 0, sizeof (FLOW_SPEC_OBJ));
+	  pFilterSpecData->NewFlowSpecValid = 0;
+	  if (StartFilterAgeOutTimer (pFilterSpecData->AgeOutValue,
+				      &pFilterSpecData->AgeOutTimer,
+				      pFilterSpecData) != E_OK)
+	    {
+	      zlog_err ("Cannot start timer %s %d", __FILE__, __LINE__);
+	    }
+	}
+      if (GenerateResvErr4SingleFilterSpec (pFilterSpecData,
+					    pRsb,
+					    pFilterSpecData->pPsb->NextHop,
+					    pFilterSpecData->pPsb->OutIfIndex,
+					    ADMISSION_CTRL_FAILURE_ERR_CODE,
+					    BW_UNAVAILABLE) != E_OK)
+	{
+	  zlog_err ("Cannot generate ResvErr message %s %d", __FILE__,
+		    __LINE__);
+	}
+      if (pFilterSpecData->pPsb->InIfIndex == 0)
+	{
+	  return E_OK;
+	}
+      if (LinkFilter2PHopList (pFilterSpecData) != E_OK)
+	{
+	  zlog_err ("An error on LinkFilter2PHopList %s %d", __FILE__,
+		    __LINE__);
+	}
+      return ProcessPHopFilterSpecLists (pRsb, 0);
+    }
+  zlog_info ("leaving ProcessFailedFFFilterSpec");
+  return E_ERR;
+}
+
+E_RC
+ProcessRsvpResvMessage (RSVP_PKT * pRsvpPkt)
+{
+  RSB *pRsb;
+  RSB_KEY RsbKey;
+  zlog_info ("entering ProcessRsvpResvMessage");
+  RsvpStatistics.ResvMsgCount++;
+  memset (&RsbKey, 0, sizeof (RSB_KEY));
+  RsbKey.Session = pRsvpPkt->Session;
+
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x",
+	     RsbKey.Session.Dest,
+	     RsbKey.Session.TunnelId, RsbKey.Session.ExtTunelId);
+
+  if ((pRsb = FindRsb (&RsbKey)) == NULL)
+    {
+      if ((pRsb = NewRSB (&RsbKey)) == NULL)
+	{
+	  return E_ERR;
+	}
+      pRsb->OldPacket.Session = pRsvpPkt->Session;
+      pRsb->OldPacket.Style = pRsvpPkt->Style;
+    }
+  else
+    {
+      if (memcmp (&pRsb->OldPacket.Style,
+		  &pRsvpPkt->Style, sizeof (STYLE_OBJ)))
+	{
+	  RSVP_PKT RsvpPkt;
+	  zlog_err ("Style object differs");
+
+	  memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+	  RsvpPkt.Session = pRsb->RsbKey.Session;
+	  RsvpPkt.Style = pRsb->OldPacket.Style;
+	  RsvpPkt.pFilterList = pRsvpPkt->pFilterList;
+	  RsvpPkt.ErrorSpec.IpAddr = GetRouterId ();
+	  RsvpPkt.ErrorSpec.ErrCode = CONFLICTING_RESV_STYLES_ERR_CODE;
+	  RsvpPkt.SentRsvpHop.LIH = pRsvpPkt->SentRsvpHop.LIH;
+	  if (IpAddrGetByIfIndex
+	      (RsvpPkt.SentRsvpHop.LIH, &RsvpPkt.SentRsvpHop.PHop) != E_OK)
+	    {
+	      zlog_err ("Cannot get IP address by IfIndex");
+	      return E_ERR;
+	    }
+	  if (EncodeAndSendRsvpResvErrMessage
+	      (&RsvpPkt, pRsvpPkt->ReceivedRsvpHop.PHop,
+	       RsvpPkt.SentRsvpHop.LIH, 255) != E_OK)
+	    {
+	      zlog_err ("An error on encode/send %s %d", __FILE__, __LINE__);
+	    }
+	  return E_ERR;
+	}
+    }
+  pRsb->OldPacket.ReceivedRsvpHop = pRsvpPkt->ReceivedRsvpHop;
+  pRsb->OldPacket.pIntegrityObj = pRsvpPkt->pIntegrityObj;
+  pRsvpPkt->pIntegrityObj = NULL;
+  pRsb->OldPacket.pPolicyDataObj = pRsvpPkt->pPolicyDataObj;
+  pRsvpPkt->pPolicyDataObj = NULL;
+  pRsb->OldPacket.pOpaqueObjList = pRsvpPkt->pOpaqueObjList;
+  pRsvpPkt->pOpaqueObjList = NULL;
+  pRsb->OldPacket.ResvConf = pRsvpPkt->ResvConf;
+  pRsb->OldPacket.TimeValues = pRsvpPkt->TimeValues;
+
+  if (ProcessReceivedFilterSpecs (pRsb, pRsvpPkt) != E_OK)
+    {
+      zlog_err ("An error on ProceessReceivedFilterSpecs");
+      return E_ERR;
+    }
+  if (pRsb->OldPacket.pFilterList == NULL)
+    {
+      FreeRSB (pRsb);
+      pRsb = NULL;
+    }
+  FreeRsvpPkt (pRsvpPkt);
+  zlog_info ("leaving ProcessRsvpResvMessage");
+  return E_OK;
+}
+
+static void
+PrepareAndSendMsg2TE4SE (RSB * pRsb, EFFECTIVE_FLOW * pEffectiveFlow)
+{
+  TE_API_MSG msg;
+  FILTER_LIST *pFilterList;
+  int i;
+  FILTER_LIST *pFilterListHead = pEffectiveFlow->pFilterList;
+
+  memset (&msg, 0, sizeof (msg));
+  msg.NotificationType = RESV_MSG_NOTIFICATION;
+  msg.u.ResvNotification.RsbKey = pRsb->RsbKey;
+  msg.u.ResvNotification.SharedExplicit = 1;
+  msg.u.ResvNotification.u.FilterDataSE.IfIndex = pEffectiveFlow->IfIndex;
+  msg.u.ResvNotification.PleaseReply = pEffectiveFlow->TE_InProcess;
+
+  if (pFilterListHead != NULL)
+    {
+      if (pFilterListHead->pFilterSpecData != NULL)
+	{
+	  msg.u.ResvNotification.Ingress =
+	    (pFilterListHead->pFilterSpecData->pPsb->InIfIndex == 0);
+
+	  if (pFilterListHead->pFilterSpecData->pPsb->OldPacket.
+	      SessionAttributes.CType == SESSION_ATTRIBUTES_RA_IPV4_CTYPE)
+	    {
+	      msg.u.ResvNotification.u.FilterDataSE.HoldPrio
+		=
+		pFilterListHead->pFilterSpecData->pPsb->OldPacket.
+		SessionAttributes.u.SessAttrRa.HoldPrio;
+	      msg.u.ResvNotification.u.FilterDataSE.SetupPrio =
+		pFilterListHead->pFilterSpecData->pPsb->OldPacket.
+		SessionAttributes.u.SessAttrRa.SetPrio;
+	    }
+	  else if (pFilterListHead->pFilterSpecData->pPsb->OldPacket.
+		   SessionAttributes.CType == SESSION_ATTRIBUTES_IPV4_CTYPE)
+	    {
+	      msg.u.ResvNotification.u.FilterDataSE.HoldPrio
+		=
+		pFilterListHead->pFilterSpecData->pPsb->OldPacket.
+		SessionAttributes.u.SessAttr.HoldPrio;
+	      msg.u.ResvNotification.u.FilterDataSE.SetupPrio =
+		pFilterListHead->pFilterSpecData->pPsb->OldPacket.
+		SessionAttributes.u.SessAttr.SetPrio;
+	    }
+	  else
+	    {
+	      msg.u.ResvNotification.u.FilterDataSE.HoldPrio =
+		msg.u.ResvNotification.u.FilterDataSE.SetupPrio = 4;
+	    }
+	}
+    }
+  if (pEffectiveFlow->NewFlowSpec.ServHdr.ServHdr ==
+      FLOW_SPEC_CTRL_LOAD_SERV_NUMBER)
+    {
+      msg.u.ResvNotification.u.FilterDataSE.BW =
+	pEffectiveFlow->NewFlowSpec.u.CtrlLoad.PeakDataRate;
+    }
+  else if (pEffectiveFlow->NewFlowSpec.ServHdr.ServHdr ==
+	   FLOW_SPEC_GUAR_SERV_NUMBER)
+    {
+      msg.u.ResvNotification.u.FilterDataSE.BW =
+	pEffectiveFlow->NewFlowSpec.u.Guar.CtrlLoad.PeakDataRate;
+    }
+  for (i = 0, pFilterList = pFilterListHead; pFilterList != NULL;
+       pFilterList = pFilterList->next)
+    {
+      FILTER_SPEC_DATA *pFilterSpecData = pFilterList->pFilterSpecData;
+      if (pFilterSpecData != NULL)
+	{
+	  if ((pFilterSpecData->NewFlowSpecValid) &&
+	      (pFilterSpecData->pPsb->TE_InProcess == FALSE))
+	    {
+	      msg.u.ResvNotification.u.FilterDataSE.FilterDataArraySE[i].
+		FilterSpec = pFilterSpecData->FilterSpec;
+
+	      msg.u.ResvNotification.u.FilterDataSE.FilterDataArraySE[i].
+		ReceivedLabel = pFilterSpecData->ReceivedLabel.Label;
+	      msg.u.ResvNotification.u.FilterDataSE.FilterDataArraySE[i].
+		AllocatedLabel = pFilterSpecData->pPsb->Label;
+	      i++;
+	      zlog_info ("Locking Flow %x %x %x %x %x %s %d",
+			 pFilterSpecData->pPsb->pRsb->RsbKey.Session.Dest,
+			 pFilterSpecData->pPsb->pRsb->RsbKey.Session.TunnelId,
+			 pFilterSpecData->pPsb->pRsb->RsbKey.Session.
+			 ExtTunelId, pFilterSpecData->FilterSpec.IpAddr,
+			 pFilterSpecData->FilterSpec.LspId, __FILE__,
+			 __LINE__);
+	      pFilterSpecData->pPsb->TE_InProcess = TRUE;
+	    }
+	}
+    }
+  msg.u.ResvNotification.u.FilterDataSE.FilterSpecNumber = i;
+  zlog_info ("sending message to TE upon RESV");
+  rsvp_send_msg (&msg, sizeof (msg));
+}
+
+static void
+PrepareAndSendMsg2TE4FF (RSB * pRsb, FILTER_SPEC_DATA * pFilterSpecData)
+{
+  TE_API_MSG msg;
+  FLOW_SPEC_OBJ *pFlowSpecObj;
+  memset (&msg, 0, sizeof (msg));
+  msg.NotificationType = RESV_MSG_NOTIFICATION;
+  msg.u.ResvNotification.RsbKey = pRsb->RsbKey;
+  msg.u.ResvNotification.SharedExplicit = 0;
+  msg.u.ResvNotification.u.FilterDataFF.IfIndex =
+    pFilterSpecData->pPsb->OutIfIndex;
+  msg.u.ResvNotification.PleaseReply = pFilterSpecData->pPsb->TE_InProcess;
+  if (pFilterSpecData == NULL)
+    {
+      zlog_err ("pFilterSpecData == NULL %s %d", __FILE__, __LINE__);
+      return;
+    }
+  msg.u.ResvNotification.Ingress = (pFilterSpecData->pPsb->InIfIndex == 0);
+  pFlowSpecObj =
+    (pFilterSpecData->NewFlowSpecValid) ? &pFilterSpecData->
+    NewFlowSpec : &pFilterSpecData->FlowSpec;
+  msg.u.ResvNotification.u.FilterDataFF.FilterSpec =
+    pFilterSpecData->FilterSpec;
+  if (pFilterSpecData->NewFlowSpec.ServHdr.ServHdr ==
+      FLOW_SPEC_CTRL_LOAD_SERV_NUMBER)
+    {
+      msg.u.ResvNotification.u.FilterDataFF.BW =
+	pFlowSpecObj->u.CtrlLoad.PeakDataRate;
+    }
+  else if (pFilterSpecData->NewFlowSpec.ServHdr.ServHdr ==
+	   FLOW_SPEC_GUAR_SERV_NUMBER)
+    {
+      msg.u.ResvNotification.u.FilterDataFF.BW =
+	pFlowSpecObj->u.Guar.CtrlLoad.PeakDataRate;
+    }
+  msg.u.ResvNotification.u.FilterDataFF.ReceivedLabel =
+    pFilterSpecData->ReceivedLabel.Label;
+  if (pFilterSpecData->pPsb->OldPacket.SessionAttributes.CType ==
+      SESSION_ATTRIBUTES_RA_IPV4_CTYPE)
+    {
+      msg.u.ResvNotification.u.FilterDataFF.HoldPrio
+	=
+	pFilterSpecData->pPsb->OldPacket.SessionAttributes.u.SessAttrRa.
+	HoldPrio;
+      msg.u.ResvNotification.u.FilterDataFF.SetupPrio =
+	pFilterSpecData->pPsb->OldPacket.SessionAttributes.u.SessAttrRa.
+	SetPrio;
+    }
+  else if (pFilterSpecData->pPsb->OldPacket.SessionAttributes.CType ==
+	   SESSION_ATTRIBUTES_IPV4_CTYPE)
+    {
+      msg.u.ResvNotification.u.FilterDataFF.HoldPrio
+	=
+	pFilterSpecData->pPsb->OldPacket.SessionAttributes.u.SessAttr.
+	HoldPrio;
+      msg.u.ResvNotification.u.FilterDataFF.SetupPrio =
+	pFilterSpecData->pPsb->OldPacket.SessionAttributes.u.SessAttr.SetPrio;
+    }
+  zlog_info ("sending message to TE upon RESV FF");
+  rsvp_send_msg (&msg, sizeof (msg));
+}
+
+void
+RsbDequeueAndInvokeMessages (RSB * pRsb)
+{
+  FILTER_LIST *pFilterList;
+  RSVP_PKT_QUEUE *pQueuedItem;
+  if (!pRsb)
+    return;
+  pFilterList = pRsb->OldPacket.pFilterList;
+  while (pFilterList != NULL)
+    {
+      while ((pFilterList->pFilterSpecData->pPsb->TE_InProcess == FALSE) &&
+	     (((pFilterList->pFilterSpecData->pEffectiveFlow != NULL)
+	       && (pFilterList->pFilterSpecData->pEffectiveFlow->
+		   TE_InProcess == FALSE))
+	      || (pFilterList->pFilterSpecData->pEffectiveFlow == NULL))
+	     &&
+	     ((pQueuedItem =
+	       DequeueRsvpPacket (&pFilterList->pFilterSpecData->pPsb->
+				  packet_queue)) != NULL))
+	{
+	  RSVP_PKT *pRsvpPkt;
+	  uns8 MsgType;
+	  uns32 InIfIndex = pQueuedItem->InIfIndex;
+	  IPV4_ADDR SourceIp = pQueuedItem->SourceIp;
+	  uns8 ttl = pQueuedItem->ttl;
+	  pRsvpPkt = pQueuedItem->pRsvpPkt;
+	  MsgType = pQueuedItem->MsgType;
+	  XFREE (MTYPE_RSVP, pQueuedItem);
+	  if (MsgType == PATH_MSG)
+	    {
+	      ProcessRsvpPathMessage (pRsvpPkt, InIfIndex, SourceIp, ttl);
+	    }
+	  else if (MsgType == PATH_TEAR_MSG)
+	    {
+	      ProcessRsvpPathTearMessage (pRsvpPkt, InIfIndex, SourceIp, ttl);
+	      return;
+	    }
+	  else if (MsgType == RESV_MSG)
+	    {
+	      ProcessRsvpResvMessage (pRsvpPkt);
+	    }
+	  else if (MsgType == RESV_TEAR_MSG)
+	    {
+	      ProcessRsvpResvTearMessage (pRsvpPkt);
+	    }
+	  else if (MsgType == RESV_ERR_MSG)
+	    {
+	      ProcessRsvpResvErrMessage (pRsvpPkt);
+	    }
+	  else
+	    zlog_err ("Unknown message type %d %s %d", MsgType, __FILE__,
+		      __LINE__);
+	}
+      pFilterList = pFilterList->next;
+    }
+}
+
+E_RC
+ResvTeMsgProc (TE_API_MSG * pMsg)
+{
+  RSB_KEY RsbKey;
+  RSB *pRsb;
+  FILTER_LIST *pFilterList;
+  int i;
+  zlog_info ("response from TE");
+  memset (&RsbKey, 0, sizeof (RSB_KEY));
+  RsbKey = pMsg->u.ResvNotification.RsbKey;
+  zlog_info ("Session.Dest %x .TunnelId %x .ExtTunnelId %x",
+	     RsbKey.Session.Dest,
+	     RsbKey.Session.TunnelId, RsbKey.Session.ExtTunelId);
+  if ((pRsb =
+       (RSB *) patricia_tree_get (&ResbTree, (const uns8 *) &RsbKey)) == NULL)
+    {
+      zlog_err ("Cannot get RSB %x %x %x %s %d",
+		RsbKey.Session.Dest,
+		RsbKey.Session.TunnelId,
+		RsbKey.Session.ExtTunelId, __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if (pMsg->u.ResvNotification.SharedExplicit)
+    {
+      for (i = 0;
+	   i < pMsg->u.ResvNotification.u.FilterDataSE.FilterSpecNumber; i++)
+	{
+	  pFilterList = pRsb->OldPacket.pFilterList;
+	  while (pFilterList != NULL)
+	    {
+	      if (memcmp (&pFilterList->pFilterSpecData->FilterSpec,
+			  &pMsg->u.ResvNotification.u.FilterDataSE.
+			  FilterDataArraySE[i].FilterSpec,
+			  sizeof (FILTER_SPEC_OBJ)) == 0)
+		{
+		  zlog_info ("Found FilterSpec %x %x",
+			     pFilterList->pFilterSpecData->FilterSpec.IpAddr,
+			     pFilterList->pFilterSpecData->FilterSpec.LspId);
+		  break;
+		}
+	      pFilterList = pFilterList->next;
+	    }
+	  if ((pFilterList != NULL)
+	      && (pFilterList->pFilterSpecData->pPsb->TE_InProcess == TRUE))
+	    {
+	      zlog_info ("Unlocking FilterSpec %x %x",
+			 pFilterList->pFilterSpecData->FilterSpec.IpAddr,
+			 pFilterList->pFilterSpecData->FilterSpec.LspId);
+	      pFilterList->pFilterSpecData->pPsb->TE_InProcess = FALSE;
+	    }
+	}
+    }
+  if (pMsg->u.ResvNotification.rc == FALSE)
+    {
+      if (pMsg->u.ResvNotification.SharedExplicit)
+	{
+	  if (ProcessFailedSEFilterSpecsByIfIndex
+	      (pRsb, pMsg->u.ResvNotification.u.FilterDataSE.IfIndex) != E_OK)
+	    {
+	      zlog_err
+		("An error on ProcessForwardedSEFilterSpecsByIfIndex %s %d",
+		 __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	}
+      else
+	{
+	  if (ProcessFailedFFFilterSpec
+	      (pRsb,
+	       &pMsg->u.ResvNotification.u.FilterDataFF.FilterSpec) != E_OK)
+	    {
+	      zlog_err ("An error on ProcessForwardedFFFilterSpec %s %d",
+			__FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	}
+      return E_OK;
+    }
+  if (pMsg->u.ResvNotification.SharedExplicit)
+    {
+      if (ProcessForwardedSEFilterSpecsByIfIndex
+	  (pRsb, pMsg->u.ResvNotification.u.FilterDataSE.IfIndex) != E_OK)
+	{
+	  zlog_err
+	    ("An error on ProcessForwardedSEFilterSpecsByIfIndex %s %d",
+	     __FILE__, __LINE__);
+	  return E_ERR;
+	}
+    }
+  else
+    {
+      if (ProcessForwardedFFFilterSpec
+	  (pRsb, &pMsg->u.ResvNotification.u.FilterDataFF.FilterSpec) != E_OK)
+	{
+	  zlog_err ("An error on ProcessForwardedFFFilterSpec %s %d",
+		    __FILE__, __LINE__);
+	  return E_ERR;
+	}
+    }
+  RsbDequeueAndInvokeMessages (pRsb);
+  zlog_info ("done...");
+  return E_OK;
+}
+
+E_RC
+FilterShutDown (FILTER_SPEC_DATA * pFilterSpecData, int Shared)
+{
+  uns8 Priority;
+  zlog_info ("entering FilterShutDown");
+  if (pFilterSpecData == NULL)
+    {
+      zlog_err ("pFilterSpecData == NULL %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  {
+    char buffer[80];
+    RSB *pRsb;
+    pRsb = pFilterSpecData->pPsb->pRsb;
+    sprintf (buffer, "Dest %x tunnel %x ext tunnel %x src %x lsp %x",
+	     pRsb->RsbKey.Session.Dest,
+	     pRsb->RsbKey.Session.TunnelId,
+	     pRsb->RsbKey.Session.ExtTunelId,
+	     pFilterSpecData->FilterSpec.IpAddr,
+	     pFilterSpecData->FilterSpec.LspId);
+    zlog_info ("Session and filter: %s", buffer);
+  }
+  if (StopFilterAgeOutTimer (&pFilterSpecData->AgeOutTimer) != E_OK)
+    {
+      zlog_err ("Cannot delete timer %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if (StopBlocadeTimer (&pFilterSpecData->BlocadeTimer) != E_OK)
+    {
+      zlog_err ("Cannot delete timer %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if ((pFilterSpecData->pPsb->InIfIndex != 0) &&
+      (pFilterSpecData->pPHopResvRefreshList != NULL))
+    {
+      zlog_info ("Not Ingress...");
+
+      pFilterSpecData->pPHopResvRefreshList->MustBeProcessed = 1;
+      if (pFilterSpecData->pPHopResvRefreshList->pSentBuffer != NULL)
+	{
+	  XFREE (MTYPE_RSVP,
+		 pFilterSpecData->pPHopResvRefreshList->pSentBuffer);
+	  pFilterSpecData->pPHopResvRefreshList->pSentBuffer = NULL;
+	  pFilterSpecData->pPHopResvRefreshList->SentBufferLen = 0;
+	}
+
+      DeleteFilterListNode (&pFilterSpecData->pPHopResvRefreshList->
+			    pFilterList, pFilterSpecData);
+
+      if (StopPHopResvRefreshTimer
+	  (&pFilterSpecData->pPHopResvRefreshList->ResvRefreshTimer) != E_OK)
+	{
+	  zlog_err ("Cannot delete timer %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+
+      if (pFilterSpecData->pPHopResvRefreshList->pFilterList == NULL)
+	{
+	  if (DeletePHopResvRefreshList (pFilterSpecData->pPsb->pRsb,
+					 pFilterSpecData->
+					 pPHopResvRefreshList) != E_OK)
+	    {
+	      zlog_err ("Cannot delete PHopResvRefreshList item");
+	    }
+	}
+    }
+#if 0
+  else if (pFilterSpecData->pPsb->InIfIndex != 0)
+#else
+  else if (pFilterSpecData->pPsb->pRsb != NULL)
+#endif
+    {
+      zlog_info
+	("PHopFilterList is NULL while not Ingress (TE may be in progress)");
+      PrepareAndSendResvTearNotificationMsg2TE (pFilterSpecData->pPsb->pRsb,
+						&pFilterSpecData->FilterSpec);
+    }
+  if (pFilterSpecData->pPsb->OutIfIndex != 0)
+    {
+      zlog_info ("Not Egress...");
+      if (Shared)
+	{
+	  if (DeleteFilterListNode
+	      (&pFilterSpecData->pEffectiveFlow->pFilterList,
+	       pFilterSpecData) != E_OK)
+	    {
+	      zlog_err
+		("Cannot delete filter from effective flow filter list");
+	      return E_ERR;
+	    }
+	  if (pFilterSpecData->pEffectiveFlow->pFilterList == NULL)
+	    {
+	      if (pFilterSpecData->pPsb->OldPacket.SessionAttributes.CType ==
+		  SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+		{
+		  Priority =
+		    pFilterSpecData->pPsb->OldPacket.SessionAttributes.u.
+		    SessAttrRa.HoldPrio;
+		}
+	      else if (pFilterSpecData->pPsb->OldPacket.SessionAttributes.
+		       CType == SESSION_ATTRIBUTES_CLASS_TYPE)
+		{
+		  Priority =
+		    pFilterSpecData->pPsb->OldPacket.SessionAttributes.u.
+		    SessAttr.HoldPrio;
+		}
+	      else
+		{
+		  Priority = 4;
+		}
+	      PrepareAndSendBWReleaseMsg2TE (pFilterSpecData->pPsb,
+					     Priority,
+					     pFilterSpecData->pEffectiveFlow->
+					     IfIndex, Shared);
+	      if (DeleteEffectiveFlow
+		  (pFilterSpecData->pPsb->pRsb,
+		   pFilterSpecData->pEffectiveFlow) != E_OK)
+		{
+		  zlog_err ("Cannot delete effective flow list item");
+		}
+	    }
+	  else
+	    {
+	      pFilterSpecData->pEffectiveFlow->MustBeProcessed = 1;
+	    }
+	}
+      else
+	{
+	  if (pFilterSpecData->pPsb->OldPacket.SessionAttributes.CType ==
+	      SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+	    {
+	      Priority =
+		pFilterSpecData->pPsb->OldPacket.SessionAttributes.u.
+		SessAttrRa.HoldPrio;
+	    }
+	  else if (pFilterSpecData->pPsb->OldPacket.SessionAttributes.CType ==
+		   SESSION_ATTRIBUTES_CLASS_TYPE)
+	    {
+	      Priority =
+		pFilterSpecData->pPsb->OldPacket.SessionAttributes.u.SessAttr.
+		HoldPrio;
+	    }
+	  else
+	    {
+	      Priority = 4;
+	    }
+	  /* update TE (BW release) */
+	  PrepareAndSendBWReleaseMsg2TE (pFilterSpecData->pPsb,
+					 Priority,
+					 pFilterSpecData->pPsb->OutIfIndex,
+					 Shared);
+	}
+    }
+  pFilterSpecData->pPsb->pRsb = NULL;
+  pFilterSpecData->pPsb->pFilterSpecData = NULL;
+  FreeFilterSpecData (&pFilterSpecData);
+  zlog_info ("leaving FilterShutDown");
+  return E_OK;
+}
+
+E_RC
+ForwardResvTearMsg (RSB * pRsb)
+{
+  RSVP_PKT RsvpPkt;
+  PHOP_RESV_REFRESH_LIST *pPHopResvRefreshList = pRsb->pPHopResvRefreshList;
+
+  zlog_info ("entering ForwardResvTearMsg");
+
+  memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+
+  RsvpPkt.Session = pRsb->RsbKey.Session;
+  RsvpPkt.pIntegrityObj = pRsb->OldPacket.pIntegrityObj;
+  RsvpPkt.pPolicyDataObj = pRsb->OldPacket.pPolicyDataObj;
+  RsvpPkt.Style = pRsb->OldPacket.Style;
+  while (pPHopResvRefreshList != NULL)
+    {
+      if (pPHopResvRefreshList->MustBeProcessed)
+	{
+	  FILTER_LIST *pFilterList =
+	    pPHopResvRefreshList->pFilterList, *pFilterListPrev = NULL;
+	  while (pFilterList != NULL)
+	    {
+	      if (pFilterList->pFilterSpecData != NULL)
+		{
+		  if (pFilterList->pFilterSpecData->ToBeDeleted)
+		    {
+		      if (pFilterListPrev == NULL)
+			{
+			  pPHopResvRefreshList->pFilterList =
+			    pPHopResvRefreshList->pFilterList->next;
+			}
+		      else
+			{
+			  pFilterListPrev->next = pFilterList->next;
+			}
+		      pFilterList->next = RsvpPkt.pFilterList;
+		      RsvpPkt.pFilterList = pFilterList;
+		    }
+		  else
+		    {
+		      pFilterListPrev = pFilterList;
+		    }
+		}
+	      pFilterList = pFilterList->next;
+	    }
+	  if (RsvpPkt.pFilterList != NULL)
+	    {
+	      if (pPHopResvRefreshList->InIfIndex != 0)
+		{
+		  if (IpAddrGetByIfIndex
+		      (pPHopResvRefreshList->InIfIndex,
+		       &RsvpPkt.SentRsvpHop.PHop) != E_OK)
+		    {
+		      zlog_err ("Cannot set RSVP HOP %s %d", __FILE__,
+				__LINE__);
+		      return E_ERR;
+		    }
+		  RsvpPkt.SentRsvpHop.LIH = pPHopResvRefreshList->PHop.LIH;
+		  if (EncodeAndSendRsvpResvTearMessage (&RsvpPkt,
+							pPHopResvRefreshList->
+							PHop.PHop,
+							pPHopResvRefreshList->
+							InIfIndex, 1) != E_OK)
+		    {
+		      zlog_err ("cannot encode/send RESV_TEAR message");
+		    }
+		}
+	      else
+		{
+		  zlog_info ("%s %d", __FILE__, __LINE__);
+		}
+	      memset (&RsvpPkt.SentRsvpHop, 0, sizeof (RSVP_HOP_OBJ));
+	      pFilterListPrev = RsvpPkt.pFilterList;
+	      while (pFilterListPrev != NULL)
+		{
+		  pFilterList = pFilterListPrev->next;
+		  XFREE (MTYPE_RSVP, pFilterListPrev);
+		  pFilterListPrev = pFilterList;
+		}
+	      RsvpPkt.pFilterList = NULL;
+	    }
+	  //pPHopResvRefreshList->MustBeProcessed = 1;
+	}
+      pPHopResvRefreshList = pPHopResvRefreshList->next;
+    }
+  zlog_info ("leaving ForwardResvTearMsg");
+  return E_OK;
+}
+
+E_RC
+ProcessRsvpResvTearMessage (RSVP_PKT * pRsvpPkt)
+{
+  RSB *pRsb;
+  RSB_KEY RsbKey;
+  FILTER_SPEC_DATA *pFilterSpecData, *pFilterSpecData2;
+  FILTER_LIST *pFilterList, *pFilterListPrev =
+    NULL, *pFilterList2, *pFilterList2BeDeleted =
+    NULL, *pFilterListPrev2, *pFilterListNext;
+  uns8 ItemExtracted;
+  int Shared = 0;
+  zlog_info ("entering ProcessRsvpResvTearMessage");
+  RsvpStatistics.ResvTearMsgCount++;
+  memset (&RsbKey, 0, sizeof (RSB_KEY));
+  RsbKey.Session = pRsvpPkt->Session;
+
+  if ((pRsb = FindRsb (&RsbKey)) == NULL)
+    {
+      zlog_info ("leaving ProcessRsvpResvTearMessage");
+      FreeRsvpPkt (pRsvpPkt);
+      return E_OK;
+    }
+
+  if ((pRsb->OldPacket.Style.OptionVector2 & 0x001F) == SE_STYLE_BITS)
+    {
+      Shared = 1;
+    }
+  /* First - for the list of FILTER_SPECs to be deleted */
+  zlog_info ("Determining FilterSpecs to be deleted...");
+  pFilterList = pRsvpPkt->pFilterList;
+  while (pFilterList != NULL)
+    {
+      pFilterSpecData = pFilterList->pFilterSpecData;
+      pFilterListNext = pFilterList->next;
+      ItemExtracted = FALSE;
+      if (pFilterSpecData != NULL)
+	{
+	  zlog_info ("FilterSpec %x %x", pFilterSpecData->FilterSpec.IpAddr,
+		     pFilterSpecData->FilterSpec.LspId);
+	  pFilterList2 = pRsb->OldPacket.pFilterList;
+	  pFilterListPrev2 = NULL;
+	  while (pFilterList2 != NULL)
+	    {
+	      pFilterSpecData2 = pFilterList2->pFilterSpecData;
+	      if (pFilterSpecData2 != NULL)
+		{
+		  zlog_info ("FilterSpec2 %x %x",
+			     pFilterSpecData2->FilterSpec.IpAddr,
+			     pFilterSpecData2->FilterSpec.LspId);
+		  if (memcmp
+		      (&pFilterSpecData->FilterSpec,
+		       &pFilterSpecData2->FilterSpec,
+		       sizeof (FILTER_SPEC_OBJ)) == 0)
+		    {
+		      if ((pFilterSpecData2->pPsb->TE_InProcess == TRUE) ||
+			  ((pFilterSpecData2->pEffectiveFlow)
+			   && (pFilterSpecData2->pEffectiveFlow->
+			       TE_InProcess)))
+			{
+			  RSVP_PKT_QUEUE *pQueuedItem;
+			  RSVP_PKT *pSavedRsvpPkt;
+			  if (pFilterListPrev == NULL)
+			    {
+			      pRsvpPkt->pFilterList = pFilterListNext;
+			    }
+			  else
+			    {
+			      pFilterListPrev->next = pFilterListNext;
+			    }
+			  ItemExtracted = TRUE;
+			  if ((pSavedRsvpPkt =
+			       (RSVP_PKT *) XMALLOC (MTYPE_RSVP,
+						     sizeof (RSVP_PKT))) ==
+			      NULL)
+			    {
+			      zlog_err ("memory allocation failed %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+			  memcpy (pSavedRsvpPkt, pRsvpPkt, sizeof (RSVP_PKT));
+			  pSavedRsvpPkt->pFilterList = pFilterList;
+			  pSavedRsvpPkt->pFilterList->next = NULL;
+			  pSavedRsvpPkt->pIntegrityObj = NULL;	/* temp. */
+			  pSavedRsvpPkt->pPolicyDataObj = NULL;	/* temp. */
+			  pSavedRsvpPkt->pOpaqueObjList = NULL;	/* temp. */
+			  pSavedRsvpPkt->ReceivedRro.rr = NULL;	/* TEMP!!! */
+			  if ((pQueuedItem =
+			       (RSVP_PKT_QUEUE *) XMALLOC (MTYPE_RSVP,
+							   sizeof
+							   (RSVP_PKT_QUEUE)))
+			      == NULL)
+			    {
+			      zlog_err ("memory allocation failed %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+
+			  pQueuedItem->MsgType = RESV_TEAR_MSG;
+			  pQueuedItem->pRsvpPkt = pSavedRsvpPkt;
+			  pQueuedItem->next = NULL;
+			  if (EnqueueRsvpPacket
+			      (pQueuedItem,
+			       &pFilterSpecData2->pPsb->packet_queue) != E_OK)
+			    {
+			      zlog_err ("Cannot enqueue packet %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+			  zlog_info ("Queued...");
+			  break;
+			}
+		      if (pFilterSpecData2->pPHopResvRefreshList != 0)
+			{
+			  pFilterSpecData2->ToBeDeleted = 1;
+			  pFilterSpecData2->pPHopResvRefreshList->
+			    MustBeProcessed = 1;
+			}
+
+		      if (pFilterListPrev2 == NULL)
+			{
+			  pRsb->OldPacket.pFilterList =
+			    pRsb->OldPacket.pFilterList->next;
+			}
+		      else
+			{
+			  pFilterListPrev2->next = pFilterList2->next;
+			}
+		      pFilterList2->next = pFilterList2BeDeleted;
+		      pFilterList2BeDeleted = pFilterList2;
+		      zlog_info ("Inserted to deletion list...");
+		      break;
+		    }
+		}
+	      else
+		{
+		  zlog_info ("FilterSpec - FlowSpecData2 is NULL!!!");
+		}
+	      pFilterListPrev2 = pFilterList2;
+	      pFilterList2 = pFilterList2->next;
+	    }
+	}
+      else
+	{
+	  zlog_info ("FilterSpec - FlowSpecData is NULL!!!");
+	}
+      if (ItemExtracted == FALSE)
+	{
+	  pFilterListPrev = pFilterList;
+	}
+      pFilterList = pFilterListNext;
+    }
+
+  if (ForwardResvTearMsg (pRsb) != E_OK)
+    {
+      zlog_err ("an error on ForwardResvTearMsg");
+    }
+
+  pFilterListPrev = pFilterList2BeDeleted;
+  while (pFilterListPrev != NULL)
+    {
+      PSB *pPsb;
+      pFilterList = pFilterListPrev->next;
+      pFilterSpecData = pFilterListPrev->pFilterSpecData;
+      pPsb = pFilterSpecData->pPsb;
+      if (FilterShutDown (pFilterSpecData, Shared) != E_OK)
+	{
+	  zlog_err ("An error in FilterShutDown %s %d", __FILE__, __LINE__);
+	}
+      XFREE (MTYPE_RSVP, pFilterListPrev);
+      pFilterListPrev = pFilterList;
+    }
+
+  if ((pRsb->OldPacket.pFilterList == NULL) &&
+      ((pRsb->pEffectiveFlow != NULL) ||
+       (pRsb->pPHopResvRefreshList != NULL)))
+    {
+      zlog_err ("Cleanup was not completed properly %s %d", __FILE__,
+		__LINE__);
+    }
+
+  if (pRsb->OldPacket.pFilterList != NULL)
+    {
+      if (Shared)
+	{
+	  if (ProcessEffectiveFlows (pRsb) != E_OK)
+	    {
+	      zlog_err ("An error in ProcessEffectiveFlows %s %d", __FILE__,
+			__LINE__);
+	    }
+	}
+      /* update TE (BW release) */
+      if (ProcessPHopFilterSpecLists (pRsb, Shared) != E_OK)
+	{
+	  zlog_err ("An error in ProcessPHopFilterSpecLists %s %d", __FILE__,
+		    __LINE__);
+	}
+    }
+  else
+    {
+      FreeRSB (pRsb);
+    }
+  FreeRsvpPkt (pRsvpPkt);
+  zlog_info ("leaving ProcessRsvpResvTearMessage");
+  return E_OK;
+}
+
+typedef struct IfList
+{
+  uns32 IfIndex;
+  IPV4_ADDR NHop;
+  uns8 ttl;
+  FILTER_LIST *pFilterList;
+  struct IfList *next;
+} IF_LIST;
+
+E_RC
+ProcessRsvpResvErrMessage (RSVP_PKT * pRsvpPkt)
+{
+  RSB *pRsb;
+  RSB_KEY RsbKey;
+  FILTER_LIST *pFilterList, *pFilterList2, *pFilterListNext,
+    *pFilterListPrev = NULL;
+  IF_LIST *pIfList = NULL, *pIfListEntry, *pIfListEntryPrev = NULL;
+  uns8 Shared = 0;
+  uns8 ItemExtracted;
+  RSVP_PKT RsvpPkt;
+  zlog_info ("entering ProcessRsvpResvErrMessage");
+  RsvpStatistics.ResvErrMsgCount++;
+  memset (&RsbKey, 0, sizeof (RSB_KEY));
+
+  RsbKey.Session = pRsvpPkt->Session;
+
+  if ((pRsb = FindRsb (&RsbKey)) == NULL)
+    {
+      zlog_err ("Cannot find RSB");
+      FreeRsvpPkt (pRsvpPkt);
+      return E_ERR;
+    }
+  if ((pRsb->OldPacket.Style.OptionVector2 & 0x001F) == SE_STYLE_BITS)
+    {
+      Shared = 1;
+    }
+
+  pFilterList = pRsvpPkt->pFilterList;
+  while (pFilterList != NULL)
+    {
+      FILTER_SPEC_DATA *pFilterSpecData = pFilterList->pFilterSpecData;
+      pFilterListNext = pFilterList->next;
+      ItemExtracted = FALSE;
+      if (pFilterSpecData == NULL)
+	{
+	  pFilterList = pFilterList->next;
+	  continue;
+	}
+      pFilterList2 = pRsb->OldPacket.pFilterList;
+      while (pFilterList2 != NULL)
+	{
+	  if (pFilterList2->pFilterSpecData == NULL)
+	    {
+	      pFilterList2 = pFilterList2->next;
+	      continue;
+	    }
+	  if ((pFilterSpecData->FilterSpec.IpAddr ==
+	       pFilterList2->pFilterSpecData->FilterSpec.IpAddr)
+	      && (pFilterSpecData->FilterSpec.LspId ==
+		  pFilterList2->pFilterSpecData->FilterSpec.LspId))
+	    {
+	      if ((pFilterList2->pFilterSpecData->pPsb->TE_InProcess == TRUE)
+		  || ((pFilterList2->pFilterSpecData->pEffectiveFlow)
+		      && (pFilterList2->pFilterSpecData->pEffectiveFlow->
+			  TE_InProcess == TRUE)))
+		{
+		  RSVP_PKT_QUEUE *pQueuedItem;
+		  RSVP_PKT *pSavedRsvpPkt;
+		  if (pFilterListPrev == NULL)
+		    {
+		      pRsvpPkt->pFilterList = pFilterListNext;
+		    }
+		  else
+		    {
+		      pFilterListPrev->next = pFilterListNext;
+		    }
+		  ItemExtracted = TRUE;
+		  if ((pSavedRsvpPkt =
+		       (RSVP_PKT *) XMALLOC (MTYPE_RSVP,
+					     sizeof (RSVP_PKT))) == NULL)
+		    {
+		      zlog_err ("memory allocation failed %s %d", __FILE__,
+				__LINE__);
+		      return E_ERR;
+		    }
+		  memcpy (pSavedRsvpPkt, pRsvpPkt, sizeof (RSVP_PKT));
+		  pSavedRsvpPkt->pFilterList = pFilterList;
+		  pSavedRsvpPkt->pFilterList->next = NULL;
+		  pSavedRsvpPkt->pIntegrityObj = NULL;	/* temp. */
+		  pSavedRsvpPkt->pPolicyDataObj = NULL;	/* temp. */
+		  pSavedRsvpPkt->pOpaqueObjList = NULL;	/* temp. */
+		  pSavedRsvpPkt->ReceivedRro.rr = NULL;	/* TEMP!!! */
+		  if ((pQueuedItem =
+		       (RSVP_PKT_QUEUE *) XMALLOC (MTYPE_RSVP,
+						   sizeof (RSVP_PKT_QUEUE)))
+		      == NULL)
+		    {
+		      zlog_err ("memory allocation failed %s %d", __FILE__,
+				__LINE__);
+		      return E_ERR;
+		    }
+		  pQueuedItem->MsgType = RESV_ERR_MSG;
+		  pQueuedItem->pRsvpPkt = pSavedRsvpPkt;
+		  pQueuedItem->next = NULL;
+		  if (EnqueueRsvpPacket
+		      (pQueuedItem,
+		       &pFilterList2->pFilterSpecData->pPsb->packet_queue) !=
+		      E_OK)
+		    {
+		      zlog_err ("Cannot enqueue packet %s %d", __FILE__,
+				__LINE__);
+		      return E_ERR;
+		    }
+		  pFilterList2 = NULL;
+		}
+	      break;
+	    }
+	  pFilterList2 = pFilterList2->next;
+	}
+      if (pFilterList2 != NULL)
+	{
+	  uns32 IfIndex = pFilterList2->pFilterSpecData->pPsb->OutIfIndex;
+	  IPV4_ADDR NHop = pFilterList2->pFilterSpecData->pPsb->NextHop;
+	  uns8 ttl = pFilterList2->pFilterSpecData->pPsb->ttl;
+	  if (IfIndex != 0)
+	    {
+	      pIfListEntry = pIfList;
+	      while (pIfListEntry != NULL)
+		{
+		  if (pIfListEntry->IfIndex == IfIndex)
+		    {
+		      break;
+		    }
+		  pIfListEntryPrev = pIfListEntry;
+		  pIfListEntry = pIfListEntry->next;
+		}
+	      if (pIfListEntry == NULL)
+		{
+		  if ((pIfListEntry =
+		       (IF_LIST *) XMALLOC (MTYPE_RSVP,
+					    sizeof (IF_LIST))) == NULL)
+		    {
+		      zlog_err ("Cannot allocate memory %s %d", __FILE__,
+				__LINE__);
+		      FreeRsvpPkt (pRsvpPkt);
+		      return E_ERR;
+		    }
+		  memset (pIfListEntry, 0, sizeof (IF_LIST));
+		  pIfListEntry->IfIndex = IfIndex;
+		  pIfListEntry->NHop = NHop;
+		  pIfListEntry->ttl = ttl;
+		  if (pIfListEntryPrev == NULL)
+		    {
+		      pIfList = pIfListEntry;
+		    }
+		  else
+		    {
+		      pIfListEntryPrev->next = pIfListEntry;
+		    }
+		}
+	      if (NewFilterListNode
+		  (&pIfListEntry->pFilterList, pFilterSpecData) != E_OK)
+		{
+		  zlog_err ("An error on NewFilterListNode");
+		  FreeRsvpPkt (pRsvpPkt);
+		  return E_ERR;
+		}
+	      if ((Shared) &&
+		  (pRsvpPkt->ErrorSpec.ErrCode ==
+		   ADMISSION_CTRL_FAILURE_ERR_CODE))
+		{
+		  pFilterList2->pFilterSpecData->pEffectiveFlow->
+		    MustBeProcessed = 1;
+		}
+	    }
+	  if (pRsvpPkt->ErrorSpec.ErrCode == ADMISSION_CTRL_FAILURE_ERR_CODE)
+	    {
+	      if (StartBlocadeTimer
+		  (pFilterList2->pFilterSpecData->BlocadeValue,
+		   &pFilterList2->pFilterSpecData->BlocadeTimer,
+		   pFilterList2->pFilterSpecData) != E_OK)
+		{
+		  zlog_err ("Cannot add timer");
+		  FreeRsvpPkt (pRsvpPkt);
+		  return E_ERR;
+		}
+	      pFilterList2->pFilterSpecData->Blocked = TRUE;
+	      memcpy (&pFilterList2->pFilterSpecData->BlockadeFlowSpec,
+		      &pFilterList->pFilterSpecData->NewFlowSpec,
+		      sizeof (FLOW_SPEC_OBJ));
+	      if (pFilterList2->pFilterSpecData->pPsb->InIfIndex != 0)
+		{
+		  pFilterList2->pFilterSpecData->pPHopResvRefreshList->
+		    MustBeProcessed = 1;
+		}
+	    }
+	}
+      if (ItemExtracted == FALSE)
+	{
+	  pFilterListPrev = pFilterList;
+	}
+      pFilterList = pFilterListNext;
+    }
+  if (pRsvpPkt->ErrorSpec.ErrCode == ADMISSION_CTRL_FAILURE_ERR_CODE)
+    {
+      if (Shared)
+	{
+	  if (ProcessEffectiveFlows (pRsb) != E_OK)
+	    {
+	      zlog_err ("An error on ProcessEffectiveFlows %s %d", __FILE__,
+			__LINE__);
+	    }
+	}
+      else
+	{
+	  pFilterList = pRsvpPkt->pFilterList;
+	  while (pFilterList != NULL)
+	    {
+	      uns8 Priority;
+	      if (pFilterList->pFilterSpecData->pPsb->OldPacket.
+		  SessionAttributes.CType == SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+		{
+		  Priority =
+		    pFilterList->pFilterSpecData->pPsb->OldPacket.
+		    SessionAttributes.u.SessAttrRa.HoldPrio;
+		}
+	      else if (pFilterList->pFilterSpecData->pPsb->OldPacket.
+		       SessionAttributes.CType ==
+		       SESSION_ATTRIBUTES_CLASS_TYPE)
+		{
+		  Priority =
+		    pFilterList->pFilterSpecData->pPsb->OldPacket.
+		    SessionAttributes.u.SessAttr.HoldPrio;
+		}
+	      else
+		{
+		  Priority = 4;
+		}
+	      PrepareAndSendBWReleaseMsg2TE (pFilterList->pFilterSpecData->
+					     pPsb, Priority,
+					     pFilterList->pFilterSpecData->
+					     pPsb->OutIfIndex, Shared);
+	      pFilterList = pFilterList->next;
+	    }
+	}
+      if (ProcessPHopFilterSpecLists (pRsb, Shared) != E_OK)
+	{
+	  zlog_err ("An error on ProcessPHopFilterSpecLists %s %d", __FILE__,
+		    __LINE__);
+	}
+    }
+
+  pIfListEntry = pIfList;
+  memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+  RsvpPkt.Session = RsbKey.Session;
+  RsvpPkt.Style = pRsb->OldPacket.Style;
+  RsvpPkt.ErrorSpec = pRsvpPkt->ErrorSpec;
+  while (pIfListEntry != NULL)
+    {
+      RsvpPkt.SentRsvpHop.LIH = pIfListEntry->IfIndex;
+      if (IpAddrGetByIfIndex
+	  (pIfListEntry->IfIndex, &RsvpPkt.SentRsvpHop.PHop) != E_OK)
+	{
+	  zlog_err ("Cannot get IP address by IfIndex");
+	  pIfListEntry = pIfListEntry->next;
+	  continue;
+	}
+      RsvpPkt.pFilterList = pIfListEntry->pFilterList;
+      if (EncodeAndSendRsvpResvErrMessage
+	  (&RsvpPkt, pIfListEntry->NHop, pIfListEntry->IfIndex,
+	   pIfListEntry->ttl) != E_OK)
+	{
+	  zlog_err ("An error on encode/send %s %d", __FILE__, __LINE__);
+	}
+      pFilterList = pIfListEntry->pFilterList;
+      while (pFilterList != NULL)
+	{
+	  pFilterList2 = pFilterList->next;
+	  XFREE (MTYPE_RSVP, pFilterList);
+	  pFilterList = pFilterList2;
+	}
+      pIfList = pIfListEntry->next;
+      XFREE (MTYPE_RSVP, pIfListEntry);
+      pIfListEntry = pIfList;
+    }
+  FreeRsvpPkt (pRsvpPkt);
+  zlog_info ("leaving ProcessRsvpResvErrMessage");
+  return E_OK;
+}
+
+static void
+PrepareAndSendBWReleaseMsg2TE (PSB * pPsb, uns8 Priority, uns32 IfIndex,
+			       uns8 Shared)
+{
+  TE_API_MSG msg;
+
+  memset (&msg, 0, sizeof (msg));
+  msg.NotificationType = BW_RELEASE_NOTIFICATION;
+  if (Shared)
+    {
+      msg.u.BwRelease.PsbKey.Session = pPsb->PsbKey.Session;
+    }
+  else
+    {
+      msg.u.BwRelease.PsbKey = pPsb->PsbKey;
+    }
+  msg.u.BwRelease.IfIndex = IfIndex;
+  msg.u.BwRelease.HoldPrio = Priority;	/*pFilterSpecData->pPsb->OldPacket.SessionAttributes.u.SessAttrRa.HoldPrio */
+  zlog_info ("sending message to TE upon RESV");
+  rsvp_send_msg (&msg, sizeof (msg));
+}
+
+static void
+PrepareAndSendResvTearNotificationMsg2TE (RSB * pRsb,
+					  FILTER_SPEC_OBJ * pFilterSpec)
+{
+  TE_API_MSG msg;
+
+  memset (&msg, 0, sizeof (msg));
+  msg.NotificationType = RESV_TEAR_NOTIFICATION;
+  msg.u.ResvTearNotification.RsbKey = pRsb->RsbKey;
+  msg.u.ResvTearNotification.FilterSpec = *pFilterSpec;
+  zlog_info ("sending message to TE upon RESV");
+  rsvp_send_msg (&msg, sizeof (msg));
+}
+
+void
+PreemptFlow (TE_API_MSG * pMsg)
+{
+  RSB *pRsb;
+  PSB *pPsb;
+  RSB_KEY RsbKey;
+  FILTER_LIST *pFilterList, *pFilterList2BeDeleted = NULL, *pFilterListPrev =
+    NULL;
+  RSVP_PKT RsvpPkt;
+  FILTER_SPEC_DATA *pFilterSpecData;
+  int Shared = 0;
+  IF_LIST *pIfList = NULL, *pIfListEntry, *pIfListEntryPrev = NULL;
+
+  zlog_info ("entering PreemptFlow");
+
+  memset (&RsbKey, 0, sizeof (RSB_KEY));
+  RsbKey = pMsg->u.PreemptFlow.RsbKey;
+  if ((pRsb = FindRsb (&RsbKey)) == NULL)
+    {
+      zlog_err ("Cannot find RSB %s %d", __FILE__, __LINE__);
+      return;
+    }
+  if ((pRsb->OldPacket.Style.OptionVector2 & 0x1F) == SE_STYLE_BITS)
+    {
+      Shared = 1;
+    }
+  memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+  RsvpPkt.Session = RsbKey.Session;
+  RsvpPkt.ErrorSpec.IpAddr = GetRouterId ();
+  RsvpPkt.ErrorSpec.ErrCode = ADMISSION_CTRL_FAILURE_ERR_CODE;
+  RsvpPkt.ErrorSpec.ErrVal = BW_UNAVAILABLE;
+  pFilterList = pRsb->OldPacket.pFilterList;
+  if (!pMsg->u.PreemptFlow.FilterSpecValid)
+    {
+      pFilterList2BeDeleted = pFilterList;
+      pRsb->OldPacket.pFilterList = NULL;
+    }
+  while (pFilterList != NULL)
+    {
+      pFilterSpecData = pFilterList->pFilterSpecData;
+      if (((pMsg->u.PreemptFlow.FilterSpecValid) &&
+	   (memcmp (&pFilterSpecData->FilterSpec,
+		    &pMsg->u.PreemptFlow.FilterSpec,
+		    sizeof (FILTER_SPEC_OBJ)) == 0)) ||
+	  (!pMsg->u.PreemptFlow.FilterSpecValid))
+	{
+	  uns32 IfIndex = pFilterSpecData->pPsb->OutIfIndex;
+	  IPV4_ADDR NHop = pFilterSpecData->pPsb->NextHop;
+	  uns8 ttl = pFilterSpecData->pPsb->ttl;
+
+	  if (IfIndex != 0)
+	    {
+	      pIfListEntry = pIfList;
+	      while (pIfListEntry != NULL)
+		{
+		  if (pIfListEntry->IfIndex == IfIndex)
+		    break;
+		  pIfListEntryPrev = pIfListEntry;
+		  pIfListEntry = pIfListEntry->next;
+		}
+	      if (pIfListEntry == NULL)
+		{
+		  if ((pIfListEntry =
+		       (IF_LIST *) XMALLOC (MTYPE_RSVP,
+					    sizeof (IF_LIST))) == NULL)
+		    {
+		      zlog_err ("Cannot allocate memory %s %d", __FILE__,
+				__LINE__);
+		      return;
+		    }
+		  memset (pIfListEntry, 0, sizeof (IF_LIST));
+		  pIfListEntry->IfIndex = IfIndex;
+		  pIfListEntry->NHop = NHop;
+		  pIfListEntry->ttl = ttl;
+		  if (NewFilterListNode
+		      (&pIfListEntry->pFilterList, pFilterSpecData) != E_OK)
+		    {
+		      zlog_err ("An error on NewFilterListNode");
+		      return;
+		    }
+		  if (pIfListEntryPrev == NULL)
+		    {
+		      pIfList = pIfListEntry;
+		    }
+		  else
+		    {
+		      pIfListEntryPrev->next = pIfListEntry;
+		    }
+		}
+	      if (Shared)
+		{
+		  pFilterSpecData->pEffectiveFlow->MustBeProcessed = 1;
+		}
+	    }
+
+	  if (pFilterSpecData->pPsb->InIfIndex != 0)
+	    {
+	      if (GeneratePathErrMessage
+		  (pFilterSpecData->pPsb, POLICY_CTRL_FAILURE_ERR_CODE,
+		   0) != E_OK)
+		{
+		  zlog_err ("Cannot encode/send PathErr message %s %d",
+			    __FILE__, __LINE__);
+		}
+	      pFilterSpecData->pPHopResvRefreshList->MustBeProcessed = 1;
+	    }
+
+	  if (pMsg->u.PreemptFlow.FilterSpecValid)
+	    {
+	      if (pFilterListPrev == NULL)
+		{
+		  pRsb->OldPacket.pFilterList =
+		    pRsb->OldPacket.pFilterList->next;
+		}
+	      else
+		{
+		  pFilterListPrev->next = pFilterList->next;
+		}
+	      pFilterList->next = pFilterList2BeDeleted;
+	      pFilterList2BeDeleted = pFilterList;
+	      break;
+	    }
+	}
+      pFilterListPrev = pFilterList;
+      pFilterList = pFilterList->next;
+    }
+  memset (&RsvpPkt, 0, sizeof (RSVP_PKT));
+  RsvpPkt.Session = RsbKey.Session;
+  RsvpPkt.Style = pRsb->OldPacket.Style;
+  pIfListEntry = pIfList;
+  while (pIfListEntry != NULL)
+    {
+      RsvpPkt.pFilterList = pIfListEntry->pFilterList;
+      if (EncodeAndSendRsvpResvErrMessage (&RsvpPkt,
+					   pIfListEntry->NHop,
+					   pIfListEntry->IfIndex,
+					   pIfListEntry->ttl) != E_OK)
+	{
+	  zlog_err ("Cannot encode/send ResvErr message %s %d", __FILE__,
+		    __LINE__);
+	}
+      pIfListEntry = pIfListEntry->next;
+    }
+  pIfListEntry = pIfList;
+  while (pIfListEntry != NULL)
+    {
+      pFilterListPrev = pIfListEntry->pFilterList;
+      while (pFilterListPrev != NULL)
+	{
+	  pFilterList = pFilterListPrev->next;
+	  XFREE (MTYPE_RSVP, pFilterListPrev);
+	  pFilterListPrev = pFilterList;
+	}
+      pIfList = pIfListEntry->next;
+      XFREE (MTYPE_RSVP, pIfListEntry);
+      pIfListEntry = pIfList;
+    }
+  pFilterListPrev = pFilterList2BeDeleted;
+  while (pFilterListPrev != NULL)
+    {
+      pFilterList = pFilterListPrev->next;
+      pFilterSpecData = pFilterListPrev->pFilterSpecData;
+      pPsb = pFilterSpecData->pPsb;
+      if (FilterShutDown (pFilterSpecData, Shared) != E_OK)
+	{
+	  zlog_err ("An error in FilterShutDown %s %d", __FILE__, __LINE__);
+	}
+      if (DeletePsb (pPsb) != E_OK)
+	{
+	  zlog_err ("Cannot delete PSB %s %d", __FILE__, __LINE__);
+	}
+      XFREE (MTYPE_RSVP, pFilterListPrev);
+      pFilterListPrev = pFilterList;
+    }
+
+  if (pRsb->OldPacket.pFilterList != NULL)
+    {
+      if (Shared)
+	{
+	  if (ProcessEffectiveFlows (pRsb) != E_OK)
+	    {
+	      zlog_err ("An error in ProcessEffectiveFlows %s %d", __FILE__,
+			__LINE__);
+	    }
+	}
+      /* update TE (BW release) */
+      if (ProcessPHopFilterSpecLists (pRsb, Shared) != E_OK)
+	{
+	  zlog_err ("An error in ProcessPHopFilterSpecLists %s %d", __FILE__,
+		    __LINE__);
+	}
+    }
+  else
+    {
+      FreeRSB (pRsb);
+    }
+  zlog_info ("leaving PreemptFlow");
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_rsb.h quagga-mpls/rsvpd/rsvp_rsb.h
--- quagga-0.99.10/rsvpd/rsvp_rsb.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_rsb.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,62 @@
+
+#ifndef __RSVP_RSB_H_
+#define __RSVP_RSB_H_
+
+typedef struct _phop_resv_refresh_list_
+{
+  RSVP_HOP_OBJ PHop;
+  uns32 InIfIndex;
+  uns32 RefreshValue;
+  struct thread *ResvRefreshTimer;
+  FILTER_LIST *pFilterList;
+  RR_SUBOBJ *pAddedRro;
+  FLOW_SPEC_OBJ FwdFlowSpec;	/* for SE only */
+  uns8 MustBeProcessed;
+  char *pSentBuffer;
+  uns16 SentBufferLen;
+  struct _phop_resv_refresh_list_ *next;
+} PHOP_RESV_REFRESH_LIST;
+
+typedef struct _effective_flow_
+{
+  uns32 IfIndex;
+  FLOW_SPEC_OBJ CurrentFlowSpec;
+  uns8 MustBeProcessed;		/* indicates that list of corresponding filters was changed */
+  FLOW_SPEC_OBJ NewFlowSpec;
+  FILTER_LIST *pFilterList;
+  uns8 TE_InProcess;
+  struct _effective_flow_ *next;
+} EFFECTIVE_FLOW;
+
+typedef struct _rsb_
+{
+  PATRICIA_NODE Node;
+  RSB_KEY RsbKey;
+  RSVP_PKT OldPacket;
+  uns8 ResvRefreshFlag;
+  PHOP_RESV_REFRESH_LIST *pPHopResvRefreshList;
+  EFFECTIVE_FLOW *pEffectiveFlow;	/* for SE only */
+} RSB;
+
+struct _te_api_msg_;
+
+RSB *FindRsb (RSB_KEY * pRsbKey);
+RSB *GetNextRSB (RSB_KEY * pRsbKey);
+E_RC ProcessEffectiveFlows (RSB * pRsb);
+E_RC ProcessPHopFilterSpecLists (RSB * pRsb, uns8 Shared);
+E_RC FilterShutDown (FILTER_SPEC_DATA * pFilterSpecData, int Shared);
+E_RC ProcessRsvpResvTearMessage (RSVP_PKT * pRsvpPkt);
+E_RC ProcessRsvpResvErrMessage (RSVP_PKT * pRsvpPkt);
+E_RC ProcessRsvpResvMessage (RSVP_PKT * pRsvpPkt);
+E_RC NewFilterListNode (FILTER_LIST ** ppFilterListHead,
+			FILTER_SPEC_DATA * pFilterSpecData);
+E_RC ForwardResvTearMsg (RSB * pRsb);
+E_RC NewModifiedPath (PSB * pPsb);
+E_RC InitResvProcessing ();
+E_RC ResvTeMsgProc (struct _te_api_msg_ *pMsg);
+void PreemptFlow (struct _te_api_msg_ *pMsg);
+E_RC RemoveRSB (RSB_KEY * pRsbKey);
+E_RC DeleteFilterListNode (FILTER_LIST ** ppFilterList,
+			   FILTER_SPEC_DATA * pFilterSpecData);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvp_socket.c quagga-mpls/rsvpd/rsvp_socket.c
--- quagga-0.99.10/rsvpd/rsvp_socket.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_socket.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,429 @@
+/* Module:   rsvp_socket.c
+   Contains: RSVP socket routines
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "rsvp.h"
+#include "if.h"
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  uns32 IfIndex;
+  int IfSocket;
+  IPV4_ADDR IpAddr;
+  IPV4_ADDR Peer;
+  char IfName[20];
+  struct thread *pThread;
+} IF_NODE;
+
+PATRICIA_TREE IfTree;
+
+char BigBuf[1024];
+
+extern struct thread_master *master;
+
+
+E_RC
+IpAddrGetByIfIndex (uns32 IfIndex, IPV4_ADDR * pIpAddr)
+{
+  IF_NODE *pIfNode;
+
+  if ((pIfNode =
+       (IF_NODE *) patricia_tree_get (&IfTree,
+				      (const uns8 *) &IfIndex)) == NULL)
+    {
+      zlog_err ("cannot get a node from patricia tree %s %d", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  *pIpAddr = pIfNode->IpAddr;
+  return E_OK;
+}
+
+E_RC
+IpAddrSetByIfIndex (uns32 IfIndex, IPV4_ADDR IpAddr)
+{
+  IF_NODE *pIfNode;
+
+  if ((pIfNode =
+       (IF_NODE *) patricia_tree_get (&IfTree,
+				      (const uns8 *) &IfIndex)) == NULL)
+    {
+      if ((pIfNode =
+	   (IF_NODE *) XMALLOC (MTYPE_RSVP, sizeof (IF_NODE))) == NULL)
+	{
+	  zlog_err ("cannot allocate memory %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      memset (pIfNode, 0, sizeof (IF_NODE));
+      pIfNode->IfIndex = IfIndex;
+      pIfNode->Node.key_info = (uns8 *) & pIfNode->IfIndex;
+      if (patricia_tree_add (&IfTree, (PATRICIA_NODE *) & pIfNode->Node) !=
+	  E_OK)
+	{
+	  zlog_err ("cannot add node to patricia");
+	  return E_ERR;
+	}
+    }
+  pIfNode->IpAddr = IpAddr;
+  return E_OK;
+}
+
+E_RC
+InitInterfaceDB ()
+{
+  PATRICIA_PARAMS params;
+
+  memset (&params, 0, sizeof (PATRICIA_PARAMS));
+  params.key_size = sizeof (uns32);
+  if (patricia_tree_init (&IfTree, &params) != E_OK)
+    {
+      zlog_err ("cannot initiate I/F patricia tree");
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+E_RC
+SetRouterAlert (int sock)
+{
+#if defined(IPOPT_RA)
+  static const char ra_opt[4] = { IPOPT_RA, 4, 0, 0 };
+
+
+  if (setsockopt (sock, IPPROTO_IP, IP_OPTIONS, ra_opt, sizeof (ra_opt)))
+    {
+      zlog_err ("Cannot set router alert %s %s %d", strerror (errno),
+		__FILE__, __LINE__);
+      return E_ERR;
+    }
+#endif /* defined(IPOPT_RA) */
+  return E_OK;
+}
+
+E_RC
+SetTtl (int sock, uns16 ttl)
+{
+  uns16 multicast = (uns16) (ttl & 0x8000);	/* most significant bit indicates multicast */
+  int set_ttl = (int) (ttl & 0x00FF);
+
+  /* specify the ttl value for subsequent datagrams sent out on this socket */
+
+#ifdef IP_TTL
+  {
+    if (multicast == 0)
+      if (setsockopt
+	  (sock, IPPROTO_IP, IP_TTL, (char *) &set_ttl,
+	   sizeof (set_ttl)) != 0)
+	{
+	  zlog_err ("Cannot set ttl %s %s %d", strerror (errno), __FILE__,
+		    __LINE__);
+	  return E_ERR;
+	}
+  }
+#endif
+
+
+  /* specify the ttl for multicast messages sent out on this socket */
+
+#ifdef IP_MULTICAST_TTL
+  {
+    if (multicast == 0x8000)
+      if (setsockopt
+	  (sock, IPPROTO_IP, IP_MULTICAST_TTL, (char *) &set_ttl,
+	   sizeof (set_ttl)) != 0)
+	{
+	  zlog_err ("Cannot set ttl %s %s %d", strerror (errno), __FILE__,
+		    __LINE__);
+	  return E_ERR;
+	}
+  }
+#endif
+
+  return E_OK;
+}
+
+E_RC
+SendRawData (char *buffer, uns32 Len, IPV4_ADDR remote_addr, uns32 IfIndex,
+	     uns8 ttl, uns8 RouterAlert)
+{
+  struct sockaddr_in saddr;
+  int bytes_sent;
+  IF_NODE *pIfNode;
+  zlog_info ("entering SendRawData");
+  if ((pIfNode =
+       (IF_NODE *) patricia_tree_get (&IfTree,
+				      (const uns8 *) &IfIndex)) == NULL)
+    {
+      zlog_err ("Cannot get node from patricia tree, IfIndex %d %s %d",
+		IfIndex, __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  memset ((char *) &saddr, 0x00, sizeof (saddr));
+  saddr.sin_family = AF_INET;
+  saddr.sin_addr.s_addr = remote_addr;
+
+
+  if (SetTtl (pIfNode->IfSocket, ttl) != E_OK)
+    {
+      zlog_err ("Cannot set ttl");
+    }
+
+  if (RouterAlert == TRUE)
+    {
+      if (SetRouterAlert (pIfNode->IfSocket) != E_OK)
+	{
+	  zlog_err ("Cannot set router alert");
+	}
+    }
+
+  bytes_sent =
+    sendto (pIfNode->IfSocket, buffer, Len, 0, (struct sockaddr *) &saddr,
+	    sizeof (saddr));
+  if (bytes_sent == -1)
+    {
+      zlog_err ("an error occured on sendto %s", strerror (errno));
+      return E_ERR;
+    }
+  else if (bytes_sent < Len)
+    {
+      zlog_err ("tried to send %d bytes, actually sent %d", Len, bytes_sent);
+      return E_ERR;
+    }
+  zlog_info ("leaving SendRawData");
+  return E_OK;
+}
+
+int
+ProcessRsvpMsg (struct thread *pThread)
+{
+  int FromLen, PktLen;
+  IF_NODE *pIfNode;
+  struct sockaddr_in from;
+  uns8 *pIpHdr;
+
+  pIfNode = pThread->arg;
+
+  memset (&from, 0, sizeof (struct sockaddr_in));
+  FromLen = sizeof (struct sockaddr_in);
+  from.sin_family = AF_INET;
+
+  if (ioctl (pIfNode->IfSocket, FIONREAD, &PktLen) < 0)
+    {
+      zlog_err (" an error %s on ioctl %s %d", strerror (errno), __FILE__,
+		__LINE__);
+    }
+  zlog_info ("message received on %d %s", pIfNode->IfIndex, pIfNode->IfName);
+  memset (BigBuf, 0, 1000);
+  if ((PktLen =
+       recvfrom (pIfNode->IfSocket, BigBuf, 1000, 0,
+		 (struct sockaddr *) &from, &FromLen)) < 0)
+    {
+      zlog_err ("an error occured on recvfrom %s %s",
+		pIfNode->IfName, strerror (errno));
+    }
+  else
+    {
+      zlog_info ("From %x", from.sin_addr.s_addr);
+      pIpHdr = BigBuf;
+      PktLen -= (unsigned int) 4 *(*pIpHdr & 0xf);
+      DecodeAndProcessRsvpMsg (&BigBuf[(unsigned int) 4 * (*pIpHdr & 0xf)],
+			       PktLen, pIfNode->IfIndex, 0);
+    }
+  pIfNode->pThread =
+    thread_add_read (master, ProcessRsvpMsg, pIfNode, pIfNode->IfSocket);
+  return 0;
+}
+
+E_RC
+IsRsvpEnabledOnIf (int IfIndex)
+{
+  IF_NODE *pIfNode;
+
+  if ((pIfNode =
+       (IF_NODE *) patricia_tree_get (&IfTree,
+				      (const uns8 *) &IfIndex)) == NULL)
+    {
+      zlog_err ("Cannot get node from patricia tree, IfIndex %d %s %d",
+		IfIndex, __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if (pIfNode->IfSocket)
+    {
+      return E_OK;
+    }
+  return E_ERR;
+}
+
+E_RC
+EnableRsvpOnInterface2 (int IfIndex)
+{
+  struct sockaddr_in saddr;
+  IF_NODE *pIfNode;
+
+  if ((pIfNode =
+       (IF_NODE *) patricia_tree_get (&IfTree,
+				      (const uns8 *) &IfIndex)) == NULL)
+    {
+      zlog_err ("cannot get a node from patricia");
+      return E_ERR;
+    }
+
+  memset (&saddr, 0x00, sizeof (saddr));
+  saddr.sin_family = AF_INET;
+  /*saddr.sin_port        = htons(0); */
+  saddr.sin_addr.s_addr = htonl (pIfNode->IpAddr);
+  if (bind
+      (pIfNode->IfSocket, (struct sockaddr *) &saddr,
+       sizeof (struct sockaddr_in)) < 0)
+    {
+      zlog_err ("cannot bind socket (%s) for %s %s %d",
+		strerror (errno), pIfNode->IfName, __FILE__, __LINE__);
+      return E_ERR;
+    }
+  {
+    char str1[16];
+    sprintf (str1, "%x", pIfNode->IpAddr);
+    zlog_info ("Upon enabling RSVP on I/F %s %s %d",
+	       pIfNode->IfName, str1, pIfNode->IfSocket);
+  }
+  if (pIfNode->pThread == NULL)
+    pIfNode->pThread =
+      thread_add_read (master, ProcessRsvpMsg, pIfNode, pIfNode->IfSocket);
+  return E_OK;
+}
+
+E_RC
+EnableRsvpOnInterface (uns32 IfIndex)
+{
+  static const unsigned int bio = 1;
+  static const int smode = 1;
+  IF_NODE *pIfNode;
+  struct interface *ifp = NULL;
+
+  int sock = socket (AF_INET, SOCK_RAW, RSVP_IP_PROTOCOL);
+
+  if ((pIfNode =
+       (IF_NODE *) patricia_tree_get (&IfTree,
+				      (const uns8 *) &IfIndex)) == NULL)
+    {
+      if ((pIfNode =
+	   (IF_NODE *) XMALLOC (MTYPE_RSVP, sizeof (IF_NODE))) == NULL)
+	{
+	  zlog_err ("cannot allocate memory %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      memset (pIfNode, 0, sizeof (IF_NODE));
+      pIfNode->IfIndex = IfIndex;
+      pIfNode->Node.key_info = (uns8 *) & pIfNode->IfIndex;
+      if (patricia_tree_add (&IfTree, (PATRICIA_NODE *) & pIfNode->Node) !=
+	  E_OK)
+	{
+	  zlog_err ("cannot add node to patricia");
+	  return E_ERR;
+	}
+    }
+
+  if (sock < 0)
+    {
+      zlog_err ("cannot open socket %s %s %d", strerror (errno), __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+
+  if (ioctl (sock, FIONBIO, &bio) < 0)
+    {
+      zlog_err ("cannot set non blocking mode for I/F %d %s %d", IfIndex,
+		__FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if (setsockopt
+      (sock, SOL_SOCKET, SO_REUSEADDR, (char *) &smode, sizeof (smode)))
+    {
+      zlog_err ("cannot set reuse address option for I/F %d %s %d", IfIndex,
+		__FILE__, __LINE__);
+      return E_ERR;
+    }
+  ifp = if_lookup_by_index (IfIndex);
+  strncpy (pIfNode->IfName, ifp->name, INTERFACE_NAMSIZ);
+#if 1
+  {
+	/** Build a ifreq to get mapping of device index to name,
+         ** since the  bind to device sockopt operates on name.
+         **/
+    struct ifreq ifr;
+    memset (&ifr, '\0', sizeof ifr);
+
+    strcpy (ifr.ifr_name, pIfNode->IfName);
+
+    if (setsockopt
+	(sock, SOL_SOCKET, SO_BINDTODEVICE, ifr.ifr_name, IFNAMSIZ))
+      {
+	zlog_err ("cannot set bind to device option for %s %s %d",
+		  pIfNode->IfName, __FILE__, __LINE__);
+	return E_ERR;
+      }
+  }
+#endif
+#if 0
+  {
+    int ra = 0, Len = sizeof (ra);
+    static const int ra_true = 1;
+    if (setsockopt
+	(sock, /*IPPROTO_IP */ SOL_SOCKET, IP_ROUTER_ALERT, &ra_true,
+	 sizeof (ra_true)) != 0)
+      {
+	zlog_err ("cannot set router alert option for %s %s %d", IfName,
+		  __FILE__, __LINE__);
+	return E_ERR;
+      }
+    if (getsockopt (sock, SOL_SOCKET, IP_ROUTER_ALERT, &ra, &Len) != 0)
+      {
+	zlog_err ("cannot get router alert option for %s error %s %s %d",
+		  IfName, strerror (errno), __FILE__, __LINE__);
+	return E_ERR;
+      }
+    else
+      {
+	printf ("ROUTER ALERT %x\n", ra);
+      }
+  }
+#endif
+
+  pIfNode->IfSocket = sock;
+  if (pIfNode->IpAddr != 0)
+    {
+      return EnableRsvpOnInterface2 (IfIndex);
+    }
+  else
+    {
+      return E_OK;
+    }
+}
+
+E_RC
+DisableRsvpOnInterface (int IfIndex)
+{
+  IF_NODE *pIfNode;
+
+  if ((pIfNode =
+       (IF_NODE *) patricia_tree_get (&IfTree,
+				      (const uns8 *) &IfIndex)) == NULL)
+    {
+      zlog_err ("cannot get a node from patricia");
+      return E_ERR;
+    }
+  if (pIfNode->pThread)
+    thread_cancel (pIfNode->pThread);
+  pIfNode->pThread = NULL;
+  close (pIfNode->IfSocket);
+  if (patricia_tree_del (&IfTree, (PATRICIA_NODE *) & pIfNode->Node) != E_OK)
+    {
+      zlog_err ("cannot del node from patricia");
+      return E_ERR;
+    }
+  XFREE (MTYPE_RSVP, pIfNode);
+  return E_OK;
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_socket.h quagga-mpls/rsvpd/rsvp_socket.h
--- quagga-0.99.10/rsvpd/rsvp_socket.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_socket.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,17 @@
+
+#ifndef __RSVP_SOCKET_H_
+#define __RSVP_SOCKET_H_
+
+E_RC EnableRsvpOnInterface (uns32 IfIndex);
+E_RC EnableRsvpOnInterface2 (int IfIndex);
+E_RC DisableRsvpOnInterface (int IfIndex);
+int ProcessRsvpMsg (struct thread *pThread);
+E_RC IpAddrGetByIfIndex (uns32 IfIndex, IPV4_ADDR * pIpAddr);
+E_RC IpAddrSetByIfIndex (uns32 IfIndex, IPV4_ADDR IpAddr);
+E_RC IsRsvpEnabledOnIf (int IfIndex);
+E_RC SendRawData (char *buffer,
+		  uns32 Len,
+		  IPV4_ADDR remote_addr,
+		  uns32 IfIndex, uns8 ttl, uns8 RouterAlert);
+E_RC InitInterfaceDB ();
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvp_utilities.c quagga-mpls/rsvpd/rsvp_utilities.c
--- quagga-0.99.10/rsvpd/rsvp_utilities.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_utilities.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,985 @@
+/* Module:   rsvp_utilities.c
+   Contains: RSVP utilities - object allocation and freeing,
+   dump etc.
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "rsvp.h"
+
+
+#define LOG1(a1) \
+{\
+   if(vty) \
+   {\
+       vty_out(vty,a1);\
+       vty_out(vty,"%s",VTY_NEWLINE);\
+   }\
+   else \
+   {\
+       zlog_info(a1);\
+   }\
+}
+
+#define LOG2(a1,a2) \
+{\
+   if(vty) \
+   {\
+       vty_out(vty,a1,a2);\
+       vty_out(vty,"%s",VTY_NEWLINE);\
+   }\
+   else \
+   {\
+       zlog_info(a1,a2);\
+   }\
+}
+
+#define LOG3(a1,a2,a3) \
+{\
+   if(vty) \
+   {\
+       vty_out(vty,a1,a2,a3);\
+       vty_out(vty,"%s",VTY_NEWLINE);\
+   }\
+   else \
+   {\
+       zlog_info(a1,a2,a3);\
+   }\
+}
+
+#define LOG4(a1,a2,a3,a4) \
+{\
+   if(vty) \
+   {\
+       vty_out(vty,a1,a2,a3,a4);\
+       vty_out(vty,"%s",VTY_NEWLINE);\
+   }\
+   else \
+   {\
+       zlog_info(a1,a2,a3,a4);\
+   }\
+}
+
+#define LOG5(a1,a2,a3,a4,a5) \
+{\
+   if(vty) \
+   {\
+       vty_out(vty,a1,a2,a3,a4,a5);\
+       vty_out(vty,"%s",VTY_NEWLINE);\
+   }\
+   else \
+   {\
+       zlog_info(a1,a2,a3,a4,a5);\
+   }\
+}
+
+#define LOG6(a1,a2,a3,a4,a5,a6) \
+{\
+   if(vty) \
+   {\
+       vty_out(vty,a1,a2,a3,a4,a5,a6);\
+       vty_out(vty,"%s",VTY_NEWLINE);\
+   }\
+   else \
+   {\
+       zlog_info(a1,a2,a3,a4,a5,a6);\
+   }\
+}
+
+#define LOG7(a1,a2,a3,a4,a5,a6,a7) \
+{\
+   if(vty) \
+   {\
+       vty_out(vty,a1,a2,a3,a4,a5,a6,a7);\
+       vty_out(vty,"%s",VTY_NEWLINE);\
+   }\
+   else \
+   {\
+       zlog_info(a1,a2,a3,a4,a5,a6,a7);\
+   }\
+}
+
+#define LOG8(a1,a2,a3,a4,a5,a6,a7,a8) \
+{\
+   if(vty) \
+   {\
+       vty_out(vty,a1,a2,a3,a4,a5,a6,a7,a8);\
+       vty_out(vty,"%s",VTY_NEWLINE);\
+   }\
+   else \
+   {\
+       zlog_info(a1,a2,a3,a4,a5,a6,a7,a8);\
+   }\
+}
+
+RSVP_STATISTICS RsvpStatistics = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  IPV4_ADDR IfIpAddress;
+  uns8 PrefixLen;
+} IF_IP_NODE;
+
+static PATRICIA_TREE IfIpAddressesTree;
+
+E_RC
+IfIpAdd (IPV4_ADDR IfIpAddress, uns8 PrefixLen)
+{
+  IF_IP_NODE *pIfIpNode;
+
+  if ((pIfIpNode =
+       (IF_IP_NODE *) XMALLOC (MTYPE_RSVP, sizeof (IF_IP_NODE))) == NULL)
+    {
+      zlog_err ("cannot allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  memset (pIfIpNode, 0, sizeof (IF_IP_NODE));
+  pIfIpNode->IfIpAddress = IfIpAddress;
+  pIfIpNode->PrefixLen = PrefixLen;
+  pIfIpNode->Node.key_info = (uns8 *) & pIfIpNode->IfIpAddress;
+  if (patricia_tree_add (&IfIpAddressesTree, &pIfIpNode->Node) != E_OK)
+    {
+      zlog_err ("cannot add node to patricia");
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+E_RC
+IfIpAddrDel (IPV4_ADDR IfIpAddress, uns8 PrefixLen)
+{
+  IF_IP_NODE *pIfIpNode;
+
+  if ((pIfIpNode =
+       (IF_IP_NODE *) patricia_tree_get (&IfIpAddressesTree,
+					 (const uns8 *) &IfIpAddress)) !=
+      NULL)
+    {
+      if (patricia_tree_del (&IfIpAddressesTree, &pIfIpNode->Node) != E_OK)
+	{
+	  zlog_err ("Cannot delete from patricia %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      return E_OK;
+    }
+  zlog_err ("IfIp entry is not found %s %d", __FILE__, __LINE__);
+  return E_ERR;
+}
+
+IPV4_ADDR
+GetRouterId ()
+{
+  IPV4_ADDR key = 0, SelectedIpAddr = 0;
+  IF_IP_NODE *pIfIpNode;
+
+  while ((pIfIpNode =
+	  (IF_IP_NODE *) patricia_tree_getnext (&IfIpAddressesTree,
+						(const uns8 *) &key)) != NULL)
+    {
+      if (pIfIpNode->IfIpAddress > SelectedIpAddr)
+	{
+	  SelectedIpAddr = pIfIpNode->IfIpAddress;
+	}
+      key = pIfIpNode->IfIpAddress;
+    }
+  return SelectedIpAddr;
+}
+
+uns8
+IsAbstractNode (IPV4_ADDR IpAddress, uns8 PrefixLen)
+{
+  IF_IP_NODE *pIfIpNode;
+  if (PrefixLen > 32)
+    {
+      zlog_warn ("PrefixLen is %d. Forcing to 32", PrefixLen);
+      PrefixLen = 32;
+    }
+  if ((pIfIpNode =
+       (IF_IP_NODE *) patricia_tree_get (&IfIpAddressesTree,
+					 (const uns8 *) &IpAddress)) == NULL)
+    {
+      return FALSE;
+    }
+  return TRUE;
+}
+
+E_RC
+InitInterfaceIpAdressesDB ()
+{
+  PATRICIA_PARAMS params;
+
+  memset (&params, 0, sizeof (PATRICIA_PARAMS));
+  params.key_size = sizeof (IPV4_ADDR);
+  if (patricia_tree_init (&IfIpAddressesTree, &params) != E_OK)
+    {
+      zlog_err ("cannot initiate I/F patricia tree");
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+E_RC
+CheckRRO4Loop (RR_SUBOBJ * pRrSubObj)
+{
+  RR_SUBOBJ *pRrSub = pRrSubObj;
+
+  while (pRrSub != NULL)
+    {
+      if (pRrSub->SubObjHdr.Type == RRO_SUBTYPE_IPV4)
+	{
+	  if (IsAbstractNode (pRrSub->u.Ipv4.IpAddr, pRrSub->u.Ipv4.PrefixLen)
+	      == TRUE)
+	    {
+	      return E_ERR;
+	    }
+	}
+      pRrSub = pRrSub->next;
+    }
+  return E_OK;
+}
+
+void
+FreeRRO (RR_OBJ * pRrObj)
+{
+  RR_SUBOBJ *pRrSubObj, *pRrSubObjNext;
+
+  pRrSubObj = pRrObj->rr;
+  while (pRrSubObj != NULL)
+    {
+      pRrSubObjNext = pRrSubObj->next;
+      XFREE (MTYPE_RSVP, pRrSubObj);
+      pRrSubObj = pRrSubObjNext;
+    }
+  pRrObj->rr = NULL;
+}
+
+void
+FreeERO (ER_OBJ * pErObj)
+{
+  ER_SUBOBJ *pErSubObj, *pErSubObjNext;
+
+  pErSubObj = pErObj->er;
+  while (pErSubObj != NULL)
+    {
+      pErSubObjNext = pErSubObj->next;
+      XFREE (MTYPE_RSVP, pErSubObj);
+      pErSubObj = pErSubObjNext;
+    }
+  pErObj->er = NULL;
+}
+
+void
+FreeSessionAttributes (SESSION_ATTRIBUTES_OBJ * pSessAttr)
+{
+  if (pSessAttr->CType == SESSION_ATTRIBUTES_RA_IPV4_CTYPE)
+    {
+      if (pSessAttr->u.SessAttrRa.SessionName != NULL)
+	{
+	  XFREE (MTYPE_RSVP, pSessAttr->u.SessAttrRa.SessionName);
+	}
+    }
+  else if (pSessAttr->CType == SESSION_ATTRIBUTES_IPV4_CTYPE)
+    {
+      if (pSessAttr->u.SessAttr.SessionName != NULL)
+	{
+	  XFREE (MTYPE_RSVP, pSessAttr->u.SessAttr.SessionName);
+	}
+    }
+}
+
+void
+FreeOpaqueObj (OPAQUE_OBJ_LIST * pOpaqueObjListHead)
+{
+  OPAQUE_OBJ_LIST *pOpaqueObjList = pOpaqueObjListHead, *pOpaqueObjListNext;
+
+  while (pOpaqueObjList != NULL)
+    {
+      pOpaqueObjListNext = pOpaqueObjList->next;
+      if (pOpaqueObjList->pData)
+	XFREE (MTYPE_RSVP, pOpaqueObjList->pData);
+      XFREE (MTYPE_RSVP, pOpaqueObjList);
+      pOpaqueObjList = pOpaqueObjListNext;
+    }
+}
+
+void
+FreeFilterSpecData (FILTER_SPEC_DATA ** ppFilterSpecData)
+{
+  FILTER_SPEC_DATA *pFilterSpecData = *ppFilterSpecData;
+  zlog_info ("entering FreeFilterSpecData");
+  FreeRRO (&pFilterSpecData->Rro);
+  XFREE (MTYPE_RSVP, *ppFilterSpecData);
+  *ppFilterSpecData = NULL;
+  zlog_info ("leaving FreeFilterSpecData");
+}
+
+void
+FreeRsvpPkt (RSVP_PKT * pRsvpPkt)
+{
+  FILTER_LIST *pFilterList, *pFilterList2;
+  zlog_info ("entering FreeRsvpPkt");
+  FreeRRO (&pRsvpPkt->AddedRro);
+  FreeRRO (&pRsvpPkt->ReceivedRro);
+  FreeERO (&pRsvpPkt->ReceivedEro);
+  FreeERO (&pRsvpPkt->SentEro);
+  FreeSessionAttributes (&pRsvpPkt->SessionAttributes);
+  FreeOpaqueObj (pRsvpPkt->pIntegrityObj);
+  FreeOpaqueObj (pRsvpPkt->pPolicyDataObj);
+  FreeOpaqueObj (pRsvpPkt->pOpaqueObjList);
+  pFilterList = pRsvpPkt->pFilterList;
+  while (pFilterList != NULL)
+    {
+      FILTER_SPEC_DATA *pFilterSpecData = pFilterList->pFilterSpecData;
+      pFilterList2 = pFilterList->next;
+      if (DeleteFilterListNode (&pRsvpPkt->pFilterList,
+				pFilterSpecData) != E_OK)
+	{
+	  zlog_err ("cannot delete filter list node %s %d", __FILE__,
+		    __LINE__);
+	}
+      FreeFilterSpecData (&pFilterSpecData);
+      pFilterList = pFilterList2;
+    }
+  XFREE (MTYPE_RSVP, pRsvpPkt);
+  zlog_info ("leaving FreeRsvpPkt");
+}
+
+E_RC
+EnqueueRsvpPacket (RSVP_PKT_QUEUE * pItem, RSVP_PKT_QUEUE ** ppQueueHead)
+{
+  RSVP_PKT_QUEUE *pQueue;
+  zlog_info ("entering EnqueueRsvpPacket");
+
+  if ((*ppQueueHead) == NULL)
+    {
+      (*ppQueueHead) = pItem;
+      zlog_info ("leaving EnqueueRsvpPacket");
+      return E_OK;
+    }
+  pQueue = (*ppQueueHead);
+  while (pQueue->next != NULL)
+    pQueue = pQueue->next;
+  pQueue->next = pItem;
+  zlog_info ("leaving EnqueueRsvpPacket");
+  return E_OK;
+}
+
+RSVP_PKT_QUEUE *
+DequeueRsvpPacket (RSVP_PKT_QUEUE ** ppQueueHead)
+{
+  RSVP_PKT_QUEUE *pTemp;
+  zlog_info ("entering DequeueRsvpPacket");
+  if ((*ppQueueHead) == NULL)
+    {
+      return NULL;
+    }
+  pTemp = (*ppQueueHead);
+  (*ppQueueHead) = (*ppQueueHead)->next;
+  zlog_info ("leaving DequeueRsvpPacket");
+  return pTemp;
+}
+
+void
+FreePSB (PSB * pPsb)
+{
+  RSVP_PKT_QUEUE *pQueueItem;
+  zlog_info ("entering FreePSB");
+  if (pPsb->pSentBuffer)
+    {
+      XFREE (MTYPE_RSVP, pPsb->pSentBuffer);
+      pPsb->pSentBuffer = NULL;
+    }
+  if (RemovePsb (&pPsb->PsbKey) == E_OK)
+    {
+      if (pPsb->OldPacket.SessionAttributes.CType ==
+	  SESSION_ATTRIBUTES_CLASS_TYPE)
+	{
+	  if (pPsb->OldPacket.SessionAttributes.u.SessAttr.SessionName !=
+	      NULL)
+	    {
+	      XFREE (MTYPE_RSVP,
+		     pPsb->OldPacket.SessionAttributes.u.SessAttr.
+		     SessionName);
+	    }
+	}
+      else if (pPsb->OldPacket.SessionAttributes.CType ==
+	       SESSION_ATTRIBUTES_RA_CLASS_TYPE)
+	{
+	  if (pPsb->OldPacket.SessionAttributes.u.SessAttrRa.SessionName !=
+	      NULL)
+	    {
+	      XFREE (MTYPE_RSVP,
+		     pPsb->OldPacket.SessionAttributes.u.SessAttrRa.
+		     SessionName);
+	    }
+	}
+      FreeRRO (&pPsb->OldPacket.AddedRro);
+      FreeRRO (&pPsb->OldPacket.ReceivedRro);
+      FreeERO (&pPsb->OldPacket.ReceivedEro);
+      FreeERO (&pPsb->OldPacket.SentEro);
+      FreeOpaqueObj (pPsb->OldPacket.pIntegrityObj);
+      FreeOpaqueObj (pPsb->OldPacket.pPolicyDataObj);
+      FreeOpaqueObj (pPsb->OldPacket.pOpaqueObjList);
+      while ((pQueueItem = DequeueRsvpPacket (&pPsb->packet_queue)) != NULL)
+	{
+	  FreeRsvpPkt (pQueueItem->pRsvpPkt);
+	}
+      XFREE (MTYPE_RSVP, pPsb);
+    }
+  else
+    {
+      zlog_err ("Freeing os PSB was not completed");
+    }
+  RsvpStatistics.DeletePsbCount++;
+  zlog_info ("leaving FreePSB");
+}
+
+void
+FreeRSB (RSB * pRsb)
+{
+  zlog_info ("entering FreeRSB");
+  if (RemoveRSB (&pRsb->RsbKey) == E_OK)
+    {
+      FreeOpaqueObj (pRsb->OldPacket.pIntegrityObj);
+      FreeOpaqueObj (pRsb->OldPacket.pPolicyDataObj);
+      FreeOpaqueObj (pRsb->OldPacket.pOpaqueObjList);
+      XFREE (MTYPE_RSVP, pRsb);
+    }
+  else
+    {
+      zlog_err ("Cannot free RSB");
+    }
+  RsvpStatistics.DeleteRsbCount++;
+  zlog_info ("leaving FreeRSB");
+}
+
+E_RC
+InsertERO (ER_OBJ * pEro, ER_HOP * Path, uns16 HopNum)
+{
+  int i;
+  ER_SUBOBJ *pErSubObjTail = pEro->er, *pErSubObjNew;
+
+  if (pErSubObjTail != NULL)
+    {
+      while (pErSubObjTail->next != NULL)
+	{
+	  pErSubObjTail = pErSubObjTail->next;
+	}
+    }
+  for (i = 0; i < HopNum; i++)
+    {
+      pErSubObjNew = (ER_SUBOBJ *) XMALLOC (MTYPE_RSVP, sizeof (ER_SUBOBJ));
+      if (pErSubObjNew == NULL)
+	{
+	  zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      if (pErSubObjTail == NULL)
+	{
+	  pEro->er = pErSubObjNew;
+	  pErSubObjTail = pErSubObjNew;
+	}
+      else
+	{
+	  pErSubObjTail->next = pErSubObjNew;
+	  pErSubObjTail = pErSubObjTail->next;
+	}
+      memset (pErSubObjTail, 0, sizeof (ER_SUBOBJ));
+      pErSubObjTail->SubObjHdr.LType = ERO_SUBTYPE_IPV4;
+      pErSubObjTail->SubObjHdr.Length = 8;
+      pErSubObjTail->u.Ipv4.IpAddress = Path[i].IpAddr;
+      pErSubObjTail->u.Ipv4.PrefixLength = Path[i].PrefixLength;
+      if (Path[i].Loose)
+	pErSubObjTail->SubObjHdr.LType |= 0x80;
+    }
+  return E_OK;
+}
+
+E_RC
+InsertRRO (RSVP_PKT * pRsvpPkt)
+{
+  RR_SUBOBJ *pRrSub = pRsvpPkt->AddedRro.rr, *pRrSubNew;
+
+  pRrSubNew = XMALLOC (MTYPE_RSVP, sizeof (RR_SUBOBJ));
+  if (!pRrSubNew)
+    {
+      return E_ERR;
+    }
+  pRrSubNew->SubObjHdr.Length = 8;
+  pRrSubNew->SubObjHdr.Type = RRO_SUBTYPE_IPV4;
+  pRrSubNew->u.Ipv4.Flags = 0;
+  pRrSubNew->u.Ipv4.IpAddr = GetRouterId ();
+  pRrSubNew->u.Ipv4.PrefixLen = 32;
+  if (pRrSub)
+    {
+      pRrSub = pRsvpPkt->AddedRro.rr;
+      while (pRrSub->next != NULL)
+	{
+	  pRrSub = pRrSub->next;
+	}
+      pRrSub->next = pRrSubNew;
+    }
+  else
+    {
+      pRsvpPkt->AddedRro.rr = pRrSubNew;
+    }
+  return E_OK;
+}
+
+void
+DumpSession (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  LOG4 ("SESSION: Dest %x Tunnel %x ExtTunnel %x",
+	pRsvpPkt->Session.Dest,
+	pRsvpPkt->Session.TunnelId, pRsvpPkt->Session.ExtTunelId);
+}
+
+void
+DumpSenderTemplate (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  LOG3 ("SENDER_TEMPLATE: SrcIp %x LSP %x",
+	pRsvpPkt->SenderTemplate.IpAddr, pRsvpPkt->SenderTemplate.LspId);
+}
+
+void
+DumpSenderTSPec (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  LOG6
+    ("SENDER_TSPEC: TockenBucketRate %f TockenBucketSize %f PeakDataRate %f MinPolicedUnit %x MaxPacketSize %x",
+     pRsvpPkt->SenderTSpec.TockenBucketRate,
+     pRsvpPkt->SenderTSpec.TockenBucketSize,
+     pRsvpPkt->SenderTSpec.PeakDataRate, pRsvpPkt->SenderTSpec.MinPolicedUnit,
+     pRsvpPkt->SenderTSpec.MaxPacketSize);
+}
+
+void
+DumpRsvpHop (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  RSVP_HOP_OBJ RsvpHop;
+  memset (&RsvpHop, 0, sizeof (RSVP_HOP_OBJ));
+  if (memcmp (&pRsvpPkt->SentRsvpHop, &RsvpHop, sizeof (RSVP_HOP_OBJ)) != 0)
+    {
+      LOG3 ("RSVP_HOP: IP %x LIH %x",
+	    pRsvpPkt->SentRsvpHop.PHop, pRsvpPkt->SentRsvpHop.LIH);
+    }
+  else
+    {
+      LOG3 ("RSVP_HOP: IP %x LIH %x",
+	    pRsvpPkt->ReceivedRsvpHop.PHop, pRsvpPkt->ReceivedRsvpHop.LIH);
+    }
+}
+
+void
+DumpSessionAttr (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  if (pRsvpPkt->SessionAttributes.CType == SESSION_ATTRIBUTES_RA_IPV4_CTYPE)
+    {
+      LOG1 ("SESSION_ATTRIBUTES with RA");
+      LOG4 ("%x %x %x",
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.ExcludeAny,
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAny,
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.IncludeAll);
+      LOG4 ("Flags: %x HoldPrio %x SetPrio %x",
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.Flags,
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.HoldPrio,
+	    pRsvpPkt->SessionAttributes.u.SessAttrRa.SetPrio);
+      if ((pRsvpPkt->SessionAttributes.u.SessAttrRa.NameLength != 0) &&
+	  (pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName != NULL))
+	{
+	  LOG2 ("SessionName %s",
+		pRsvpPkt->SessionAttributes.u.SessAttrRa.SessionName);
+	}
+    }
+  else if (pRsvpPkt->SessionAttributes.CType == SESSION_ATTRIBUTES_IPV4_CTYPE)
+    {
+      LOG1 ("SESSION_ATTRIBUTES w/o RA");
+      LOG4 ("Flags: %x HoldPrio %x SetPrio %x",
+	    pRsvpPkt->SessionAttributes.u.SessAttr.Flags,
+	    pRsvpPkt->SessionAttributes.u.SessAttr.HoldPrio,
+	    pRsvpPkt->SessionAttributes.u.SessAttr.SetPrio);
+      if ((pRsvpPkt->SessionAttributes.u.SessAttr.NameLength != 0) &&
+	  (pRsvpPkt->SessionAttributes.u.SessAttr.SessionName != NULL))
+	{
+	  LOG2 ("SessionName %s",
+		pRsvpPkt->SessionAttributes.u.SessAttr.SessionName);
+	}
+    }
+}
+
+void
+DumpTimeValues (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  LOG2 ("TIME_VALUES %x", pRsvpPkt->TimeValues.TimeValues);
+}
+
+void
+DumpAdSpec (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  LOG1 ("ADSPEC");
+  if (pRsvpPkt->SentAdSpec.CType != 0)
+    {
+      LOG5 ("ComposedMTU %x IS_HopCount %x MinPathLatency %x PathBW %f",
+	    pRsvpPkt->SentAdSpec.AdSpecGen.ComposedMTU,
+	    pRsvpPkt->SentAdSpec.AdSpecGen.IS_HopCount,
+	    pRsvpPkt->SentAdSpec.AdSpecGen.MinPathLatency,
+	    pRsvpPkt->SentAdSpec.AdSpecGen.PathBW);
+    }
+  else if (pRsvpPkt->ReceivedAdSpec.CType != 0)
+    {
+      LOG5 ("ComposedMTU %x IS_HopCount %x MinPathLatency %x PathBW %f",
+	    pRsvpPkt->ReceivedAdSpec.AdSpecGen.ComposedMTU,
+	    pRsvpPkt->ReceivedAdSpec.AdSpecGen.IS_HopCount,
+	    pRsvpPkt->ReceivedAdSpec.AdSpecGen.MinPathLatency,
+	    pRsvpPkt->ReceivedAdSpec.AdSpecGen.PathBW);
+    }
+}
+
+void
+DumpRRO (RR_SUBOBJ * pRrSubObj, struct vty *vty)
+{
+  LOG1 ("RRO");
+  while (pRrSubObj != NULL)
+    {
+      switch (pRrSubObj->SubObjHdr.Type)
+	{
+	case RRO_SUBTYPE_IPV4:
+	  LOG4 ("IP %x PrefixLen %x Flags %x",
+		pRrSubObj->u.Ipv4.IpAddr,
+		pRrSubObj->u.Ipv4.PrefixLen, pRrSubObj->u.Ipv4.Flags);
+	  break;
+	case RRO_SUBTYPE_LABEL:
+	  LOG3 ("LABEL %x Flags %x",
+		pRrSubObj->u.Label.Label, pRrSubObj->u.Label.Flags);
+	  break;
+	default:
+	  LOG2 ("RR subobject of unknown type %x", pRrSubObj->SubObjHdr.Type);
+	}
+      pRrSubObj = pRrSubObj->next;
+    }
+}
+
+void
+DumpERO (ER_SUBOBJ * pErSubObj, struct vty *vty)
+{
+  LOG1 ("ERO");
+  while (pErSubObj != NULL)
+    {
+      if (pErSubObj->SubObjHdr.LType & 0x80)
+	{
+	  LOG1 ("LOOSE");
+	}
+      switch (pErSubObj->SubObjHdr.LType & 0x7F)
+	{
+	case ERO_SUBTYPE_IPV4:
+	  LOG3 ("IP %x PrefixLen %x", pErSubObj->u.Ipv4.IpAddress,
+		pErSubObj->u.Ipv4.PrefixLength);
+	  break;
+	case ERO_SUBTYPE_AS:
+	  LOG2 ("AS %x", pErSubObj->u.AS.AsNumber);
+	  break;
+	default:
+	  LOG2 ("ER subobject of unknown type %x",
+		(pErSubObj->SubObjHdr.LType & 0x7F));
+	}
+      pErSubObj = pErSubObj->next;
+    }
+}
+
+void
+DumpPathMsg (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  DumpSession (pRsvpPkt, vty);
+  DumpSenderTemplate (pRsvpPkt, vty);
+  DumpSenderTSPec (pRsvpPkt, vty);
+  DumpRsvpHop (pRsvpPkt, vty);
+  DumpSessionAttr (pRsvpPkt, vty);
+  DumpTimeValues (pRsvpPkt, vty);
+  DumpAdSpec (pRsvpPkt, vty);
+  DumpERO (pRsvpPkt->ReceivedEro.er, vty);
+  DumpERO (pRsvpPkt->SentEro.er, vty);
+  DumpRRO (pRsvpPkt->ReceivedRro.rr, vty);
+  DumpRRO (pRsvpPkt->AddedRro.rr, vty);
+}
+
+void
+DumpFilterSpec (FILTER_SPEC_OBJ * pFilterSpec, struct vty *vty)
+{
+  LOG3 ("IP %x LSP %x", pFilterSpec->IpAddr, pFilterSpec->LspId);
+}
+
+void
+DumpFlowSpec (FLOW_SPEC_OBJ * pFlowSpec, struct vty *vty)
+{
+  if (pFlowSpec->ServHdr.ServHdr == FLOW_SPEC_CTRL_LOAD_SERV_NUMBER)
+    {
+      LOG6
+	("TockenBucketRate %f TockenBucketSize %f PeakDataRate %f MinPolicedUnit %f MaxPacketSize %f",
+	 pFlowSpec->u.CtrlLoad.TockenBucketRate,
+	 pFlowSpec->u.CtrlLoad.TockenBucketSize,
+	 pFlowSpec->u.CtrlLoad.PeakDataRate,
+	 pFlowSpec->u.CtrlLoad.MinPolicedUnit,
+	 pFlowSpec->u.CtrlLoad.MaxPacketSize);
+    }
+  else if (pFlowSpec->ServHdr.ServHdr == FLOW_SPEC_GUAR_SERV_NUMBER)
+    {
+      LOG6
+	("TockenBucketRate %f TockenBucketSize %f PeakDataRate %f MinPolicedUnit %f MaxPacketSize %f",
+	 pFlowSpec->u.Guar.CtrlLoad.TockenBucketRate,
+	 pFlowSpec->u.Guar.CtrlLoad.TockenBucketSize,
+	 pFlowSpec->u.Guar.CtrlLoad.PeakDataRate,
+	 pFlowSpec->u.Guar.CtrlLoad.MinPolicedUnit,
+	 pFlowSpec->u.Guar.CtrlLoad.MaxPacketSize);
+      LOG3 ("Rate %f SlackTerm %x", pFlowSpec->u.Guar.Rate,
+	    pFlowSpec->u.Guar.SlackTerm);
+    }
+}
+
+void
+DumpFlowDescr (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  FILTER_LIST *pFilterList = pRsvpPkt->pFilterList;
+  while (pFilterList != NULL)
+    {
+      FILTER_SPEC_DATA *pFilterSpecData;
+      if ((pFilterSpecData = pFilterList->pFilterSpecData) == NULL)
+	{
+	  pFilterList = pFilterList->next;
+	  continue;
+	}
+      DumpFilterSpec (&pFilterSpecData->FilterSpec, vty);
+      DumpFlowSpec (&pFilterSpecData->FlowSpec, vty);
+      LOG2 ("Label %x", pFilterSpecData->ReceivedLabel.Label);
+      DumpRRO (pFilterSpecData->Rro.rr, vty);
+      pFilterList = pFilterList->next;
+    }
+}
+
+void
+DumpStyle (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  LOG2 ("STYLE %x", pRsvpPkt->Style.OptionVector2);
+}
+
+void
+DumpResvMsg (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  DumpSession (pRsvpPkt, vty);
+  DumpTimeValues (pRsvpPkt, vty);
+  DumpRsvpHop (pRsvpPkt, vty);
+  DumpStyle (pRsvpPkt, vty);
+  DumpFlowDescr (pRsvpPkt, vty);
+}
+
+void
+DumpErrSpec (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  LOG5 ("Error code %x Error value %x IP %x flags %x",
+	pRsvpPkt->ErrorSpec.ErrCode,
+	pRsvpPkt->ErrorSpec.ErrVal,
+	pRsvpPkt->ErrorSpec.IpAddr, pRsvpPkt->ErrorSpec.Flags);
+}
+
+void
+DumpPathErrMsg (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  DumpSession (pRsvpPkt, vty);
+  DumpErrSpec (pRsvpPkt, vty);
+  DumpSenderTemplate (pRsvpPkt, vty);
+  DumpSenderTSPec (pRsvpPkt, vty);
+}
+
+void
+DumpResvErrMsg (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  DumpSession (pRsvpPkt, vty);
+  DumpRsvpHop (pRsvpPkt, vty);
+  DumpErrSpec (pRsvpPkt, vty);
+  DumpStyle (pRsvpPkt, vty);
+  DumpFlowDescr (pRsvpPkt, vty);
+}
+
+void
+DumpPathTearMsg (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  DumpSession (pRsvpPkt, vty);
+  DumpRsvpHop (pRsvpPkt, vty);
+  DumpSenderTemplate (pRsvpPkt, vty);
+  DumpSenderTSPec (pRsvpPkt, vty);
+}
+
+void
+DumpResvTearMsg (RSVP_PKT * pRsvpPkt, struct vty *vty)
+{
+  DumpSession (pRsvpPkt, vty);
+  DumpRsvpHop (pRsvpPkt, vty);
+  DumpStyle (pRsvpPkt, vty);
+  DumpFlowDescr (pRsvpPkt, vty);
+}
+
+void
+DumpPSB (PSB_KEY * pPsbKey, struct vty *vty)
+{
+  PSB_KEY PsbKey;
+  PSB *pPsb;
+
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+
+  if (memcmp (pPsbKey, &PsbKey, sizeof (PSB_KEY)) == 0)
+    {
+      while ((pPsb = GetNextPSB (&PsbKey)) != NULL)
+	{
+	  LOG8
+	    ("InIfIndex %x Label %x NextHop %x OutIfIndex %x TTL %x PrevHop %x TE_InProcess %x",
+	     pPsb->InIfIndex, pPsb->Label, pPsb->NextHop, pPsb->OutIfIndex,
+	     pPsb->ttl, pPsb->PrevHop, pPsb->TE_InProcess);
+	  LOG5
+	    ("AgeOutValue %x AgeOutTimer %s RefreshValue %x RefreshTimer %s",
+	     pPsb->AgeOutValue,
+	     (pPsb->AgeOutTimer == (uns32) NULL) ? "stopped" : "running",
+	     pPsb->RefreshValue,
+	     (pPsb->PathRefreshTimer ==
+	      (uns32) NULL) ? "stopped" : "running");
+	  LOG3 ("%s %s",
+		(pPsb->pSentBuffer ==
+		 NULL) ? "hasn't already encoded buffer (for refresh)" :
+		"has encoded buffer for refresh",
+		(pPsb->pRsb == NULL) ? "hasn't RSB" : "has RSB");
+	  DumpPathMsg (&pPsb->OldPacket, vty);
+	  PsbKey = pPsb->PsbKey;
+	}
+    }
+  else
+    {
+      if ((pPsb = FindPsb (pPsbKey)) != NULL)
+	{
+	  LOG8
+	    ("InIfIndex %x Label %x NextHop %x OutIfIndex %x TTL %x PrevHop %x TE_InProcess %x",
+	     pPsb->InIfIndex, pPsb->Label, pPsb->NextHop, pPsb->OutIfIndex,
+	     pPsb->ttl, pPsb->PrevHop, pPsb->TE_InProcess);
+	  LOG5
+	    ("AgeOutValue %x AgeOutTimer %s RefreshValue %x RefreshTimer %s",
+	     pPsb->AgeOutValue,
+	     (pPsb->AgeOutTimer == (uns32) NULL) ? "stopped" : "running",
+	     pPsb->RefreshValue,
+	     (pPsb->PathRefreshTimer ==
+	      (uns32) NULL) ? "stopped" : "running");
+	  LOG3 ("%s %s",
+		(pPsb->pSentBuffer ==
+		 NULL) ? "has already encoded buffer (for refresh)" :
+		"hasn't encoded buffer for refresh",
+		(pPsb->pRsb == NULL) ? "hasn't RSB" : "has RSB");
+	  DumpPathMsg (&pPsb->OldPacket, vty);
+	}
+    }
+}
+
+
+void
+DumpSingleRSB (RSB * pRsb, struct vty *vty)
+{
+  FILTER_LIST *pFilterList = pRsb->OldPacket.pFilterList;
+
+  while (pFilterList != NULL)
+    {
+      FILTER_SPEC_DATA *pFilterSpecData = pFilterList->pFilterSpecData;
+      if (pFilterSpecData == NULL)
+	{
+	  pFilterList = pFilterList->next;
+	  continue;
+	}
+      DumpFilterSpec (&pFilterSpecData->FilterSpec, vty);
+      if (pFilterSpecData->NewFlowSpecValid)
+	{
+	  DumpFlowSpec (&pFilterSpecData->NewFlowSpec, vty);
+	}
+      DumpFlowSpec (&pFilterSpecData->FlowSpec, vty);
+      LOG2 ("Label %x", pFilterSpecData->ReceivedLabel.Label);
+      DumpRRO (pFilterSpecData->Rro.rr, vty);
+      if (pFilterSpecData->pEffectiveFlow != NULL)
+	{
+	  LOG3 ("IfIndex %x %s",
+		pFilterSpecData->pEffectiveFlow->IfIndex,
+		(pFilterSpecData->pEffectiveFlow->MustBeProcessed ==
+		 1) ? "MustBeProcessed" : "");
+	  DumpFlowSpec (&pFilterSpecData->pEffectiveFlow->CurrentFlowSpec,
+			vty);
+	  DumpFlowSpec (&pFilterSpecData->pEffectiveFlow->NewFlowSpec, vty);
+	}
+      if (pFilterSpecData->pPHopResvRefreshList != NULL)
+	{
+	  LOG8
+	    ("PHOP IP %x PHOP LIH %x InIfIndex %x %s RefreshValue %x %s %s",
+	     pFilterSpecData->pPHopResvRefreshList->PHop.PHop,
+	     pFilterSpecData->pPHopResvRefreshList->PHop.LIH,
+	     pFilterSpecData->pPHopResvRefreshList->InIfIndex,
+	     (pFilterSpecData->pPHopResvRefreshList->MustBeProcessed ==
+	      1) ? "MustBeProcessed" : "",
+	     pFilterSpecData->pPHopResvRefreshList->RefreshValue,
+	     (pFilterSpecData->pPHopResvRefreshList->ResvRefreshTimer ==
+	      (uns32) NULL) ? "refresh timer is stopped" :
+	     "refresh timer is running",
+	     (pFilterSpecData->pPHopResvRefreshList->pSentBuffer ==
+	      NULL) ? "hasn't encoded buffer for refresh" :
+	     "has encoded buffer for refresh");
+	  DumpRRO (pFilterSpecData->pPHopResvRefreshList->pAddedRro, vty);
+	  DumpFlowSpec (&pFilterSpecData->pPHopResvRefreshList->FwdFlowSpec,
+			vty);
+	}
+      LOG3 ("AgeOut value %x %s",
+	    pFilterSpecData->AgeOutValue,
+	    (pFilterSpecData->AgeOutTimer ==
+	     (uns32) NULL) ? "age out timer is not running" :
+	    "age out timer is running");
+      pFilterList = pFilterList->next;
+    }
+}
+
+void
+DumpRSB (RSB_KEY * pRsbKey, struct vty *vty)
+{
+  RSB_KEY RsbKey;
+  RSB *pRsb;
+
+  memset (&RsbKey, 0, sizeof (RSB_KEY));
+
+  if (memcmp (&RsbKey, pRsbKey, sizeof (RSB_KEY)) == 0)
+    {
+      while ((pRsb = GetNextRSB (&RsbKey)) != NULL)
+	{
+	  DumpSingleRSB (pRsb, vty);
+	  RsbKey = pRsb->RsbKey;
+	}
+    }
+  else
+    {
+      if ((pRsb = FindRsb (pRsbKey)) != NULL)
+	{
+	  DumpSingleRSB (pRsb, vty);
+	}
+    }
+}
+
+void
+DumpRsvpStatistics (struct vty *vty)
+{
+  LOG7
+    ("PathMsg %d ResvMsg %d PathTearMsg %d ResvTearMsg %d PathErrMsg %d ResvErrMsg %d",
+     RsvpStatistics.PathMsgCount, RsvpStatistics.ResvMsgCount,
+     RsvpStatistics.PathTearMsgCount, RsvpStatistics.ResvTearMsgCount,
+     RsvpStatistics.PathErrMsgCount, RsvpStatistics.ResvErrMsgCount);
+  LOG6 ("NewPsb %d DeletedPsb %d NewRsb %d DeletedRsb %d NewFilters %d",
+	RsvpStatistics.NewPsbCount, RsvpStatistics.DeletePsbCount,
+	RsvpStatistics.NewRsbCount, RsvpStatistics.DeleteRsbCount,
+	RsvpStatistics.NewFiltersCount);
+  LOG3 ("PathAgeOut %d FilterAgeOut %d", RsvpStatistics.PsbAgeOutCount,
+	RsvpStatistics.FilterAgeOutCount);
+}
+
+int
+RefreshRandomize (uns32 RefreshTimeBase)
+{
+  uns32 Range = RefreshTimeBase / 10;
+  int k = rand ();
+  while (k > Range)
+    k = k / 3;
+  return (k % 2) ? k : -k;
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_utilities.h quagga-mpls/rsvpd/rsvp_utilities.h
--- quagga-0.99.10/rsvpd/rsvp_utilities.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_utilities.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,59 @@
+
+#ifndef _RSVP_UTILITIES_H_
+#define _RSVP_UTILITIES_H_
+
+typedef struct _rsvp_statistics_
+{
+  uns32 NewPsbCount;
+  uns32 DeletePsbCount;
+  uns32 NewRsbCount;
+  uns32 DeleteRsbCount;
+  uns32 NewFiltersCount;
+  uns32 PsbAgeOutCount;
+  uns32 FilterAgeOutCount;
+  uns32 PathMsgCount;
+  uns32 ResvMsgCount;
+  uns32 PathTearMsgCount;
+  uns32 ResvTearMsgCount;
+  uns32 PathErrMsgCount;
+  uns32 ResvErrMsgCount;
+} RSVP_STATISTICS;
+
+
+E_RC EnqueueRsvpPacket (RSVP_PKT_QUEUE * pItem,
+			RSVP_PKT_QUEUE ** ppQueueHead);
+RSVP_PKT_QUEUE *DequeueRsvpPacket (RSVP_PKT_QUEUE ** ppQueueHead);
+
+int RefreshRandomize (uns32 RefreshTimeBase);
+
+E_RC InsertRRO (RSVP_PKT * pRsvpPkt);
+
+E_RC InsertERO (ER_OBJ * pEro, ER_HOP * Path, uns16 HopNum);
+
+void FreeRSB (RSB * pRsb);
+
+void FreePSB (PSB * pPsb);
+
+void FreeRsvpPkt (RSVP_PKT * pRsvpPkt);
+
+void FreeERO (ER_OBJ *);
+void FreeRRO (RR_OBJ *);
+void FreeFilterSpecData (FILTER_SPEC_DATA ** ppFilterSpecData);
+
+E_RC IfIpAdd (IPV4_ADDR IfIpAddress, uns8 PrefixLen);
+E_RC IfIpAddrDel (IPV4_ADDR IfIpAddress, uns8 PrefixLen);
+
+void DumpResvTearMsg (RSVP_PKT * pRsvpPkt, struct vty *vty);
+void DumpResvMsg (RSVP_PKT * pRsvpPkt, struct vty *vty);
+void DumpPathErrMsg (RSVP_PKT * pRsvpPkt, struct vty *vty);
+void DumpResvErrMsg (RSVP_PKT * pRsvpPkt, struct vty *vty);
+void DumpPathMsg (RSVP_PKT * pRsvpPkt, struct vty *vty);
+void DumpPathTearMsg (RSVP_PKT * pRsvpPkt, struct vty *vty);
+IPV4_ADDR GetRouterId ();
+E_RC CheckRRO4Loop (RR_SUBOBJ * pRrSubObj);
+uns8 IsAbstractNode (IPV4_ADDR IpAddress, uns8 PrefixLen);
+E_RC InitInterfaceIpAdressesDB ();
+void DumpRSB (RSB_KEY * pRsbKey, struct vty *vty);
+void DumpPSB (PSB_KEY * pPsbKey, struct vty *vty);
+void DumpRsvpStatistics (struct vty *vty);
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvp_vty.c quagga-mpls/rsvpd/rsvp_vty.c
--- quagga-0.99.10/rsvpd/rsvp_vty.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_vty.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,656 @@
+/* Module:   rsvp_vty.c
+   Contains: RSVP vty function
+   Module creator: original code by Vadim Suraev, vadim_suraev@hotmail.com
+                   adapted by James R. Leu, jleu@mindspring.com
+   */
+
+#include <zebra.h>
+
+#include "memory.h"
+#include "thread.h"
+#include "vty.h"
+#include "command.h"
+#include "log.h"
+
+#include "rsvp.h"
+#include "te.h"
+#include "te_cspf.h"
+
+char MplsTePrompt[50] = "%s(mpls_te_tunnel-";
+char CurrentTunnelName[20];
+
+struct cmd_node mpls_te_conf_node = {
+  MPLS_TE_TUNNEL_CONF_NODE,
+  ""
+};
+
+struct cmd_node mpls_te_tunnel_node = {
+  MPLS_TE_TUNNEL_NODE,
+  MplsTePrompt,
+  1
+};
+
+int
+DummyConfigWrite (struct vty *vty)
+{
+  return 0;
+}
+
+void
+WriteTunnel (USER_LSP * pUserLsp, struct vty *vty)
+{
+  struct in_addr tmp;
+  tmp.s_addr = ntohl (pUserLsp->params.to);
+  vty_out (vty, "interface tunnel %s%s", pUserLsp->params.LspName,
+	   VTY_NEWLINE);
+  vty_out (vty, "  tunnel destination %s%s", inet_ntoa (tmp), VTY_NEWLINE);
+  if (pUserLsp->params.lsp_params.BW)
+    {
+#if 0				/* for now - no support for floating point input */
+      vty_out (vty, "  tunnel mpls traffic-eng bandwidth %f%s",
+	       pUserLsp->params.lsp_params.BW, VTY_NEWLINE);
+#else
+      int bw = pUserLsp->params.lsp_params.BW;
+      vty_out (vty, "  tunnel mpls traffic-eng bandwidth %d%s",
+	       /*pUserLsp->params.lsp_params.BW */ bw,
+	       VTY_NEWLINE);
+#endif
+    }
+
+  if ((pUserLsp->params.lsp_params.setup_priority != 4) ||
+      (pUserLsp->params.lsp_params.hold_priority != 4))
+    {
+      vty_out (vty, "  tunnel mpls traffic-eng priority %d %d%s",
+	       pUserLsp->params.lsp_params.setup_priority,
+	       pUserLsp->params.lsp_params.hold_priority, VTY_NEWLINE);
+    }
+  if (pUserLsp->params.lsp_params.hop_limit)
+    {
+      vty_out (vty, "  tunnel mpls traffic-eng hop-limit %d%s",
+	       pUserLsp->params.lsp_params.hop_limit, VTY_NEWLINE);
+    }
+  if (pUserLsp->params.lsp_params.optimize_timer)
+    {
+      vty_out (vty, "  tunnel mpls traffic-eng optimize-timer %d%s",
+	       pUserLsp->params.lsp_params.optimize_timer, VTY_NEWLINE);
+    }
+  if (pUserLsp->params.lsp_params.record)
+    {
+      vty_out (vty, "  tunnel mpls traffic-eng record-route%s", VTY_NEWLINE);
+    }
+  if (pUserLsp->params.lsp_params.affinity_properties)
+    {
+      vty_out (vty, "  tunnel mpls traffic-eng affinity %x %x%s",
+	       pUserLsp->params.lsp_params.affinity_properties,
+	       pUserLsp->params.lsp_params.affinity_mask, VTY_NEWLINE);
+    }
+  if (pUserLsp->params.retry_timer)
+    {
+      vty_out (vty, "  tunnel mpls traffic-eng retry-timer %d%s",
+	       pUserLsp->params.retry_timer, VTY_NEWLINE);
+    }
+  if (pUserLsp->params.retry_limit)
+    {
+      vty_out (vty, "  tunnel mpls traffic-eng retry-limit %d%s",
+	       pUserLsp->params.retry_limit, VTY_NEWLINE);
+    }
+  vty_out (vty, "  exit%s", VTY_NEWLINE);
+}
+
+int
+MPLS_TE_ConfigWrite (struct vty *vty)
+{
+  UserLspLoop ((LSP_LOOP_CALLBACK_T) WriteTunnel, vty);
+  return 0;
+}
+
+static void
+TeEndConfigureCallback (struct vty *vty)
+{
+  USER_LSP *pUserLsp;
+  SM_CALL_T *pCall;
+
+  pUserLsp = vty->index;
+
+  if ((pCall =
+       lsp_sm_sync_invoke (0, pUserLsp, USER_LSP_REQUEST_EVENT)) == NULL)
+    {
+      zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+    }
+  else
+    {
+      zlog_info ("%s %d", __FILE__, __LINE__);
+      sm_call (pCall);
+    }
+}
+
+DEFUN (mpls_te_tunnel,
+       mpls_te_tunnel_cmd,
+       "interface tunnel WORD ",
+       "MPLS TE tunnel name\n" "Start MPLS TE tunnel configuration\n")
+{
+  USER_LSP *pUserLsp, *pCurrUserLsp;
+  vty->node = MPLS_TE_TUNNEL_NODE;
+  strcpy (CurrentTunnelName, argv[0]);
+  strcpy (MplsTePrompt, "%s(mpls_te_tunnel-");
+  strcat (MplsTePrompt, CurrentTunnelName);
+  strcat (MplsTePrompt, ")# ");
+  if ((pUserLsp = (USER_LSP *) XMALLOC (MTYPE_TE, sizeof (USER_LSP))) == NULL)
+    {
+      zlog_info ("leaving UserLspAPI %s %d", __FILE__, __LINE__);
+      return CMD_SUCCESS;
+    }
+  memset (pUserLsp, 0, sizeof (USER_LSP));
+  strcpy (pUserLsp->params.LspName, CurrentTunnelName);
+  if ((pCurrUserLsp = UserLspGet (pUserLsp->params.LspName)) != NULL)
+    {
+      USER_LSP_PARAMS *pDestParams = &pUserLsp->params, *pSrcParams =
+	&pCurrUserLsp->params;
+      SECONDARY_PATH_LIST *pSrcSecPathList =
+	pSrcParams->SecondaryPaths, *pDestSecPathList = NULL, *pPathListTemp;
+      pDestParams->to = pSrcParams->to;
+      pDestParams->from = pSrcParams->from;
+      pDestParams->metric = pSrcParams->metric;
+      pDestParams->no_decrement_ttl = pSrcParams->no_decrement_ttl;
+      pDestParams->bw_policy = pSrcParams->bw_policy;
+      pDestParams->retry_timer = pSrcParams->retry_timer;
+      pDestParams->retry_limit = pSrcParams->retry_limit;
+      pDestParams->FastReRoute = pSrcParams->FastReRoute;
+      strcpy (pDestParams->PolicyName, pSrcParams->PolicyName);
+      memcpy (&pDestParams->lsp_params, &pSrcParams->lsp_params,
+	      sizeof (LSP_PATH_SHARED_PARAMS));
+      strcpy (pDestParams->Primary, pSrcParams->Primary);
+      if (pSrcParams->PrimaryPathParams != NULL)
+	{
+	  if ((pDestParams->PrimaryPathParams =
+	       (LSP_PATH_SHARED_PARAMS *) XMALLOC (MTYPE_TE,
+						   sizeof
+						   (LSP_PATH_SHARED_PARAMS)))
+	      == NULL)
+	    {
+	      zlog_info ("leaving UserLspAPI %s %d", __FILE__, __LINE__);
+	      return CMD_SUCCESS;
+	    }
+	  memcpy (pDestParams->PrimaryPathParams,
+		  pSrcParams->PrimaryPathParams,
+		  sizeof (LSP_PATH_SHARED_PARAMS));
+	}
+      while (pSrcSecPathList != NULL)
+	{
+	  if ((pPathListTemp =
+	       (SECONDARY_PATH_LIST *) XMALLOC (MTYPE_TE,
+						sizeof (SECONDARY_PATH_LIST)))
+	      == NULL)
+	    {
+	      zlog_info ("leaving UserLspAPI %s %d", __FILE__, __LINE__);
+	      return CMD_SUCCESS;
+	    }
+	  memset (pPathListTemp, 0, sizeof (SECONDARY_PATH_LIST));
+	  if (pDestParams->SecondaryPaths == NULL)
+	    {
+	      pDestSecPathList = pDestParams->SecondaryPaths = pPathListTemp;
+	    }
+	  else
+	    {
+	      pDestSecPathList->next = pPathListTemp;
+	      pDestSecPathList = pDestSecPathList->next;
+	    }
+	  strcpy (pDestSecPathList->Secondary, pSrcSecPathList->Secondary);
+	  if (pSrcSecPathList->SecondaryPathParams != NULL)
+	    {
+	      if ((pDestSecPathList->SecondaryPathParams =
+		   (LSP_PATH_SHARED_PARAMS *) XMALLOC (MTYPE_TE,
+						       sizeof
+						       (LSP_PATH_SHARED_PARAMS)))
+		  == NULL)
+		{
+		  zlog_info ("leaving UserLspAPI %s %d", __FILE__, __LINE__);
+		  return CMD_SUCCESS;
+		}
+	      memcpy (pDestSecPathList->SecondaryPathParams,
+		      pSrcSecPathList->SecondaryPathParams,
+		      sizeof (LSP_PATH_SHARED_PARAMS));
+	    }
+	  pSrcSecPathList = pSrcSecPathList->next;
+	}
+    }
+  else
+    {
+      pUserLsp->params.lsp_params.setup_priority =
+	pUserLsp->params.lsp_params.hold_priority = 4;
+    }
+  vty->index = pUserLsp;
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_te_tunnel,
+       no_mpls_te_tunnel_cmd,
+       "no interface tunnel WORD",
+       "MPLS TE tunnel name\n" "Remove MPLS TE tunnel configuration\n")
+{
+  USER_LSP *pCurrUserLsp;
+  SM_CALL_T *pCall;
+
+  strcpy (CurrentTunnelName, "");
+  if ((pCurrUserLsp = UserLspGet (argv[0])) != NULL)
+    {
+      pCurrUserLsp->params.lsp_params.disable = TRUE;
+      if ((pCall =
+	   lsp_sm_sync_invoke (0, pCurrUserLsp,
+			       USER_LSP_REQUEST_EVENT)) == NULL)
+	{
+	  zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+	}
+      else
+	{
+	  zlog_info ("%s %d", __FILE__, __LINE__);
+	  sm_call (pCall);
+	}
+    }
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_mpls_te_tunnel,
+       show_mpls_te_tunnel_cmd,
+       "show mpls traffic-eng tunnel WORD", "MPLS TE Tunnel's name")
+{
+  UserLspsDump (argv[0], vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_mpls_te_tunnels,
+       show_mpls_te_tunnels_cmd,
+       "show mpls traffic-eng tunnels", "Shows MPLS TE tunnels")
+{
+  UserLspsDump (NULL, vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_te_tunnel_dest,
+       mpls_te_tunnel_dest_cmd,
+       "tunnel destination A.B.C.D",
+       "MPLS TE Tunnel's destination IP address")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  struct in_addr dest;
+  int ret;
+  ret = inet_aton (argv[0], &dest);
+  if (!ret)
+    {
+      vty_out (vty, "Please specify destination IP address %s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+  pDestParams->to = ntohl (dest.s_addr);
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_te_tunnel_bandwidth,
+       mpls_te_tunnel_bandwidth_cmd,
+       "tunnel mpls traffic-eng bandwidth <0-4294967295>",
+       "MPLS TE Tunnel's bandwidth")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.BW = atol (argv[0]);
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_te_tunnel_bandwidth,
+       no_mpls_te_tunnel_bandwidth_cmd,
+       "no tunnel mpls traffic-eng bandwidth", "MPLS TE Tunnel's bandwidth")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.BW = 0;
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_te_tunnel_sprio,
+       mpls_te_tunnel_sprio_cmd,
+       "tunnel mpls traffic-eng priority <0-7>",
+       "MPLS TE Tunnel's setup priority")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.setup_priority = atol (argv[0]);
+  pDestParams->lsp_params.hold_priority =
+    pDestParams->lsp_params.setup_priority;
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_te_tunnel_shprio,
+       mpls_te_tunnel_shprio_cmd,
+       "tunnel mpls traffic-eng priority <0-7> <0-7>",
+       "MPLS TE Tunnel's setup priority" "MPLS TE Tunnel's hold priority")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.setup_priority = atol (argv[0]);
+  pDestParams->lsp_params.hold_priority = atol (argv[1]);
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_te_tunnel_prio,
+       no_mpls_te_tunnel_prio_cmd,
+       "no tunnel mpls traffic-eng priority", "MPLS TE Tunnel's priority")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.hold_priority =
+    pDestParams->lsp_params.setup_priority = 4;
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_te_tunnel_hop_limit,
+       mpls_te_tunnel_hop_limit_cmd,
+       "tunnel mpls traffic-eng hop-limit <0-255>",
+       "MPLS TE Tunnel's path hop limit")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.hop_limit = atol (argv[0]);
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_te_tunnel_hop_limit,
+       no_mpls_te_tunnel_hop_limit_cmd,
+       "no tunnel mpls traffic-eng hop-limit",
+       "MPLS TE Tunnel's path hop limit")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.hop_limit = 0;
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_te_tunnel_optimize_timer,
+       mpls_te_tunnel_optimize_timer_cmd,
+       "tunnel mpls traffic-eng optimize-timer <0-604800>",
+       "MPLS TE Tunnel's optimize timer")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.optimize_timer = atol (argv[0]);
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_te_tunnel_optimize_timer,
+       no_mpls_te_tunnel_optimize_timer_cmd,
+       "no tunnel mpls traffic-eng optimize-timer",
+       "MPLS TE Tunnel's optimize timer")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.optimize_timer = 0;
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_te_tunnel_record_route,
+       mpls_te_tunnel_record_route_cmd,
+       "tunnel mpls traffic-eng record-route",
+       "MPLS TE Tunnel's record route")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.record = 1;
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_te_tunnel_record_route,
+       no_mpls_te_tunnel_record_route_cmd,
+       "no tunnel mpls traffic-eng record-route",
+       "MPLS TE Tunnel's record route")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.record = 0;
+  return CMD_SUCCESS;
+}
+
+#if 0				/* for now - no support for hexa input */
+DEFUN (mpls_te_tunnel_affinity,
+       mpls_te_tunnel_affinity_cmd,
+       "tunnel mpls traffic-eng affinity <0-255>",
+       "MPLS TE Tunnel's resource affinity")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.affinity_properties = atol (argv[0]);
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_te_tunnel_affinity,
+       no_mpls_te_tunnel_affinity_cmd,
+       "no tunnel mpls traffic-eng affinity",
+       "MPLS TE Tunnel's resource affinity")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->lsp_params.affinity_properties = 0;
+  return CMD_SUCCESS;
+}
+#endif
+
+DEFUN (mpls_te_tunnel_retry_timer,
+       mpls_te_tunnel_retry_timer_cmd,
+       "tunnel mpls traffic-eng retry-timer <1-604800>",
+       "MPLS TE Tunnel's setup retry timer")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->retry_timer = atol (argv[0]);
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_te_tunnel_retry_timer,
+       no_mpls_te_tunnel_retry_timer_cmd,
+       "no tunnel mpls traffic-eng retry-timer",
+       "MPLS TE Tunnel's setup retry timer")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->retry_timer = 0;
+  return CMD_SUCCESS;
+}
+
+DEFUN (mpls_te_tunnel_retry_limit,
+       mpls_te_tunnel_retry_limit_cmd,
+       "tunnel mpls traffic-eng retry-limit <0-4294967295>",
+       "MPLS TE Tunnel's setup retry attempts limit")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->retry_limit = atol (argv[0]);
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_te_tunnel_retry_limit,
+       no_mpls_te_tunnel_retry_limit_cmd,
+       "no tunnel mpls traffic-eng retry-limit",
+       "MPLS TE Tunnel's setup retry attempts limit")
+{
+  USER_LSP *pUserLsp = vty->index;
+  USER_LSP_PARAMS *pDestParams = &pUserLsp->params;
+  pDestParams->retry_limit = 0;
+  return CMD_SUCCESS;
+}
+
+
+DEFUN (show_mpls_te_links,
+       show_mpls_te_links_cmd, "show mpls traffic-eng links", "MPLS TE links")
+{
+  rdb_te_links_dump (vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_mpls_te_path_cache,
+       show_mpls_te_path_cache_cmd,
+       "show mpls traffic-eng path-cache",
+       "MPLS TE CSPF calculated path cache")
+{
+  rdb_path_dump (vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_mpls_te_remote_link,
+       show_mpls_te_remote_link_cmd,
+       "show mpls traffic-eng remote-link", "MPLS TE remote links cache")
+{
+  rdb_remote_link_dump (vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_mpls_te_next_hop,
+       show_mpls_te_next_hop_cmd,
+       "show mpls traffic-eng next-hop", "MPLS TE next hops cache")
+{
+  rdb_next_hop_dump (vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_mpls_te_configured_paths,
+       show_mpls_te_configured_paths_cmd,
+       "show mpls traffic-eng static-path", "MPLS TE configured static paths")
+{
+  rdb_static_path_dump (NULL, vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_mpls_te_ip_2_rtr_id_map,
+       show_mpls_te_ip_2_rtr_id_map_cmd,
+       "show mpls traffic-eng ip2routerID",
+       "MPLS TE show I/F IP addresses to RouterIDs mapping")
+{
+  rdb_remote_link_router_id_mapping_dump (vty);
+  return CMD_SUCCESS;
+}
+
+
+DEFUN (show_rsvp_te_psbs,
+       show_rsvp_te_psbs_cmd, "show rsvpte psbs", "RSVP TE PSBs")
+{
+  PSB_KEY PsbKey;
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+  DumpPSB (&PsbKey, vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_rsvp_te_rsbs,
+       show_rsvp_te_rsbs_cmd, "show rsvpte rsbs", "RSVP TE RSBs")
+{
+  RSB_KEY RsbKey;
+  memset (&RsbKey, 0, sizeof (RSB_KEY));
+  DumpRSB (&RsbKey, vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_rsvp_te_psb,
+       show_rsvp_te_psb_cmd, "show rsvpte psb A.B.C.D", "RSVP TE PSB")
+{
+  PSB_KEY PsbKey;
+  struct in_addr dest;
+  int ret;
+  ret = inet_aton (argv[0], &dest);
+  if (!ret)
+    {
+      vty_out (vty, "Please specify destination IP address %s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+  PsbKey.Session.Dest = dest.s_addr;
+  DumpPSB (&PsbKey, vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_rsvp_te_rsb,
+       show_rsvp_te_rsb_cmd, "show rsvpte rsb A.B.C.D", "RSVP TE RSB ")
+{
+  RSB_KEY RsbKey;
+  struct in_addr dest;
+  int ret;
+
+  ret = inet_aton (argv[0], &dest);
+  if (!ret)
+    {
+      vty_out (vty, "Please specify destination IP address %s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+  memset (&RsbKey, 0, sizeof (RSB_KEY));
+  RsbKey.Session.Dest = dest.s_addr;
+  DumpRSB (&RsbKey, vty);
+  return CMD_SUCCESS;
+}
+
+DEFUN (show_rsvp_te_statistics,
+       show_rsvp_te_statistics_cmd,
+       "show rsvpte statistics", "RSVP TE statistics")
+{
+  DumpRsvpStatistics (vty);
+  return CMD_SUCCESS;
+}
+
+void
+rsvp_vty ()
+{
+  install_node (&mpls_te_tunnel_node, DummyConfigWrite);
+  install_node (&mpls_te_conf_node, MPLS_TE_ConfigWrite);
+
+  /* Install ospf commands. */
+  install_element (VIEW_NODE, &show_mpls_te_tunnel_cmd);
+  install_element (VIEW_NODE, &show_mpls_te_tunnels_cmd);
+  install_element (VIEW_NODE, &show_mpls_te_links_cmd);
+  install_element (VIEW_NODE, &show_mpls_te_path_cache_cmd);
+  install_element (VIEW_NODE, &show_mpls_te_remote_link_cmd);
+  install_element (VIEW_NODE, &show_mpls_te_next_hop_cmd);
+  install_element (VIEW_NODE, &show_mpls_te_configured_paths_cmd);
+  install_element (VIEW_NODE, &show_mpls_te_ip_2_rtr_id_map_cmd);
+
+  install_element (ENABLE_NODE, &show_mpls_te_tunnel_cmd);
+  install_element (ENABLE_NODE, &show_mpls_te_tunnels_cmd);
+  install_element (ENABLE_NODE, &show_mpls_te_links_cmd);
+  install_element (ENABLE_NODE, &show_mpls_te_path_cache_cmd);
+  install_element (ENABLE_NODE, &show_mpls_te_remote_link_cmd);
+  install_element (ENABLE_NODE, &show_mpls_te_next_hop_cmd);
+  install_element (ENABLE_NODE, &show_mpls_te_configured_paths_cmd);
+  install_element (ENABLE_NODE, &show_mpls_te_ip_2_rtr_id_map_cmd);
+
+  install_element (CONFIG_NODE, &mpls_te_tunnel_cmd);
+  install_element (CONFIG_NODE, &no_mpls_te_tunnel_cmd);
+
+  install_default (MPLS_TE_TUNNEL_NODE);
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_dest_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_bandwidth_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &no_mpls_te_tunnel_bandwidth_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_sprio_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_shprio_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &no_mpls_te_tunnel_prio_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_hop_limit_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &no_mpls_te_tunnel_hop_limit_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_optimize_timer_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE,
+		   &no_mpls_te_tunnel_optimize_timer_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_record_route_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &no_mpls_te_tunnel_record_route_cmd);
+#if 0				/* for now - no support for hexa input */
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_affinity_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &no_mpls_te_tunnel_affinity_cmd);
+#endif
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_retry_timer_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &no_mpls_te_tunnel_retry_timer_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &mpls_te_tunnel_retry_limit_cmd);
+  install_element (MPLS_TE_TUNNEL_NODE, &no_mpls_te_tunnel_retry_limit_cmd);
+
+  install_element (VIEW_NODE, &show_rsvp_te_psbs_cmd);
+  install_element (ENABLE_NODE, &show_rsvp_te_psbs_cmd);
+  install_element (VIEW_NODE, &show_rsvp_te_rsbs_cmd);
+  install_element (ENABLE_NODE, &show_rsvp_te_rsbs_cmd);
+
+  install_element (VIEW_NODE, &show_rsvp_te_psb_cmd);
+  install_element (ENABLE_NODE, &show_rsvp_te_psb_cmd);
+  install_element (VIEW_NODE, &show_rsvp_te_rsb_cmd);
+  install_element (ENABLE_NODE, &show_rsvp_te_rsb_cmd);
+
+  install_element (VIEW_NODE, &show_rsvp_te_statistics_cmd);
+  install_element (ENABLE_NODE, &show_rsvp_te_statistics_cmd);
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_vty.h quagga-mpls/rsvpd/rsvp_vty.h
--- quagga-0.99.10/rsvpd/rsvp_vty.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_vty.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,6 @@
+#ifndef _QUAGGA_RSVP_VTY_H
+#define _QUAGGA_RSVP_VTY_H
+
+extern void rsvp_vty ();
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/rsvp_zebra.c quagga-mpls/rsvpd/rsvp_zebra.c
--- quagga-0.99.10/rsvpd/rsvp_zebra.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_zebra.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,533 @@
+/*
+ * Zebra connect library for RSVPd
+ * Copyright (C) 1997, 98, 99, 2000 Kunihiro Ishiguro, Toshiaki Takada
+ *
+ * This file is part of GNU Zebra.
+ *
+ * GNU Zebra is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2, or (at your option) any
+ * later version.
+ *
+ * GNU Zebra is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU Zebra; see the file COPYING.  If not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA. 
+ */
+
+#include <zebra.h>
+
+#include "thread.h"
+#include "command.h"
+#include "network.h"
+#include "prefix.h"
+#include "routemap.h"
+#include "table.h"
+#include "stream.h"
+#include "memory.h"
+#include "zclient.h"
+#include "filter.h"
+#include "plist.h"
+#include "log.h"
+
+#include "rsvp.h"
+#include "te.h"
+
+/* Zebra structure to hold current status. */
+struct zclient *zclient = NULL;
+
+/* For registering threads. */
+extern struct thread_master *master;
+struct in_addr router_id_zebra;
+
+/* Router-id update message from zebra. */
+static int
+rsvp_router_id_update_zebra (int command, struct zclient *zclient,
+			     zebra_size_t length)
+{
+  struct prefix router_id;
+  char buf[128];
+  zebra_router_id_update_read (zclient->ibuf, &router_id);
+
+  prefix2str (&router_id, buf, sizeof (buf));
+  zlog_debug ("Zebra rcvd: router id update %s", buf);
+
+  router_id_zebra = router_id.u.prefix4;
+  rdb_set_router_id (router_id_zebra.s_addr);
+
+  return 0;
+}
+
+/* Inteface addition message from zebra. */
+static int
+rsvp_interface_add (int command, struct zclient *zclient, zebra_size_t length)
+{
+  struct interface *ifp;
+
+  ifp = zebra_interface_add_read (zclient->ibuf);
+
+  zlog_debug ("Zebra: interface add %s index %d flags %ld metric %d mtu %d",
+	      ifp->name, ifp->ifindex, ifp->flags, ifp->metric, ifp->mtu);
+
+  if (EnableRsvpOnInterface (ifp->ifindex) != E_OK)
+    {
+      zlog_err ("cannot enable RSVP on I/F %d", ifp->ifindex);
+    }
+  else
+    {
+      zlog_debug (" RSVP enabled");
+    }
+
+  return 0;
+}
+
+static int
+rsvp_interface_delete (int command, struct zclient *zclient,
+		       zebra_size_t length)
+{
+  struct interface *ifp;
+  struct stream *s;
+
+  s = zclient->ibuf;
+  /* zebra_interface_state_read() updates interface structure in iflist */
+  ifp = zebra_interface_state_read (s);
+
+  if (ifp == NULL)
+    return 0;
+
+  if (if_is_up (ifp))
+    zlog_warn ("Zebra: got delete of %s, but interface is still up",
+	       ifp->name);
+
+  zlog_debug
+    ("Zebra: interface delete %s index %d flags %ld metric %d mtu %d",
+     ifp->name, ifp->ifindex, ifp->flags, ifp->metric, ifp->mtu);
+
+  if (DisableRsvpOnInterface (ifp->ifindex) != E_OK)
+    {
+      zlog_err ("cannot disable RSVP on I/F %d", ifp->ifindex);
+    }
+  else
+    {
+      zlog_debug (" RSVP disabled");
+    }
+
+  return 0;
+}
+
+static struct interface *
+zebra_interface_if_lookup (struct stream *s)
+{
+  char ifname_tmp[INTERFACE_NAMSIZ];
+
+  /* Read interface name. */
+  stream_get (ifname_tmp, s, INTERFACE_NAMSIZ);
+
+  /* And look it up. */
+  return if_lookup_by_name_len (ifname_tmp,
+				strnlen (ifname_tmp, INTERFACE_NAMSIZ));
+}
+
+static int
+rsvp_interface_state_up (int command, struct zclient *zclient,
+			 zebra_size_t length)
+{
+  struct interface *ifp;
+
+  ifp = zebra_interface_if_lookup (zclient->ibuf);
+
+  if (ifp == NULL)
+    return 0;
+
+  /* Interface is already up. */
+  if (if_is_operative (ifp))
+    {
+      /* Temporarily keep ifp values. */
+      struct interface if_tmp;
+      memcpy (&if_tmp, ifp, sizeof (struct interface));
+
+      zebra_interface_if_set_value (zclient->ibuf, ifp);
+
+      zlog_debug ("Zebra: Interface[%s] state update.", ifp->name);
+
+      if (if_tmp.bandwidth != ifp->bandwidth)
+	{
+	  zlog_debug ("Zebra: Interface[%s] bandwidth change %d -> %d.",
+		      ifp->name, if_tmp.bandwidth, ifp->bandwidth);
+	}
+      return 0;
+    }
+
+  zebra_interface_if_set_value (zclient->ibuf, ifp);
+
+  zlog_debug ("Zebra: Interface[%s] state change to up.", ifp->name);
+
+  return 0;
+}
+
+static int
+rsvp_interface_state_down (int command, struct zclient *zclient,
+			   zebra_size_t length)
+{
+  struct interface *ifp;
+
+  ifp = zebra_interface_state_read (zclient->ibuf);
+
+  if (ifp == NULL)
+    return 0;
+
+  zlog_debug ("Zebra: Interface[%s] state change to down.", ifp->name);
+
+  return 0;
+}
+
+static int
+rsvp_interface_address_add (int command, struct zclient *zclient,
+			    zebra_size_t length)
+{
+  struct connected *c;
+  char buf[128];
+
+  c = zebra_interface_address_read (command, zclient->ibuf);
+
+  if (c == NULL)
+    return 0;
+
+  prefix2str (c->address, buf, sizeof (buf));
+  zlog_debug ("Zebra: interface %s address add %s", c->ifp->name, buf);
+
+  zlog_info ("trying to add IP address %s", buf);
+
+  if (IfIpAdd (c->address->u.prefix4.s_addr, c->address->prefixlen) != E_OK)
+    {
+      zlog_err ("Cannot add IP address %s %d", __FILE__, __LINE__);
+    }
+  if (IpAddrSetByIfIndex (c->ifp->ifindex, c->address->u.prefix4.s_addr) !=
+      E_OK)
+    {
+      zlog_err ("Cannot set IP address %s %d", __FILE__, __LINE__);
+    }
+  if (IsRsvpEnabledOnIf (c->ifp->ifindex) == E_OK)
+    {
+      if (EnableRsvpOnInterface2 (c->ifp->ifindex) != E_OK)
+        {
+          zlog_err ("Cannot enable RSVP on I/F %d %s %d",
+                    c->ifp->ifindex, __FILE__, __LINE__);
+        }
+    }
+
+  return 0;
+}
+
+static int
+rsvp_interface_address_delete (int command, struct zclient *zclient,
+			       zebra_size_t length)
+{
+  struct connected *c;
+  char buf[128];
+
+  c = zebra_interface_address_read (command, zclient->ibuf);
+
+  if (c == NULL)
+    return 0;
+
+  prefix2str (c->address, buf, sizeof (buf));
+  zlog_debug ("Zebra: interface %s address delete %s", c->ifp->name, buf);
+
+  if (IfIpAddrDel (c->address->u.prefix4.s_addr, c->address->prefixlen) !=
+      E_OK)
+    {
+      zlog_err ("Cannot add IP address %s %d", __FILE__, __LINE__);
+    }
+  if (IpAddrSetByIfIndex (c->ifp->ifindex, 0) != E_OK)
+    {
+      zlog_err ("Cannot unset IP address %s %d", __FILE__, __LINE__);
+    }
+  DisableRsvpOnInterface (c->ifp->ifindex);
+
+  connected_free (c);
+
+  return 0;
+}
+
+/* Zebra route add and delete treatment. */
+static int
+rsvp_zebra_read_ipv4 (int command, struct zclient *zclient,
+		      zebra_size_t length)
+{
+  struct stream *s;
+  struct zapi_ipv4 api;
+  unsigned long ifindex;
+  struct in_addr nexthop;
+  struct prefix_ipv4 p;
+  int i;
+
+  s = zclient->ibuf;
+
+  zapi_ipv4_read (s, length, &api, &p);
+
+  if (IPV4_NET127 (ntohl (p.prefix.s_addr)))
+    return 0;
+
+  /* Nexthop, ifindex, distance, metric. */
+  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
+    {
+      for (i = 0; i < api.nexthop_num; i++)
+	{
+	  nexthop.s_addr = 0;
+	  ifindex = 0;
+
+	  if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IPV4))
+	    nexthop.s_addr = api.nexthop[i].gw.ipv4.s_addr;
+
+	  if (CHECK_FLAG (api.nexthop[i].type, ZEBRA_NEXTHOP_IFINDEX))
+	    ifindex = api.nexthop[i].intf.index;
+
+	  if (command == ZEBRA_IPV4_ROUTE_ADD)
+	    {
+	    }
+	}
+    }
+
+  return 0;
+}
+
+
+COMPONENT_LINK *
+new_component_link ()
+{
+  COMPONENT_LINK *pComponentLink;
+
+  if ((pComponentLink =
+       (COMPONENT_LINK *) XMALLOC (MTYPE_TE,
+				   sizeof (COMPONENT_LINK))) == NULL)
+    {
+      zlog_err ("\n can not allocate memory %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  pComponentLink->next = NULL;
+  return pComponentLink;
+}
+
+#if 0
+static int
+te_zebra_read_link (int command, struct zclient *zclient, zebra_size_t length)
+{
+  struct stream *s;
+  struct zapi_te_link link;
+  s = zclient->ibuf;
+  zapi_te_link_read(s, &link);
+  switch(command)
+    {
+      case ZEBRA_TE_LINK_ADD:
+{
+  TE_LINK *pTeLink;
+  COMPONENT_LINK *pComponentLink;
+  int ComponentLinksNumber = 1, i, j;
+  PATRICIA_PARAMS params;
+
+  if ((pTeLink = (TE_LINK *) XMALLOC (MTYPE_TE, sizeof (TE_LINK))) == NULL)
+    {
+      zlog_err ("\ncannnot allocate memory");
+      return;
+    }
+  pTeLink->component_links = NULL;
+  pTeLink->te_link_id = link->linkid;
+  pTeLink->type = PSC_PATH;
+  pTeLink->te_link_properties.TeMetric = link->metric;
+  pTeLink->te_link_properties.color_mask = link->color_mask;
+  pTeLink->te_link_properties.MaxLspBW = link->max_lsp_bw;
+  pTeLink->te_link_properties.MaxReservableBW = link->max_res_bw;
+
+  for (j = 0; j < 8; j++)
+    pTeLink->te_link_properties.ReservableBW[j] = 0;
+  for (i = 0; i < ComponentLinksNumber; i++)
+    {
+      if ((pComponentLink = new_component_link ()) == NULL)
+	{
+	  zlog_err ("\ncan initiate component link %s %d", __FILE__,
+		    __LINE__);
+	  return;
+	}
+      params.key_size = sizeof (FRR_LABEL_ENTRY);
+      params.info_size = 0;
+      if (patricia_tree_init (&pComponentLink->ProtectionTree, &params) !=
+	  E_OK)
+	{
+	  zlog_err ("\ncannot initiate patricia tree (per SM) for FRR");
+	  return;
+	}
+
+      params.key_size = sizeof (PSB_KEY);
+      params.info_size = 0;
+      if (patricia_tree_init (&pComponentLink->IngressProtectionTree, &params)
+	  != E_OK)
+	{
+	  zlog_err ("\ncannot initiate patricia tree (per SM) for FRR");
+	  return;
+	}
+      pComponentLink->next = pTeLink->component_links;
+      pTeLink->component_links = pComponentLink;
+      pComponentLink->oifIndex = link->ifindex; /*pTeLink->te_link_id */
+      for (j = 0; j < 8; j++)
+	{
+	  pComponentLink->ReservableBW[j] = link->reservable_bw[j];
+	  pComponentLink->ConfiguredReservableBW[j] = link->reservable_bw[j];
+	  pTeLink->te_link_properties.ReservableBW[j] +=
+	    pComponentLink->ReservableBW[j];
+	}
+    }
+
+  if (rdb_add_te_link (pTeLink) != E_OK)
+    {
+      zlog_err ("\nCannot delete TE link");
+    }
+}
+        break;
+      case ZEBRA_TE_LINK_DELETE:
+  if (rdb_del_te_link (link->linkid) != E_OK)
+    {
+      zlog_err ("\nCannot delete TE link");
+    }
+        break;
+      case ZEBRA_TE_LINK_UPDATE:
+  if (rdb_local_link_status_change (link->linkid, link->status) != E_OK)
+    {
+      zlog_err ("\nCannot set TE link down");
+    }
+
+        break;
+    }
+}
+
+static int
+te_zebra_read_remote_link (int command, struct zclient *zclient, zebra_size_t length)
+{
+  struct zapi_te_remote_link link;
+  struct stream *s;
+  s = zclient->ibuf;
+  zapi_te_remote_link_read(s, &link);
+#if 0
+  switch (command)
+    {
+case RemoteLsUpdate:
+{
+  LINK_PROPERTIES LinkProperties;
+  int j;
+
+  LinkProperties.LinkTeMetric = link->metric;
+  LinkProperties.LinkColorMask = link->color_mask;
+  LinkProperties.LinkMaxLspBW = link->max_lsp_bw;
+  LinkProperties.LinkMaxReservableBW = link->max_res_bw;
+
+  for (j = 0; j < 8; j++)
+    {
+      LinkProperties.LinkReservableBW[j] = link->reservable_bw[j];
+    }
+
+  LinkProperties.LinkType = PSC_PATH;
+
+  if (rdb_link_state_update (link->from_node.s_addr, link->to_node.s_addr, &LinkProperties) != E_OK)
+    {
+      zlog_err ("\nFailure");
+    }
+}
+break;
+case ConnectivityBroken:
+  if (rdb_connectivity_broken (link->from_node.s_addr, link->to_node.s_addr, PSC_PATH) != E_OK)
+    {
+      zlog_err ("\nfailed");
+    }
+break;
+
+    }
+#endif
+}
+
+static int
+te_zebra_read_link2rtrid (int command, struct zclient *zclient, zebra_size_t length)
+{
+  struct zapi_te_link2rtrid l2ri;
+  struct stream *s;
+  s = zclient->ibuf;
+  zapi_te_link2rtrid_read(s, &l2ri);
+  switch (command)
+    {
+      case ZEBRA_TE_LINK2RTRID_ADD:
+  if (rdb_remote_link_2_router_id_mapping (l2ri->linkid, l2ri->routerid.s_addr) != E_OK)
+    {
+      zlog_err ("Cannot map link with ip address %x to router with id %x",
+                l2ri->linkid, l2ri->routerid.s_addr);
+    }
+        break;
+      case ZEBRA_TE_LINK2RTRID_DELETE:
+  if (rdb_remote_link_2_router_id_mapping_withdraw (l2ri->linkid) != E_OK)
+    {
+      zlog_err ("Cannot withdraw mapping of link with ip address %x",
+                l2ri->linkid);
+    }
+        break;
+    }
+}
+
+static int
+te_zebra_read_nexthop (int command, struct zclient *zclient, zebra_size_t length)
+{
+  struct zapi_te_nexthop nh;
+  struct stream *s;
+  s = zclient->ibuf;
+  zapi_te_nexthop_read(s, &nh);
+  switch(command)
+    {
+      case ZEBRA_TE_NEXTHOP_ADD:
+  if (rdb_add_next_hop (nh->nh.gw.ipv4.s_addr, nh->linkid) != E_OK)
+    {
+      zlog_err ("\nCannot add next hop");
+    }
+      case ZEBRA_TE_NEXTHOP_DELETE:
+  if (rdb_del_next_hop (nh->nh.gw.ipv4.s_addr, nh->linkid) != E_OK)
+    {
+      zlog_err ("\nCannot delete Next Hop");
+    }
+
+    }
+}
+#endif
+
+
+void
+rsvp_zebra_init ()
+{
+  /* Allocate zebra structure. */
+  zclient = zclient_new ();
+  zclient_init (zclient, ZEBRA_ROUTE_RSVP);
+  zclient->router_id_update = rsvp_router_id_update_zebra;
+  zclient->interface_add = rsvp_interface_add;
+  zclient->interface_delete = rsvp_interface_delete;
+  zclient->interface_up = rsvp_interface_state_up;
+  zclient->interface_down = rsvp_interface_state_down;
+  zclient->interface_address_add = rsvp_interface_address_add;
+  zclient->interface_address_delete = rsvp_interface_address_delete;
+  zclient->ipv4_route_add = rsvp_zebra_read_ipv4;
+  zclient->ipv4_route_delete = rsvp_zebra_read_ipv4;
+#if 0
+  zclient->te_link_add = te_zebra_read_link;
+  zclient->te_link_delete = te_zebra_read_link;
+  zclient->te_link_update = te_zebra_read_link;
+  zclient->te_link_remote_update = te_zebra_read_remote_link;
+  zclient->te_link2rtrid_add = te_zebra_read_link2rtrid;
+  zclient->te_link2rtrid_delete = te_zebra_read_link2rtrid;
+  zclient->te_nexthop_add = te_zebra_read_nexthop;
+  zclient->te_nexthop_delete = te_zebra_read_nexthop;
+#endif
+
+  zclient_redistribute (ZEBRA_REDISTRIBUTE_ADD, zclient, ZEBRA_ROUTE_TE);
+#if 0
+  rdb_igp_hello();
+#endif
+}
diff -Naur quagga-0.99.10/rsvpd/rsvp_zebra.h quagga-mpls/rsvpd/rsvp_zebra.h
--- quagga-0.99.10/rsvpd/rsvp_zebra.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/rsvp_zebra.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,28 @@
+/*
+ * Zebra connect library for RSVPd
+ * Copyright (C) 1997, 98, 99, 2000 Kunihiro Ishiguro, Toshiaki Takada
+ *
+ * This file is part of GNU Zebra.
+ *
+ * GNU Zebra is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2, or (at your option) any
+ * later version.
+ *
+ * GNU Zebra is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU Zebra; see the file COPYING.  If not, write to the
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330,
+ * Boston, MA 02111-1307, USA. 
+ */
+
+#ifndef _ZEBRA_RSVP_ZEBRA_H
+#define _ZEBRA_RSVP_ZEBRA_H
+
+extern void rsvp_zebra_init (void);
+
+#endif /* _ZEBRA_RSVP_ZEBRA_H */
diff -Naur quagga-0.99.10/rsvpd/te_api.c quagga-mpls/rsvpd/te_api.c
--- quagga-0.99.10/rsvpd/te_api.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_api.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,157 @@
+/* Module:   api.c
+   Contains: TE application in-process API functions
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "te.h"
+
+#define MAX_FLOAT 40000000000.0
+
+void
+TE_RSVPTE_API_TransitReqAPI (TE_API_MSG * dmsg)
+{
+  SM_T *pNewSm;
+  PATH_NOTIFICATION *pTransitRequest;
+  PSB_KEY PsbKey;
+  SM_CALL_T *pCall;
+
+  if ((pTransitRequest =
+       (PATH_NOTIFICATION *) XMALLOC (MTYPE_TE,
+				      sizeof (PATH_NOTIFICATION))) == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      return;
+    }
+
+  memcpy (pTransitRequest, &dmsg->u.PathNotification,
+	  sizeof (PATH_NOTIFICATION));
+
+  PsbKey = pTransitRequest->PsbKey;
+
+  pNewSm = sm_gen_alloc (0, TRANSIT_LSP_SM);
+  if (pNewSm == NULL)
+    {
+      zlog_err ("fatal %s %d\n", __FILE__, __LINE__);
+      return;
+    }
+  if ((pCall =
+       sm_gen_sync_event_send (pNewSm, TRANSIT_REQ_EVENT,
+			       pTransitRequest)) == NULL)
+    {
+      zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+      return;
+    }
+  sm_call (pCall);
+  return;
+}
+
+void
+TE_IGP_API_PathAdd (void *pBuf, int Len)
+{
+  char *p;
+  PATH *pPath;
+  IPV4_ADDR dest_ip;
+  TE_HOP *er_hops;
+  float PathMinReservableBW[8], PathMaxBW = MAX_FLOAT, PathMaxReservableBW = MAX_FLOAT;	/*FIXME!! */
+  int hop_count, i, j, SumTeMetric = 0;
+  zlog_info ("PathAdd");
+
+
+  pBuf += sizeof (EVENTS_E);
+  Len -= sizeof (EVENTS_E);
+  p = pBuf;
+  dest_ip = *((int *) p);
+  p += sizeof (int);
+  Len -= sizeof (int);
+  if (Len % 56)
+    {
+      zlog_err
+	("The payload after destination field is not %d-alligned %d %d",
+	 Len % 56, Len, sizeof (TE_HOP));
+      return;
+    }
+  hop_count = Len / sizeof (TE_HOP);
+  pPath = (PATH *) XMALLOC (MTYPE_TE, sizeof (PATH));
+  if (pPath == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return;
+    }
+  memset (pPath, 0, sizeof (PATH));
+  er_hops = (TE_HOP *) XMALLOC (MTYPE_TE, sizeof (TE_HOP) * hop_count);
+  if (er_hops == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return;
+    }
+  for (i = 0; i < 8; i++)
+    {
+      PathMinReservableBW[i] = MAX_FLOAT;
+    }
+
+  for (i = 0; i < hop_count; i++)
+    {
+      er_hops[i].local_ip = *((int *) p);
+      p += sizeof (int);
+      er_hops[i].remote_ip = *((int *) p);
+      p += sizeof (int);
+      er_hops[i].MaxReservableBW = *((float *) p);
+      p += sizeof (float);
+      for (j = 0; j < 8; j++)
+	{
+	  er_hops[i].ReservableBW[j] = *((float *) p);
+	  p += sizeof (float);
+	}
+      er_hops[i].MaxLspBW = *((float *) p);
+      if (er_hops[i].MaxLspBW < PathMaxBW)
+	PathMaxBW = er_hops[i].MaxLspBW;
+      p += sizeof (float);
+
+      for (j = 0; j < 8; j++)
+	{
+	  if (er_hops[i].ReservableBW[j] < PathMinReservableBW[j])
+	    PathMinReservableBW[j] = er_hops[i].ReservableBW[j];
+	}
+      er_hops[i].te_metric = *((int *) p);
+      p += sizeof (int);
+      SumTeMetric += er_hops[i].te_metric;
+      er_hops[i].ColorMask = *((int *) p);
+      p += sizeof (int);
+      if (er_hops[i].MaxReservableBW < PathMaxReservableBW)
+	PathMaxReservableBW = er_hops[i].MaxReservableBW;
+    }
+  if (hop_count == 0)
+    er_hops = NULL;
+  pPath->u.er_hops = er_hops;
+  pPath->PathProperties.PathType = PSC_PATH;
+  pPath->PathProperties.PathHopCount = hop_count;
+  pPath->PathProperties.PathMaxLspBW = PathMaxBW;
+  pPath->PathProperties.PathMaxReservableBW = PathMaxReservableBW;
+
+  for (j = 0; j < 8; j++)
+    pPath->PathProperties.PathReservableBW[j] = PathMinReservableBW[j];
+
+  pPath->PathProperties.PathSumTeMetric = SumTeMetric;
+  pPath->destination = dest_ip;
+  if (rdb_add_mod_path (dest_ip, pPath) != E_OK)
+    {
+      zlog_err ("Cannot add path");
+    }
+}
+
+void
+TE_IGP_API_ReadPathCash (void *pBuf, int Len)
+{
+  IPV4_ADDR IpAddr;
+  int handle;
+  char *p;
+
+  pBuf += sizeof (EVENTS_E);
+  Len -= sizeof (EVENTS_E);
+  p = pBuf;
+
+  IpAddr = *((int *) p);
+  p += sizeof (int);
+  handle = *((int *) p);
+  p += sizeof (int);
+  CspfReply (IpAddr, (void *) handle);
+}
diff -Naur quagga-0.99.10/rsvpd/te_api.h quagga-mpls/rsvpd/te_api.h
--- quagga-0.99.10/rsvpd/te_api.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_api.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,8 @@
+#ifndef __TE_API_H__
+#define __TE_API_H__
+
+void TE_RSVPTE_API_TransitReqAPI (TE_API_MSG * dmsg);
+void TE_IGP_API_ReadPathCash (void *pBuf, int Len);
+void TE_IGP_API_PathAdd (void *pBuf, int Len);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te_bw_man.c quagga-mpls/rsvpd/te_bw_man.c
--- quagga-0.99.10/rsvpd/te_bw_man.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_bw_man.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,1408 @@
+/* Module:   bw_man.c
+   Contains: TE application bandwidth manager
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "te.h"
+#include "te_cspf.h"
+
+extern PATRICIA_TREE BwOwnersTree[8];
+extern PATRICIA_TREE IfBwOwnersTree[8];
+extern struct zclient *zclient;
+
+typedef struct
+{
+  uns32 IfIndex;
+  PSB_KEY PsbKey;
+} IF_BW_KEY;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  IF_BW_KEY if_bw_key;
+  float BW;
+} IF_BW_DATA;
+
+static void CancelBwAllocAtHigherPriorities (PSB_KEY * key,
+					     uns32 TeLinkId,
+					     COMPONENT_LINK * pComponentLink,
+					     uns8 Priority);
+static void CancelBwAllocAtLowerPriorities (PSB_KEY * key,
+					    uns32 TeLinkId,
+					    COMPONENT_LINK * pComponentLink,
+					    uns8 Priority);
+static void CancelBwAllocAtOtherPriorities (PSB_KEY * key,
+					    uns32 TeLinkId,
+					    COMPONENT_LINK * pComponentLink,
+					    uns8 Priority);
+static float PreemptTunnel (uns32 TeLinkId,
+			    COMPONENT_LINK * pComponentLink,
+			    uns8 Priority, uns8 PreemptorPrio, PSB_KEY * key);
+static void GetEfficientBwAtHigherPriorities (PSB_KEY * key,
+					      uns32 TeLinkId,
+					      COMPONENT_LINK * pComponentLink,
+					      uns8 Priority, float *BW);
+static uns32 UpdateIfBwOwnerStructure (uns32 IfIndex, PSB_KEY * key, float BW,
+				       uns8 Priority);
+static BOOL BwPreemptionUseful (uns32 IfIndex, uns8 SetupPriority,
+				float RequiredBW, uns8 * PreemptedPriority,
+				float *MaximumPossibleBW);
+static void AllocateBW (TE_LINK * pTeLink, COMPONENT_LINK * pComponentLink,
+			uns8 Priority, float BW);
+static void ReleaseBW (TE_LINK * pTeLink, COMPONENT_LINK * pComponentLink,
+		       uns8 Priority, float BW);
+static void PreemptBW (COMPONENT_LINK * pComponentLink,
+		       uns8 PreemptorPriority, uns8 PreemptedPriority,
+		       float BW);
+
+typedef struct
+{
+  int Event;
+  BW_UPDATE_REQUEST BwUpdateReq;
+} BW_UPDATE_MSG;
+
+void
+BwUpdateRequest2Igp (TE_LINK * pTeLink)
+{
+#if 0
+  struct zapi_te_link link;
+  int i;
+
+  memset(&link, 0, sizeof(struct zapi_te_link));
+  link.linkid = pTeLink->te_link_id;
+  link.max_res_bw = pTeLink->te_link_properties.MaxReservableBW;
+  
+  for (i = 0; i < 8; i++)
+    link.reservable_bw[i] = pTeLink->te_link_properties.ReservableBW[i];
+
+  zapi_te_link_update(zclient, &link);
+#endif
+}
+
+static void
+CancelBwAllocAtHigherPriorities (PSB_KEY * key,
+				 uns32 TeLinkId,
+				 COMPONENT_LINK * pComponentLink,
+				 uns8 Priority)
+{
+  BW_OWNER_ENTRY *pBwOwnerEntry;
+  BW_OWNER_DATA *pBwOwnerData, *pBwOwnerDataPrev = NULL;
+  TE_LINK *pTeLink;
+  int j;
+
+  if (Priority == 0)
+    return;
+
+  if (rdb_get_te_link (TeLinkId, &pTeLink) != E_OK)
+    {
+      zlog_err ("\ncannot get TE link %s %d", __FILE__, __LINE__);
+      return;
+    }
+  for (j = 0; j < Priority; j++)
+    {
+      if ((pBwOwnerEntry =
+	   (BW_OWNER_ENTRY *) patricia_tree_get (&BwOwnersTree[j],
+						 (const uns8 *) key)) != NULL)
+	{
+	  pBwOwnerData = pBwOwnerEntry->pBwOwnerData;
+	  while (pBwOwnerData != NULL)
+	    {
+	      if ((pBwOwnerData->TeLinkId == TeLinkId) &&
+		  (pBwOwnerData->OutIf == pComponentLink->oifIndex))
+		{
+		  ReleaseBW (pTeLink, pComponentLink, Priority,
+			     pBwOwnerData->BW + pBwOwnerData->PreAllocBW);
+		  if (pBwOwnerEntry->pBwOwnerData == pBwOwnerData)
+		    pBwOwnerEntry->pBwOwnerData =
+		      pBwOwnerEntry->pBwOwnerData->next;
+		  else
+		    pBwOwnerDataPrev->next = pBwOwnerData->next;
+		  XFREE (MTYPE_TE, pBwOwnerData);
+		  if (pBwOwnerEntry->pBwOwnerData == NULL)
+		    {
+		      zlog_info ("\nBW Owners Entry will be deleted2");
+		      if (patricia_tree_del
+			  (&BwOwnersTree[j], &pBwOwnerEntry->Node) != E_OK)
+			{
+			  zlog_err
+			    ("\ncannot delete node from patricia %s %d",
+			     __FILE__, __LINE__);
+			}
+		      else
+			XFREE (MTYPE_TE, pBwOwnerEntry);
+		    }
+		  break;
+		}
+	      pBwOwnerData = pBwOwnerData->next;
+	    }
+	}
+    }
+}
+
+static void
+CancelBwAllocAtLowerPriorities (PSB_KEY * key,
+				uns32 TeLinkId,
+				COMPONENT_LINK * pComponentLink,
+				uns8 Priority)
+{
+  BW_OWNER_ENTRY *pBwOwnerEntry;
+  BW_OWNER_DATA *pBwOwnerData, *pBwOwnerDataPrev = NULL;
+  TE_LINK *pTeLink;
+  int j;
+
+  if (rdb_get_te_link (TeLinkId, &pTeLink) != E_OK)
+    {
+      zlog_err ("\ncannot get TE link %s %d", __FILE__, __LINE__);
+      return;
+    }
+  for (j = Priority + 1; j < 8; j++)
+    {
+      if ((pBwOwnerEntry =
+	   (BW_OWNER_ENTRY *) patricia_tree_get (&BwOwnersTree[j],
+						 (const uns8 *) key)) != NULL)
+	{
+	  pBwOwnerData = pBwOwnerEntry->pBwOwnerData;
+	  while (pBwOwnerData != NULL)
+	    {
+	      if ((pBwOwnerData->TeLinkId == TeLinkId) &&
+		  (pBwOwnerData->OutIf == pComponentLink->oifIndex))
+		{
+		  ReleaseBW (pTeLink, pComponentLink, Priority,
+			     pBwOwnerData->BW + pBwOwnerData->PreAllocBW);
+		  if (pBwOwnerEntry->pBwOwnerData == pBwOwnerData)
+		    pBwOwnerEntry->pBwOwnerData =
+		      pBwOwnerEntry->pBwOwnerData->next;
+		  else
+		    pBwOwnerDataPrev->next = pBwOwnerData->next;
+		  XFREE (MTYPE_TE, pBwOwnerData);
+		  if (pBwOwnerEntry->pBwOwnerData == NULL)
+		    {
+		      zlog_info ("\nBW Owners Entry will be deleted2");
+		      if (patricia_tree_del
+			  (&BwOwnersTree[j], &pBwOwnerEntry->Node) != E_OK)
+			{
+			  zlog_err
+			    ("\ncannot delete node from patricia %s %d",
+			     __FILE__, __LINE__);
+			}
+		      else
+			XFREE (MTYPE_TE, pBwOwnerEntry);
+		    }
+		  break;
+		}
+	      pBwOwnerData = pBwOwnerData->next;
+	    }
+	}
+    }
+}
+
+static void
+CancelBwAllocAtOtherPriorities (PSB_KEY * key,
+				uns32 TeLinkId,
+				COMPONENT_LINK * pComponentLink,
+				uns8 Priority)
+{
+  CancelBwAllocAtHigherPriorities (key, TeLinkId, pComponentLink, Priority);
+  CancelBwAllocAtLowerPriorities (key, TeLinkId, pComponentLink, Priority);
+  return;
+}
+
+static void
+GetEfficientBwAtHigherPriorities (PSB_KEY * key,
+				  uns32 TeLinkId,
+				  COMPONENT_LINK * pComponentLink,
+				  uns8 Priority, float *BW)
+{
+  BW_OWNER_ENTRY *pBwOwnerEntry;
+  BW_OWNER_DATA *pBwOwnerData;
+  int j, i, k;
+  float AllocBW[8], AllocatedBW[8][8], ReservableBW[8], ReleasedBW = 0;
+
+  memset (AllocBW, 0, sizeof (AllocBW));
+  memcpy (AllocatedBW, pComponentLink->AllocatedBW, sizeof (AllocatedBW));
+  memcpy (ReservableBW, pComponentLink->ReservableBW, sizeof (ReservableBW));
+
+  for (j = 0; j < Priority; j++)
+    {
+      if ((pBwOwnerEntry =
+	   (BW_OWNER_ENTRY *) patricia_tree_get (&BwOwnersTree[j],
+						 (const uns8 *) key)) != NULL)
+	{
+	  pBwOwnerData = pBwOwnerEntry->pBwOwnerData;
+
+	  while (pBwOwnerData != NULL)
+	    {
+	      if ((pBwOwnerData->TeLinkId == TeLinkId) &&
+		  (pBwOwnerData->OutIf == pComponentLink->oifIndex))
+		{
+		  AllocBW[j] = pBwOwnerData->BW + pBwOwnerData->PreAllocBW;
+		  break;
+		}
+	      pBwOwnerData = pBwOwnerData->next;
+	    }
+	}
+    }
+  for (k = 0; k < 8; k++)
+    {
+      for (i = 0; (i < 8) && (BW > 0); i++)
+	{
+	  if (AllocatedBW[i][i] > 0)
+	    {
+	      ReleasedBW = 0;
+	      if (AllocBW[k] >= AllocatedBW[i][i])
+		{
+		  ReleasedBW = AllocatedBW[i][i];
+		  ReservableBW[i] += AllocatedBW[i][i];
+		  AllocBW[k] -= AllocatedBW[i][i];
+		  AllocatedBW[i][i] = 0;
+		}
+	      else
+		{
+		  ReleasedBW = AllocBW[k];
+		  ReservableBW[i] += AllocBW[k];
+		  AllocatedBW[i][i] -= AllocBW[k];
+		  AllocBW[k] = 0;
+		}
+	      for (j = i + 1; (j < 8) && (ReleasedBW > 0); j++)
+		{
+		  if (AllocatedBW[i][j] > 0)
+		    {
+		      if (ReleasedBW >= AllocatedBW[i][j])
+			{
+			  AllocatedBW[j][j] += AllocatedBW[i][j];
+			  ReleasedBW -= AllocatedBW[i][j];
+			  AllocatedBW[i][j] = 0;
+			}
+		      else
+			{
+			  AllocatedBW[j][j] += ReleasedBW;
+			  AllocatedBW[i][j] -= ReleasedBW;
+			  ReleasedBW = 0;
+			}
+		    }
+		}
+	    }
+	}
+      if (ReleasedBW > 0)
+	{
+	  for (; i < 8; i++)
+	    {
+	      if (AllocatedBW[i][i] > 0)
+		{
+		  break;
+		}
+	      if (pComponentLink->ConfiguredReservableBW[i] > ReservableBW[i])
+		{
+		  if ((ReservableBW[i] + ReleasedBW) <=
+		      pComponentLink->ConfiguredReservableBW[i])
+		    {
+		      ReservableBW[i] += ReleasedBW;
+		    }
+		  else
+		    {
+		      ReservableBW[i] =
+			pComponentLink->ConfiguredReservableBW[i];
+		    }
+		}
+	    }
+	}
+    }
+  if (ReservableBW[Priority] >= pComponentLink->ReservableBW[Priority])
+    {
+      *BW = ReservableBW[Priority] - pComponentLink->ReservableBW[Priority];
+    }
+  else
+    {
+      *BW = 0;
+    }
+  return;
+}
+
+static float
+PreemptTunnel (uns32 TeLinkId,
+	       COMPONENT_LINK * pComponentLink,
+	       uns8 Priority, uns8 PreemptorPrio, PSB_KEY * key)
+{
+  IF_BW_KEY if_bw_key;
+  IF_BW_DATA *pIfBwEntry;
+  PSB_KEY PsbKey;
+  TE_API_MSG Msg;
+  float BW = 0;
+  memset (&if_bw_key, 0, sizeof (IF_BW_KEY));
+  if_bw_key.IfIndex = pComponentLink->oifIndex;
+  if ((pIfBwEntry =
+       (IF_BW_DATA *) patricia_tree_getnext (&IfBwOwnersTree[Priority],
+					     (const uns8 *) &if_bw_key)) !=
+      NULL)
+    {
+      PsbKey = pIfBwEntry->if_bw_key.PsbKey;
+      BW = pIfBwEntry->BW;
+      if (patricia_tree_del (&IfBwOwnersTree[Priority], &pIfBwEntry->Node) !=
+	  E_OK)
+	{
+	  zlog_err ("\ncannot delete node %s %d", __FILE__, __LINE__);
+	}
+      else
+	{
+	  XFREE (MTYPE_TE, pIfBwEntry);
+	}
+      if (memcmp (&PsbKey, key, sizeof (PSB_KEY)) != 0)
+	{
+	  Msg.NotificationType = PREEMPT_FLOW_CMD;
+	  Msg.u.PreemptFlow.RsbKey.Session = PsbKey.Session;
+	  if ((PsbKey.SenderTemplate.IpAddr != 0) ||
+	      (PsbKey.SenderTemplate.LspId != 0))
+	    {
+	      Msg.u.PreemptFlow.FilterSpecValid = 1;
+	      Msg.u.PreemptFlow.FilterSpec = PsbKey.SenderTemplate;
+	    }
+	  else
+	    {
+	      Msg.u.PreemptFlow.FilterSpecValid = 0;
+	    }
+	  PreemptBW (pComponentLink, PreemptorPrio, Priority, BW);
+	}
+    }
+  return BW;
+}
+
+static uns32
+UpdateIfBwOwnerStructure (uns32 IfIndex, PSB_KEY * key, float BW,
+			  uns8 Priority)
+{
+  IF_BW_KEY if_bw_key;
+  IF_BW_DATA *pIfBwEntry;
+  memset (&if_bw_key, 0, sizeof (IF_BW_KEY));
+  if_bw_key.IfIndex = IfIndex;
+  if_bw_key.PsbKey = *key;
+  if ((pIfBwEntry =
+       (IF_BW_DATA *) patricia_tree_get (&IfBwOwnersTree[Priority],
+					 (const uns8 *) &if_bw_key)) == NULL)
+    {
+      if ((pIfBwEntry =
+	   (IF_BW_DATA *) XMALLOC (MTYPE_TE, sizeof (IF_BW_DATA))) == NULL)
+	{
+	  zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pIfBwEntry->if_bw_key.IfIndex = IfIndex;
+      pIfBwEntry->if_bw_key.PsbKey = *key;
+      pIfBwEntry->BW = BW;
+      pIfBwEntry->Node.key_info = (uns8 *) & pIfBwEntry->if_bw_key;
+      if (patricia_tree_add (&IfBwOwnersTree[Priority], &pIfBwEntry->Node) !=
+	  E_OK)
+	{
+	  zlog_err ("\ncannot add node to patricia tree %s %d", __FILE__,
+		    __LINE__);
+	  return E_ERR;
+	}
+    }
+  else
+    {
+      pIfBwEntry->BW = BW;
+    }
+  return E_OK;
+}
+
+static BOOL
+BwPreemptionUseful (uns32 IfIndex, uns8 SetupPriority, float RequiredBW,
+		    uns8 * PreemptedPriority, float *MaximumPossibleBW)
+{
+  IF_BW_KEY if_bw_key;
+  IF_BW_DATA *pIfBwEntry;
+  int j;
+  zlog_info ("entering BwPreemptionUseful");
+  (*MaximumPossibleBW) = 0;
+  memset (&if_bw_key, 0, sizeof (IF_BW_KEY));
+  if_bw_key.IfIndex = IfIndex;
+  for (j = SetupPriority + 1; j < 8; j++)
+    {
+      while ((pIfBwEntry =
+	      (IF_BW_DATA *) patricia_tree_getnext (&IfBwOwnersTree[j],
+						    (const uns8 *)
+						    &if_bw_key)) != NULL)
+	{
+	  (*MaximumPossibleBW) += pIfBwEntry->BW;
+	  if ((*MaximumPossibleBW) >= RequiredBW)
+	    {
+	      *PreemptedPriority = j;
+	      zlog_info ("leaving BwPreemptionUseful+");
+	      return TRUE;
+	    }
+	  if_bw_key = pIfBwEntry->if_bw_key;
+	}
+    }
+  zlog_info ("leaving BwPreemptionUseful-");
+  return FALSE;
+}
+
+void
+TE_RSVPTE_API_BwReleaseMessage (TE_API_MSG * dmsg)
+{
+  zlog_info
+    ("\nBW release If %x dest %x tunnel id %x ext tunnel id %x Priority %x",
+     dmsg->u.BwRelease.IfIndex, dmsg->u.BwRelease.PsbKey.Session.Dest,
+     dmsg->u.BwRelease.PsbKey.Session.TunnelId,
+     dmsg->u.BwRelease.PsbKey.Session.ExtTunelId, dmsg->u.BwRelease.HoldPrio);
+
+  if (DoRelease (&dmsg->u.BwRelease.PsbKey,
+		 dmsg->u.BwRelease.IfIndex /* temporary */ ,
+		 dmsg->u.BwRelease.IfIndex,
+		 dmsg->u.BwRelease.HoldPrio /*??? */ ) != E_OK)
+    {
+      zlog_info ("\nBW release failed %s %d", __FILE__, __LINE__);
+    }
+  zlog_info ("\nAfter release...........");
+  return;
+}
+
+uns32
+DoPreBwAllocation (PSB_KEY * key,
+		   uns32 TeLinkId,
+		   COMPONENT_LINK * pComponentLink,
+		   float BW, uns8 HoldPriority)
+{
+  BW_OWNER_ENTRY *pBwOwnerEntry;
+  BW_OWNER_DATA *pBwOwnerData;
+
+  /* First - register an allocation on the BW owners tree 
+     BW owner is the session if SE reservation style or 
+     Session and Sender if FF reservation style 
+     BW owners tree serves for the prevention of the double accounting
+     Upon the Path message, existing reservations are found
+     Additional BW is attempted to be allocated on the links,
+     where reservation already exists */
+  zlog_info ("inside of DoPreAlloc Hold %x BW %f Dest %x TunnelId %x Src %x",
+	     HoldPriority, BW, key->Session.Dest, key->Session.TunnelId,
+	     key->Session.ExtTunelId, key->SenderTemplate.IpAddr,
+	     key->SenderTemplate.LspId);
+  if ((pBwOwnerEntry =
+       (BW_OWNER_ENTRY *) patricia_tree_get (&BwOwnersTree[HoldPriority],
+					     (const uns8 *) key)) == NULL)
+    {
+      if ((pBwOwnerEntry =
+	   (BW_OWNER_ENTRY *) XMALLOC (MTYPE_TE,
+				       sizeof (BW_OWNER_ENTRY))) == NULL)
+	{
+	  zlog_err ("\nFailed to allocate memory %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pBwOwnerEntry->key = *key;
+      zlog_info ("\nBW owner entry creation %x %x %x %x %x...",
+		 pBwOwnerEntry->key.Session.Dest,
+		 pBwOwnerEntry->key.Session.TunnelId,
+		 pBwOwnerEntry->key.Session.ExtTunelId,
+		 pBwOwnerEntry->key.SenderTemplate.IpAddr,
+		 pBwOwnerEntry->key.SenderTemplate.LspId);
+      pBwOwnerEntry->Node.key_info = (uns8 *) & pBwOwnerEntry->key;
+      zlog_info ("\ninside of DoPreAlloc adding to %x", HoldPriority);
+      if (patricia_tree_add (&BwOwnersTree[HoldPriority],
+			     &pBwOwnerEntry->Node) != E_OK)
+	{
+	  zlog_err ("\nFailed to allocate memory %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+    }
+  else
+    zlog_info ("\nBW owner entry found %x %x %x %x %x...",
+	       key->Session.Dest,
+	       key->Session.TunnelId,
+	       key->Session.ExtTunelId,
+	       key->SenderTemplate.IpAddr, key->SenderTemplate.LspId);
+  /* however, pBwOwnerEntry points on new or existing BW entry now 
+     find the existing reservation */
+  pBwOwnerData = pBwOwnerEntry->pBwOwnerData;
+  while (pBwOwnerData != NULL)
+    {
+      if ((pBwOwnerData->TeLinkId == TeLinkId) &&
+	  (pBwOwnerData->OutIf == pComponentLink->oifIndex))
+	{
+	  if (pBwOwnerData->BW <= BW)
+	    {
+	      if ((pBwOwnerData->PreAllocBW + pBwOwnerData->BW) >= BW)
+		{
+		  if (pBwOwnerData->PreAllocBW <= BW)
+		    {
+		      te_stop_timer (&pBwOwnerData->BwHoldTimer);
+		      pBwOwnerData->BwHoldTimer.data.bw_hold_data.BW +=
+			(BW - pBwOwnerData->PreAllocBW);
+		      pBwOwnerData->PreAllocBW +=
+			(BW - pBwOwnerData->PreAllocBW);
+		      if (te_start_timer
+			  (&pBwOwnerData->BwHoldTimer, BW_HOLD_EXPIRY,
+			   30) != E_OK)
+			{
+			  zlog_err ("\ncannot start BW hold timer %s %d",
+				    __FILE__, __LINE__);
+			}
+		    }
+		  else
+		    {		/* just resttart the timer */
+		      te_stop_timer (&pBwOwnerData->BwHoldTimer);
+		      if (te_start_timer
+			  (&pBwOwnerData->BwHoldTimer, BW_HOLD_EXPIRY,
+			   30) != E_OK)
+			{
+			  zlog_err ("\ncannot start BW hold timer %s %d",
+				    __FILE__, __LINE__);
+			}
+		    }
+		}
+	      else
+		{
+		  if (BW <=
+		      (pComponentLink->ReservableBW[HoldPriority] +
+		       (pBwOwnerData->PreAllocBW + pBwOwnerData->BW)))
+		    {
+		      float delta;
+		      delta =
+			BW - (pBwOwnerData->PreAllocBW + pBwOwnerData->BW);
+
+		      te_stop_timer (&pBwOwnerData->BwHoldTimer);
+
+		      pBwOwnerData->PreAllocBW += delta;
+		      pBwOwnerData->BwHoldTimer.data.bw_hold_data.BW += delta;
+
+		      if (te_start_timer
+			  (&pBwOwnerData->BwHoldTimer, BW_HOLD_EXPIRY,
+			   30) != E_OK)
+			{
+			  zlog_err ("\ncannot start BW hold timer %s %d",
+				    __FILE__, __LINE__);
+			}
+		      else
+			{
+			  TE_LINK *pTeLink = NULL;
+
+			  if (rdb_get_te_link (TeLinkId, &pTeLink) != E_OK)
+			    {
+			      zlog_err ("\ncannot get TE link %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+			  AllocateBW (pTeLink, pComponentLink, HoldPriority,
+				      delta);
+			  rdb_te_link_max_lsp_bw_calc (pTeLink);
+			  BwUpdateRequest2Igp (pTeLink);
+			}
+		    }
+		  else
+		    {
+		      zlog_err
+			("CALCULATION ERROR: expected to find BW %f %f !!!",
+			 BW, pComponentLink->ReservableBW[HoldPriority]);
+		      zlog_err
+			("TE link id %x OutIf %x dest %x tunnel %x ext tunnel %x lsp id %x",
+			 TeLinkId, pComponentLink->oifIndex,
+			 key->Session.Dest, key->Session.TunnelId,
+			 key->Session.ExtTunelId, key->SenderTemplate.LspId);
+		      return E_ERR;
+		    }
+		}
+	    }
+	  if (UpdateIfBwOwnerStructure (pComponentLink->oifIndex,
+					key,
+					pBwOwnerData->PreAllocBW +
+					pBwOwnerData->BW,
+					HoldPriority) != E_OK)
+	    {
+	      zlog_err ("\ncannot update IfBwOwnerStrucutre %s %d", __FILE__,
+			__LINE__);
+	      return E_ERR;
+	    }
+	  zlog_info ("\ninside of %x...", pComponentLink->oifIndex);
+	  return E_OK;
+	}
+      pBwOwnerData = pBwOwnerData->next;
+    }
+  if (pComponentLink->ReservableBW[HoldPriority] < BW)
+    {
+      zlog_err ("\nCALCULATION ERROR: expected to find BW %f %f !!!",
+		BW, pComponentLink->ReservableBW[HoldPriority]);
+      zlog_err
+	("\nTE link id %x OutIf %x dest %x tunnel %x ext tunnel %x lsp id %x",
+	 TeLinkId, pComponentLink->oifIndex, key->Session.Dest,
+	 key->Session.TunnelId, key->Session.ExtTunelId,
+	 key->SenderTemplate.LspId);
+      return E_ERR;
+    }
+  /* BW reservation does not exist on the particular TE link and If */
+  if ((pBwOwnerData =
+       (BW_OWNER_DATA *) XMALLOC (MTYPE_TE, sizeof (BW_OWNER_DATA))) == NULL)
+    {
+      zlog_err ("\nFailed to allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  pBwOwnerData->next = pBwOwnerEntry->pBwOwnerData;
+  pBwOwnerEntry->pBwOwnerData = pBwOwnerData;
+  pBwOwnerData->BW = 0;
+  pBwOwnerData->PreAllocBW = BW;
+  pBwOwnerData->OutIf = pComponentLink->oifIndex;
+  pBwOwnerData->TeLinkId = TeLinkId;
+
+  pBwOwnerData->BwHoldTimer.data.bw_hold_data.key = *key;
+  pBwOwnerData->BwHoldTimer.data.bw_hold_data.handle = (uns32) pBwOwnerData;
+  pBwOwnerData->BwHoldTimer.data.bw_hold_data.TeLinkId = TeLinkId;
+  pBwOwnerData->BwHoldTimer.data.bw_hold_data.OutIf =
+    pComponentLink->oifIndex;
+  pBwOwnerData->BwHoldTimer.data.bw_hold_data.BW = BW;
+  pBwOwnerData->BwHoldTimer.data.bw_hold_data.Priority = HoldPriority;
+  if (te_start_timer (&pBwOwnerData->BwHoldTimer, BW_HOLD_EXPIRY, 30) != E_OK)
+    {
+      zlog_err ("\ncannot start BW hold timer %s %d", __FILE__, __LINE__);
+    }
+  else
+    {
+      TE_LINK *pTeLink = NULL;
+
+      if (rdb_get_te_link (TeLinkId, &pTeLink) != E_OK)
+	{
+	  zlog_err ("\ncannot get TE link %s %d", __FILE__, __LINE__);
+	}
+      zlog_info ("calling ALLOCATE");
+      AllocateBW (pTeLink, pComponentLink, HoldPriority, BW);
+      rdb_te_link_max_lsp_bw_calc (pTeLink);
+      BwUpdateRequest2Igp (pTeLink);
+    }
+  if (UpdateIfBwOwnerStructure
+      (pComponentLink->oifIndex, key, BW, HoldPriority) != E_OK)
+    {
+      zlog_err ("cannot update IfBwOwnerStructure %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+uns32
+CalcActualAlloc (PSB_KEY * key,
+		 uns32 TeLinkId,
+		 COMPONENT_LINK * pComponentLink,
+		 float *BW,
+		 uns8 SetupPriority,
+		 uns8 HoldPriority, uns8 * PreemptedPriority)
+{
+  BW_OWNER_ENTRY *pBwOwnerEntry;
+  BW_OWNER_DATA *pBwOwnerData;
+  float BwAtHigherPriority;
+
+  GetEfficientBwAtHigherPriorities (key, TeLinkId, pComponentLink,
+				    HoldPriority, &BwAtHigherPriority);
+
+  zlog_info ("\n%x %x %x %x %f",
+	     key->Session.Dest,
+	     key->Session.TunnelId,
+	     key->Session.ExtTunelId,
+	     key->SenderTemplate.LspId, BwAtHigherPriority);
+
+  if ((pBwOwnerEntry =
+       (BW_OWNER_ENTRY *) patricia_tree_get (&BwOwnersTree[HoldPriority],
+					     (const uns8 *) key)) != NULL)
+    {
+      pBwOwnerData = pBwOwnerEntry->pBwOwnerData;
+      while (pBwOwnerData != NULL)
+	{
+	  if ((pBwOwnerData->TeLinkId == TeLinkId) &&
+	      (pBwOwnerData->OutIf == pComponentLink->oifIndex))
+	    {
+	      if ((pBwOwnerData->PreAllocBW + pBwOwnerData->BW +
+		   BwAtHigherPriority) >= *BW)
+		{
+		  zlog_info ("Additional allocation is not required: %f %f",
+			     pBwOwnerData->PreAllocBW + pBwOwnerData->BW,
+			     *BW);
+		  *BW = 0;
+		  return E_OK;
+		}
+	      else if ((pComponentLink->ReservableBW[SetupPriority] +
+			pBwOwnerData->PreAllocBW + pBwOwnerData->BW +
+			BwAtHigherPriority) >= *BW)
+		{
+		  zlog_info
+		    ("Reservable#%f, alloc %f and higher prio alloc %f",
+		     pComponentLink->ReservableBW[SetupPriority],
+		     pBwOwnerData->PreAllocBW + pBwOwnerData->BW,
+		     BwAtHigherPriority);
+		  *BW =
+		    *BW - (pBwOwnerData->PreAllocBW + pBwOwnerData->BW +
+			   BwAtHigherPriority);
+		  return E_OK;
+		}
+	      else
+		{
+		  float RequiredBW =
+		    *BW - (pComponentLink->ReservableBW[SetupPriority] +
+			   pBwOwnerData->PreAllocBW + pBwOwnerData->BW);
+		  uns8 Preempted;
+		  float MaximumPossibleBW;
+		  /* checking for bumping possibilities */
+		  if (BwPreemptionUseful
+		      (pComponentLink->oifIndex, SetupPriority, RequiredBW,
+		       &Preempted, &MaximumPossibleBW) == TRUE)
+		    {
+		      zlog_info
+			("Preemption is useful. Priority2BePreempted %x Currently %x",
+			 Preempted, *PreemptedPriority);
+		      if (*PreemptedPriority <= Preempted)
+			{
+			  *PreemptedPriority = Preempted;
+			}
+		      *BW = pComponentLink->ReservableBW[SetupPriority];
+		      return E_OK;
+		    }
+		  else
+		    {
+		      zlog_info ("Preemption will not help %s %d", __FILE__,
+				 __LINE__);
+		      return E_ERR;
+		    }
+		}
+	    }
+	  pBwOwnerData = pBwOwnerData->next;
+	}
+    }
+  else
+    zlog_info ("First time pre-allocation...");
+
+  if ((pComponentLink->ReservableBW[SetupPriority] + BwAtHigherPriority) >=
+      *BW)
+    {
+      if (*BW > BwAtHigherPriority)
+	{
+	  zlog_info ("Reservable#%f BW at Higher priority#%f, required %f",
+		     pComponentLink->ReservableBW[SetupPriority],
+		     BwAtHigherPriority, *BW);
+	  *BW -= BwAtHigherPriority;
+	}
+      else
+	{
+	  zlog_info
+	    ("Reservable#%f BW at Lower priority#%f, required %f (actually 0)",
+	     pComponentLink->ReservableBW[SetupPriority], BwAtHigherPriority,
+	     *BW);
+	  *BW = 0;
+	}
+      return E_OK;
+    }
+  else
+    {
+      float RequiredBW = *BW - pComponentLink->ReservableBW[SetupPriority];
+      uns8 Preempted;
+      float MaximumPossibleBW = 0;
+      /* checking for bumping possibilities */
+      if (BwPreemptionUseful
+	  (pComponentLink->oifIndex, SetupPriority, RequiredBW, &Preempted,
+	   &MaximumPossibleBW) == TRUE)
+	{
+	  zlog_info ("Preemption will help: Required#%f PreemptedPrio %x %f",
+		     RequiredBW, Preempted,
+		     pComponentLink->ReservableBW[SetupPriority]);
+	  if (*PreemptedPriority <= Preempted)
+	    {
+	      *PreemptedPriority = Preempted;
+	    }
+	  *BW = pComponentLink->ReservableBW[SetupPriority];
+	  return E_OK;
+	}
+      else
+	return E_ERR;
+    }
+  return E_ERR;
+}
+
+uns32
+TE_RSVPTE_API_DoAllocation (PSB_KEY * key,
+			    uns32 TeLinkId,
+			    uns32 OutIfIndex,
+			    float BW,
+			    uns8 SetupPriority,
+			    uns8 HoldPriority, float *MaximumPossibleBW)
+{
+  BW_OWNER_ENTRY *pBwOwnerEntry;
+  BW_OWNER_DATA *pBwOwnerData;
+  COMPONENT_LINK *pComponentLink = NULL;
+  TE_LINK *pTeLink = NULL;
+  float BwAtHigherPriority;
+
+  zlog_info
+    ("inside of DoAllocation BW %f Dest %x tunnel %x source %x %x LSP %x HoldPrio %x SetupPrio %x ...",
+     BW, key->Session.Dest, key->Session.TunnelId, key->Session.ExtTunelId,
+     key->SenderTemplate.IpAddr, key->SenderTemplate.LspId, HoldPriority,
+     SetupPriority);
+  zlog_info ("TE Link ID %d OutIfIndex %d", TeLinkId, OutIfIndex);
+
+  /* First - register an allocation on the BW owners tree 
+     BW owner is the session if SE reservation style or 
+     Session and Sender if FF reservation style 
+     BW owners tree serves for the prevention of the double accounting
+     Upon the Path message, existing reservations are found
+     Additional BW is attempted to be allocated on the links,
+     where reservation already exists */
+  if (rdb_get_component_link (TeLinkId, OutIfIndex, &pComponentLink) != E_OK)
+    {
+      zlog_err ("\ncannot get component link %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if (rdb_get_te_link (TeLinkId, &pTeLink) != E_OK)
+    {
+      zlog_err ("\ncannot get TE link %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if ((pBwOwnerEntry =
+       (BW_OWNER_ENTRY *) patricia_tree_get (&BwOwnersTree[HoldPriority],
+					     (const uns8 *) key)) != NULL)
+    {
+      pBwOwnerData = pBwOwnerEntry->pBwOwnerData;
+      while (pBwOwnerData != NULL)
+	{
+	  if ((pBwOwnerData->TeLinkId == TeLinkId) &&
+	      (pBwOwnerData->OutIf == OutIfIndex))
+	    {
+	      te_stop_timer (&pBwOwnerData->BwHoldTimer);
+	      zlog_info
+		("BW %f pBwOwnerData->BW %f pBwOwnerData->PreAlloc %f SetupPrio %x HoldPrio %x %s %d",
+		 BW, pBwOwnerData->BW, pBwOwnerData->PreAllocBW,
+		 SetupPriority, HoldPriority, __FILE__, __LINE__);
+	      if (pBwOwnerData->BW > BW)	/* is this BW decrease ? */
+		{
+		  zlog_info ("res BW %f updt BW %f resbl BW %f",
+			     pBwOwnerData->BW, BW,
+			     pComponentLink->ReservableBW[HoldPriority]);
+
+		  ReleaseBW (pTeLink, pComponentLink, HoldPriority,
+			     pBwOwnerData->BW - BW);
+		  pBwOwnerData->BW = BW;
+		  pBwOwnerData->PreAllocBW = 0;
+		}
+	      else
+		{
+		  if (BW >= (pBwOwnerData->PreAllocBW + pBwOwnerData->BW))
+		    {
+		      float DeltaBW =
+			BW - (pBwOwnerData->PreAllocBW + pBwOwnerData->BW);
+		      zlog_info ("DeltaBW %f PreAlloc %f Alloc %f BW %f",
+				 DeltaBW, pBwOwnerData->PreAllocBW,
+				 pBwOwnerData->BW, BW);
+
+		      zlog_info
+			("Required BW#%f  is greater than allocated#%f", BW,
+			 (pBwOwnerData->PreAllocBW + pBwOwnerData->BW));
+		      GetEfficientBwAtHigherPriorities (key, TeLinkId,
+							pComponentLink,
+							HoldPriority,
+							&BwAtHigherPriority);
+		      zlog_info ("At higher priorities #%x",
+				 BwAtHigherPriority);
+		      if (DeltaBW < BwAtHigherPriority)
+			{
+			  zlog_info
+			    ("It is enough to release own BW at higher priorities");
+			  CancelBwAllocAtHigherPriorities (key, TeLinkId,
+							   pComponentLink,
+							   HoldPriority);
+			  AllocateBW (pTeLink, pComponentLink, HoldPriority,
+				      DeltaBW);
+			}
+		      else if ((DeltaBW + BwAtHigherPriority) <=
+			       pComponentLink->ReservableBW[HoldPriority])
+			{
+			  zlog_info
+			    ("Releasing own BW at higher priorities, allocating#%x",
+			     DeltaBW - BwAtHigherPriority);
+			  DeltaBW -= BwAtHigherPriority;
+			  /* cancel BW allocations at lower priorities */
+			  CancelBwAllocAtHigherPriorities (key, TeLinkId,
+							   pComponentLink,
+							   HoldPriority);
+			  /* now take remaining BW from this priority should be sufficient */
+			  AllocateBW (pTeLink, pComponentLink, HoldPriority,
+				      DeltaBW);
+			}
+		      else
+			{
+			  uns8 PreemptedPriority;
+			  zlog_info
+			    ("BW can be allocated if only preemption helps");
+			  /* try to get BW from lowest priority */
+			  if (BwPreemptionUseful
+			      (pComponentLink->oifIndex, SetupPriority,
+			       DeltaBW, &PreemptedPriority,
+			       MaximumPossibleBW) == TRUE)
+			    {
+			      uns8 Prio = 7;
+			      zlog_info
+				("Preemption will help. Trying to release #%f",
+				 DeltaBW);
+			      while (DeltaBW > 0)
+				{
+				  float FoundBW;
+
+				  if ((FoundBW = PreemptTunnel (TeLinkId,
+								pComponentLink,
+								Prio,
+								HoldPriority,
+								key)) == 0)
+				    {
+				      if (Prio == (SetupPriority + 1))
+					{
+					  zlog_err ("Algorithmic error %s %d",
+						    __FILE__, __LINE__);
+					  return E_ERR;
+					}
+				      else
+					{
+					  Prio--;
+					}
+				    }
+				  DeltaBW -= FoundBW;
+				}
+			    }
+			  else
+			    {
+			      (*MaximumPossibleBW) +=
+				pBwOwnerData->PreAllocBW + pBwOwnerData->BW;
+			      zlog_err ("cannot get enough BW %s %d",
+					__FILE__, __LINE__);
+			      return E_ERR;
+			    }
+			}
+		      pBwOwnerData->PreAllocBW = 0;
+		      pBwOwnerData->BW = BW;
+		    }
+		  else
+		    {
+		      zlog_info
+			("BW, allocated#%f and pre-allocated#%f is greater than required#%f",
+			 pBwOwnerData->BW, pBwOwnerData->PreAllocBW, BW);
+		      pBwOwnerData->PreAllocBW =
+			(pBwOwnerData->PreAllocBW + pBwOwnerData->BW) - BW;
+		      pBwOwnerData->BwHoldTimer.data.bw_hold_data.BW =
+			pBwOwnerData->PreAllocBW;
+		      if (te_start_timer
+			  (&pBwOwnerData->BwHoldTimer, BW_HOLD_EXPIRY,
+			   30) != E_OK)
+			{
+			  zlog_err ("\ncannot start BW hold timer %s %d",
+				    __FILE__, __LINE__);
+			}
+		      pBwOwnerData->BW = BW;
+		    }
+		}
+	      /* if we're here, allocation succeeded */
+	      /* cancel BW allocation at other priorities */
+	      CancelBwAllocAtOtherPriorities (key, TeLinkId, pComponentLink,
+					      HoldPriority);
+	      rdb_te_link_max_lsp_bw_calc (pTeLink);
+	      BwUpdateRequest2Igp (pTeLink);
+	      /* Update If-BW owners structure */
+	      if (UpdateIfBwOwnerStructure
+		  (pComponentLink->oifIndex, key, BW, HoldPriority) != E_OK)
+		{
+		  zlog_err ("\ncannot update IfBwOwnerStructure %s %d",
+			    __FILE__, __LINE__);
+		  return E_ERR;
+		}
+	      return E_OK;
+	    }
+	  pBwOwnerData = pBwOwnerData->next;
+	}
+      zlog_info ("Expected BW owner data is not found.");
+
+      if (pComponentLink->ReservableBW[SetupPriority] < BW)
+	{
+	  uns8 Preempted;
+	  if (BwPreemptionUseful
+	      (pComponentLink->oifIndex, SetupPriority, BW, &Preempted,
+	       MaximumPossibleBW) == FALSE)
+	    {
+	      zlog_info ("cannot allocate BW exhausted %s %d", __FILE__,
+			 __LINE__);
+	      return E_ERR;
+	    }
+	}
+    }
+  else
+    {
+      zlog_info
+	("expected BW owner (Session) %x %x %x Prio %x is not found on the patricia tree %s %d",
+	 key->Session.Dest, key->Session.TunnelId, key->Session.ExtTunelId,
+	 HoldPriority, __FILE__, __LINE__);
+
+      if (pComponentLink->ReservableBW[SetupPriority] < BW)
+	{
+	  /* try to get BW from lowest priority */
+	  uns8 Preempted;
+	  if (BwPreemptionUseful
+	      (pComponentLink->oifIndex, SetupPriority, BW, &Preempted,
+	       MaximumPossibleBW) == FALSE)
+	    {
+	      zlog_info ("cannot allocate, BW exhausted %s %d", __FILE__,
+			 __LINE__);
+	      return E_ERR;
+	    }
+	}
+      if ((pBwOwnerEntry =
+	   (BW_OWNER_ENTRY *) XMALLOC (MTYPE_TE,
+				       sizeof (BW_OWNER_ENTRY))) == NULL)
+	{
+	  zlog_err ("\nFailed to allocate memory %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pBwOwnerEntry->key = *key;
+      pBwOwnerEntry->Node.key_info = (uns8 *) & pBwOwnerEntry->key;
+      if (patricia_tree_add
+	  (&BwOwnersTree[HoldPriority], &pBwOwnerEntry->Node) != E_OK)
+	{
+	  zlog_err ("\nFailed to allocate memory %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+    }
+  /* BW reservation does not exist on the particular TE link and If */
+  if ((pBwOwnerData =
+       (BW_OWNER_DATA *) XMALLOC (MTYPE_TE, sizeof (BW_OWNER_DATA))) == NULL)
+    {
+      zlog_err ("\nFailed to allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  pBwOwnerData->next = pBwOwnerEntry->pBwOwnerData;
+  pBwOwnerEntry->pBwOwnerData = pBwOwnerData;
+  pBwOwnerData->BW = BW;
+  pBwOwnerData->OutIf = OutIfIndex;
+  pBwOwnerData->TeLinkId = TeLinkId;
+
+  if (pComponentLink->ReservableBW[SetupPriority] < BW)
+    {
+      float TempBW = BW;
+      uns32 Prio = 7;
+      while (TempBW > 0)
+	{
+	  float FoundBW;
+
+	  if ((FoundBW = PreemptTunnel (TeLinkId,
+					pComponentLink,
+					Prio, HoldPriority, key)) == 0)
+	    {
+	      if (Prio == (SetupPriority + 1))
+		{
+		  zlog_err ("Algorithmic error %s %d", __FILE__, __LINE__);
+		  return E_ERR;
+		}
+	      else
+		{
+		  Prio--;
+		}
+	    }
+	  TempBW -= FoundBW;
+	}
+    }
+  /* if we're here, allocation succeeded */
+  /* cancel BW allocation at other priorities */
+  CancelBwAllocAtOtherPriorities (key, TeLinkId, pComponentLink,
+				  HoldPriority);
+
+  rdb_te_link_max_lsp_bw_calc (pTeLink);
+
+  BwUpdateRequest2Igp (pTeLink);
+
+  /* Update If-BW owners structure */
+  if (UpdateIfBwOwnerStructure
+      (pComponentLink->oifIndex, key, BW, HoldPriority) != E_OK)
+    {
+      zlog_err ("cannot update IfBwOwnerStructure %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+uns32
+DoRelease (PSB_KEY * key, uns32 TeLinkId, uns32 OutIfIndex, uns8 Priority)
+{
+  BW_OWNER_ENTRY *pBwOwnerEntry;
+  BW_OWNER_DATA *pBwOwnerData, *pBwOwnerDataPrev;
+  COMPONENT_LINK *pComponentLink = NULL;
+  TE_LINK *pTeLink = NULL;
+  float Released = 0;
+  zlog_info ("inside of DoRelease..");
+  if ((pBwOwnerEntry =
+       (BW_OWNER_ENTRY *) patricia_tree_get (&BwOwnersTree[Priority],
+					     (const uns8 *) key)) != NULL)
+    {
+      pBwOwnerDataPrev = pBwOwnerData = pBwOwnerEntry->pBwOwnerData;
+      while (pBwOwnerData != NULL)
+	{
+	  if ((pBwOwnerData->TeLinkId == TeLinkId) &&
+	      (pBwOwnerData->OutIf == OutIfIndex))
+	    {
+	      Released = pBwOwnerData->BW + pBwOwnerData->PreAllocBW;
+	      zlog_info ("pBwOwnerData->BW %f, PreallocBW %f",
+			 pBwOwnerData->BW, pBwOwnerData->PreAllocBW);
+	      if (rdb_get_component_link
+		  (TeLinkId, OutIfIndex, &pComponentLink) != E_OK)
+		{
+		  zlog_info ("\ncannot get componentl link %x %x %s %x",
+			     TeLinkId, OutIfIndex, __FILE__, __LINE__);
+		  return E_ERR;
+		}
+
+	      if (rdb_get_te_link (TeLinkId, &pTeLink) != E_OK)
+		{
+		  zlog_err ("\ncannot get TE link %s %d", __FILE__, __LINE__);
+		}
+	      ReleaseBW (pTeLink, pComponentLink, Priority, Released);
+	      rdb_te_link_max_lsp_bw_calc (pTeLink);
+	      BwUpdateRequest2Igp (pTeLink);
+	      zlog_info ("BW Owners Entry will be deleted");
+	      te_stop_timer (&pBwOwnerData->BwHoldTimer);
+	      if (pBwOwnerEntry->pBwOwnerData == pBwOwnerData)
+		pBwOwnerEntry->pBwOwnerData =
+		  pBwOwnerEntry->pBwOwnerData->next;
+	      else
+		pBwOwnerDataPrev->next = pBwOwnerData->next;
+	      XFREE (MTYPE_TE, pBwOwnerData);
+	      if (pBwOwnerEntry->pBwOwnerData == NULL)
+		{
+		  if (patricia_tree_del
+		      (&BwOwnersTree[Priority], &pBwOwnerEntry->Node) != E_OK)
+		    {
+		      zlog_err ("\ncannot delete node from patricia %s %d",
+				__FILE__, __LINE__);
+		    }
+		  else
+		    {
+		      XFREE (MTYPE_TE, pBwOwnerEntry);
+		    }
+		}
+	      if (UpdateIfBwOwnerStructure
+		  (pComponentLink->oifIndex, key, Released, Priority) != E_OK)
+		{
+		  zlog_err ("\ncannot update IfBwOwnerStructure %s %d",
+			    __FILE__, __LINE__);
+		  return E_ERR;
+		}
+	      return E_OK;
+	    }
+	  pBwOwnerDataPrev = pBwOwnerData;
+	  pBwOwnerData = pBwOwnerData->next;
+	}
+    }
+  else
+    {
+      zlog_err ("\ncannot get entry from BW owners patricia tree %s %d",
+		__FILE__, __LINE__);
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+static void
+AllocateBW (TE_LINK * pTeLink, COMPONENT_LINK * pComponentLink, uns8 Priority,
+	    float BW)
+{
+  int j;
+
+  if (pComponentLink->ReservableBW[Priority] >= BW)
+    {
+      pComponentLink->ReservableBW[Priority] -= BW;
+      pTeLink->te_link_properties.ReservableBW[Priority] -= BW;
+      pComponentLink->AllocatedBW[Priority][Priority] += BW;
+    }
+  else
+    {
+      pComponentLink->ReservableBW[Priority] = 0;
+    }
+
+  for (j = Priority + 1; j < 8; j++)
+    {
+      if (pComponentLink->ReservableBW[j] >= BW)
+	{
+	  pComponentLink->ReservableBW[j] -= BW;
+	  pTeLink->te_link_properties.ReservableBW[j] -= BW;
+	}
+      else
+	{
+	  pComponentLink->ReservableBW[j] = 0;
+	}
+    }
+}
+
+static void
+ReleaseBW (TE_LINK * pTeLink, COMPONENT_LINK * pComponentLink, uns8 Priority,
+	   float BW)
+{
+  int i, j;
+  float ReleasedBW = 0;
+  /* Find highest priority where BW remains to be allocated */
+  for (i = 0; (i < 8) && (BW > 0); i++)
+    {
+      if (pComponentLink->AllocatedBW[i][i] > 0)
+	{
+	  ReleasedBW = 0;
+	  if (BW >= pComponentLink->AllocatedBW[i][i])
+	    {
+	      ReleasedBW = pComponentLink->AllocatedBW[i][i];
+	      pComponentLink->ReservableBW[i] +=
+		pComponentLink->AllocatedBW[i][i];
+	      pTeLink->te_link_properties.ReservableBW[i] +=
+		pComponentLink->AllocatedBW[i][i];
+	      BW -= pComponentLink->AllocatedBW[i][i];
+	      pComponentLink->AllocatedBW[i][i] = 0;
+	    }
+	  else
+	    {
+	      ReleasedBW = BW;
+	      pComponentLink->ReservableBW[i] += BW;
+	      pTeLink->te_link_properties.ReservableBW[i] += BW;
+	      pComponentLink->AllocatedBW[i][i] -= BW;
+	      BW = 0;
+	    }
+	  for (j = i + 1; (j < 8) && (ReleasedBW > 0); j++)
+	    {
+	      if (pComponentLink->AllocatedBW[i][j] > 0)
+		{
+		  if (ReleasedBW >= pComponentLink->AllocatedBW[i][j])
+		    {
+		      pComponentLink->AllocatedBW[j][j] +=
+			pComponentLink->AllocatedBW[i][j];
+		      ReleasedBW -= pComponentLink->AllocatedBW[i][j];
+		      pComponentLink->AllocatedBW[i][j] = 0;
+		    }
+		  else
+		    {
+		      pComponentLink->AllocatedBW[j][j] += ReleasedBW;
+		      pComponentLink->AllocatedBW[i][j] -= ReleasedBW;
+		      ReleasedBW = 0;
+		    }
+		}
+	    }
+	}
+    }
+  if (ReleasedBW > 0)
+    {
+      for (; i < 8; i++)
+	{
+	  if (pComponentLink->AllocatedBW[i][i] > 0)
+	    {
+	      break;
+	    }
+	  if (pComponentLink->ConfiguredReservableBW[i] >
+	      pComponentLink->ReservableBW[i])
+	    {
+	      if ((pComponentLink->ReservableBW[i] + ReleasedBW) <=
+		  pComponentLink->ConfiguredReservableBW[i])
+		{
+		  pComponentLink->ReservableBW[i] += ReleasedBW;
+		  pTeLink->te_link_properties.ReservableBW[i] += ReleasedBW;
+		}
+	      else
+		{
+		  pTeLink->te_link_properties.ReservableBW[i] =
+		    (pComponentLink->ConfiguredReservableBW[i] -
+		     pComponentLink->ReservableBW[i]);
+		  pComponentLink->ReservableBW[i] =
+		    pComponentLink->ConfiguredReservableBW[i];
+		}
+	    }
+	}
+    }
+}
+
+static void
+PreemptBW (COMPONENT_LINK * pComponentLink,
+	   uns8 PreemptorPriority, uns8 PreemptedPriority, float BW)
+{
+  int i;
+  if (PreemptedPriority == 0)
+    {
+      zlog_err ("\nBUG: Preempted priority is 0!!!");
+      return;
+    }
+  for (i = 7; (i >= PreemptedPriority) && (BW > 0); i--)
+    {
+      if (pComponentLink->AllocatedBW[PreemptedPriority][i] > 0)
+	{
+	  if (pComponentLink->AllocatedBW[PreemptedPriority][i] >= BW)
+	    {
+	      pComponentLink->AllocatedBW[PreemptedPriority][i] -= BW;
+	      pComponentLink->AllocatedBW[PreemptorPriority][i] += BW;
+	      return;
+	    }
+	  else
+	    {
+	      pComponentLink->AllocatedBW[PreemptorPriority][i] +=
+		pComponentLink->AllocatedBW[PreemptedPriority][i];
+	      BW -= pComponentLink->AllocatedBW[PreemptedPriority][i];
+	      pComponentLink->AllocatedBW[PreemptedPriority][i] = 0;
+	    }
+	}
+    }
+  if (BW > 0)
+    {
+      zlog_err ("\nBUG: BW > 0 %s %d", __FILE__, __LINE__);
+    }
+}
+
+void
+BwOwnersDump ()
+{
+  BW_OWNER_ENTRY *pBwOwnerEntry;
+  BW_OWNER_DATA *pBwOwnerData;
+  PSB_KEY PsbKey;
+  int j;
+
+  for (j = 0; j < 8; j++)
+    {
+      memset (&PsbKey, 0, sizeof (PSB_KEY));
+      zlog_debug ("Priority# %x", j);
+      while ((pBwOwnerEntry =
+	      (BW_OWNER_ENTRY *) patricia_tree_getnext (&BwOwnersTree[j],
+							(const uns8 *)
+							&PsbKey)) != NULL)
+	{
+	  zlog_debug
+	    ("owner dest %x tunnel id %x ext tunnel id %x sender ip %x lsp id %x",
+	     pBwOwnerEntry->key.Session.Dest,
+	     pBwOwnerEntry->key.Session.TunnelId,
+	     pBwOwnerEntry->key.Session.ExtTunelId,
+	     pBwOwnerEntry->key.SenderTemplate.IpAddr,
+	     pBwOwnerEntry->key.SenderTemplate.LspId);
+	  pBwOwnerData = pBwOwnerEntry->pBwOwnerData;
+	  while (pBwOwnerData != NULL)
+	    {
+	      zlog_debug ("TE Link ID %x Out IF %x BW %f PreAlloc BW %f",
+			  pBwOwnerData->BW,
+			  pBwOwnerData->TeLinkId,
+			  pBwOwnerData->OutIf, pBwOwnerData->PreAllocBW);
+	      pBwOwnerData = pBwOwnerData->next;
+	    }
+	  PsbKey = pBwOwnerEntry->key;
+	}
+    }
+  return;
+}
+
+void
+IfBwOwnersDump ()
+{
+  IF_BW_KEY if_bw_key;
+  IF_BW_DATA *pIfBwEntry;
+  int j;
+
+  memset (&if_bw_key, 0, sizeof (IF_BW_KEY));
+
+  for (j = 0; j < 8; j++)
+    {
+      zlog_debug ("Priority#%x", j);
+      while ((pIfBwEntry =
+	      (IF_BW_DATA *) patricia_tree_getnext (&IfBwOwnersTree[j],
+						    (const uns8 *)
+						    &if_bw_key)) != NULL)
+	{
+	  zlog_debug ("IF#%x Dest #%x Tunnel #%x Source #%x BW #%f",
+		      pIfBwEntry->if_bw_key.IfIndex,
+		      pIfBwEntry->if_bw_key.PsbKey.Session.Dest,
+		      pIfBwEntry->if_bw_key.PsbKey.Session.TunnelId,
+		      pIfBwEntry->if_bw_key.PsbKey.Session.ExtTunelId,
+		      pIfBwEntry->BW);
+	  if_bw_key = pIfBwEntry->if_bw_key;
+	}
+    }
+  return;
+}
diff -Naur quagga-0.99.10/rsvpd/te_bw_man.h quagga-mpls/rsvpd/te_bw_man.h
--- quagga-0.99.10/rsvpd/te_bw_man.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_bw_man.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,30 @@
+
+#ifndef _BW_MAN_H_
+#define _BW_MAN_H_
+
+uns32 DoPreBwAllocation (PSB_KEY * key,
+			 uns32 TeLinkId,
+			 COMPONENT_LINK * pComponentLink,
+			 float BW, uns8 HoldPriority);
+uns32 CalcActualAlloc (PSB_KEY * key,
+		       uns32 TeLinkId,
+		       COMPONENT_LINK * pComponentLink,
+		       float *BW,
+		       uns8 SetupPriority,
+		       uns8 HoldPriority, uns8 * PreemptedPriority);
+uns32 TE_RSVPTE_API_DoAllocation (PSB_KEY * key,
+				  uns32 TeLinkId,
+				  uns32 OutIfIndex,
+				  float BW,
+				  uns8 SetupPriority,
+				  uns8 HoldPriority,
+				  float *MaximumPossibleBW);
+uns32 DoRelease (PSB_KEY * key, uns32 TeLinkId, uns32 OutIfIndex,
+		 uns8 Priority);
+void BwOwnersDump ();
+void IfBwOwnersDump ();
+
+void TE_RSVPTE_API_BwReleaseMessage (TE_API_MSG * dmsg);
+void BwUpdateRequest2Igp (TE_LINK * pTeLink);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te_common.c quagga-mpls/rsvpd/te_common.c
--- quagga-0.99.10/rsvpd/te_common.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_common.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,1685 @@
+/* Module:   te_common_proc.c
+   Contains: TE application common procedures
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "te.h"
+#include "thread.h"
+#include "vty.h"
+
+extern struct thread_master *master;
+
+PATRICIA_TREE PlatformWideFreeLabels;
+PATRICIA_TREE BwOwnersTree[8];
+PATRICIA_TREE IfBwOwnersTree[8];
+PATRICIA_TREE SeparateAdaptiveLspsTrunkTree;
+PATRICIA_TREE SeparateNonAdaptiveLspsTrunkTree;
+PATRICIA_TREE NonSeparateServiceLspsTrunkTree;
+PATRICIA_TREE NonSeparateServiceBWAdaptiveLspsTrunkTree;
+PATRICIA_TREE NonSeparateTunnelsLspsTrunkTree;
+PATRICIA_TREE SLAsTree;
+PATRICIA_TREE ConstraintRouteResReqTree;
+PATRICIA_TREE ConstraintRouteResClientsTree;
+
+USER_LSP_LIST *UserLspListHead;
+
+#define MAX_TUNNELS_IF 1000
+#define TUNNELS_IF_OFFSET 100
+
+IPV4_ADDR tunnels_if_array[MAX_TUNNELS_IF];
+extern LABEL_ENTRY PlatformWideLabelSpace[LABEL_SPACE_SIZE];
+
+SM_CALL_T *(*sm_handler[MAX_SM]) (SM_T * pSm, SM_EVENT_T * sm_data) =
+{
+  lsp_sm_handler,
+    transit_req_sm_handler, constraint_route_resolution_sm_handler
+#ifdef FRR_SM_DEFINED
+    , fast_reroute_sm_handler
+#endif
+};
+
+void
+sm_gen_event_trace (SM_E event)
+{
+  switch (event)
+    {
+    case USER_LSP_REQUEST_EVENT:
+      zlog_info ("USER_LSP_REQUEST_EVENT\n");
+      break;
+    case SLA_USER_REQUEST_EVENT:
+      zlog_info ("SLA_USER_REQUEST_EVENT\n");
+      break;
+    case INGRESS_LSP_REQUEST_EVENT:
+      zlog_info ("INGRESS_LSP_REQUEST_EVENT\n");
+      break;
+    case SLA_DELETE_USER_REQUEST_EVENT:
+      zlog_info ("SLA_DELETE_USER_REQUEST_EVENT\n");
+      break;
+    case INGRESS_LSP_DELETE_REQUEST_EVENT:
+      zlog_info ("INGRESS_LSP_DELETE_REQUEST_EVENT\n");
+      break;
+    case TRANSIT_REQ_EVENT:
+      zlog_info ("TRANSIT_REQ_EVENT\n");
+      break;
+    case CONSTRAINT_ROUTE_RESOLUTION_REQ_EVENT:
+      zlog_info ("CONSTRAINT_ROUTE_RESOLUTION_REQ_EVENT\n");
+      break;
+    case CONSTRAINT_ROUTE_RESOLVED_EVENT:
+      zlog_info ("CONSTRAINT_ROUTE_RESOLVED_EVENT\n");
+      break;
+    case CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT:
+      zlog_info ("CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT\n");
+      break;
+    case CSPF_REPLY_EVENT:
+      zlog_info ("CSPF_REPLY_EVENT\n");
+      break;
+    case DYNAMIC_ADAPTATION_REQ_EVENT:
+      zlog_info ("DYNAMIC_ADAPTATION_REQ_EVENT\n");
+      break;
+    case SLA_ADAPTATION_REQ_EVENT:
+      zlog_info ("SLA_ADAPTATION_REQ_EVENT\n");
+      break;
+    case SLA_ADAPTATION_COMPLETE_EVENT:
+      zlog_info ("SLA_ADAPTATION_COMPLETE_EVENT\n");
+      break;
+    case SLA_ADAPTATION_FAILED_EVENT:
+      zlog_info ("SLA ADAPTATION FAILED EVENT\n");
+      break;
+    case INGRESS_LSP_OPERATION_COMPLETE_EVENT:
+      zlog_info ("INGRESS_LSP_OPERATION_COMPLETE_EVENT\n");
+      break;
+    case INGRESS_LSP_OPERATION_FAILED_EVENT:
+      zlog_info ("INGRESS_LSP_OPERATION_FAILED_EVENT\n");
+      break;
+    case MPLS_SIGNALING_INGRESS_ESTABLISHED_NOTIFICATION_EVENT:
+      zlog_info ("MPLS_SIGNALING_INGRESS_ESTABLISHED_NOTIFICATION_EVENT\n");
+      break;
+    case MPLS_SIGNALING_INGRESS_FAILED_NOTIFICATION_EVENT:
+      zlog_info ("MPLS_SIGNALING_INGRESS_FAILED_NOTIFICATION_EVENT\n");
+      break;
+    case LSP_SETUP_TIMER_EXPIRY:
+      zlog_info ("LSP_SETUP_TIMER_EXPIRY\n");
+      break;
+    case ADAPTIVITY_TIMER_EXPIRY:
+      zlog_info ("ADAPTIVITY_TIMER_EXPIRY\n");
+      break;
+    case RETRY_TIMER_EXPIRY:
+      zlog_info ("RETRY_TIMER_EXPIRY\n");
+      break;
+    case CSPF_RETRY_EVENT:
+      zlog_info ("CSPF_RETRY_EVENT\n");
+      break;
+    default:
+      zlog_err ("\nunknown event %d", event);
+    }
+}
+
+
+int
+sm_gen_async_event_send (SM_T * sm, SM_EVENT_E event, void *data)
+{
+  TE_MSG dmsg;
+  SM_CALL_T *sm_packet;
+  SM_EVENT_T *pEvent = (SM_EVENT_T *) XMALLOC (MTYPE_TE, sizeof (SM_EVENT_T));
+  if (pEvent == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d %d", __FILE__, __LINE__, event);
+      return 1;
+    }
+  dmsg.event = EVENT_TE_SM;
+  pEvent->event = event;
+  pEvent->data = data;
+  sm_packet = (SM_CALL_T *) XMALLOC (MTYPE_TE, sizeof (SM_CALL_T));
+  if (sm_packet == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      XFREE (MTYPE_TE, pEvent);
+      return 1;
+    }
+  sm_packet->sm = sm;
+  sm_packet->sm_data = pEvent;
+  dmsg.u.te_sm_event.data = sm_packet;
+  te_send_msg (&dmsg, sizeof (TE_MSG));
+  return 0;
+}
+
+SM_CALL_T *
+sm_gen_sync_event_send (SM_T * sm, SM_EVENT_E event, void *data)
+{
+  SM_CALL_T *sm_packet;
+  SM_EVENT_T *pEvent = (SM_EVENT_T *) XMALLOC (MTYPE_TE, sizeof (SM_EVENT_T));
+  if (pEvent == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d %d", __FILE__, __LINE__, event);
+      return NULL;
+    }
+  pEvent->event = event;
+  pEvent->data = data;
+  sm_packet = (SM_CALL_T *) XMALLOC (MTYPE_TE, sizeof (SM_CALL_T));
+  if (sm_packet == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      XFREE (MTYPE_TE, pEvent);
+      return NULL;
+    }
+  sm_packet->sm = sm;
+  sm_packet->sm_data = pEvent;
+  return sm_packet;
+}
+
+void
+sm_call (SM_CALL_T * sm_packet)
+{
+  SM_CALL_T *pPacket = sm_packet, *pPrevPacket;
+  SM_E sm_type;
+
+  do
+    {
+      sm_type = pPacket->sm->sm_type;
+      pPrevPacket = pPacket;
+      pPacket = sm_handler[sm_type] (pPacket->sm, pPacket->sm_data);
+      XFREE (MTYPE_TE, pPrevPacket->sm_data);
+      XFREE (MTYPE_TE, pPrevPacket);
+    }
+  while (pPacket != NULL);
+}
+
+SM_T *
+sm_gen_alloc (SM_T * caller, SM_E sm_type)
+{
+  SM_T *pSmGen;
+  pSmGen = (SM_T *) XMALLOC (MTYPE_TE, sizeof (SM_T));
+  if (pSmGen == NULL)
+    {
+      zlog_err ("\ncannot allocate memory %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  pSmGen->data = NULL;
+  pSmGen->sm_type = sm_type;
+  pSmGen->caller = caller;
+  pSmGen->state = INIT_STATE;
+  return pSmGen;
+}
+
+void
+sm_gen_free (SM_T * sm)
+{
+  XFREE (MTYPE_TE, sm);
+  return;
+}
+
+#if 1
+
+//extern PATRICIA_TREE BwOwnersTree[8];
+
+void
+BwHoldTimerExpiry (BW_HOLD_TIMER_DATA * pBwHoldTimerExpiry)
+{
+  BW_OWNER_ENTRY *pBwOwnerEntry;
+  BW_OWNER_DATA *pBwOwnerData;
+  COMPONENT_LINK *pComponentLink = NULL;
+  TE_LINK *pTeLink = NULL;
+  int j;
+  uns8 Priority = pBwHoldTimerExpiry->Priority;
+
+  if ((pBwOwnerEntry =
+       (BW_OWNER_ENTRY *) patricia_tree_get (&BwOwnersTree[Priority],
+					     (const uns8 *)
+					     &pBwHoldTimerExpiry->key)) !=
+      NULL)
+    {
+      pBwOwnerData = pBwOwnerEntry->pBwOwnerData;
+      while (pBwOwnerData != NULL)
+	{
+	  if ((pBwOwnerData->TeLinkId == pBwHoldTimerExpiry->TeLinkId) &&
+	      (pBwOwnerData->OutIf == pBwHoldTimerExpiry->OutIf))
+	    {
+	      if (pBwOwnerData !=
+		  (BW_OWNER_DATA *) pBwHoldTimerExpiry->handle)
+		{
+		  zlog_err ("unexpected timer expiry %s %d", __FILE__,
+			    __LINE__);
+		  pBwOwnerData->PreAllocBW = 0;
+		  pBwOwnerData->BwHoldTimer.data.bw_hold_data.BW = 0;
+		  pBwOwnerData->BwHoldTimer.is_active = FALSE;
+		  return;
+		}
+	      if (pBwOwnerData->PreAllocBW !=
+		  pBwOwnerData->BwHoldTimer.data.bw_hold_data.BW)
+		{
+		  zlog_err ("unexpected timer expiry %s %d", __FILE__,
+			    __LINE__);
+		  pBwOwnerData->PreAllocBW = 0;
+		  pBwOwnerData->BwHoldTimer.data.bw_hold_data.BW = 0;
+		  pBwOwnerData->BwHoldTimer.is_active = FALSE;
+		  return;
+		}
+	      if (rdb_get_component_link (pBwHoldTimerExpiry->TeLinkId,
+					  pBwHoldTimerExpiry->OutIf,
+					  &pComponentLink) != E_OK)
+		{
+		  zlog_err ("cannot get component link %s %d", __FILE__,
+			    __LINE__);
+		  pBwOwnerData->PreAllocBW = 0;
+		  pBwOwnerData->BwHoldTimer.data.bw_hold_data.BW = 0;
+		  pBwOwnerData->BwHoldTimer.is_active = FALSE;
+		  return;
+		}
+	      zlog_info
+		("releasing BW: DestIP %x Source %x tunnel %x TmrBW %f EntryBW %f Priority %x",
+		 pBwHoldTimerExpiry->key.Session.Dest,
+		 pBwHoldTimerExpiry->key.Session.ExtTunelId,
+		 pBwHoldTimerExpiry->key.Session.TunnelId,
+		 pBwHoldTimerExpiry->BW, pBwOwnerData->BW,
+		 pBwHoldTimerExpiry->Priority);
+	      if (rdb_get_te_link (pBwHoldTimerExpiry->TeLinkId, &pTeLink) !=
+		  E_OK)
+		{
+		  zlog_err ("\ncannot get TE link %s %d", __FILE__, __LINE__);
+		}
+	      for (j = Priority; j < 8; j++)
+		{
+		  pComponentLink->ReservableBW[j] += pBwOwnerData->PreAllocBW;
+		  pTeLink->te_link_properties.ReservableBW[j] +=
+		    pBwOwnerData->PreAllocBW;
+		}
+	      rdb_te_link_max_lsp_bw_calc (pTeLink);
+	      pBwOwnerData->PreAllocBW = 0;
+	      pBwOwnerData->BwHoldTimer.is_active = FALSE;
+	      pBwOwnerData->BwHoldTimer.data.bw_hold_data.BW = 0;
+	      return;
+	    }
+	  pBwOwnerData = pBwOwnerData->next;
+	}
+      zlog_info ("\nBW owner data is not found %s %d", __FILE__, __LINE__);
+    }
+  else
+    {
+      zlog_err
+	("\ncannot get entry for BW holder %s %d destIP %x Tunnel ID %x SourceIP %x %x %x Priority %x",
+	 __FILE__, __LINE__, pBwHoldTimerExpiry->key.Session.Dest,
+	 pBwHoldTimerExpiry->key.Session.TunnelId,
+	 pBwHoldTimerExpiry->key.Session.ExtTunelId,
+	 pBwHoldTimerExpiry->key.SenderTemplate.IpAddr,
+	 pBwHoldTimerExpiry->key.SenderTemplate.LspId,
+	 pBwHoldTimerExpiry->Priority);
+    }
+}
+
+void
+LspSetupTimerExpiry (LSP_SETUP_TIMER_DATA * pData)
+{
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  SM_CALL_T *pCall = NULL;
+  if (FindTunnel (&pData->key, &pTunnel, ALL_TRUNKS) != TRUE)
+    {
+      zlog_err ("\ncannot find tunnel %x %x %x",
+		pData->key.Session.Dest,
+		pData->key.Session.ExtTunelId, pData->key.Session.TunnelId);
+      return;
+    }
+  if (pTunnel->sm_handle == 0)
+    {
+      zlog_err
+	("\nThere is no SM to process LSP SETUP RETRY for tunnle %x %x %x",
+	 pData->key.Session.Dest, pData->key.Session.ExtTunelId,
+	 pData->key.Session.TunnelId);
+      return;
+    }
+  if ((pCall =
+       sm_gen_sync_event_send (pTunnel->sm_handle, LSP_SETUP_TIMER_EXPIRY,
+			       &pData->key)) == NULL)
+    {
+      zlog_err ("\ncannot send sync event %s %d", __FILE__, __LINE__);
+      return;
+    }
+  sm_call (pCall);
+}
+
+void
+AdaptivityTimerExpiry (ADAPTIVITY_TIMER_DATA * pData)
+{
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  SM_CALL_T *pCall = NULL;
+  if (FindTunnel (&pData->key, &pTunnel, ALL_TRUNKS) != TRUE)
+    {
+      zlog_err ("\ncannot find tunnel %x %x %x",
+		pData->key.Session.Dest,
+		pData->key.Session.ExtTunelId, pData->key.Session.TunnelId);
+      return;
+    }
+  if (pTunnel->sm_handle == 0)
+    {
+      zlog_err
+	("\nThere is no SM to process LSP SETUP RETRY for tunnle %x %x %x",
+	 pData->key.Session.Dest, pData->key.Session.ExtTunelId,
+	 pData->key.Session.TunnelId);
+      return;
+    }
+  if ((pCall =
+       sm_gen_sync_event_send (pTunnel->sm_handle, ADAPTIVITY_TIMER_EXPIRY,
+			       &pData->key)) == NULL)
+    {
+      zlog_err ("\ncannot send sync event %s %d", __FILE__, __LINE__);
+      return;
+    }
+  sm_call (pCall);
+}
+
+void
+LspSetupRetryTimerExpiry (LSP_SETUP_RETRY_TIMER_DATA * pData)
+{
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  SM_CALL_T *pCall = NULL;
+  if (FindTunnel (&pData->key, &pTunnel, ALL_TRUNKS) != TRUE)
+    {
+      zlog_err ("\ncannot find tunnel %x %x %x",
+		pData->key.Session.Dest,
+		pData->key.Session.ExtTunelId, pData->key.Session.TunnelId);
+      return;
+    }
+  if (pTunnel->sm_handle == 0)
+    {
+      zlog_err
+	("\nThere is no SM to process LSP SETUP RETRY for tunnlel %x %x %x",
+	 pData->key.Session.Dest, pData->key.Session.ExtTunelId,
+	 pData->key.Session.TunnelId);
+      return;
+    }
+  if ((pCall =
+       sm_gen_sync_event_send (pTunnel->sm_handle, RETRY_TIMER_EXPIRY,
+			       &pData->key)) == NULL)
+    {
+      zlog_err ("\ncannot send sync event %s %d", __FILE__, __LINE__);
+      return;
+    }
+  sm_call (pCall);
+}
+
+void
+CspfRetryTimerExpiry (CSPF_RETRY_TIMER_DATA * pData)
+{
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  SM_CALL_T *pCall = NULL;
+  if (FindTunnel (&pData->key, &pTunnel, ALL_TRUNKS) != TRUE)
+    {
+      zlog_err ("\ncannot find tunnel %x %x %x",
+		pData->key.Session.Dest,
+		pData->key.Session.ExtTunelId, pData->key.Session.TunnelId);
+      return;
+    }
+  if (pTunnel->sm_handle == 0)
+    {
+      zlog_err ("There is no SM to process CSPF RETRY for tunnlel %x %x %x",
+		pData->key.Session.Dest,
+		pData->key.Session.ExtTunelId, pData->key.Session.TunnelId);
+      return;
+    }
+  if ((pCall =
+       sm_gen_sync_event_send (pTunnel->sm_handle, CSPF_RETRY_EVENT,
+			       &pData->key)) == NULL)
+    {
+      zlog_err ("\ncannot send sync event %s %d", __FILE__, __LINE__);
+      return;
+    }
+  sm_call (pCall);
+}
+
+void
+te_timer_expiry (struct thread *thread)
+{
+  TE_TMR *tmr = (TE_TMR *) THREAD_ARG (thread);
+  int period = THREAD_VAL (tmr->thread);
+  tmr->thread = thread_add_timer (master, te_timer_expiry, tmr, period);
+
+  tmr->is_active = FALSE;
+
+  switch (tmr->type)
+    {
+    case BW_HOLD_EXPIRY:
+      zlog_info
+	("BW Hold expiry: TE Link ID %x IP Dest %x Tunnel ID %x Source %x BW %f Priority %x",
+	 tmr->data.bw_hold_data.TeLinkId,
+	 tmr->data.bw_hold_data.key.Session.Dest,
+	 tmr->data.bw_hold_data.key.Session.TunnelId,
+	 tmr->data.bw_hold_data.key.Session.ExtTunelId,
+	 tmr->data.bw_hold_data.BW, tmr->data.bw_hold_data.Priority);
+      BwHoldTimerExpiry (&tmr->data.bw_hold_data);
+      break;
+    case LSP_SETUP_EXPIRY:
+      zlog_info ("LSP SETUP expiry: %x %x %x",
+		 tmr->data.lsp_setup_data.key.Session.Dest,
+		 tmr->data.lsp_setup_data.key.Session.TunnelId,
+		 tmr->data.lsp_setup_data.key.Session.ExtTunelId);
+      LspSetupTimerExpiry (&tmr->data.lsp_setup_data);
+      break;
+    case ADAPTIVITY_EXPIRY:
+      AdaptivityTimerExpiry (&tmr->data.adaptivity_timer_data);
+      break;
+    case LSP_SETUP_RETRY_EXPIRY:
+      zlog_info ("LSP SETUP RETRY expiry: %x %x %x",
+		 tmr->data.lsp_setup_retry_data.key.Session.Dest,
+		 tmr->data.lsp_setup_retry_data.key.Session.TunnelId,
+		 tmr->data.lsp_setup_retry_data.key.Session.ExtTunelId);
+      LspSetupRetryTimerExpiry (&tmr->data.lsp_setup_retry_data);
+      break;
+    case CSPF_RETRY_EXPIRY:
+      zlog_info ("CSPF RETRY expiry: %x %x %x",
+		 tmr->data.cspf_retry_data.key.Session.Dest,
+		 tmr->data.cspf_retry_data.key.Session.TunnelId,
+		 tmr->data.cspf_retry_data.key.Session.ExtTunelId);
+      CspfRetryTimerExpiry (&tmr->data.cspf_retry_data);
+      break;
+#if 0
+    case BYPASS_TUNNEL_RETRY_EXPIRY:
+      dmsg.event = EVENT_BYPASS_TUNNEL_RETRY_EXPIRY;
+      memcpy (&dmsg.u.bypass_retry_expiry.key,
+	      &tmr->data.bypass_retry_data, sizeof (FRR_SM_KEY));
+      zlog_info ("\nBYPASS TUNNEL RETRY expiry: %x %x %x",
+		 tmr->data.bypass_retry_data.merge_node,
+		 tmr->data.bypass_retry_data.OutIfIndex,
+		 tmr->data.bypass_retry_data.protected_node);
+      te_send_msg (&dmsg, sizeof (TE_MSG));
+      break;
+#endif
+    default:
+      zlog_err ("\ndefault case %s %d", __FILE__, __LINE__);
+    }
+  return;
+}
+
+uns32
+te_start_timer (TE_TMR * tmr, TE_TMR_E type, uns32 period)
+{
+  zlog_info ("entering te_start_timer");
+  if (tmr->thread)
+    {
+      te_stop_timer (tmr);
+    }
+  tmr->type = type;
+  if (tmr->is_active == FALSE)
+    {
+      tmr->thread = thread_add_timer (master, te_timer_expiry, tmr, period);
+      THREAD_VAL (tmr->thread) = period;
+      tmr->is_active = TRUE;
+    }
+  zlog_info ("leaving te_start_timer");
+  return E_OK;
+}
+
+void
+te_stop_timer (TE_TMR * tmr)
+{
+  /* Stop the timer if it is active... */
+  zlog_info ("entering te_stop_timer");
+  if (tmr->is_active == TRUE)
+    {
+      thread_cancel (tmr->thread);
+      tmr->thread = NULL;
+      tmr->is_active = FALSE;
+    }
+  zlog_info ("leaving te_stop_timer");
+}
+#endif
+
+uns32
+TeApplicationInit ()
+{
+  PATRICIA_PARAMS params;
+  unsigned int i;
+
+  UserLspListHead = NULL;
+
+  params.key_size = sizeof (unsigned int);
+  params.info_size = 0;
+  memset (PlatformWideLabelSpace, 0, sizeof (LABEL_ENTRY) * LABEL_SPACE_SIZE);
+  if (patricia_tree_init (&PlatformWideFreeLabels, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+  zlog_info ("\nPlatformWideFreeLabelsTree init succeeded");
+
+  for (i = 0; i < LABEL_SPACE_SIZE; i++)
+    {
+      PlatformWideLabelSpace[i].label = i + 1;
+      PlatformWideLabelSpace[i].ReceivedOutLabel = 0;
+      PlatformWideLabelSpace[i].Node.key_info =
+	(uns8 *) & PlatformWideLabelSpace[i].label;
+      if (patricia_tree_add
+	  (&PlatformWideFreeLabels,
+	   &(PlatformWideLabelSpace[i].Node)) != E_OK)
+	{
+	  zlog_err ("\ncannot add label %d", i + 1);
+	  return E_ERR;
+	}
+    }
+  params.key_size = sizeof (PSB_KEY);
+  params.info_size = 0;
+
+  for (i = 0; i < 8; i++)
+    {
+      if (patricia_tree_init (&BwOwnersTree[i], &params) != E_OK)
+	{
+	  return E_ERR;
+	}
+    }
+
+  params.key_size = sizeof (PSB_KEY) + sizeof (uns32);
+  params.info_size = 0;
+
+  for (i = 0; i < 8; i++)
+    {
+      if (patricia_tree_init (&IfBwOwnersTree[i], &params) != E_OK)
+	{
+	  return E_ERR;
+	}
+    }
+
+  memset (&params, 0, sizeof (params));
+  params.key_size = sizeof (TRUNK_KEY);
+  params.info_size = 0;
+
+  if (patricia_tree_init (&SeparateNonAdaptiveLspsTrunkTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+
+  if (patricia_tree_init (&SeparateAdaptiveLspsTrunkTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+
+  if (patricia_tree_init (&NonSeparateServiceLspsTrunkTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+
+  if (patricia_tree_init (&NonSeparateTunnelsLspsTrunkTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+
+  if (patricia_tree_init (&NonSeparateServiceBWAdaptiveLspsTrunkTree,
+			  &params) != E_OK)
+    {
+      return E_ERR;
+    }
+
+  memset (&params, 0, sizeof (params));
+  params.key_size = sizeof (SLA_KEY);
+  params.info_size = 0;
+  if (patricia_tree_init (&SLAsTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+
+  params.key_size = sizeof (IPV4_ADDR);
+  params.info_size = 0;
+
+  if (patricia_tree_init (&ConstraintRouteResReqTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+
+  params.key_size = sizeof (int);
+  params.info_size = 0;
+
+  if (patricia_tree_init (&ConstraintRouteResClientsTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+#ifdef FRR_SM_DEFINED
+  InitFastReRoute ();
+#endif
+  zlog_info ("\nTE application init success");
+  return E_OK;
+}
+
+PATRICIA_TREE *
+GetPatriciaTree (TRUNK_TYPE trunk_type)
+{
+  PATRICIA_TREE *pTree = NULL;
+  switch (trunk_type)
+    {
+    case SEPARATE_NON_ADAPTIVE:
+      pTree = &SeparateNonAdaptiveLspsTrunkTree;
+      break;
+    case SEPARATE_ADAPTIVE:
+      pTree = &SeparateAdaptiveLspsTrunkTree;
+      break;
+    case NON_SEPARATE_SERVICE:
+      pTree = &NonSeparateServiceLspsTrunkTree;
+      break;
+    case NON_SEPARATE_SERVICE_BW_ADAPTIVE:
+      pTree = &NonSeparateServiceBWAdaptiveLspsTrunkTree;
+      break;
+    case NON_SEPARATE_TUNNELS:
+      pTree = &NonSeparateTunnelsLspsTrunkTree;
+      break;
+    default:
+      zlog_err ("\ndefault case %s %d", __FILE__, __LINE__);
+    }
+  return pTree;
+}
+
+BOOL
+FindTunnel (PSB_KEY * PsbKey, RSVP_TUNNEL_PROPERTIES ** ppTunnel,
+	    TRUNK_TYPE trunk_type)
+{
+  TRUNK_KEY trunk_key;
+  TRUNK_ENTRY *pTrunkEntry;
+  int i, l;
+  PATRICIA_TREE *pTree = NULL;
+
+  switch (trunk_type)
+    {
+    case SEPARATE_NON_ADAPTIVE:
+    case SEPARATE_ADAPTIVE:
+    case NON_SEPARATE_SERVICE:
+    case NON_SEPARATE_TUNNELS:
+      i = l = trunk_type;
+      break;
+    case ALL_TRUNKS:
+      i = 0;
+      l = ALL_TRUNKS - 1;
+      break;
+    default:
+      zlog_err ("\ndefault case %s %d", __FILE__, __LINE__);
+      i = 0;
+      l = ALL_TRUNKS - 1;
+    }
+
+  memset (&trunk_key, 0, sizeof (TRUNK_KEY));
+  trunk_key.Dest = PsbKey->Session.Dest;
+  for (; i <= l; i++)
+    {
+      if ((pTree = GetPatriciaTree (i)) == NULL)
+	continue;
+      if ((pTrunkEntry =
+	   (TRUNK_ENTRY *) patricia_tree_get (pTree,
+					      (const uns8 *) &trunk_key)) !=
+	  NULL)
+	{
+	  RSVP_TUNNEL_PROPERTIES *pTunnel = pTrunkEntry->Lsps;
+	  while (pTunnel != NULL)
+	    {
+	      if (pTunnel->TunnelId == PsbKey->Session.TunnelId)
+		{
+		  *ppTunnel = pTunnel;
+		  return TRUE;
+		}
+	      pTunnel = pTunnel->next;
+	    }
+	}
+    }
+  return FALSE;
+}
+
+uns32
+NewRsvpLsp (RSVP_TUNNEL_PROPERTIES * pTunnel,
+	    RSVP_LSP_PROPERTIES ** ppRsvpLsp)
+{
+  RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties;
+
+  if (pTunnel->properties == NULL)
+    {
+      if ((pTunnel->properties =
+	   (RSVP_LSP_PROPERTIES *) XMALLOC (MTYPE_TE,
+					    sizeof (RSVP_LSP_PROPERTIES))) ==
+	  NULL)
+	{
+	  zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      memset (pTunnel->properties, 0, sizeof (RSVP_LSP_PROPERTIES));
+      *ppRsvpLsp = pTunnel->properties;
+      return E_OK;
+    }
+
+  while (pRsvpLsp != NULL)
+    {
+      if (pRsvpLsp->next == NULL)
+	{
+	  if ((pRsvpLsp->next =
+	       (RSVP_LSP_PROPERTIES *) XMALLOC (MTYPE_TE,
+						sizeof (RSVP_LSP_PROPERTIES)))
+	      == NULL)
+	    {
+	      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  *ppRsvpLsp = pRsvpLsp->next;	/* !!! */
+	  return E_OK;
+	}
+      pRsvpLsp = pRsvpLsp->next;
+    }
+  return E_ERR;			/* should not be reached */
+}
+
+uns32
+NewTunnel (PSB_KEY * PsbKey, RSVP_TUNNEL_PROPERTIES ** ppNewTunnel,
+	   TRUNK_TYPE trunk_type)
+{
+  TRUNK_ENTRY *pTrunkEntry;
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  TRUNK_KEY trunk_key;
+  PATRICIA_TREE *pTree;
+
+  if ((pTree = GetPatriciaTree (trunk_type)) == NULL)
+    {
+      zlog_err ("\nno trunk type specified %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  memset (&trunk_key, 0, sizeof (TRUNK_KEY));
+  trunk_key.Dest = PsbKey->Session.Dest;
+
+  if ((pTrunkEntry =
+       (TRUNK_ENTRY *) patricia_tree_get (pTree,
+					  (const uns8 *) &trunk_key)) == NULL)
+    {
+      if ((pTrunkEntry =
+	   (TRUNK_ENTRY *) XMALLOC (MTYPE_TE, sizeof (TRUNK_ENTRY))) == NULL)
+	{
+	  zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      memset (pTrunkEntry, 0, sizeof (TRUNK_ENTRY));
+      pTrunkEntry->trunk_key.Dest = PsbKey->Session.Dest;
+      pTrunkEntry->Node.key_info = (uns8 *) & (pTrunkEntry->trunk_key);
+      if (patricia_tree_add (pTree, &(pTrunkEntry->Node)) != E_OK)
+	{
+	  XFREE (MTYPE_TE, pTrunkEntry);
+	  zlog_err ("\ncannot add node to patricia %s %d", __FILE__,
+		    __LINE__);
+	  return E_ERR;
+	}
+    }
+  if ((pTunnel =
+       (RSVP_TUNNEL_PROPERTIES *) XMALLOC (MTYPE_TE,
+					   sizeof (RSVP_TUNNEL_PROPERTIES)))
+      == NULL)
+    {
+      zlog_err ("\ncannot allocate memory %s %d", __FILE__, __LINE__);
+      if (pTrunkEntry->Lsps == NULL)
+	{
+	  if (patricia_tree_del (pTree, &pTrunkEntry->Node) != E_OK)
+	    {
+	      zlog_err ("\ncannot delete node from patricia");
+	    }
+	  else
+	    XFREE (MTYPE_TE, pTrunkEntry);
+	}
+      return E_ERR;
+    }
+  pTunnel->TunnelId = PsbKey->Session.TunnelId;
+  pTunnel->adaptivity_timer.data.adaptivity_timer_data.key = *PsbKey;
+  pTunnel->lsp_setup_timer.data.lsp_setup_data.key = *PsbKey;
+  pTunnel->lsp_setup_retry_timer.data.lsp_setup_retry_data.key = *PsbKey;
+  pTunnel->cspf_retry_timer.data.cspf_retry_data.key = *PsbKey;
+  pTunnel->next = pTrunkEntry->Lsps;
+  pTrunkEntry->Lsps = pTunnel;
+  pTrunkEntry->TunnelsCounter++;
+  *ppNewTunnel = pTunnel;
+  return E_OK;
+}
+
+uns32
+DeleteTunnel (PSB_KEY * PsbKey, TRUNK_TYPE trunk_type)
+{
+  TRUNK_KEY trunk_key;
+  TRUNK_ENTRY *pTrunkEntry;
+  RSVP_TUNNEL_PROPERTIES *pTunnel, *pTunnelPrev = NULL;
+  PATRICIA_TREE *pTree;
+
+  if ((pTree = GetPatriciaTree (trunk_type)) == NULL)
+    {
+      zlog_err ("\ntrunk type is not specified %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  memset (&trunk_key, 0, sizeof (TRUNK_KEY));
+  trunk_key.Dest = PsbKey->Session.Dest;
+  if ((pTrunkEntry =
+       (TRUNK_ENTRY *) patricia_tree_get (pTree,
+					  (const uns8 *) &trunk_key)) != NULL)
+    {
+      pTunnel = pTrunkEntry->Lsps;
+      while (pTunnel != NULL)
+	{
+	  if (pTunnel->TunnelId == PsbKey->Session.TunnelId)
+	    {
+	      RSVP_LSP_PROPERTIES *pLsp, *pLspNext;
+	      if (pTrunkEntry->Lsps == pTunnel)
+		pTrunkEntry->Lsps = pTrunkEntry->Lsps->next;
+	      else
+		pTunnelPrev->next = pTunnel->next;
+	      pLsp = pTunnel->properties;
+	      while (pLsp != NULL)
+		{
+		  if (pLsp->forw_info.path.pErHopsList != NULL)
+		    XFREE (MTYPE_TE, pLsp->forw_info.path.pErHopsList);
+		  pLspNext = pLsp->next;
+		  XFREE (MTYPE_TE, pLsp);
+		  pLsp = pLspNext;
+		}
+	      XFREE (MTYPE_TE, pTunnel);
+	      pTrunkEntry->TunnelsCounter--;
+	      if (pTrunkEntry->Lsps == NULL)
+		{
+		  if (patricia_tree_del (pTree, &pTrunkEntry->Node) != E_OK)
+		    zlog_err ("\ncannot delete node from patricia %s %d",
+			      __FILE__, __LINE__);
+		  else
+		    XFREE (MTYPE_TE, pTrunkEntry);
+		}
+	      return E_OK;
+	    }
+	  pTunnelPrev = pTunnel;
+	  pTunnel = pTunnel->next;
+	}
+    }
+  return E_ERR;
+}
+
+void
+TE_RSVPTE_API_RsvpTunnelEstablished (RESV_NOTIFICATION * resv_notif)
+{
+  PSB_KEY PsbKey;
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  LSP_SM_NOTIF_DATA *pLspSmNotifData = NULL;
+  SM_CALL_T *pCall = NULL;
+  int i;
+  zlog_info ("entering of RsvpTunnelEstablished");
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+  PsbKey.Session = resv_notif->RsbKey.Session;
+
+  if (FindTunnel (&PsbKey, &pTunnel, ALL_TRUNKS) == FALSE)
+    {
+      zlog_err ("\nunexpected TUNNEL Dest %x Tunnel ID %x",
+		PsbKey.Session.Dest, PsbKey.Session.TunnelId);
+      return;
+    }
+  if (pTunnel->sm_handle == 0)	/* one is waiting for this... */
+    {
+      zlog_err ("\nThere is no SM to process RSVP TUNNEL %x TO %x",
+		pTunnel->TunnelId, PsbKey.Session.Dest);
+      return;
+    }
+  if ((pLspSmNotifData =
+       (LSP_SM_NOTIF_DATA *) XMALLOC (MTYPE_TE,
+				      sizeof (LSP_SM_NOTIF_DATA))) == NULL)
+    {
+      zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+      return;
+    }
+  pLspSmNotifData->ingress_lsp_notif = SETUP_COMPLETE_NOTIF;
+  pLspSmNotifData->PsbKey = PsbKey;
+
+  if (resv_notif->SharedExplicit)
+    {
+      pLspSmNotifData->data.setup_complete.NumberOfItems =
+	resv_notif->u.FilterDataSE.FilterSpecNumber;
+
+      if ((pLspSmNotifData->data.setup_complete.pLspLabel =
+	   (LSP_LABEL *) XMALLOC (MTYPE_TE,
+				  sizeof (LSP_LABEL) *
+				  (pLspSmNotifData->data.setup_complete.
+				   NumberOfItems))) == NULL)
+	{
+	  zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+	  return;
+	}
+      pLspSmNotifData->data.setup_complete.BW = resv_notif->u.FilterDataSE.BW;
+      for (i = 0; i < resv_notif->u.FilterDataSE.FilterSpecNumber; i++)
+	{
+	  pLspSmNotifData->data.setup_complete.pLspLabel[i].LspId
+	    =
+	    resv_notif->u.FilterDataSE.FilterDataArraySE[i].FilterSpec.LspId;
+	  pLspSmNotifData->data.setup_complete.pLspLabel[i].Label =
+	    resv_notif->u.FilterDataSE.FilterDataArraySE[i].ReceivedLabel;
+	  zlog_info ("LspId %x Label %x",
+		     resv_notif->u.FilterDataSE.FilterDataArraySE[i].
+		     FilterSpec.LspId,
+		     resv_notif->u.FilterDataSE.FilterDataArraySE[i].
+		     ReceivedLabel);
+	}
+    }
+  else
+    {
+      pLspSmNotifData->data.setup_complete.NumberOfItems = 1;
+      if ((pLspSmNotifData->data.setup_complete.pLspLabel =
+	   (LSP_LABEL *) XMALLOC (MTYPE_TE, sizeof (LSP_LABEL))) == NULL)
+	{
+	  zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+	  return;
+	}
+      pLspSmNotifData->data.setup_complete.BW = resv_notif->u.FilterDataFF.BW;
+      pLspSmNotifData->data.setup_complete.pLspLabel->LspId
+	= resv_notif->u.FilterDataFF.FilterSpec.LspId;
+      pLspSmNotifData->data.setup_complete.pLspLabel->Label
+	= resv_notif->u.FilterDataFF.ReceivedLabel;
+      zlog_info ("LspId %x Label %x",
+		 resv_notif->u.FilterDataFF.FilterSpec.LspId,
+		 resv_notif->u.FilterDataFF.ReceivedLabel);
+    }
+  if (pLspSmNotifData != NULL)
+    {
+      if ((pCall = sm_gen_sync_event_send ((SM_T *) (pTunnel->sm_handle),
+					   MPLS_SIGNALING_INGRESS_ESTABLISHED_NOTIFICATION_EVENT,
+					   pLspSmNotifData)) == NULL)
+	{
+	  zlog_err ("can not invoke sm %s %d", __FILE__, __LINE__);
+	}
+      sm_call (pCall);
+    }
+  zlog_info ("leaving of RsvpTunnelEstablished");
+}
+
+
+void
+RsvpTunnelsDump ()
+{
+  TRUNK_KEY trunk_key;
+  TRUNK_ENTRY *pTrunkEntry;
+  int i;
+
+  memset (&trunk_key, 0, sizeof (TRUNK_KEY));
+
+  for (i = 0; i < ALL_TRUNKS; i++)
+    {
+      PATRICIA_TREE *pTree;
+
+      if ((pTree = GetPatriciaTree (i)) == NULL)
+	{
+	  zlog_info ("\ncannot get patricia tree %s %d", __FILE__, __LINE__);
+	  continue;
+	}
+      while ((pTrunkEntry =
+	      (TRUNK_ENTRY *) patricia_tree_getnext (pTree,
+						     (const uns8 *)
+						     &trunk_key)) != NULL)
+	{
+	  RSVP_TUNNEL_PROPERTIES *pTunnel = pTrunkEntry->Lsps;
+	  while (pTunnel != NULL)
+	    {
+	      RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties;
+
+	      zlog_info
+		("RSVP TUNNEL %x AllocBW %f ReqBW %f LSP ID %x ReRoute %x",
+		 pTunnel->TunnelId, pTunnel->AllocatedBW, pTunnel->RequiredBW,
+		 pTunnel->LspId, pTunnel->ReRoute);
+	      zlog_info
+		("\nAdjustment Required %x UserLspName %s StaticPath %s Adaptivity %x LspSetup %x LspSetupRetry %x",
+		 pTunnel->AdjustmentRequired, pTunnel->UserLspName,
+		 pTunnel->StaticPathName, pTunnel->adaptivity_timer.is_active,
+		 pTunnel->lsp_setup_timer.is_active,
+		 pTunnel->lsp_setup_retry_timer.is_active);
+	      if (pTunnel->sm_handle != 0)
+		zlog_info ("\nTunnel's SM %x",
+			   ((SM_T *) pTunnel->sm_handle)->sm_type);
+
+	      while (pRsvpLsp != NULL)
+		{
+		  zlog_info
+		    ("\nRSVP LSP: LSP ID %x RequestedBW %f Label(out) %x",
+		     pRsvpLsp->LspId, pRsvpLsp->RequestedBW, pRsvpLsp->Label);
+
+		  if (pRsvpLsp->tunneled == FALSE)
+		    {
+		      int j;
+		      zlog_info ("\nPath:");
+		      for (j = 0; j < pRsvpLsp->forw_info.path.HopCount; j++)
+			zlog_info ("\nER HOP#%d %x", j + 1,
+				   pRsvpLsp->forw_info.path.pErHopsList[j]);
+		      zlog_info
+			("\nRSVP LSP Backup Info: Merge node %x OutIf %x Protected node %x Bypass label %x Merege node label valid %x Merge node label %x OutIF %x",
+			 pRsvpLsp->forw_info.path.BackupForwardingInformation.
+			 frr_key.merge_node,
+			 pRsvpLsp->forw_info.path.BackupForwardingInformation.
+			 frr_key.OutIfIndex,
+			 pRsvpLsp->forw_info.path.BackupForwardingInformation.
+			 frr_key.protected_node,
+			 pRsvpLsp->forw_info.path.BackupForwardingInformation.
+			 BypassTunnelsLabel,
+			 pRsvpLsp->forw_info.path.BackupForwardingInformation.
+			 MergeNodeLabelValid,
+			 pRsvpLsp->forw_info.path.BackupForwardingInformation.
+			 MergeNodeLabel,
+			 pRsvpLsp->forw_info.path.BackupForwardingInformation.
+			 OutIf);
+		    }
+		  pRsvpLsp = pRsvpLsp->next;
+		}
+	      pTunnel = pTunnel->next;
+	    }
+	  trunk_key = pTrunkEntry->trunk_key;
+	}
+    }
+}
+
+void
+UserLspsDump (char *pName, struct vty *vty)
+{
+  USER_LSP_LIST *pUserLsp = UserLspListHead;
+
+
+  while (pUserLsp != NULL)
+    {
+      RSVP_TUNNEL_PROPERTIES *pTunnel = pUserLsp->lsp->pUserLspTunnels;
+      if (pName)
+	{
+	  if (strcmp (pName, pUserLsp->lsp->params.LspName) != 0)
+	    {
+	      pUserLsp = pUserLsp->next;
+	      continue;
+	    }
+	}
+      vty_out (vty, "Tunnel's name %s%s",
+	       pUserLsp->lsp->params.LspName, VTY_NEWLINE);
+      vty_out (vty, "Destination %x%s", pUserLsp->lsp->params.to,
+	       VTY_NEWLINE);
+      if (pUserLsp->lsp->params.Primary[0] != '\0')
+	vty_out (vty, "Primary path %s%s", pUserLsp->lsp->params.Primary,
+		 VTY_NEWLINE);
+      else
+	vty_out (vty, "No primary path%s", VTY_NEWLINE);
+      {
+	LSP_PATH_SHARED_PARAMS *pParams = &pUserLsp->lsp->params.lsp_params;
+	vty_out (vty, "Common tunnel's parameters%s", VTY_NEWLINE);
+	vty_out (vty, "Bandwidth %f %s", pParams->BW, VTY_NEWLINE);
+	vty_out (vty, "Setup priority %d Hold priority %d%s",
+		 pParams->setup_priority, pParams->hold_priority,
+		 VTY_NEWLINE);
+	vty_out (vty, "Hop limit %d%s", pParams->hop_limit, VTY_NEWLINE);
+	vty_out (vty, "Optimize timer %d%s", pParams->optimize_timer,
+		 VTY_NEWLINE);
+	vty_out (vty, "Record route: %s%s", (pParams->record) ? "yes" : "no",
+		 VTY_NEWLINE);
+      }
+      if (pUserLsp->lsp->params.PrimaryPathParams != NULL)
+	{
+	  LSP_PATH_SHARED_PARAMS *pParams =
+	    pUserLsp->lsp->params.PrimaryPathParams;
+
+	  vty_out (vty, "Primary path parameters %s", VTY_NEWLINE);
+	  vty_out (vty, "Bandwidth %f %s", pParams->BW, VTY_NEWLINE);
+	  vty_out (vty, "Setup priority %d Hold priority %d%s",
+		   pParams->setup_priority, pParams->hold_priority,
+		   VTY_NEWLINE);
+	  vty_out (vty, "Hop limit %d%s", pParams->hop_limit, VTY_NEWLINE);
+	  vty_out (vty, "Optimize timer %d%s", pParams->optimize_timer,
+		   VTY_NEWLINE);
+	  vty_out (vty, "Record route: %s%s",
+		   (pParams->record) ? "yes" : "no", VTY_NEWLINE);
+	}
+      {
+	SECONDARY_PATH_LIST *pSecPathList =
+	  pUserLsp->lsp->params.SecondaryPaths;
+	while (pSecPathList != NULL)
+	  {
+	    vty_out (vty, "Secondary %s%s", pSecPathList->Secondary,
+		     VTY_NEWLINE);
+	    if (pSecPathList->SecondaryPathParams != NULL)
+	      {
+		LSP_PATH_SHARED_PARAMS *pParams =
+		  pSecPathList->SecondaryPathParams;
+		vty_out (vty, "Bandwidth %f %s", pParams->BW, VTY_NEWLINE);
+		vty_out (vty, "Setup priority %d Hold priority %d%s",
+			 pParams->setup_priority, pParams->hold_priority,
+			 VTY_NEWLINE);
+		vty_out (vty, "Hop limit %d%s", pParams->hop_limit,
+			 VTY_NEWLINE);
+		vty_out (vty, "Optimize timer %d%s", pParams->optimize_timer,
+			 VTY_NEWLINE);
+		vty_out (vty, "Record route: %s%s",
+			 (pParams->record) ? "yes" : "no", VTY_NEWLINE);
+		vty_out (vty, "Standby %s%s",
+			 (pParams->standby) ? "yes" : "no", VTY_NEWLINE);
+	      }
+	    pSecPathList = pSecPathList->next;
+	  }
+      }
+      while (pTunnel != NULL)
+	{
+	  RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties;
+	  vty_out (vty, "Tunnel ID %x%s", pTunnel->TunnelId, VTY_NEWLINE);
+	  if (pTunnel->LspId)
+	    {
+	      vty_out (vty, " is UP%s", VTY_NEWLINE);
+	    }
+	  if (pTunnel->StaticPathName[0] != '\0')
+	    {
+	      vty_out (vty, "Static Path Name %s%s",
+		       pTunnel->StaticPathName, VTY_NEWLINE);
+	    }
+	  while (pRsvpLsp != NULL)
+	    {
+	      vty_out (vty, "LSP ID %x", pRsvpLsp->LspId);
+	      if (pTunnel->LspId == pRsvpLsp->LspId)
+		{
+		  vty_out (vty, " is installed");
+		}
+	      vty_out (vty, "%s", VTY_NEWLINE);
+	      if (pRsvpLsp->tunneled == FALSE)
+		{
+		  int k;
+
+		  vty_out (vty, "Setup Prio %d Hold Prio %d %s",
+			   pRsvpLsp->SetupPriority, pRsvpLsp->HoldPriority,
+			   VTY_NEWLINE);
+		  vty_out (vty, "ExcludeAny %x IncludeAny %x IncludeAll %x%s",
+			   pRsvpLsp->ExcludeAny, pRsvpLsp->IncludeAny,
+			   pRsvpLsp->IncludeAll, VTY_NEWLINE);
+		  if (pRsvpLsp->FrrDesired)
+		    {
+		      vty_out (vty, "FastReRoute desired%s", VTY_NEWLINE);
+		    }
+		  if (pRsvpLsp->LabelRecordingDesired)
+		    {
+		      vty_out (vty, "Label Recording desired%s", VTY_NEWLINE);
+		    }
+		  if (pRsvpLsp->Label)
+		    {
+		      vty_out (vty, "Label %x%s", pRsvpLsp->Label,
+			       VTY_NEWLINE);
+		    }
+		  if (pRsvpLsp->RequestedBW)
+		    {
+		      vty_out (vty, "Bandwidth %f%s", pRsvpLsp->RequestedBW,
+			       VTY_NEWLINE);
+		    }
+		  vty_out (vty, "Path:%s", VTY_NEWLINE);
+		  for (k = 0; k < pRsvpLsp->forw_info.path.HopCount; k++)
+		    {
+		      vty_out (vty, "HOP %x%s",
+			       pRsvpLsp->forw_info.path.pErHopsList[k],
+			       VTY_NEWLINE);
+		    }
+		}
+	      pRsvpLsp = pRsvpLsp->next;
+	    }
+	  pTunnel = pTunnel->next_user_lsp_tunnel;
+	}
+      if (pName)
+	{
+	  if (strcmp (pName, pUserLsp->lsp->params.LspName) == 0)
+	    {
+	      break;
+	    }
+	}
+      pUserLsp = pUserLsp->next;
+    }
+}
+
+void
+TE_RSVPTE_API_RsvpResvTear (RESV_TEAR_NOTIF * pResvTearNotif)
+{
+  PSB_KEY PsbKey;
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  LSP_SM_NOTIF_DATA *pLspSmNotifData = NULL;
+  SM_CALL_T *pCall = NULL;
+  zlog_info ("inside of RsvpResvTear");
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+  PsbKey.Session = pResvTearNotif->RsbKey.Session;
+
+  if (FindTunnel (&PsbKey, &pTunnel, ALL_TRUNKS) == FALSE)
+    {
+      zlog_err ("\ncannot find tunnel %x %x %x",
+		PsbKey.Session.Dest,
+		PsbKey.Session.TunnelId, PsbKey.Session.ExtTunelId);
+      return;
+    }
+  if (pTunnel->sm_handle == 0)	/* one is waiting for this... */
+    {
+      zlog_err ("\nThere is no SM for tunnel %x %x %x",
+		PsbKey.Session.Dest,
+		PsbKey.Session.TunnelId, PsbKey.Session.ExtTunelId);
+      return;
+    }
+  if ((pLspSmNotifData =
+       (LSP_SM_NOTIF_DATA *) XMALLOC (MTYPE_TE,
+				      sizeof (LSP_SM_NOTIF_DATA))) == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      return;
+    }
+  pLspSmNotifData->ingress_lsp_notif = TEAR_DOWN_NOTIF;
+  pLspSmNotifData->PsbKey.Session = pResvTearNotif->RsbKey.Session;
+  pLspSmNotifData->data.tunnel_down.Lsps.LspId =
+    pResvTearNotif->FilterSpec.LspId;
+  pLspSmNotifData->data.tunnel_down.NumberOfItems = 1;
+  if (pLspSmNotifData != NULL)
+    {
+
+      zlog_info ("\nDestIP %x Tunnel ID %x LSP ID %x",
+		 pLspSmNotifData->PsbKey.Session.Dest,
+		 pLspSmNotifData->PsbKey.Session.TunnelId,
+		 pLspSmNotifData->data.tunnel_down.Lsps.LspId);
+      if ((pCall = sm_gen_sync_event_send ((SM_T *) pTunnel->sm_handle,
+					   MPLS_SIGNALING_INGRESS_FAILED_NOTIFICATION_EVENT,
+					   pLspSmNotifData)) == NULL)
+	{
+	  zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+	}
+      else
+	sm_call (pCall);
+    }
+}
+
+void
+TE_RSVPTE_API_RsvpPathErr (PATH_ERR_NOTIF * pPathErrNotif)
+{
+  PSB_KEY PsbKey;
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  LSP_SM_NOTIF_DATA *pLspSmNotifData = NULL;
+  SM_CALL_T *pCall = NULL;
+  zlog_info ("inside of RsvpPathErr");
+  memset (&PsbKey, 0, sizeof (PSB_KEY));
+  PsbKey.Session = pPathErrNotif->PsbKey.Session;
+
+  if (FindTunnel (&PsbKey, &pTunnel, ALL_TRUNKS) == FALSE)
+    {
+      zlog_err ("\ncannot find tunnel %x %x %x",
+		PsbKey.Session.Dest,
+		PsbKey.Session.TunnelId, PsbKey.Session.ExtTunelId);
+      return;
+    }
+  if (pTunnel->sm_handle == 0)	/* one is waiting for this... */
+    {
+      zlog_err ("\nThere is no SM for tunnel %x %x %x",
+		PsbKey.Session.Dest,
+		PsbKey.Session.TunnelId, PsbKey.Session.ExtTunelId);
+      return;
+    }
+  if ((pLspSmNotifData =
+       (LSP_SM_NOTIF_DATA *) XMALLOC (MTYPE_TE,
+				      sizeof (LSP_SM_NOTIF_DATA))) == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      return;
+    }
+  if (pPathErrNotif->ErrSpec.ErrCode == NOTIFY_ERR_CODE)
+    {
+      if (((pPathErrNotif->ErrSpec.ErrVal & 0xC000) == 0)
+	  && ((pPathErrNotif->ErrSpec.ErrVal & 0xC000) ==
+	      RRO_TOO_LARGE_4_MTU))
+	{
+	  zlog_info ("Error code %d is not handled yet",
+		     pPathErrNotif->ErrSpec.ErrCode);
+	  XFREE (MTYPE_TE, pLspSmNotifData);
+	  return;
+	}
+    }
+  pLspSmNotifData->ingress_lsp_notif = SETUP_FAILED_NOTIF;
+  pLspSmNotifData->PsbKey.Session = pPathErrNotif->PsbKey.Session;
+  pLspSmNotifData->data.setup_failed.LspId =
+    pPathErrNotif->PsbKey.SenderTemplate.LspId;
+  pLspSmNotifData->data.setup_failed.IpAddr = pPathErrNotif->ErrSpec.IpAddr;
+
+  if ((pCall = sm_gen_sync_event_send ((SM_T *) pTunnel->sm_handle,
+				       MPLS_SIGNALING_INGRESS_FAILED_NOTIFICATION_EVENT,
+				       pLspSmNotifData)) == NULL)
+    {
+      zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+    }
+  else
+    sm_call (pCall);
+}
+
+TRUNK_ENTRY *
+GetTunnelsTrunk (TRUNK_KEY * trunk_key)
+{
+  return (TRUNK_ENTRY *) patricia_tree_get (&NonSeparateTunnelsLspsTrunkTree,
+					    (const uns8 *) trunk_key);
+}
+
+TRUNK_ENTRY *
+NewTunnelsTrunk (TRUNK_KEY * trunk_key)
+{
+  TRUNK_ENTRY *pTrunkEntry;
+
+  if ((pTrunkEntry =
+       (TRUNK_ENTRY *) XMALLOC (MTYPE_TE, sizeof (TRUNK_ENTRY))) == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  if ((pTrunkEntry->pTrunkData =
+       (TRUNK_DATA *) XMALLOC (MTYPE_TE, sizeof (TRUNK_DATA))) == NULL)
+    {
+      XFREE (MTYPE_TE, pTrunkEntry);
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+
+  pTrunkEntry->trunk_key = *trunk_key;
+  pTrunkEntry->Node.key_info = (uns8 *) & pTrunkEntry->trunk_key;
+
+  if (patricia_tree_add (&NonSeparateTunnelsLspsTrunkTree, &pTrunkEntry->Node)
+      != E_OK)
+    {
+      zlog_err ("\ncannot add node to patricia %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  return pTrunkEntry;
+}
+
+BOOL
+PathsEqual (ER_HOP_L_LIST * pErHopsLList, IPV4_ADDR * pIpAddr, int HopCount)
+{
+  int i;
+  for (i = 0; ((i < HopCount) && (pErHopsLList != NULL));
+       i += 2, pErHopsLList = pErHopsLList->next)
+    {
+      if (pErHopsLList->er_hop->remote_ip != pIpAddr[i])
+	{
+	  /*zlog_info("\nlocal ip %x %x",pErHopsLList->er_hop->local_ip,pIpAddr[i]); */
+	  return FALSE;
+	}
+    }
+  return TRUE;
+}
+
+PATH *
+GetLspPath (RSVP_LSP_PROPERTIES * pRsvpLsp)
+{
+  PATH_L_LIST *pPathLList = NULL;
+  IPV4_ADDR dest;
+
+  if (pRsvpLsp->tunneled)
+    {
+      return NULL;
+    }
+  if (pRsvpLsp->forw_info.path.pErHopsList == NULL)
+    {
+      return NULL;
+    }
+  dest =
+    pRsvpLsp->forw_info.path.pErHopsList[pRsvpLsp->forw_info.path.HopCount -
+					 1];
+
+  if (IsDestinationIntraArea (dest, &pPathLList) != E_OK)
+    {
+      zlog_err ("\nsome error in IsDestinationIntraArea %s %d ...", __FILE__,
+		__LINE__);
+      return NULL;
+    }
+  zlog_info ("\npPathLList %x dest %x", pPathLList, dest);
+  while (pPathLList != NULL)
+    {
+      if ((pPathLList->pPath->PathProperties.PathHopCount >=
+	   (pRsvpLsp->forw_info.path.HopCount / 2))
+	  &&
+	  (PathsEqual
+	   (pPathLList->pPath->u.er_hops_l_list,
+	    pRsvpLsp->forw_info.path.pErHopsList,
+	    pRsvpLsp->forw_info.path.HopCount) == TRUE))
+	{
+	  return pPathLList->pPath;
+	}
+      pPathLList = pPathLList->next;
+    }
+  return NULL;
+}
+
+uns8 TunnelIds[0xFFFF];
+
+uns16
+NewTunnelId (PSB_KEY * PsbKey)
+{
+  uns16 TunnelId = 0;
+  uns32 i;
+  PATRICIA_TREE *pTree;
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  TRUNK_ENTRY *pTrunkEntry;
+  TRUNK_KEY trunk_key;
+
+  memset (&trunk_key, 0, sizeof (TRUNK_KEY));
+  memset (TunnelIds, 0, sizeof (uns8) * 0xFFFF);
+
+  trunk_key.Dest = PsbKey->Session.Dest;
+
+  for (i = 0; i < ALL_TRUNKS; i++)
+    {
+      pTree = GetPatriciaTree (i);
+      if ((pTrunkEntry =
+	   (TRUNK_ENTRY *) patricia_tree_get (pTree,
+					      (const uns8 *) &trunk_key)) !=
+	  NULL)
+	{
+	  pTunnel = pTrunkEntry->Lsps;
+	  while (pTunnel != NULL)
+	    {
+	      TunnelIds[pTunnel->TunnelId - 1] = 1;
+	      pTunnel = pTunnel->next;
+	    }
+	}
+    }
+  for (i = 0; i < 0xFFFF; i++)
+    if (TunnelIds[i] == 0)
+      TunnelId = i + 1;
+  return TunnelId;
+}
+
+uns32
+UserLspAdd (USER_LSP * pUserLsp)
+{
+  USER_LSP_LIST *pUserLspList;
+
+  if ((pUserLspList =
+       (USER_LSP_LIST *) XMALLOC (MTYPE_TE, sizeof (USER_LSP_LIST))) == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  pUserLspList->lsp = pUserLsp;
+  pUserLspList->next = UserLspListHead;
+  UserLspListHead = pUserLspList;
+  return E_OK;
+}
+
+USER_LSP *
+UserLspGet (char *pLspName)
+{
+  USER_LSP_LIST *pUserLsp = UserLspListHead;
+  zlog_info ("entering UserLspGet");
+  while (pUserLsp != NULL)
+    {
+      if (strcmp (pLspName, pUserLsp->lsp->params.LspName) == 0)
+	{
+	  zlog_info ("leaving UserLspGet+");
+	  return pUserLsp->lsp;
+	}
+      pUserLsp = pUserLsp->next;
+    }
+  zlog_info ("leaving UserLspGet-");
+  return NULL;
+}
+
+uns32
+UserLspDelete (char *pLspName)
+{
+  USER_LSP_LIST *pUserLsp = UserLspListHead, *pUserLspPrev = NULL;
+  SECONDARY_PATH_LIST *pSecondaryPathList, *pSecondaryPathListNext;
+
+  while (pUserLsp != NULL)
+    {
+      if (strcmp (pLspName, pUserLsp->lsp->params.LspName) == 0)
+	{
+	  if (pUserLsp == UserLspListHead)
+	    UserLspListHead = UserLspListHead->next;
+	  else
+	    pUserLspPrev->next = pUserLsp->next;
+#if 0
+	  if (pUserLsp->lsp->params.FastReroute != NULL)
+	    XFREE (MTYPE_TE, pUserLsp->lsp->params.FastReroute);
+#endif
+	  if (pUserLsp->lsp->params.PrimaryPathParams != NULL)
+	    XFREE (MTYPE_TE, pUserLsp->lsp->params.PrimaryPathParams);
+	  pSecondaryPathList = pUserLsp->lsp->params.SecondaryPaths;
+	  while (pSecondaryPathList != NULL)
+	    {
+	      if (pSecondaryPathList->SecondaryPathParams != NULL)
+		XFREE (MTYPE_TE, pSecondaryPathList->SecondaryPathParams);
+	      pSecondaryPathListNext = pSecondaryPathList->next;
+	      XFREE (MTYPE_TE, pSecondaryPathList);
+	      pSecondaryPathList = pSecondaryPathListNext;
+	    }
+	  XFREE (MTYPE_TE, pUserLsp->lsp);
+	  XFREE (MTYPE_TE, pUserLsp);
+	  return E_OK;
+	}
+      pUserLspPrev = pUserLsp;
+      pUserLsp = pUserLsp->next;
+    }
+  return E_ERR;
+}
+
+void
+UserLspLoop (void (*CallBackFunc) (USER_LSP *, void *), void *data)
+{
+  USER_LSP_LIST *pUserLsp = UserLspListHead, *pUserLspNext;
+  while (pUserLsp != NULL)
+    {
+      pUserLspNext = pUserLsp->next;
+      CallBackFunc (pUserLsp->lsp, data);
+      pUserLsp = pUserLspNext;
+    }
+}
+
+uns16
+GetPimaryTunnelId (char *pLspName)
+{
+  USER_LSP_LIST *pUserLsp = UserLspListHead;
+  while (pUserLsp != NULL)
+    {
+      if (strcmp (pLspName, pUserLsp->lsp->params.LspName) == 0)
+	{
+	  if (pUserLsp->lsp->pUserLspTunnels != NULL)
+	    return pUserLsp->lsp->pUserLspTunnels->TunnelId;
+	}
+      pUserLsp = pUserLsp->next;
+    }
+  return 0;
+}
+
+BOOL
+RightPathCheaper (PATH_PROPERTIES * pLeftPathProp,
+		  PATH_PROPERTIES * pRightPathProp, uns8 Priority)
+{
+  if (pLeftPathProp->PathCost < pRightPathProp->PathCost)
+    {
+      zlog_info ("\nmore expensive...");
+      return FALSE;
+    }
+  if (pLeftPathProp->PathCost > pRightPathProp->PathCost)
+    {
+      zlog_info ("\ncheaper....");
+      return TRUE;
+    }
+  if (pLeftPathProp->PathHopCount < pRightPathProp->PathHopCount)
+    {
+      zlog_info ("\nlonger...");
+      return FALSE;
+    }
+  if (pLeftPathProp->PathHopCount > pRightPathProp->PathHopCount)
+    {
+      zlog_info ("\nshorter....");
+      return TRUE;
+    }
+  if (pLeftPathProp->PathReservableBW[Priority] >
+      pRightPathProp->PathReservableBW[Priority])
+    {
+      zlog_info ("\nless reservable BW....");
+      return FALSE;
+    }
+  if (pLeftPathProp->PathReservableBW[Priority] <
+      pRightPathProp->PathReservableBW[Priority])
+    {
+      zlog_info ("\nmore reservable BW....");
+      return TRUE;
+    }
+  if (pLeftPathProp->PathMaxLspBW > pRightPathProp->PathMaxLspBW)
+    {
+      zlog_info ("\nless Max LSP BW....");
+      return FALSE;
+    }
+  if (pLeftPathProp->PathMaxLspBW < pRightPathProp->PathMaxLspBW)
+    {
+      zlog_info ("\nmore Max LSP BW....");
+      return TRUE;
+    }
+  if (pLeftPathProp->PathMaxReservableBW >
+      pRightPathProp->PathMaxReservableBW)
+    {
+      zlog_info ("\nmore Max Reservable BW....");
+      return FALSE;
+    }
+  if (pLeftPathProp->PathMaxReservableBW <
+      pRightPathProp->PathMaxReservableBW)
+    {
+      zlog_info ("\nless Max Reservable BW....");
+      return TRUE;
+    }
+  return FALSE;
+}
+
+uns32
+TunnelIfIdRelease (uns32 IfIndex)
+{
+  if ((IfIndex < MAX_TUNNELS_IF) && (IfIndex > 6))
+    {
+      tunnels_if_array[IfIndex] = 0;
+      return E_OK;
+    }
+  return E_ERR;
+}
+
+INGRESS_API *
+CreateRequest2Signalling (IPV4_ADDR dest,
+			  uns16 tunnel_id,
+			  uns32 ErHopsNumber,
+			  ER_HOP * pErHops,
+			  float BW,
+			  uns8 SetupPriority,
+			  uns8 HoldPriority,
+			  uns8 Flags,
+			  uns32 ExcludeAny,
+			  uns32 IncludeAny, uns32 IncludeAll)
+{
+  INGRESS_API *pOpenLspParams;
+  int i;
+
+  zlog_info ("entering CreateRequest2Signalling");
+
+  if ((pOpenLspParams =
+       (INGRESS_API *) XMALLOC (MTYPE_TE, sizeof (INGRESS_API))) == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d...", __FILE__, __LINE__);
+      return NULL;
+    }
+  pOpenLspParams->Egress = dest;
+  pOpenLspParams->src_ip = rdb_get_router_id ();
+  pOpenLspParams->TunnelId = tunnel_id;
+  pOpenLspParams->BW = BW;
+  pOpenLspParams->HopNum = ErHopsNumber;
+  for (i = 0; i < pOpenLspParams->HopNum; i++, pErHops++)
+    {
+      pOpenLspParams->Path[i].IpAddr = pErHops->IpAddr;
+      pOpenLspParams->Path[i].PrefixLength = pErHops->PrefixLength;
+      pOpenLspParams->Path[i].Loose = pErHops->Loose;
+    }
+  pOpenLspParams->Shared = TRUE;
+  if (Flags & LABEL_RECORDING_DESIRED)
+    pOpenLspParams->LabelRecordingDesired = TRUE;
+  if (Flags & LOCAL_PROTECTION_DESIRED)
+    pOpenLspParams->FrrDesired = TRUE;
+  pOpenLspParams->SetPrio = SetupPriority;
+  pOpenLspParams->HoldPrio = HoldPriority;
+  pOpenLspParams->ExcludeAny = ExcludeAny;
+  pOpenLspParams->IncludeAny = IncludeAny;
+  pOpenLspParams->IncludeAll = IncludeAll;
+  zlog_info ("leaving CreateRequest2Signalling");
+  return pOpenLspParams;
+}
diff -Naur quagga-0.99.10/rsvpd/te_common.h quagga-mpls/rsvpd/te_common.h
--- quagga-0.99.10/rsvpd/te_common.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_common.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,115 @@
+
+#ifndef __COMMON_PROC_H__
+#define __COMMON_PROC_H__
+
+typedef enum
+{
+  LSP_SM,
+  TRANSIT_LSP_SM,
+  CONSTRAINT_ROUTE_RESOLUTION_SM,
+  FAST_REROUTE_SM,
+  MAX_SM
+} SM_E;
+
+typedef enum
+{
+  USER_LSP_REQUEST_EVENT,
+  INGRESS_LSP_REQUEST_EVENT,
+  INGRESS_LSP_DELETE_REQUEST_EVENT,
+  INGRESS_LSP_OPERATION_COMPLETE_EVENT,
+  INGRESS_LSP_OPERATION_FAILED_EVENT,
+  TRANSIT_REQ_EVENT,
+  SLA_USER_REQUEST_EVENT,
+  SLA_DELETE_USER_REQUEST_EVENT,
+  CONSTRAINT_ROUTE_RESOLUTION_REQ_EVENT,
+  CONSTRAINT_ROUTE_RESOLVED_EVENT,
+  CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT,
+  CSPF_REPLY_EVENT,
+  DYNAMIC_ADAPTATION_REQ_EVENT,
+  SLA_ADAPTATION_REQ_EVENT,
+  SLA_ADAPTATION_COMPLETE_EVENT,
+  SLA_ADAPTATION_FAILED_EVENT,
+  MPLS_SIGNALING_INGRESS_ESTABLISHED_NOTIFICATION_EVENT,
+  MPLS_SIGNALING_INGRESS_FAILED_NOTIFICATION_EVENT,
+  LSP_SETUP_TIMER_EXPIRY,
+  ADAPTIVITY_TIMER_EXPIRY,
+  RETRY_TIMER_EXPIRY,
+  BYPASS_SETUP_REQ_EVENT,
+  RRO_CHANGED_EVENT,
+  CSPF_RETRY_EVENT,
+  SM_MAX_EVENT
+} SM_EVENT_E;
+
+typedef struct
+{
+  SM_EVENT_E event;
+  void *data;
+} SM_EVENT_T;
+
+typedef struct _sm_t_
+{
+  SM_E sm_type;
+  int state;
+  struct _sm_t_ *caller;
+  void *data;
+} SM_T;
+
+typedef struct
+{
+  SM_T *sm;
+  SM_EVENT_T *sm_data;
+} SM_CALL_T;
+
+
+#define INIT_STATE  1
+
+typedef void (*LSP_LOOP_CALLBACK_T) (USER_LSP *, void *);
+
+INGRESS_API *CreateRequest2Signalling (IPV4_ADDR dest,
+				       uns16 tunnel_id,
+				       uns32 ErHopsNumber,
+				       ER_HOP * pErHops,
+				       float BW,
+				       uns8 SetupPriority,
+				       uns8 HoldPriority,
+				       uns8 Flags,
+				       uns32 ExcludeAny,
+				       uns32 IncludeAny, uns32 IncludeAll);
+BOOL RightPathCheaper (PATH_PROPERTIES * pLeftPathProp,
+		       PATH_PROPERTIES * pRightPathProp, uns8 Priority);
+uns16 GetPimaryTunnelId (char *pLspName);
+uns32 UserLspDelete (char *pLspName);
+USER_LSP *UserLspGet (char *pLspName);
+uns32 UserLspAdd (USER_LSP * pUserLsp);
+uns16 NewTunnelId (PSB_KEY * PsbKey);
+PATH *GetLspPath (RSVP_LSP_PROPERTIES * pRsvpLsp);
+BOOL PathsEqual (ER_HOP_L_LIST * pErHopsLList, IPV4_ADDR * pIpAddr,
+		 int HopCount);
+TRUNK_ENTRY *NewTunnelsTrunk (TRUNK_KEY * trunk_key);
+TRUNK_ENTRY *GetTunnelsTrunk (TRUNK_KEY * trunk_key);
+void TE_RSVPTE_API_RsvpPathErr (PATH_ERR_NOTIF * pPathErrNotif);
+void TE_RSVPTE_API_RsvpResvTear (RESV_TEAR_NOTIF * pResvTearNotif);
+//void UserLspsDump(char *pName,int PortNum);
+void RsvpTunnelsDump ();
+void TE_RSVPTE_API_RsvpTunnelEstablished (RESV_NOTIFICATION * resv_notif);
+uns32 DeleteTunnel (PSB_KEY * PsbKey, TRUNK_TYPE trunk_type);
+uns32 NewTunnel (PSB_KEY * PsbKey, RSVP_TUNNEL_PROPERTIES ** ppNewTunnel,
+		 TRUNK_TYPE trunk_type);
+uns32 NewRsvpLsp (RSVP_TUNNEL_PROPERTIES * pTunnel,
+		  RSVP_LSP_PROPERTIES ** ppRsvpLsp);
+BOOL FindTunnel (PSB_KEY * PsbKey, RSVP_TUNNEL_PROPERTIES ** ppTunnel,
+		 TRUNK_TYPE trunk_type);
+uns32 TeApplicationInit ();
+void te_stop_timer (TE_TMR * tmr);
+uns32 te_start_timer (TE_TMR * tmr, TE_TMR_E type, uns32 period);
+void sm_call (SM_CALL_T * sm_packet);
+void sm_gen_free (SM_T * sm);
+SM_T *sm_gen_alloc (SM_T * caller, SM_E sm_type);
+SM_CALL_T *sm_gen_sync_event_send (SM_T * sm, SM_EVENT_E event, void *data);
+int sm_gen_async_event_send (SM_T * sm, SM_EVENT_E event, void *data);
+void sm_gen_event_trace (SM_E event);
+void UserLspLoop (void (*CallBackFunc) (USER_LSP *, void *), void *data);
+void UserLspsDump (char *pName, struct vty *vty);
+uns32 NewTunnelIfId (IPV4_ADDR dest, uns32 IfIndex);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te_crr.c quagga-mpls/rsvpd/te_crr.c
--- quagga-0.99.10/rsvpd/te_crr.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_crr.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,2095 @@
+/* Module:   constraint_route_resolution.c
+   Contains: TE application constraint route resolution
+   state machine
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+
+#include "te.h"
+#include "te_cspf.h"
+
+static E_RC CreateConstraintRouteResReq (SM_T * pSm, int handle);
+
+static uns32 InterAreaConstraintRouteResolution (SM_T * pSm,
+						 CONSTRAINT_ROUTE_RESOLUTION_ARGS
+						 * args);
+static uns32 IntraAreaConstraintRouteResolution (SM_T * pSm,
+						 CONSTRAINT_ROUTE_RESOLUTION_ARGS
+						 * args);
+static uns32 NextHopConstraintRouteResolution (SM_T * pSm,
+					       CONSTRAINT_ROUTE_RESOLUTION_ARGS
+					       * args);
+static uns32 DetermineDestinationType (SM_T * pSm,
+				       CONSTRAINT_ROUTE_RESOLUTION_ARGS *
+				       args, DESTINATION_TYPE_E * type);
+static BOOL OwnTunnel (IPV4_ADDR addr);
+
+static BOOL TunnelsTunnel2BeModified (CONSTRAINT_ROUTE_RESOLUTION_ARGS * args,
+				      SM_T * pSm);
+
+static BOOL SummaryAdmissionControl (SUMMARY_PROPERTIES * pSummaryProperties,
+				     CONSTRAINT_ROUTE_RESOLUTION_ARGS * args);
+static RSVP_TUNNEL_PROPERTIES *FindTunnelByPath (TRUNK_ENTRY * pTrunkEntry,
+						 PATH * pPath);
+
+static BOOL SummaryTieBreak (SUMMARY_PROPERTIES * pLeftSummary,
+			     PATH * pLeftPath,
+			     SUMMARY_PROPERTIES * pRightSummary,
+			     PATH * pRightPath, uns8 Priority);
+static int SelectAreaBorder (SM_T * pSm, ABRS_L_LIST * pAbrs,
+			     CONSTRAINT_ROUTE_RESOLUTION_ARGS * args,
+			     ABR ** ppAbr, PATH ** ppPath);
+static BOOL PathAdmissionControl (PATH * pPath,
+				  CONSTRAINT_ROUTE_RESOLUTION_ARGS * args);
+
+static uns32 GetSharedHopsNumber (PATH * pPath,
+				  CONSTRAINT_ROUTE_RESOLUTION_ARGS * args);
+
+static BOOL PathTieBreak (PATH * pLeftPath,
+			  PATH * pRigthPath,
+			  CONSTRAINT_ROUTE_RESOLUTION_ARGS * args,
+			  uns32 * CurrentSharedHopsNumber);
+
+static BOOL LinkAdmissionControl (TE_LINK_PROPERTIES * pTeLinkProperties,
+				  COMPONENT_LINK * pComponentLink,
+				  CONSTRAINT_ROUTE_RESOLUTION_ARGS * args);
+
+static uns32 DetermineDestinationType (SM_T * pSm,
+				       CONSTRAINT_ROUTE_RESOLUTION_ARGS *
+				       args, DESTINATION_TYPE_E * type);
+
+static SM_CALL_T *constraint_route_resolution_sm_dynamic_adaptivity (SM_T *
+								     pSm,
+								     SM_EVENT_T
+								     *
+								     sm_event);
+static SM_CALL_T *constraint_route_resolution_sm_empty_handler (SM_T * pSm,
+								SM_EVENT_T *
+								sm_data);
+static SM_CALL_T *constraint_route_resolution_sm_init (SM_T * pSm,
+						       SM_EVENT_T * sm_event);
+static void constraint_route_resolution_sm_destroy (SM_T * pSm);
+
+BOOL TunnelsAutoSetup = FALSE;
+BOOL DontUsePathCash = FALSE;
+
+void
+TunnelsAutoSetupEnable ()
+{
+  TunnelsAutoSetup = TRUE;
+}
+
+void
+TunnelsAutoSetupDisable ()
+{
+  TunnelsAutoSetup = FALSE;
+}
+
+CSPF_REQUEST *
+CreateCspfRequest (int Dest /* IN */ ,
+		   int Priority /* IN */ ,
+		   int ExcludeColorMask /* IN */ ,
+		   int IncludeAnyColorMask /* IN */ ,
+		   int IncludeColorMask /* IN */ ,
+		   int HopCountLimit /* IN */ ,
+		   float Bw /* IN */ ,
+		   int LinkBwCount /* IN */ ,
+		   LINK_BW * pLinkBw /* IN */ ,
+		   int Hops2AvoidCount /* IN */ ,
+		   int *Hops2Avoid /* IN */ ,
+		   int Hops2ExcludeCount /* IN */ ,
+		   int *Hops2Exclude /* IN */ ,
+		   int *Len /* OUT */ ,
+		   int **ppMessage)
+{
+  int size =
+    sizeof (CSPF_REQUEST) + LinkBwCount * sizeof (LINK_BW) +
+    Hops2AvoidCount * sizeof (int) + Hops2ExcludeCount * sizeof (int) +
+    sizeof (int);
+  CSPF_REQUEST *pCspfRequest;
+  int *pMessage;
+  char *pData;
+
+  pMessage = XMALLOC (MTYPE_TE, size);
+
+  if (pMessage == NULL)
+    {
+      return NULL;
+    }
+  *pMessage = CSPF_REQ;
+  pCspfRequest = (CSPF_REQUEST *) (pMessage + 1);
+  pCspfRequest->Destination.s_addr = Dest;
+  pCspfRequest->Priority = Priority;
+  pCspfRequest->ExcludeColorMask = ExcludeColorMask;
+  pCspfRequest->IncludeAnyColorMask = IncludeAnyColorMask;
+  pCspfRequest->IncludeColorMask = IncludeColorMask;
+  pCspfRequest->HopCountLimit = HopCountLimit;
+  pCspfRequest->Bw = Bw;
+  pCspfRequest->LinkBwCount = LinkBwCount;
+  pCspfRequest->Hops2AvoidCount = Hops2AvoidCount;
+  pCspfRequest->Hops2ExcludeCount = Hops2ExcludeCount;
+  pCspfRequest->pLinkBw = NULL;
+  pCspfRequest->Hops2Avoid = NULL;
+  pData = (char *) (pCspfRequest + 1);
+  if (LinkBwCount)
+    {
+      memcpy (pData, pLinkBw, sizeof (LINK_BW) * LinkBwCount);
+      pData += sizeof (LINK_BW) * LinkBwCount;
+    }
+  if (Hops2AvoidCount)
+    {
+      memcpy (pData, Hops2Avoid, sizeof (int) * Hops2AvoidCount);
+      pData += sizeof (int) * Hops2AvoidCount;
+    }
+  if (Hops2ExcludeCount)
+    {
+      memcpy (pData, Hops2Exclude, sizeof (int) * Hops2ExcludeCount);
+    }
+  *Len = size;
+  *ppMessage = pMessage;
+  return pCspfRequest;
+}
+
+void
+RegisterClient (int handle, int instance, IPV4_ADDR dest, void *pSm)
+{
+  CR_CLIENT_NODE *pCrClientNode;
+  CR_CLIENT_KEY key;
+  zlog_info ("entering RegisterClient");
+  key.handle = handle;
+  key.instance = instance;
+
+  if ((pCrClientNode =
+       (CR_CLIENT_NODE *) patricia_tree_get (&ConstraintRouteResClientsTree,
+					     (const uns8 *) &key)) != NULL)
+    {
+      CR_REQ_NODE *pCrNode;
+      CR_REQUESTS_LIST *pCrReqList, *pCrReqListPrev = NULL, *pCrReqList2;
+      if ((pCrNode =
+	   (CR_REQ_NODE *) patricia_tree_get (&ConstraintRouteResReqTree,
+					      (const uns8 *) &pCrClientNode->
+					      dest)) != NULL)
+	{
+	  pCrReqList = pCrNode->pCrReqList;
+	  while (pCrReqList != NULL)
+	    {
+	      if (pCrReqList->pParentSm == (void *) handle)
+		{
+		  constraint_route_resolution_sm_destroy (pCrReqList->pSm);
+		  pCrReqList->pSm = pSm;
+		  if (pCrClientNode->dest != dest)
+		    {
+		      if (pCrReqListPrev == NULL)
+			{
+			  pCrNode->pCrReqList = pCrNode->pCrReqList->next;
+			}
+		      else
+			{
+			  pCrReqListPrev->next = pCrReqList->next;
+			}
+		      pCrReqList->next = NULL;
+		      if (pCrNode->pCrReqList == NULL)
+			{
+			  patricia_tree_del (&ConstraintRouteResReqTree,
+					     &pCrNode->Node);
+			  pCrNode->dest = dest;
+			  if (patricia_tree_add
+			      (&ConstraintRouteResReqTree,
+			       &pCrNode->Node) != E_OK)
+			    {
+			      zlog_err ("Cannot add node to patricia %s %d",
+					__FILE__, __LINE__);
+			    }
+			}
+		      if ((pCrReqList2 = pCrNode->pCrReqList) == NULL)
+			{
+			  pCrNode->pCrReqList = pCrReqList;
+			}
+		      else
+			{
+			  while (pCrReqList2->next != NULL)
+			    pCrReqList2 = pCrReqList2->next;
+			  pCrReqList2->next = pCrReqList;
+			}
+		    }
+		  break;
+		}
+	      pCrReqListPrev = pCrReqList;
+	      pCrReqList = pCrReqList->next;
+	    }
+	}
+      pCrClientNode->dest = dest;
+//      pCrClientNode->sm = pSm;
+      zlog_info ("leaving RegisterClient1");
+      return;
+    }
+
+  if ((pCrClientNode =
+       (CR_CLIENT_NODE *) XMALLOC (MTYPE_TE,
+				   sizeof (CR_CLIENT_NODE))) == NULL)
+    {
+      zlog_err ("canot allocate memory %s %d", __FILE__, __LINE__);
+      return;
+    }
+  pCrClientNode->Node.key_info = (uns8 *) & pCrClientNode->key;
+  pCrClientNode->key = key;
+  pCrClientNode->dest = dest;
+
+  if (patricia_tree_add (&ConstraintRouteResClientsTree, &pCrClientNode->Node)
+      != E_OK)
+    {
+      zlog_err ("Cannot add node to patricia %s %d", __FILE__, __LINE__);
+    }
+  if (CreateConstraintRouteResReq (pSm, handle) != E_OK)
+    {
+      zlog_err ("cannot create CR request %s %d", __FILE__, __LINE__);
+    }
+  zlog_info ("leaving RegisterClient2");
+}
+
+void
+UnregisterClient (int handle, int TunnelId)
+{
+  CR_CLIENT_NODE *pCrClientNode;
+  CR_CLIENT_KEY key;
+
+  zlog_info ("entering UnregisterClient");
+
+  key.handle = handle;
+  key.instance = TunnelId;
+
+  if ((pCrClientNode =
+       (CR_CLIENT_NODE *) patricia_tree_get (&ConstraintRouteResClientsTree,
+					     (const uns8 *) &key)) != NULL)
+    {
+      CR_REQ_NODE *pCrNode;
+      CR_REQUESTS_LIST *pCrReqList, *pCrReqListPrev = NULL;
+
+      if ((pCrNode =
+	   (CR_REQ_NODE *) patricia_tree_get (&ConstraintRouteResReqTree,
+					      (const uns8 *) &pCrClientNode->
+					      dest)) == NULL)
+	{
+	  zlog_err ("leaving UnregisterClient-");
+	  return;
+	}
+
+      pCrReqList = pCrNode->pCrReqList;
+      while (pCrReqList != NULL)
+	{
+	  if (pCrReqList->pParentSm == (void *) handle)
+	    {
+	      if (pCrReqListPrev == NULL)
+		{
+		  pCrNode->pCrReqList = pCrNode->pCrReqList->next;
+		  if (pCrNode->pCrReqList == NULL)
+		    {
+		      if (patricia_tree_del
+			  (&ConstraintRouteResReqTree,
+			   &pCrNode->Node) != E_OK)
+			{
+			  zlog_err ("Cannot delete node from patricia %s %d",
+				    __FILE__, __LINE__);
+			  return;
+			}
+		      else
+			{
+			  XFREE (MTYPE_TE, pCrNode);
+			}
+		    }
+		}
+	      else
+		{
+		  pCrReqListPrev->next = pCrReqList->next;
+		}
+	      if (patricia_tree_del
+		  (&ConstraintRouteResClientsTree,
+		   &pCrClientNode->Node) != E_OK)
+		{
+		  zlog_err ("Cannot delete a node from patricia %s %d",
+			    __FILE__, __LINE__);
+		  return;
+		}
+	      constraint_route_resolution_sm_destroy (pCrReqList->pSm);
+	      XFREE (MTYPE_TE, pCrReqList);
+	      XFREE (MTYPE_TE, pCrClientNode);
+	      zlog_info ("leaving UnregisterClient2");
+	      return;
+	    }
+	  pCrReqListPrev = pCrReqList;
+	  pCrReqList = pCrReqList->next;
+	}
+    }
+  zlog_info ("leaving UnregisterClient3");
+}
+
+int
+constraint_route_resolution_sm_cspf_reply (SM_T * pSm)
+{
+  SM_CALL_T *pCall = NULL;
+  SM_EVENT_E event = CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT;
+  CONSTRAINT_ROUTE_RESOLUTION_ARGS *pCrArgs =
+    ((CONSTRAINT_ROUTE_RESOLUTION_SM_DATA *) pSm->data)->args;
+
+  if (IntraAreaConstraintRouteResolution (pSm, pCrArgs) != E_OK)
+    {
+      zlog_info ("intra-area constraint route resolution is failed");
+      if ((pCall =
+	   sm_gen_sync_event_send (pSm->caller, event, pCrArgs)) == NULL)
+	{
+	  zlog_err ("cannot send sycn event %s %d", __FILE__, __LINE__);
+	  constraint_route_resolution_sm_destroy (pSm);
+	}
+      else
+	{
+	  constraint_route_resolution_sm_destroy (pSm);
+	  sm_call (pCall);
+	}
+      return 1;
+    }
+  switch (pCrArgs->rc)
+    {
+    case OUTPUT_LSP_SETUP_PENDING:
+      pSm->state = CONSTAINT_ROUTE_RESOLUTION_SM_ADAPTIVITY_STATE;
+      return 0;
+    case OUTPUT_EGRESS:
+    case OUTPUT_LSP:
+    case OUTPUT_NEXT_HOP:
+    case OUTPUT_PATH:
+      event = CONSTRAINT_ROUTE_RESOLVED_EVENT;
+      break;
+    case OUTPUT_CAC_FAILED:
+    case OUTPUT_UNREACHABLE:
+      event = CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT;
+      break;
+    default:
+      zlog_err ("default case %s %d", __FILE__, __LINE__);
+      event = CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT;
+    }
+  if ((pCall = sm_gen_sync_event_send (pSm->caller, event, pCrArgs)) == NULL)
+    {
+      zlog_err ("cannot send sycn event %s %d", __FILE__, __LINE__);
+      return 1;
+    }
+  sm_call (pCall);
+  return (event == CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT);
+}
+
+void
+CspfReply (IPV4_ADDR dest, void *handle)
+{
+  CR_REQ_NODE *pCrNode;
+  CR_REQUESTS_LIST *pCrReqList, *pCrReqListPrev = NULL, *pCrReqListNew;
+  CR_CLIENT_NODE *pCrClientNode;
+  CR_CLIENT_KEY key;
+  int rc;
+  zlog_info ("entering CspfReply");
+  if ((pCrNode =
+       (CR_REQ_NODE *) patricia_tree_get (&ConstraintRouteResReqTree,
+					  (const uns8 *) &dest)) == NULL)
+    {
+      zlog_info ("leaving CspfReply1 %x", dest);
+      return;
+    }
+  pCrReqList = pCrNode->pCrReqList;
+
+  while (pCrReqList != NULL)
+    {
+      if (pCrReqList->pSm == handle)
+	{
+	  CONSTRAINT_ROUTE_RESOLUTION_ARGS *pCrArgs;
+	  int TunnelId;
+	  SM_T *pSm;
+	  pSm = pCrReqList->pSm;
+	  pCrArgs =
+	    ((CONSTRAINT_ROUTE_RESOLUTION_SM_DATA *) (pSm->data))->args;
+	  TunnelId = pCrArgs->PsbKey.Session.TunnelId;
+	  constraint_route_resolution_sm_cspf_reply (pSm);
+	  //UnregisterClient(pSm->caller,TunnelId);
+	  key.handle = (int) pSm->caller;
+	  key.instance = TunnelId;
+	  if ((pCrClientNode =
+	       (CR_CLIENT_NODE *)
+	       patricia_tree_get (&ConstraintRouteResClientsTree,
+				  (const uns8 *) &key)) != NULL)
+	    {
+	      if (patricia_tree_del
+		  (&ConstraintRouteResClientsTree,
+		   &pCrClientNode->Node) != E_OK)
+		{
+		  zlog_err ("Cannot delete a node from patricia %s %d",
+			    __FILE__, __LINE__);
+		}
+	      else
+		{
+		  XFREE (MTYPE_TE, pCrClientNode);
+		}
+	    }
+	  else
+	    {
+	      zlog_err ("Cannot get a node from patricia %s %d", __FILE__,
+			__LINE__);
+	    }
+	  if (pCrReqListPrev == NULL)
+	    {
+	      pCrNode->pCrReqList = pCrNode->pCrReqList->next;
+	      if (pCrNode->pCrReqList == NULL)
+		{
+		  if (patricia_tree_del
+		      (&ConstraintRouteResReqTree, &pCrNode->Node) != E_OK)
+		    {
+		      zlog_err ("Cannot delete node from patricia %s %d",
+				__FILE__, __LINE__);
+		    }
+		  else
+		    {
+		      XFREE (MTYPE_TE, pCrNode);
+		    }
+		  XFREE (MTYPE_TE, pCrReqList);
+		  zlog_info ("leaving CspfReply2");
+		  return;
+		}
+	    }
+	  else
+	    {
+	      pCrReqListPrev->next = pCrReqList->next;
+	      XFREE (MTYPE_TE, pCrReqList);
+	    }
+	  break;
+	}
+      pCrReqListPrev = pCrReqList;
+      pCrReqList = pCrReqList->next;
+    }
+
+  if (DontUsePathCash)
+    {
+      return;
+    }
+  pCrReqListPrev = NULL;
+  pCrReqList = pCrNode->pCrReqList;
+  rc = 0;
+  while (pCrReqList != NULL)
+    {
+      CONSTRAINT_ROUTE_RESOLUTION_ARGS *pCrArgs;
+      int TunnelId;
+      SM_T *pSm;
+      pSm = pCrReqList->pSm;
+      pCrArgs = ((CONSTRAINT_ROUTE_RESOLUTION_SM_DATA *) (pSm->data))->args;
+      TunnelId = pCrArgs->PsbKey.Session.TunnelId;
+      if ((rc = constraint_route_resolution_sm_cspf_reply (pSm)) == 0)
+	{
+	  key.handle = (int) pSm->caller;
+	  key.instance = TunnelId;
+	  //zlog_info("trying to get RouteResClient node (%s %d): handle %x tunnel_id %x sm %x",__FILE__,__LINE__,handle,TunnelId,pSm);
+	  if ((pCrClientNode =
+	       (CR_CLIENT_NODE *)
+	       patricia_tree_get (&ConstraintRouteResClientsTree,
+				  (const uns8 *) &key)) != NULL)
+	    {
+	      if (patricia_tree_del
+		  (&ConstraintRouteResClientsTree,
+		   &pCrClientNode->Node) != E_OK)
+		{
+		  zlog_err ("Cannot delete a node from patricia %s %d",
+			    __FILE__, __LINE__);
+		}
+	      else
+		{
+		  XFREE (MTYPE_TE, pCrClientNode);
+		}
+	    }
+	  else
+	    {
+	      zlog_err ("Cannot get a node from patricia %s %d", __FILE__,
+			__LINE__);
+	    }
+	  if (pCrReqListPrev == NULL)
+	    {
+	      pCrNode->pCrReqList = pCrNode->pCrReqList->next;
+	    }
+	  else
+	    {
+	      pCrReqListPrev->next = pCrReqList->next;
+	    }
+	  pCrReqListNew = pCrReqList->next;
+	  XFREE (MTYPE_TE, pCrReqList);
+	  pCrReqList = pCrReqListNew;
+	  if (pCrNode->pCrReqList == NULL)
+	    {
+	      if (patricia_tree_del
+		  (&ConstraintRouteResReqTree, &pCrNode->Node) != E_OK)
+		{
+		  zlog_err ("Cannot delete node from patricia %s %d",
+			    __FILE__, __LINE__);
+		}
+	      else
+		{
+		  XFREE (MTYPE_TE, pCrNode);
+		}
+	      XFREE (MTYPE_TE, pCrReqList);
+	      zlog_info ("leaving CspfReply3");
+	      return;
+	    }
+	}
+      else
+	{
+	  pCrReqListPrev = pCrReqList;
+	  pCrReqList = pCrReqList->next;
+	}
+    }
+  zlog_info ("leaving CspfReply4");
+}
+
+E_RC
+CreateConstraintRouteResReq (SM_T * pSm, int handle)
+{
+  CR_REQ_NODE *pCrNode;
+  CR_REQUESTS_LIST *pCrReqList, *pCrReqListNew;
+  CONSTRAINT_ROUTE_RESOLUTION_ARGS *pCrArgs;
+
+  zlog_info ("entering CreateConstraintRouteResReq");
+
+  pCrArgs = ((CONSTRAINT_ROUTE_RESOLUTION_SM_DATA *) (pSm->data))->args;
+
+  if ((pCrReqListNew =
+       (CR_REQUESTS_LIST *) XMALLOC (MTYPE_TE,
+				     sizeof (CR_REQUESTS_LIST))) == NULL)
+    {
+      zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  pCrReqListNew->pSm = pSm;
+  pCrReqListNew->pParentSm = (void *) handle;
+  //zlog_info("handle %x tunnel_id %x sm %x",handle,pCrArgs->dest,pSm);
+  if ((pCrNode =
+       (CR_REQ_NODE *) patricia_tree_get (&ConstraintRouteResReqTree,
+					  (const uns8 *) &pCrArgs->dest)) ==
+      NULL)
+    {
+      if ((pCrNode =
+	   (CR_REQ_NODE *) XMALLOC (MTYPE_TE, sizeof (CR_REQ_NODE))) == NULL)
+	{
+	  zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+	  XFREE (MTYPE_TE, pCrReqListNew);
+	  return E_ERR;
+	}
+      pCrNode->dest = pCrArgs->dest;
+      pCrNode->Node.key_info = (uns8 *) & pCrNode->dest;
+      pCrNode->pCrReqList = pCrReqListNew;
+      if (patricia_tree_add (&ConstraintRouteResReqTree, &pCrNode->Node) !=
+	  E_OK)
+	{
+	  zlog_err ("Cannot add node to patricia %s %d", __FILE__, __LINE__);
+	  XFREE (MTYPE_TE, pCrReqListNew);
+	  XFREE (MTYPE_TE, pCrNode);
+	  return E_ERR;
+	}
+      zlog_info ("leaving CreateConstraintRouteResReq0 %x",
+		 ((CONSTRAINT_ROUTE_RESOLUTION_SM_DATA *) (pSm->data))->args);
+      return E_OK;
+    }
+  pCrReqList = pCrNode->pCrReqList;
+  if (!pCrReqList)
+    {
+      pCrNode->pCrReqList = pCrReqListNew;
+      zlog_info ("leaving CreateConstraintRouteResReq1 %x",
+		 ((CONSTRAINT_ROUTE_RESOLUTION_SM_DATA *) (pSm->data))->args);
+      return E_OK;
+    }
+  while (pCrReqList->next != NULL)
+    pCrReqList = pCrReqList->next;
+  pCrReqList->next = pCrReqListNew;
+  zlog_info ("leaving CreateConstraintRouteResReq2");
+  return E_OK;
+}
+
+static SM_CALL_T *
+constraint_route_resolution_sm_empty_handler (SM_T * pSm,
+					      SM_EVENT_T * sm_data)
+{
+  zlog_err ("\nconstraint_route_resolution_sm_empty_handler, state %d",
+	    pSm->state);
+  return NULL;
+}
+
+static SM_CALL_T *
+constraint_route_resolution_sm_init (SM_T * pSm, SM_EVENT_T * sm_event)
+{
+  SM_CALL_T *pCall = NULL;
+  CONSTRAINT_ROUTE_RESOLUTION_ARGS *pCrArgs = NULL;
+  DESTINATION_TYPE_E type;
+  CSPF_REQUEST *pCspfRequest;
+  int Len = 0, *pMessage;
+  SM_EVENT_E event = CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT;
+
+
+  if ((pSm->data =
+       (CONSTRAINT_ROUTE_RESOLUTION_SM_DATA *) XMALLOC (MTYPE_TE,
+							sizeof
+							(CONSTRAINT_ROUTE_RESOLUTION_SM_DATA)))
+      == NULL)
+    {
+      zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+      if ((pCall =
+	   sm_gen_sync_event_send (pSm->caller, event, pCrArgs)) == NULL)
+	{
+	  zlog_err ("cannot send sycn event %s %d", __FILE__, __LINE__);
+	  constraint_route_resolution_sm_destroy (pSm);
+	  return NULL;
+	}
+      else
+	{
+	  constraint_route_resolution_sm_destroy (pSm);
+	  return pCall;
+	}
+    }
+  switch (sm_event->event)
+    {
+    case CONSTRAINT_ROUTE_RESOLUTION_REQ_EVENT:
+      sm_gen_event_trace (sm_event->event);
+      pCrArgs = sm_event->data;
+      if ((!pSm) || (!pSm->data) || (!pCrArgs))
+	{
+	  printf ("fatal error: %x %x %x %s %d", pSm,
+		  (int) ((pSm) ? pSm->data : 0), (int) pCrArgs, __FILE__,
+		  __LINE__);
+	  exit (0);
+	}
+      ((CONSTRAINT_ROUTE_RESOLUTION_SM_DATA *) pSm->data)->args = pCrArgs;
+
+      if ((DontUsePathCash) || (pCrArgs->AvoidHopNumber != 0))
+	{
+	  if ((pCspfRequest = CreateCspfRequest (pCrArgs->dest,
+						 pCrArgs->SetupPriority,
+						 pCrArgs->ExclColorMask,
+						 pCrArgs->InclAnyColorMask,
+						 pCrArgs->InclColorMask,
+						 pCrArgs->HopCount,
+						 pCrArgs->BW,
+						 pCrArgs->LinkBwNumber,
+						 (LINK_BW *) pCrArgs->pLinkBw,
+						 pCrArgs->AvoidHopNumber,
+						 pCrArgs->AvoidHopsArray,
+						 pCrArgs->ExcludeHopNumber,
+						 pCrArgs->ExcludeHopsArray,
+						 &Len, &pMessage)) == NULL)
+	    {
+	      return NULL;
+	    }
+	  pCspfRequest->handle = pSm;
+	  te_send_msg (pMessage, Len);
+	  XFREE (MTYPE_TE, pMessage);
+	  RegisterClient ((int) pSm->caller,
+			  pCrArgs->PsbKey.Session.TunnelId,
+			  pCrArgs->dest, pSm);
+	  return NULL;
+	}
+
+      if (TunnelsTunnel2BeModified (pCrArgs, pSm) == TRUE)
+	{
+	  pSm->state = CONSTAINT_ROUTE_RESOLUTION_SM_ADAPTIVITY_STATE;
+	  return NULL;
+	}
+
+      if (DetermineDestinationType (pSm, pCrArgs, &type) != E_OK)
+	{
+	  zlog_info ("DetermineDestinationType failed...");
+	  if ((pCall =
+	       sm_gen_sync_event_send (pSm->caller, event, pCrArgs)) == NULL)
+	    {
+	      zlog_err ("cannot send sycn event %s %d", __FILE__, __LINE__);
+	      constraint_route_resolution_sm_destroy (pSm);
+	      return NULL;
+	    }
+	  else
+	    {
+	      constraint_route_resolution_sm_destroy (pSm);
+	      return pCall;
+	    }
+	}
+      switch (type)
+	{
+	case OUT_OF_AREA_DEST:
+	  if (InterAreaConstraintRouteResolution (pSm, pCrArgs) != E_OK)
+	    {
+	      zlog_info ("inter-area constraint route resolution is failed");
+	      if ((pCall =
+		   sm_gen_sync_event_send (pSm->caller, event,
+					   pCrArgs)) == NULL)
+		{
+		  zlog_err ("cannot send sycn event %s %d", __FILE__,
+			    __LINE__);
+		  constraint_route_resolution_sm_destroy (pSm);
+		  return NULL;
+		}
+	      else
+		{
+		  constraint_route_resolution_sm_destroy (pSm);
+		  return pCall;
+		}
+	    }
+	  switch (pCrArgs->rc)
+	    {
+	    case OUTPUT_LSP_SETUP_PENDING:
+	      pSm->state = CONSTAINT_ROUTE_RESOLUTION_SM_ADAPTIVITY_STATE;
+	      return NULL;
+	    case OUTPUT_EGRESS:
+	    case OUTPUT_LSP:
+	    case OUTPUT_NEXT_HOP:
+	    case OUTPUT_PATH:
+	      event = CONSTRAINT_ROUTE_RESOLVED_EVENT;
+	      break;
+	    case OUTPUT_CAC_FAILED:
+	    case OUTPUT_UNREACHABLE:
+	      if ((pCspfRequest = CreateCspfRequest (pCrArgs->dest,
+						     pCrArgs->SetupPriority,
+						     pCrArgs->ExclColorMask,
+						     pCrArgs->
+						     InclAnyColorMask,
+						     pCrArgs->InclColorMask,
+						     pCrArgs->HopCount,
+						     pCrArgs->BW,
+						     pCrArgs->LinkBwNumber,
+						     (LINK_BW *) pCrArgs->
+						     pLinkBw,
+						     pCrArgs->AvoidHopNumber,
+						     pCrArgs->AvoidHopsArray,
+						     pCrArgs->
+						     ExcludeHopNumber,
+						     pCrArgs->
+						     ExcludeHopsArray, &Len,
+						     &pMessage)) == NULL)
+		{
+		  return NULL;
+		}
+	      pCspfRequest->handle = pSm;
+	      te_send_msg (pMessage, Len);
+	      XFREE (MTYPE_TE, pMessage);
+	      RegisterClient ((int) pSm->caller,
+			      pCrArgs->PsbKey.Session.TunnelId,
+			      pCrArgs->dest, pSm);
+	      return NULL;
+	    default:
+	      zlog_err ("default case %s %d", __FILE__, __LINE__);
+	      event = CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT;
+	    }
+	  if ((pCall =
+	       sm_gen_sync_event_send (pSm->caller, event, pCrArgs)) == NULL)
+	    {
+	      zlog_err ("cannot send sycn event %s %d", __FILE__, __LINE__);
+	    }
+	  break;
+	case INTRA_AREA_DEST:
+	  if (IntraAreaConstraintRouteResolution (pSm, pCrArgs) != E_OK)
+	    {
+	      zlog_info ("intra-area constraint route resolution is failed");
+	      if ((pCall =
+		   sm_gen_sync_event_send (pSm->caller, event,
+					   pCrArgs)) == NULL)
+		{
+		  zlog_err ("cannot send sycn event %s %d", __FILE__,
+			    __LINE__);
+		  constraint_route_resolution_sm_destroy (pSm);
+		  return NULL;
+		}
+	      else
+		{
+		  constraint_route_resolution_sm_destroy (pSm);
+		  return pCall;
+		}
+	    }
+	  switch (pCrArgs->rc)
+	    {
+	    case OUTPUT_LSP_SETUP_PENDING:
+	      pSm->state = CONSTAINT_ROUTE_RESOLUTION_SM_ADAPTIVITY_STATE;
+	      return NULL;
+	    case OUTPUT_EGRESS:
+	    case OUTPUT_LSP:
+	    case OUTPUT_NEXT_HOP:
+	    case OUTPUT_PATH:
+	      event = CONSTRAINT_ROUTE_RESOLVED_EVENT;
+	      break;
+	    case OUTPUT_CAC_FAILED:
+	    case OUTPUT_UNREACHABLE:
+	      if ((pCspfRequest = CreateCspfRequest (pCrArgs->dest,
+						     pCrArgs->SetupPriority,
+						     pCrArgs->ExclColorMask,
+						     pCrArgs->
+						     InclAnyColorMask,
+						     pCrArgs->InclColorMask,
+						     pCrArgs->HopCount,
+						     pCrArgs->BW,
+						     pCrArgs->LinkBwNumber,
+						     (LINK_BW *) pCrArgs->
+						     pLinkBw,
+						     pCrArgs->AvoidHopNumber,
+						     pCrArgs->AvoidHopsArray,
+						     pCrArgs->
+						     ExcludeHopNumber,
+						     pCrArgs->
+						     ExcludeHopsArray, &Len,
+						     &pMessage)) == NULL)
+		{
+		  return NULL;
+		}
+	      pCspfRequest->handle = pSm;
+	      te_send_msg (pMessage, Len);
+	      XFREE (MTYPE_TE, pMessage);
+	      RegisterClient ((int) pSm->caller,
+			      pCrArgs->PsbKey.Session.TunnelId,
+			      pCrArgs->dest, pSm);
+	      return NULL;
+	    default:
+	      zlog_err ("default case %s %d", __FILE__, __LINE__);
+	      event = CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT;
+	    }
+	  if ((pCall =
+	       sm_gen_sync_event_send (pSm->caller, event, pCrArgs)) == NULL)
+	    {
+	      zlog_err ("cannot send sycn event %s %d", __FILE__, __LINE__);
+	    }
+	  break;
+	case NEXT_HOP_DEST:
+	  if (NextHopConstraintRouteResolution (pSm, pCrArgs) != E_OK)
+	    {
+	      zlog_info ("Next Hop constraint route resolution failed");
+	      if ((pCall =
+		   sm_gen_sync_event_send (pSm->caller, event,
+					   pCrArgs)) == NULL)
+		{
+		  zlog_err ("cannot send sycn event %s %d", __FILE__,
+			    __LINE__);
+		  constraint_route_resolution_sm_destroy (pSm);
+		  return NULL;
+		}
+	      else
+		{
+		  constraint_route_resolution_sm_destroy (pSm);
+		  return pCall;
+		}
+	    }
+	  switch (pCrArgs->rc)
+	    {
+	    case OUTPUT_EGRESS:
+	    case OUTPUT_LSP:
+	    case OUTPUT_NEXT_HOP:
+	    case OUTPUT_PATH:
+	      event = CONSTRAINT_ROUTE_RESOLVED_EVENT;
+	      break;
+	    case OUTPUT_CAC_FAILED:
+	    case OUTPUT_UNREACHABLE:
+	      event = CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT;
+	      break;
+	    default:
+	      zlog_err ("default case %s %d", __FILE__, __LINE__);
+	      event = CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT;
+	    }
+	  if ((pCall =
+	       sm_gen_sync_event_send (pSm->caller, event, pCrArgs)) == NULL)
+	    {
+	      zlog_err ("cannot send sycn event %s %d", __FILE__, __LINE__);
+	    }
+	  break;
+	case UNKNOWN_DEST:
+	  if ((pCspfRequest = CreateCspfRequest (pCrArgs->dest,
+						 pCrArgs->SetupPriority,
+						 pCrArgs->ExclColorMask,
+						 pCrArgs->InclAnyColorMask,
+						 pCrArgs->InclColorMask,
+						 pCrArgs->HopCount,
+						 pCrArgs->BW,
+						 pCrArgs->LinkBwNumber,
+						 (LINK_BW *) pCrArgs->pLinkBw,
+						 pCrArgs->AvoidHopNumber,
+						 pCrArgs->AvoidHopsArray,
+						 pCrArgs->ExcludeHopNumber,
+						 pCrArgs->ExcludeHopsArray,
+						 &Len, &pMessage)) == NULL)
+	    {
+	      return NULL;
+	    }
+	  pCspfRequest->handle = pSm;
+	  te_send_msg (pMessage, Len);
+	  XFREE (MTYPE_TE, pMessage);
+	  RegisterClient ((int) pSm->caller,
+			  pCrArgs->PsbKey.Session.TunnelId,
+			  pCrArgs->dest, pSm);
+	  return NULL;
+	case LOCAL_IF_DEST:
+	  pCrArgs->rc = OUTPUT_EGRESS;
+	  if ((pCall = sm_gen_sync_event_send (pSm->caller,
+					       CONSTRAINT_ROUTE_RESOLVED_EVENT,
+					       pCrArgs)) == NULL)
+	    {
+	      zlog_err ("cannot send sycn event %s %d", __FILE__, __LINE__);
+	    }
+	  break;
+	default:
+	  zlog_err ("default case %s %d", __FILE__, __LINE__);
+	  if ((pCall = sm_gen_sync_event_send (pSm->caller,
+					       CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT,
+					       pCrArgs)) == NULL)
+	    {
+	      zlog_err ("cannot send sycn event %s %d", __FILE__, __LINE__);
+	    }
+	}
+      break;
+    default:
+      zlog_err ("unexpected event %d %s %d",
+		sm_event->event, __FILE__, __LINE__);
+    }
+  constraint_route_resolution_sm_destroy (pSm);
+  return pCall;
+}
+
+static SM_CALL_T *
+constraint_route_resolution_sm_dynamic_adaptivity (SM_T * pSm,
+						   SM_EVENT_T * sm_event)
+{
+  LSP_SM_REPLY *pLspSmReply = sm_event->data;
+  SM_CALL_T *pCall = NULL;
+  CONSTRAINT_ROUTE_RESOLUTION_SM_DATA *pCrSmData = pSm->data;
+  SM_EVENT_E event = CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT;
+  //TUNNEL_KEY_T tunnel_key;
+
+  switch (sm_event->event)
+    {
+    case INGRESS_LSP_OPERATION_COMPLETE_EVENT:
+      sm_gen_event_trace (sm_event->event);
+      pCrSmData->args->rc = OUTPUT_LSP;
+      pCrSmData->args->data.tunnel.Session.Dest = pLspSmReply->dest;
+      pCrSmData->args->data.tunnel.Session.TunnelId = pLspSmReply->tunnel_id;
+      pCrSmData->args->data.tunnel.Session.ExtTunelId = rdb_get_router_id ();
+      pCrSmData->args->OutNHop = pLspSmReply->dest;
+
+      zlog_info ("\nTUNNELED: Tunnels Dest %x tunnel id %x IfIndex %d",
+		 pLspSmReply->dest, pLspSmReply->tunnel_id,
+		 pCrSmData->args->OutIf);
+      break;
+    case INGRESS_LSP_OPERATION_FAILED_EVENT:
+      sm_gen_event_trace (sm_event->event);
+      pCrSmData->args->rc = OUTPUT_UNREACHABLE;
+      break;
+    default:
+      zlog_err ("\nunexpected event %d %s %d",
+		sm_event->event, __FILE__, __LINE__);
+    }
+  if ((pCall =
+       sm_gen_sync_event_send (pSm->caller, event, pCrSmData->args)) == NULL)
+    {
+      zlog_err ("\ncannot send sycn event %s %d", __FILE__, __LINE__);
+    }
+  constraint_route_resolution_sm_destroy (pSm);
+  return pCall;
+}
+
+static SM_CALL_T
+  *(*constraint_route_resolution_sm_event_handler
+    [CONSTRAINT_ROUTE_RESOLUTION_SM_MAX_STATE]) (SM_T * pSm,
+						 SM_EVENT_T * sm_data) =
+{
+constraint_route_resolution_sm_empty_handler,
+    constraint_route_resolution_sm_init,
+    constraint_route_resolution_sm_dynamic_adaptivity};
+
+SM_CALL_T *
+constraint_route_resolution_sm_handler (SM_T * pSm, SM_EVENT_T * sm_data)
+{
+  if (sm_data == NULL)
+    {
+      zlog_err ("\nfatal: sm_data is NULL %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  zlog_info ("constraint_route_resolution_sm_handler. state %d", pSm->state);
+  if ((pSm->state < INIT_STATE)
+      || (pSm->state >= CONSTRAINT_ROUTE_RESOLUTION_SM_MAX_STATE))
+    {
+      zlog_err ("\nstate is invalid");
+      XFREE (MTYPE_TE, sm_data);
+      sm_gen_free (pSm);
+      return NULL;
+    }
+  return constraint_route_resolution_sm_event_handler[pSm->state] (pSm,
+								   sm_data);
+}
+
+SM_CALL_T *
+constraint_route_resolution_sm_invoke (SM_T * caller, void *data)
+{
+  SM_T *pNewSm;
+  SM_CALL_T *pEvent;
+
+  pNewSm = sm_gen_alloc (caller, CONSTRAINT_ROUTE_RESOLUTION_SM);
+  if (pNewSm == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  if ((pEvent = sm_gen_sync_event_send (pNewSm,
+					CONSTRAINT_ROUTE_RESOLUTION_REQ_EVENT,
+					data)) == NULL)
+    {
+      zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+    }
+  return pEvent;
+}
+
+static RSVP_TUNNEL_PROPERTIES *
+FindTunnelByPath (TRUNK_ENTRY * pTrunkEntry, PATH * pPath)
+{
+  RSVP_TUNNEL_PROPERTIES *pTunnel = pTrunkEntry->Lsps;
+  while (pTunnel != NULL)
+    {
+      RSVP_LSP_PROPERTIES *pRsvpLsp;
+      if ((pRsvpLsp = GetWorkingRsvpLsp (pTunnel)) != NULL)
+	{
+	  if (PathsEqual (pPath->u.er_hops_l_list,
+			  pRsvpLsp->forw_info.path.pErHopsList,
+			  (pPath->PathProperties.PathHopCount >=
+			   (pRsvpLsp->forw_info.path.HopCount - 1)) ?
+			  pRsvpLsp->forw_info.path.HopCount : pPath->
+			  PathProperties.PathHopCount) == TRUE)
+	    {
+	      return pTunnel;
+	    }
+	}
+      pTunnel = pTunnel->next;
+    }
+  return NULL;
+}
+
+static BOOL
+SummaryAdmissionControl (SUMMARY_PROPERTIES * pSummaryProperties,
+			 CONSTRAINT_ROUTE_RESOLUTION_ARGS * args)
+{
+  if (pSummaryProperties->SummaryMaxLspBW < args->BW)
+    {
+      zlog_info ("\nSummaryMaxLspBW#%x < BW#%x",
+		 pSummaryProperties->SummaryMaxLspBW, args->BW);
+      return FALSE;
+    }
+  if (pSummaryProperties->SummaryMaxReservableBW < args->BW)
+    {
+      zlog_info ("\nSummaryMaxReservableBW#%x < BW#%x",
+		 pSummaryProperties->SummaryMaxReservableBW, args->BW);
+      return FALSE;
+    }
+  /*
+     if(pSummaryProperties->ColorMask & args->ExclColorMask)
+     {
+     zlog_info("\nColors to be excluded#%x exist#%x",
+     args->ExclColorMask,
+     pPathProperties->PathColorMask);
+     return FALSE;
+     }
+     if((pSummaryProperties->ColorMask & args->InclColorMask) != args->InclColorMask)
+     {
+     zlog_info("\nColors to be included#%x don't exist#%x",
+     args->InclColorMask,
+     pPathProperties->PathColorMask);
+     return FALSE;
+     }
+     if(pSummaryProperties->HopCount > args->HopCount)
+     {
+     zlog_info("\nHop count#%x is higher#%x",args->HopCount,pPathProperties->PathHopCount);
+     return FALSE;
+     }
+   */
+  return TRUE;
+}
+
+static BOOL
+SummaryTieBreak (SUMMARY_PROPERTIES * pLeftSummary, PATH * pLeftPath,
+		 SUMMARY_PROPERTIES * pRightSummary, PATH * pRightPath,
+		 uns8 Priority)
+{
+  float LeftMin, RightMin;
+  if ((pLeftSummary->SummaryCost + pLeftPath->PathProperties.PathCost) <
+      (pRightSummary->SummaryCost + pRightPath->PathProperties.PathCost))
+    {
+      return FALSE;
+    }
+
+  if ((pLeftSummary->SummaryCost + pLeftPath->PathProperties.PathCost) >
+      (pRightSummary->SummaryCost + pRightPath->PathProperties.PathCost))
+    {
+      return TRUE;
+    }
+
+  LeftMin =
+    (pLeftSummary->SummaryReservableBW[Priority] <
+     pLeftPath->PathProperties.PathReservableBW[Priority]) ? pLeftSummary->
+    SummaryReservableBW[Priority] : pLeftPath->PathProperties.
+    PathReservableBW[Priority];
+
+  RightMin =
+    (pRightSummary->SummaryReservableBW[Priority] <
+     pRightPath->PathProperties.PathReservableBW[Priority]) ? pRightSummary->
+    SummaryReservableBW[Priority] : pRightPath->PathProperties.
+    PathReservableBW[Priority];
+
+  if (LeftMin > RightMin)
+    {
+      return FALSE;
+    }
+
+  if (LeftMin < RightMin)
+    {
+      return TRUE;
+    }
+
+  LeftMin =
+    (pLeftSummary->SummaryMaxLspBW <
+     pLeftPath->PathProperties.PathMaxLspBW) ? pLeftSummary->
+    SummaryMaxLspBW : pLeftPath->PathProperties.PathMaxLspBW;
+
+  RightMin =
+    (pRightSummary->SummaryMaxLspBW <
+     pRightPath->PathProperties.PathMaxLspBW) ? pRightSummary->
+    SummaryMaxLspBW : pRightPath->PathProperties.PathMaxLspBW;
+  if (LeftMin > RightMin)
+    {
+      return FALSE;
+    }
+  if (LeftMin < RightMin)
+    {
+      return TRUE;
+    }
+  return FALSE;
+}
+
+static int
+SelectAreaBorder (SM_T * pSm,
+		  ABRS_L_LIST * pAbrs,
+		  CONSTRAINT_ROUTE_RESOLUTION_ARGS * args,
+		  ABR ** ppAbr, PATH ** ppPath)
+{
+  PATH_L_LIST *pPathList = NULL;
+  PATH *pPath, *pSelectedPath = NULL;
+  ABR *pSelectedAbr = NULL;
+  zlog_info ("\ninside of Select AreaBorder...");
+  while (pAbrs != NULL)
+    {
+      SUMMARY_PROPERTIES *pProperties = pAbrs->Abr->SummaryProperties;
+      int NumberOfSummaries = pAbrs->Abr->NumberOfSummaries, i;
+      zlog_info ("\n#");
+      for (i = 0; i < NumberOfSummaries; i++)
+	{
+	  zlog_info ("\n##");
+	  if (pProperties->SummaryPathType == PSC_PATH)
+	    {
+	      if (SummaryAdmissionControl (pProperties, args) == TRUE)
+		{
+		  if (IsDestinationIntraArea
+		      (pAbrs->Abr->AbrIpAddr, &pPathList) != E_OK)
+		    {
+		      zlog_err
+			("\nsome error in IsDestinationIntraArea %s %d ...",
+			 __FILE__, __LINE__);
+		      return E_ERR;
+		    }
+		  else
+		    {
+		      pPath = NULL;
+		      if (SelectPath (pPathList, args, &pPath) != E_OK)
+			{
+			  pPath = NULL;
+			}
+		      else if ((pSelectedPath != NULL)
+			       && (pSelectedAbr != NULL))
+			{
+			  if (SummaryTieBreak
+			      (pSelectedAbr->SummaryProperties, pSelectedPath,
+			       pProperties, pPath,
+			       args->SetupPriority) == TRUE)
+			    {
+			      pSelectedAbr = pAbrs->Abr;
+			      pSelectedPath = pPath;
+			    }
+			}
+		      else
+			{
+			  pSelectedAbr = pAbrs->Abr;
+			  pSelectedPath = pPath;
+			}
+		    }
+		}
+	    }
+	  else
+	    {
+	      zlog_err ("\ntype %x is not supported",
+			pProperties->SummaryPathType);
+	    }
+	  pProperties++;
+	}
+      pAbrs = pAbrs->next;
+    }
+  *ppAbr = pSelectedAbr;
+  *ppPath = pSelectedPath;
+  return E_OK;
+}
+
+static BOOL
+PathAdmissionControl (PATH * pPath, CONSTRAINT_ROUTE_RESOLUTION_ARGS * args)
+{
+  int i, j;
+  ER_HOP_L_LIST *er_hop_l_list;
+  PATH_PROPERTIES *pPathProperties = &pPath->PathProperties;
+  if (pPathProperties->PathMaxLspBW < args->BW)
+    {
+      zlog_info ("MaxLspBW#%f < BW#%f", pPathProperties->PathMaxLspBW,
+		 args->BW);
+      return FALSE;
+    }
+  if (pPathProperties->PathMaxReservableBW < args->BW)
+    {
+      zlog_info ("MaxReservableBW#%f < BW#%f",
+		 pPathProperties->PathMaxReservableBW, args->BW);
+      return FALSE;
+    }
+  if (pPathProperties->PathReservableBW[args->HoldPriority] < args->BW)
+    {
+      zlog_info ("ReservableBW#%f < BW#%f",
+		 pPathProperties->PathReservableBW[args->HoldPriority],
+		 args->BW);
+      return FALSE;
+    }
+  if (pPathProperties->PathColorMask & args->ExclColorMask)
+    {
+      zlog_info ("nColors to be excluded#%x exist#%x",
+		 args->ExclColorMask, pPathProperties->PathColorMask);
+      return FALSE;
+    }
+  if ((args->InclAnyColorMask)
+      && ((pPathProperties->PathColorMask & args->InclAnyColorMask) == 0))
+    {
+      return FALSE;
+    }
+  if ((args->InclColorMask)
+      &&
+      (((pPathProperties->PathColorMask & args->InclColorMask) ^ args->
+	InclColorMask) != 0))
+    {
+      return FALSE;
+    }
+  if ((args->HopCount != 0) &&
+      (pPathProperties->PathHopCount > args->HopCount))
+    {
+      zlog_info ("Hop count#%x is higher#%x", args->HopCount,
+		 pPathProperties->PathHopCount);
+      return FALSE;
+    }
+  for (er_hop_l_list = pPath->u.er_hops_l_list, i = 0;
+       i < (pPathProperties->PathHopCount) && (er_hop_l_list != NULL);
+       i++, er_hop_l_list = er_hop_l_list->next)
+    {
+      IPV4_ADDR router_id = er_hop_l_list->er_hop->local_ip;
+      rdb_remote_link_router_id_get (er_hop_l_list->er_hop->local_ip,
+				     &router_id);
+      for (j = 0; j < args->ExcludeHopNumber; j++)
+	{
+	  if (args->ExcludeHopsArray[j] == router_id)
+	    {
+	      return FALSE;
+	    }
+	}
+    }
+  return TRUE;
+}
+
+static uns32
+GetSharedHopsNumber (PATH * pPath, CONSTRAINT_ROUTE_RESOLUTION_ARGS * args)
+{
+  uns32 SharedHopsNumber = 0, i;
+  for (i = 0; i < args->AvoidHopNumber; i++)
+    {
+      ER_HOP_L_LIST *pErHopsLList = pPath->u.er_hops_l_list;
+      while (pErHopsLList != NULL)
+	{
+	  IPV4_ADDR router_id;
+	  /* zlog_info("\nLeft ER HOP %x Right ER HOP %x",
+	     pErHopsLList->er_hop->local_ip,
+	     args->ExcludeHopsArray[i]); */
+	  if (rdb_remote_link_router_id_get
+	      (pErHopsLList->er_hop->remote_ip, &router_id) == E_OK)
+	    {
+	      if (router_id == args->AvoidHopsArray[i])
+		{
+		  SharedHopsNumber++;
+		}
+	    }
+	  else
+	    {
+	      SharedHopsNumber++;
+	    }
+	  pErHopsLList = pErHopsLList->next;
+	}
+    }
+  return SharedHopsNumber;
+}
+
+static BOOL
+PathTieBreak (PATH * pLeftPath,
+	      PATH * pRigthPath,
+	      CONSTRAINT_ROUTE_RESOLUTION_ARGS * args,
+	      uns32 * CurrentSharedHopsNumber)
+{
+  uns32 SharedHopsNumber = 0;
+  PATH_PROPERTIES *pLeftPathProperties =
+    &pLeftPath->PathProperties, *pRightPathProperties =
+    &pRigthPath->PathProperties;
+  if ((SharedHopsNumber =
+       GetSharedHopsNumber (pRigthPath, args)) < *CurrentSharedHopsNumber)
+    {
+      zlog_info ("Tie break by shared hops");
+      *CurrentSharedHopsNumber = SharedHopsNumber;
+      return TRUE;
+    }
+  else if (SharedHopsNumber > *CurrentSharedHopsNumber)
+    {
+      return FALSE;
+    }
+  /* if(args->BwPolicy == LEAST_FILL)
+     {
+     }
+     else if(args->BwPolicy == MOST_FILL)
+     {
+     }
+     else
+     {
+     }
+   */
+  return RightPathCheaper (pLeftPathProperties, pRightPathProperties,
+			   args->SetupPriority);
+}
+
+int
+SelectPath (PATH_L_LIST * pPaths,
+	    CONSTRAINT_ROUTE_RESOLUTION_ARGS * args, PATH ** ppPath)
+{
+  uns32 OutIf;
+  TE_LINK_L_LIST *pTeLinks = NULL;
+  uns32 SharedHopsNumber = 0;
+  IPV4_ADDR router_id;
+
+  while (pPaths != NULL)
+    {
+      zlog_info ("\n...");
+      if (PathAdmissionControl (pPaths->pPath, args) == TRUE)
+	{
+	  zlog_info ("looking for first ER hop %x...",
+		     pPaths->pPath->u.er_hops_l_list->er_hop->remote_ip);
+
+	  if (rdb_remote_link_router_id_get
+	      (pPaths->pPath->u.er_hops_l_list->er_hop->remote_ip,
+	       &router_id) != E_OK)
+	    {
+	      router_id = pPaths->pPath->u.er_hops_l_list->er_hop->remote_ip;
+	    }
+	  if (IsDestinationNextHop (router_id, &pTeLinks) != E_OK)
+	    {
+	      zlog_err ("some error in IsDestinationNextHop %s %d ...",
+			__FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  if (pTeLinks != NULL)
+	    {
+	      zlog_info ("looking for Out IF...");
+	      if (SelectOutIf (pTeLinks, &OutIf, args, FALSE) != E_OK)
+		{
+		  zlog_err ("some error in SelectOutIf %s %d ...", __FILE__,
+			    __LINE__);
+		  return E_ERR;
+		}
+	      else if (OutIf != 0xFFFFFFFF)
+		{
+		  if (*ppPath != NULL)
+		    {
+		      zlog_info ("Second matching path %x %x %x %x...",
+				 SharedHopsNumber, *ppPath, pPaths->pPath,
+				 args);
+		      if (PathTieBreak
+			  (*ppPath, pPaths->pPath, args,
+			   &SharedHopsNumber) == TRUE)
+			{
+			  zlog_info (" Selected %x.", SharedHopsNumber);
+			  *ppPath = pPaths->pPath;
+			}
+		      zlog_info ("After PathTieBreak...");
+		    }
+		  else
+		    {
+		      zlog_info ("First matching path...");
+		      SharedHopsNumber =
+			GetSharedHopsNumber (pPaths->pPath, args);
+		      *ppPath = pPaths->pPath;
+		    }
+		}
+	    }
+	  else
+	    {
+	      zlog_info ("there is no TE link...");
+	    }
+	}
+      pPaths = pPaths->next;
+    }
+  return E_OK;
+}
+
+static BOOL
+LinkAdmissionControl (TE_LINK_PROPERTIES * pTeLinkProperties,
+		      COMPONENT_LINK * pComponentLink,
+		      CONSTRAINT_ROUTE_RESOLUTION_ARGS * args)
+{
+  int reason = 0;
+  if (pTeLinkProperties->MaxLspBW < args->BW)
+    {
+      reason = 1;
+    }
+  if (pTeLinkProperties->MaxReservableBW < args->BW)
+    {
+      reason = 2;
+    }
+  if (pTeLinkProperties->ReservableBW[args->HoldPriority] < args->BW)
+    {
+      zlog_info ("HoldPrio %x ResBw %d BW %d", args->HoldPriority,
+		 pTeLinkProperties->ReservableBW[args->HoldPriority],
+		 args->BW);
+      reason = 3;
+    }
+  if ((pTeLinkProperties->color_mask & args->ExclColorMask) != 0)
+    {
+      reason = 4;
+    }
+  if ((args->InclAnyColorMask)
+      && ((pTeLinkProperties->color_mask & args->InclAnyColorMask) == 0))
+    {
+      reason = 5;
+    }
+  if ((args->InclColorMask)
+      &&
+      (((pTeLinkProperties->color_mask & args->InclColorMask) ^ args->
+	InclColorMask) != 0))
+    {
+      reason = 6;
+    }
+  if (reason)
+    zlog_info ("LinkAdmissionControl failed. Reason %d", reason);
+  return (reason) ? FALSE : TRUE;
+}
+
+int
+SelectOutIf (TE_LINK_L_LIST * pTeLinks,
+	     uns32 * OutIf,
+	     CONSTRAINT_ROUTE_RESOLUTION_ARGS * args, BOOL PerformAllocation)
+{
+  COMPONENT_LINK *pComponentLink, *pSelectedComponentLink = NULL;
+  TE_LINK *pSelectedTeLink = NULL;
+  float ActuallyRequired, LeastActuallyRequired = 0xFFFFFFFF;
+  /*FIXME*/ PSB_KEY * owner = &args->PsbKey;
+  float BW = args->BW;
+  uns8 PreemptedPriority = args->HoldPriority, MostPreemptedPriority = 0;
+  ActuallyRequired = BW;
+  *OutIf = 0xFFFFFFFF;
+
+  while (pTeLinks != NULL)
+    {
+      zlog_info ("TE link %x ActuallyRequired %f...",
+		 pTeLinks->te_link->te_link_id, BW);
+      pComponentLink = pTeLinks->te_link->component_links;
+      while (pComponentLink != NULL)
+	{
+	  if (LinkAdmissionControl
+	      (&pTeLinks->te_link->te_link_properties, pComponentLink,
+	       args) == FALSE)
+	    {
+	      pComponentLink = pComponentLink->next;
+	      continue;
+	    }
+	  zlog_info ("trying to calculate BW to be allocated actually...");
+	  if (CalcActualAlloc (owner,
+			       pTeLinks->te_link->te_link_id,
+			       pComponentLink,
+			       &ActuallyRequired,
+			       args->SetupPriority,
+			       args->HoldPriority,
+			       &PreemptedPriority) == E_OK)
+	    {
+	      zlog_info ("Actual BW to be allocated %f PreemptedPriority %x",
+			 ActuallyRequired, PreemptedPriority);
+	      if (PerformAllocation == TRUE)
+		{
+		  if ((ActuallyRequired < LeastActuallyRequired) &&
+		      (PreemptedPriority >= MostPreemptedPriority))
+		    {
+		      zlog_info
+			("##Actual BW to be allocated %f PreemptedPriority %x",
+			 ActuallyRequired, PreemptedPriority);
+		      LeastActuallyRequired = ActuallyRequired;
+		      MostPreemptedPriority = PreemptedPriority;
+		      pSelectedComponentLink = pComponentLink;
+		      pSelectedTeLink = pTeLinks->te_link;
+		    }
+		}
+	      else
+		{
+		  *OutIf = pComponentLink->oifIndex;
+		  return E_OK;
+		}
+	    }
+	  pComponentLink = pComponentLink->next;
+	}
+      pTeLinks = pTeLinks->next;
+    }
+  if (PerformAllocation == TRUE)
+    {
+      if ((pSelectedComponentLink != NULL) && (pSelectedTeLink != NULL))
+	{
+	  zlog_info ("trying to perform allocation...");
+	  if (DoPreBwAllocation (owner,
+				 pSelectedTeLink->te_link_id,
+				 pSelectedComponentLink,
+				 ActuallyRequired,
+				 args->HoldPriority) != E_OK)
+	    {
+	      zlog_err ("something wrong %s %d", __FILE__, __LINE__);
+	    }
+	  else
+	    {
+	      zlog_info ("Success!!!");
+	      *OutIf = pSelectedComponentLink->oifIndex;
+	    }
+	}
+      else
+	{
+	  *OutIf = 0xFFFFFFFF;
+	}
+    }
+  zlog_info ("inside of %x...", *OutIf);
+  return E_OK;
+}
+
+static uns32
+DetermineDestinationType (SM_T * pSm,
+			  CONSTRAINT_ROUTE_RESOLUTION_ARGS * args,
+			  DESTINATION_TYPE_E * type)
+{
+  TE_LINK_L_LIST *pTeLinks = NULL;
+  PATH_L_LIST *pPaths = NULL;
+  ABRS_L_LIST *pAbrs = NULL;
+  uns32 OutIf = 0xFFFFFFFF;
+  IPV4_ADDR router_id;
+
+  zlog_info ("Am I the destination? %x", args->dest);
+  if (AmIDestination (args->dest, &OutIf) != E_OK)
+    {
+      zlog_err ("some error in AmIDestination %s %d...", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if ((OutIf == 0) || (OutIf != 0xFFFFFFFF))
+    {
+      zlog_info ("\nYes");
+      *type = LOCAL_IF_DEST;
+      return E_OK;
+    }
+
+  zlog_info ("Is destination %x a Next Hop?", args->dest);
+
+  if (rdb_remote_link_router_id_get (args->dest, &router_id) != E_OK)
+    {
+      router_id = args->dest;
+    }
+
+  if (IsDestinationNextHop (router_id, &pTeLinks) != E_OK)
+    {
+      zlog_err ("some error in IsDestinationNextHop %s %d...", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  if (pTeLinks == NULL)
+    {
+      zlog_info ("Is destination intra-area?");
+      if (IsDestinationIntraArea (args->dest, &pPaths) != E_OK)
+	{
+	  zlog_err ("some error in IsDestinationIntraArea %s %d...", __FILE__,
+		    __LINE__);
+	  return E_ERR;
+	}
+      if (pPaths == NULL)
+	{
+	  zlog_info ("Is destination AS border?");
+	  if (IsDestinationASBorder (args->dest, &pAbrs) != E_OK)
+	    {
+	      zlog_err ("some error in IsDestinationASBorder %s %d...",
+			__FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  if (pAbrs == NULL)
+	    {
+	      zlog_info
+		("Destination seems to be nor Next Hop nor Area Border nor AS Border...");
+	      *type = UNKNOWN_DEST;
+	    }
+	  else
+	    {
+	      *type = OUT_OF_AREA_DEST;
+	    }
+	}
+      else
+	{
+	  *type = INTRA_AREA_DEST;
+	}
+    }
+  else
+    {
+      *type = NEXT_HOP_DEST;
+    }
+  return E_OK;
+}
+
+static uns32
+NextHopConstraintRouteResolution (SM_T * pSm,
+				  CONSTRAINT_ROUTE_RESOLUTION_ARGS * args)
+{
+  TE_LINK_L_LIST *pTeLinks = NULL;
+  IPV4_ADDR router_id;
+
+  if (rdb_remote_link_router_id_get (args->dest, &router_id) != E_OK)
+    {
+      router_id = args->dest;
+    }
+
+  if (IsDestinationNextHop (router_id, &pTeLinks) != E_OK)
+    {
+      zlog_err ("some error in IsDestinationNextHop %s %d ...", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  if (pTeLinks == NULL)
+    {
+      zlog_err ("unexpected error: pTeLink == NULL %s %d", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  if (SelectOutIf (pTeLinks, &args->OutIf, args, TRUE) != E_OK)
+    {
+      zlog_err ("error in SelectOutIf %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if (args->OutIf == 0xFFFFFFFF)
+    {
+      args->rc = OUTPUT_CAC_FAILED;
+    }
+  else
+    {
+      args->OutNHop = args->dest;
+      args->rc = OUTPUT_NEXT_HOP;
+    }
+  return E_OK;
+}
+
+static BOOL
+OwnTunnel (IPV4_ADDR addr)
+{
+  return (addr == rdb_get_router_id ());
+}
+
+static uns32
+IntraAreaConstraintRouteResolution (SM_T * pSm,
+				    CONSTRAINT_ROUTE_RESOLUTION_ARGS * args)
+{
+  PATH_L_LIST *pPaths = NULL;
+  PATH *pSelectedPath = NULL;
+  TE_LINK_L_LIST *pTeLinks = NULL;
+  PSB_KEY PsbKey;
+  IPV4_ADDR *pIpAddrArray, router_id;
+
+  if (IsDestinationIntraArea (args->dest, &pPaths) != E_OK)
+    {
+      zlog_err ("some error in IsDestinationIntraArea %s %d ...", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  if (pPaths != NULL)
+    {
+      if (SelectPath (pPaths, args, &pSelectedPath) != E_OK)
+	{
+	  zlog_err ("some error in SelectPath %s %d ...", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      if (pSelectedPath != NULL)
+	{
+	  ER_HOP_L_LIST *pErHopList = pSelectedPath->u.er_hops_l_list;
+	  int i;
+
+	  if ((TunnelsAutoSetup == TRUE) &&
+	      (!((args->dest == args->PsbKey.Session.Dest) &&
+		 (OwnTunnel (args->PsbKey.Session.ExtTunelId)))))
+	    {
+	      TRUNK_KEY trunk_key;
+	      TRUNK_ENTRY *pTrunkEntry;
+	      RSVP_TUNNEL_PROPERTIES *pTunnel;
+	      INGRESS_API *pOpenLspParams;
+	      SM_CALL_T *pCall;
+
+	      memset (&trunk_key, 0, sizeof (TRUNK_KEY));
+	      trunk_key.Dest = args->dest;
+	      if ((pTrunkEntry = GetTunnelsTrunk (&trunk_key)) == NULL)
+		{
+		  if ((pTrunkEntry = NewTunnelsTrunk (&trunk_key)) == NULL)
+		    {
+		      zlog_err ("cannot create tunnels trunk %s %d", __FILE__,
+				__LINE__);
+		      return E_ERR;
+		    }
+		}
+	      pTunnel = pTrunkEntry->Lsps;
+	      if ((pOpenLspParams = CreateRequest2Signalling (pSelectedPath->destination, 0,	/* Filled below */
+							      0, NULL,	/* Filled below */
+							      0,	/* Filled below */
+							      4, 4,	/* Default */
+							      LOCAL_PROTECTION_DESIRED,
+							      0, 0,
+							      0
+							      /* Default for now */
+							      )) == NULL)
+		{
+		  zlog_err ("cannot create request %s %d", __FILE__,
+			    __LINE__);
+		  return E_ERR;
+		}
+
+	      pOpenLspParams->HopNum =
+		pSelectedPath->PathProperties.PathHopCount * 2;
+
+	      for (i = 0, pErHopList = pSelectedPath->u.er_hops_l_list;
+		   pErHopList != NULL; pErHopList = pErHopList->next)
+		{
+		  if (i)
+		    {
+		      pOpenLspParams->Path[i++].IpAddr =
+			pErHopList->er_hop->local_ip;
+		    }
+		  pOpenLspParams->Path[i++].IpAddr =
+		    pErHopList->er_hop->remote_ip;
+		}
+	      args->OutNHop = pOpenLspParams->Path[0].IpAddr;
+	      args->tunneled = TRUE;
+	      if ((pTunnel =
+		   FindTunnelByPath (pTrunkEntry, pSelectedPath)) != NULL)
+		{
+		  if (CurrentPathHasAvBw (pTunnel, args->BW) != NULL)
+		    {
+		      pOpenLspParams->TunnelId = pTunnel->TunnelId;
+		      pOpenLspParams->BW = pTunnel->RequiredBW + args->BW;
+		    }
+		  else
+		    {
+		      memset (&PsbKey, 0, sizeof (PSB_KEY));
+		      PsbKey.Session.Dest = pSelectedPath->destination;
+		      pOpenLspParams->TunnelId = NewTunnelId (&PsbKey);
+		      pOpenLspParams->BW = args->BW;
+		    }
+		}
+	      else
+		{
+		  memset (&PsbKey, 0, sizeof (PSB_KEY));
+		  PsbKey.Session.Dest = pSelectedPath->destination;
+		  pOpenLspParams->TunnelId = NewTunnelId (&PsbKey);
+		  pOpenLspParams->BW = args->BW;
+		}
+	      if ((pCall =
+		   lsp_sm_sync_invoke (pSm, pOpenLspParams,
+				       INGRESS_LSP_REQUEST_EVENT)) == NULL)
+		{
+		  zlog_err ("cannot invoke lsp sm %s %d", __FILE__, __LINE__);
+		  return E_ERR;
+		}
+	      else
+		sm_call (pCall);
+	      args->rc = OUTPUT_LSP_SETUP_PENDING;
+	      return E_OK;
+	    }
+
+	  if (rdb_remote_link_router_id_get
+	      (pSelectedPath->u.er_hops_l_list->er_hop->remote_ip,
+	       &router_id) != E_OK)
+	    {
+	      router_id = pSelectedPath->u.er_hops_l_list->er_hop->remote_ip;
+	    }
+
+	  if (IsDestinationNextHop (router_id, &pTeLinks) != E_OK)
+	    {
+	      zlog_err ("some error in IsDestinationNextHop %s %d ...",
+			__FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  if (pTeLinks == NULL)
+	    {
+	      zlog_err ("unexpected error: pTeLink == NULL %s %d", __FILE__,
+			__LINE__);
+	      return E_ERR;
+	    }
+
+	  args->tunneled = FALSE;
+
+	  if (SelectOutIf (pTeLinks, &args->OutIf, args, TRUE) != E_OK)
+	    {
+	      zlog_err ("an error in SelectOutIf %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  if (args->OutIf == 0xFFFFFFFF)
+	    {
+	      args->rc = OUTPUT_CAC_FAILED;
+	    }
+	  else
+	    {
+	      if ((pIpAddrArray =
+		   (IPV4_ADDR *) XMALLOC (MTYPE_TE,
+					  sizeof (IPV4_ADDR) *
+					  (pSelectedPath->PathProperties.
+					   PathHopCount * 2))) == NULL)
+		{
+		  zlog_err ("mem_alloc failed %s %d", __FILE__, __LINE__);
+		  args->rc = OUTPUT_CAC_FAILED;
+		  return E_ERR;
+		}
+	      for (i = 0, pErHopList = pSelectedPath->u.er_hops_l_list;
+		   pErHopList; pErHopList = pErHopList->next)
+		{
+		  if (i)
+		    pIpAddrArray[i++] = pErHopList->er_hop->local_ip;
+		  pIpAddrArray[i++] = pErHopList->er_hop->remote_ip;
+		}
+	      pIpAddrArray[i] = pSelectedPath->destination;
+	      args->OutNHop = pIpAddrArray[0];
+	      args->data.path.ErHopNumber =
+		pSelectedPath->PathProperties.PathHopCount * 2;
+	      args->data.path.pErHop = pIpAddrArray;
+	      zlog_info ("\nConsRouteResolution ErHopNumber %d pErHop %x",
+			 args->data.path.ErHopNumber, args->data.path.pErHop);
+	      args->rc = OUTPUT_PATH;
+	    }
+	}
+      else
+	{
+	  args->rc = OUTPUT_CAC_FAILED;
+	}
+    }
+  return E_OK;
+}
+
+static uns32
+InterAreaConstraintRouteResolution (SM_T * pSm,
+				    CONSTRAINT_ROUTE_RESOLUTION_ARGS * args)
+{
+  PATH *pPath = NULL;
+  ABRS_L_LIST *pAbrs = NULL;
+  TE_LINK_L_LIST *pTeLinks = NULL;
+  ABR *pAbr = NULL;
+  RSVP_TUNNEL_PROPERTIES *pTunnel = NULL;
+  IPV4_ADDR *pErHopArray, router_id;
+  INGRESS_API *pOpenLspParams;
+  PSB_KEY PsbKey;
+  SM_CALL_T *pCall;
+  ER_HOP_L_LIST *pErHopList;
+  int i;
+
+  /* select the existing tunnels */
+  if (IsDestinationASBorder (args->dest, &pAbrs) != E_OK)
+    {
+      zlog_err ("\nsome error in IsDestinationASBorder %s %d...", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  if (SelectAreaBorder (pSm, pAbrs, args, &pAbr, &pPath) != E_OK)
+    {
+      zlog_err ("\nSelectAreaBorders failed...");
+      return E_ERR;
+    }
+  if ((pAbr == NULL) || (pPath == NULL))
+    {
+      zlog_info ("\nRR failed %s %d", __FILE__, __LINE__);
+      args->rc = OUTPUT_UNREACHABLE;
+      return E_ERR;
+    }
+  pErHopList = pPath->u.er_hops_l_list;
+
+  if ((TunnelsAutoSetup == TRUE) &&
+      (!((pAbr->AbrIpAddr == args->PsbKey.Session.Dest) &&
+	 (OwnTunnel (args->PsbKey.Session.ExtTunelId)))))
+    {
+      TRUNK_ENTRY *pTrunkEntry;
+      TRUNK_KEY trunk_key;
+
+      memset (&trunk_key, 0, sizeof (TRUNK_KEY));
+      trunk_key.Dest = pAbr->AbrIpAddr;
+      if ((pTrunkEntry = GetTunnelsTrunk (&trunk_key)) == NULL)
+	{
+	  if ((pTrunkEntry = NewTunnelsTrunk (&trunk_key)) == NULL)
+	    {
+	      zlog_err ("\ncannot create new tunnels trunk %s %d", __FILE__,
+			__LINE__);
+	      return E_ERR;
+	    }
+	}
+      if ((pOpenLspParams = CreateRequest2Signalling (pAbr->AbrIpAddr, 0,	/* Filled below */
+						      0, NULL,	/* Filled below */
+						      0,	/* Filled below */
+						      4, 4,	/* Default for now */
+						      LOCAL_PROTECTION_DESIRED,
+						      0, 0,
+						      0 /* Default for now */
+						      )) == NULL)
+	{
+	  zlog_info ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pOpenLspParams->Egress = pAbr->AbrIpAddr;
+      args->tunneled = TRUE;
+      if ((pTunnel = FindTunnelByPath (pTrunkEntry, pPath)) != NULL)
+	{
+	  if (CurrentPathHasAvBw (pTunnel, args->BW) != NULL)
+	    {
+	      pOpenLspParams->TunnelId = pTunnel->TunnelId;
+	      pOpenLspParams->BW = pTunnel->RequiredBW + args->BW;
+	    }
+	  else
+	    {
+	      memset (&PsbKey, 0, sizeof (PSB_KEY));
+	      PsbKey.Session.Dest = pAbr->AbrIpAddr;
+	      pOpenLspParams->TunnelId = NewTunnelId (&PsbKey);
+	      pOpenLspParams->BW = args->BW;
+	    }
+	}
+      else
+	{
+	  memset (&PsbKey, 0, sizeof (PSB_KEY));
+	  PsbKey.Session.Dest = pAbr->AbrIpAddr;
+	  pOpenLspParams->TunnelId = NewTunnelId (&PsbKey);
+	  pOpenLspParams->BW = args->BW;
+	}
+      if ((pCall =
+	   lsp_sm_sync_invoke (pSm, pOpenLspParams,
+			       INGRESS_LSP_REQUEST_EVENT)) == NULL)
+	{
+	  zlog_err ("\ncannot invoke lsp sm %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      else
+	sm_call (pCall);
+      args->rc = OUTPUT_LSP_SETUP_PENDING;
+      return E_OK;
+    }
+  if (rdb_remote_link_router_id_get
+      (pPath->u.er_hops_l_list->er_hop->remote_ip, &router_id) != E_OK)
+    {
+      router_id = pPath->u.er_hops_l_list->er_hop->remote_ip;
+    }
+  if (IsDestinationNextHop (router_id, &pTeLinks) != E_OK)
+    {
+      zlog_err ("\nsome error in IsDestinationNextHop %s %d ...", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  if (pTeLinks == NULL)
+    {
+      zlog_err ("\nunexpected error: pTeLink == NULL %s %d", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  if ((pErHopArray =
+       (IPV4_ADDR *) XMALLOC (MTYPE_TE,
+			      sizeof (IPV4_ADDR) *
+			      (pPath->PathProperties.PathHopCount * 2))) ==
+      NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  args->tunneled = FALSE;
+  args->data.path.ErHopNumber = pPath->PathProperties.PathHopCount * 2;
+
+  for (i = 0, pErHopList = pPath->u.er_hops_l_list;
+       pErHopList != NULL; pErHopList = pErHopList->next)
+    {
+      if (i)
+	{
+	  *(pErHopArray + i) = pErHopList->er_hop->local_ip;
+	  i++;
+	}
+      *(pErHopArray + i) = pErHopList->er_hop->remote_ip;
+      i++;
+    }
+
+  if (SelectOutIf (pTeLinks, &args->OutIf, args, TRUE) != E_OK)
+    {
+      zlog_err ("\nerror in SelectOutIf %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  args->data.path.pErHop = pErHopArray;
+  args->OutNHop = pPath->u.er_hops_l_list->er_hop->remote_ip;
+  args->rc = OUTPUT_PATH;
+
+  return E_OK;
+}
+
+static BOOL
+TunnelsTunnel2BeModified (CONSTRAINT_ROUTE_RESOLUTION_ARGS * args, SM_T * pSm)
+{
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  if (FindTunnel (&args->PsbKey, &pTunnel, ALL_TRUNKS) == TRUE)
+    {
+      RSVP_LSP_PROPERTIES *pRsvpLsp = GetWorkingRsvpLsp (pTunnel);
+      if (pRsvpLsp != NULL)
+	{
+	  if (pRsvpLsp->tunneled == TRUE)
+	    {
+	      SM_CALL_T *pCall;
+	      INGRESS_API *pOpenLspParams;
+	      RSVP_TUNNEL_PROPERTIES *pTunnelsTunnel;
+	      if (FindTunnel
+		  (&pRsvpLsp->forw_info.tunnel, &pTunnelsTunnel,
+		   ALL_TRUNKS) != TRUE)
+		{
+		  zlog_err ("\ncannot find tunnels tunnel %s %d...", __FILE__,
+			    __LINE__);
+		  return FALSE;
+		}
+	      if ((pOpenLspParams = CreateRequest2Signalling (pRsvpLsp->forw_info.tunnel.Session.Dest, pRsvpLsp->forw_info.tunnel.Session.TunnelId, 0, NULL, pTunnelsTunnel->RequiredBW + args->BW, 4, 4,	/* Default for now */
+							      LOCAL_PROTECTION_DESIRED,
+							      0, 0,
+							      0
+							      /* Default for now */
+							      )) == NULL)
+		{
+		  zlog_err ("\ncannot create request %s %d", __FILE__,
+			    __LINE__);
+		  return FALSE;
+		}
+
+	      if ((pCall =
+		   lsp_sm_sync_invoke (pSm, pOpenLspParams,
+				       INGRESS_LSP_REQUEST_EVENT)) == NULL)
+		{
+		  zlog_err ("\ncannot invoke lsp sm %s %d", __FILE__,
+			    __LINE__);
+		  return FALSE;
+		}
+	      else
+		{
+		  sm_call (pCall);
+		  return TRUE;
+		}
+	    }
+	}
+    }
+  return FALSE;
+}
+
+static void
+constraint_route_resolution_sm_destroy (SM_T * pSm)
+{
+  XFREE (MTYPE_TE, pSm->data);
+  sm_gen_free (pSm);
+}
diff -Naur quagga-0.99.10/rsvpd/te_crr.h quagga-mpls/rsvpd/te_crr.h
--- quagga-0.99.10/rsvpd/te_crr.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_crr.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,111 @@
+
+#ifndef __CONSTRAINT_ROUTE_RESOLUTION_SM_H__
+#define __CONSTRAINT_ROUTE_RESOLUTION_SM_H__
+
+typedef enum
+{
+  CONSTAINT_ROUTE_RESOLUTION_SM_ADAPTIVITY_STATE = INIT_STATE + 1,
+  CONSTRAINT_ROUTE_RESOLUTION_SM_MAX_STATE
+} CONSTRAINT_ROUTE_RESOLUTION_SM_STATE_E;
+
+typedef enum
+{
+  LOCAL_IF_DEST,
+  NEXT_HOP_DEST,
+  INTRA_AREA_DEST,
+  OUT_OF_AREA_DEST,
+  UNKNOWN_DEST
+} DESTINATION_TYPE_E;
+
+typedef enum
+{
+  OUTPUT_EGRESS,
+  OUTPUT_NEXT_HOP,
+  OUTPUT_PATH,
+  OUTPUT_LSP,
+  OUTPUT_LSP_SETUP_PENDING,
+  OUTPUT_UNREACHABLE,
+  OUTPUT_CAC_FAILED
+} CONSTRAINT_ROUTE_RESOLUTION_RC_E;
+
+typedef struct
+{
+  IPV4_ADDR dest;		/* IN */
+  float BW;			/* IN */
+  uns32 ExclColorMask;		/* IN */
+  uns32 InclAnyColorMask;	/* IN */
+  uns32 InclColorMask;		/* IN */
+  uns32 HopCount;		/* IN */
+  PSB_KEY PsbKey;		/* IN */
+  uns32 AvoidHopNumber;		/* IN */
+  IPV4_ADDR *AvoidHopsArray;	/* IN */
+  uns32 ExcludeHopNumber;	/* IN */
+  IPV4_ADDR *ExcludeHopsArray;	/* IN */
+  uns32 LinkBwNumber;		/* IN */
+  void *pLinkBw;		/* IN */
+  uns8 SetupPriority;		/* IN */
+  uns8 HoldPriority;		/* IN */
+  uns32 OutIf;			/* OUT */
+  IPV4_ADDR OutNHop;		/* OUT */
+  BOOL tunneled;
+  union
+  {
+    struct
+    {
+      uns32 ErHopNumber;	/* OUT */
+      IPV4_ADDR *pErHop;	/* OUT */
+    } path;
+    PSB_KEY tunnel;
+  } data;
+  CONSTRAINT_ROUTE_RESOLUTION_RC_E rc;
+} CONSTRAINT_ROUTE_RESOLUTION_ARGS;
+
+typedef struct cr_req_list
+{
+  void *pSm;
+  void *pParentSm;
+  struct cr_req_list *next;
+} CR_REQUESTS_LIST;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  IPV4_ADDR dest;
+  CR_REQUESTS_LIST *pCrReqList;
+} CR_REQ_NODE;
+
+typedef struct
+{
+  int handle;
+  int instance;
+} CR_CLIENT_KEY;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  CR_CLIENT_KEY key;
+  IPV4_ADDR dest;
+} CR_CLIENT_NODE;
+
+typedef struct
+{
+  CONSTRAINT_ROUTE_RESOLUTION_ARGS *args;
+} CONSTRAINT_ROUTE_RESOLUTION_SM_DATA;
+
+extern PATRICIA_TREE ConstraintRouteResReqTree;
+extern PATRICIA_TREE ConstraintRouteResClientsTree;
+SM_CALL_T *constraint_route_resolution_sm_invoke (SM_T * caller, void *data);
+SM_CALL_T *constraint_route_resolution_sm_handler (SM_T * pSm,
+						   SM_EVENT_T * sm_data);
+
+int SelectPath (PATH_L_LIST * pPaths,
+		CONSTRAINT_ROUTE_RESOLUTION_ARGS * args, PATH ** ppPath);
+int SelectOutIf (TE_LINK_L_LIST * pTeLinks,
+		 uns32 * OutIf,
+		 CONSTRAINT_ROUTE_RESOLUTION_ARGS * args,
+		 BOOL PerformAllocation);
+void CspfReply (IPV4_ADDR dest, void *handle);
+
+void UnregisterClient (int handle, int TunnelId);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te_cspf.h quagga-mpls/rsvpd/te_cspf.h
--- quagga-0.99.10/rsvpd/te_cspf.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_cspf.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,50 @@
+
+#ifndef _CSPF_REQ_H_
+#define _CSPF_REQ_H_
+
+#define CSPF_REQ             1
+#define BW_UPDATE_REQ        2
+#define HELLO_REQ            3
+#define REMOTE_BW_UPDATE_REQ 4
+
+typedef struct
+{
+  struct in_addr LocalIp;
+  struct in_addr RemoteIp;
+  float Bw;
+} LINK_BW;
+
+typedef struct
+{
+  struct in_addr Destination;
+  int Priority;
+  int ExcludeColorMask;
+  int IncludeAnyColorMask;
+  int IncludeColorMask;
+  int HopCountLimit;
+  float Bw;
+  int LinkBwCount;
+  int Hops2AvoidCount;
+  int Hops2ExcludeCount;
+  LINK_BW *pLinkBw;
+  struct in_addr *Hops2Avoid;
+  struct in_addr *Hops2Exclude;
+  void *handle;
+} CSPF_REQUEST;
+
+typedef struct
+{
+  int IfIndex;
+  float MaxResBw;
+  float ResBw[8];
+} BW_UPDATE_REQUEST;
+
+typedef struct
+{
+  struct in_addr RouterId;
+  struct in_addr LocalIp;
+  struct in_addr RemoteIp;
+  float ResBw[8];
+} REMOTE_BW_UPDATE_REQUEST;
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te_frr.c quagga-mpls/rsvpd/te_frr.c
--- quagga-0.99.10/rsvpd/te_frr.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_frr.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,1661 @@
+/* Module:   fast_reroute.c
+   Contains: TE application fast-reroute state machine 
+   functions.
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "te.h"
+#include "mpls_rtm.h"
+
+
+PATRICIA_TREE FastReRouteSmTree;
+
+static SM_CALL_T *
+fast_reroute_sm_empty_handler (SM_T * pSm, SM_EVENT_T * sm_data)
+{
+  zlog_err ("\nfast_reroute_sm_empty_handler, state %d", pSm->state);
+  return NULL;
+}
+
+static SM_CALL_T *
+fast_reroute_sm_init (SM_T * pSm, SM_EVENT_T * sm_event)
+{
+  INGRESS_API *pOpenLspParams;
+  PSB_KEY PsbKey;
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  RSVP_LSP_PROPERTIES *pRsvpLsp;
+  TUNNEL_KEY_T tunnel_key;
+  SM_CALL_T *pCall = NULL;
+  FRR_SM_DATA *pFrrSmData = pSm->data;
+  FRR_SM_ENTRY *pFrrEntry = &pFrrSmData->FrrSmEntry;
+
+  switch (sm_event->event)
+    {
+    case BYPASS_SETUP_REQ_EVENT:
+      if ((pOpenLspParams = XMALLOC (MTYPE_TE, sizeof (INGRESS_API))) == NULL)
+	{
+	  zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  /* Do some clean up here */
+	  return NULL;
+	}
+      memset (&PsbKey, 0, sizeof (PSB_KEY));
+      PsbKey.Session.Dest = pFrrEntry->frr_key.merge_node;
+      pOpenLspParams->TunnelId = NewTunnelId (&PsbKey);
+      pOpenLspParams->ErHops2Exclude[0] = pFrrEntry->frr_key.protected_node;
+      pOpenLspParams->ErHops2Exclude[1] =
+	pFrrEntry->frr_key.prohibited_penultimate_node;
+      pOpenLspParams->Egress = pFrrEntry->frr_key.merge_node;
+      pOpenLspParams->BW = 0;
+      pOpenLspParams->SetupPriority = 4;
+      pOpenLspParams->HoldPriority = 4;
+      pFrrEntry->BypassTunnelId = pOpenLspParams->tunnel_id;
+      if ((pCall =
+	   lsp_sm_sync_invoke (pSm, pOpenLspParams,
+			       INGRESS_LSP_REQUEST_EVENT)) == NULL)
+	{
+	  zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+	}
+      else
+	sm_call (pCall);
+      break;
+    case INGRESS_LSP_OPERATION_COMPLETE_EVENT:
+      if (pFrrEntry->bypass_retry_timer.is_active == TRUE)
+	{
+	  te_stop_timer (&pFrrEntry->bypass_retry_timer);
+	}
+      pSm->state = FAST_REROUTE_SM_UP_STATE;
+      memset (&PsbKey, 0, sizeof (PSB_KEY));
+      PsbKey.Session.Dest = pFrrEntry->frr_key.merge_node;
+      PsbKey.Session.TunnelId = pFrrEntry->BypassTunnelId;
+      PsbKey.Session.ExtTunelId = rdb_get_router_id ();
+      if (FindTunnel (&PsbKey, &pTunnel, ALL_TRUNKS) == TRUE)
+	{
+	  if ((pRsvpLsp = GetWorkingRsvpLsp (pTunnel)) != NULL)
+	    {
+	      pFrrSmData->BackupOutIf = pRsvpLsp->oIfIndex;
+	      pFrrSmData->BypassTunnelsLabel = pRsvpLsp->Label;
+	      memset (&tunnel_key, 0, sizeof (TUNNEL_KEY_T));
+	      tunnel_key.Dest = PsbKey.Session.Dest;
+	      tunnel_key.TunnelId = PsbKey.Session.TunnelId;
+	      tunnel_key.Source = PsbKey.Session.ExtTunelId;
+	      /*if(CreateRsvpRequest(rdb_get_router_id(),
+	         GetLSP(&tunnel_key),
+	         100,900000,
+	         100,900000,
+	         FALSE,FALSE,
+	         pFrrSmData->card) != E_OK)
+	         {
+	         zlog_info("\ncannnot create RSVP instance on LSP-Tunnel");
+	         } HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! */
+	    }
+	  else
+	    {
+	      zlog_err ("\ncannot get working RSVP LSP %s %d", __FILE__,
+			__LINE__);
+	    }
+	}
+      else
+	{
+	  zlog_err ("\ncannot find tunnel %x %x %x %s %d",
+		    PsbKey.Session.Dest,
+		    PsbKey.Session.TunnelId,
+		    PsbKey.Session.ExtTunelId, __FILE__, __LINE__);
+	}
+      UpdateIfWithBacupInfo (pFrrSmData);
+      break;
+    case INGRESS_LSP_OPERATION_FAILED_EVENT:
+      zlog_info ("\nBypass tunnel setup is failed %x %x %x %s %d",
+		 pFrrEntry->frr_key.protected_node,
+		 pFrrEntry->frr_key.merge_node,
+		 pFrrEntry->frr_key.OutIfIndex, __FILE__, __LINE__);
+      pFrrEntry->bypass_retry_timer.data.bypass_retry_data =
+	pFrrEntry->frr_key;
+      if (te_start_timer
+	  (&pFrrEntry->bypass_retry_timer, BYPASS_TUNNEL_RETRY_EXPIRY,
+	   10000) != E_OK)
+	{
+	  zlog_err ("\ncannot start timer %s %d", __FILE__, __LINE__);
+	}
+      pSm->state = FAST_REROUTE_RETRY_STATE;
+      break;
+    default:
+      zlog_err ("\nDefault case reached %s %d", __FILE__, __LINE__);
+    }
+  return NULL;
+}
+
+static SM_CALL_T *
+fast_reroute_sm_up (SM_T * pSm, SM_EVENT_T * sm_event)
+{
+  FRR_SM_DATA *pFrrSmData = pSm->data;
+  FRR_SM_ENTRY *pFrrEntry = &pFrrSmData->FrrSmEntry;
+  SM_CALL_T *pCall = NULL;
+  TUNNEL_KEY_T tunnel_key;
+
+  switch (sm_event->event)
+    {
+    case BYPASS_SETUP_REQ_EVENT:
+      UpdateIfWithBacupInfo (pFrrSmData);
+      break;
+    case INGRESS_LSP_OPERATION_FAILED_EVENT:
+      BypassTunnelFailed (pFrrSmData);
+      pFrrEntry->bypass_retry_timer.data.bypass_retry_data =
+	pFrrEntry->frr_key;
+      if (te_start_timer
+	  (&pFrrEntry->bypass_retry_timer, BYPASS_TUNNEL_RETRY_EXPIRY,
+	   10000) != E_OK)
+	{
+	  zlog_info ("\ncannot start timer %s %d", __FILE__, __LINE__);
+	}
+      memset (&tunnel_key, 0, sizeof (TUNNEL_KEY_T));
+      tunnel_key.Dest = pFrrEntry->frr_key.merge_node;
+      tunnel_key.TunnelId = pFrrEntry->BypassTunnelId;
+      tunnel_key.Source = rdb_get_router_id ();
+      /*if(DestroyRsvpRequest(rdb_get_router_id(),
+         GetLSP(&tunnel_key),
+         pFrrSmData->card) != E_OK)
+         {
+         zlog_info("\ncannot put down RSVP");
+         } HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! */
+      pSm->state = FAST_REROUTE_RETRY_STATE;
+      break;
+    default:
+      zlog_err ("\nDefault case reached %s %d", __FILE__, __LINE__);
+    }
+  return pCall;
+}
+
+static SM_CALL_T *
+fast_reroute_sm_retry (SM_T * pSm, SM_EVENT_T * sm_event)
+{
+  PSB_KEY PsbKey;
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  RSVP_LSP_PROPERTIES *pRsvpLsp;
+  TUNNEL_KEY_T tunnel_key;
+  SM_CALL_T *pCall = NULL;
+  FRR_SM_DATA *pFrrSmData = pSm->data;
+  FRR_SM_ENTRY *pFrrEntry = &pFrrSmData->FrrSmEntry;
+
+  switch (sm_event->event)
+    {
+    case INGRESS_LSP_OPERATION_COMPLETE_EVENT:
+      if (pFrrEntry->bypass_retry_timer.is_active == TRUE)
+	{
+	  te_stop_timer (&pFrrEntry->bypass_retry_timer);
+	}
+      pSm->state = FAST_REROUTE_SM_UP_STATE;
+      memset (&PsbKey, 0, sizeof (PSB_KEY));
+      PsbKey.Session.Dest = pFrrEntry->frr_key.merge_node;
+      PsbKey.Session.TunnelId = pFrrEntry->BypassTunnelId;
+      PsbKey.Session.ExtTunelId = rdb_get_router_id ();
+      if (FindTunnel (&PsbKey, &pTunnel, ALL_TRUNKS) == TRUE)
+	{
+	  if ((pRsvpLsp = GetWorkingRsvpLsp (pTunnel)) != NULL)
+	    {
+	      pFrrSmData->BackupOutIf = pRsvpLsp->oIfIndex;
+	      pFrrSmData->BypassTunnelsLabel = pRsvpLsp->Label;
+	      memset (&tunnel_key, 0, sizeof (TUNNEL_KEY_T));
+	      tunnel_key.Dest = PsbKey.Session.Dest;
+	      tunnel_key.TunnelId = PsbKey.Session.TunnelId;
+	      tunnel_key.Source = PsbKey.Session.ExtTunelId;
+	      /*if(CreateRsvpRequest(rdb_get_router_id(),
+	         GetLSP(&tunnel_key),
+	         100,900000,
+	         100,900000,
+	         FALSE,FALSE,
+	         pFrrSmData->card) != E_OK)
+	         {
+	         zlog_info("\ncannnot create RSVP instance on LSP-Tunnel");
+	         } HERE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! */
+	    }
+	  else
+	    {
+	      zlog_err ("\ncannot get working RSVP LSP %s %d", __FILE__,
+			__LINE__);
+	    }
+	}
+      else
+	{
+	  zlog_err ("\ncannot find tunnel %x %x %x %s %d",
+		    PsbKey.Session.Dest,
+		    PsbKey.Session.TunnelId,
+		    PsbKey.Session.ExtTunelId, __FILE__, __LINE__);
+	}
+      UpdateIfWithBacupInfo (pFrrSmData);
+      pSm->state = FAST_REROUTE_SM_UP_STATE;
+      break;
+    case INGRESS_LSP_OPERATION_FAILED_EVENT:
+      zlog_info ("\nBypass tunnel setup is failed %x %x %x %s %d",
+		 pFrrEntry->frr_key.protected_node,
+		 pFrrEntry->frr_key.merge_node,
+		 pFrrEntry->frr_key.OutIfIndex, __FILE__, __LINE__);
+      pFrrEntry->bypass_retry_timer.data.bypass_retry_data =
+	pFrrEntry->frr_key;
+      if (te_start_timer
+	  (&pFrrEntry->bypass_retry_timer, BYPASS_TUNNEL_RETRY_EXPIRY,
+	   10000) != E_OK)
+	{
+	  zlog_err ("\ncannot start timer %s %d", __FILE__, __LINE__);
+	}
+      break;
+    case BYPASS_SETUP_REQ_EVENT:
+      break;
+    default:
+      zlog_err ("\nDefault case reached %s %d", __FILE__, __LINE__);
+    }
+  return NULL;
+}
+
+static SM_CALL_T *(*lsp_sm_event_handler[FAST_REROUTE_SM_MAX_STATE])
+  (HANDLE sm_handle, SM_EVENT_T * sm_data) =
+{
+fast_reroute_sm_empty_handler,
+    fast_reroute_sm_init, fast_reroute_sm_up, fast_reroute_sm_retry};
+
+SM_CALL_T *
+fast_reroute_sm_handler (HANDLE sm_handle, SM_EVENT_T * sm_data)
+{
+  SM_T *pSm = (SM_T *) sm_handle;
+  if (sm_data == NULL)
+    {
+      zlog_err ("\nfatal: sm_data is NULL %s %d", __FILE__, __LINE__);
+      FastReRouteSmDestroy (pSm);
+      return NULL;
+    }
+  if ((pSm->state < INIT_STATE) || (pSm->state >= FAST_REROUTE_SM_MAX_STATE))
+    {
+      FastReRouteSmDestroy (pSm);
+      return NULL;
+    }
+  return lsp_sm_event_handler[pSm->state] (pSm, sm_data);
+}
+
+SM_CALL_T *
+fast_reroute_sm_sync_invoke (FRR_SM_CALL * pFrrCall, SM_EVENT_E event)
+{
+  SM_T *pSm;
+  SM_CALL_T *pEvent = NULL;
+  FRR_SM_DATA *pFrrSmData;
+  FRR_SM_ENTRY *pFrrEntry;
+  FRR_LABEL_ENTRY *pLabelEntry;
+  FRR_INGRESS_ENTRY *pIngressEntry;
+  PATRICIA_PARAMS params;
+  BOOL malloc_performed = FALSE;
+  zlog_info ("\ninside of fast_reroute_sm_sync_invoke");
+  if (event == BYPASS_SETUP_REQ_EVENT)
+    {
+      if ((pFrrEntry = FindFastRerouteSm (&pFrrCall->frr_key)) == NULL)
+	{
+	  zlog_info ("\nnew FRR SM creation...");
+	  pSm = sm_gen_alloc (0, FAST_REROUTE_SM);
+	  if (pSm == NULL)
+	    {
+	      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	      return NULL;
+	    }
+
+	  if ((pFrrSmData = XMALLOC (MTYPE_TE, sizeof (FRR_SM_DATA))) == NULL)
+	    {
+	      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	      sm_gen_free (pSm);
+	      return NULL;
+	    }
+	  malloc_performed = TRUE;
+	  pFrrEntry = &pFrrSmData->FrrSmEntry;
+	  pFrrEntry->frr_key = pFrrCall->frr_key;
+	  pFrrEntry->Node.key_info = &pFrrEntry->frr_key;
+	  pFrrEntry->sm_handle = pSm;
+	  pSm->data = pFrrSmData;
+	  params.key_size = sizeof (unsigned int);
+	  params.info_size = 0;
+	  zlog_info ("\nLabel's tree initialization...");
+	  if (patricia_tree_init (&pFrrEntry->labels_tree, &params) != E_OK)
+	    {
+	      zlog_err ("\ncannot initiate patricia tree (per SM) for FRR");
+	      sm_gen_free (pSm);
+	      XFREE (MTYPE_TE, pFrrSmData);
+	      return NULL;
+	    }
+
+	  params.key_size = sizeof (PSB_KEY);
+	  params.info_size = 0;
+	  zlog_info ("\nIngress tree initialization...");
+	  if (patricia_tree_init (&pFrrEntry->ingress_tree, &params) != E_OK)
+	    {
+	      zlog_err ("\ncannot initiate patricia tree (per SM) for FRR");
+	      sm_gen_free (pSm);
+	      XFREE (MTYPE_TE, pFrrSmData);
+	      return NULL;
+	    }
+
+	  zlog_info ("\nadding FRR SM node to the tree...");
+
+	  if (patricia_tree_add (&FastReRouteSmTree, &pFrrEntry->Node) !=
+	      E_OK)
+	    {
+	      sm_gen_free (pSm);
+	      XFREE (MTYPE_TE, pFrrSmData);
+	      return NULL;
+	    }
+	}
+      else
+	{
+	  pSm = pFrrEntry->sm_handle;
+	}
+      if (pFrrCall->Label != 0)
+	{
+	  if ((pLabelEntry =
+	       XMALLOC (MTYPE_TE, sizeof (FRR_LABEL_ENTRY))) == NULL)
+	    {
+	      zlog_err ("\nmalloc failed...");
+	      if (malloc_performed == TRUE)
+		{
+		  if (patricia_tree_del (&FastReRouteSmTree, &pFrrEntry->Node)
+		      != E_OK)
+		    {
+		      zlog_err
+			("\ncannot delete FRR ENTRY from FastReRouteTree");
+		      return NULL;
+		    }
+		  XFREE (MTYPE_TE, pFrrSmData);
+		  sm_gen_free (pSm);
+		}
+	      return NULL;
+	    }
+	  pLabelEntry->Label = pFrrCall->Label;
+	  pLabelEntry->Node.key_info = &pLabelEntry->Label;
+	  if (patricia_tree_add (&pFrrEntry->labels_tree, &pLabelEntry->Node)
+	      != E_OK)
+	    {
+	      if (patricia_tree_get (&pFrrEntry->labels_tree,
+				     (const uns8 *) &pLabelEntry->Label) ==
+		  NULL)
+		{
+		  zlog_err ("\ncannot add label frr entry - unknown reason");
+		}
+	      XFREE (MTYPE_TE, pLabelEntry);
+	      return NULL;
+	    }
+	  PlatformWideLabelSpace[pLabelEntry->Label -
+				 1].BackupForwardingInformation.frr_key =
+	    pFrrCall->frr_key;
+	  PlatformWideLabelSpace[pLabelEntry->Label -
+				 1].BackupForwardingInformation.MergeNode =
+	    pFrrCall->MergeNode;
+	  PlatformWideLabelSpace[pLabelEntry->Label -
+				 1].BackupForwardingInformation.PSB_KEY =
+	    pFrrCall->PSB_KEY;
+	  zlog_info ("\nINVOKE: %x %x %x %x %x",
+		     PlatformWideLabelSpace[pLabelEntry->Label -
+					    1].BackupForwardingInformation.
+		     PSB_KEY.Session.Dest,
+		     PlatformWideLabelSpace[pLabelEntry->Label -
+					    1].BackupForwardingInformation.
+		     PSB_KEY.Session.TunnelId,
+		     PlatformWideLabelSpace[pLabelEntry->Label -
+					    1].BackupForwardingInformation.
+		     PSB_KEY.Session.ExtTunelId,
+		     PlatformWideLabelSpace[pLabelEntry->Label -
+					    1].BackupForwardingInformation.
+		     PSB_KEY.sender.Lsp_IdNet,
+		     PlatformWideLabelSpace[pLabelEntry->Label -
+					    1].BackupForwardingInformation.
+		     PSB_KEY.sender.IPv4TunnelSenderNet);
+	}
+      else
+	{
+	  RSVP_TUNNEL_PROPERTIES *pTunnel;
+	  RSVP_LSP_PROPERTIES *pRsvpLsp;
+	  uns16 SavedLspId;
+	  IPV4_ADDR SavedSenderIp;
+	  zlog_info ("\nIngress LER call...");
+	  if ((pIngressEntry =
+	       XMALLOC (MTYPE_TE, sizeof (FRR_INGRESS_ENTRY))) == NULL)
+	    {
+	      zlog_info ("\nmalloc failed...");
+	      if (malloc_performed == TRUE)
+		{
+		  if (patricia_tree_del (&FastReRouteSmTree, &pFrrEntry->Node)
+		      != E_OK)
+		    {
+		      zlog_err
+			("\ncannot delete FRR ENTRY from FastReRouteTree");
+		      return NULL;
+		    }
+		  XFREE (MTYPE_TE, pFrrSmData);
+		  sm_gen_free (pSm);
+		}
+	      return NULL;
+	    }
+	  pIngressEntry->PsbKey = pFrrCall->PsbKey;
+	  pIngressEntry->Node.key_info = &pIngressEntry->PsbKey;
+	  zlog_info ("\nadding node to Ingress tree....");
+	  if (patricia_tree_add
+	      (&pFrrEntry->ingress_tree, &pIngressEntry->Node) != E_OK)
+	    {
+	      if (patricia_tree_get (&pFrrEntry->ingress_tree,
+				     (const uns8 *) &pIngressEntry->PsbKey) ==
+		  NULL)
+		{
+		  zlog_err ("\ncannot add label frr entry - unknown reason");
+		}
+	      XFREE (MTYPE_TE, pIngressEntry);
+	      return NULL;
+	    }
+	  SavedLspId = pFrrCall->PsbKey.SenderTemplate.LspId;
+	  SavedSenderIp = pFrrCall->PsbKey.SenderTemplate.IpAddr;
+	  pFrrCall->PsbKey.sender.Lsp_IdNet = 0;
+	  pFrrCall->PsbKey.sender.IPv4TunnelSenderNet = 0;
+	  if (FindTunnel (&pFrrCall->PsbKey, &pTunnel, ALL_TRUNKS) == TRUE)
+	    {
+	      pFrrCall->PsbKey.SenderTemplate.LspId = SavedLspId;
+	      pFrrCall->PsbKey.SenderTemplate.IpAddr = SavedSenderIp;
+	      if (((pRsvpLsp =
+		    FindRsvpLspByLspId (pTunnel, SavedLspId)) != NULL)
+		  && (pRsvpLsp->tunneled == FALSE))
+		{
+		  pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		    frr_key = pFrrCall->frr_key;
+		  pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		    MergeNode = pFrrCall->MergeNode;
+		  pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		    PsbKey = pFrrCall->PsbKey;
+		}
+	      else
+		{
+		  zlog_err
+		    ("\ncannot get RSVP LSP by LSP ID or LSP is tunneled %x %s %d",
+		     pRsvpLsp, __FILE__, __LINE__);
+		}
+	    }
+	  else
+	    {
+	      zlog_err ("\ncannot find tunnel %x %x %x %s %d",
+			pFrrCall->PsbKey.Session.Dest,
+			pFrrCall->PsbKey.Session.TunnelId,
+			pFrrCall->PsbKey.Session.ExtTunelId,
+			__FILE__, __LINE__);
+	    }
+	}
+      zlog_info ("\ncreation event...");
+      if ((pEvent =
+	   sm_gen_sync_event_send ((HANDLE) pSm, event, NULL)) == NULL)
+	{
+	  zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+	  XFREE (MTYPE_TE, pFrrSmData);
+	  sm_gen_free (pSm);
+	}
+    }
+  return pEvent;
+}
+
+extern PATRICIA_TREE PlatformWideFreeLabels;
+extern LABEL_ENTRY PlatformWideLabelSpace[LABEL_SPACE_SIZE];
+
+uns32
+UpdateIfWithSingleBacupInfo (FRR_SM_DATA * pFrrSmData,
+			     unsigned int Label,
+			     PSB_KEY * PSB_KEY, unsigned int MergeNodeLabel)
+{
+  COMPONENT_LINK *pComponentLink;
+  FRR_LABEL_ENTRY *pLabelEntry;
+  FRR_INGRESS_ENTRY *pIngressEntry;
+  FRR_SM_ENTRY *pFrrEntry = &pFrrSmData->FrrSmEntry;
+
+  if (rdb_get_component_link (pFrrEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      pFrrEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      &pComponentLink) != E_OK)
+    {
+      zlog_err ("\ncannot get component link %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if ((pLabelEntry =
+       patricia_tree_get (&pFrrEntry->labels_tree,
+			  (const uns8 *) &Label)) != NULL)
+    {
+      if (patricia_tree_get
+	  (&PlatformWideFreeLabels,
+	   (const uns8 *) &pLabelEntry->Label) == NULL)
+	{
+	  PlatformWideLabelSpace[pLabelEntry->Label -
+				 1].BackupForwardingInformation.
+	    MergeNodeLabel = MergeNodeLabel;
+	  PlatformWideLabelSpace[pLabelEntry->Label -
+				 1].BackupForwardingInformation.
+	    MergeNodeLabelValid = TRUE;
+	  /*PlatformWideLabelSpace[pLabelEntry->Label-1].BackupForwardingInformation.PSB_KEY = *PSB_KEY; */
+	  if (pFrrSmData->BypassTunnelsLabel != 0)
+	    {
+	      PlatformWideLabelSpace[pLabelEntry->Label -
+				     1].BackupForwardingInformation.
+		BypassTunnelsLabel = pFrrSmData->BypassTunnelsLabel;
+	      PlatformWideLabelSpace[pLabelEntry->Label -
+				     1].BackupForwardingInformation.OutIf =
+		pFrrSmData->BackupOutIf;
+	      zlog_info
+		("\nLSR: deletion from FRR SM tree and insertion to component link tree");
+	      if (patricia_tree_del
+		  (&pFrrEntry->labels_tree, &pLabelEntry->Node) != E_OK)
+		{
+		  zlog_err ("\ncannot delete node from patricia tree %s %d",
+			    __FILE__, __LINE__);
+		}
+	      else
+		if (patricia_tree_add
+		    (&pComponentLink->ProtectionTree,
+		     &pLabelEntry->Node) != E_OK)
+		{
+		  zlog_err ("\ncannot add node to patricia %s %d", __FILE__,
+			    __LINE__);
+		}
+	      else
+		{
+		  if (InformRsvpAboutFrr
+		      (&PlatformWideLabelSpace[pLabelEntry->Label - 1].
+		       BackupForwardingInformation.PSB_KEY,
+		       PlatformWideLabelSpace[pLabelEntry->Label -
+					      1].allocator,
+		       PlatformWideLabelSpace[pLabelEntry->Label - 1].IfIndex,
+		       pFrrSmData->BackupOutIf, pFrrSmData->card,
+		       PlatformWideLabelSpace[pLabelEntry->Label -
+					      1].BackupForwardingInformation.
+		       MergeNode) != E_OK)
+		    {
+		      zlog_err ("\ncannot update LCC with backup intfo");
+		    }
+		}
+	    }
+	}
+      else
+	{
+	  zlog_err ("\nAllocated Label %x is not really allocated %s %d...",
+		    pLabelEntry->Label, __FILE__, __LINE__);
+	}
+    }
+  return E_OK;
+}
+
+uns32
+UpdateIfWithSingleIngressBacupInfo (FRR_SM_DATA * pFrrSmData,
+				    PSB_KEY * PsbKey,
+				    unsigned int MergeNodeLabel)
+{
+  COMPONENT_LINK *pComponentLink;
+  FRR_INGRESS_ENTRY *pIngressEntry;
+  FRR_SM_ENTRY *pFrrEntry = &pFrrSmData->FrrSmEntry;
+
+  PsbKey->SenderTemplate.LspId = ntohs (PsbKey->SenderTemplate.LspId);
+
+  if (rdb_get_component_link (pFrrEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      pFrrEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      &pComponentLink) != E_OK)
+    {
+      zlog_err ("\ncannot get component link %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if ((pIngressEntry =
+       patricia_tree_get (&pFrrEntry->ingress_tree,
+			  (const uns8 *) PSB_KEY)) != NULL)
+    {
+      /* update working RSVP LSP with valid info */
+      if (pFrrSmData->BypassTunnelsLabel != 0)
+	{
+	  RSVP_TUNNEL_PROPERTIES *pTunnel;
+	  RSVP_LSP_PROPERTIES *pRsvpLsp;
+	  uns16 SavedLspId = pIngressEntry->PSB_KEY.sender.Lsp_IdNet;
+	  IPV4_ADDR SavedSenderIp =
+	    pIngressEntry->PSB_KEY.sender.IPv4TunnelSenderNet;
+	  pIngressEntry->PsbKey.SenderTemplate.LspId = 0;
+	  pIngressEntry->PsbKey.SenderTemplate.IpAddr = 0;
+	  if (FindTunnel (&pIngressEntry->PsbKey, &pTunnel, ALL_TRUNKS) ==
+	      TRUE)
+	    {
+	      pIngressEntry->PsbKey.SenderTemplate.LspId = SavedLspId;
+	      pIngressEntry->PsbKey.SenderTemplate.IpAddr = SavedSenderIp;
+	      if (((pRsvpLsp =
+		    FindRsvpLspByLspId (pTunnel, SavedLspId)) != NULL)
+		  && (pRsvpLsp->tunneled == FALSE))
+		{
+		  pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		    MergeNodeLabelValid = TRUE;
+		  pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		    MergeNodeLabel = MergeNodeLabel;
+		  /*pRsvpLsp->forw_info.path.BackupForwardingInformation.PSB_KEY = *PSB_KEY; */
+		  if (pFrrSmData->BypassTunnelsLabel != 0)
+		    {
+		      pRsvpLsp->forw_info.path.BackupForwardingInformation.
+			BypassTunnelsLabel = pFrrSmData->BypassTunnelsLabel;
+		      pRsvpLsp->forw_info.path.BackupForwardingInformation.
+			OutIf = pFrrSmData->BackupOutIf;
+		      zlog_info
+			("\nIngress: deletion from FRR SM tree and insertion to component link tree");
+		      if (patricia_tree_del
+			  (&pFrrEntry->ingress_tree,
+			   &pIngressEntry->Node) != E_OK)
+			{
+			  zlog_err
+			    ("\ncannot delete node from patricia tree %s %d",
+			     __FILE__, __LINE__);
+			}
+		      else
+			if (patricia_tree_add
+			    (&pComponentLink->IngressProtectionTree,
+			     &pIngressEntry->Node) != E_OK)
+			{
+			  zlog_err ("\ncannot add node to patricia %s %d",
+				    __FILE__, __LINE__);
+			}
+		      else
+			{
+			  if (InformRsvpAboutFrr (PsbKey,
+						  pRsvpLsp->card,
+						  pRsvpLsp->oIfIndex,
+						  pFrrSmData->BackupOutIf,
+						  pRsvpLsp->forw_info.path.
+						  BackupForwardingInformation.
+						  MergeNode) != E_OK)
+			    {
+			      zlog_err
+				("\ncannot update LCC with backup intfo");
+			    }
+			}
+		    }
+		}
+	      else
+		{
+		  if (pRsvpLsp == NULL)
+		    {
+		      zlog_err
+			("\ncannot get working RSVP LSP %x %x %x %x %x %s %d",
+			 pIngressEntry->PsbKey.Session.Dest,
+			 pIngressEntry->PsbKey.Session.TunnelId,
+			 pIngressEntry->PsbKey.Session.ExtTunelId, SavedLspId,
+			 SavedSenderIp, __FILE__, __LINE__);
+		    }
+		  else
+		    {
+		      zlog_err ("\nRSVP LSP %x %x %x is tunneled %x %s %d",
+				pIngressEntry->PsbKey.Session.Dest,
+				pIngressEntry->PsbKey.Session.TunnelId,
+				pIngressEntry->PsbKey.Session.ExtTunelId,
+				pRsvpLsp->tunneled, __FILE__, __LINE__);
+		    }
+		}
+	    }
+	}
+    }
+  return E_OK;
+}
+
+uns32
+UpdateIfWithBacupInfo (FRR_SM_DATA * pFrrSmData)
+{
+  COMPONENT_LINK *pComponentLink;
+  FRR_LABEL_ENTRY *pLabelEntry;
+  FRR_INGRESS_ENTRY *pIngressLabelEntry;
+  unsigned int key = 0;
+  PSB_KEY PsbKey;
+  FRR_SM_ENTRY *pFrrEntry = &pFrrSmData->FrrSmEntry;
+
+  if (rdb_get_component_link (pFrrEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      pFrrEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      &pComponentLink) != E_OK)
+    {
+      zlog_err ("\ncannot get component link %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  /* first - update LSR entries */
+  zlog_info ("\nupdating an LSR entries %x %x %x...",
+	     pFrrEntry->frr_key.merge_node, pFrrEntry->frr_key.OutIfIndex,
+	     pFrrEntry->frr_key.protected_node);
+  while ((pLabelEntry =
+	  patricia_tree_getnext (&pFrrEntry->labels_tree,
+				 (const uns8 *) &key)) != NULL)
+    {
+      if (patricia_tree_get
+	  (&PlatformWideFreeLabels,
+	   (const uns8 *) &pLabelEntry->Label) == NULL)
+	{
+	  if (PlatformWideLabelSpace[pLabelEntry->Label - 1].
+	      BackupForwardingInformation.MergeNodeLabelValid == TRUE)
+	    {
+	      PlatformWideLabelSpace[pLabelEntry->Label -
+				     1].BackupForwardingInformation.
+		BypassTunnelsLabel = pFrrSmData->BypassTunnelsLabel;
+	      PlatformWideLabelSpace[pLabelEntry->Label -
+				     1].BackupForwardingInformation.OutIf =
+		pFrrSmData->BackupOutIf;
+	      zlog_info
+		("\naLSR: deletion from FRR SM tree and insertion to component link tree");
+	      if (patricia_tree_del
+		  (&pFrrEntry->labels_tree, &pLabelEntry->Node) != E_OK)
+		{
+		  zlog_err ("\ncannot delete node from patricia tree %s %d",
+			    __FILE__, __LINE__);
+		}
+	      else
+		{
+		  if (patricia_tree_add
+		      (&pComponentLink->ProtectionTree,
+		       &pLabelEntry->Node) != E_OK)
+		    {
+		      zlog_err ("\ncannot add node to patricia %s %d",
+				__FILE__, __LINE__);
+		    }
+		  else
+		    if (InformRsvpAboutFrr
+			(&PlatformWideLabelSpace[pLabelEntry->Label - 1].
+			 BackupForwardingInformation.PSB_KEY,
+			 PlatformWideLabelSpace[pLabelEntry->Label -
+						1].allocator,
+			 PlatformWideLabelSpace[pLabelEntry->Label -
+						1].IfIndex,
+			 pFrrSmData->BackupOutIf, pFrrSmData->card,
+			 PlatformWideLabelSpace[pLabelEntry->Label -
+						1].
+			 BackupForwardingInformation.MergeNode) != E_OK)
+		    {
+		      zlog_err ("\ncannot update LCC with backup intfo");
+		    }
+		}
+	    }
+	}
+      else
+	{
+	  zlog_err ("\nAllocated Label %x is not really allocated %s %d...",
+		    pLabelEntry->Label, __FILE__, __LINE__);
+	}
+      key = pLabelEntry->Label;
+    }
+  /* second - update Ingress entries */
+  memset (&PSB_KEY, 0, sizeof (PSB_KEY));
+  zlog_info ("\nupdating an Ingress entries...");
+  while ((pIngressLabelEntry =
+	  patricia_tree_getnext (&pFrrEntry->ingress_tree,
+				 (const uns8 *) &PSB_KEY)) != NULL)
+    {
+      RSVP_TUNNEL_PROPERTIES *pTunnel;
+      uns16 SavedLspId = pIngressLabelEntry->PSB_KEY.sender.Lsp_IdNet;
+      IPV4_ADDR SavedSenderIp =
+	pIngressLabelEntry->PSB_KEY.sender.IPv4TunnelSenderNet;
+
+      pIngressLabelEntry->PsbKey.SenderTemplate.LspId = 0;
+      pIngressLabelEntry->PsbKey.SenderTemplate.IpAddr = 0;
+      zlog_info ("\nfinding a tunnel...");
+      if (FindTunnel (&pIngressLabelEntry->PsbKey, &pTunnel, ALL_TRUNKS) ==
+	  TRUE)
+	{
+	  RSVP_LSP_PROPERTIES *pRsvpLsp;
+
+	  pIngressLabelEntry->PsbKey.SenderTemplate.LspId = SavedLspId;
+	  pIngressLabelEntry->PsbKey.SenderTemplate.IpAddr = SavedSenderIp;
+	  zlog_info ("\nfinding an LSP...");
+	  if (((pRsvpLsp = FindRsvpLspByLspId (pTunnel, SavedLspId)) != NULL)
+	      && (pRsvpLsp->tunneled == FALSE))
+	    {
+	      if (pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		  MergeNodeLabelValid == TRUE)
+		{
+		  pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		    BypassTunnelsLabel = pFrrSmData->BypassTunnelsLabel;
+		  pRsvpLsp->forw_info.path.BackupForwardingInformation.OutIf =
+		    pFrrSmData->BackupOutIf;
+		  zlog_info
+		    ("\naIngress: deletion from FRR SM tree and insertion to component link tree");
+		  if (patricia_tree_del
+		      (&pFrrEntry->ingress_tree,
+		       &pIngressLabelEntry->Node) == E_OK)
+		    {
+		      if (patricia_tree_add
+			  (&pComponentLink->IngressProtectionTree,
+			   &pIngressLabelEntry->Node) != E_OK)
+			{
+			  zlog_err
+			    ("\ncannot add entry to Ingress tree %x %x %x %x %s %d",
+			     pComponentLink->oifIndex,
+			     pIngressLabelEntry->PsbKey.Session.Dest,
+			     pIngressLabelEntry->PsbKey.Session.TunnelId,
+			     pIngressLabelEntry->PsbKey.Session.ExtTunelId,
+			     __FILE__, __LINE__);
+			}
+		      else
+			{
+			  if (InformRsvpAboutFrr
+			      (&pRsvpLsp->forw_info.path.
+			       BackupForwardingInformation.PsbKey,
+			       pRsvpLsp->oIfIndex, pFrrSmData->BackupOutIf,
+			       pRsvpLsp->forw_info.path.
+			       BackupForwardingInformation.MergeNode) != E_OK)
+			    {
+			      zlog_err
+				("\ncannot update LCC with backup intfo");
+			    }
+			}
+		    }
+		  else
+		    {
+		      zlog_err
+			("\ncannot delete node from patricia %x %x %x %s %d",
+			 pIngressLabelEntry->PsbKey.Session.Dest,
+			 pIngressLabelEntry->PsbKey.Session.TunnelId,
+			 pIngressLabelEntry->PsbKey.Session.ExtTunelId,
+			 __FILE__, __LINE__);
+		    }
+		}
+	    }
+	  else
+	    {
+	      if (pRsvpLsp == NULL)
+		{
+		  zlog_err
+		    ("\ncannot get working RSVP LSP %x %x %x %x %x %s %d",
+		     pIngressLabelEntry->PsbKey.Session.Dest,
+		     pIngressLabelEntry->PsbKey.Session.TunnelId,
+		     pIngressLabelEntry->PsbKey.Session.ExtTunelId,
+		     SavedLspId, SavedSenderIp, __FILE__, __LINE__);
+		}
+	      else
+		{
+		  zlog_err ("\nRSVP LSP %x %x %x is tunneled %x %s %d",
+			    pIngressLabelEntry->PsbKey.Session.Dest,
+			    pIngressLabelEntry->PsbKey.Session.TunnelId,
+			    pIngressLabelEntry->PsbKey.Session.ExtTunelId,
+			    pRsvpLsp->tunneled, __FILE__, __LINE__);
+		}
+	    }
+	}
+      else
+	{
+	  zlog_err ("\ncannot find tunnel %x %x %x %s %d", __FILE__,
+		    __LINE__);
+	}
+      PsbKey = pIngressLabelEntry->PsbKey;
+    }
+  return E_OK;
+}
+
+FRR_SM_ENTRY *
+FindFastRerouteSm (FRR_SM_KEY * frr_key)
+{
+  return patricia_tree_get (&FastReRouteSmTree, (const uns8 *) frr_key);
+}
+
+void
+InitFastReRoute ()
+{
+  PATRICIA_PARAMS params;
+
+  params.key_size = sizeof (FRR_SM_KEY);
+  params.info_size = 0;
+  if (patricia_tree_init (&FastReRouteSmTree, &params) != E_OK)
+    {
+      zlog_err ("\ncannot initiate patricia tree for FRR");
+      return;
+    }
+}
+
+void
+RRO_ChangedHook (uns32 Label,
+		 RSVP_RRO_LSP_TUNNEL * pRro,
+		 SESSION_OBJ * pSess,
+		 SENDER_TEMPLATE_OBJ * pSender, uns32 IfIndex)
+{
+  TE_MSG *pMsg;
+  /* clone RRO and send it up */
+  /*if((pMsg = dmsg_create(GetLcbPtr(),LTCS_EVENT_RRO_CHANGED)) == NULL)
+     {
+     zlog_info("\ncannot create message %s %d",__FILE__,__LINE__);
+     return;
+     } */
+  if (Label == 0)
+    {
+      zlog_info
+	("\ninside of RRO_ChangedHook: Dest#%x Tunnel#%x Source#%x LspId#%x Source %x",
+	 pSess->Dest, pSess->TunnelId, pSess->ExtTunelId, pSender->LspId,
+	 pSender->IpAddr);
+    }
+  else
+    {
+      zlog_info ("\ninside of RRO_ChangedHook: Label#%x", Label);
+    }
+  if ((pRro != NULL) && (pRro->nSubObjects != 0))
+    {
+      if ((pMsg->info.rro_changed_hook.pRro =
+	   XMALLOC (MTYPE_TE,
+		    (sizeof (RSVP_RRO_LSP_TUNNEL) +
+		     sizeof (RSVP_RRO_SUBOBJ) * (pRro->nSubObjects - 1)))) ==
+	  NULL)
+	{
+	  zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  dmsg_release (pMsg);
+	  return;
+	}
+      pMsg->info.rro_changed_hook.pRro->nSubObjects = pRro->nSubObjects;
+      memcpy (pMsg->info.rro_changed_hook.pRro->SubObjects,
+	      pRro->SubObjects,
+	      sizeof (RSVP_RRO_SUBOBJ) * (pRro->nSubObjects));
+#if 1
+      {
+	int i;
+	RSVP_RRO_SUBOBJ *pDbg = pMsg->info.rro_changed_hook.pRro->SubObjects;
+	for (i = 0; i < pMsg->info.rro_changed_hook.pRro->nSubObjects; i++)
+	  {
+	    switch (pDbg[i].SubType)
+	      {
+	      case 1:
+		zlog_info
+		  ("\nobj#%d IP ADDR %x/%x prefix len %x/%x flag %x/%x", i,
+		   pDbg[i].SubData.IPv4.Addr,
+		   pRro->SubObjects[i].SubData.IPv4.Addr,
+		   pDbg[i].SubData.IPv4.PrefixBitLen,
+		   pRro->SubObjects[i].SubData.IPv4.PrefixBitLen,
+		   pDbg[i].SubData.IPv4.Flags,
+		   pRro->SubObjects[i].SubData.IPv4.Flags);
+		break;
+	      case 3:
+		zlog_info
+		  ("\nobj#%d LABEL ctype %x/%x flags %x/%x value %x/%x", i,
+		   pDbg[i].SubData.Label.Label_CType,
+		   pRro->SubObjects[i].SubData.Label.Label_CType,
+		   pDbg[i].SubData.Label.Label_Flags,
+		   pRro->SubObjects[i].SubData.Label.Label_Flags,
+		   pDbg[i].SubData.Label.Label_Value,
+		   pRro->SubObjects[i].SubData.Label.Label_Value);
+		break;
+	      default:
+		zlog_info ("\nobject of unknown type %x/%x", pDbg[i].SubType,
+			   pRro->SubObjects[i].SubType);
+	      }
+	  }
+      }
+#endif
+    }
+  pMsg->info.rro_changed_hook.Label = Label;
+  pMsg->info.rro_changed_hook.OutIf = IfIndex;
+  if (pMsg->info.rro_changed_hook.Label == 0)
+    {
+      pMsg->info.rro_changed_hook.PSB_KEY.Session.Dest = pSess->IPDestNet;
+      pMsg->info.rro_changed_hook.PSB_KEY.Session.TunnelId = pSess->TunnelId;
+      pMsg->info.rro_changed_hook.PSB_KEY.Session.ExtTunelId =
+	pSess->ExtendedTunnelId;
+      pMsg->info.rro_changed_hook.PSB_KEY.sender.Lsp_IdNet =
+	pSender->Lsp_IdNet;
+      pMsg->info.rro_changed_hook.PSB_KEY.sender.IPv4TunnelSenderNet =
+	pSender->IPv4TunnelSenderNet;
+    }
+  if (svc_send_msg (pMsg, 1, MDS_USR_CONSOLE_SVC) != E_OK)
+    zlog_info ("\nFatal: can not send mds message %s %d", __FILE__, __LINE__);
+  if (pMsg->info.rro_changed_hook.pRro != NULL)
+    XFREE (MTYPE_TE, pMsg->info.rro_changed_hook.pRro);
+  return;
+}
+
+void
+RRO_ChangedMsg (RRO_CHANGED_HOOK * pChangedRRO)
+{
+  int i;
+  RSVP_RRO_LSP_TUNNEL *pRro = pChangedRRO->pRro;
+  FRR_SM_ENTRY *pFrrSmEntry;
+  FRR_SM_KEY *pFrrSmKey;
+  IPV4_ADDR merge_node_router_id = 0;
+  HJCONTEXT rdb_handle = ((LTCS_CB *) GetLcbPtr ())->rdb_layer_handle;
+
+  zlog_info ("\ninside of RRO_ChangedMsg %x", pChangedRRO->Label);
+  if (pChangedRRO->Label != 0)
+    {
+      pFrrSmKey =
+	&PlatformWideLabelSpace[pChangedRRO->Label -
+				1].BackupForwardingInformation.frr_key;
+      pFrrSmEntry = FindFastRerouteSm (pFrrSmKey);
+      if (pFrrSmEntry == NULL)
+	{
+	  zlog_err ("\ncannot get FRR SM entry for %x %x %x %s %d",
+		    pFrrSmKey->merge_node, pFrrSmKey->OutIfIndex,
+		    pFrrSmKey->protected_node, __FILE__, __LINE__);
+	  return;
+	}
+    }
+  else
+    {
+      RSVP_TUNNEL_PROPERTIES *pTunnel;
+      uns16 SavedLspId = pChangedRRO->PSB_KEY.sender.Lsp_IdNet;
+      IPV4_ADDR SavedSenderIp =
+	pChangedRRO->PSB_KEY.sender.IPv4TunnelSenderNet;
+
+      pChangedRRO->PSB_KEY.Session.Dest =
+	ntohl (pChangedRRO->PSB_KEY.Session.Dest);
+
+      pChangedRRO->PSB_KEY.sender.Lsp_IdNet = 0;
+      pChangedRRO->PSB_KEY.sender.IPv4TunnelSenderNet = 0;
+
+      if (FindTunnel (&pChangedRRO->PSB_KEY, &pTunnel, ALL_TRUNKS) == TRUE)
+	{
+	  RSVP_LSP_PROPERTIES *pRsvpLsp;
+
+	  pChangedRRO->PSB_KEY.sender.Lsp_IdNet = ntohs (SavedLspId);
+	  pChangedRRO->PSB_KEY.sender.IPv4TunnelSenderNet = SavedSenderIp;
+
+	  if (((pRsvpLsp =
+		FindRsvpLspByLspId (pTunnel, ntohs (SavedLspId))) != NULL)
+	      && (pRsvpLsp->tunneled == FALSE))
+	    {
+	      pFrrSmKey =
+		&pRsvpLsp->forw_info.path.BackupForwardingInformation.frr_key;
+	      pFrrSmEntry = FindFastRerouteSm (pFrrSmKey);
+	      if (pFrrSmEntry == NULL)
+		{
+		  zlog_err
+		    ("\ncannot get FRR SM entry for %x/%x %x/%x %x/%x %s %d",
+		     pFrrSmKey->merge_node,
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     frr_key.merge_node, pFrrSmKey->OutIfIndex,
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     frr_key.OutIfIndex, pFrrSmKey->protected_node,
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     frr_key.protected_node, __FILE__, __LINE__);
+		  return;
+		}
+	    }
+	  else
+	    {
+	      if (pRsvpLsp == NULL)
+		{
+		  zlog_err
+		    ("\ncannot get working RSVP LSP for %x %x %x %x %x %s %d",
+		     pChangedRRO->PSB_KEY.Session.Dest,
+		     pChangedRRO->PSB_KEY.Session.TunnelId,
+		     pChangedRRO->PSB_KEY.Session.ExtTunelId, SavedLspId,
+		     SavedSenderIp, __FILE__, __LINE__);
+		}
+	      else
+		{
+		  zlog_err ("\nRSVP LSP %x %x %x %x %x is tunneled %x %s %d",
+			    pChangedRRO->PSB_KEY.Session.Dest,
+			    pChangedRRO->PSB_KEY.Session.TunnelId,
+			    pChangedRRO->PSB_KEY.Session.ExtTunelId,
+			    SavedLspId,
+			    SavedSenderIp,
+			    pRsvpLsp->tunneled, __FILE__, __LINE__);
+		}
+	      return;
+	    }
+	}
+      else
+	{
+	  zlog_err ("\ncannot find tunnel %x %x %x %x %x %s %d",
+		    pChangedRRO->PSB_KEY.Session.Dest,
+		    pChangedRRO->PSB_KEY.Session.TunnelId,
+		    pChangedRRO->PSB_KEY.Session.ExtTunelId,
+		    SavedLspId, SavedSenderIp, __FILE__, __LINE__);
+	  return;
+	}
+    }
+
+
+  if (pFrrSmEntry == NULL)
+    {
+      zlog_err ("\ncannot find FastReRoute SM by key %x %x %x",
+		pFrrSmKey->merge_node,
+		pFrrSmKey->OutIfIndex, pFrrSmKey->protected_node);
+      return;
+    }
+  if (rdb_remote_link_router_id_get (rdb_handle,
+				     pFrrSmKey->merge_node,
+				     &merge_node_router_id) != E_OK)
+    {
+      zlog_err ("\ncannot get merge node's %x router ID %s %d",
+		pFrrSmKey->merge_node, __FILE__, __LINE__);
+    }
+  zlog_info ("\nRouterID of the merge node %x", merge_node_router_id);
+
+  if (pRro != NULL)
+    {
+      for (i = 0; i < pRro->nSubObjects; i++)
+	{
+	  if (pRro->SubObjects[i].SubType == RSVP_RRO_SUBOBJ_TYPE_IPV4_ADDR)
+	    {
+	      IPV4_ADDR node_router_id = 0;
+	      if (rdb_remote_link_router_id_get (rdb_handle,
+						 pRro->SubObjects[i].SubData.
+						 IPv4.Addr,
+						 &node_router_id) != E_OK)
+		{
+		  node_router_id = pRro->SubObjects[i].SubData.IPv4.Addr;
+		}
+
+	      zlog_info ("\nnode#%d/%x router ID %x",
+			 i,
+			 pRro->SubObjects[i].SubData.IPv4.Addr,
+			 node_router_id);
+
+	      if ((node_router_id == merge_node_router_id) &&
+		  (i < (pRro->nSubObjects - 1)))
+		{
+		  if ((pRro->SubObjects[i + 1].SubType ==
+		       RSVP_RRO_SUBOBJ_TYPE_LABEL_OBJ)
+		      && (pRro->SubObjects[i + 1].SubData.Label.Label_Flags !=
+			  0))
+		    {
+		      /* call here SM */
+		      if (pChangedRRO->Label != 0)
+			{
+			  UpdateIfWithSingleBacupInfo (((SM_T *) pFrrSmEntry->
+							sm_handle)->data,
+						       pChangedRRO->Label,
+						       &pChangedRRO->PSB_KEY,
+						       pRro->SubObjects[i +
+									1].
+						       SubData.Label.
+						       Label_Value);
+			}
+		      else
+			{
+			  UpdateIfWithSingleIngressBacupInfo (((SM_T *)
+							       pFrrSmEntry->
+							       sm_handle)->
+							      data,
+							      &pChangedRRO->
+							      PSB_KEY,
+							      pRro->
+							      SubObjects[i +
+									 1].
+							      SubData.Label.
+							      Label_Value);
+			}
+		      return;
+		    }
+		  else
+		    if ((pRro->SubObjects[i + 1].SubType ==
+			 RSVP_RRO_SUBOBJ_TYPE_LABEL_OBJ)
+			&& (pRro->SubObjects[i + 1].SubData.Label.
+			    Label_Flags == 0))
+		    {
+		      zlog_err
+			("\nMerge node does not use platform-wide label space");
+		    }
+		  else
+		    {
+		      zlog_err
+			("\nThere is no label object after hop object");
+		    }
+		}
+	      else if (merge_node_router_id == node_router_id)
+		{
+		  zlog_err ("\nMerge node is found but it is last object");
+		}
+	    }
+	}
+      XFREE (MTYPE_TE, pRro);
+    }
+  zlog_err ("\nMerge node is not found %s %d", __FILE__, __LINE__);
+}
+
+void
+FrrLabelRelease (unsigned int Label)
+{
+  FRR_SM_KEY *pFrrSmKey;
+  FRR_SM_ENTRY *pFrrSmEntry;
+  FRR_LABEL_ENTRY *pLabelEntry;
+  COMPONENT_LINK *pComponentLink;
+  /* validate the Label here */
+  zlog_info ("\ninside of FrrLabelRelease %x", Label);
+  pFrrSmKey =
+    &PlatformWideLabelSpace[Label - 1].BackupForwardingInformation.frr_key;
+  if ((pFrrSmEntry = FindFastRerouteSm (pFrrSmKey)) != NULL)
+    {
+      if ((pLabelEntry =
+	   patricia_tree_get (&pFrrSmEntry->labels_tree,
+			      (const uns8 *) &Label)) != NULL)
+	{
+	  zlog_info ("\nLabel entry is on FRR's tree...");
+	  if (patricia_tree_del
+	      (&pFrrSmEntry->labels_tree, &pLabelEntry->Node) != E_OK)
+	    {
+	      zlog_err ("\ncannot delete node from patricia %s %d", __FILE__,
+			__LINE__);
+	      return;
+	    }
+	  XFREE (MTYPE_TE, pLabelEntry);
+	  return;
+	}
+    }
+  else
+    {
+      zlog_err ("\ncannot find FRR SM entry %x %x %x %s %d",
+		pFrrSmKey->merge_node,
+		pFrrSmKey->OutIfIndex,
+		pFrrSmKey->protected_node, __FILE__, __LINE__);
+      return;
+    }
+  if (rdb_get_component_link (((LTCS_CB *) GetLcbPtr ())->rdb_layer_handle, pFrrSmEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      pFrrSmEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      &pComponentLink) != E_OK)
+    {
+      zlog_err ("\ncannot get component link %s %d", __FILE__, __LINE__);
+      return;
+    }
+  zlog_info ("\nLooking for the label entry on component link's tree...");
+  if ((pLabelEntry =
+       patricia_tree_get (&pComponentLink->ProtectionTree,
+			  (const uns8 *) &Label)) != NULL)
+    {
+      if (patricia_tree_del
+	  (&pComponentLink->ProtectionTree, &pLabelEntry->Node) != E_OK)
+	{
+	  zlog_err ("\ncannot delete node from patricia %s %d", __FILE__,
+		    __LINE__);
+	  return;
+	}
+      XFREE (MTYPE_TE, pLabelEntry);
+      return;
+    }
+  zlog_err ("\nLabel is not backuped nor goes to be backuped %s %d", __FILE__,
+	    __LINE__);
+}
+
+void
+FrrIngressRelease (PSB_KEY * PSB_KEY)
+{
+  FRR_SM_KEY *pFrrSmKey;
+  FRR_SM_ENTRY *pFrrSmEntry;
+  FRR_INGRESS_ENTRY *pIngressLabelEntry;
+  COMPONENT_LINK *pComponentLink;
+  RSVP_TUNNEL_PROPERTIES *pTunnel;
+  RSVP_LSP_PROPERTIES *pRsvpLsp;
+  uns16 SavedLspId = PSB_KEY->sender.Lsp_IdNet;
+  IPV4_ADDR SavedSenderIp = PSB_KEY->sender.IPv4TunnelSenderNet;
+  zlog_info ("\nInside of FrrIngressRelease...");
+  PSB_KEY->sender.Lsp_IdNet = 0;
+  PSB_KEY->sender.IPv4TunnelSenderNet = 0;
+  if (FindTunnel (PSB_KEY, &pTunnel, ALL_TRUNKS) == TRUE)
+    {
+      if (((pRsvpLsp =
+	    FindRsvpLspByLspId (pTunnel, ntohs (SavedLspId))) != NULL)
+	  && (pRsvpLsp->tunneled == FALSE))
+	{
+	  pFrrSmKey =
+	    &pRsvpLsp->forw_info.path.BackupForwardingInformation.frr_key;
+	  if ((pFrrSmEntry = FindFastRerouteSm (pFrrSmKey)) != NULL)
+	    {
+	      PSB_KEY->sender.Lsp_IdNet = SavedLspId;
+	      PSB_KEY->sender.IPv4TunnelSenderNet = SavedSenderIp;
+	      zlog_info
+		("\nLooking for the label entry on ont hte FRR's tree...");
+	      if ((pIngressLabelEntry =
+		   patricia_tree_get (&pFrrSmEntry->ingress_tree,
+				      (const uns8 *) PSB_KEY)) != NULL)
+		{
+		  if (patricia_tree_del
+		      (&pFrrSmEntry->ingress_tree,
+		       &pIngressLabelEntry->Node) != E_OK)
+		    {
+		      zlog_err ("\ncannot delete node from patricia %s %d",
+				__FILE__, __LINE__);
+		      return;
+		    }
+		  XFREE (MTYPE_TE, pIngressLabelEntry);
+		  return;
+		}
+	    }
+	  else
+	    {
+	      zlog_err ("\ncannot find FRR SM %x %x %x %s %d",
+			pFrrSmKey->merge_node,
+			pFrrSmKey->OutIfIndex,
+			pFrrSmKey->protected_node, __FILE__, __LINE__);
+	      return;
+	    }
+	}
+      else
+	{
+	  zlog_err ("\ncannot get RSVP LSP by id %x %s %d", SavedLspId,
+		    __FILE__, __LINE__);
+	  return;
+	}
+    }
+  else
+    {
+      zlog_err ("\ncannot find tunnel %x %x %x %s %d",
+		PSB_KEY->Session.Dest,
+		PSB_KEY->Session.TunnelId,
+		PSB_KEY->Session.ExtTunelId, __FILE__, __LINE__);
+      return;
+    }
+
+  if (rdb_get_component_link (((LTCS_CB *) GetLcbPtr ())->rdb_layer_handle, pFrrSmEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      pFrrSmEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      &pComponentLink) != E_OK)
+    {
+      zlog_err ("\ncannot get component link %s %d", __FILE__, __LINE__);
+      return;
+    }
+  zlog_info ("\nLooking for the label entry on component link's tree...");
+  if ((pIngressLabelEntry =
+       patricia_tree_get (&pComponentLink->IngressProtectionTree,
+			  (const uns8 *) PSB_KEY)) != NULL)
+    {
+      if (patricia_tree_del
+	  (&pComponentLink->IngressProtectionTree,
+	   &pIngressLabelEntry->Node) != E_OK)
+	{
+	  zlog_err ("\ncannot delete node from patricia %s %d", __FILE__,
+		    __LINE__);
+	  return;
+	}
+      XFREE (MTYPE_TE, pIngressLabelEntry);
+      return;
+    }
+  zlog_err ("\nLabel is not backuped nor goes to be backuped %s %d", __FILE__,
+	    __LINE__);
+}
+
+void
+BypassTunnelFailed (FRR_SM_DATA * pFrrSmData)
+{
+  COMPONENT_LINK *pComponentLink;
+  FRR_LABEL_ENTRY *pLabelEntry;
+  FRR_INGRESS_ENTRY *pIngressLabelEntry;
+  unsigned int key = 0;
+  PSB_KEY PSB_KEY;
+  FRR_SM_ENTRY *pFrrEntry = &pFrrSmData->FrrSmEntry;
+
+  if (rdb_get_component_link (((LTCS_CB *) GetLcbPtr ())->rdb_layer_handle, pFrrEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      pFrrEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+			      &pComponentLink) != E_OK)
+    {
+      zlog_err ("\ncannot get component link %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  memset (&PSB_KEY, 0, sizeof (PSB_KEY));
+  while ((pIngressLabelEntry =
+	  patricia_tree_getnext (&pComponentLink->IngressProtectionTree,
+				 (const uns8 *) &PSB_KEY)) != NULL)
+    {
+      if (patricia_tree_del
+	  (&pComponentLink->IngressProtectionTree,
+	   &pIngressLabelEntry->Node) != E_OK)
+	{
+	  zlog_err ("\ncannot delete a node from patricia %s %d", __FILE__,
+		    __LINE__);
+	}
+      else
+	{
+	  if (patricia_tree_add
+	      (&pFrrEntry->ingress_tree, &pIngressLabelEntry->Node) != E_OK)
+	    {
+	      zlog_err ("\ncannot add node to patricia tree %s %d", __FILE__,
+			__LINE__);
+	    }
+	}
+      PSB_KEY = pIngressLabelEntry->PSB_KEY;
+    }
+  while ((pLabelEntry =
+	  patricia_tree_getnext (&pComponentLink->ProtectionTree,
+				 (const uns8 *) &key)) != NULL)
+    {
+      if (patricia_tree_del
+	  (&pComponentLink->ProtectionTree, &pLabelEntry->Node) != E_OK)
+	{
+	  zlog_err ("\ncannot delete a node from patricia %s %d", __FILE__,
+		    __LINE__);
+	}
+      else
+	{
+	  if (patricia_tree_add (&pFrrEntry->labels_tree, &pLabelEntry->Node)
+	      != E_OK)
+	    {
+	      zlog_err ("\ncannot add node to patricia tree %s %d", __FILE__,
+			__LINE__);
+	    }
+	}
+      key = pLabelEntry->Label;
+    }
+}
+
+void
+BypassTunnelRetryExpiry (LTCS_MSG * pMsg)
+{
+  FRR_SM_ENTRY *pFrrSmEntry;
+  OPEN_RSVP_CRLSP *pOpenLspParams;
+  PSB_KEY PSB_KEY;
+  SM_CALL_T *pCall;
+  SM_T *pSm;
+
+  if ((pFrrSmEntry =
+       FindFastRerouteSm (&pMsg->info.bypass_retry_expiry.key)) != NULL)
+    {
+      pSm = pFrrSmEntry->sm_handle;
+      if ((pOpenLspParams =
+	   XMALLOC (MTYPE_TE, sizeof (OPEN_RSVP_CRLSP))) == NULL)
+	{
+	  zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  /* Do some clean up here */
+	  return;
+	}
+      pOpenLspParams->tunnel_id = pFrrSmEntry->BypassTunnelId;
+      pOpenLspParams->ErHops2Exclude[0] = pFrrSmEntry->frr_key.protected_node;
+      pOpenLspParams->ErHops2Exclude[1] =
+	pFrrSmEntry->frr_key.prohibited_penultimate_node;
+      pOpenLspParams->dest_ip = pFrrSmEntry->frr_key.merge_node;
+      pOpenLspParams->src_ip = rdb_get_router_id ();
+      pOpenLspParams->BW = 0;
+      pOpenLspParams->Flags = RSVP_SESS_ATTRIBUTE_FLAG_SE_STYLE;
+      pOpenLspParams->SetupPriority = 4;
+      pOpenLspParams->HoldPriority = 4;
+
+      if ((pCall =
+	   lsp_sm_sync_invoke (pSm, pOpenLspParams,
+			       INGRESS_LSP_REQUEST_EVENT)) == NULL)
+	{
+	  zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+	}
+      else
+	sm_call (pCall);
+    }
+  else
+    {
+      zlog_err ("\ncannot get FRR SM entry %x %x %x %s %d",
+		pMsg->info.bypass_retry_expiry.key.merge_node,
+		pMsg->info.bypass_retry_expiry.key.OutIfIndex,
+		pMsg->info.bypass_retry_expiry.key.protected_node,
+		__FILE__, __LINE__);
+    }
+}
+
+uns32
+InformRsvpAboutFrr (PSB_KEY * PSB_KEY,
+		    V_CARD_ID to_card,
+		    uns32 to_if,
+		    uns32 NewOutIf, V_CARD_ID NewVcardId, IPV4_ADDR first_hop)
+{
+  LTCS_MSG *pMsg;
+  if ((pMsg = dmsg_create (GetLcbPtr (), LTCS_EVENT_FRR_INFO_SET)) == NULL)
+    {
+      zlog_info ("\ncannot create message %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  zlog_info ("\ninside of InformRsvpAboutFrr %x %x %x %x %x",
+	     PSB_KEY->Session.Dest,
+	     PSB_KEY->Session.TunnelId,
+	     PSB_KEY->Session.ExtTunelId,
+	     PSB_KEY->sender.Lsp_IdNet, PSB_KEY->sender.IPv4TunnelSenderNet);
+  pMsg->info.frr_data_set.PSB_KEY = *PSB_KEY;
+  pMsg->info.frr_data_set.IfIndex = to_if;
+  pMsg->info.frr_data_set.BackupOutIf = NewOutIf;
+  pMsg->info.frr_data_set.BackupVcardId = NewVcardId;
+  pMsg->info.frr_data_set.MergeNodeIp = first_hop;
+  if (svc_send_msg (pMsg, to_card, MDS_USR_CONSOLE_SVC) != E_OK)
+    {
+      zlog_info ("\nFatal: can not send mds message %s %d", __FILE__,
+		 __LINE__);
+      return E_ERR;
+    }
+  dmsg_release (pMsg);
+  return E_OK;
+}
+
+void
+FastReRouteSmDestroy (SM_T * pSm)
+{
+  sm_gen_free (pSm);
+}
+
+void
+FrrSmDump ()
+{
+  FRR_SM_ENTRY *pFrrSmEntry;
+  FRR_SM_KEY frr_key;
+  FRR_INGRESS_ENTRY *pIngressEntry;
+  FRR_LABEL_ENTRY *pLabelEntry;
+  PSB_KEY PSB_KEY;
+  unsigned int label;
+  SM_T *pSm;
+  FRR_SM_DATA *pFrrSmData;
+  COMPONENT_LINK *pComponentLink;
+
+  memset (&frr_key, 0, sizeof (FRR_SM_KEY));
+
+  while ((pFrrSmEntry =
+	  patricia_tree_getnext (&FastReRouteSmTree,
+				 (const uns8 *) &frr_key)) != NULL)
+    {
+      pSm = pFrrSmEntry->sm_handle;
+      pFrrSmData = pSm->data;
+      zlog_info
+	("\nFRR SM protected node: %x I/F %x merge node %x tunnel ID %x BypassLabel %x BypasIfIndex %x",
+	 pFrrSmEntry->frr_key.protected_node, pFrrSmEntry->frr_key.OutIfIndex,
+	 pFrrSmEntry->frr_key.merge_node, pFrrSmEntry->BypassTunnelId,
+	 pFrrSmData->BypassTunnelsLabel, pFrrSmData->BackupOutIf);
+      label = 0;
+      zlog_info ("\nNot completed Label (LSR) entries:");
+      while ((pLabelEntry =
+	      patricia_tree_getnext (&pFrrSmEntry->labels_tree,
+				     (const uns8 *) &label)) != NULL)
+	{
+	  zlog_info
+	    ("\nLabel#%x valid %x merge node label %x Out I/F %x Bypass label %x",
+	     pLabelEntry->Label,
+	     PlatformWideLabelSpace[pLabelEntry->Label -
+				    1].BackupForwardingInformation.
+	     MergeNodeLabelValid,
+	     PlatformWideLabelSpace[pLabelEntry->Label -
+				    1].BackupForwardingInformation.
+	     MergeNodeLabel,
+	     PlatformWideLabelSpace[pLabelEntry->Label -
+				    1].BackupForwardingInformation.OutIf,
+	     PlatformWideLabelSpace[pLabelEntry->Label -
+				    1].BackupForwardingInformation.
+	     BypassTunnelsLabel);
+	  label = pLabelEntry->Label;
+	}
+      memset (&PSB_KEY, 0, sizeof (PSB_KEY));
+      zlog_info ("\nNot completed Ingress entries:");
+      while ((pIngressEntry =
+	      patricia_tree_getnext (&pFrrSmEntry->ingress_tree,
+				     (const uns8 *) &PSB_KEY)) != NULL)
+	{
+	  RSVP_TUNNEL_PROPERTIES *pTunnel;
+	  RSVP_LSP_PROPERTIES *pRsvpLsp;
+	  PSB_KEY rkey;
+
+	  zlog_info ("\nDEST#%x Tunnel#%x Source#%x LSP ID#%x",
+		     pIngressEntry->PSB_KEY.Session.Dest,
+		     pIngressEntry->PSB_KEY.Session.TunnelId,
+		     pIngressEntry->PSB_KEY.Session.ExtTunelId,
+		     pIngressEntry->PSB_KEY.sender.Lsp_IdNet);
+
+	  memset (&rkey, 0, sizeof (PSB_KEY));
+	  rkey = pIngressEntry->PSB_KEY;
+	  rkey.sender.Lsp_IdNet = 0;
+	  if (FindTunnel (&rkey, &pTunnel, ALL_TRUNKS) == TRUE)
+	    {
+	      if ((pRsvpLsp =
+		   FindRsvpLspByLspId (pTunnel,
+				       pIngressEntry->PSB_KEY.sender.
+				       Lsp_IdNet)) != NULL)
+		{
+		  zlog_info
+		    ("\n Bypass label %x Merge node label valid %x Merge node label %x Out I/F %x",
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     BypassTunnelsLabel,
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     MergeNodeLabelValid,
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     MergeNodeLabel,
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     OutIf);
+		}
+	    }
+	  PSB_KEY = pIngressEntry->PSB_KEY;
+	}
+
+      if (rdb_get_component_link (((LTCS_CB *) GetLcbPtr ())->rdb_layer_handle, pFrrSmEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+				  pFrrSmEntry->frr_key.OutIfIndex,	/* SAME FOR NOW!!! */
+				  &pComponentLink) != E_OK)
+	{
+	  zlog_err ("\ncannot get component link %s %d", __FILE__, __LINE__);
+	  frr_key = pFrrSmEntry->frr_key;
+	  continue;
+	}
+      zlog_info ("\nCompleted Label (LSR) entries:");
+      while ((pLabelEntry =
+	      patricia_tree_getnext (&pComponentLink->ProtectionTree,
+				     (const uns8 *) &label)) != NULL)
+	{
+	  zlog_info
+	    ("\nLabel#%x valid %x merge node label %x Out I/F %x Bypass label %x",
+	     pLabelEntry->Label,
+	     PlatformWideLabelSpace[pLabelEntry->Label -
+				    1].BackupForwardingInformation.
+	     MergeNodeLabelValid,
+	     PlatformWideLabelSpace[pLabelEntry->Label -
+				    1].BackupForwardingInformation.
+	     MergeNodeLabel,
+	     PlatformWideLabelSpace[pLabelEntry->Label -
+				    1].BackupForwardingInformation.OutIf,
+	     PlatformWideLabelSpace[pLabelEntry->Label -
+				    1].BackupForwardingInformation.
+	     BypassTunnelsLabel);
+	  label = pLabelEntry->Label;
+	}
+      memset (&PSB_KEY, 0, sizeof (PSB_KEY));
+      zlog_info ("\nCompleted Ingress entries:");
+      while ((pIngressEntry =
+	      patricia_tree_getnext (&pComponentLink->IngressProtectionTree,
+				     (const uns8 *) &PSB_KEY)) != NULL)
+	{
+	  RSVP_TUNNEL_PROPERTIES *pTunnel;
+	  RSVP_LSP_PROPERTIES *pRsvpLsp;
+	  PSB_KEY rkey;
+
+	  zlog_info ("\nDEST#%x Tunnel#%x Source#%x LSP ID#%x",
+		     pIngressEntry->PSB_KEY.Session.Dest,
+		     pIngressEntry->PSB_KEY.Session.TunnelId,
+		     pIngressEntry->PSB_KEY.Session.ExtTunelId,
+		     pIngressEntry->PSB_KEY.sender.Lsp_IdNet);
+	  memset (&rkey, 0, sizeof (PSB_KEY));
+	  rkey = pIngressEntry->PSB_KEY;
+	  rkey.sender.Lsp_IdNet = 0;
+	  if (FindTunnel (&rkey, &pTunnel, ALL_TRUNKS) == TRUE)
+	    {
+	      if ((pRsvpLsp =
+		   FindRsvpLspByLspId (pTunnel,
+				       pIngressEntry->PSB_KEY.sender.
+				       Lsp_IdNet)) != NULL)
+		{
+		  zlog_info
+		    ("\n Bypass label %x Merge node label valid %x Merge node label %x Out I/F %x",
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     BypassTunnelsLabel,
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     MergeNodeLabelValid,
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     MergeNodeLabel,
+		     pRsvpLsp->forw_info.path.BackupForwardingInformation.
+		     OutIf);
+		}
+	    }
+	  PSB_KEY = pIngressEntry->PSB_KEY;
+	}
+      frr_key = pFrrSmEntry->frr_key;
+    }
+}
diff -Naur quagga-0.99.10/rsvpd/te_frr.h quagga-mpls/rsvpd/te_frr.h
--- quagga-0.99.10/rsvpd/te_frr.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_frr.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,52 @@
+#ifndef __FAST_REROUTE_H_
+#define __FAST_REROUTE_H_
+
+typedef enum
+{
+  FAST_REROUTE_SM_UP_STATE = INIT_STATE + 1,
+  FAST_REROUTE_RETRY_STATE,
+  FAST_REROUTE_SM_MAX_STATE
+} FAST_REROUTE_SM_STATE_E;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  unsigned int Label;
+} FRR_LABEL_ENTRY;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  PSB_KEY PsbKey;
+} FRR_INGRESS_ENTRY;
+
+typedef struct
+{
+  FRR_SM_KEY frr_key;
+  PSB_KEY PsbKey;
+  unsigned int Label;
+  IPV4_ADDR MergeNode;
+} FRR_SM_CALL;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  FRR_SM_KEY frr_key;
+  uns32 sm_handle;
+  PATRICIA_TREE labels_tree;
+  PATRICIA_TREE ingress_tree;
+  uns16 BypassTunnelId;
+  TE_TMR bypass_retry_timer;
+} FRR_SM_ENTRY;
+
+typedef struct
+{
+  FRR_SM_ENTRY FrrSmEntry;
+  unsigned int BypassTunnelsLabel;
+  uns32 BackupOutIf;
+  //V_CARD_ID    card;
+} FRR_SM_DATA;
+
+SM_CALL_T *fast_reroute_sm_handler (HANDLE sm_handle, SM_EVENT_T * sm_data);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te.h quagga-mpls/rsvpd/te.h
--- quagga-0.99.10/rsvpd/te.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,45 @@
+#ifndef _TE_INCLUDES_H_
+#define _TE_INCLUDES_H_
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+#include <sys/ioctl.h>
+#include <net/if.h>
+#include <netinet/in.h>
+#include <netinet/ip.h>
+#include <unistd.h>
+#include <time.h>
+#include <sys/time.h>
+#include <sys/file.h>
+#include <sys/fcntl.h>
+#include <sys/ioctl.h>
+#include <sys/uio.h>
+#include <ctype.h>
+#include <math.h>
+#include <errno.h>
+#include <zebra.h>
+#include "thread.h"
+#include "vty.h"
+#include "command.h"
+#include "log.h"
+#include "memory.h"
+#include "patricia.h"
+#include "zclient.h"
+
+#include "general.h"
+#include "messages.h"
+#include "rsvp_packet.h"
+#include "te_lib.h"
+#include "te_rdb.h"
+#include "te_api.h"
+#include "te_common.h"
+#include "te_lsp.h"
+#include "te_tr.h"
+#include "te_crr.h"
+#include "te_frr.h"
+#include "te_bw_man.h"
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te_lib.c quagga-mpls/rsvpd/te_lib.c
--- quagga-0.99.10/rsvpd/te_lib.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_lib.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,270 @@
+/* Module:   te_config_data_plane.c
+   Contains: TE application data plane configuration
+   functions. Called when an tunnel is established.
+   For the transit tunnels (LSR) - when corresponding
+   RESV received.
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "te.h"
+
+void
+mplsTePolicy (char *PolicyName, char *LabelEntryKey, int opcode)
+{
+}
+
+void
+mplsTeInOutLabel (unsigned int AllocatedLabel,
+		  unsigned int ReceivedLabelMapping, unsigned int OutIfIndex)
+{
+}
+
+/* A data plane configuration for the Ingress tunnels (only outgoing label) */
+void
+mplsTeOutLabel (int *OutLabels, int OutLabelsCount, char *key, int NextHop,
+		int opcode)
+{
+}
+
+/* Module:   label_man.c
+   Contains: TE application label manager
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+
+extern PATRICIA_TREE PlatformWideFreeLabels;
+extern PATRICIA_TREE LineCard2LabelsTree;
+
+LABEL_ENTRY PlatformWideLabelSpace[LABEL_SPACE_SIZE];
+
+uns32
+LabelAllocate (unsigned int *Label, LABEL_POLICY_E policy, PSB_KEY * pKey,
+	       uns32 IfIndex)
+{
+  uns8 key = 0;
+  LABEL_ENTRY *p_label_entry;
+  if ((p_label_entry = (LABEL_ENTRY *)
+       patricia_tree_getnext (&PlatformWideFreeLabels,
+			      (const uns8 *) &key)) == NULL)
+    {
+      zlog_err ("\ncannot allocate label %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if (((p_label_entry->label % 2) && (policy == EVEN_LABELS)) ||
+      ((!(p_label_entry->label % 2)) && (policy == ODD_LABELS)))
+    {
+      key = p_label_entry->label;
+      if ((p_label_entry = (LABEL_ENTRY *)
+	   patricia_tree_getnext (&PlatformWideFreeLabels,
+				  (const uns8 *) &key)) == NULL)
+	{
+	  zlog_err ("\ncannot allocate label %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+    }
+  if (patricia_tree_del (&PlatformWideFreeLabels, &p_label_entry->Node) !=
+      E_OK)
+    {
+      zlog_err ("\nfatal: cannot remove entry from patricia tree %s %d",
+		__FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  p_label_entry->IfIndex = IfIndex;	/* needed for FRR */
+
+  *Label = p_label_entry->label;
+  zlog_info ("\nLabel allocation performed: label %x \
+dest %x tunnel id %x ext tunnel id %x lsp id %x ", *Label, pKey->Session.Dest, pKey->Session.TunnelId, pKey->Session.ExtTunelId, pKey->SenderTemplate.LspId);
+  return E_OK;
+}
+
+uns32
+TE_RSVPTE_API_LabelRelease (TE_API_MSG * dmsg)
+{
+  LABEL_ENTRY *p_label_entry;
+#ifdef FRR_SM_DEFINED
+  FrrLabelRelease (dmsg->u.LabelRelease.Label);
+#endif
+  if ((dmsg->u.LabelRelease.Label <= 0)
+      || (dmsg->u.LabelRelease.Label >= LABEL_SPACE_SIZE))
+    {
+      zlog_err ("Invalid label %x %s %d", dmsg->u.LabelRelease.Label,
+		__FILE__, __LINE__);
+      return E_ERR;
+    }
+  p_label_entry = &PlatformWideLabelSpace[dmsg->u.LabelRelease.Label - 1];
+
+  if (patricia_tree_add (&PlatformWideFreeLabels, &p_label_entry->Node) !=
+      E_OK)
+    {
+      zlog_err ("\ncannot return label %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  return E_OK;
+}
+
+
+int
+LSRLabelMappingReceived (unsigned int AllocatedLabel,
+			 unsigned int ReceivedLabelMapping,
+			 unsigned int OutIfIndex)
+{
+  if ((AllocatedLabel >= LABEL_SPACE_SIZE) || (AllocatedLabel < 1))
+    {
+      zlog_err ("\ninvalid AllocatedLabel (out of range) %s %d", __FILE__,
+		__LINE__);
+      return E_ERR;
+    }
+  if (patricia_tree_get
+      (&PlatformWideFreeLabels, (const uns8 *) &AllocatedLabel) != NULL)
+    {
+      zlog_err ("\nAllocated Label is not really allocated %s %d...",
+		__FILE__, __LINE__);
+      return E_ERR;
+    }
+  PlatformWideLabelSpace[AllocatedLabel - 1].ReceivedOutLabel =
+    ReceivedLabelMapping;
+  PlatformWideLabelSpace[AllocatedLabel - 1].OutIf = OutIfIndex;
+  mplsTeInOutLabel (AllocatedLabel, ReceivedLabelMapping, OutIfIndex);
+  return E_OK;
+}
+
+void
+IngressLabelMappingReceived (unsigned int ReceivedLabelMapping,
+			     unsigned int OutIfIndex, PSB_KEY * pKey)
+{
+#if DATA_PLANE
+  {
+    char key[23];
+    IPV4_ADDR next_hop = 0;
+    RSVP_TUNNEL_PROPERTIES *pTunnel;
+    RSVP_LSP_PROPERTIES *pRsvpLsp;
+    USER_LSP *pUserLsp;
+    if (FindTunnel (pKey, &pTunnel, ALL_TRUNKS) != TRUE)
+      {
+	return;
+      }
+    pUserLsp = UserLspGet (pTunnel->UserLspName);
+    if ((pUserLsp) && (pUserLsp->pUserLspTunnels == NULL))
+      {
+	return;
+      }
+/* commented in order to configure the label of the backup LSP in the data plane 
+        if((pUserLsp->pUserLspTunnels->TunnelId != pTunnel->TunnelId)&&
+           (pUserLsp->BackupTunnelId != pTunnel->TunnelId))
+        {
+            return;
+        }*/
+    if ((pRsvpLsp = GetWorkingRsvpLsp (pTunnel)) == NULL)
+      {
+	return;
+      }
+    if ((pRsvpLsp->tunneled == FALSE)
+	&& (pRsvpLsp->forw_info.path.HopCount != 0))
+      {
+	next_hop = pRsvpLsp->forw_info.path.pErHopsList[0];
+      }
+    sprintf (key, "%x%d%x%d", pKey->Session.Dest, pTunnel->TunnelId,
+	     pKey->Session.ExtTunelId, pRsvpLsp->LspId);
+    zlog_info ("create label %x next hop %x \nkey %s\nUserLspName %s\n",
+	       pRsvpLsp->Label, next_hop, key, pTunnel->UserLspName);
+    mplsTeOutLabel (&pRsvpLsp->Label, 1, key, next_hop, 1);
+    if ((pUserLsp != NULL) && (pUserLsp->params.PolicyName[0] != '\0'))
+      {
+	if ((pUserLsp->pUserLspTunnels->TunnelId == pTunnel->TunnelId) &&
+	    (pUserLsp->BackupTunnelId))
+	  {
+	    char key1[23];
+	    PSB_KEY PsbKey;
+
+	    memset (&PsbKey, 0, sizeof (PSB_KEY));
+	    PsbKey.Session.Dest = pKey->Session.Dest;
+	    PsbKey.Session.ExtTunelId = pKey->Session.ExtTunelId;
+	    PsbKey.Session.TunnelId = pUserLsp->BackupTunnelId;
+	    if (FindTunnel (&PsbKey, &pTunnel, ALL_TRUNKS) != TRUE)
+	      {
+		return;
+	      }
+	    if ((pRsvpLsp = GetWorkingRsvpLsp (pTunnel)) == NULL)
+	      {
+		return;
+	      }
+	    sprintf (key1, "%x%d%x%d", pKey->Session.Dest, pTunnel->TunnelId,
+		     pKey->Session.ExtTunelId, pRsvpLsp->LspId);
+	    mplsTePolicy (pUserLsp->params.PolicyName, key1, 0);
+	    pUserLsp->BackupTunnelId = 0;
+	  }
+	zlog_info ("PolicyName %s", pUserLsp->params.PolicyName);
+	mplsTePolicy (pUserLsp->params.PolicyName, key, 1);
+      }
+  }
+#endif
+  return;
+}
+
+void
+AssignedLabelsDump ()
+{
+  uns32 key = 0, i;
+  LABEL_ENTRY *p_label_entry;
+  for (i = 0; i < LABEL_SPACE_SIZE; i++)
+    {
+      key = i + 1;
+      if ((p_label_entry = (LABEL_ENTRY *)
+	   patricia_tree_get (&PlatformWideFreeLabels,
+			      (const uns8 *) &key)) != NULL)
+	zlog_info ("\nlabel %x", p_label_entry->label);
+    }
+  return;
+}
+
+
+/* Module:   lsr.c
+   Contains: TE application transit RESV message processing
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+
+
+
+void
+TE_RSVPTE_API_TransitResv (TE_API_MSG * dmsg)
+{
+  PSB_KEY key;
+  int i;
+  float MaximumPossibleBW = 0;
+  memset (&key, 0, sizeof (PSB_KEY));
+  key.Session = dmsg->u.ResvNotification.RsbKey.Session;
+  if (TE_RSVPTE_API_DoAllocation (&key,
+				  dmsg->u.ResvNotification.u.FilterDataSE.
+				  IfIndex /* temporary */ ,
+				  dmsg->u.ResvNotification.u.FilterDataSE.
+				  IfIndex,
+				  dmsg->u.ResvNotification.u.FilterDataSE.BW,
+				  dmsg->u.ResvNotification.u.FilterDataSE.
+				  SetupPrio,
+				  dmsg->u.ResvNotification.u.FilterDataSE.
+				  HoldPrio, &MaximumPossibleBW) != E_OK)
+    {
+      zlog_info ("\nBW allocation failed %s %d", __FILE__, __LINE__);
+      dmsg->u.ResvNotification.u.FilterDataSE.BW = MaximumPossibleBW;
+      dmsg->u.ResvNotification.rc = FALSE;
+    }
+  else
+    {
+      zlog_info ("BW allocation succeeded. Updating LSR's table...");
+      for (i = 0;
+	   i < dmsg->u.ResvNotification.u.FilterDataSE.FilterSpecNumber; i++)
+	{
+	  if (LSRLabelMappingReceived
+	      (dmsg->u.ResvNotification.u.FilterDataSE.FilterDataArraySE[i].
+	       AllocatedLabel,
+	       dmsg->u.ResvNotification.u.FilterDataSE.FilterDataArraySE[i].
+	       ReceivedLabel,
+	       dmsg->u.ResvNotification.u.FilterDataSE.IfIndex) != E_OK)
+	    {
+	    }
+	}
+      dmsg->u.ResvNotification.rc = TRUE;
+    }
+  zlog_info ("Sending reply to TE");
+  rsvp_send_msg (dmsg, sizeof (TE_API_MSG));
+  return;
+}
diff -Naur quagga-0.99.10/rsvpd/te_lib.h quagga-mpls/rsvpd/te_lib.h
--- quagga-0.99.10/rsvpd/te_lib.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_lib.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,44 @@
+#ifndef __TE_CONFIG_DATA_PLANE_H_
+#define __TE_CONFIG_DATA_PLANE_H_
+
+void mplsTePolicy (char *PolicyName, char *LabelEntryKey, int opcode);
+void mplsTeInOutLabel (unsigned int AllocatedLabel,
+		       unsigned int ReceivedLabelMapping,
+		       unsigned int OutIfIndex);
+void mplsTeOutLabel (int *OutLabels, int OutLabelsCount, char *key,
+		     int NextHop, int opcode);
+
+#endif
+
+#ifndef __LABEL_MAN_H_
+#define __LABEL_MAN_H_
+
+
+typedef enum
+{
+  ODD_LABELS,
+  EVEN_LABELS,
+  ALL_LABELS,
+  MAX_LABELS
+} LABEL_POLICY_E;
+
+#define LABEL_SPACE_SIZE  0x2000
+
+uns32 TE_RSVPTE_API_LabelRelease (TE_API_MSG * dmsg);
+uns32 LabelAllocate (unsigned int *Label,
+		     LABEL_POLICY_E policy, PSB_KEY * pKey, uns32 IfIndex);
+void IngressLabelMappingReceived (unsigned int ReceivedLabelMapping,
+				  unsigned int OutIfIndex, PSB_KEY * pKey);
+
+int LSRLabelMappingReceived (unsigned int AllocatedLabel,
+			     unsigned int ReceivedLabelMapping,
+			     unsigned int OutIfIndex);
+
+#endif
+
+#ifndef __LSR_H__
+#define __LSR_H__
+
+void TE_RSVPTE_API_TransitResv (TE_API_MSG * dmsg);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te_lsp.c quagga-mpls/rsvpd/te_lsp.c
--- quagga-0.99.10/rsvpd/te_lsp.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_lsp.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,4372 @@
+/* Module:   lsp_sm.c
+   Contains: TE application LSP (tunnel) state machine
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "te.h"
+#include "te_cspf.h"
+
+typedef enum
+{
+    WORKING_LSP_FAILED,
+    NEW_LSP_FAILED
+}RECOVERY_TYPE_E;
+
+void LspSmDestroy(SM_T *pSm);
+void UserLspDestroy(USER_LSP *pUserLsp);
+E_RC SetErHopList(STATIC_PATH *pStaticPath,ER_HOP **ppErHopsList);
+SM_CALL_T *ProcessPrimaryLsp(USER_LSP *pCurrentUserLsp,
+                             USER_LSP *pUserLsp,
+                             SM_T *pSm,
+                             char *PrimaryLspPathName);
+RSVP_TUNNEL_PROPERTIES *GetSecondaryTunnel2Reroute(USER_LSP *pUserLsp,
+                                                   USER_LSP *pCurrentUserLsp);
+SM_CALL_T *ProcessSecondaryPaths(USER_LSP *pCurrentUserLsp,
+                                 USER_LSP *pUserLsp,
+                                 SM_T *pSm,
+                                 char *PrimaryLspPathName,
+                                 BOOL PrimaryLspOperation);
+uns32 StartAdaptivityTimer(uns32 optimize_timer,
+                           RSVP_TUNNEL_PROPERTIES *pTunnel);
+
+void StopAdaptivityTimer(RSVP_TUNNEL_PROPERTIES *pTunnel);
+uns32 StartLspSetupTimer(RSVP_TUNNEL_PROPERTIES *pTunnel);
+void StopLspSetupTimer(RSVP_TUNNEL_PROPERTIES *pTunnel);
+uns32 StartLspSetupRetryTimer(uns32 retry_timer,uns32 *retry_count,RSVP_TUNNEL_PROPERTIES *pTunnel);
+void StopLspSetupRetryTimer(RSVP_TUNNEL_PROPERTIES *pTunnel);
+SM_CALL_T *LspSetupExpiry(PSB_KEY *PsbKey,SM_T *pSm);
+SM_CALL_T *AdaptivityExpiry(PSB_KEY *PsbKey,SM_T *pSm);
+SM_CALL_T *LspSetupRetryExpiry(PSB_KEY *PsbKey,SM_T *pSm);
+SM_CALL_T *CspfRetryExpiry(PSB_KEY *PsbKey,SM_T *pSm);
+void TearDownAndRemoveSecondary(USER_LSP *pCurrentUserLsp,char *PathName);
+void CalculateUnneededPathAndTearDown(USER_LSP *pUserLsp,USER_LSP *pCurrentUserLsp);
+SM_CALL_T *PrepareAndIssueCrResolutionRequest(INGRESS_API *pOpenLspParams,
+                                              uns32       AvoidHopNumber,
+                                              IPV4_ADDR    *AvoidHopsArray,
+                                              RSVP_TUNNEL_PROPERTIES *pTunnel,
+                                              SM_T *pSm,
+                                              LSP_PATH_SHARED_PARAMS *pParams);
+SM_CALL_T *LspRequest(INGRESS_API *pOpenLspParams,
+                      uns32       ExcludeHopNumber,
+                      IPV4_ADDR   *ExcludeHopsArray,
+                      SM_T    *pSm,
+                      RSVP_TUNNEL_PROPERTIES **ppTunnel,
+                      BOOL        ForceCrResolution,
+                      LSP_PATH_SHARED_PARAMS *pParams);
+
+BOOL NewRsvpLspRequired(RSVP_TUNNEL_PROPERTIES *pTunnel,INGRESS_API *pOpenLspParams);
+RSVP_LSP_PROPERTIES *FindRsvpLspPathWithBW(RSVP_TUNNEL_PROPERTIES *pTunnel,float BW);
+void NotifySatisfiedRequests(RSVP_TUNNEL_PROPERTIES *pTunnel);
+void NotifyFailedRequests(RSVP_TUNNEL_PROPERTIES *pTunnel);
+uns16 NewRsvpLspId(RSVP_TUNNEL_PROPERTIES *pTunnel);
+uns32 CopyRsvpLspPath(RSVP_LSP_PROPERTIES *pRsvpLsp,INGRESS_API *pOpenRsvpLsp);
+RSVP_LSP_PROPERTIES *GetWorkingRsvpLsp(RSVP_TUNNEL_PROPERTIES *pTunnel);
+uns32 CopyWorkingPath(RSVP_LSP_PROPERTIES *pDestRsvpLsp,RSVP_LSP_PROPERTIES *pSourceRsvpLsp);
+BOOL IdenticalRsvpLspExists(RSVP_TUNNEL_PROPERTIES *pTunnel,RSVP_LSP_PROPERTIES *pThisRsvpLsp,uns16 *LspDiffPathSameParams);
+void UpdatePathBW(RSVP_TUNNEL_PROPERTIES *pTunnel,RSVP_LSP_PROPERTIES *pCurrentRsvpLsp,IPV4_ADDR dest);
+uns32 CreateAndInvokeRsvpLsp(RSVP_TUNNEL_PROPERTIES *pTunnel,
+                             RSVP_LSP_PROPERTIES *pRsvpLsp2TakePath,
+                             BOOL tunneled,
+                             PSB_KEY *PsbKey);
+uns32 RsvpTunnelTearDown(RSVP_TUNNEL_PROPERTIES *pTunnel,IPV4_ADDR dest,IPV4_ADDR source);
+void RemoveRsvpLsp(RSVP_TUNNEL_PROPERTIES *pTunnel,uns16 LspId,IPV4_ADDR dest,IPV4_ADDR source);
+RSVP_LSP_PROPERTIES *FindRsvpLspByLspId(RSVP_TUNNEL_PROPERTIES *pTunnel,uns16 LspId);
+void FindClosestRsvpLsp(RSVP_TUNNEL_PROPERTIES *pTunnel,
+                        SETUP_COMPLETE *setup_complete,
+                        float *BW,
+                        uns16 *LspId);
+SM_CALL_T *DetermineWorkingLspAndTearUnneeded(RSVP_TUNNEL_PROPERTIES *pTunnel,
+                                              float BW,
+                                              uns16 LspId,
+                                              IPV4_ADDR dest,
+                                              IPV4_ADDR source,
+                                              SM_T *pSm);
+RSVP_LSP_PROPERTIES *GetRsvpLspMaxBW(RSVP_TUNNEL_PROPERTIES *pTunnel,uns16 LspId,float MaxBw);
+IPV4_ADDR GetLastErHop(RSVP_LSP_PROPERTIES *pRsvpLsp);
+BOOL IsPathEqual(PATH *pPath,IPV4_ADDR *IpAddrList);
+PATH *FindRsvpLspPath(PATH_L_LIST *pPaths,RSVP_LSP_PROPERTIES *pRsvpLsp);
+uns16 GetSecondaryUserLspId(RSVP_TUNNEL_PROPERTIES *pTunnel,char *pSecondaryPathName);
+uns32 AddSecondaryTunnel(USER_LSP *pUserLsp,RSVP_TUNNEL_PROPERTIES *pSecondaryTunnel);
+void CleanSecodaryPaths(USER_LSP *pUserLsp);
+void CleanUserLsp(USER_LSP *pUserLsp);
+void CopyUserLsp(USER_LSP *pDestLsp,USER_LSP *pSrcLsp);
+LSP_PATH_SHARED_PARAMS *PathParamsGet(USER_LSP *pUserLsp,char *PathName,uns8 IsPrimary);
+RSVP_TUNNEL_PROPERTIES *StaticPathIsUsed(USER_LSP *pUserLsp,char *PathName);
+SM_CALL_T *UserPrimaryLspRecovery(RSVP_TUNNEL_PROPERTIES *pTunnel,SM_T *pSm,RECOVERY_TYPE_E recovery_type,IPV4_ADDR exclude_node);
+SM_CALL_T *UserSecondaryLspRecovery(RSVP_TUNNEL_PROPERTIES *pTunnel,SM_T *pSm,IPV4_ADDR exclude_node);
+SM_CALL_T *UserLspFailed(RSVP_TUNNEL_PROPERTIES *pTunnel,SM_T *pSm,IPV4_ADDR exclude_node);
+uns32 GetTunnelHops(RSVP_TUNNEL_PROPERTIES *pTunnel,uns32 *ErHopNumber,IPV4_ADDR **ppErHops);
+BOOL TunnelsHaveSharedErHops(IPV4_ADDR *pFirstArray,
+                             uns32 FirstArraySize,
+                             IPV4_ADDR *pSecondArray,
+                             uns32 SecondArraySize);
+SM_CALL_T *ModifySecondary(RSVP_TUNNEL_PROPERTIES *pTunnel,
+                           SM_T *pSm,
+                           STATIC_PATH *pPrimaryStaticPath,
+                           USER_LSP *pUserLsp);
+SM_CALL_T *OptimizeSingleLsp(RSVP_TUNNEL_PROPERTIES *pTunnel,IPV4_ADDR dest,IPV4_ADDR source);
+static void StopCspfRetryTimer(RSVP_TUNNEL_PROPERTIES *pTunnel);
+static E_RC GetAlreadyAllocatedBW(RSVP_TUNNEL_PROPERTIES *pTunnel,void **ppLinkBw,uns32 *LinkBwNumber,float CommonBwValue);
+
+int LspSetupTimeOut = 30;
+
+static SM_CALL_T *lsp_sm_empty_handler(SM_T *pSm,SM_EVENT_T *sm_data)
+{
+    zlog_err("lsp_sm_empty_handler, state %d",pSm->state);
+    return NULL;
+}
+
+static SM_CALL_T *lsp_sm_init(SM_T *pSm,SM_EVENT_T *sm_event)
+{
+    SM_CALL_T *pCall = NULL;
+    RSVP_TUNNEL_PROPERTIES *pTunnel = NULL;
+    PSB_KEY PsbKey;
+    INGRESS_API *pOpenLspParams = NULL;
+    USER_LSP *pUserLsp,*pCurrentUserLsp;
+    LSP_SM_DATA *pLspSmData;
+    CONSTRAINT_ROUTE_RESOLUTION_ARGS *pCrArgs;
+    LSP_SM_NOTIF_DATA *pLspSmNotifData;
+    uns16 LspId = 0;
+    float BW = 0;
+    int i;
+    char PrimaryLspPathName[16];
+    
+    pLspSmData = pSm->data;
+
+    switch(sm_event->event)
+    {
+    case USER_LSP_REQUEST_EVENT:
+        sm_gen_event_trace(sm_event->event);
+        pUserLsp = sm_event->data;
+        if((pCurrentUserLsp = UserLspGet(pUserLsp->params.LspName)) == NULL)
+        {
+            if(pUserLsp->params.to == 0)
+            {
+                zlog_err("LSP's destination cannot be 0 %s %d",__FILE__,__LINE__);
+                CleanSecodaryPaths(pUserLsp);
+                CleanUserLsp(pUserLsp);
+                XFREE(MTYPE_TE,pUserLsp);
+                return NULL;
+            }
+            if(pUserLsp->params.lsp_params.disable == TRUE)
+            {
+                zlog_err("User LSP to be deleted is not found! %s %d",__FILE__,__LINE__);
+                CleanSecodaryPaths(pUserLsp);
+                CleanUserLsp(pUserLsp);
+                XFREE(MTYPE_TE,pUserLsp);
+                return NULL;
+            }
+            if(UserLspAdd(pUserLsp) != E_OK)
+            {
+                zlog_err("cannot add user LSP %s %d",__FILE__,__LINE__);
+                return NULL;
+            }
+            pCurrentUserLsp = pUserLsp;
+        }
+        if(pUserLsp->params.lsp_params.disable == TRUE)
+        {
+            UserLspDestroy(pCurrentUserLsp);
+            zlog_info("Cleaning up the UserLsp memory");
+            if(pCurrentUserLsp != pUserLsp)
+            {
+                if(UserLspDelete(pCurrentUserLsp->params.LspName) != E_OK)
+                {
+                    zlog_err(
+                           "A problem occured while deleting an User LSP %s %d",__FILE__,__LINE__);
+                }
+            }
+            CleanSecodaryPaths(pUserLsp);
+            CleanUserLsp(pUserLsp);
+            XFREE(MTYPE_TE,pUserLsp);
+            LspSmDestroy(pSm);
+            return NULL;
+        }
+        pUserLsp->params.to = pCurrentUserLsp->params.to;
+        if(pUserLsp != pCurrentUserLsp)
+            CalculateUnneededPathAndTearDown(pUserLsp,pCurrentUserLsp);
+        
+        pCall = ProcessPrimaryLsp(pCurrentUserLsp,pUserLsp,pSm,PrimaryLspPathName);
+        
+        ProcessSecondaryPaths(pCurrentUserLsp,
+                              pUserLsp,
+                              pSm,
+                              PrimaryLspPathName,
+                              (pCall == NULL) ? FALSE : TRUE);
+        zlog_info(
+            "After secondary %s %s %s",
+             PrimaryLspPathName,pCurrentUserLsp->params.Primary,pUserLsp->params.Primary);
+        if(pCurrentUserLsp != pUserLsp)
+        {
+            if((pUserLsp->params.retry_timer != pCurrentUserLsp->params.retry_timer)||
+               (pUserLsp->params.retry_limit != pCurrentUserLsp->params.retry_limit))
+            {
+               pCurrentUserLsp->params.retry_count = pUserLsp->params.retry_limit;
+               if(pCurrentUserLsp->pUserLspTunnels != NULL)
+               {
+                  StartLspSetupRetryTimer(pUserLsp->params.retry_timer,
+                                          &pCurrentUserLsp->params.retry_count,
+                                          pCurrentUserLsp->pUserLspTunnels);
+               }
+            }
+            CopyUserLsp(pCurrentUserLsp,pUserLsp);
+            XFREE(MTYPE_TE,pUserLsp);
+        }
+        break;
+    case INGRESS_LSP_REQUEST_EVENT:
+        sm_gen_event_trace(sm_event->event);
+        pOpenLspParams = sm_event->data;
+        pCall = LspRequest(pOpenLspParams,0,NULL,pSm,&pTunnel,FALSE,NULL);
+        break;
+    case INGRESS_LSP_DELETE_REQUEST_EVENT:
+        sm_gen_event_trace(sm_event->event);
+        memset(&PsbKey,0,sizeof(PSB_KEY));
+        pOpenLspParams = sm_event->data;
+        PsbKey.Session.Dest = pOpenLspParams->Egress;
+        PsbKey.Session.TunnelId = pOpenLspParams->TunnelId;
+        PsbKey.Session.ExtTunelId = pOpenLspParams->src_ip;
+        pOpenLspParams->BW = 0;
+        if(FindTunnel(&PsbKey,&pTunnel,ALL_TRUNKS) == TRUE)
+        {
+            if(RsvpTunnelTearDown(pTunnel,pOpenLspParams->Egress,pOpenLspParams->src_ip) != E_OK)
+            {
+                zlog_err("can not complete RSVP tunnel tear down %s %d",__FILE__,__LINE__);
+            }
+            XFREE(MTYPE_TE,pOpenLspParams);
+        }
+        else
+            zlog_err("Required RSVP tunnel is not found!!! %s %d",__FILE__,__LINE__);
+        /*LspSmDestroy(pSm);*/
+        break;
+    case LSP_SETUP_TIMER_EXPIRY:
+        sm_gen_event_trace(sm_event->event);
+        pCall = LspSetupExpiry(sm_event->data,pSm);
+        break;
+    case ADAPTIVITY_TIMER_EXPIRY:
+        pCall = AdaptivityExpiry(sm_event->data,pSm);
+        break;
+    case RETRY_TIMER_EXPIRY:
+        sm_gen_event_trace(sm_event->event);
+        pCall = LspSetupRetryExpiry(sm_event->data,pSm);
+        break;
+    case CSPF_RETRY_EVENT:
+        sm_gen_event_trace(sm_event->event);
+        pCall = CspfRetryExpiry(sm_event->data,pSm);
+        break;
+    case CONSTRAINT_ROUTE_RESOLVED_EVENT:
+        sm_gen_event_trace(sm_event->event);
+
+        pCrArgs = sm_event->data;
+
+        if(FindTunnel(&pCrArgs->PsbKey,&pTunnel,ALL_TRUNKS) != TRUE)
+        {
+            zlog_err("cannot find tunnel Dest %x Tunnel %x %s %d",
+                pCrArgs->PsbKey.Session.Dest,
+                pCrArgs->PsbKey.Session.TunnelId,
+                __FILE__,__LINE__);
+            XFREE(MTYPE_TE,pCrArgs);
+            return NULL;
+        }
+        if((pCrArgs->tunneled == FALSE)&&
+           (pCrArgs->data.path.pErHop != NULL)&&
+           (pCrArgs->data.path.ErHopNumber != 0))
+        {                                                                                
+            int i;
+            zlog_info("Not tunneled, with path");
+                              
+            zlog_info("Insertion of returned ER hops...");
+            for(i = 0;i < pCrArgs->data.path.ErHopNumber;i++)
+            {
+                ((INGRESS_API *)(pTunnel->pOpenLspParams))->Path[i].IpAddr = pCrArgs->data.path.pErHop[i];
+                ((INGRESS_API *)(pTunnel->pOpenLspParams))->Path[i].PrefixLength = 32;
+            }
+            zlog_info("Insertion of received %d ER hops...",pCrArgs->data.path.ErHopNumber);
+            for(i = pCrArgs->data.path.ErHopNumber;
+                i < (((INGRESS_API *)(pTunnel->pOpenLspParams))->HopNum + pCrArgs->data.path.ErHopNumber);
+                i++)
+            {
+                ((INGRESS_API *)(pTunnel->pOpenLspParams))->Path[i].IpAddr
+                    = ((INGRESS_API *)(pTunnel->pOpenLspParams))->Path[i - pCrArgs->data.path.ErHopNumber].IpAddr;
+                ((INGRESS_API *)(pTunnel->pOpenLspParams))->Path[i].PrefixLength = 32;
+            }
+            zlog_info("Done...");
+            ((INGRESS_API *)(pTunnel->pOpenLspParams))->HopNum += pCrArgs->data.path.ErHopNumber;
+        }
+        else if(pCrArgs->tunneled == TRUE)
+        {
+            /*pRequest->pOpenLspParams*/
+        }
+        zlog_info("NextHop %x %s %d",pCrArgs->OutNHop,__FILE__,__LINE__);
+        ((INGRESS_API *)(pTunnel->pOpenLspParams))->OutIfIndex = pCrArgs->OutIf;
+        ((INGRESS_API *)(pTunnel->pOpenLspParams))->NextHop = pCrArgs->OutNHop;
+        if(CreateAndInvokeRsvpLsp(pTunnel,
+                                  NULL,
+                                  pCrArgs->tunneled,
+                                  (pCrArgs->tunneled == TRUE) ?
+                                  &pCrArgs->data.tunnel : NULL) != E_OK)
+        {
+            zlog_err("cannot copy path for RSVP LSP %s %d",__FILE__,__LINE__);
+            LspSmDestroy(pSm);
+            return NULL;
+        }
+        if((pCrArgs->tunneled == FALSE)&&
+           (pCrArgs->data.path.ErHopNumber != 0))
+        {
+            XFREE(MTYPE_TE,pCrArgs->data.path.pErHop);
+        }
+        if(pCrArgs->AvoidHopNumber != 0)
+        {
+            XFREE(MTYPE_TE,pCrArgs->AvoidHopsArray);
+        }
+        if(pCrArgs->ExcludeHopNumber != 0)
+        {
+            XFREE(MTYPE_TE,pCrArgs->ExcludeHopsArray);
+        }
+        if(pCrArgs->LinkBwNumber)
+        {
+            XFREE(MTYPE_TE,pCrArgs->pLinkBw);
+            pCrArgs->pLinkBw = NULL;
+            pCrArgs->LinkBwNumber = 0;
+        }
+        XFREE(MTYPE_TE,pCrArgs);
+        pTunnel->pCrArgs = NULL;
+        StopCspfRetryTimer(pTunnel);
+//        return NULL;
+        break;
+    case CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT:
+        sm_gen_event_trace(sm_event->event);
+        break;
+    case MPLS_SIGNALING_INGRESS_ESTABLISHED_NOTIFICATION_EVENT:
+        sm_gen_event_trace(sm_event->event);
+                
+        pLspSmNotifData = sm_event->data;
+       
+        if(FindTunnel(&pLspSmNotifData->PsbKey,&pTunnel,ALL_TRUNKS) != TRUE)
+        {
+            zlog_err("cannot find tunnel Dest %x Tunnel %x %s %d",
+                pLspSmNotifData->PsbKey.Session.Dest,
+                pLspSmNotifData->PsbKey.Session.TunnelId,
+                __FILE__,__LINE__);
+            XFREE(MTYPE_TE,pLspSmNotifData);
+            return NULL;
+        }
+
+        StopLspSetupTimer(pTunnel);
+
+        if((pTunnel->properties != NULL)&&
+            (pTunnel->properties->next == NULL)&&
+            (pTunnel->properties->LspId == pTunnel->LspId))
+        {
+            if(pLspSmNotifData->data.setup_complete.pLspLabel)
+            {
+                XFREE(MTYPE_TE,pLspSmNotifData->data.setup_complete.pLspLabel);
+            }
+            XFREE(MTYPE_TE,pLspSmNotifData);
+            return NULL;
+        }
+        
+        FindClosestRsvpLsp(pTunnel,&pLspSmNotifData->data.setup_complete,&BW,&LspId);
+
+        pCall = DetermineWorkingLspAndTearUnneeded(pTunnel,
+                                                   BW,
+                                                   LspId,
+                                                   pLspSmNotifData->PsbKey.Session.Dest,
+                                                   pLspSmNotifData->PsbKey.Session.ExtTunelId,
+                                                   pSm);
+
+                                
+        pUserLsp = UserLspGet(pTunnel->UserLspName);
+        if((pUserLsp != NULL)&&(pUserLsp->pUserLspTunnels != NULL)&&
+            (pTunnel->TunnelId == pUserLsp->pUserLspTunnels->TunnelId))
+        {
+            if(strcmp(pTunnel->StaticPathName,pUserLsp->params.Primary) == 0)
+            {
+                if(strcmp(pUserLsp->CurrentSecondaryPathName,"") != 0)
+                {
+                    zlog_info("Current Secondary Path Name %s Primary Path Name %s",
+                        pUserLsp->CurrentSecondaryPathName,pUserLsp->params.Primary);
+                    pUserLsp->CurrentSecondaryPathName[0] = '\0';
+                    
+                    if(pUserLsp->params.retry_count != pUserLsp->params.retry_limit)
+                        pUserLsp->params.retry_count = pUserLsp->params.retry_limit;
+                    StopLspSetupRetryTimer(pTunnel);
+                }
+            }
+        }
+        
+        if(pLspSmNotifData->data.setup_complete.pLspLabel)
+        {
+            XFREE(MTYPE_TE,pLspSmNotifData->data.setup_complete.pLspLabel);
+        }
+        XFREE(MTYPE_TE,pLspSmNotifData);
+                
+        NotifySatisfiedRequests(pTunnel);
+        break;
+    case MPLS_SIGNALING_INGRESS_FAILED_NOTIFICATION_EVENT:
+        sm_gen_event_trace(sm_event->event);
+         
+        pLspSmNotifData = sm_event->data;
+
+        if(FindTunnel(&pLspSmNotifData->PsbKey,&pTunnel,ALL_TRUNKS) != TRUE)
+        {
+            zlog_err("cannot find tunnel Dest %x Tunnel %x %s %d",
+                pLspSmNotifData->PsbKey.Session.Dest,
+                pLspSmNotifData->PsbKey.Session.TunnelId,
+                __FILE__,__LINE__);
+            XFREE(MTYPE_TE,pLspSmNotifData);
+            return NULL;
+        }
+        
+        switch(pLspSmNotifData->ingress_lsp_notif)
+        {
+        case SETUP_FAILED_NOTIF:
+            RemoveRsvpLsp(pTunnel,
+                          pLspSmNotifData->data.setup_failed.LspId,
+                          pLspSmNotifData->PsbKey.Session.Dest,
+                          pLspSmNotifData->PsbKey.Session.ExtTunelId);
+            break;
+        case TEAR_DOWN_NOTIF:
+            if(pLspSmNotifData->data.tunnel_down.NumberOfItems == 1)
+            {
+                RemoveRsvpLsp(pTunnel,
+                              pLspSmNotifData->data.tunnel_down.Lsps.LspId,
+                              pLspSmNotifData->PsbKey.Session.Dest,
+                              pLspSmNotifData->PsbKey.Session.ExtTunelId);
+            }
+            else
+            {
+                for(i = 0;i < pLspSmNotifData->data.tunnel_down.NumberOfItems;i++)
+                {            
+                    RemoveRsvpLsp(pTunnel,
+                                  pLspSmNotifData->data.tunnel_down.Lsps.pLsps[i],
+                                  pLspSmNotifData->PsbKey.Session.Dest,
+                                  pLspSmNotifData->PsbKey.Session.ExtTunelId);
+                }
+            }
+            break;
+        default:
+            zlog_err("default case %s %d",__FILE__,__LINE__);
+        }
+        if(pTunnel->UserLspName[0] != '\0')
+        {
+            IPV4_ADDR exclude_node = 0;
+            if(pLspSmNotifData->ingress_lsp_notif == SETUP_FAILED_NOTIF)
+            {
+               exclude_node = pLspSmNotifData->data.setup_failed.IpAddr;
+               rdb_remote_link_router_id_get(pLspSmNotifData->data.setup_failed.IpAddr,
+                                                  &exclude_node);
+            }
+            pCall = UserLspFailed(pTunnel,pSm,exclude_node);
+        }
+        else
+        {
+            NotifyFailedRequests(pTunnel);
+        }
+        XFREE(MTYPE_TE,pLspSmNotifData); /* new!!! */
+        break;
+    default:
+        zlog_err("unexpected event %d %s %d",
+            sm_event->event,
+            __FILE__,
+            __LINE__);
+        LspSmDestroy(pSm);
+    }
+    return pCall;
+}
+
+static SM_CALL_T* (*lsp_sm_event_handler[LSP_SM_MAX_STATE])(SM_T *pSm,SM_EVENT_T *sm_data) = 
+{
+    lsp_sm_empty_handler,
+    lsp_sm_init
+};
+
+SM_CALL_T *lsp_sm_handler(SM_T *pSm,SM_EVENT_T *sm_data)
+{
+    if(sm_data == NULL)
+    {
+        zlog_err("fatal: sm_data is NULL %s %d",__FILE__,__LINE__);
+        LspSmDestroy(pSm);
+        return NULL;
+    }
+    if((pSm->state < INIT_STATE)||(pSm->state >= LSP_SM_MAX_STATE))
+    {
+        LspSmDestroy(pSm);
+        return NULL;
+    }
+    return lsp_sm_event_handler[pSm->state](pSm,sm_data);
+}
+
+SM_CALL_T *lsp_sm_sync_invoke(SM_T *caller,void *data,SM_EVENT_E event)
+{
+    SM_T *pNewSm;
+    SM_CALL_T *pEvent = NULL;
+    LSP_SM_DATA *pLspSmData = NULL;
+    PSB_KEY PsbKey;
+    RSVP_TUNNEL_PROPERTIES *pTunnel;
+    INGRESS_API *pOpenLspParams;
+    USER_LSP        *pUserLsp;
+
+    memset(&PsbKey,0,sizeof(PSB_KEY));
+
+    if(event == USER_LSP_REQUEST_EVENT)
+    {
+        zlog_info("%s %d",__FILE__,__LINE__);
+        pUserLsp = data;
+        PsbKey.Session.Dest        = pUserLsp->params.to;
+        PsbKey.Session.TunnelId         = GetPimaryTunnelId(pUserLsp->params.LspName);
+        PsbKey.Session.ExtTunelId = pUserLsp->params.from;
+        zlog_info("%s %d",__FILE__,__LINE__);
+    }
+    else
+    {
+        pOpenLspParams = data;
+        pOpenLspParams->sm_handle = (uns32)caller;
+        PsbKey.Session.Dest = pOpenLspParams->Egress;
+        PsbKey.Session.TunnelId = pOpenLspParams->TunnelId;
+        PsbKey.Session.ExtTunelId = pOpenLspParams->src_ip;
+    }
+
+    if(FindTunnel(&PsbKey,&pTunnel,ALL_TRUNKS) != TRUE)
+    {
+        zlog_info("%s %d",__FILE__,__LINE__);
+        pNewSm = sm_gen_alloc(0,LSP_SM);
+        if(pNewSm == NULL)
+        {
+            zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+            return NULL;
+        }
+        if((pLspSmData = (LSP_SM_DATA *)XMALLOC(MTYPE_TE,sizeof(LSP_SM_DATA))) == NULL)
+        {
+            zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+            sm_gen_free(pNewSm);
+            return NULL;
+        }
+        pNewSm->data = pLspSmData;
+    }
+    else if(pTunnel->sm_handle == 0)
+    {
+        zlog_info("%s %d",__FILE__,__LINE__);
+        pNewSm = sm_gen_alloc(0,LSP_SM);
+        if(pNewSm == NULL)
+        {
+            zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+            return NULL;
+        }
+
+        if((pLspSmData = (LSP_SM_DATA *)XMALLOC(MTYPE_TE,sizeof(LSP_SM_DATA))) == NULL)
+        {
+            zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+            sm_gen_free(pNewSm);
+            return NULL;
+        }
+        pNewSm->data = pLspSmData;
+    }
+    else
+    {
+        zlog_info("%s %d",__FILE__,__LINE__);
+        pNewSm = (SM_T *)pTunnel->sm_handle;
+    }
+    zlog_info("%s %d",__FILE__,__LINE__);
+    if((pEvent = sm_gen_sync_event_send(pNewSm,event,data)) == NULL)
+    { 
+        zlog_err("\ncan not invoke sm %s %d",__FILE__,__LINE__);
+        XFREE(MTYPE_TE,pLspSmData);
+        sm_gen_free(pNewSm);
+    }
+    zlog_info("%s %d",__FILE__,__LINE__);
+    return pEvent;
+}
+
+void LspSmDestroy(SM_T *pSm)
+{
+    PSB_KEY PsbKey;
+    RSVP_TUNNEL_PROPERTIES *pTunnel = NULL;
+    LSP_SM_DATA *pLspSmData = pSm->data;
+    TUNNEL_ID_LIST *pTunnelIdList = pLspSmData->TunnelIdHead,*pTunnelIdListNext;
+
+    while(pTunnelIdList != NULL)
+    {
+        memset(&PsbKey,0,sizeof(PSB_KEY));
+        PsbKey.Session.Dest = pTunnelIdList->dest;
+        PsbKey.Session.TunnelId = pTunnelIdList->tunnel_id;
+        PsbKey.Session.ExtTunelId = pTunnelIdList->source;
+        if(FindTunnel(&PsbKey,&pTunnel,ALL_TRUNKS) == TRUE)
+            pTunnel->sm_handle = 0;
+        pTunnelIdListNext = pTunnelIdList->next;
+        XFREE(MTYPE_TE,pTunnelIdList);
+        pTunnelIdList = pTunnelIdListNext;
+    }
+
+    if(pLspSmData != NULL)
+    {
+        XFREE(MTYPE_TE,pLspSmData);
+    }
+    sm_gen_free(pSm);
+}
+
+void UserLspDestroy(USER_LSP *pUserLsp)
+{
+    RSVP_TUNNEL_PROPERTIES *pTunnel = pUserLsp->pUserLspTunnels,*pTunnelNext;
+    
+    if(pTunnel == NULL)
+    {
+        zlog_err("\nunexpected: tunnel id list empty %s %d",__FILE__,__LINE__);
+        return;
+    }
+    while(pTunnel != NULL)
+    {
+        pTunnelNext = pTunnel->next_user_lsp_tunnel;
+        if(RsvpTunnelTearDown(pTunnel,
+                              pUserLsp->params.to,
+                              pUserLsp->params.from) != E_OK)
+        {
+            zlog_err("\ncannot tear donw the tunnel %s %d",__FILE__,__LINE__);
+        }
+        pTunnel = pTunnelNext;
+    }
+    pUserLsp->pUserLspTunnels = NULL;
+    return;
+}
+
+
+E_RC SetErHopList(STATIC_PATH *pStaticPath,ER_HOP **ppErHopsList)
+{
+    ER_HOP *pErHopsList;
+    IPV4_HOP *pHops;
+    int i;
+    if(pStaticPath->HopCount == 0)
+    {
+        return E_OK;
+    }
+    if((pErHopsList = (ER_HOP *)XMALLOC(MTYPE_TE,sizeof(IPV4_HOP)*(pStaticPath->HopCount))) == NULL)
+    {
+        zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+        return E_ERR;
+    }
+    for(i = 0,pHops = pStaticPath->HopList;i < pStaticPath->HopCount;i++,pHops = pHops->next)
+    {
+        pErHopsList[i].IpAddr = pHops->IpAddr;
+        pErHopsList[i].Loose = pHops->Loose;
+        pErHopsList[i].PrefixLength = 32;
+    }
+    *ppErHopsList = pErHopsList;
+    return E_OK;
+}
+
+SM_CALL_T *ProcessPrimaryLsp(USER_LSP *pCurrentUserLsp,
+                             USER_LSP *pUserLsp,
+                             SM_T *pSm,
+                             char *PrimaryLspPathName)
+{
+    SM_CALL_T *pCall = NULL;
+    INGRESS_API *pOpenLspParams = NULL;
+    PSB_KEY PsbKey;
+    RSVP_TUNNEL_PROPERTIES *pPrimaryTunnel;
+    STATIC_PATH *pStaticPath = NULL;
+    SECONDARY_PATH_LIST *pSecList;
+    LSP_PATH_SHARED_PARAMS *pParams = NULL,*pParams2;
+    BOOL OperationRequired = FALSE;
+    uns8 Flags = 0;
+    ER_HOP *pErHopsList = NULL;
+    zlog_info("entering ProcessPrimaryLsp");
+    zlog_info("LSP NAME %s",pCurrentUserLsp->params.LspName);
+
+    if((pPrimaryTunnel = pCurrentUserLsp->pUserLspTunnels) == NULL)
+    {
+        memset(&PsbKey,0,sizeof(PSB_KEY));
+        PsbKey.Session.Dest = pUserLsp->params.to;
+        PsbKey.Session.TunnelId = NewTunnelId(&PsbKey);
+        PsbKey.Session.ExtTunelId = pUserLsp->params.from = rdb_get_router_id();
+        if(NewTunnel(&PsbKey,&pPrimaryTunnel,SEPARATE_NON_ADAPTIVE) != E_OK)
+        {
+            zlog_err("Cannot create new tunnel %s %d",__FILE__,__LINE__);
+            return NULL;
+        }
+        pCurrentUserLsp->pUserLspTunnels = pPrimaryTunnel;
+        zlog_info("New tunnel (Primary) created %x %s",pPrimaryTunnel->TunnelId,pPrimaryTunnel->StaticPathName);
+        OperationRequired = TRUE;
+    }
+    strcpy(PrimaryLspPathName,pUserLsp->params.Primary);
+    strcpy(pPrimaryTunnel->StaticPathName,PrimaryLspPathName);
+    /* calculate the primary LSP parameters */
+    if((!((pUserLsp->params.PrimaryPathParams)&&(!pUserLsp->params.PrimaryPathParams->disable)))||
+       (rdb_get_static_path(pUserLsp->params.Primary,&pStaticPath) != E_OK))
+    {
+        zlog_info("No primary path...");
+        pSecList = pUserLsp->params.SecondaryPaths;
+        while(pSecList != NULL)
+        {
+            if(((pSecList->SecondaryPathParams)&&(pSecList->SecondaryPathParams->standby == 0))&&
+               (rdb_get_static_path(pSecList->Secondary,&pStaticPath) == E_OK))
+            {
+                zlog_info("Processing secondary path %s",pSecList->Secondary);
+                if(StaticPathIsUsed(pCurrentUserLsp,pSecList->Secondary) == NULL)
+                {
+                    zlog_info("\nSecondary path hasn't LSP");
+                    pParams = PathParamsGet(pUserLsp,pSecList->Secondary,0);
+                    Flags |= (pParams->record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+                    /* for now the FRR is only boolean. However, in future it may be more complicated */
+                    Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+                    if(SetErHopList(pStaticPath,&pErHopsList) != E_OK)
+                    {
+                        zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+                        return NULL;
+                    }
+                    if((pOpenLspParams = CreateRequest2Signalling(pCurrentUserLsp->params.to,
+                                                                  pPrimaryTunnel->TunnelId,
+                                                                  pStaticPath->HopCount,
+                                                                  pErHopsList,
+                                                                  pParams->BW,
+                                                                  pParams->setup_priority,
+                                                                  pParams->hold_priority,
+                                                                  Flags,
+                                                                  (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                                  0,
+                                                                  pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+                    {
+                        zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+                        if(pErHopsList != NULL)
+                            XFREE(MTYPE_TE,pErHopsList);
+                        return NULL;
+                    }
+                    strcpy(PrimaryLspPathName,pSecList->Secondary);
+                    OperationRequired = TRUE;
+                    break;
+                }
+                pStaticPath = NULL;
+            }
+            pSecList = pSecList->next;
+        }
+        if((pUserLsp->params.PrimaryPathParams != NULL)&&
+           (!pUserLsp->params.PrimaryPathParams->disable))
+        {
+           pParams = pUserLsp->params.PrimaryPathParams;
+        }
+        else
+        {
+           pParams = &pUserLsp->params.lsp_params;
+        }
+        if(pCurrentUserLsp->params.PrimaryPathParams != NULL)
+        {
+           pParams2 = pCurrentUserLsp->params.PrimaryPathParams;
+        }
+        else
+        {
+           pParams2 = &pCurrentUserLsp->params.lsp_params;
+        }
+        if((pStaticPath == NULL)&&
+           ((pParams->BW != pParams2->BW)||
+            (pParams->class_of_service != pParams2->class_of_service)||
+            (pParams->hold_priority != pParams2->hold_priority)||
+            (pParams->setup_priority != pParams2->setup_priority)||
+            (pParams->hop_limit != pParams2->hop_limit)||
+            (pParams->record != pParams2->record)||
+            (pUserLsp->params.FastReRoute != pCurrentUserLsp->params.FastReRoute)||
+            (pUserLsp == pCurrentUserLsp)))
+        {
+            zlog_info("no paths provided");
+            Flags |= (pUserLsp->params.lsp_params.record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+                /* for now the FRR is only boolean. However, in future it may be more complicated */
+            Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+            if((pOpenLspParams = CreateRequest2Signalling(pCurrentUserLsp->params.to,
+                                                          pPrimaryTunnel->TunnelId, 
+                                                          0,NULL,
+                                                          pParams->BW,
+                                                          pParams->setup_priority,
+                                                          pParams->hold_priority,
+                                                          Flags,
+                                                          (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                          0,
+                                                          pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+            {
+                zlog_err("\ncannot create request %s %d",__FILE__,__LINE__);
+                return NULL;
+            }
+            OperationRequired = TRUE;
+        }
+        else if(pStaticPath == NULL)
+        {
+            if(pParams->optimize_timer != pParams2->optimize_timer)
+            {
+               StartAdaptivityTimer(pParams->optimize_timer,pPrimaryTunnel);
+            }
+        }
+    }
+    else
+    {
+        zlog_info(
+               "\nCurrent Primary %s New Primary %s",
+               pCurrentUserLsp->params.Primary,pUserLsp->params.Primary);
+        if((pUserLsp->params.PrimaryPathParams != NULL)&&
+           (!pUserLsp->params.PrimaryPathParams->disable))
+        {
+            pParams = pUserLsp->params.PrimaryPathParams;
+        }
+        else
+        {
+            pParams = &pUserLsp->params.lsp_params;
+        }
+        if(pCurrentUserLsp->params.PrimaryPathParams != NULL)
+        {
+            pParams2 = pCurrentUserLsp->params.PrimaryPathParams;
+        }
+        else
+        {
+            pParams2 = &pCurrentUserLsp->params.lsp_params;
+        }
+        if((pParams->BW != pParams2->BW)||
+           (pParams->class_of_service != pParams2->class_of_service)||
+           (pParams->hold_priority != pParams2->hold_priority)||
+           (pParams->setup_priority != pParams2->setup_priority)||
+           (pParams->hop_limit != pParams2->hop_limit)||
+           (pParams->record != pParams2->record)||
+           (pUserLsp->params.FastReRoute != pCurrentUserLsp->params.FastReRoute))
+        {
+            OperationRequired = TRUE;
+        }
+        
+        if(strcmp(pCurrentUserLsp->params.Primary,pUserLsp->params.Primary) != 0)
+        {
+            OperationRequired = TRUE;
+        }
+           
+        if(pCurrentUserLsp->params.FastReRoute != pUserLsp->params.FastReRoute)
+        {
+            OperationRequired = TRUE;
+        }
+
+        if(OperationRequired == TRUE)
+        {
+            zlog_info("Parameters have changed");
+            pParams = PathParamsGet(pUserLsp,pUserLsp->params.Primary,1);
+            Flags |= (pParams->record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+            /* for now the FRR is only boolean. However, in future it may be more complicated */
+            Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+            if(SetErHopList(pStaticPath,&pErHopsList) != E_OK)
+            {
+                zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+                return NULL;
+            }
+            if((pOpenLspParams = CreateRequest2Signalling(pCurrentUserLsp->params.to,
+                                                          pPrimaryTunnel->TunnelId,
+                                                          pStaticPath->HopCount,
+                                                          pErHopsList,
+                                                          pParams->BW,
+                                                          pParams->setup_priority,
+                                                          pParams->hold_priority,
+                                                          Flags,
+                                                          (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                          0,
+                                                          pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+            {
+                zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+                if(pErHopsList != NULL)
+                    XFREE(MTYPE_TE,pErHopsList);
+                return NULL;
+            }
+        }
+        else
+        {
+            if(pParams->optimize_timer != pParams2->optimize_timer)
+            {
+               StartAdaptivityTimer(pParams->optimize_timer,pPrimaryTunnel);
+            }
+        }
+    }
+    if(OperationRequired == TRUE)
+    {
+        /* setup the primary LSP */
+        pOpenLspParams->TunnelId = pPrimaryTunnel->TunnelId;
+        zlog_info(
+               "\nDEST %x SOURCE %x TUNNEL %x",
+               pOpenLspParams->Egress,pOpenLspParams->src_ip,pOpenLspParams->TunnelId);
+        pCall = LspRequest(pOpenLspParams,0,NULL,pSm,&pPrimaryTunnel,FALSE,pParams);
+        pPrimaryTunnel->sm_handle = pSm;
+        strcpy(pPrimaryTunnel->StaticPathName,PrimaryLspPathName);
+        strcpy(pPrimaryTunnel->UserLspName,pUserLsp->params.LspName);
+        zlog_info("\nPrimary Tunnel Name %s",pPrimaryTunnel->UserLspName);
+    }
+    zlog_info("leaving ProcessPrimaryLsp");
+    return pCall;
+}
+
+RSVP_TUNNEL_PROPERTIES *GetSecondaryTunnel2Reroute(USER_LSP *pUserLsp,
+                                                   USER_LSP *pCurrentUserLsp)
+{
+    RSVP_TUNNEL_PROPERTIES *pTunnel;
+    SECONDARY_PATH_LIST *pSecList;
+    BOOL Found;
+    zlog_info("entering GetSecondaryTunnel2Reroute");
+    if((pTunnel = pCurrentUserLsp->pUserLspTunnels) == NULL)
+    {
+        zlog_err(
+               "\nBUG: first Tunnel ID is NULL %s %d %s",
+               __FILE__,__LINE__,pCurrentUserLsp->params.LspName);
+        return NULL;
+    }
+    pTunnel = pTunnel->next_user_lsp_tunnel;
+    while(pTunnel != NULL)
+    {
+        pSecList = pUserLsp->params.SecondaryPaths;
+        Found = FALSE;
+        while(pSecList != NULL)
+        {
+            if((pSecList->SecondaryPathParams != NULL)&&
+               (pSecList->SecondaryPathParams->standby == TRUE))
+            {
+                if(strcmp(pSecList->Secondary,pTunnel->StaticPathName) == 0)
+                {
+                    Found = TRUE;
+                    break;
+                }
+            }
+            pSecList = pSecList->next;
+        }
+        if(Found == FALSE)
+        {
+            /* should we do some clean up like stop the timers etc ??? */
+            return pTunnel;
+        }
+        pTunnel = pTunnel->next_user_lsp_tunnel;
+    }
+    zlog_info("leaving GetSecondaryTunnel2Reroute");
+    return NULL;
+}
+
+SM_CALL_T *ProcessSecondaryPaths(USER_LSP *pCurrentUserLsp,
+                                 USER_LSP *pUserLsp,
+                                 SM_T *pSm,
+                                 char *PrimaryLspPathName,
+                                 BOOL PrimaryLspOperation)
+{
+    SECONDARY_PATH_LIST *pSecList;
+    BOOL OperationRequired;
+    INGRESS_API *pOpenLspParams;
+    RSVP_TUNNEL_PROPERTIES *pSecondaryTunnel,*pSecTunnel2Modify,*pSecReusedTunnel;
+    STATIC_PATH *pStaticPath;
+    PSB_KEY PsbKey;
+    LSP_PATH_SHARED_PARAMS *pParams = NULL,*pParams2;
+    uns8 Flags = 0;
+    ER_HOP *pErHopsList = NULL;
+    SM_CALL_T *pCall = NULL;
+
+    zlog_info("entering ProcessSecondaryPaths");
+
+    pSecList = pUserLsp->params.SecondaryPaths;
+                
+    /* find all the secondary LSPs (hot-standby) that must be established */
+    while(pSecList != NULL)
+    {
+        OperationRequired = FALSE;
+        pCall = NULL;
+        pErHopsList = NULL;
+        zlog_info("Secondary path...");
+        if((pSecList->SecondaryPathParams != NULL)&&
+           (pSecList->SecondaryPathParams->disable == FALSE)&&
+           (pSecList->SecondaryPathParams->standby == TRUE))
+        {
+            zlog_info("Secondary path2...");
+            if(rdb_get_static_path(pSecList->Secondary,
+                                        &pStaticPath) != E_OK)
+            {
+               zlog_info("static path is not found in TE DB");
+               pStaticPath = NULL; 
+            }
+            else
+            {
+                if(SetErHopList(pStaticPath,&pErHopsList) != E_OK)
+                {
+                    zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+                    return NULL;
+                }
+            }
+            pSecReusedTunnel = NULL;    
+            pParams = PathParamsGet(pUserLsp,pSecList->Secondary,0);
+            if((pSecTunnel2Modify = StaticPathIsUsed(pCurrentUserLsp,pSecList->Secondary)) == NULL)
+            {
+                zlog_info("Secondary path3 ...");
+                   
+                if((pSecReusedTunnel = GetSecondaryTunnel2Reroute(pUserLsp,pCurrentUserLsp)) != NULL)
+                {
+                    strcpy(pSecReusedTunnel->StaticPathName,pSecList->Secondary);
+                }
+                OperationRequired = TRUE;         
+            }
+            else
+            {
+                pParams2  = PathParamsGet(pCurrentUserLsp,pSecList->Secondary,0);
+                pSecReusedTunnel = pSecTunnel2Modify;          
+                if((pParams->BW != pParams2->BW)||
+                   (pParams->class_of_service != pParams2->class_of_service)||
+                   (pParams->hold_priority != pParams2->hold_priority)||
+                   (pParams->setup_priority != pParams2->setup_priority)||
+                   (pParams->hop_limit != pParams2->hop_limit)||
+                   (pParams->record != pParams2->record)||
+                   (pUserLsp->params.FastReRoute != pCurrentUserLsp->params.FastReRoute))
+                {
+                     OperationRequired = TRUE;
+                }
+                if(pCurrentUserLsp->params.FastReRoute != pUserLsp->params.FastReRoute)
+                {
+                    OperationRequired = TRUE;
+                }
+                if(OperationRequired == FALSE)
+                {
+                   if(pParams->optimize_timer != pParams2->optimize_timer)
+                   {
+                      StartAdaptivityTimer(pParams->optimize_timer,pSecReusedTunnel);
+                   }
+                }
+            }
+            if(OperationRequired == TRUE)
+            {
+                if((((pStaticPath != NULL)&&(pStaticPath->HopCount != 0))&&
+                    ((pErHopsList != NULL)&&(pErHopsList[0].Loose == 0)))||
+                    (PrimaryLspOperation == FALSE))
+                {
+                    uns32 ErHopNumber = 0;
+                    IPV4_ADDR *pErHops = NULL;
+                    if(!((pErHopsList != NULL)&&(pErHopsList[0].Loose == 0)))
+                    {
+                       if(GetTunnelHops(pCurrentUserLsp->pUserLspTunnels,
+                                        &ErHopNumber,
+                                        &pErHops) != E_OK)
+                       {
+                           zlog_info(
+                                  "cannot get ER HOPs to be avoided %s %d",
+                                  __FILE__,__LINE__);
+                           ErHopNumber = 0;
+                           pErHops = NULL;
+                       }
+                    }
+                    memset(&PsbKey,0,sizeof(PSB_KEY));
+                    PsbKey.Session.Dest = pUserLsp->params.to;
+                    Flags |= pParams->record == TRUE ? LABEL_RECORDING_DESIRED : 0;
+                    /* for now the FRR is only boolean. However, in future it may be more complicated */
+                    Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+                    if((pOpenLspParams = CreateRequest2Signalling(pUserLsp->params.to,
+                                                                  (pSecReusedTunnel == NULL) ? 
+                                                                     NewTunnelId(&PsbKey) : pSecReusedTunnel->TunnelId,
+                                                                  (pStaticPath == NULL) ? 0 : pStaticPath->HopCount,
+                                                                  pErHopsList,
+                                                                  pParams->BW,
+                                                                  pParams->setup_priority,
+                                                                  pParams->hold_priority,
+                                                                  Flags,
+                                                                  (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                                  0,
+                                                                  pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+                    {
+                         zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+                         return NULL;
+                    }
+                    pCall = LspRequest(pOpenLspParams,
+                                       ErHopNumber,
+                                       pErHops,
+                                       pSm,
+                                       &pSecondaryTunnel,
+                                       TRUE,
+                                       pParams);
+                    pSecondaryTunnel->sm_handle = pSm;
+                    if(AddSecondaryTunnel(pCurrentUserLsp,
+                                          pSecondaryTunnel) != E_OK)
+                    {
+                        zlog_err("\ncannot add secodary tunnel to the list %s %d",
+                               __FILE__,__LINE__);
+                        return NULL;
+                    }
+                }
+                else
+                {
+                    uns16 TunnelId;
+                    if(pSecReusedTunnel == NULL)
+                    {
+                        memset(&PsbKey,0,sizeof(PsbKey));
+                        PsbKey.Session.Dest = pUserLsp->params.to;
+                        PsbKey.Session.ExtTunelId = pUserLsp->params.from;
+                        TunnelId = NewTunnelId(&PsbKey);
+                        PsbKey.Session.TunnelId = TunnelId;
+                        zlog_info("DEST %x TUNNEL %x SOURCE %x",
+                               PsbKey.Session.Dest,
+                               PsbKey.Session.TunnelId,
+                               PsbKey.Session.ExtTunelId);
+                        if(NewTunnel(&PsbKey,&pSecondaryTunnel,SEPARATE_NON_ADAPTIVE) != E_OK)
+                        {
+                            zlog_err("\ncannot create new tunnel's structure");
+                            LspSmDestroy(pSm);
+                            return NULL;
+                        }
+                    }
+                    else
+                    {
+                        pSecondaryTunnel = pSecReusedTunnel;
+                    }
+                        
+                    pSecondaryTunnel->RequiredBW = pParams->BW;
+                    pSecondaryTunnel->sm_handle = pSm;
+                    if(AddSecondaryTunnel(pCurrentUserLsp,
+                                          pSecondaryTunnel) != E_OK)
+                    {
+                        zlog_err("\ncannot add secodary tunnel to the list %s %d",
+                               __FILE__,__LINE__);
+                        return NULL;
+                    }
+                    pSecondaryTunnel->AdjustmentRequired = TRUE;
+                }
+                zlog_info("after UserLSpRequest %s %d %x",__FILE__,__LINE__,pSecondaryTunnel->TunnelId);
+                if(pSecondaryTunnel != NULL)
+                {
+                    strcpy(pSecondaryTunnel->StaticPathName,pSecList->Secondary);
+                    strcpy(pSecondaryTunnel->UserLspName,pUserLsp->params.LspName);
+                    zlog_info("pSecondaryTunnel->StaticPathName %s pSecondaryTunnel->UserLspName %s",
+                           pSecondaryTunnel->StaticPathName,pSecondaryTunnel->UserLspName);
+                }
+                if(pCall)
+                {
+                   sm_call(pCall);
+                   pCall = NULL;
+                }
+            }
+        }
+        pSecList = pSecList->next;
+    }
+    zlog_info("leaving ProcessSecondaryPaths");
+    return NULL;
+}
+
+uns32 StartAdaptivityTimer(uns32 optimize_timer,
+                           RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    zlog_info("entering StartAdaptivityTimer");
+
+    if(pTunnel->adaptivity_timer.is_active == TRUE)
+    {
+        te_stop_timer(&pTunnel->adaptivity_timer);
+    }
+    zlog_info("triggering optimize timer for tunnel %x value %d",pTunnel->TunnelId,optimize_timer);
+    if(optimize_timer != 0)
+    {
+        if(te_start_timer(&pTunnel->adaptivity_timer,
+                          ADAPTIVITY_EXPIRY,
+                          optimize_timer) != E_OK)
+        {
+             zlog_err("\ncannot start adaptivity timer %s %d",__FILE__,__LINE__);
+             return E_ERR;
+        }
+    }
+    else
+    {
+        zlog_info("\nOptimize timer is 0...");
+    }
+    zlog_info("leaving StartAdaptivityTimer");
+    return E_OK;
+}
+
+void StopAdaptivityTimer(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    zlog_info("entering StopAdaptivityTimer");
+    te_stop_timer(&pTunnel->adaptivity_timer);
+    zlog_info("leaving StopAdaptivityTimer");
+}
+
+uns32 StartLspSetupTimer(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    zlog_info("entering StartLspSetupTimer");
+    //return E_OK;
+    if(pTunnel->lsp_setup_timer.is_active == TRUE)
+    {
+        te_stop_timer(&pTunnel->lsp_setup_timer);
+    }
+    if(te_start_timer(&pTunnel->lsp_setup_timer,
+                      LSP_SETUP_EXPIRY,
+                      LspSetupTimeOut) != E_OK)
+    {
+        zlog_err("\ncannot start te timer %s %d",__FILE__,__LINE__);
+        return E_ERR;
+    }
+    zlog_info("leaving StartLspSetupTimer");
+    return E_OK;
+}
+
+void StopLspSetupTimer(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    zlog_info("entering StopLspSetupTimer");
+    te_stop_timer(&pTunnel->lsp_setup_timer);
+    zlog_info("leaving StopLspSetupTimer");
+}
+
+uns32 StartLspSetupRetryTimer(uns32 retry_timer,
+                              uns32 *retry_count,
+                              RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    zlog_info("entering StartLspSetupRetryTimer");
+  
+    if(*retry_count > 0)
+    {
+        if(retry_timer != 0)
+        {
+            if(pTunnel->lsp_setup_retry_timer.is_active == TRUE)
+            {
+                te_stop_timer(&pTunnel->lsp_setup_retry_timer);
+            }
+            zlog_info("\ninside of StartLspSetupRetryTimer %x %x %x",
+                   pTunnel->lsp_setup_retry_timer.data.lsp_setup_retry_data.key.Session.Dest,
+                   pTunnel->lsp_setup_retry_timer.data.lsp_setup_retry_data.key.Session.TunnelId,
+                   pTunnel->lsp_setup_retry_timer.data.lsp_setup_retry_data.key.Session.ExtTunelId);
+            if(te_start_timer(&pTunnel->lsp_setup_retry_timer,
+                              LSP_SETUP_RETRY_EXPIRY,
+                              retry_timer) != E_OK)
+            {
+                zlog_err("\ncannot start te timer %s %d",__FILE__,__LINE__);
+                return E_ERR;
+            }
+        }
+        (*retry_count)--;
+    }
+    zlog_info("leaving StartLspSetupRetryTimer");
+    return E_OK;
+}
+
+void StopLspSetupRetryTimer(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    zlog_info("entering StopLspSetupTimer");
+    te_stop_timer(&pTunnel->lsp_setup_retry_timer);
+    zlog_info("leaving StopLspSetupRetryTimer");
+}
+
+uns32 StartCspfRetryTimer(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    int r,k;
+    zlog_info("entering StartCspfRetryTimer");
+
+    if(pTunnel->cspf_retry_timer.is_active == TRUE)
+    {
+        te_stop_timer(&pTunnel->cspf_retry_timer);
+    }
+    zlog_info("inside of StartCspfRetryTimer %x %x %x",
+                       pTunnel->cspf_retry_timer.data.cspf_retry_data.key.Session.Dest,
+                       pTunnel->cspf_retry_timer.data.cspf_retry_data.key.Session.TunnelId,
+                       pTunnel->cspf_retry_timer.data.cspf_retry_data.key.Session.ExtTunelId);
+    r = rand();
+    r = r%30;
+    k = rand();
+    if(te_start_timer(&pTunnel->cspf_retry_timer,
+                      CSPF_RETRY_EXPIRY,
+                      /*(k%2) ? (300 + r) : (300 - r)*/5) != E_OK)
+    {
+        zlog_err("\ncannot start te timer %s %d",__FILE__,__LINE__);
+        return E_ERR;
+    }
+    zlog_info("leaving StartCspfRetryTimer");
+    return E_OK;
+}
+
+static void StopCspfRetryTimer(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    zlog_info("entering StopCspfRetryTimer");
+    te_stop_timer(&pTunnel->cspf_retry_timer);
+    zlog_info("leaving StopCspfRetryTimer");
+}
+
+SM_CALL_T *CspfRetryExpiry(PSB_KEY *PsbKey,SM_T *pSm)
+{
+    RSVP_TUNNEL_PROPERTIES *pTunnel;
+    SM_CALL_T *pCall = NULL;
+
+    zlog_info("entering CspfRetryExpiry");
+    
+    if(FindTunnel(PsbKey,&pTunnel,ALL_TRUNKS) != TRUE)
+    {
+        zlog_info("leaving CspfRetryExpiry1-");
+        return NULL;
+    }
+
+    if((pTunnel->pOpenLspParams)&&(pTunnel->pCrArgs))
+    {
+       ((INGRESS_API *)(pTunnel->pOpenLspParams))->ErHops2Exclude[0] = 0;
+       ((INGRESS_API *)(pTunnel->pOpenLspParams))->ErHops2Exclude[1] = 0;
+       UnregisterClient((int)pSm,
+                        pTunnel->TunnelId);
+       if((pCall = constraint_route_resolution_sm_invoke(pSm,
+                                                         pTunnel->pCrArgs)) == NULL)
+       {
+           zlog_err("cannot invoke constraint route resolution");
+           return NULL;
+       }
+    }
+    StartCspfRetryTimer(pTunnel);
+    zlog_info("leaving CspfRetryExpiry");
+    return pCall;
+}
+
+SM_CALL_T *LspSetupExpiry(PSB_KEY *PsbKey,SM_T *pSm)
+{
+    RSVP_TUNNEL_PROPERTIES *pTunnel;
+    RSVP_LSP_PROPERTIES *pRsvpLsp;
+  
+    zlog_info("entering LspSetupExpiry");
+  
+    if(FindTunnel(PsbKey,&pTunnel,ALL_TRUNKS) != TRUE)
+    {
+        zlog_err("\ncannot find tunnel %x %x %x %s %d",
+            PsbKey->Session.Dest,
+            PsbKey->Session.TunnelId,
+            PsbKey->Session.ExtTunelId,__FILE__,__LINE__);
+        return NULL;
+    }
+    pRsvpLsp = pTunnel->properties;
+    while(pRsvpLsp != NULL)
+    {
+        if(pRsvpLsp->LspId != pTunnel->LspId)
+        {
+            RSVP_LSP_PROPERTIES *pTemp = pRsvpLsp->next;
+            RemoveRsvpLsp(pTunnel,pRsvpLsp->LspId,PsbKey->Session.Dest,PsbKey->Session.ExtTunelId);
+            pRsvpLsp = pTemp;
+        }
+        else
+        {
+            pRsvpLsp = pRsvpLsp->next;
+        }
+    }
+    //pTunnel->ReRoute = FALSE;
+    if(pTunnel->UserLspName[0] != '\0')
+    {
+        return UserLspFailed(pTunnel,pSm,0);
+    }
+    else
+    {
+        NotifyFailedRequests(pTunnel);
+    }
+    zlog_info("leaving LspSetupExpiry");
+    return NULL;
+}
+
+SM_CALL_T *AdaptivityExpiry(PSB_KEY *PsbKey,SM_T *pSm)
+{
+    RSVP_TUNNEL_PROPERTIES *pTunnel;
+    USER_LSP *pUserLsp;
+    STATIC_PATH *pStaticPath;
+
+    zlog_info("entering AdaptivityExpiry");
+    
+    if(FindTunnel(PsbKey,&pTunnel,ALL_TRUNKS) != TRUE)
+    {
+        zlog_err("\ncannot find tunnel %x %x %x %s %d",
+            PsbKey->Session.Dest,
+            PsbKey->Session.TunnelId,
+            PsbKey->Session.ExtTunelId,
+            __FILE__,__LINE__);
+        return NULL;
+    }
+    
+    if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != 0)
+    {
+        LSP_PATH_SHARED_PARAMS *pParams = PathParamsGet(pUserLsp,
+                                                        pTunnel->StaticPathName,
+                                                        ((!strcmp(pUserLsp->params.Primary,pTunnel->StaticPathName))&&(pUserLsp->pUserLspTunnels->TunnelId == pTunnel->TunnelId)));
+        
+        if(pParams == NULL)
+        {
+            zlog_err("\ncannot get User Lsp PAth Params %s %d",__FILE__,__LINE__);
+        }
+        else
+        {
+            if(StartAdaptivityTimer(pParams->optimize_timer,pTunnel) != E_OK)
+            {
+                zlog_err("\ncannot start adaptivity timer %s %d",__FILE__,__LINE__);
+            }
+        }
+        
+        if(pTunnel->ReRoute == FALSE)
+        {
+            IPV4_ADDR dest = PsbKey->Session.Dest;
+
+            if(rdb_get_static_path(pTunnel->StaticPathName,
+                                        &pStaticPath) == E_OK)
+            {
+                if(pStaticPath->HopCount != 0)
+                {
+                    if(pStaticPath->HopList->Loose == 0)
+                    {
+                        return NULL;
+                    }
+                    else
+                    {
+                        dest = pStaticPath->HopList->IpAddr;
+                    }
+                }
+            }
+            return OptimizeSingleLsp(pTunnel,
+                                     dest,
+                                     PsbKey->Session.ExtTunelId);
+        }
+        else
+        {
+            zlog_info("\nDEBUG: No adaptation during reroute %x %x %x %s %d",
+                PsbKey->Session.Dest,
+                PsbKey->Session.TunnelId,
+                PsbKey->Session.ExtTunelId,
+                __FILE__,__LINE__);
+        }
+    }
+    zlog_info("leaving AdaptivityExpiry");
+    return NULL;
+}
+
+SM_CALL_T *LspSetupRetryExpiry(PSB_KEY *PsbKey,SM_T *pSm)
+{
+    RSVP_TUNNEL_PROPERTIES *pTunnel;
+    USER_LSP *pUserLsp;
+    STATIC_PATH *pStaticPath;
+    INGRESS_API *pOpenLspParams;
+    SM_CALL_T *pCall = NULL;
+    uns32 ErHops2BeAvoidedNumber = 0;
+    IPV4_ADDR *ErHops2BeAvoided = NULL;
+    LSP_PATH_SHARED_PARAMS *pParams;
+    ER_HOP *pErHopsList = NULL;
+    uns8 Flags = 0;
+
+    zlog_info("entering LspSetupRetryExpiry");
+
+    if(FindTunnel(PsbKey,&pTunnel,ALL_TRUNKS) != TRUE)
+    {
+        zlog_err("\ncannot find tunnel %x %x %x %s %d",
+            PsbKey->Session.Dest,
+            PsbKey->Session.TunnelId,
+            PsbKey->Session.ExtTunelId,
+            __FILE__,__LINE__);
+        return NULL;
+    }
+    if((pUserLsp = UserLspGet(pTunnel->UserLspName)) == NULL)
+    {
+        zlog_err("\ncannot get user lsp %s %d",__FILE__,__LINE__);
+        return NULL;
+    }
+    if(rdb_get_static_path(pUserLsp->params.Primary,
+                                &pStaticPath) != E_OK)
+    {
+        pStaticPath = NULL;
+    }
+    pParams = PathParamsGet(pUserLsp,pUserLsp->params.Primary,1);
+    Flags |= (pParams->record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+    /* for now the FRR is only boolean. However, in future it may be more complicated */
+    Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+    if(pStaticPath)
+    {
+       if(SetErHopList(pStaticPath,&pErHopsList) != E_OK)
+       {
+           zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+           return NULL;
+       }
+    }
+    if((pOpenLspParams = CreateRequest2Signalling(pUserLsp->params.to,
+                                                  pUserLsp->pUserLspTunnels->TunnelId,
+                                                  (pStaticPath) ? pStaticPath->HopCount : 0,
+                                                  pErHopsList,
+                                                  pParams->BW,
+                                                  pParams->setup_priority,
+                                                  pParams->hold_priority,
+                                                  Flags,
+                                                  (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                  0,
+                                                  pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+    {
+        zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+        XFREE(MTYPE_TE,pErHopsList);
+        return NULL;
+    }
+    
+#if 0
+    if((pTunnelIdList = pUserLsp->TunnelIdList) == NULL)
+    {
+        zlog_info("\nUser's LSP tunnel ID list is empty...");
+    }
+    else
+    {
+        RSVP_TUNNEL_PROPERTIES *pTun;
+        PSB_KEY rsvp_k;
+        memset(&rsvp_k,0,sizeof(PSB_KEY));
+        rsvp_k.Session.Dest = pTunnelIdList->dest;
+        rsvp_k.Session.ExtTunelId = pTunnelIdList->source;
+        pTunnelIdList = pTunnelIdList->next;
+        while(pTunnelIdList != NULL)
+        {
+            rsvp_k.Session.TunnelId = pTunnelIdList->tunnel_id;
+            if(FindTunnel(&rsvp_k,&pTun,ALL_TRUNKS) == TRUE)
+            {
+                if(strcmp(pUserLsp->CurrentSecondaryPathName,
+                    pTun->StaticPathName) == 0)
+                {
+                    if(GetTunnelHops(pTunnelIdList,&ErHops2BeAvoidedNumber,&ErHops2BeAvoided) != E_OK)
+                    {
+                        zlog_err("\ncannot get tunnel's hops %x %x %x %s %d",
+                            rsvp_k.Session.Dest,
+                            pTunnelIdList->tunnel_id,
+                            rsvp_k.Session.ExtTunelId,
+                            __FILE__,__LINE__);
+                        ErHops2BeAvoidedNumber = 0;
+                        ErHops2BeAvoided = NULL;
+                    }
+                    break;
+                }
+            }
+            else
+            {
+                zlog_err("\ncannot get Tunnel %x %x %x %s %d",
+                    rsvp_k.Session.Dest,
+                    pTunnelIdList->tunnel_id,
+                    rsvp_k.Session.ExtTunelId,
+                    __FILE__,__LINE__);
+            }
+            pTunnelIdList = pTunnelIdList->next;
+        }
+    }
+#endif
+    pCall = LspRequest(pOpenLspParams,ErHops2BeAvoidedNumber,ErHops2BeAvoided,pSm,&pTunnel,TRUE,pParams);
+    strcpy(pTunnel->StaticPathName,pUserLsp->params.Primary);
+    StartLspSetupRetryTimer(pUserLsp->params.retry_timer,&pUserLsp->params.retry_count,pTunnel);
+    zlog_info("leaving LspSetupRetryExpiry");
+    return pCall;
+}
+
+void TearDownAndRemoveSecondary(USER_LSP *pCurrentUserLsp,char *PathName)
+{
+    RSVP_TUNNEL_PROPERTIES *pTunnel = pCurrentUserLsp->pUserLspTunnels,*pTunnelPrev = NULL;
+
+    zlog_info("entering TearDownAndRemoveSecondary");
+
+    if(pTunnel == NULL)
+    {
+        zlog_err("\nTunnelIDList is empty %s %d",__FILE__,__LINE__);
+        return;
+    }
+    pTunnelPrev = pTunnel;
+    pTunnel = pTunnel->next_user_lsp_tunnel;
+    while(pTunnel != NULL)
+    {
+        if(strcmp(pTunnel->StaticPathName,PathName) == 0)
+        {
+            pTunnelPrev->next_user_lsp_tunnel = pTunnel->next_user_lsp_tunnel;
+            if(RsvpTunnelTearDown(pTunnel,
+                                  pCurrentUserLsp->params.to,
+                                  pCurrentUserLsp->params.from) != E_OK)
+            {
+                zlog_err("\ncannot tear donw the tunnel %s %d",__FILE__,__LINE__);
+            }
+            return;
+        }
+        pTunnelPrev = pTunnel;
+        pTunnel = pTunnel->next_user_lsp_tunnel;
+    }
+    zlog_info("leaving TearDownAndRemoveSecondary");
+}
+
+void CalculateUnneededPathAndTearDown(USER_LSP *pUserLsp,USER_LSP *pCurrentUserLsp)
+{
+    SECONDARY_PATH_LIST *pSecList,*pSecList2,*pSecListPrev,*pSecListNext,*pSecListPrev2;
+    uns32 SecTunnelsCount = 0,SecPathCount = 0,SecTunnels2BeTorn = 0;
+    BOOL Found;
+    RSVP_TUNNEL_PROPERTIES *pTunnel;
+                
+    zlog_info("entering CalculateUnneededPathAndTearDown");
+
+
+    pSecList = pUserLsp->params.SecondaryPaths;
+    pSecListPrev = NULL;
+    while(pSecList != NULL)
+    {
+        zlog_info("Received: %s %s",pSecList->Secondary,(pSecList->SecondaryPathParams) ? ((pSecList->SecondaryPathParams->disable) ? "is disabled" : "") : "");
+        pSecListNext = pSecList->next;
+        if((pSecList->SecondaryPathParams != NULL)&&
+           (pSecList->SecondaryPathParams->disable == TRUE))
+        {
+           pSecList2 = pCurrentUserLsp->params.SecondaryPaths;
+           pSecListPrev2 = NULL;
+           while(pSecList2 != NULL)
+           {
+              zlog_info("Exists: %s",pSecList2->Secondary);
+              if(strcmp(pSecList2->Secondary,pSecList->Secondary) == 0)
+              {
+                 break;
+              }
+              pSecListPrev2 = pSecList2;
+              pSecList2 = pSecList2->next;
+           }
+           if(pSecList2 != NULL)
+           {
+              if(pSecListPrev2 == NULL)
+              {
+                 pCurrentUserLsp->params.SecondaryPaths = pCurrentUserLsp->params.SecondaryPaths->next;
+              }
+              else
+              {
+                 pSecListPrev2->next = pSecList2->next;
+              }
+              XFREE(MTYPE_TE,pSecList2->SecondaryPathParams);
+              XFREE(MTYPE_TE,pSecList2);
+           }
+           if(pSecListPrev == NULL)
+           {
+              pUserLsp->params.SecondaryPaths = pUserLsp->params.SecondaryPaths->next;
+           }
+           else
+           {
+              pSecListPrev->next = pSecList->next;
+           }
+           XFREE(MTYPE_TE,pSecList->SecondaryPathParams);
+           XFREE(MTYPE_TE,pSecList);
+        }
+        else
+        {
+           pSecListPrev = pSecList;
+        }
+        pSecList = pSecListNext;
+    }
+
+    /* find all the secondary LSPs (hot-standby) that must be established */
+    if(pCurrentUserLsp->pUserLspTunnels == NULL)
+    {
+        zlog_err("\nFirst Tunnel ID is NULL %s %d %s",__FILE__,__LINE__,pCurrentUserLsp->params.LspName);
+        return;
+    }
+    pTunnel = pCurrentUserLsp->pUserLspTunnels->next_user_lsp_tunnel;
+    /* First - count all the secondary tunnels */
+    while(pTunnel != NULL)
+    {
+        SecTunnelsCount++;
+        pTunnel = pTunnel->next_user_lsp_tunnel;
+    }
+    /* Second - count all the secondary hot-standby paths for new request */
+    pSecList = pUserLsp->params.SecondaryPaths;
+    while(pSecList != NULL)
+    {
+        if((pSecList->SecondaryPathParams != NULL)&&
+           (pSecList->SecondaryPathParams->standby == TRUE))
+        {
+            SecPathCount++;
+        }
+        pSecList = pSecList->next;
+    }
+    
+    if(SecPathCount >= SecTunnelsCount)
+    {
+        zlog_info("SecPathCount %d SecTunnelsCount %d",SecPathCount,SecTunnelsCount);
+        return; /* There is no "spare" secondary tunnels */
+    }
+
+    /* How many tunnels should be torn down */
+    SecTunnels2BeTorn = SecTunnelsCount - SecPathCount;
+
+    /* set to the start of the list */
+    pTunnel = pCurrentUserLsp->pUserLspTunnels->next_user_lsp_tunnel;
+
+    /* Tear down the calculated number of tunnels */
+    /* Keep tunnels, passing over secondary paths of the new request */
+    while((pTunnel != NULL)&&(SecTunnels2BeTorn > 0))
+    {
+        pSecList = pUserLsp->params.SecondaryPaths;
+        Found = FALSE;
+        while(pSecList != NULL)
+        {
+            if((pSecList->SecondaryPathParams != NULL)&&
+               (pSecList->SecondaryPathParams->standby == TRUE))
+            {
+                if(strcmp(pSecList->Secondary,pTunnel->StaticPathName) == 0)
+                {
+                   Found = TRUE;
+                   break;
+                }
+            }
+            pSecList = pSecList->next;
+        }
+        if(Found == FALSE)
+        {
+            TearDownAndRemoveSecondary(pCurrentUserLsp,pTunnel->StaticPathName);
+            SecTunnels2BeTorn--;
+        }
+        pTunnel = pTunnel->next_user_lsp_tunnel;
+    }
+    zlog_info("leaving CalculateUnneededPathAndTearDown");
+}
+
+SM_CALL_T *PrepareAndIssueCrResolutionRequest(INGRESS_API *pOpenLspParams,
+                                              uns32           AvoidHopNumber,
+                                              IPV4_ADDR    *AvoidHopsArray,
+                                              RSVP_TUNNEL_PROPERTIES *pTunnel,
+                                              SM_T *pSm,
+                                              LSP_PATH_SHARED_PARAMS *pParams)
+{
+    CONSTRAINT_ROUTE_RESOLUTION_ARGS *pCrArgs;
+    SM_CALL_T *pCall = NULL;
+    zlog_info("entering PrepareAndIssueCrResolutionRequest");
+    if((pCrArgs = (CONSTRAINT_ROUTE_RESOLUTION_ARGS *)XMALLOC(MTYPE_TE,sizeof(CONSTRAINT_ROUTE_RESOLUTION_ARGS))) == NULL)
+    {
+        zlog_err("malloc failed %s %d",__FILE__,__LINE__);
+        LspSmDestroy(pSm);
+        return NULL;
+    }
+    pCrArgs->BW = pOpenLspParams->BW;
+    pCrArgs->ExclColorMask = pOpenLspParams->ExcludeAny;
+    pCrArgs->InclAnyColorMask = pOpenLspParams->IncludeAny;
+    pCrArgs->InclColorMask = pOpenLspParams->IncludeAll;
+    zlog_info("preparing CR request1");
+    if(pOpenLspParams->HopNum != 0)
+    {
+        pCrArgs->dest = pOpenLspParams->Path[0].IpAddr;
+    }
+    else
+        pCrArgs->dest = pOpenLspParams->Egress;
+    zlog_info("preparing CR request2 dest %x hop %x %x",pCrArgs->dest,pOpenLspParams->HopNum,pOpenLspParams->Path[0].IpAddr);
+    pCrArgs->PsbKey.Session.Dest = pOpenLspParams->Egress;
+    pCrArgs->PsbKey.Session.TunnelId = pOpenLspParams->TunnelId;
+    pCrArgs->PsbKey.Session.ExtTunelId = pOpenLspParams->src_ip;
+    pCrArgs->AvoidHopNumber = AvoidHopNumber;
+    pCrArgs->AvoidHopsArray = AvoidHopsArray;
+    if(GetAlreadyAllocatedBW(pTunnel,&pCrArgs->pLinkBw,&pCrArgs->LinkBwNumber,pCrArgs->BW) != E_OK)
+    {
+        zlog_err("Cannot get Link BW");
+    }
+    if(pOpenLspParams->ErHops2Exclude[0] != 0)
+    {
+        if(pOpenLspParams->ErHops2Exclude[1] != 0)
+        {
+            pCrArgs->ExcludeHopNumber = 2;
+        }
+        else
+        {
+            pCrArgs->ExcludeHopNumber = 1;
+        }
+        
+        if((pCrArgs->ExcludeHopsArray = (IPV4_ADDR *)XMALLOC(MTYPE_TE,sizeof(IPV4_ADDR)*(pCrArgs->ExcludeHopNumber))) != NULL)
+        {
+            memcpy(pCrArgs->ExcludeHopsArray,
+                   pOpenLspParams->ErHops2Exclude,
+                   sizeof(IPV4_ADDR)*(pCrArgs->ExcludeHopNumber));
+        }
+    }
+    
+    pCrArgs->SetupPriority = pOpenLspParams->SetPrio;
+    pCrArgs->HoldPriority  = pOpenLspParams->HoldPrio;
+    if(pParams != NULL)
+    {
+        pCrArgs->HopCount = pParams->hop_limit;
+    }
+    else
+    {
+        pCrArgs->HopCount = 0;
+    }
+    zlog_info("HOP COUNT#%d",pCrArgs->HopCount);
+    if(pTunnel->pOpenLspParams != NULL)
+    {
+        zlog_info("%s %d",__FILE__,__LINE__);
+        XFREE(MTYPE_TE,pTunnel->pOpenLspParams);
+    }
+    zlog_info("%s %d",__FILE__,__LINE__);
+    pTunnel->pOpenLspParams = pOpenLspParams;
+    if(pTunnel->pCrArgs != NULL)
+    {
+        if((((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->tunneled == FALSE)&&
+           (((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->data.path.ErHopNumber != 0))
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->data.path.pErHop);
+        }
+        if(((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->AvoidHopNumber != 0)
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->AvoidHopsArray);
+        }
+        if(((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->ExcludeHopNumber != 0)
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->ExcludeHopsArray);
+        }
+        if(((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->LinkBwNumber)
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->pLinkBw);
+        }
+        XFREE(MTYPE_TE,pTunnel->pCrArgs);
+    }
+    pTunnel->pCrArgs = pCrArgs;
+
+    if(StartCspfRetryTimer(pTunnel) != E_OK)
+    {
+        zlog_err("Cannot start CSPF retry timer");
+    }
+    UnregisterClient((int)pSm,pOpenLspParams->TunnelId);
+
+    zlog_info("preparing CR request5");
+    if((pCall = constraint_route_resolution_sm_invoke(pSm,
+                                                      pCrArgs)) == NULL)
+    {
+        zlog_err("cannot invoke constraint route resolution");
+        XFREE(MTYPE_TE,pCrArgs);
+        LspSmDestroy(pSm);
+        return NULL;
+    }
+    zlog_info("leaving PrepareAndIssueCrResolutionRequest");
+    return pCall;
+}
+
+SM_CALL_T *LspRequest(INGRESS_API *pOpenLspParams,
+                      uns32       ExcludeHopNumber,
+                      IPV4_ADDR   *ExcludeHopsArray,
+                      SM_T    *pSm,
+                      RSVP_TUNNEL_PROPERTIES **ppTunnel,
+                      BOOL        ForceCrResolution,
+                      LSP_PATH_SHARED_PARAMS *pParams)
+{
+    SM_CALL_T *pCall = NULL;
+    PSB_KEY PsbKey;
+    RSVP_TUNNEL_PROPERTIES *pTunnel;
+    
+    zlog_info("entering LspRequest");
+
+    memset(&PsbKey,0,sizeof(PSB_KEY));
+    PsbKey.Session.Dest = pOpenLspParams->Egress;
+    PsbKey.Session.TunnelId  = pOpenLspParams->TunnelId;
+    PsbKey.Session.ExtTunelId = pOpenLspParams->src_ip;
+
+    if(FindTunnel(&PsbKey,&pTunnel,ALL_TRUNKS) != TRUE)
+    {
+        TRUNK_TYPE trunk_type;
+        if(pOpenLspParams->sm_handle != 0)
+        {
+            switch(((SM_T *)pOpenLspParams->sm_handle)->sm_type)
+            {
+            default:
+                trunk_type = SEPARATE_NON_ADAPTIVE;
+            }
+        }
+        else
+        {
+            trunk_type = SEPARATE_NON_ADAPTIVE;
+        }
+        if(NewTunnel(&PsbKey,&pTunnel,trunk_type) != E_OK)
+        {
+            zlog_err("cannot create new tunnel's structure");
+            LspSmDestroy(pSm);
+            return NULL;
+        }
+        if(pOpenLspParams->sm_handle != 0)
+        {
+            switch(((SM_T *)pOpenLspParams->sm_handle)->sm_type)
+            {
+            case FAST_REROUTE_SM:
+                pTunnel->up_sm_handle = (void *)pOpenLspParams->sm_handle;
+                break;
+            default:
+                ;
+            }
+        }
+        *ppTunnel = pTunnel;
+        pTunnel->RequiredBW = pOpenLspParams->BW;
+        pTunnel->sm_handle = pSm;
+
+        return PrepareAndIssueCrResolutionRequest(pOpenLspParams,
+                                                  ExcludeHopNumber,
+                                                  ExcludeHopsArray,
+                                                  pTunnel,
+                                                  pSm,
+                                                  pParams);
+    }
+    else if(pOpenLspParams->HopNum != 0) /* Possible REROUTE */
+    {
+        *ppTunnel = pTunnel;
+        pTunnel->RequiredBW = pOpenLspParams->BW;
+        pTunnel->sm_handle = pSm;
+        return PrepareAndIssueCrResolutionRequest(pOpenLspParams,
+            ExcludeHopNumber,
+            ExcludeHopsArray,
+            pTunnel,
+            pSm,
+            pParams);
+    }
+    else
+    {
+        RSVP_LSP_PROPERTIES *pRsvpLsp = GetWorkingRsvpLsp(pTunnel);
+
+        *ppTunnel = pTunnel;
+
+        pTunnel->sm_handle = pSm;
+           
+        /* BW DECREASE OPERATION */
+        if(pTunnel->RequiredBW > pOpenLspParams->BW)
+        {
+            /* For tunneled LSPs */
+            if((pRsvpLsp != NULL)&&
+                (pRsvpLsp->tunneled == TRUE))
+            {
+                /* invoke lsp sm for the tunnel */
+            }
+
+            NotifySatisfiedRequests(pTunnel);
+                           
+                  
+            if(ForceCrResolution == TRUE)
+            {
+                pTunnel->RequiredBW = pOpenLspParams->BW;
+                return PrepareAndIssueCrResolutionRequest(pOpenLspParams,
+                    ExcludeHopNumber,
+                    ExcludeHopsArray,
+                    pTunnel,
+                    pSm,
+                    pParams);
+            }
+            else
+            {
+                if(NewRsvpLspRequired(pTunnel,pOpenLspParams) == TRUE)
+                {
+                    if(((pRsvpLsp != NULL)&&(pRsvpLsp->RequestedBW >= pOpenLspParams->BW))||(pRsvpLsp == NULL))
+                    {
+                        pTunnel->pOpenLspParams = pOpenLspParams;
+                        if(CreateAndInvokeRsvpLsp(pTunnel,
+                                                  pRsvpLsp,
+                                                  FALSE,
+                                                  NULL) != E_OK) 
+                        {
+                            zlog_err("cannot modify LSP %s %d",__FILE__,__LINE__);
+                        }
+                    }
+                    else
+                    {
+                        RSVP_LSP_PROPERTIES *pRsvpLsp2TakePath;
+                        if((pRsvpLsp2TakePath = FindRsvpLspPathWithBW(pTunnel,pOpenLspParams->BW)) == NULL)
+                        {
+                            zlog_err("unexpected: cannot find path with BW %s %d",__FILE__,__LINE__);
+                            return NULL;
+                        }
+                        pTunnel->pOpenLspParams = pOpenLspParams;
+                        if(CreateAndInvokeRsvpLsp(pTunnel,
+                                                  pRsvpLsp2TakePath,
+                                                  FALSE,
+                                                  NULL) != E_OK) 
+                        {
+                            zlog_err("cannot modify LSP %s %d",__FILE__,__LINE__);
+                        }
+                    }
+                    pTunnel->RequiredBW = pOpenLspParams->BW;
+                }
+            }
+        }
+        else /* BW INCREASE OPERATION */
+        {
+            RSVP_LSP_PROPERTIES *pWorkingRsvpLsp;
+
+            if((pRsvpLsp != NULL)&&
+               (pRsvpLsp->tunneled == TRUE))
+            {
+                return PrepareAndIssueCrResolutionRequest(pOpenLspParams,
+                    ExcludeHopNumber,
+                    ExcludeHopsArray,
+                    pTunnel,
+                    pSm,
+                    pParams);
+            }
+
+            if(((pWorkingRsvpLsp = CurrentPathHasAvBw(pTunnel,pOpenLspParams->BW)) != NULL)&&
+                (ForceCrResolution == FALSE))
+            {
+                int i;
+                zlog_info("Path is extendable.");
+                /* pRsvpLsp's path is choosen */
+                pOpenLspParams->HopNum = pWorkingRsvpLsp->forw_info.path.HopCount;
+                for(i = 0;i < pOpenLspParams->HopNum;i++)
+                {
+                    pOpenLspParams->Path[i].Loose = 0;
+                    pOpenLspParams->Path[i].IpAddr = pWorkingRsvpLsp->forw_info.path.pErHopsList[i];
+                    pOpenLspParams->Path[i].PrefixLength = 32;
+                }
+            }
+            pTunnel->RequiredBW = pOpenLspParams->BW;
+            zlog_info("Issuing CR Resolution request...");
+            return PrepareAndIssueCrResolutionRequest(pOpenLspParams,
+                ExcludeHopNumber,
+                ExcludeHopsArray,
+                pTunnel,
+                pSm,
+                pParams);
+        }
+    }
+    return pCall;
+}
+
+BOOL NewRsvpLspRequired(RSVP_TUNNEL_PROPERTIES *pTunnel,INGRESS_API *pOpenLspParams)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties;
+
+    zlog_info("entering NewRsvpLspRequired");
+
+    while(pRsvpLsp != NULL)
+    {
+        if(pRsvpLsp->RequestedBW == pOpenLspParams->BW)
+        {
+            zlog_info("leaving NewRsvpLspRequired");
+            return FALSE;
+        }
+        pRsvpLsp = pRsvpLsp->next;
+    }
+    zlog_info("leaving NewRsvpLspRequired");
+    return TRUE;
+}
+
+RSVP_LSP_PROPERTIES *FindRsvpLspPathWithBW(RSVP_TUNNEL_PROPERTIES *pTunnel,float BW)
+{
+    float TempBW = 0xFFFFFFFF; /* FIXME*/
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties,*pSelectedRsvpLsp = NULL;
+
+    zlog_info("entering FindRsvpLspPathWithBW");
+
+    while(pRsvpLsp != NULL)
+    {
+        if(pRsvpLsp->RequestedBW >= BW)
+        {
+            if(pRsvpLsp->RequestedBW < TempBW)
+            {
+                pSelectedRsvpLsp = pRsvpLsp;
+                TempBW = pRsvpLsp->RequestedBW;
+            }
+        }
+        pRsvpLsp = pRsvpLsp->next;
+    }
+    zlog_info("leaving FindRsvpLspPathWithBW");
+    return pSelectedRsvpLsp;
+}
+
+void NotifySatisfiedRequests(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    zlog_info("entering NotifySatisfiedRequests");
+    if(pTunnel->up_sm_handle != 0)
+    {
+        if(sm_gen_async_event_send(pTunnel->up_sm_handle,INGRESS_LSP_OPERATION_COMPLETE_EVENT,NULL) != 0)
+        {
+            zlog_err("\ncannot send async event %s %d",__FILE__,__LINE__);
+        }
+    }
+    zlog_info("leaving NotifySatisfiedRequests");
+}
+
+void NotifyFailedRequests(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    zlog_info("entering NotifyFailedRequests");
+
+    if(pTunnel->up_sm_handle != 0)
+    {
+        if(sm_gen_async_event_send(pTunnel->up_sm_handle,INGRESS_LSP_OPERATION_FAILED_EVENT,NULL) != 0)
+        {
+            zlog_err("\ncannot send async event %s %d",__FILE__,__LINE__);
+        }
+    }
+    zlog_info("leaving NotifyFailedRequests");
+}
+
+uns16 NewRsvpLspId(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    if(pTunnel->LastInvokedLspId == 0xFFFF)
+        pTunnel->LastInvokedLspId = 1;
+    else
+        pTunnel->LastInvokedLspId++;
+    return pTunnel->LastInvokedLspId;
+}
+
+uns32 CopyRsvpLspPath(RSVP_LSP_PROPERTIES *pRsvpLsp,INGRESS_API *pOpenRsvpLsp)
+{
+    zlog_info("entering CopyRsvpLspPath");
+    if(pOpenRsvpLsp->HopNum != 0)
+    {
+        IPV4_ADDR *pArray;
+        int i;
+
+        if((pArray = (IPV4_ADDR *)XMALLOC(MTYPE_TE,sizeof(IPV4_ADDR)*pOpenRsvpLsp->HopNum)) == NULL)
+        {
+            zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+            return E_ERR;
+        }
+          
+        for(i = 0;i < pOpenRsvpLsp->HopNum;i++)
+        {
+            *(pArray + i) = pOpenRsvpLsp->Path[i].IpAddr;
+        }
+        pRsvpLsp->forw_info.path.pErHopsList = pArray;
+    }
+    else
+        pRsvpLsp->forw_info.path.pErHopsList = NULL;
+    pRsvpLsp->forw_info.path.HopCount = pOpenRsvpLsp->HopNum;
+    pRsvpLsp->oIfIndex = pOpenRsvpLsp->OutIfIndex;
+    zlog_info("leaving CopyRsvpLspPath");
+    return E_OK;
+}
+
+RSVP_LSP_PROPERTIES *GetWorkingRsvpLsp(RSVP_TUNNEL_PROPERTIES *pTunnel)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties;
+
+    zlog_info("entering GetWorkingRsvpLsp");
+
+    while(pRsvpLsp != NULL)
+    {
+        if(pRsvpLsp->LspId == pTunnel->LspId)
+            return pRsvpLsp;
+        pRsvpLsp = pRsvpLsp->next;
+    }
+    zlog_info("leaving GetWorkingRsvpLsp");
+    return NULL;
+}
+
+uns32 CopyWorkingPath(RSVP_LSP_PROPERTIES *pDestRsvpLsp,RSVP_LSP_PROPERTIES *pSourceRsvpLsp)
+{
+    IPV4_ADDR *pArray;
+    int i;
+
+    zlog_info("entering CopyWorkingPath");
+
+    if((pArray = (IPV4_ADDR *)XMALLOC(MTYPE_TE,sizeof(IPV4_ADDR)*pSourceRsvpLsp->forw_info.path.HopCount)) == NULL)
+    {
+        zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+        return E_ERR;
+    }
+          
+    for(i = 0;i < pSourceRsvpLsp->forw_info.path.HopCount;i++)
+    {
+        *(pArray + i) = pSourceRsvpLsp->forw_info.path.pErHopsList[i];
+    }
+    pDestRsvpLsp->forw_info.path.pErHopsList = pArray;
+    pDestRsvpLsp->forw_info.path.HopCount = pSourceRsvpLsp->forw_info.path.HopCount;
+//    pDestRsvpLsp->card = pSourceRsvpLsp->card;
+    pDestRsvpLsp->oIfIndex = pSourceRsvpLsp->oIfIndex;
+    zlog_info("leaving CopyWorkingPath");
+    return E_OK;
+}
+
+BOOL IdenticalRsvpLspExists(RSVP_TUNNEL_PROPERTIES *pTunnel,RSVP_LSP_PROPERTIES *pThisRsvpLsp,uns16 *LspDiffPathSameParams)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties;
+
+    zlog_info("entering IdenticalRsvpLspExists");
+
+    while(pRsvpLsp != NULL)
+    {
+        if(pRsvpLsp->LspId != pThisRsvpLsp->LspId)
+        {
+            if((pRsvpLsp->RequestedBW == pThisRsvpLsp->RequestedBW)&&
+                //(pRsvpLsp->card == pThisRsvpLsp->card)&&
+                (pRsvpLsp->oIfIndex == pThisRsvpLsp->oIfIndex)&&
+                (pRsvpLsp->SetupPriority == pThisRsvpLsp->SetupPriority)&&
+                (pRsvpLsp->HoldPriority == pThisRsvpLsp->HoldPriority)&&
+                (pRsvpLsp->ExcludeAny == pThisRsvpLsp->ExcludeAny)&&
+                (pRsvpLsp->IncludeAny == pThisRsvpLsp->IncludeAny)&&
+                (pRsvpLsp->IncludeAll == pThisRsvpLsp->IncludeAll)&&
+                (pRsvpLsp->FrrDesired == pThisRsvpLsp->FrrDesired)&&
+                (pRsvpLsp->LabelRecordingDesired == pThisRsvpLsp->LabelRecordingDesired))
+            {
+                *LspDiffPathSameParams = pRsvpLsp->LspId;
+                if((pRsvpLsp->tunneled == FALSE)&&
+                    (pThisRsvpLsp->tunneled == FALSE))
+                {
+                    if((pRsvpLsp->forw_info.path.HopCount == pThisRsvpLsp->forw_info.path.HopCount)&&
+                        (memcmp(pRsvpLsp->forw_info.path.pErHopsList,
+                                pThisRsvpLsp->forw_info.path.pErHopsList,
+                                sizeof(IPV4_ADDR)*(pRsvpLsp->forw_info.path.HopCount)) == 0))
+                    {
+                        return TRUE;
+                    }
+                }
+                else if((pRsvpLsp->tunneled == TRUE)&&
+                    (pThisRsvpLsp->tunneled == TRUE))
+                {
+                    if(memcmp(&pRsvpLsp->forw_info.tunnel,&pThisRsvpLsp->forw_info.tunnel,sizeof(PSB_KEY)) == 0)
+                    {
+                        return TRUE;
+                    }
+                }
+            }
+        }
+        pRsvpLsp = pRsvpLsp->next;
+    }
+    zlog_info("leaving IdenticalRsvpLspExists");
+    return FALSE;
+}
+
+void UpdatePathBW(RSVP_TUNNEL_PROPERTIES *pTunnel,RSVP_LSP_PROPERTIES *pCurrentRsvpLsp,IPV4_ADDR dest)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties;
+    uns16 LspId = pCurrentRsvpLsp->LspId;
+    float *BWs;
+    int lsp_hop_index,curr_lsp_hop_index,number_of_links,i;
+    IPV4_ADDR lsp_local_ip,lsp_remote_ip,current_lsp_local_ip,current_lsp_remote_ip;
+
+    zlog_info("entering UpdatePathBW");
+
+    if(pRsvpLsp->tunneled == TRUE)
+    {
+        return;
+    }
+    number_of_links = pCurrentRsvpLsp->forw_info.path.HopCount / 2;
+    if((BWs = (float *)XMALLOC(MTYPE_TE,sizeof(float)*(number_of_links))) == NULL)
+    {
+        zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+        return;
+    }
+    
+    while(pRsvpLsp != NULL)
+    {
+        if((pRsvpLsp->LspId != LspId)&&
+           (pRsvpLsp->tunneled == FALSE)&&
+           (pRsvpLsp->HoldPriority <= pCurrentRsvpLsp->HoldPriority))
+        {
+            for(lsp_hop_index = 1;
+                lsp_hop_index < pRsvpLsp->forw_info.path.HopCount;
+                lsp_hop_index += 2)
+            {
+                for(curr_lsp_hop_index = 1,i = 0;
+                    (curr_lsp_hop_index < (pCurrentRsvpLsp->forw_info.path.HopCount - 1))&&(i <  number_of_links);
+                    curr_lsp_hop_index += 2,i++)
+                {
+                    lsp_local_ip = pRsvpLsp->forw_info.path.pErHopsList[lsp_hop_index];
+                    current_lsp_local_ip = pCurrentRsvpLsp->forw_info.path.pErHopsList[curr_lsp_hop_index];
+                    if(lsp_local_ip == current_lsp_local_ip)
+                    {
+                        lsp_remote_ip = pRsvpLsp->forw_info.path.pErHopsList[lsp_hop_index + 1];
+                        current_lsp_remote_ip = pCurrentRsvpLsp->forw_info.path.pErHopsList[curr_lsp_hop_index + 1];
+                        if(lsp_remote_ip == current_lsp_remote_ip)
+                        {
+                            if(BWs[i] < pRsvpLsp->RequestedBW)
+                            {
+                                BWs[i] = pRsvpLsp->RequestedBW;
+                            }
+                        }
+                    }
+                }
+            }
+        }
+        pRsvpLsp = pRsvpLsp->next;
+    }
+    for(curr_lsp_hop_index = 1,i = 0;
+        (curr_lsp_hop_index < (pCurrentRsvpLsp->forw_info.path.HopCount - 1))&&(i < number_of_links);
+        curr_lsp_hop_index += 2,i++)
+    {
+        if(BWs[i] < pCurrentRsvpLsp->RequestedBW)
+        {
+            IPV4_ADDR *pIpAddrArray = pCurrentRsvpLsp->forw_info.path.pErHopsList;
+            IPV4_ADDR remote_ip = pIpAddrArray[curr_lsp_hop_index + 1];
+            if(pIpAddrArray[curr_lsp_hop_index] != remote_ip)
+            {
+                zlog_info("Updating BW#%f  Local IP#%x Remote IP#%x",
+                       pCurrentRsvpLsp->RequestedBW - BWs[i],
+                       pCurrentRsvpLsp->forw_info.path.pErHopsList[curr_lsp_hop_index],
+                       pCurrentRsvpLsp->forw_info.path.pErHopsList[curr_lsp_hop_index + 1]);
+                if(rdb_remote_link_bw_update(pCurrentRsvpLsp->forw_info.path.pErHopsList[curr_lsp_hop_index],
+                                                  pCurrentRsvpLsp->forw_info.path.pErHopsList[curr_lsp_hop_index + 1],
+                                                  pCurrentRsvpLsp->RequestedBW - BWs[i],
+                                                  pCurrentRsvpLsp->HoldPriority, /* SHOULD BE CHECKED!!!*/
+                                                  PSC_PATH) != E_OK)
+                {
+                    zlog_err("\ncannot update remote link %s %d",__FILE__,__LINE__);
+                }
+            }
+        }
+    }
+    zlog_info("leaving UpdatePathBW");
+    XFREE(MTYPE_TE,BWs);
+}
+
+static E_RC GetAlreadyAllocatedBW(RSVP_TUNNEL_PROPERTIES *pTunnel,void **ppLinkBw,uns32 *LinkBwNumber,float CommonBwValue)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp;
+    LINK_BW *pLinkBw;
+    int curr_lsp_hop_index,i,number_of_links;
+    float Bw;
+    zlog_info("entering GetAlreadyAllocatedBW");
+    *ppLinkBw = NULL;
+    if((pRsvpLsp = GetWorkingRsvpLsp(pTunnel)) == NULL)
+    {
+        return E_OK;
+    }
+    if(pRsvpLsp->tunneled)
+    {
+        return E_OK;
+    }
+    if(pRsvpLsp->forw_info.path.HopCount < 2)
+    {
+        return E_OK;
+    }
+    number_of_links = pRsvpLsp->forw_info.path.HopCount / 2;
+    if((pLinkBw = XMALLOC(MTYPE_TE,sizeof(LINK_BW)*(number_of_links))) == NULL)
+    {
+        zlog_err("Memory allocation failed %s %d",__FILE__,__LINE__);
+        return E_ERR;
+    }
+    if(pRsvpLsp->RequestedBW < CommonBwValue)
+    {
+        Bw = CommonBwValue - pRsvpLsp->RequestedBW;
+    }
+    else
+    {
+        Bw = 0;
+    }
+    for(curr_lsp_hop_index = 1,i = 0;
+        (curr_lsp_hop_index < pRsvpLsp->forw_info.path.HopCount)&&(i < number_of_links);
+        curr_lsp_hop_index += 2,i++)
+    {
+        pLinkBw[i].LocalIp.s_addr = pRsvpLsp->forw_info.path.pErHopsList[curr_lsp_hop_index];
+        pLinkBw[i].RemoteIp.s_addr = pRsvpLsp->forw_info.path.pErHopsList[curr_lsp_hop_index + 1];
+        pLinkBw[i].Bw = Bw;
+    }
+    *ppLinkBw = pLinkBw;
+    *LinkBwNumber = number_of_links;
+    zlog_info("leaving GetAlreadyAllocatedBW");
+    return E_OK;
+}
+
+uns32 CreateAndInvokeRsvpLsp(RSVP_TUNNEL_PROPERTIES *pTunnel,
+                             RSVP_LSP_PROPERTIES *pRsvpLsp2TakePath,
+                             BOOL tunneled,
+                             PSB_KEY *PsbKey)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = NULL,*pRsvpWorkingLsp = NULL;
+    uns16 LspId = 0;
+    TE_API_MSG Msg;
+    INGRESS_API *pOpenRsvpLsp;
+    uns16 LspDiffPathSameParams = 0,RemoveLspAndExit = 0;
+    USER_LSP *pUserLsp;
+  
+    zlog_info("entering CreateAndInvokeRsvpLsp");
+      
+    pOpenRsvpLsp = pTunnel->pOpenLspParams;
+
+    LspId = NewRsvpLspId(pTunnel);
+
+    if(NewRsvpLsp(pTunnel,&pRsvpLsp) != E_OK)
+    {
+        zlog_err("\ncannot create and invoke RSVP LSP %s %d",__FILE__,__LINE__);
+        return E_ERR;
+    }
+    pRsvpLsp->RequestedBW = pOpenRsvpLsp->BW;
+
+    pRsvpLsp->LspId = LspId;
+    zlog_info("\nTunnel # %x LSP # %x",pTunnel->TunnelId,pRsvpLsp->LspId);
+    pOpenRsvpLsp->LspId = LspId;
+
+    pRsvpLsp->SetupPriority = pOpenRsvpLsp->SetPrio;
+    pRsvpLsp->HoldPriority = pOpenRsvpLsp->HoldPrio;
+    pRsvpLsp->ExcludeAny = pOpenRsvpLsp->ExcludeAny;
+    pRsvpLsp->IncludeAny = pOpenRsvpLsp->IncludeAny;
+    pRsvpLsp->IncludeAll = pOpenRsvpLsp->IncludeAll;
+    pRsvpLsp->FrrDesired = pOpenRsvpLsp->FrrDesired;
+    pRsvpLsp->LabelRecordingDesired = pOpenRsvpLsp->LabelRecordingDesired;
+
+    if(pRsvpLsp2TakePath == NULL)
+    {
+        if(tunneled == TRUE)
+        {
+            pRsvpLsp->tunneled = TRUE;
+            pRsvpLsp->forw_info.tunnel = *PsbKey;
+            pRsvpLsp->oIfIndex = pOpenRsvpLsp->OutIfIndex;
+            zlog_info("\nTunneled LSP: %x %x %x %x %x %x %x",
+                pOpenRsvpLsp->Egress,
+                pOpenRsvpLsp->TunnelId,
+                pOpenRsvpLsp->src_ip,
+                pOpenRsvpLsp->LspId,
+                pOpenRsvpLsp->OutIfIndex,
+                pOpenRsvpLsp->NextHop);
+        }
+        else if(CopyRsvpLspPath(pRsvpLsp,pOpenRsvpLsp) != E_OK)
+        {
+            zlog_err("\ncannot copy RSVP LSP path %s %d",__FILE__,__LINE__);
+            return E_ERR;
+        }
+    }
+    else
+    {
+        zlog_info("\ncopying working path");
+        if(CopyWorkingPath(pRsvpLsp,pRsvpLsp2TakePath) != E_OK)
+        {
+            zlog_err("\ncannot copy RSVP LSP path %s %d",__FILE__,__LINE__);
+            return E_ERR;
+        }
+        if(pRsvpLsp->tunneled == FALSE)
+        {
+            pOpenRsvpLsp->HopNum = pRsvpLsp->forw_info.path.HopCount;
+            if(pRsvpLsp->forw_info.path.HopCount != 0)
+            {
+                int i;
+                for(i = 0;i < pOpenRsvpLsp->HopNum;i++)
+                {
+                    pOpenRsvpLsp->Path[i].Loose = 0;
+                    pOpenRsvpLsp->Path[i].PrefixLength = 32;
+                    pOpenRsvpLsp->Path[i].IpAddr = pRsvpLsp->forw_info.path.pErHopsList[i];
+                }
+                pOpenRsvpLsp->NextHop = pRsvpLsp->forw_info.path.pErHopsList[0];
+            }
+            else
+            {
+                zlog_info("\nER hops list is empty %s %d",__FILE__,__LINE__);
+            }
+            pOpenRsvpLsp->NextHop = pRsvpLsp->forw_info.path.pErHopsList[0];
+        }
+        else
+        {
+            pOpenRsvpLsp->NextHop = pRsvpLsp->forw_info.tunnel.Session.Dest;
+        }
+        pOpenRsvpLsp->OutIfIndex = pRsvpLsp->oIfIndex;
+    }
+        
+    UpdatePathBW(pTunnel,pRsvpLsp,pOpenRsvpLsp->Egress);
+    
+    if(IdenticalRsvpLspExists(pTunnel,pRsvpLsp,&LspDiffPathSameParams) == TRUE)
+    {
+        RemoveLspAndExit = 1;
+    }
+    else if(LspDiffPathSameParams)
+    {
+        if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != NULL)
+        {
+            STATIC_PATH *pStaticPath;
+            if((pUserLsp->pUserLspTunnels != NULL)&&
+               (pTunnel->TunnelId != pUserLsp->pUserLspTunnels->TunnelId)&&
+               (rdb_get_static_path(pTunnel->StaticPathName,&pStaticPath) != E_OK))
+            {
+                IPV4_ADDR *pPrimaryErHops;
+                uns32 PrimaryErHopsNumber = 0;
+                RSVP_LSP_PROPERTIES *pClone = pTunnel->properties;
+                while(pClone != NULL)
+                {
+                    if(pClone->LspId == LspDiffPathSameParams)
+                    {
+                        break;
+                    }
+                    pClone = pClone->next;
+                }
+                if((pClone != NULL)&&(!pClone->tunneled)&&(!pRsvpLsp->tunneled))
+                {
+                   if(GetTunnelHops(pUserLsp->pUserLspTunnels,&PrimaryErHopsNumber,&pPrimaryErHops) == E_OK)
+                   {
+                      int i,j,ClonesSharedHopsCount = 0,ThisLspSharedHopsCount = 0;
+                      if(pPrimaryErHops != NULL)
+                      {
+                          for(i = 0,j = 0;i < PrimaryErHopsNumber;i++,j += 2)
+                          {
+                              if(pPrimaryErHops[i] == pClone->forw_info.path.pErHopsList[j])
+                              {
+                                  ClonesSharedHopsCount++;
+                              }
+                          }
+                          for(i = 0,j = 0;i < PrimaryErHopsNumber;i++,j += 2)
+                          {
+                              if(pPrimaryErHops[i] == pRsvpLsp->forw_info.path.pErHopsList[j])
+                              {
+                                  ThisLspSharedHopsCount++;
+                              }
+                          }
+                          if(ThisLspSharedHopsCount >= ClonesSharedHopsCount)
+                          {
+                              RemoveLspAndExit = 1;
+                          }
+                          XFREE(MTYPE_TE,pPrimaryErHops);
+                      }
+                   }
+                }
+            }
+        }
+    }
+    if(RemoveLspAndExit)
+    {
+        RSVP_LSP_PROPERTIES *pTemp = pTunnel->properties,*pRsvpLspPrev = NULL;
+        while(pTemp != NULL)
+        {
+            if(pTemp == pRsvpLsp)
+            {
+                if(pTemp == pTunnel->properties)
+                {
+                    pTunnel->properties = pTunnel->properties->next;
+                }
+                else
+                {
+                    pRsvpLspPrev->next = pTemp->next;
+                }
+                if(pRsvpLsp->tunneled == FALSE)
+                {
+                    if(pRsvpLsp->forw_info.path.pErHopsList != NULL)
+                    {
+                        XFREE(MTYPE_TE,pRsvpLsp->forw_info.path.pErHopsList);
+                    }
+                }
+                XFREE(MTYPE_TE,pRsvpLsp);
+                if(pTunnel->adaptivity_timer.is_active == FALSE)
+                {
+                    if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != NULL)
+                    {
+                        LSP_PATH_SHARED_PARAMS *pParams;
+                        pParams = PathParamsGet(pUserLsp,
+                                                pTunnel->StaticPathName,
+                                                ((!strcmp(pUserLsp->params.Primary,pTunnel->StaticPathName))&&(pUserLsp->pUserLspTunnels->TunnelId == pTunnel->TunnelId)));
+                        StartAdaptivityTimer(pParams->optimize_timer,pTunnel);
+                    }
+                }
+                return E_OK;
+            }
+            pRsvpLspPrev = pTemp;
+            pTemp = pTemp->next;
+        }
+    }
+    if(pRsvpLsp->tunneled == FALSE)
+    {
+        int i;
+        IPV4_ADDR  *pIpAddr = pRsvpLsp->forw_info.path.pErHopsList;
+        zlog_info("\nPATH:");
+        for(i = 0;i < pRsvpLsp->forw_info.path.HopCount;i++)
+            zlog_info("\nER HOP#%d %x",i+1,pIpAddr[i]);
+    }
+    Msg.NotificationType = PATH_SEND_CMD;
+    memcpy(&Msg.u.IngressApi,pOpenRsvpLsp,sizeof(INGRESS_API));
+    if((pRsvpWorkingLsp = GetWorkingRsvpLsp(pTunnel)) != NULL)
+    {
+        if((pRsvpLsp->tunneled == FALSE)&&
+            (pRsvpWorkingLsp->tunneled == FALSE))
+        {
+            if(!((pRsvpLsp->forw_info.path.HopCount == pRsvpWorkingLsp->forw_info.path.HopCount)&&
+                (memcmp(pRsvpLsp->forw_info.path.pErHopsList,
+                    pRsvpWorkingLsp->forw_info.path.pErHopsList,
+                    sizeof(IPV4_ADDR)*(pRsvpLsp->forw_info.path.HopCount)) == 0)))
+                pTunnel->ReRoute = TRUE;
+        }
+    }
+    else
+    {
+        pTunnel->ReRoute = TRUE;
+    }
+    Msg.u.IngressApi.LspId = LspId;
+    Msg.u.IngressApi.NextHop = htonl(Msg.u.IngressApi.NextHop);
+
+    zlog_info("Next Hop %x OutIf %x %s %d",
+           Msg.u.IngressApi.NextHop,Msg.u.IngressApi.OutIfIndex,__FILE__,__LINE__);
+
+    te_send_msg(&Msg,sizeof(Msg));
+
+    StartLspSetupTimer(pTunnel);
+
+    if((pOpenRsvpLsp->FrrDesired)&&
+        (pRsvpLsp->tunneled == FALSE)&&   /* if tunneled, the tunnel should be reestablished with local protection */
+        (pOpenRsvpLsp->HopNum > 1))
+    {
+        FRR_SM_CALL frr_sm_call;
+        int k;
+        IPV4_ADDR protected_node_router_id = 0,merge_node_router_id = 0,after_merge_node_router_id = 0;
+
+        memset(&frr_sm_call,0,sizeof(FRR_SM_CALL));
+        frr_sm_call.frr_key.OutIfIndex = pOpenRsvpLsp->OutIfIndex;
+        
+        if(rdb_remote_link_router_id_get(pOpenRsvpLsp->NextHop,
+            &protected_node_router_id) != E_OK)
+        {
+            protected_node_router_id = pOpenRsvpLsp->NextHop;
+        }
+        frr_sm_call.frr_key.protected_node = protected_node_router_id;
+        for(k = 1;k < pOpenRsvpLsp->HopNum;k++)
+        {
+            rdb_remote_link_router_id_get(pOpenRsvpLsp->Path[k].IpAddr,
+                &merge_node_router_id);
+            if((merge_node_router_id != 0)&&
+                (merge_node_router_id != protected_node_router_id))
+            {
+                frr_sm_call.frr_key.merge_node = merge_node_router_id;
+                frr_sm_call.MergeNode = pOpenRsvpLsp->Path[k].IpAddr;
+                break;
+            }
+        }
+        if(frr_sm_call.frr_key.merge_node == 0)
+        {
+            merge_node_router_id = 
+                frr_sm_call.frr_key.merge_node = 
+                pOpenRsvpLsp->Path[1].IpAddr;
+            frr_sm_call.MergeNode = pOpenRsvpLsp->Path[1].IpAddr;
+        }
+        for(;k < pOpenRsvpLsp->HopNum;k++)
+        {
+            rdb_remote_link_router_id_get(pOpenRsvpLsp->Path[k].IpAddr,
+                &after_merge_node_router_id);
+            if((after_merge_node_router_id != 0)&&
+                (after_merge_node_router_id != merge_node_router_id))
+            {
+                frr_sm_call.frr_key.prohibited_penultimate_node = after_merge_node_router_id;
+                break;
+            }
+        }
+        
+        zlog_info("\ncalling FRR SM with key %x %x %x %x",
+            frr_sm_call.frr_key.protected_node,
+            frr_sm_call.frr_key.OutIfIndex,
+            frr_sm_call.frr_key.merge_node,
+            frr_sm_call.frr_key.prohibited_penultimate_node);
+
+        frr_sm_call.PsbKey.Session.Dest = pOpenRsvpLsp->Egress;
+        frr_sm_call.PsbKey.Session.TunnelId = pOpenRsvpLsp->TunnelId;
+        frr_sm_call.PsbKey.Session.ExtTunelId = pOpenRsvpLsp->src_ip;
+        frr_sm_call.PsbKey.SenderTemplate.LspId = pOpenRsvpLsp->LspId;
+#ifdef FRR_SM_DEFINED
+        if((pCall = fast_reroute_sm_sync_invoke(&frr_sm_call,BYPASS_SETUP_REQ_EVENT)) != NULL)
+        {
+            zlog_info("\nOK...");
+            sm_call(pCall);
+        }
+        else
+        {
+            zlog_err("\ncannot invoke FRR SM %s %d",__FILE__,__LINE__);
+        }
+#endif
+    }
+    XFREE(MTYPE_TE,pTunnel->pOpenLspParams);
+    pTunnel->pOpenLspParams = NULL;
+    zlog_info("leaving CreateAndInvokeRsvpLsp");
+    return E_OK;
+}
+
+uns32 RsvpTunnelTearDown(RSVP_TUNNEL_PROPERTIES *pTunnel,IPV4_ADDR dest,IPV4_ADDR source)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties;
+    TE_API_MSG TeApi;
+    PSB_KEY PsbKey;
+  
+    zlog_info("entering RsvpTunnelTearDown");
+      
+    TeApi.NotificationType = PATH_TEAR_CMD;
+    TeApi.u.IngressApi.Egress = dest;
+    TeApi.u.IngressApi.TunnelId = pTunnel->TunnelId;
+    TeApi.u.IngressApi.src_ip = source;
+
+    memset(&PsbKey,0,sizeof(PSB_KEY));
+
+    PsbKey.Session.Dest = dest;
+    PsbKey.Session.TunnelId = pTunnel->TunnelId;
+    PsbKey.Session.ExtTunelId = source;
+
+    while(pRsvpLsp != NULL)
+    {
+        TeApi.u.IngressApi.LspId = pRsvpLsp->LspId;
+        te_send_msg(&TeApi,sizeof(TeApi));
+#if DATA_PLANE
+        {
+           char key[23];
+           USER_LSP *pUserLsp;
+           IPV4_ADDR next_hop = 0;
+           if((pRsvpLsp->tunneled == FALSE)&&(pRsvpLsp->forw_info.path.HopCount != 0))
+           {
+              next_hop = pRsvpLsp->forw_info.path.pErHopsList[0];
+           }
+           sprintf(key,"%x%d%x%d",dest,pTunnel->TunnelId,source,pRsvpLsp->LspId);
+           mplsTeOutLabel(&pRsvpLsp->Label,1,key,next_hop,0);
+           if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != NULL)
+           {
+               if(pUserLsp->params.PolicyName[0] != '\0')
+               {
+                  mplsTePolicy(pUserLsp->params.PolicyName,key,0);
+               }
+           }
+        }
+#endif
+        PsbKey.SenderTemplate.LspId = pRsvpLsp->LspId;
+#ifdef FRR_SM_DEFINED
+        FrrIngressRelease(&PsbKey);
+#endif
+        pRsvpLsp = pRsvpLsp->next;
+    }
+
+    PsbKey.SenderTemplate.LspId = 0;
+    StopAdaptivityTimer(pTunnel);
+    StopLspSetupTimer(pTunnel);
+    StopLspSetupRetryTimer(pTunnel);
+    StopCspfRetryTimer(pTunnel);
+    if(pTunnel->pCrArgs != NULL)
+    {
+        if((((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->tunneled == FALSE)&&
+           (((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->data.path.ErHopNumber != 0))
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->data.path.pErHop);
+        }
+        if(((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->AvoidHopNumber != 0)
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->AvoidHopsArray);
+        }
+        if(((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->ExcludeHopNumber != 0)
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->ExcludeHopsArray);
+        }
+        if(((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->LinkBwNumber)
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->pLinkBw);
+        }
+        XFREE(MTYPE_TE,pTunnel->pCrArgs);
+    }
+    if(pTunnel->pOpenLspParams != NULL)
+    {
+        UnregisterClient((int)pTunnel->sm_handle,
+                         ((INGRESS_API *)(pTunnel->pOpenLspParams))->TunnelId);
+        XFREE(MTYPE_TE,pTunnel->pOpenLspParams);
+    }
+    
+    if(DeleteTunnel(&PsbKey,SEPARATE_NON_ADAPTIVE) != E_OK)
+    {
+        zlog_err("\ncannot delete tunnel %s %d",__FILE__,__LINE__);
+        return E_ERR;
+    }
+    zlog_info("\nTunnel %x deleted",PsbKey.Session.TunnelId);
+    zlog_info("leaving RsvpTunnelTearDown");
+    return E_OK;
+}
+
+void RemoveRsvpLsp(RSVP_TUNNEL_PROPERTIES *pTunnel,uns16 LspId,IPV4_ADDR dest,IPV4_ADDR source)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties,*pRsvpLspNext,*pRsvpLspPrev = NULL;
+    TE_API_MSG TeApi;
+    PSB_KEY PsbKey;
+
+    zlog_info("entering RemoveRsvpLsp");
+
+    memset(&PsbKey,0,sizeof(PSB_KEY));
+    PsbKey.Session.Dest = dest;
+    PsbKey.Session.TunnelId = pTunnel->TunnelId;
+    PsbKey.Session.ExtTunelId = source;
+    
+    while(pRsvpLsp != NULL)
+    {
+        /* tear down all that in the range > Allocated */
+        if(pRsvpLsp->LspId == LspId)
+        {
+            /* tear this lsp down */
+            TeApi.NotificationType = PATH_TEAR_CMD;
+            TeApi.u.IngressApi.Egress = dest;
+            TeApi.u.IngressApi.TunnelId = pTunnel->TunnelId;
+            TeApi.u.IngressApi.src_ip = source;
+            TeApi.u.IngressApi.LspId = pRsvpLsp->LspId;
+            /*                zlog_info("\nsending tear down request to %x for Dest %x Tunnel %d Source %x LSP %x",
+                              pRsvpLsp->card,
+                              dest,
+                              pTunnel->TunnelId,
+                              source,
+                              pRsvpLsp->LspId);*/
+            te_send_msg(&TeApi,sizeof(TeApi));
+#if DATA_PLANE
+            {
+               char key[23];
+               USER_LSP *pUserLsp;
+               IPV4_ADDR next_hop = 0;
+               if((pRsvpLsp->tunneled == FALSE)&&(pRsvpLsp->forw_info.path.HopCount != 0))
+               {
+                  next_hop = pRsvpLsp->forw_info.path.pErHopsList[0];
+               }
+               sprintf(key,"%x%d%x%d",dest,pTunnel->TunnelId,source,pRsvpLsp->LspId);
+               mplsTeOutLabel(&pRsvpLsp->Label,1,key,next_hop,0);
+               if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != NULL)
+               {
+                  if(pUserLsp->params.PolicyName[0] != '\0')
+                  {
+                     mplsTePolicy(pUserLsp->params.PolicyName,key,0);
+                  }
+               }
+            }
+#endif
+            PsbKey.SenderTemplate.LspId = pRsvpLsp->LspId;
+#ifdef FRR_SM_DEFINED
+            FrrIngressRelease(&PsbKey);
+#endif
+            if(pTunnel->LspId == LspId)
+            {
+                pTunnel->LspId = 0;
+            }
+            pRsvpLspNext = pRsvpLsp->next;
+            if(pRsvpLsp->forw_info.path.pErHopsList != NULL)
+            {
+                XFREE(MTYPE_TE,pRsvpLsp->forw_info.path.pErHopsList);
+            }
+            if(pTunnel->properties == pRsvpLsp)
+            {
+                pTunnel->properties = pTunnel->properties->next;
+            }
+            else
+            {
+                pRsvpLspPrev->next = pRsvpLsp->next;
+            }
+            XFREE(MTYPE_TE,pRsvpLsp);
+            pRsvpLsp = pRsvpLspNext;
+        }
+        else
+        {
+            pRsvpLspPrev = pRsvpLsp;
+            pRsvpLsp = pRsvpLsp->next;
+        }
+    }
+    zlog_info("leaving RemoveRsvpLsp");
+}
+
+RSVP_LSP_PROPERTIES *FindRsvpLspByLspId(RSVP_TUNNEL_PROPERTIES *pTunnel,uns16 LspId)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties;
+    while(pRsvpLsp != NULL)
+    {
+        if(pRsvpLsp->LspId == LspId)
+            return pRsvpLsp;
+        pRsvpLsp = pRsvpLsp->next;
+    }
+    return pRsvpLsp;
+}
+
+void FindClosestRsvpLsp(RSVP_TUNNEL_PROPERTIES *pTunnel,
+                        SETUP_COMPLETE *setup_complete,
+                        float *BW,
+                        uns16 *LspId)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp;
+    int i;
+    float Delta;
+    RSVP_LSP_PROPERTIES *pSelectedRsvpLsp = NULL;
+    BOOL GreaterThanRequired;
+
+    zlog_info("entering FindClosestRsvpLsp");
+  
+    if(pTunnel->RequiredBW < setup_complete->BW)
+    {
+        Delta = setup_complete->BW - pTunnel->RequiredBW;
+        GreaterThanRequired = TRUE;
+    }
+    else
+    {
+        Delta = pTunnel->RequiredBW - setup_complete->BW;
+        GreaterThanRequired = FALSE;
+    }
+    for(i = 0;i < setup_complete->NumberOfItems;i++)
+    {
+        pRsvpLsp = FindRsvpLspByLspId(pTunnel,setup_complete->pLspLabel[i].LspId);
+        if(pRsvpLsp == NULL)
+        {
+            continue;
+        }
+        pRsvpLsp->Label = setup_complete->pLspLabel[i].Label;
+        if(GreaterThanRequired == TRUE)
+        {
+            if((pRsvpLsp->RequestedBW > pTunnel->RequiredBW)||
+                ((pRsvpLsp->RequestedBW == pTunnel->RequiredBW)&&(pSelectedRsvpLsp == NULL)))
+            {
+                if((pRsvpLsp->RequestedBW - pTunnel->RequiredBW) <= Delta)
+                {
+                    Delta = pRsvpLsp->RequestedBW - pTunnel->RequiredBW;
+                    pSelectedRsvpLsp = pRsvpLsp;
+                }
+            }
+            else if(pRsvpLsp->RequestedBW == pTunnel->RequiredBW)
+            {
+                if(pSelectedRsvpLsp->LspId != 0xFFFF)
+                {
+                    if(pSelectedRsvpLsp->LspId < pRsvpLsp->LspId)
+                    {
+                        Delta = 0;
+                        pSelectedRsvpLsp = pRsvpLsp;
+                    }
+                }
+                else
+                {
+                    if(pSelectedRsvpLsp->LspId > pRsvpLsp->LspId)
+                    {
+                        Delta = 0;
+                        pSelectedRsvpLsp = pRsvpLsp;
+                    }
+                }
+            }
+        }
+        else
+        {
+            if((pTunnel->RequiredBW > pRsvpLsp->RequestedBW)||
+                ((pTunnel->RequiredBW == pRsvpLsp->RequestedBW)&&(pSelectedRsvpLsp == NULL)))
+            {
+                if((pTunnel->RequiredBW - pRsvpLsp->RequestedBW) <= Delta)
+                {
+                    Delta = pTunnel->RequiredBW - pRsvpLsp->RequestedBW;
+                    pSelectedRsvpLsp = pRsvpLsp;
+                }
+            }
+            else if(pRsvpLsp->RequestedBW == pTunnel->RequiredBW)
+            {
+                if(pSelectedRsvpLsp->LspId != 0xFFFF)
+                {
+                    if(pSelectedRsvpLsp->LspId < pRsvpLsp->LspId)
+                    {
+                        Delta = 0;
+                        pSelectedRsvpLsp = pRsvpLsp;
+                    }
+                }
+                else
+                {
+                    if(pSelectedRsvpLsp->LspId > pRsvpLsp->LspId)
+                    {
+                        Delta = 0;
+                        pSelectedRsvpLsp = pRsvpLsp;
+                    }
+                }
+            }
+        }
+    }
+    if(pSelectedRsvpLsp != NULL)
+    {
+        *BW    = pSelectedRsvpLsp->RequestedBW;
+        *LspId = pSelectedRsvpLsp->LspId;
+    }
+    else
+    {
+        *BW = *LspId = 0;
+    }
+    zlog_info("leaving FindClosestRsvpLsp");
+}
+
+SM_CALL_T *DetermineWorkingLspAndTearUnneeded(RSVP_TUNNEL_PROPERTIES *pTunnel,
+                                              float BW,
+                                              uns16 LspId,
+                                              IPV4_ADDR dest,
+                                              IPV4_ADDR source,
+                                              SM_T *pSm)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties,*pRsvpLspNext,*pRsvpLspPrev = NULL,*pWorkingRsvpLsp = NULL;
+    TE_API_MSG TeApi;
+    LSP_PATH_SHARED_PARAMS *pParams = NULL;
+    PSB_KEY PsbKey;
+    SM_CALL_T *pCall = NULL;
+
+    zlog_info("entering DetermineWorkingLspAndTearUnneeded");
+
+    if(BW == pTunnel->RequiredBW) /* modification complete */
+    {
+        memset(&PsbKey,0,sizeof(PSB_KEY));
+        PsbKey.Session.Dest = dest;
+        PsbKey.Session.TunnelId = pTunnel->TunnelId;
+        PsbKey.Session.ExtTunelId = source;
+
+        while(pRsvpLsp != NULL)
+        {
+            if(pRsvpLsp->LspId == LspId)
+            {
+                pWorkingRsvpLsp = pRsvpLsp;
+            }
+            if((pRsvpLsp->LspId != LspId)&&
+                (!((pRsvpLsp->LspId > LspId)&&(pRsvpLsp->RequestedBW == pTunnel->RequiredBW))))
+            {
+                TeApi.NotificationType = PATH_TEAR_CMD;
+                TeApi.u.IngressApi.Egress = dest;
+                TeApi.u.IngressApi.TunnelId = pTunnel->TunnelId;
+                TeApi.u.IngressApi.src_ip = source;
+                TeApi.u.IngressApi.LspId = pRsvpLsp->LspId;
+
+                zlog_info("\nsending tear down request1 for LSP %x tnl %x dest %x src %x bw %x",
+                    pRsvpLsp->LspId,
+                    pTunnel->TunnelId,
+                    dest,
+                    source,
+                    pRsvpLsp->RequestedBW);
+
+                te_send_msg(&TeApi,sizeof(TeApi));
+#if DATA_PLANE
+                {
+                   char key[23];
+                   USER_LSP *pUserLsp;
+                   IPV4_ADDR next_hop = 0;
+                   if((pRsvpLsp->tunneled == FALSE)&&(pRsvpLsp->forw_info.path.HopCount != 0))
+                   {
+                      next_hop = pRsvpLsp->forw_info.path.pErHopsList[0];
+                   }
+                   sprintf(key,"%x%d%x%d",dest,pTunnel->TunnelId,source,pRsvpLsp->LspId);
+                   zlog_info("delete label %x next hop %x key %s\n",pRsvpLsp->Label,next_hop,key);
+                   mplsTeOutLabel(&pRsvpLsp->Label,1,key,next_hop,0);
+                   if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != NULL)
+                   {
+                       if(pUserLsp->params.PolicyName[0] != '\0')
+                       {
+                           mplsTePolicy(pUserLsp->params.PolicyName,key,0);
+                       }
+                   }
+                }
+#endif
+                PsbKey.SenderTemplate.LspId = pRsvpLsp->LspId;
+#ifdef FRR_SM_DEFINED
+                FrrIngressRelease(&PsbKey);
+#endif
+
+                pRsvpLspNext = pRsvpLsp->next;
+                
+                if(pTunnel->properties == pRsvpLsp)
+                {
+                    pTunnel->properties = pTunnel->properties->next;
+                }
+                else
+                {
+                    pRsvpLspPrev->next = pRsvpLsp->next;
+                }
+                                
+                if((pRsvpLsp->tunneled == FALSE)&&
+                    (pRsvpLsp->forw_info.path.pErHopsList != NULL))
+                {
+                    XFREE(MTYPE_TE,pRsvpLsp->forw_info.path.pErHopsList);
+                }
+                XFREE(MTYPE_TE,pRsvpLsp);
+                
+                pRsvpLsp = pRsvpLspNext;
+            }
+            else
+            {
+                pRsvpLspPrev = pRsvpLsp;
+                pRsvpLsp = pRsvpLsp->next;
+            }
+        }
+        if(pTunnel->LspId != LspId)
+        {
+            pTunnel->LspId = LspId;
+            pTunnel->AllocatedBW = BW;
+            memset(&PsbKey,0,sizeof(PSB_KEY));
+            PsbKey.Session.Dest = dest;
+            PsbKey.Session.TunnelId = pTunnel->TunnelId;
+            PsbKey.Session.ExtTunelId = source;
+            
+            if(pWorkingRsvpLsp != NULL)
+            {
+                IngressLabelMappingReceived(pWorkingRsvpLsp->Label,pWorkingRsvpLsp->oIfIndex,&PsbKey);
+            }
+            else
+            {
+                zlog_err("\nBUG: pWorkingRsvpLsp is NULL %s %d",__FILE__,__LINE__);
+            }
+        }
+    }
+    else if(BW > pTunnel->RequiredBW)
+    {
+        if(pTunnel->AllocatedBW < pTunnel->RequiredBW) /* Allocated < RequiredBW < BW */
+        {
+            memset(&PsbKey,0,sizeof(PSB_KEY));
+            PsbKey.Session.Dest = dest;
+            PsbKey.Session.TunnelId = pTunnel->TunnelId;
+            PsbKey.Session.ExtTunelId = source;
+
+            while(pRsvpLsp != NULL)
+            {
+                if(pRsvpLsp->LspId == LspId)
+                {
+                    pWorkingRsvpLsp = pRsvpLsp;
+                }
+                /* tear down all that in the range Allocated < x < Required and > BW */
+                /* In another words, only Required < x < BW remains */
+                if((pRsvpLsp->LspId != LspId)&&
+                    ((pRsvpLsp->RequestedBW < pTunnel->RequiredBW)||(pRsvpLsp->RequestedBW > BW)))
+                {
+                    TeApi.NotificationType = PATH_TEAR_CMD;
+                    TeApi.u.IngressApi.Egress = dest;
+                    TeApi.u.IngressApi.TunnelId = pTunnel->TunnelId;
+                    TeApi.u.IngressApi.src_ip = source;
+                    TeApi.u.IngressApi.LspId = pRsvpLsp->LspId;
+
+                    zlog_info("\nsending tear down request2 for LSP %x tnl %x dest %x src %x bw %x",
+                        pRsvpLsp->LspId,
+                        pTunnel->TunnelId,
+                        dest,
+                        source,
+                        pRsvpLsp->RequestedBW);
+
+                    te_send_msg(&TeApi,sizeof(TeApi));
+#if DATA_PLANE
+                    {
+                       char key[23];
+                       USER_LSP *pUserLsp;
+                       IPV4_ADDR next_hop = 0;
+                       if((pRsvpLsp->tunneled == FALSE)&&(pRsvpLsp->forw_info.path.HopCount != 0))
+                       {
+                          next_hop = pRsvpLsp->forw_info.path.pErHopsList[0];
+                       }
+                       sprintf(key,"%x%d%x%d",dest,pTunnel->TunnelId,source,pRsvpLsp->LspId);
+                       zlog_info("delete label %x next hop %x key %s\n",pRsvpLsp->Label,next_hop,key);
+                       mplsTeOutLabel(&pRsvpLsp->Label,1,key,next_hop,0);
+                       if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != NULL)
+                       {
+                           if(pUserLsp->params.PolicyName[0] != '\0')
+                           {
+                              mplsTePolicy(pUserLsp->params.PolicyName,key,0);
+                           }
+                       }
+                    }
+#endif
+
+                    PsbKey.SenderTemplate.LspId = pRsvpLsp->LspId;
+#ifdef FRR_SM_DEFINED
+                    FrrIngressRelease(&PsbKey);
+#endif
+                    pRsvpLspNext = pRsvpLsp->next;
+                    if(pTunnel->properties == pRsvpLsp)
+                        pTunnel->properties = pTunnel->properties->next;
+                    else                                                                  
+                        pRsvpLspPrev->next = pRsvpLsp->next;
+
+                    if((pRsvpLsp->tunneled == FALSE)&&
+                        (pRsvpLsp->forw_info.path.pErHopsList != NULL))
+                    {
+                        XFREE(MTYPE_TE,pRsvpLsp->forw_info.path.pErHopsList);
+                    }
+                    XFREE(MTYPE_TE,pRsvpLsp);
+                                   
+                    pRsvpLsp = pRsvpLspNext;
+                }
+                else
+                {
+                    pRsvpLspPrev = pRsvpLsp;
+                    pRsvpLsp = pRsvpLsp->next;
+                }
+            }
+            if(pTunnel->LspId != LspId)
+            {
+                pTunnel->LspId = LspId;
+                pTunnel->AllocatedBW = BW;
+                memset(&PsbKey,0,sizeof(PSB_KEY));
+                PsbKey.Session.Dest = dest;
+                PsbKey.Session.TunnelId = pTunnel->TunnelId;
+                PsbKey.Session.ExtTunelId = source;
+                if(pWorkingRsvpLsp != NULL)
+                {
+                    IngressLabelMappingReceived(pWorkingRsvpLsp->Label,pWorkingRsvpLsp->oIfIndex,&PsbKey);
+                }
+                else
+                {
+                    zlog_err("\nBUG: pWorkingRsvpLsp is NULL %s %d",__FILE__,__LINE__);
+                }
+            }
+        }
+        else /* Required <= Allocated < BW */
+        {
+            RemoveRsvpLsp(pTunnel,LspId,dest,source);
+        }
+    }
+    else
+    {
+        if(BW > pTunnel->AllocatedBW) /* AllocatedBW < BW < RequiredBW */
+        {
+            memset(&PsbKey,0,sizeof(PSB_KEY));
+            PsbKey.Session.Dest = dest;
+            PsbKey.Session.TunnelId = pTunnel->TunnelId;
+            PsbKey.Session.ExtTunelId = source;
+
+            while(pRsvpLsp != NULL)
+            {
+                if(pRsvpLsp->LspId == LspId)
+                {
+                    pWorkingRsvpLsp = pRsvpLsp;
+                }
+                /* tear down all that < BW */
+                if((pRsvpLsp->LspId != LspId)&&
+                    (pRsvpLsp->RequestedBW < BW))
+                {
+                    TeApi.NotificationType = PATH_TEAR_CMD;
+                    TeApi.u.IngressApi.Egress = dest;
+                    TeApi.u.IngressApi.TunnelId = pTunnel->TunnelId;
+                    TeApi.u.IngressApi.src_ip = source;
+                    TeApi.u.IngressApi.LspId = pRsvpLsp->LspId;
+
+                    zlog_info("\nsending tear down request3 for LSP %x tnl %x dest %x src %x bw %x",
+                        pRsvpLsp->LspId,
+                        pTunnel->TunnelId,
+                        dest,
+                        source,
+                        pRsvpLsp->RequestedBW);
+
+                    te_send_msg(&TeApi,sizeof(TeApi));
+#if DATA_PLANE
+                    {
+                        char key[23];
+                        USER_LSP *pUserLsp;
+                        IPV4_ADDR next_hop = 0;
+                        if((pRsvpLsp->tunneled == FALSE)&&(pRsvpLsp->forw_info.path.HopCount != 0))
+                        {
+                            next_hop = pRsvpLsp->forw_info.path.pErHopsList[0];
+                        }
+                        sprintf(key,"%x%d%x%d",dest,pTunnel->TunnelId,source,pRsvpLsp->LspId);
+                        zlog_info("delete label %x next hop %x key %s\n",pRsvpLsp->Label,next_hop,key);
+                        mplsTeOutLabel(&pRsvpLsp->Label,1,key,next_hop,0);
+                        if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != NULL)
+                        {
+                            if(pUserLsp->params.PolicyName[0] != '\0')
+                            {
+                                mplsTePolicy(pUserLsp->params.PolicyName,key,0);
+                            }
+                        }
+                    }
+#endif
+                    PsbKey.SenderTemplate.LspId = pRsvpLsp->LspId;
+#ifdef FRR_SM_DEFINED
+                    FrrIngressRelease(&PsbKey);
+#endif
+                    pRsvpLspNext = pRsvpLsp->next;
+                    if(pTunnel->properties == pRsvpLsp)
+                        pTunnel->properties = pTunnel->properties->next;
+                    else
+                        pRsvpLspPrev->next = pRsvpLsp->next;
+                                  
+                    if((pRsvpLsp->tunneled == FALSE)&&
+                        (pRsvpLsp->forw_info.path.pErHopsList != NULL))
+                    {
+                        XFREE(MTYPE_TE,pRsvpLsp->forw_info.path.pErHopsList);
+                    }
+                    XFREE(MTYPE_TE,pRsvpLsp);
+                                  
+                    pRsvpLsp = pRsvpLspNext;
+                }
+                else
+                {
+                    pRsvpLspPrev = pRsvpLsp;
+                    pRsvpLsp = pRsvpLsp->next;
+                }
+            }
+            if(pTunnel->LspId != LspId)
+            {
+                pTunnel->LspId = LspId;
+                pTunnel->AllocatedBW = BW;
+                memset(&PsbKey,0,sizeof(PSB_KEY));
+                PsbKey.Session.Dest = dest;
+                PsbKey.Session.TunnelId = pTunnel->TunnelId;
+                PsbKey.Session.ExtTunelId = source;
+                if(pWorkingRsvpLsp != NULL)
+                {
+                    IngressLabelMappingReceived(pWorkingRsvpLsp->Label,pWorkingRsvpLsp->oIfIndex,&PsbKey);
+                }
+                else
+                {
+                    zlog_err("\nBUG: pWorkingRsvpLsp is NULL %s %d",__FILE__,__LINE__);
+                }
+            }
+        }
+        else /* BW <= Allocated < Required */
+        {
+            RemoveRsvpLsp(pTunnel,LspId,dest,source);
+        }
+    }
+    if(pTunnel->properties != NULL)
+    {
+        if(pTunnel->properties->next == NULL)
+        {
+            if(pTunnel->properties->LspId == pTunnel->LspId)
+            {
+                USER_LSP *pUserLsp;
+                pTunnel->ReRoute = FALSE;
+                if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != NULL)
+                {      
+                    RSVP_TUNNEL_PROPERTIES *pTunnel1 = pUserLsp->pUserLspTunnels;
+                    StopLspSetupTimer(pTunnel);
+                    if((pUserLsp->pUserLspTunnels)&&(pUserLsp->pUserLspTunnels->TunnelId == pTunnel->TunnelId))
+                    {
+                        StopLspSetupRetryTimer(pTunnel);
+                    }
+
+                    if(pTunnel->AdjustmentRequired == TRUE)
+                    {
+                        zlog_info("Adjustment required for tunnel %x",pTunnel->TunnelId);
+                        pTunnel->AdjustmentRequired = FALSE;
+                        while(pTunnel1 != NULL)
+                        {
+                            if(pTunnel1->TunnelId == pTunnel->TunnelId)
+                                break;
+                            pTunnel1 = pTunnel1->next_user_lsp_tunnel;
+                        }
+                    }
+                    else if(pTunnel1)
+                    {
+                        pTunnel1 = pTunnel1->next_user_lsp_tunnel;
+                    }
+                    if(pTunnel1 != NULL)
+                    {
+                        STATIC_PATH  *pStaticPath;
+                           
+                        if(rdb_get_static_path(pTunnel->StaticPathName,
+                                                    &pStaticPath) != E_OK)
+                        {
+                            pStaticPath = NULL;
+                        }
+                        pCall = ModifySecondary(pTunnel1,
+                                                pSm,
+                                                pStaticPath,
+                                                pUserLsp);
+                    }
+                    pParams = PathParamsGet(pUserLsp,
+                                            pTunnel->StaticPathName,
+                                            ((!strcmp(pUserLsp->params.Primary,pTunnel->StaticPathName))&&(pUserLsp->pUserLspTunnels->TunnelId == pTunnel->TunnelId)));
+                    StartAdaptivityTimer(pParams->optimize_timer,pTunnel);
+                }
+            }
+            else
+            {
+                zlog_err("\none RSVP LSP remains and it is not a working LSP!!! %s %d",__FILE__,__LINE__);
+            }
+        }
+    }
+    else
+    {
+        zlog_err("\npTunnel->properties is NULL %s %d",__FILE__,__LINE__);
+    }
+    zlog_info("leaving DetermineWorkingLspAndTearUnneeded");
+    return pCall;
+}
+
+RSVP_LSP_PROPERTIES *GetRsvpLspMaxBW(RSVP_TUNNEL_PROPERTIES *pTunnel,uns16 LspId,float MaxBw)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp = pTunnel->properties,*pSelectedRsvpLsp = NULL;
+    float MaxRsvpLspBW = 0;
+    while(pRsvpLsp != NULL)
+    {
+        if((pRsvpLsp->RequestedBW <= MaxBw)&&
+            (pRsvpLsp->LspId != LspId)&&
+            (pRsvpLsp->RequestedBW > MaxRsvpLspBW))
+            pSelectedRsvpLsp = pRsvpLsp;
+        pRsvpLsp = pRsvpLsp->next;
+    }
+    return pSelectedRsvpLsp;
+}
+
+BOOL IsPathEqual(PATH *pPath,IPV4_ADDR *IpAddrList)
+{
+    ER_HOP_L_LIST *pErHopLList = pPath->u.er_hops_l_list;
+    int i = 0;
+    
+    while(pErHopLList != NULL)
+    {
+        if(pErHopLList->er_hop->local_ip != IpAddrList[i])
+            return FALSE;
+        pErHopLList = pErHopLList->next;
+        i++;
+    }
+    return TRUE;
+}
+
+PATH *FindRsvpLspPath(PATH_L_LIST *pPaths,RSVP_LSP_PROPERTIES *pRsvpLsp)
+{
+    while(pPaths != NULL)
+    {
+        PATH *pPath = pPaths->pPath;
+
+        if((pPath->PathProperties.PathHopCount + 1) == pRsvpLsp->forw_info.path.HopCount)
+        {
+            if(IsPathEqual(pPath,pRsvpLsp->forw_info.path.pErHopsList) == TRUE)
+                return pPath;
+        }
+        pPaths = pPaths->next;
+    }
+    return NULL;
+}
+
+RSVP_LSP_PROPERTIES *CurrentPathHasAvBw(RSVP_TUNNEL_PROPERTIES *pTunnel,float BW)
+{
+    RSVP_LSP_PROPERTIES *pRsvpLsp;
+    PATH *pPath;
+    float Delta;
+
+    zlog_info("entering CurrentPathHasAvBw");
+
+    if((pRsvpLsp = GetWorkingRsvpLsp(pTunnel)) != NULL)
+    {
+        if((pPath = GetLspPath(pRsvpLsp)) != NULL)
+        {
+            if(pPath->PathProperties.PathMaxLspBW >= BW)
+            {
+                if(pRsvpLsp->RequestedBW < BW)
+                    Delta = BW - pRsvpLsp->RequestedBW;
+                else
+                    Delta = pRsvpLsp->RequestedBW - BW;
+                                
+                if(pPath->PathProperties.PathReservableBW[pRsvpLsp->SetupPriority] >= Delta)
+                    return pRsvpLsp;
+            }
+        }
+        else
+            zlog_info("cannot get working lsp's path %s %d",__FILE__,__LINE__);
+    }
+    else
+        zlog_info("cannot get working lsp %s %d",__FILE__,__LINE__);
+    zlog_info("leaving CurrentPathHasAvBw");
+    return NULL;
+}
+
+uns32 AddSecondaryTunnel(USER_LSP *pUserLsp,
+                         RSVP_TUNNEL_PROPERTIES *pSecondaryTunnel)
+{
+    RSVP_TUNNEL_PROPERTIES *pTunnel,*pTunnelPrev = NULL;
+
+    zlog_info("entering AddSecondaryTunnel");
+
+    if((pTunnel = pUserLsp->pUserLspTunnels) == NULL)
+    {
+        zlog_err("\nFATAL at %s %d - TunnelIdList is empty",__FILE__,__LINE__);
+        return E_ERR;
+    }
+    zlog_info("Primary: %x %s",pTunnel->TunnelId,pTunnel->StaticPathName);
+    if(pTunnel->next_user_lsp_tunnel == NULL)
+    {
+        zlog_info("First secondary tunnel %s %d",__FILE__,__LINE__);
+        pTunnel->next_user_lsp_tunnel = pSecondaryTunnel;
+        return E_OK;
+    }
+    pTunnel = pTunnel->next_user_lsp_tunnel;
+    while(pTunnel != NULL)
+    {
+        if(pTunnel->TunnelId == pSecondaryTunnel->TunnelId)
+        {
+            zlog_info("exists on the lists...");
+            zlog_info("leaving AddSecondaryTunnel"); 
+            return E_OK;
+        }
+        pTunnelPrev = pTunnel;
+        pTunnel = pTunnel->next_user_lsp_tunnel;
+    }
+    pTunnelPrev->next_user_lsp_tunnel = pSecondaryTunnel;
+    zlog_info("leaving AddSecondaryTunnel");      
+    return E_OK;
+}
+
+void CleanSecodaryPaths(USER_LSP *pUserLsp)
+{
+    SECONDARY_PATH_LIST *pSecPathList = pUserLsp->params.SecondaryPaths,*pSecPathListNext;
+    while(pSecPathList != NULL)
+    {
+        if(pSecPathList->SecondaryPathParams != NULL)
+            XFREE(MTYPE_TE,pSecPathList->SecondaryPathParams);
+        pSecPathListNext = pSecPathList->next;
+        XFREE(MTYPE_TE,pSecPathList);
+        pSecPathList = pSecPathListNext;
+    }
+}
+
+void CleanUserLsp(USER_LSP *pUserLsp)
+{
+#if 0
+    if(pUserLsp->params.FastReroute != NULL)
+        XFREE(MTYPE_TE,pUserLsp->params.FastReroute);
+#endif              
+    if(pUserLsp->params.PrimaryPathParams != NULL)
+        XFREE(MTYPE_TE,pUserLsp->params.PrimaryPathParams);
+}
+
+void CopyUserLsp(USER_LSP *pDestLsp,USER_LSP *pSrcLsp)
+{
+    SECONDARY_PATH_LIST *pDestSecondaryPathList,*pSrcSecondaryPathList,*pPrevSecPath;
+
+    zlog_info("entering CopyUserLsp");
+
+    strcpy(pDestLsp->params.LspName,pSrcLsp->params.LspName);
+
+    if((pDestLsp->params.PrimaryPathParams)&&
+       (((pSrcLsp->params.PrimaryPathParams)&&(pSrcLsp->params.PrimaryPathParams->disable))||
+        (!pSrcLsp->params.PrimaryPathParams)))
+    {
+       zlog_info("removing primary %s %s %d",pDestLsp->params.Primary,__FILE__,__LINE__);
+       XFREE(MTYPE_TE,pDestLsp->params.PrimaryPathParams);
+       pDestLsp->params.PrimaryPathParams = NULL;
+       pDestLsp->params.Primary[0] = '\0';
+       if(pSrcLsp->params.PrimaryPathParams)
+       {
+          XFREE(MTYPE_TE,pSrcLsp->params.PrimaryPathParams);
+          pSrcLsp->params.PrimaryPathParams = NULL;
+       }
+       pSrcLsp->params.Primary[0] = '\0';
+    }
+    strcpy(pDestLsp->params.Primary,pSrcLsp->params.Primary);
+#if 0
+    pDestLsp->params.FastReroute = pSrcLsp->params.FastReroute;
+    pSrcLsp->params.FastReroute = NULL;
+#endif
+    if(pDestLsp->params.PrimaryPathParams != NULL)
+    {
+        XFREE(MTYPE_TE,pDestLsp->params.PrimaryPathParams);
+    }
+    pDestLsp->params.PrimaryPathParams = pSrcLsp->params.PrimaryPathParams;
+    pSrcLsp->params.PrimaryPathParams = NULL;
+    pDestSecondaryPathList = pDestLsp->params.SecondaryPaths;
+    while(pDestSecondaryPathList != NULL)
+    {
+        pSrcSecondaryPathList = pSrcLsp->params.SecondaryPaths;
+        pPrevSecPath = NULL;
+        while(pSrcSecondaryPathList != NULL)
+        {
+            if(strcmp(pDestSecondaryPathList->Secondary,pSrcSecondaryPathList->Secondary) == 0)
+            {
+                if(pDestSecondaryPathList->SecondaryPathParams != NULL)
+                {
+                   XFREE(MTYPE_TE,pDestSecondaryPathList->SecondaryPathParams);
+                }
+                pDestSecondaryPathList->SecondaryPathParams = pSrcSecondaryPathList->SecondaryPathParams;
+                pSrcSecondaryPathList->SecondaryPathParams = NULL;
+                if(pPrevSecPath != NULL)
+                {
+                    pPrevSecPath->next = pSrcSecondaryPathList->next;
+                }
+                else
+                {
+                    pSrcLsp->params.SecondaryPaths = pSrcLsp->params.SecondaryPaths->next;
+                }
+                XFREE(MTYPE_TE,pSrcSecondaryPathList);
+                break;
+            }
+            pPrevSecPath = pSrcSecondaryPathList;
+            pSrcSecondaryPathList = pSrcSecondaryPathList->next;
+        }
+        if(pDestSecondaryPathList->next == NULL)
+        {
+            pDestSecondaryPathList->next = pSrcLsp->params.SecondaryPaths;
+            break;
+        }
+        pDestSecondaryPathList = pDestSecondaryPathList->next;
+    }
+    if(pDestLsp->params.SecondaryPaths == NULL)
+    {
+        pDestLsp->params.SecondaryPaths = pSrcLsp->params.SecondaryPaths;
+    }
+    if(pDestLsp->params.FastReRoute != pSrcLsp->params.FastReRoute)
+    {
+       pDestLsp->params.FastReRoute = pSrcLsp->params.FastReRoute;
+    }
+    if(pDestLsp->params.bw_policy != pSrcLsp->params.bw_policy)
+    {
+       pDestLsp->params.bw_policy = pSrcLsp->params.bw_policy;
+    }
+    if(pDestLsp->params.metric != pSrcLsp->params.metric)
+    {
+       pDestLsp->params.metric = pSrcLsp->params.metric;
+    }
+    if(pDestLsp->params.no_decrement_ttl != pSrcLsp->params.no_decrement_ttl)
+    {
+       pDestLsp->params.no_decrement_ttl = pSrcLsp->params.no_decrement_ttl;
+    }
+    if(pDestLsp->params.retry_timer != pSrcLsp->params.retry_timer)
+    {
+       pDestLsp->params.retry_timer = pSrcLsp->params.retry_timer;
+    }
+    if(pDestLsp->params.retry_limit != pSrcLsp->params.retry_limit)
+    {
+       pDestLsp->params.retry_limit = pSrcLsp->params.retry_limit;
+    }
+    pDestLsp->params.retry_count = pSrcLsp->params.retry_limit;
+    if(memcmp(&pDestLsp->params.lsp_params,&pSrcLsp->params.lsp_params,sizeof(LSP_PATH_SHARED_PARAMS)) != 0)
+    {
+       pDestLsp->params.lsp_params = pSrcLsp->params.lsp_params;
+    }
+    zlog_info("leaving CopyUserLsp");
+}
+
+LSP_PATH_SHARED_PARAMS *PathParamsGet(USER_LSP *pUserLsp,char *PathName,uns8 IsPrimary)
+{
+    zlog_info("entering PathParamsGet");
+
+    if((IsPrimary)&&(strcmp(pUserLsp->params.Primary,PathName) == 0))
+    {
+        if(pUserLsp->params.PrimaryPathParams != NULL)
+        {
+            return pUserLsp->params.PrimaryPathParams;
+        }
+        else
+        {
+            return &pUserLsp->params.lsp_params;
+        }
+    }
+    else if(!IsPrimary)
+    {
+        SECONDARY_PATH_LIST *pSecondaryPathList = pUserLsp->params.SecondaryPaths;
+        while(pSecondaryPathList != NULL)
+        {
+            if(strcmp(pSecondaryPathList->Secondary,PathName) == 0)
+            {
+                if(pSecondaryPathList->SecondaryPathParams != NULL)
+                {
+                    return pSecondaryPathList->SecondaryPathParams;
+                }
+                else
+                {
+                    return &pUserLsp->params.lsp_params;
+                }
+            }
+            pSecondaryPathList = pSecondaryPathList->next;
+        }
+    }
+    zlog_info("leaving PathParamsGet");
+    return &pUserLsp->params.lsp_params;
+}
+
+RSVP_TUNNEL_PROPERTIES *StaticPathIsUsed(USER_LSP *pUserLsp,char *PathName)
+{
+    RSVP_TUNNEL_PROPERTIES *pTunnel = pUserLsp->pUserLspTunnels;
+
+    zlog_info("entering StaticPathIsUsed");
+
+    if(pTunnel != NULL)
+    {
+        pTunnel = pTunnel->next_user_lsp_tunnel;
+    }
+    while(pTunnel != NULL)
+    {
+        if(strcmp(pTunnel->StaticPathName,PathName) == 0)
+            return pTunnel;
+        pTunnel = pTunnel->next_user_lsp_tunnel;
+    }
+    zlog_info("leaving StaticPathIsUsed");
+    return NULL;
+}
+
+SM_CALL_T *UserPrimaryLspRecovery(RSVP_TUNNEL_PROPERTIES *pTunnel,
+                                  SM_T *pSm,
+                                  RECOVERY_TYPE_E recovery_type,
+                                  IPV4_ADDR exclude_node)
+{
+    STATIC_PATH *pStaticPath;
+    USER_LSP *pUserLsp;
+    SECONDARY_PATH_LIST *pSecondaryPathList;
+    INGRESS_API *pOpenLspParams;
+    SM_CALL_T *pCall = NULL;
+    RSVP_TUNNEL_PROPERTIES *pSavedTunnel = pTunnel;
+    LSP_PATH_SHARED_PARAMS *pParams = NULL;
+    uns8 Flags = 0;
+    ER_HOP *pErHopsList = NULL;
+
+    zlog_info("entering UserPrimaryLspRecovery");
+
+    if((pUserLsp = UserLspGet(pTunnel->UserLspName)) == NULL)
+    {
+        zlog_err("\nerror: cannot get user lsp %s %d",__FILE__,__LINE__);
+        return NULL;
+    }
+    pTunnel = pTunnel->next_user_lsp_tunnel;
+    /* First - try to find secondary LSP (hot-standby), which is UP */
+    if(recovery_type == WORKING_LSP_FAILED)
+    {
+        while(pTunnel != NULL)
+        {
+            RSVP_LSP_PROPERTIES *pRsvpLsp;
+            if((pRsvpLsp = GetWorkingRsvpLsp(pTunnel)) != NULL)
+            {
+#if DATA_PLANE
+                {
+                   char key[23];
+                   sprintf(key,"%x%d%x%d",pUserLsp->params.to,pTunnel->TunnelId,pUserLsp->params.from,pRsvpLsp->LspId);
+                   if(pUserLsp->params.PolicyName[0] != '\0')
+                   {
+                       mplsTePolicy(pUserLsp->params.PolicyName,key,1);
+                       pUserLsp->BackupTunnelId = pTunnel->TunnelId;
+                   }
+                }
+#endif
+                zlog_info("Protection switch to secondary hot-stanby tunnel Dest %x Tunnel %x  Source %x %s %s %x",
+                        pUserLsp->params.to,
+                        pTunnel->TunnelId,
+                        pUserLsp->params.from,
+                        pTunnel->StaticPathName,
+                        __FILE__,__LINE__);
+                    strcpy(pUserLsp->CurrentSecondaryPathName,pTunnel->StaticPathName);
+                    if(StartLspSetupRetryTimer(pUserLsp->params.retry_timer,
+                                               &pUserLsp->params.retry_count,
+                                               pSavedTunnel) != E_OK)
+                    {
+                        zlog_err("cannot start lsp setup retry timer %s %d",__FILE__,__LINE__);
+                    }
+                    return NULL;
+            }
+            pTunnel = pTunnel->next_user_lsp_tunnel;
+        }
+    }
+    
+    /* if reached here, there is no hot-stanby tunnels UP. */
+    pSecondaryPathList = pUserLsp->params.SecondaryPaths;
+    /* if there is secondary path, which was used, spin up the secondary paths to get next secondary path */
+    if(pUserLsp->CurrentSecondaryPathName[0] != 0)
+    {
+        while(pSecondaryPathList != NULL)
+        {
+            if(strcmp(pSecondaryPathList->Secondary,pUserLsp->CurrentSecondaryPathName) == 0)
+            {
+                pSecondaryPathList = pSecondaryPathList->next;
+                break;
+            }
+            pSecondaryPathList = pSecondaryPathList->next;
+        }
+        if(pSecondaryPathList == NULL)
+        {
+            pSecondaryPathList = pUserLsp->params.SecondaryPaths;
+        }
+    }
+    
+    while(pSecondaryPathList != NULL)
+    {
+        if(strcmp(pSecondaryPathList->Secondary,pUserLsp->CurrentSecondaryPathName) == 0)
+        {
+            pSecondaryPathList = NULL;
+            break;
+        }
+        if(StaticPathIsUsed(pUserLsp,pSecondaryPathList->Secondary) == NULL)
+        {
+            if(rdb_get_static_path(pSecondaryPathList->Secondary,
+                                        &pStaticPath) == E_OK)
+            {
+                break;
+            }
+        }
+        pSecondaryPathList = pSecondaryPathList->next;
+    }
+    
+    if(pUserLsp->pUserLspTunnels == NULL)
+    {
+        zlog_err("\nSW ERROR %s %d",__FILE__,__LINE__);
+        return NULL;
+    }
+    
+    if(pSecondaryPathList != NULL)
+    {
+        pParams = PathParamsGet(pUserLsp,pSecondaryPathList->Secondary,0);
+        Flags |= (pParams->record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+        /* for now the FRR is only boolean. However, in future it may be more complicated */
+        Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+        if(SetErHopList(pStaticPath,&pErHopsList) != E_OK)
+        {
+            zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+            return NULL;
+        }
+        /* reroute primary LSP to the secondary path */
+        if((pOpenLspParams = CreateRequest2Signalling(pUserLsp->params.to,
+                                                      pUserLsp->pUserLspTunnels->TunnelId,
+                                                      pStaticPath->HopCount,
+                                                      pErHopsList,
+                                                      pParams->BW,
+                                                      pParams->setup_priority,
+                                                      pParams->hold_priority,
+                                                      Flags,
+                                                      (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                      0,
+                                                      pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+        {
+            zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+            XFREE(MTYPE_TE,pErHopsList);
+            return NULL;
+        }
+        
+        zlog_info("\nRerouting primary: Dest %x Tunnel %x Source %x New Path %s",
+            pOpenLspParams->Egress,
+            pOpenLspParams->TunnelId,
+            pOpenLspParams->src_ip,
+            pSecondaryPathList->Secondary);
+        
+        strcpy(pUserLsp->CurrentSecondaryPathName,pSecondaryPathList->Secondary);
+        if(StartLspSetupRetryTimer(pUserLsp->params.retry_timer,&pUserLsp->params.retry_count,pSavedTunnel) != E_OK)
+        {
+            zlog_err("\ncannot start lsp setup retry timer %s %d",__FILE__,__LINE__);
+        }
+        pParams = PathParamsGet(pUserLsp,pStaticPath->PathName,0);
+        if(pUserLsp->params.to != exclude_node)
+          pOpenLspParams->ErHops2Exclude[0] = exclude_node;
+        pCall = LspRequest(pOpenLspParams,0,NULL,pSm,&pSavedTunnel,TRUE,pParams);
+        strcpy(pSavedTunnel->StaticPathName,pSecondaryPathList->Secondary);
+        return pCall;
+       
+    }
+
+    if(rdb_get_static_path(pSavedTunnel->StaticPathName,
+                                &pStaticPath) != E_OK)
+    {
+        pStaticPath = NULL;
+    }
+    
+    pParams = PathParamsGet(pUserLsp,
+                            pSavedTunnel->StaticPathName,
+                            ((!strcmp(pUserLsp->params.Primary,pSavedTunnel->StaticPathName))&&(pUserLsp->pUserLspTunnels->TunnelId == pSavedTunnel->TunnelId)));
+
+    if(StartLspSetupRetryTimer(pUserLsp->params.retry_timer,&pUserLsp->params.retry_count,pSavedTunnel) != E_OK)
+    {
+        zlog_err("\ncannot start lsp setup retry timer %s %d",__FILE__,__LINE__);
+    }
+
+    if((pStaticPath != NULL)&&
+        (pStaticPath->HopList != NULL)&&
+        (pStaticPath->HopList->Loose == 1))
+    {
+        /* reroute primary LSP to the secondary path */
+        if(SetErHopList(pStaticPath,&pErHopsList) != E_OK)
+        {
+            zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+            return NULL;
+        }
+    }
+    else
+    {
+        pStaticPath = NULL;
+    }
+    Flags |= (pParams->record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+    /* for now the FRR is only boolean. However, in future it may be more complicated */
+    Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+    if((pOpenLspParams = CreateRequest2Signalling(pUserLsp->params.to,
+                                                  pUserLsp->pUserLspTunnels->TunnelId,
+                                                  (pStaticPath == NULL) ? 0 : pStaticPath->HopCount,
+                                                  pErHopsList,
+                                                  pParams->BW,
+                                                  pParams->setup_priority,
+                                                  pParams->hold_priority,
+                                                  Flags,
+                                                  (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                  0,
+                                                  pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+    {
+        zlog_err("malloc failed %s %d",__FILE__,__LINE__);
+        return NULL;
+    }
+        
+    zlog_info("Creation secondary - %x %x %s %d",pOpenLspParams->Egress,pOpenLspParams->src_ip,__FILE__,__LINE__);
+    if(pUserLsp->params.to != exclude_node)
+          pOpenLspParams->ErHops2Exclude[0] = exclude_node;
+    return LspRequest(pOpenLspParams,0,NULL,pSm,&pSavedTunnel,TRUE,pParams);
+}
+
+SM_CALL_T *UserSecondaryLspRecovery(RSVP_TUNNEL_PROPERTIES *pTunnel,SM_T *pSm,IPV4_ADDR exclude_node)
+{
+    LSP_PATH_SHARED_PARAMS *pSecondaryPathParams;
+    USER_LSP *pUserLsp;
+    STATIC_PATH *pStaticPath;
+    INGRESS_API *pOpenLspParams;
+    uns32 ErHopNumber = 0;
+    IPV4_ADDR *pErHops = NULL;
+    uns8 Flags = 0;
+    ER_HOP *pErHopsList = NULL;
+
+    zlog_info("entering UserSecondaryLspRecovery");
+
+    if((pUserLsp = UserLspGet(pTunnel->UserLspName)) == NULL)
+    {
+        zlog_err("\nerror: cannot get user lsp %s %d",__FILE__,__LINE__);
+        return NULL;
+    }
+    if(pUserLsp->pUserLspTunnels == NULL)
+    {
+        zlog_err("\nTunnel ID list empty %s %d",__FILE__,__LINE__);
+        return NULL;
+    }
+    pSecondaryPathParams = PathParamsGet(pUserLsp,pTunnel->StaticPathName,0);
+    
+    if(rdb_get_static_path(pTunnel->StaticPathName,
+                                &pStaticPath) != E_OK)
+    {
+        Flags |= (pSecondaryPathParams->record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+        /* for now the FRR is only boolean. However, in future it may be more complicated */
+        Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+        
+        /* reroute the secondary LSP inside of the path */
+        if((pOpenLspParams = CreateRequest2Signalling(pUserLsp->params.to,
+                                                      pTunnel->TunnelId,
+                                                      0,
+                                                      NULL,
+                                                      pSecondaryPathParams->BW,
+                                                      pSecondaryPathParams->setup_priority,
+                                                      pSecondaryPathParams->hold_priority,
+                                                      Flags,
+                                                      (~(pSecondaryPathParams->affinity_properties & pSecondaryPathParams->affinity_mask)) & pSecondaryPathParams->affinity_mask,
+                                                      0,
+                                                      pSecondaryPathParams->affinity_properties & pSecondaryPathParams->affinity_mask)) == NULL)
+        {
+            zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+            return NULL;
+        }
+               
+        if(GetTunnelHops(pUserLsp->pUserLspTunnels,&ErHopNumber,&pErHops) != E_OK)
+        {
+            zlog_err("\ncannot get ER HOPs to be avoided %s %d",__FILE__,__LINE__);
+            ErHopNumber = 0;
+            pErHops = NULL;
+        }
+        if(pUserLsp->params.to != exclude_node)
+          pOpenLspParams->ErHops2Exclude[0] = exclude_node;
+        return LspRequest(pOpenLspParams,ErHopNumber,pErHops,pSm,&pTunnel,TRUE,pSecondaryPathParams);
+    }
+    
+    Flags |= (pSecondaryPathParams->record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+    /* for now the FRR is only boolean. However, in future it may be more complicated */
+    Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+    if(pStaticPath != NULL)
+    {
+       if(SetErHopList(pStaticPath,&pErHopsList) != E_OK)
+       {
+           zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+           return NULL;
+       }
+    }
+    /* reroute the secondary LSP inside of the path */
+    if((pOpenLspParams = CreateRequest2Signalling(pUserLsp->params.to,
+                                                  pTunnel->TunnelId,
+                                                  pStaticPath->HopCount,
+                                                  pErHopsList,
+                                                  pSecondaryPathParams->BW,
+                                                  pSecondaryPathParams->setup_priority,
+                                                  pSecondaryPathParams->hold_priority,
+                                                  Flags,
+                                                  (~(pSecondaryPathParams->affinity_properties & pSecondaryPathParams->affinity_mask)) & pSecondaryPathParams->affinity_mask,
+                                                  0,
+                                                  pSecondaryPathParams->affinity_properties & pSecondaryPathParams->affinity_mask)) == NULL)
+    {
+        zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+        return NULL;
+    }
+    if(!((pErHopsList != NULL)&&(pErHopsList[0].Loose == 0)))
+    {
+        if(GetTunnelHops(pUserLsp->pUserLspTunnels,&ErHopNumber,&pErHops) != E_OK)
+        {
+           zlog_err("\ncannot get ER HOPs to be avoided %s %d",__FILE__,__LINE__);
+           ErHopNumber = 0;
+           pErHops = NULL;
+        }
+    }
+    if(pUserLsp->params.to != exclude_node)
+        pOpenLspParams->ErHops2Exclude[0] = exclude_node;
+    return LspRequest(pOpenLspParams,ErHopNumber,pErHops,pSm,&pTunnel,TRUE,pSecondaryPathParams);
+}
+
+SM_CALL_T *UserLspFailed(RSVP_TUNNEL_PROPERTIES *pTunnel,SM_T *pSm,IPV4_ADDR exclude_node)
+{
+    USER_LSP *pUserLsp;
+    RECOVERY_TYPE_E recovery_type = WORKING_LSP_FAILED;
+   
+    zlog_info("entering UserLspFailed");
+    zlog_info("Exclude Node %x",exclude_node);
+    if((pUserLsp = UserLspGet(pTunnel->UserLspName)) == NULL)
+    {
+        zlog_err("\nerror: cannot get user lsp %s %d",__FILE__,__LINE__);
+        return NULL;
+    }
+    if(pUserLsp->pUserLspTunnels == NULL)
+    {
+        zlog_err("\nerror: tunnel id list empty %s %d",__FILE__,__LINE__);
+        return NULL;
+    }
+        
+    if(pUserLsp->pUserLspTunnels->TunnelId == pTunnel->TunnelId)
+    {
+        if(GetWorkingRsvpLsp(pTunnel)!= NULL)
+        {
+            if(pTunnel->ReRoute == TRUE)
+            {
+                recovery_type = NEW_LSP_FAILED;
+            }
+            else
+            {
+                zlog_info("\nLSP is not rerouted and having working lsp...");
+                return NULL;
+            }
+        }
+        else
+        {
+            if((pTunnel->ReRoute == TRUE)&&
+                (pTunnel->properties != NULL))
+            {
+                zlog_info("\nLSP is not working lsp, reroute lasts...");
+                return NULL;
+            }
+        }
+        zlog_info("\nPrimary Tunnel failed Dest %x Tunnel ID %x Source %x recovery type %d",
+            pUserLsp->params.to,pUserLsp->pUserLspTunnels->TunnelId,pUserLsp->params.from,recovery_type);
+        return UserPrimaryLspRecovery(pTunnel,pSm,recovery_type,exclude_node);
+        
+    }
+    else
+    {
+        if(GetWorkingRsvpLsp(pTunnel)== NULL)
+        {
+            if((pTunnel->ReRoute == TRUE)&&
+                (pTunnel->properties != NULL))
+            {
+                return NULL;
+            }
+            else
+            {
+                zlog_info("\npTunnel->Reroute %d pTunnel->properties %x",pTunnel->ReRoute,pTunnel->properties);
+            }
+        }
+        else if(pTunnel->ReRoute == FALSE)
+        {
+            return NULL;
+        }
+        zlog_info("\nSecondary Tunnel failed Dest %x Tunnel ID %x Source %x",
+            pUserLsp->params.to,pTunnel->TunnelId,pUserLsp->params.from);
+        return UserSecondaryLspRecovery(pTunnel,pSm,exclude_node);
+    }
+}
+
+uns32 GetTunnelHops(RSVP_TUNNEL_PROPERTIES *pTunnel,uns32 *ErHopNumber,IPV4_ADDR **ppErHops)
+{
+    RSVP_LSP_PROPERTIES *pRsvpWorkingLsp;
+    IPV4_ADDR *pWorkingRsvpLspErHops = NULL;
+    uns32 WorkingRsvpLspHops = 0,i,j;
+
+    zlog_info("entering GetTunnelHops");
+
+    *ErHopNumber = 0;
+    *ppErHops = NULL;
+    if(pTunnel == NULL)
+    {
+        return E_ERR;
+    }
+    if((pRsvpWorkingLsp = GetWorkingRsvpLsp(pTunnel)) != NULL)
+    {
+        if(pRsvpWorkingLsp->tunneled == FALSE)
+        {
+            WorkingRsvpLspHops = pRsvpWorkingLsp->forw_info.path.HopCount;
+            pWorkingRsvpLspErHops = pRsvpWorkingLsp->forw_info.path.pErHopsList;
+#if 0
+            if((pWorkingRsvpLspErHops)&&(pWorkingRsvpLspErHops[WorkingRsvpLspHops-1] == PsbKey.Session.Dest)
+            {
+                WorkingRsvpLspHops--;
+            }
+#endif
+        }
+        else
+        {
+            zlog_err("\nthis case is not supported %s %d",__FILE__,__LINE__);
+        }
+    }
+    else
+    {
+        WorkingRsvpLspHops = 0;
+    }
+    /* now, fill in the array */
+    if(WorkingRsvpLspHops != 0)
+    {
+        if((*ppErHops = (IPV4_ADDR *)XMALLOC(MTYPE_TE,sizeof(IPV4_ADDR)*(WorkingRsvpLspHops/2))) == NULL)
+        {
+            zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+            return E_ERR;
+        }
+        for(j = 0,i = 0;i < WorkingRsvpLspHops;i += 2,j++)
+        {
+           if(rdb_remote_link_router_id_get(pWorkingRsvpLspErHops[i],&((*ppErHops)[j])) != E_OK)
+           {
+               zlog_err("Cannot get router ID for %x %s %d",pWorkingRsvpLspErHops[i],__FILE__,__LINE__);
+           }
+        }
+        *ErHopNumber = WorkingRsvpLspHops/2;
+    }
+    zlog_info("leaving GetTunnelHops");
+    return E_OK;
+}
+
+BOOL TunnelsHaveSharedErHops(IPV4_ADDR *pFirstArray,
+                             uns32 FirstArraySize,
+                             IPV4_ADDR *pSecondArray,
+                             uns32 SecondArraySize)
+{
+    int i,j;
+    for(i = 0;i < FirstArraySize;i++)
+    {
+        for(j = 0;j < SecondArraySize;j++)
+        {
+            if(pFirstArray[i] == pSecondArray[j])
+            {
+                zlog_info("Hop %x is shared",pFirstArray[i]);
+                return TRUE;
+            }
+        }
+    }
+    return FALSE;
+}
+
+SM_CALL_T *ModifySecondary(RSVP_TUNNEL_PROPERTIES *pSecTunnel,
+                           SM_T *pSm,
+                           STATIC_PATH *pPrimaryStaticPath,
+                           USER_LSP *pUserLsp)
+{
+    INGRESS_API *pOpenLspParams = NULL;
+    STATIC_PATH *pSecStaticPath;
+    IPV4_ADDR *pSecondaryLspErHops;
+    uns32 SecondaryLspErHopNumber;
+    LSP_PATH_SHARED_PARAMS *pParams;
+    ER_HOP *pErHopsList = NULL;
+    IPV4_ADDR *pPrimaryLspErHops;
+    uns32 PrimaryLspErHopNumber;
+    uns8 Flags = 0;
+
+    zlog_info("entering ModifySecondary");
+    if(pSecTunnel == NULL)
+    {
+        return NULL;
+    }
+    if(pSecTunnel->ReRoute == TRUE)
+    {
+        pSecTunnel->AdjustmentRequired = TRUE;
+        zlog_info("\nSecondary LSP adjustment is postponed...");
+        return NULL;
+    }
+    if(rdb_get_static_path(pSecTunnel->StaticPathName,
+                                &pSecStaticPath) == E_OK)
+    {
+        /* if checking for shared hops makes sense */
+        if((((pSecStaticPath->HopList != NULL)&&
+            (pSecStaticPath->HopList->Loose == 1))||
+            (pSecStaticPath->HopList == NULL))||
+            (((pPrimaryStaticPath != NULL)&&
+                (pPrimaryStaticPath->HopList != NULL)&&
+                (pPrimaryStaticPath->HopList->Loose == 1))||
+                ((pPrimaryStaticPath == NULL)||
+                    (pPrimaryStaticPath->HopList == NULL))))
+        {
+            if(GetTunnelHops(pSecTunnel,&SecondaryLspErHopNumber,&pSecondaryLspErHops) != E_OK)
+            {
+                SecondaryLspErHopNumber = 0;
+                pSecondaryLspErHops = NULL;
+                zlog_info("\ncannot get Secondary Tunnel's ER HOPS");
+            }
+            if(GetTunnelHops(pUserLsp->pUserLspTunnels,&PrimaryLspErHopNumber,&pPrimaryLspErHops) != E_OK)
+            {
+                PrimaryLspErHopNumber = 0;
+                pPrimaryLspErHops = NULL;
+                zlog_info("\ncannot get Primary tunnel's ER HOPs");
+            }
+            zlog_info("\nSecondary Tunnel's ER HOPS number %d",SecondaryLspErHopNumber);
+            if((TunnelsHaveSharedErHops(pPrimaryLspErHops,
+                                        PrimaryLspErHopNumber,
+                                        pSecondaryLspErHops,
+                                        SecondaryLspErHopNumber) == TRUE)||
+               (GetWorkingRsvpLsp(pSecTunnel) == NULL))
+            {
+                zlog_info("\nSTEP1");
+                pParams = PathParamsGet(pUserLsp,pSecStaticPath->PathName,0);
+                Flags |= (pParams->record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+                /* for now the FRR is only boolean. However, in future it may be more complicated */
+                Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+                if(SetErHopList(pSecStaticPath,&pErHopsList) != E_OK)
+                {
+                    zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+                    return NULL;
+                }
+                if((pOpenLspParams = CreateRequest2Signalling(pUserLsp->params.to,
+                                                              pSecTunnel->TunnelId,
+                                                              pSecStaticPath->HopCount,
+                                                              pErHopsList,
+                                                              pSecTunnel->RequiredBW,
+                                                              pParams->setup_priority,
+                                                              pParams->hold_priority,
+                                                              Flags,
+                                                              (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                              0,
+                                                              pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+                {
+                    zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+                    XFREE(MTYPE_TE,pErHopsList);
+                    return NULL;
+                }
+                
+                return LspRequest(pOpenLspParams,PrimaryLspErHopNumber,pPrimaryLspErHops,pSm,&pSecTunnel,TRUE,pParams);
+            }
+            else
+            {
+                zlog_info("Tunnels do not have shared hops");
+            }
+            XFREE(MTYPE_TE,pSecondaryLspErHops);
+        }
+        else
+        {
+            zlog_info("\nRoute re-resolution doesn't makes sense %s %x %x",
+                pSecStaticPath->PathName,
+                pPrimaryStaticPath,pSecStaticPath);
+            if((pPrimaryStaticPath != NULL)&&
+                (pPrimaryStaticPath->HopList != NULL))
+                zlog_info("\nLoose (primary) %d",pPrimaryStaticPath->HopList->Loose);
+            if(pSecStaticPath->HopList != NULL)
+                zlog_info("\nLoose (secondary) %d",pSecStaticPath->HopList->Loose);
+        }
+    }
+    else
+    {
+        if(GetTunnelHops(pSecTunnel,&SecondaryLspErHopNumber,&pSecondaryLspErHops) != E_OK)
+        {
+            SecondaryLspErHopNumber = 0;
+            pSecondaryLspErHops = NULL;
+            zlog_info("\ncannot get Secondary Tunnel's ER HOPS");
+        }
+        if(GetTunnelHops(pUserLsp->pUserLspTunnels,&PrimaryLspErHopNumber,&pPrimaryLspErHops) != E_OK)
+        {
+            PrimaryLspErHopNumber = 0;
+            pPrimaryLspErHops = NULL;
+            zlog_info("\ncannot get Primary tunnel's ER HOPs");
+        }
+        zlog_info("\nSecondary Tunnel's ER HOPS number %d",SecondaryLspErHopNumber);
+        if((TunnelsHaveSharedErHops(pPrimaryLspErHops,
+                                    PrimaryLspErHopNumber,
+                                    pSecondaryLspErHops,
+                                    SecondaryLspErHopNumber) == TRUE)||
+           (GetWorkingRsvpLsp(pSecTunnel) == NULL))
+        {
+            zlog_info("\nSTEP1`");
+            pParams = PathParamsGet(pUserLsp,pSecTunnel->StaticPathName,0);
+            Flags |= (pParams->record == TRUE) ? LABEL_RECORDING_DESIRED : 0;
+            /* for now the FRR is only boolean. However, in future it may be more complicated */
+            Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+            
+            if((pOpenLspParams = CreateRequest2Signalling(pUserLsp->params.to,
+                                                          pSecTunnel->TunnelId,
+                                                          0,
+                                                          NULL,
+                                                          pSecTunnel->RequiredBW,
+                                                          pParams->setup_priority,
+                                                          pParams->hold_priority,
+                                                          Flags,
+                                                          (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                          0,
+                                                          pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+            {
+                 zlog_err("\nmalloc failed %s %d",__FILE__,__LINE__);
+                 return NULL;
+            }
+                
+            return LspRequest(pOpenLspParams,PrimaryLspErHopNumber,pPrimaryLspErHops,pSm,&pSecTunnel,TRUE,pParams);
+        }
+        else
+        {
+            zlog_info("\nTunnels do not have shared hops");
+        }
+        XFREE(MTYPE_TE,pSecondaryLspErHops);
+    }
+    return NULL;
+}
+
+SM_CALL_T *OptimizeSingleLsp(RSVP_TUNNEL_PROPERTIES *pTunnel,IPV4_ADDR dest,IPV4_ADDR source)
+{
+    SM_CALL_T *pCall = NULL;
+    LSP_PATH_SHARED_PARAMS *pParams;
+    USER_LSP *pUserLsp;
+    STATIC_PATH *pStaticPath = NULL;
+    uns8 Flags = 0;
+    ER_HOP *pErHopsList = NULL;
+    RSVP_TUNNEL_PROPERTIES *pDummyTunnel;
+    SM_T *pSm;
+    INGRESS_API *pOpenLspParams;
+    RSVP_LSP_PROPERTIES *pRsvpLsp;
+
+    zlog_info("entering OptimizeSingleLsp");
+    pSm = pTunnel->sm_handle;
+    UnregisterClient((int)pSm,pTunnel->TunnelId);
+    if(pTunnel->pOpenLspParams)
+    {
+        XFREE(MTYPE_TE,pTunnel->pOpenLspParams);
+        pTunnel->pOpenLspParams = NULL;
+    }
+    if(pTunnel->pCrArgs)
+    {
+        if((((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->tunneled == FALSE)&&
+             (((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->data.path.ErHopNumber))
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->data.path.pErHop);
+            ((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->data.path.pErHop = NULL;
+            ((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->data.path.ErHopNumber = 0;
+        }
+        if(((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->AvoidHopNumber)
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->AvoidHopsArray);
+            ((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->AvoidHopsArray = NULL;
+            ((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->AvoidHopNumber = 0;
+        }
+        if(((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->LinkBwNumber)
+        {
+            XFREE(MTYPE_TE,((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->pLinkBw);
+            ((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->pLinkBw = NULL;
+            ((CONSTRAINT_ROUTE_RESOLUTION_ARGS *)(pTunnel->pCrArgs))->LinkBwNumber = 0;
+        }
+        XFREE(MTYPE_TE,pTunnel->pCrArgs);
+    }
+
+    if((pUserLsp = UserLspGet(pTunnel->UserLspName)) != NULL)
+    {
+        pParams = PathParamsGet(pUserLsp,
+                                pTunnel->StaticPathName,
+                                ((!strcmp(pUserLsp->params.Primary,pTunnel->StaticPathName))&&(pUserLsp->pUserLspTunnels->TunnelId == pTunnel->TunnelId)));
+        if(rdb_get_static_path(pTunnel->StaticPathName,
+                                    &pStaticPath) != E_OK)
+        {
+           pStaticPath = NULL; 
+        }
+        if(pStaticPath)
+        {
+            if(SetErHopList(pStaticPath,&pErHopsList) != E_OK)
+            {
+                zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+                return NULL;
+            }
+        }
+        if((pErHopsList != NULL)&&(pErHopsList[0].Loose == 0)) /* nothing to optimize */
+        {
+           XFREE(MTYPE_TE,pErHopsList);
+           return NULL;
+        }
+        if((pUserLsp->pUserLspTunnels->TunnelId == pTunnel->TunnelId)||(pTunnel->ReRoute == 0))
+        {
+            uns32 ErHopNumber;
+            IPV4_ADDR *pErHops;
+            if(pUserLsp->pUserLspTunnels->TunnelId != pTunnel->TunnelId)
+            {
+               if(GetTunnelHops(pUserLsp->pUserLspTunnels,
+                                &ErHopNumber,
+                                &pErHops) != E_OK)
+               {
+                   zlog_info(
+                          "cannot get ER HOPs to be avoided %s %d",
+                          __FILE__,__LINE__);
+                   ErHopNumber = 0;
+                   pErHops = NULL;
+               }
+            }
+            else
+            {
+               ErHopNumber = 0;
+               pErHops = NULL;
+            }
+            Flags |= pParams->record == TRUE ? LABEL_RECORDING_DESIRED : 0;
+            /* for now the FRR is only boolean. However, in future it may be more complicated */
+            Flags |= (pUserLsp->params.FastReRoute == TRUE) ? LOCAL_PROTECTION_DESIRED : 0;
+            if((pStaticPath != NULL)&&(SetErHopList(pStaticPath,&pErHopsList) != E_OK))
+            {
+                zlog_err("Cannot set ER hops list %s %d",__FILE__,__LINE__);
+                return NULL;
+            }
+            if((pOpenLspParams = CreateRequest2Signalling(pUserLsp->params.to,
+                                                          pTunnel->TunnelId,
+                                                          (pStaticPath == NULL) ? 0 : pStaticPath->HopCount,
+                                                          pErHopsList,
+                                                          pParams->BW,
+                                                          pParams->setup_priority,
+                                                          pParams->hold_priority,
+                                                          Flags,
+                                                          (~(pParams->affinity_properties & pParams->affinity_mask)) & pParams->affinity_mask,
+                                                          0,
+                                                          pParams->affinity_properties & pParams->affinity_mask)) == NULL)
+            {
+                zlog_err("malloc failed %s %d",__FILE__,__LINE__);
+                return NULL;
+            }
+            return LspRequest(pOpenLspParams,
+                              ErHopNumber,
+                              pErHops,
+                              pSm,
+                              &pDummyTunnel,
+                              TRUE,
+                              pParams);
+        }
+    }
+    else if((pRsvpLsp = GetWorkingRsvpLsp(pTunnel)) != NULL)
+    {
+        Flags |= LABEL_RECORDING_DESIRED;
+        /* for now the FRR is only boolean. However, in future it may be more complicated */
+        Flags |= LOCAL_PROTECTION_DESIRED;
+        if((pOpenLspParams = CreateRequest2Signalling(dest,
+                                                      pTunnel->TunnelId,
+                                                      0,
+                                                      NULL,
+                                                      pTunnel->RequiredBW,
+                                                      pRsvpLsp->SetupPriority,
+                                                      pRsvpLsp->HoldPriority,
+                                                      Flags,
+                                                      0,0,0)) == NULL)
+        {
+            zlog_err("malloc failed %s %d",__FILE__,__LINE__);
+            return NULL;
+        }
+        return LspRequest(pOpenLspParams,
+                          0,
+                          NULL,
+                          pSm,
+                          &pDummyTunnel,
+                          TRUE,
+                          NULL);
+    }
+    StartCspfRetryTimer(pTunnel);
+    zlog_info("leaving OptimizeSingleLsp");
+    return pCall;
+}
+
+
diff -Naur quagga-0.99.10/rsvpd/te_lsp.h quagga-mpls/rsvpd/te_lsp.h
--- quagga-0.99.10/rsvpd/te_lsp.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_lsp.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,77 @@
+
+#ifndef __LSP_SM_H__
+#define __LSP_SM_H__
+
+typedef enum
+{
+  LSP_SM_MAX_STATE = INIT_STATE + 1
+} LSP_SM_STATE_E;
+
+typedef struct
+{
+  TUNNEL_ID_LIST *TunnelIdHead;
+} LSP_SM_DATA;
+
+typedef enum
+{
+  SETUP_COMPLETE_NOTIF,
+  SETUP_FAILED_NOTIF,
+  TEAR_DOWN_NOTIF
+} LSP_NOTIF_E;
+
+typedef struct
+{
+  uns32 Label;
+  uns16 LspId;
+} LSP_LABEL;
+
+typedef struct
+{
+  uns32 NumberOfItems;
+  float BW;
+  LSP_LABEL *pLspLabel;
+} SETUP_COMPLETE;
+
+typedef struct
+{
+  uns16 LspId;
+  IPV4_ADDR IpAddr;
+} SETUP_FAILED;
+
+typedef struct
+{
+  uns32 NumberOfItems;
+  union
+  {
+    uns16 LspId;
+    uns16 *pLsps;
+  } Lsps;
+} TUNNEL_DOWN_T;
+
+typedef struct
+{
+  PSB_KEY PsbKey;
+  LSP_NOTIF_E ingress_lsp_notif;
+  union
+  {
+    SETUP_COMPLETE setup_complete;
+    SETUP_FAILED setup_failed;
+    TUNNEL_DOWN_T tunnel_down;
+  } data;
+} LSP_SM_NOTIF_DATA;
+
+typedef struct
+{
+  IPV4_ADDR dest;
+  uns16 tunnel_id;
+} LSP_SM_REPLY;
+
+SM_CALL_T *lsp_sm_handler (SM_T * pSm, SM_EVENT_T * sm_data);
+
+SM_CALL_T *lsp_sm_sync_invoke (SM_T * caller, void *data, SM_EVENT_E event);
+
+RSVP_LSP_PROPERTIES *GetWorkingRsvpLsp (RSVP_TUNNEL_PROPERTIES * pTunnel);
+RSVP_LSP_PROPERTIES *CurrentPathHasAvBw (RSVP_TUNNEL_PROPERTIES * pTunnel,
+					 float BW);
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te_rdb.c quagga-mpls/rsvpd/te_rdb.c
--- quagga-0.99.10/rsvpd/te_rdb.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_rdb.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,2854 @@
+/* Module:   rdb.c
+   Contains: TE application route DB and pach cache
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "te.h"
+#include "te_cspf.h"
+
+extern struct zclient *zclient;
+
+/***********************************************************************************
+ ***********************************************************************************
+ *                                                                                 *
+ *                                                                                 *
+ *                             Routing Database Manager                            *
+ *                                                                                 *
+ *                                                                                 *
+ ***********************************************************************************
+ **********************************************************************************/
+
+/** This is an Routing  Table Entry, created via rdb_add_route wrapper
+ **/
+
+/** This is an IfAddr Table Entry, created via rdb_add_ifaddr
+ **/
+typedef struct rdb_ifaddr_tag
+{
+  struct rdb_ifaddr_tag *next;
+  IPV4_ADDR ip_addr;
+  uns32 ifIndex;
+} SYSF_RDB_IFADDR;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  IPV4_ADDR dest;
+  PATH_L_LIST *PathLList;
+  uns32 LListItemsCount;
+} RDB_PATH;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  IPV4_ADDR dest;
+  TE_LINK_L_LIST *TELinkLList;
+  uns32 LListItemsCount;
+} RDB_NEXT_HOP;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  IPV4_ADDR neighbor;
+} TE_LINK_NEXT_HOP;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  IPV4_ADDR dest;
+  ABRS_L_LIST *AbrsLList;
+  uns32 LListItemsCount;
+} RDB_ABRS;
+
+/** This is the Routing Database, created via rdb_create wrapper.
+ **/
+SYSF_RDB_IFADDR *ifaddr_anchor;
+PATRICIA_TREE ASBorderTree;
+PATRICIA_TREE AreaBorderTree;
+PATRICIA_TREE NextHopTree;
+TE_LINK_L_LIST *TeLinkLListHead;
+PATRICIA_TREE RemoteLinkTree[MAX_PATH_TYPE - 1];
+PATRICIA_TREE Link2RouterIdTree;
+STATIC_PATH *StaticPathHead;
+IPV4_ADDR RouterID = 0;
+
+static uns32 compare_er_hops (ER_HOP_L_LIST * er_hops1, TE_HOP * er_hops2,
+			      uns8 hop_count);
+
+static void copy_te_link (TE_LINK * te_link1, TE_LINK * te_link2);
+
+static void delete_te_link (TE_LINK * te_link);
+
+static void delete_abr (ABR * pAbr);
+static void delete_component_link (COMPONENT_LINK * pComponentLink);
+
+uns32
+AmIDestination (IPV4_ADDR dest, uns32 * pDestIf)
+{
+  SYSF_RDB_IFADDR *ifaddr;
+
+  *pDestIf = 0xFFFFFFFF;
+
+  for (ifaddr = ifaddr_anchor; ifaddr != NULL; ifaddr = ifaddr->next)
+    {
+      if (ifaddr->ip_addr == dest)
+	{
+	  *pDestIf = ifaddr->ifIndex;
+	  break;
+	}
+    }
+  return E_OK;
+}
+
+uns32
+IsDestinationNextHop (IPV4_ADDR dest, TE_LINK_L_LIST ** ppTeLinks)
+{
+  RDB_NEXT_HOP *next_hop_entry;
+
+
+  if ((next_hop_entry =
+       (RDB_NEXT_HOP *) patricia_tree_get (&NextHopTree,
+					   (const uns8 *) &dest)) != NULL)
+    {
+      *ppTeLinks = next_hop_entry->TELinkLList;
+    }
+  else
+    {
+      *ppTeLinks = NULL;
+    }
+  return E_OK;
+}
+
+uns32
+IsDestinationIntraArea (IPV4_ADDR dest, PATH_L_LIST ** ppPaths)
+{
+  RDB_PATH *path_entry;
+
+  if ((path_entry =
+       (RDB_PATH *) patricia_tree_get (&AreaBorderTree,
+				       (const uns8 *) &dest)) != NULL)
+    {
+      *ppPaths = path_entry->PathLList;
+    }
+  else
+    {
+      *ppPaths = NULL;
+    }
+  return E_OK;
+}
+
+uns32
+GetPathNumber (IPV4_ADDR dest)
+{
+  RDB_PATH *path_entry;
+
+  if ((path_entry =
+       (RDB_PATH *) patricia_tree_get (&AreaBorderTree,
+				       (const uns8 *) &dest)) != NULL)
+    {
+      return path_entry->LListItemsCount;
+    }
+  return 0;
+}
+
+uns32
+IsDestinationASBorder (IPV4_ADDR dest, ABRS_L_LIST ** ppAbrs)
+{
+  RDB_ABRS *abr_entry;
+
+  if ((abr_entry =
+       (RDB_ABRS *) patricia_tree_get (&ASBorderTree,
+				       (const uns8 *) &dest)) != NULL)
+    {
+      *ppAbrs = abr_entry->AbrsLList;
+    }
+  else
+    {
+      *ppAbrs = NULL;
+    }
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:   rdb_create
+
+  DESCRIPTION:
+
+  Creates a routing database.
+
+*****************************************************************************/
+E_RC
+rdb_create ()
+{
+  PATRICIA_PARAMS params;
+  int i;
+  memset (&params, 0, sizeof (params));
+  params.key_size = sizeof (IPV4_ADDR);
+  params.info_size = 0;
+
+  TeLinkLListHead = NULL;
+  ifaddr_anchor = NULL;
+
+  if (patricia_tree_init (&AreaBorderTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+  if (patricia_tree_init (&ASBorderTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+  if (patricia_tree_init (&NextHopTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+
+  if (patricia_tree_init (&Link2RouterIdTree, &params) != E_OK)
+    {
+      return E_ERR;
+    }
+
+  params.key_size = sizeof (IPV4_ADDR) + sizeof (IPV4_ADDR);
+  params.info_size = 0;
+
+  for (i = 0; i < (MAX_PATH_TYPE - 1); i++)
+    {
+      if (patricia_tree_init (&(RemoteLinkTree[i]), &params) != E_OK)
+	{
+	  return E_ERR;
+	}
+    }
+
+  StaticPathHead = NULL;
+
+  return E_OK;
+}
+
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_destroy
+
+  DESCRIPTION:
+
+
+*****************************************************************************/
+uns32
+rdb_destroy ()
+{
+  RDB_PATH *path_entry;
+  RDB_NEXT_HOP *next_hop_entry;
+  RDB_ABRS *abr_entry;
+  IPV4_ADDR key_ip;
+
+  key_ip = 0;
+  while ((abr_entry =
+	  (RDB_ABRS *) patricia_tree_getnext (&ASBorderTree,
+					      (const uns8 *) &key_ip)) !=
+	 NULL)
+    {
+      while (abr_entry->AbrsLList != NULL)
+	{
+	  ABRS_L_LIST *pAbrLl = abr_entry->AbrsLList->next;
+	  XFREE (MTYPE_TE, abr_entry->AbrsLList->Abr->SummaryProperties);
+	  XFREE (MTYPE_TE, abr_entry->AbrsLList->Abr);
+	  XFREE (MTYPE_TE, abr_entry->AbrsLList);
+	  abr_entry->AbrsLList = pAbrLl;
+	}
+      key_ip = abr_entry->dest;
+      if (patricia_tree_del (&ASBorderTree, &abr_entry->Node) != E_OK)
+	{
+	  zlog_err ("\ncannot delete ASBR");
+	}
+    }
+  patricia_tree_destroy (&ASBorderTree);
+  key_ip = 0;
+  while ((path_entry =
+	  (RDB_PATH *) patricia_tree_getnext (&AreaBorderTree,
+					      (const uns8 *) &key_ip)) !=
+	 NULL)
+    {
+      while (path_entry->PathLList != NULL)
+	{
+	  PATH_L_LIST *pPathLl = path_entry->PathLList->next;
+	  XFREE (MTYPE_TE, path_entry->PathLList->pPath->u.er_hops);
+	  XFREE (MTYPE_TE, path_entry->PathLList->pPath);
+	  XFREE (MTYPE_TE, path_entry->PathLList);
+	  path_entry->PathLList = pPathLl;
+	}
+      key_ip = path_entry->dest;
+      if (patricia_tree_del (&AreaBorderTree, &path_entry->Node) != E_OK)
+	{
+	  zlog_err ("\ncannot delete ASBR");
+	}
+    }
+  patricia_tree_destroy (&AreaBorderTree);
+  key_ip = 0;
+  while ((next_hop_entry =
+	  (RDB_NEXT_HOP *) patricia_tree_getnext (&NextHopTree,
+						  (const uns8 *) &key_ip)) !=
+	 NULL)
+    {
+      while (next_hop_entry->TELinkLList != NULL)
+	{
+	  TE_LINK_L_LIST *pTeLinkLl = next_hop_entry->TELinkLList->next;
+	  XFREE (MTYPE_TE, next_hop_entry->TELinkLList);
+	  next_hop_entry->TELinkLList = pTeLinkLl;
+	}
+      key_ip = next_hop_entry->dest;
+      if (patricia_tree_del (&NextHopTree, &next_hop_entry->Node) != E_OK)
+	{
+	  zlog_err ("\ncannot delete ASBR");
+	}
+    }
+  patricia_tree_destroy (&NextHopTree);
+  return E_OK;
+}
+
+uns32
+compare_er_hops (ER_HOP_L_LIST * er_hops1, TE_HOP * er_hops2, uns8 hop_count)
+{
+  int i;
+  for (i = 0; i < hop_count; i++)
+    {
+      if ((er_hops1->er_hop->local_ip != er_hops2->local_ip) ||
+	  (er_hops1->er_hop->remote_ip != er_hops2->remote_ip))
+	return FALSE;
+      er_hops1 = er_hops1->next;
+      er_hops2++;
+    }
+  return TRUE;
+}
+
+void
+copy_te_link (TE_LINK * te_link1, TE_LINK * te_link2)
+{
+  COMPONENT_LINK *pComponentLink1, *pComponentLink2, *pTemp;
+  int j;
+
+  te_link1->te_link_id = te_link2->te_link_id;
+  te_link1->Status = te_link2->Status;
+  te_link1->type = te_link2->type;
+  memcpy (&te_link1->te_link_properties, &te_link2->te_link_properties,
+	  sizeof (TE_LINK_PROPERTIES));
+  pComponentLink1 = te_link1->component_links;
+  pComponentLink2 = te_link2->component_links;
+  while ((pComponentLink1 != NULL) && (pComponentLink2 != NULL))
+    {
+      pComponentLink1->oifIndex = pComponentLink2->oifIndex;
+//              pComponentLink1->vcard_id = pComponentLink2->vcard_id;
+      for (j = 0; j < 8; j++)
+	{
+	  pComponentLink1->ReservableBW[j] = pComponentLink2->ReservableBW[j];
+	  pComponentLink1->ConfiguredReservableBW[j] =
+	    pComponentLink2->ConfiguredReservableBW[j];
+	}
+      pComponentLink1 = pComponentLink1->next;
+      pComponentLink2 = pComponentLink2->next;
+    }
+  if ((pComponentLink1 == NULL) && (pComponentLink2 != NULL))
+    {
+      while (pComponentLink2 != NULL)
+	{
+	  pTemp = pComponentLink2->next;
+	  pComponentLink2->next = te_link1->component_links;
+	  te_link1->component_links = pComponentLink2;
+	  pComponentLink2 = pTemp;
+	}
+    }
+  else if ((pComponentLink1 != NULL) && (pComponentLink2 == NULL))
+    {
+      while (pComponentLink1 != NULL)
+	{
+	  pTemp = pComponentLink1->next;
+	  delete_component_link (pComponentLink1);
+	  pComponentLink1 = pTemp;
+	}
+    }
+
+}
+
+void
+delete_component_link (COMPONENT_LINK * pComponentLink)
+{
+  XFREE (MTYPE_TE, pComponentLink);
+}
+
+void
+delete_te_link (TE_LINK * te_link)
+{
+  COMPONENT_LINK *pComponentLink;
+
+  while (te_link->component_links != NULL)
+    {
+      pComponentLink = te_link->component_links->next;
+      delete_component_link (te_link->component_links);
+      te_link->component_links = pComponentLink;
+    }
+  XFREE (MTYPE_TE, te_link);
+}
+
+void
+delete_abr (ABR * pAbr)
+{
+  XFREE (MTYPE_TE, pAbr->SummaryProperties);
+  XFREE (MTYPE_TE, pAbr);
+  return;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_add_component_link
+
+  DESCRIPTION:  The routine adds a new TE link into TE links linked links.
+  
+  PARAMETERS:   rdb_handle - Routing Data Base handler
+                pTeLink - pointer to TE Link's properties (may span component links).
+  IMPORTANT NOTE: The memory for pTeLink MUST be allocated from HEAP (not on the stack!!!).
+
+*****************************************************************************/
+
+uns32
+rdb_add_component_link (uns32 TeLinkId, COMPONENT_LINK * pComponentLink)
+{
+  TE_LINK_L_LIST *pTeLinks;
+  COMPONENT_LINK *pTemp;
+  int j;
+  float MaxReservableBW = 0;
+
+  pTeLinks = TeLinkLListHead;
+  while (pTeLinks != NULL)
+    {
+      if (pTeLinks->te_link->te_link_id == TeLinkId)
+	{
+	  while (pComponentLink != NULL)
+	    {
+	      pTemp = pComponentLink->next;
+	      pComponentLink->next = pTeLinks->te_link->component_links;
+	      pTeLinks->te_link->component_links = pComponentLink;
+	      for (j = 0; j < 8; j++)
+		{
+		  pTeLinks->te_link->te_link_properties.ReservableBW[j] +=
+		    pComponentLink->ReservableBW[j];
+		  if (pComponentLink->ReservableBW[j] > MaxReservableBW)
+		    MaxReservableBW = pComponentLink->ReservableBW[j];
+		}
+	      pComponentLink = pTemp;
+	    }
+	  break;
+	}
+      pTeLinks = pTeLinks->next;
+    }
+  if (pTeLinks == NULL)
+    {
+      zlog_err ("\nTE link was not found");
+      return E_ERR;
+    }
+  if (pTeLinks->te_link->te_link_properties.MaxReservableBW < MaxReservableBW)
+    pTeLinks->te_link->te_link_properties.MaxReservableBW = MaxReservableBW;
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_delete_component_link
+
+  DESCRIPTION:  The routine adds a new TE link into TE links linked links.
+  
+  PARAMETERS:   rdb_handle - Routing Data Base handler
+                pTeLink - pointer to TE Link's properties (may span component links).
+  IMPORTANT NOTE: The memory for pTeLink MUST be allocated from HEAP (not on the stack!!!).
+
+*****************************************************************************/
+
+uns32
+rdb_delete_component_link (uns32 TeLinkId, uns32 oIfIndex)
+{
+  TE_LINK_L_LIST *pTeLinks;
+  COMPONENT_LINK *pComponentLink, *pComponentLinkPrev;
+  BOOL delete_te_link = 0;
+  int j;
+
+  pTeLinks = TeLinkLListHead;
+  while (pTeLinks != NULL)
+    {
+      if (pTeLinks->te_link->te_link_id == TeLinkId)
+	{
+	  pComponentLink = pComponentLinkPrev =
+	    pTeLinks->te_link->component_links;
+	  while (pComponentLink != NULL)
+	    {
+	      if (pComponentLink->oifIndex == oIfIndex)
+		{
+		  for (j = 0; j < 8; j++)
+		    pTeLinks->te_link->te_link_properties.ReservableBW[j] -=
+		      pComponentLink->ReservableBW[j];
+		  if (pComponentLink == pTeLinks->te_link->component_links)
+		    pTeLinks->te_link->component_links =
+		      pTeLinks->te_link->component_links->next;
+		  else
+		    pComponentLinkPrev->next = pComponentLink->next;
+		  delete_component_link (pComponentLink);
+		  if (pTeLinks->te_link->component_links == NULL)
+		    delete_te_link = 1;
+		  break;
+		}
+	      pComponentLinkPrev = pComponentLink;
+	      pComponentLink = pComponentLink->next;
+	    }
+	  break;
+	}
+      pTeLinks = pTeLinks->next;
+    }
+  if (pTeLinks == NULL)
+    {
+      zlog_err ("\nTE link was not found");
+      return E_ERR;
+    }
+  if (!delete_te_link)
+    {
+      rdb_te_link_max_lsp_bw_calc (pTeLinks->te_link);
+    }
+  if (delete_te_link)
+    return rdb_del_te_link (TeLinkId);
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_get_te_link
+
+  DESCRIPTION:  The routine gets a component link with IfIndex, belonging to TE Link with TeLinkId.
+  
+  PARAMETERS:   rdb_handle - Routing Data Base handler
+                ppTeLink - pointer to TE Link.
+                                TeLinkId - TE Link identifier.
+                                IfIndex - If index.
+  IMPORTANT NOTE: The memory for pTeLink MUST be allocated from HEAP (not on the stack!!!).
+
+*****************************************************************************/
+
+uns32
+rdb_get_component_link (uns32 TeLinkId, uns32 IfIndex,
+			COMPONENT_LINK ** ppCompLink)
+{
+  TE_LINK_L_LIST *pTeLinks;
+  COMPONENT_LINK *pComponentLinks;
+  zlog_info ("entering rdb_get_component_link");
+  *ppCompLink = NULL;
+  pTeLinks = TeLinkLListHead;
+  while (pTeLinks != NULL)
+    {
+      if (pTeLinks->te_link->te_link_id == TeLinkId)
+	{
+	  pComponentLinks = pTeLinks->te_link->component_links;
+	  while (pComponentLinks != NULL)
+	    {
+	      if (pComponentLinks->oifIndex == IfIndex)
+		{
+		  *ppCompLink = pComponentLinks;
+		  zlog_info ("leaving rdb_get_component_link+");
+		  return E_OK;
+		}
+	      pComponentLinks = pComponentLinks->next;
+	    }
+	}
+      pTeLinks = pTeLinks->next;
+    }
+  zlog_info ("leaving rdb_get_component_link-");
+  return E_ERR;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_get_te_link
+
+  DESCRIPTION:  The routine gets a component link with IfIndex, belonging to TE Link with TeLinkId.
+  
+  PARAMETERS:   rdb_handle - Routing Data Base handler
+                ppTeLink - pointer to TE Link.
+                                TeLinkId - TE Link identifier.
+                                IfIndex - If index.
+  IMPORTANT NOTE: The memory for pTeLink MUST be allocated from HEAP (not on the stack!!!).
+
+*****************************************************************************/
+
+uns32
+rdb_get_te_link (uns32 TeLinkId, TE_LINK ** ppTeLink)
+{
+  TE_LINK_L_LIST *pTeLinks;
+
+  *ppTeLink = NULL;
+
+  pTeLinks = TeLinkLListHead;
+  while (pTeLinks != NULL)
+    {
+      if (pTeLinks->te_link->te_link_id == TeLinkId)
+	{
+	  *ppTeLink = pTeLinks->te_link;
+	  return E_OK;
+	}
+      pTeLinks = pTeLinks->next;
+    }
+  return E_ERR;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_add_te_link
+
+  DESCRIPTION:  The routine adds a new TE link into TE links linked links.
+  
+  PARAMETERS:   rdb_handle - Routing Data Base handler
+                pTeLink - pointer to TE Link's properties (may span component links).
+  IMPORTANT NOTE: The memory for pTeLink MUST be allocated from HEAP (not on the stack!!!).
+
+*****************************************************************************/
+
+void
+rdb_te_link_max_lsp_bw_calc (TE_LINK * pTeLink)
+{
+  float MaxReservableBW = 0;
+  int j;
+  COMPONENT_LINK *pComponentLink = pTeLink->component_links;
+  while (pComponentLink != NULL)
+    {
+      for (j = 0; j < 8; j++)
+	{
+	  if (pComponentLink->ReservableBW[j] > MaxReservableBW)
+	    MaxReservableBW = pComponentLink->ReservableBW[j];
+	}
+      pComponentLink = pComponentLink->next;
+    }
+  pTeLink->te_link_properties.MaxReservableBW = MaxReservableBW;
+  return;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_add_te_link
+
+  DESCRIPTION:  The routine adds a new TE link into TE links linked links.
+  
+  PARAMETERS:   rdb_handle - Routing Data Base handler
+                pTeLink - pointer to TE Link's properties (may span component links).
+  IMPORTANT NOTE: The memory for pTeLink MUST be allocated from HEAP (not on the stack!!!).
+
+*****************************************************************************/
+
+uns32
+rdb_add_te_link (TE_LINK * pTeLink)
+{
+  TE_LINK_L_LIST *pTeLinks, *pTeLinksPrev = NULL, *pNew;
+  PATRICIA_PARAMS params;
+
+  zlog_info
+    ("entering rdb_add_te_link: TE link ID %x Metric %d Colors %x BW %f",
+     pTeLink->te_link_id, pTeLink->te_link_properties.TeMetric,
+     pTeLink->te_link_properties.color_mask,
+     pTeLink->te_link_properties.MaxLspBW);
+
+  if ((pNew =
+       (TE_LINK_L_LIST *) XMALLOC (MTYPE_TE,
+				   sizeof (TE_LINK_L_LIST))) == NULL)
+    {
+      delete_te_link (pTeLink);
+      return E_ERR;
+    }
+  pNew->te_link = pTeLink;
+  pNew->next = NULL;
+
+  memset (&params, 0, sizeof (params));
+  params.key_size = sizeof (IPV4_ADDR);
+  params.info_size = 0;
+
+  if (patricia_tree_init (&pTeLink->NeighborsTree, &params) != E_OK)
+    {
+      XFREE (MTYPE_TE, pNew);
+      return E_ERR;
+    }
+
+  if (TeLinkLListHead == NULL)
+    {
+      TeLinkLListHead = pNew;
+      zlog_info ("leaving rdb_add_te_link1");
+      return E_OK;
+    }
+  else
+    {
+      pTeLinks = TeLinkLListHead;
+      while (pTeLinks != NULL)
+	{
+	  if (pTeLinks->te_link->te_link_id > pTeLink->te_link_id)
+	    {
+	      if (pTeLinks == TeLinkLListHead)
+		{
+		  pNew->next = TeLinkLListHead;
+		  TeLinkLListHead = pNew;
+		}
+	      else
+		{
+		  pTeLinksPrev->next = pNew;
+		  pNew->next = pTeLinks;
+		}
+	      zlog_info ("leaving rdb_add_te_link2");
+	      return E_OK;
+	    }
+	  else if (pTeLinks->te_link->te_link_id == pTeLink->te_link_id)
+	    {
+	      copy_te_link (pTeLinks->te_link, pTeLink);
+	      delete_te_link (pTeLink);
+	      XFREE (MTYPE_TE, pNew);
+	      zlog_info ("leaving rdb_add_te_link3");
+	      return E_OK;
+	    }
+	  pTeLinksPrev = pTeLinks;
+	  pTeLinks = pTeLinks->next;
+	}
+      pTeLinksPrev->next = pNew;
+      zlog_info ("leaving rdb_add_te_link4");
+      return E_OK;
+    }
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_del_te_link
+
+  DESCRIPTION: The routine deletes the TE link with ID - te_link_id from the
+  TE link's linked list.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              te_link_id - TE link ID, by which TE link is found and deleted.
+
+*****************************************************************************/
+
+uns32
+rdb_del_te_link (uns32 te_link_id)
+{
+  TE_LINK_L_LIST *pTeLink, *pPrev;
+  TE_LINK_NEXT_HOP *pTeLinkNextHop;
+  uns32 key = 0;
+
+  zlog_info ("entering rdb_del_te_link: TE link ID %x", te_link_id);
+
+  pPrev = pTeLink = TeLinkLListHead;
+  while (pTeLink != NULL)
+    {
+      if (pTeLink->te_link->te_link_id == te_link_id)
+	break;
+      pPrev = pTeLink;
+      pTeLink = pTeLink->next;
+    }
+  if (pTeLink == NULL)
+    {
+      return E_ERR;
+    }
+
+  if (pPrev == pTeLink)
+    {
+      TeLinkLListHead = TeLinkLListHead->next;
+    }
+  else
+    {
+      pPrev->next = pTeLink->next;
+    }
+  while ((pTeLinkNextHop =
+	  (TE_LINK_NEXT_HOP *) patricia_tree_getnext (&pTeLink->te_link->
+						      NeighborsTree,
+						      (uns8 *) & key)) !=
+	 NULL)
+    {
+      key = pTeLinkNextHop->neighbor;
+      rdb_del_next_hop (pTeLinkNextHop->neighbor,
+			pTeLink->te_link->te_link_id);
+    }
+  delete_te_link (pTeLink->te_link);
+  XFREE (MTYPE_TE, pTeLink);
+  zlog_info ("leaving rdb_del_te_link");
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_add_next_hop
+
+  DESCRIPTION: The routine associates the TE link with ID - te_link_id with
+  the next hop next_hop.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              next_hop - Next Hop's IP address.
+              TeLinkId - TE link ID, by which TE link is found and associated.
+
+*****************************************************************************/
+
+uns32
+rdb_add_next_hop (IPV4_ADDR next_hop, uns32 TeLinkId)
+{
+  RDB_NEXT_HOP *next_hop_entry;
+  TE_LINK_L_LIST *pPrevTeLink, *pTeLinkLList, *pNew, *pTeLinkLList2;
+  TE_LINK_NEXT_HOP *pTeLinkNextHop;
+
+  zlog_info ("entering rdb_add_next_hop: next hop %x TE link ID %x", next_hop,
+	     TeLinkId);
+
+  pTeLinkLList = TeLinkLListHead;
+  while (pTeLinkLList != NULL)
+    {
+      if (pTeLinkLList->te_link->te_link_id == TeLinkId)
+	break;
+      pTeLinkLList = pTeLinkLList->next;
+    }
+  if (pTeLinkLList == NULL)
+    {
+      zlog_err ("an error at %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if ((pNew =
+       (TE_LINK_L_LIST *) XMALLOC (MTYPE_TE,
+				   sizeof (TE_LINK_L_LIST))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  pNew->te_link = pTeLinkLList->te_link;
+
+  if ((pTeLinkNextHop =
+       (TE_LINK_NEXT_HOP *) XMALLOC (MTYPE_TE,
+				     sizeof (TE_LINK_NEXT_HOP))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      XFREE (MTYPE_TE, pNew);
+      return E_ERR;
+    }
+  pTeLinkNextHop->neighbor = next_hop;
+  pTeLinkNextHop->Node.key_info = (uns8 *) & pTeLinkNextHop->neighbor;
+  if (patricia_tree_add (&pNew->te_link->NeighborsTree, &pTeLinkNextHop->Node)
+      != E_OK)
+    {
+      XFREE (MTYPE_TE, pNew);
+      XFREE (MTYPE_TE, pTeLinkNextHop);
+      zlog_err ("an error at %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if ((next_hop_entry =
+       (RDB_NEXT_HOP *) patricia_tree_get (&NextHopTree,
+					   (const uns8 *) &next_hop)) == NULL)
+    {
+      if ((next_hop_entry =
+	   (RDB_NEXT_HOP *) XMALLOC (MTYPE_TE,
+				     sizeof (RDB_NEXT_HOP))) == NULL)
+	{
+	  zlog_err ("an error at %s %d", __FILE__, __LINE__);
+	  XFREE (MTYPE_TE, pNew);
+	  return E_ERR;
+	}
+
+      next_hop_entry->dest = next_hop;
+      next_hop_entry->Node.key_info = (uns8 *) & next_hop_entry->dest;
+
+      next_hop_entry->TELinkLList = pNew;
+      next_hop_entry->LListItemsCount = 1;
+
+      if (patricia_tree_add (&NextHopTree, &next_hop_entry->Node) != E_OK)
+	{
+	  XFREE (MTYPE_TE, next_hop_entry->TELinkLList);
+	  XFREE (MTYPE_TE, next_hop_entry);
+	  XFREE (MTYPE_TE, pNew);
+	  zlog_err ("an error at %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      zlog_info ("leaving rdb_add_next_hop1+");
+      return E_OK;
+    }
+  else
+    {
+      pTeLinkLList2 = next_hop_entry->TELinkLList;
+      pPrevTeLink = pTeLinkLList2;
+      while (pTeLinkLList2 != NULL)
+	{
+	  if (pTeLinkLList2->te_link->te_link_id == TeLinkId)
+	    {
+	      if (patricia_tree_del
+		  (&pNew->te_link->NeighborsTree,
+		   &pTeLinkNextHop->Node) != E_OK)
+		{
+		  zlog_err ("an error at %s %d", __FILE__, __LINE__);
+		  return E_ERR;
+		}
+	      XFREE (MTYPE_TE, pTeLinkNextHop);
+	      XFREE (MTYPE_TE, pNew);
+	      zlog_info ("leaving rdb_add_next_hop2+");
+	      return E_OK;
+	    }
+	  else if (pTeLinkLList2->te_link->te_link_id > TeLinkId)
+	    {
+	      if (pTeLinkLList2 == pPrevTeLink)
+		{
+		  next_hop_entry->TELinkLList = pNew;
+		  pNew->next = pTeLinkLList2;
+		}
+	      else
+		{
+		  pNew->next = pTeLinkLList2;
+		  pPrevTeLink->next = pNew;
+		}
+	      next_hop_entry->LListItemsCount++;
+	      zlog_info ("leaving rdb_add_next_hop3+");
+	      return E_OK;
+	    }
+	  pPrevTeLink = pTeLinkLList2;
+	  pTeLinkLList2 = pTeLinkLList2->next;
+	}			/* of while */
+
+      /* if this point is reached, TE link is new and should be inserted */
+      pPrevTeLink->next = pNew;
+      next_hop_entry->LListItemsCount++;
+      zlog_info ("leaving rdb_add_next_hop4+");
+      return E_OK;
+    }
+  /* should not be reached */
+  zlog_err ("an error at %s %d", __FILE__, __LINE__);
+  XFREE (MTYPE_TE, pNew);
+  return E_ERR;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_local_link_down
+
+  DESCRIPTION: The routine deletes the association of TE link with ID - TeLinkId with
+  it's next hop.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              TeLinkId - TE link ID, by which TE link is found.
+
+*****************************************************************************/
+
+uns32
+rdb_local_link_status_change (uns32 TeLinkId, uns8 Status)
+{
+  TE_LINK_L_LIST *pTeLinkLList;
+  zlog_info ("entering rdb_local_link_status_change: TE link ID %x status %x",
+	     TeLinkId, Status);
+  pTeLinkLList = TeLinkLListHead;
+  while (pTeLinkLList != NULL)
+    {
+      if (pTeLinkLList->te_link->te_link_id == TeLinkId)
+	break;
+      pTeLinkLList = pTeLinkLList->next;
+    }
+  if (pTeLinkLList == NULL)
+    {
+      return E_ERR;
+    }
+
+  pTeLinkLList->te_link->Status = Status;
+  zlog_info ("leaving rdb_local_link_status_change");
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_del_next_hop
+
+  DESCRIPTION: The routine deletes the next hop next_hop.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              next_hop - Next Hop's IP address.
+
+*****************************************************************************/
+
+uns32
+rdb_del_next_hop (IPV4_ADDR next_hop, uns32 te_link_id)
+{
+  RDB_NEXT_HOP *next_hop_entry;
+  TE_LINK_L_LIST *pTeLink, *pTeLinkPrev = NULL;
+  TE_LINK_NEXT_HOP *pTeLinkNextHop;
+
+  zlog_info ("entering rdb_del_next_hop: next hop %x TE link ID %x", next_hop,
+	     te_link_id);
+
+  if ((next_hop_entry =
+       (RDB_NEXT_HOP *) patricia_tree_get (&NextHopTree,
+					   (const uns8 *) &next_hop)) == NULL)
+    {
+      return E_ERR;
+    }
+  pTeLink = TeLinkLListHead;
+  while (pTeLink != NULL)
+    {
+      if (pTeLink->te_link->te_link_id == te_link_id)
+	{
+	  break;
+	}
+      pTeLink = pTeLink->next;
+    }
+  if (pTeLink != NULL)
+    {
+      if ((pTeLinkNextHop =
+	   (TE_LINK_NEXT_HOP *) patricia_tree_get (&pTeLink->te_link->
+						   NeighborsTree,
+						   (const uns8 *) &next_hop))
+	  != NULL)
+	{
+	  if (patricia_tree_del
+	      (&pTeLink->te_link->NeighborsTree,
+	       &pTeLinkNextHop->Node) == E_OK)
+	    {
+	      XFREE (MTYPE_TE, pTeLinkNextHop);
+	    }
+	}
+    }
+  pTeLink = next_hop_entry->TELinkLList;
+  while (pTeLink != NULL)
+    {
+      if (pTeLink->te_link->te_link_id == te_link_id)
+	{
+	  if (pTeLinkPrev == NULL)
+	    {
+	      next_hop_entry->TELinkLList = next_hop_entry->TELinkLList->next;
+	    }
+	  else
+	    {
+	      pTeLinkPrev->next = pTeLink->next;
+	    }
+	  XFREE (MTYPE_TE, pTeLink);
+	  break;
+	}
+      pTeLink = pTeLink->next;
+    }
+  if (next_hop_entry->TELinkLList == NULL)
+    {
+      if (patricia_tree_del (&NextHopTree, &next_hop_entry->Node) != E_OK)
+	{
+	  return E_ERR;
+	}
+      XFREE (MTYPE_TE, next_hop_entry);
+    }
+  zlog_info ("leaving rdb_del_next_hop");
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_add_mod_summary
+
+  DESCRIPTION: The routine adds the summary advertisement to AS border router asbr_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              asbr_ip - AS border's IP address.
+                          *pAbr - pointer to Area Border structure, which contains Area Border's IP
+                          and summary attributes to AS border.
+
+*****************************************************************************/
+uns32
+rdb_add_mod_summary (IPV4_ADDR asbr_ip, ABR * pAbr)
+{
+  RDB_ABRS *abr_entry;
+  ABRS_L_LIST *pAbrsLList, *pAbrsLListPrev, *pNew;
+
+  if ((pNew =
+       (ABRS_L_LIST *) XMALLOC (MTYPE_TE, sizeof (ABRS_L_LIST))) == NULL)
+    {
+      delete_abr (pAbr);
+      zlog_err ("\nFatal at %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  pNew->Abr = pAbr;
+  pNew->next = NULL;
+
+  if ((abr_entry =
+       (RDB_ABRS *) patricia_tree_get (&ASBorderTree,
+				       (const uns8 *) &asbr_ip)) == NULL)
+    {
+      if ((abr_entry =
+	   (RDB_ABRS *) XMALLOC (MTYPE_TE, sizeof (RDB_ABRS))) == NULL)
+	{
+	  delete_abr (pAbr);
+	  return E_ERR;
+	}
+
+      /* Initialize new ASBR */
+      abr_entry->dest = asbr_ip;
+      abr_entry->Node.key_info = (uns8 *) & abr_entry->dest;
+
+      abr_entry->LListItemsCount = 1;
+
+      /* Initialize new and first ABR to ASBR */
+      abr_entry->AbrsLList = pNew;
+      if (patricia_tree_add (&ASBorderTree, &abr_entry->Node) != E_OK)
+	{
+	  XFREE (MTYPE_TE, abr_entry->AbrsLList);
+	  XFREE (MTYPE_TE, abr_entry);
+	  XFREE (MTYPE_TE, pNew);
+	  return E_ERR;
+	}
+      return E_OK;
+    }
+  /* There is such ASBR */
+  else
+    {
+      if ((pAbrsLList = abr_entry->AbrsLList) == NULL)
+	{
+	  patricia_tree_del (&ASBorderTree, &abr_entry->Node);
+	  XFREE (MTYPE_TE, abr_entry);
+	  XFREE (MTYPE_TE, pNew);
+	  zlog_err ("\nFatal at %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      /* Lookup for the ABR in ABR's Linked List  */
+      pAbrsLListPrev = pAbrsLList;
+      while (pAbrsLList != NULL)
+	{
+	  /* if summaries are equal */
+	  if (pAbrsLList->Abr->AbrIpAddr == pAbr->AbrIpAddr)
+	    {
+	      /* free the unneeded memory */
+	      delete_abr (pAbrsLList->Abr);
+	      pAbrsLList->Abr = pAbr;
+	      XFREE (MTYPE_TE, pNew);
+	      return E_OK;
+	    }			/* if this is the ABR ? */
+	  else if (pAbrsLList->Abr->AbrIpAddr > pAbr->AbrIpAddr)
+	    {
+	      /* insert to the head */
+	      if (pAbrsLList == abr_entry->AbrsLList)
+		{
+		  pNew->next = abr_entry->AbrsLList;
+		  abr_entry->AbrsLList = pNew;
+		}
+	      /* insert to the middle */
+	      else
+		{
+		  pAbrsLListPrev->next = pNew;
+		  pNew->next = pAbrsLList;
+		}
+	      abr_entry->LListItemsCount++;
+	      return E_OK;
+	    }
+	  pAbrsLListPrev = pAbrsLList;
+	  pAbrsLList = pAbrsLList->next;
+	}			/* while pAbrsLList != NULL */
+
+      /* If this point is reached, ABR should be inserted to the ABR's list */
+      pAbrsLListPrev->next = pNew;
+      pNew->next = pAbrsLList;
+      abr_entry->LListItemsCount++;
+      return E_OK;
+    }
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_delete_asbr
+
+  DESCRIPTION: When Area Border abr_ip does not longer advertise the reachability
+  information to AS border asbr_ip, the Area Border's summary to the AS border
+  is deleted.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              asbr_ip - AS border's IP address.
+                          abr_ip - Area border's IP address.
+
+*****************************************************************************/
+uns32
+rdb_delete_asbr (IPV4_ADDR asbr_ip, IPV4_ADDR abr_ip)
+{
+  RDB_ABRS *abr_entry;
+  ABRS_L_LIST *pAbrsLList, *pAbrsLListPrev = NULL;
+
+  if ((abr_entry = (RDB_ABRS *) patricia_tree_get (&ASBorderTree,
+						   (const uns8 *) &asbr_ip))
+      == NULL)
+    {
+      return E_ERR;
+    }
+  else
+    {
+      pAbrsLList = abr_entry->AbrsLList;
+      while (pAbrsLList != NULL)
+	{
+	  if (pAbrsLList->Abr->AbrIpAddr == abr_ip)
+	    {
+	      delete_abr (pAbrsLList->Abr);
+
+	      if (abr_entry->AbrsLList == pAbrsLList)
+		{
+		  abr_entry->AbrsLList = abr_entry->AbrsLList->next;
+		  XFREE (MTYPE_TE, pAbrsLList);
+		  abr_entry->LListItemsCount--;
+		  if (abr_entry->AbrsLList == NULL)
+		    {
+		      if (patricia_tree_del (&ASBorderTree, &abr_entry->Node)
+			  != E_OK)
+			{
+			  return E_ERR;
+			}
+		      XFREE (MTYPE_TE, abr_entry);
+		    }
+		}
+	      else
+		{
+		  pAbrsLListPrev->next = pAbrsLList->next;
+		  abr_entry->LListItemsCount--;
+		  XFREE (MTYPE_TE, pAbrsLList);
+
+		}
+	      return E_OK;
+	    }
+	  else
+	    {
+	      pAbrsLListPrev = pAbrsLList;
+	      pAbrsLList = pAbrsLList->next;
+	    }
+	}
+    }
+  return E_ERR;
+}
+
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_create_static_path
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_create_static_path (char *StaticPathName)
+{
+  STATIC_PATH *pStaticPath;
+
+  if (rdb_get_static_path (StaticPathName, &pStaticPath) == E_OK)
+    {
+      zlog_err ("Static path with the name %s already exists %s %d",
+		StaticPathName, __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if ((pStaticPath =
+       (STATIC_PATH *) XMALLOC (MTYPE_TE, sizeof (STATIC_PATH))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  memset (pStaticPath, 0, sizeof (STATIC_PATH));
+  strcpy (pStaticPath->PathName, StaticPathName);
+
+  if (StaticPathHead == NULL)
+    {
+      StaticPathHead = pStaticPath;
+      StaticPathHead->next = NULL;
+    }
+  else
+    {
+      pStaticPath->next = StaticPathHead;
+      StaticPathHead = pStaticPath;
+    }
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_delete_static_path
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_delete_static_path (char *StaticPathName)
+{
+  IPV4_HOP *HopsList, *HopsListNext;
+  STATIC_PATH *pTemp = StaticPathHead, *pPrev = NULL;
+
+  while (pTemp != NULL)
+    {
+      if (strcmp (pTemp->PathName, StaticPathName) == 0)
+	{
+	  HopsList = pTemp->HopList;
+	  while (HopsList != NULL)
+	    {
+	      HopsListNext = HopsList->next;
+	      XFREE (MTYPE_TE, HopsList);
+	      HopsList = HopsListNext;
+	    }
+	  if (pPrev == NULL)
+	    {
+	      StaticPathHead = StaticPathHead->next;
+	    }
+	  else
+	    {
+	      pPrev->next = pTemp->next;
+	    }
+	  XFREE (MTYPE_TE, pTemp);
+	  return E_OK;
+	}
+      pPrev = pTemp;
+      pTemp = pTemp->next;
+    }
+  return E_ERR;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_get_static_path
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_get_static_path (char *pName, STATIC_PATH ** ppStaticPath)
+{
+  if (StaticPathHead == NULL)
+    {
+      *ppStaticPath = NULL;
+    }
+  else
+    {
+      STATIC_PATH *pTemp = StaticPathHead;
+      while (pTemp != NULL)
+	{
+	  if (strcmp (pTemp->PathName, pName) == 0)
+	    {
+	      *ppStaticPath = pTemp;
+	      return E_OK;
+	    }
+	  pTemp = pTemp->next;
+	}
+    }
+  return E_ERR;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_static_path_add_hop
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_static_path_add_hop (char *StaticPathName, IPV4_ADDR IpAddr, int Loose)
+{
+  STATIC_PATH *pStaticPath;
+  IPV4_HOP *HopsList, *HopsListNew;
+
+  if (rdb_get_static_path (StaticPathName, &pStaticPath) != E_OK)
+    {
+      zlog_err ("Cannot find a path with name %s %s %d", StaticPathName,
+		__FILE__, __LINE__);
+      return E_ERR;
+    }
+  if ((HopsListNew =
+       (IPV4_HOP *) XMALLOC (MTYPE_TE, sizeof (IPV4_HOP))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  memset (HopsListNew, 0, sizeof (IPV4_HOP));
+  HopsListNew->IpAddr = IpAddr;
+  HopsListNew->Loose = Loose;
+  if (pStaticPath->HopList == NULL)
+    {
+      pStaticPath->HopList = HopsListNew;
+    }
+  else
+    {
+      HopsList = pStaticPath->HopList;
+      while (HopsList->next != NULL)
+	HopsList = HopsList->next;
+      HopsList->next = HopsListNew;
+    }
+  pStaticPath->HopCount++;
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_static_path_add_hop_by_index
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_static_path_add_hop_by_index (char *StaticPathName, IPV4_ADDR IpAddr,
+				  int Loose, int index)
+{
+  STATIC_PATH *pStaticPath;
+  IPV4_HOP *HopsList, *HopsListNew, *HopsListPrev = NULL;
+  int i = 0;
+
+  if (index == 0)
+    {
+      zlog_err ("invalid parameter (index == 0) %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  index--;
+  if (rdb_get_static_path (StaticPathName, &pStaticPath) != E_OK)
+    {
+      zlog_err ("Cannot find a path %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  zlog_info ("Index %d", index);
+  HopsList = pStaticPath->HopList;
+  while ((HopsList != NULL) && (i < index))
+    {
+      HopsListPrev = HopsList;
+      HopsList = HopsList->next;
+      i++;
+    }
+  if (i != index)
+    {
+      zlog_err ("There is no such index %d %s %d", index, __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if (HopsList)
+    {
+      HopsList->IpAddr = IpAddr;
+      HopsList->Loose = Loose;
+    }
+  else
+    {
+      if ((HopsListNew =
+	   (IPV4_HOP *) XMALLOC (MTYPE_TE, sizeof (IPV4_HOP))) == NULL)
+	{
+	  zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      memset (HopsListNew, 0, sizeof (IPV4_HOP));
+      HopsListNew->IpAddr = IpAddr;
+      HopsListNew->Loose = Loose;
+      if (HopsListPrev == NULL)
+	{
+	  pStaticPath->HopList = HopsListNew;
+	}
+      else
+	{
+	  HopsListPrev->next = HopsListNew;
+	  HopsListNew = HopsList;
+	}
+      pStaticPath->HopCount++;
+    }
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_static_path_add_hop_after_index
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_static_path_add_hop_after_index (char *StaticPathName, IPV4_ADDR IpAddr,
+				     int Loose, int index)
+{
+  STATIC_PATH *pStaticPath;
+  IPV4_HOP *HopsList, *HopsListNew, *HopsListPrev = NULL;
+  int i = 0;
+
+  if (index == 0)
+    {
+      zlog_err ("invalid parameter (index == 0) %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  zlog_info ("Index %d", index);
+  if (rdb_get_static_path (StaticPathName, &pStaticPath) != E_OK)
+    {
+      zlog_err ("Cannot find a path %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  HopsList = pStaticPath->HopList;
+  while ((HopsList != NULL) && (i < index))
+    {
+      HopsListPrev = HopsList;
+      HopsList = HopsList->next;
+      i++;
+    }
+  if (i != index)
+    {
+      zlog_err ("There is no such index %d %s %d", index, __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if ((HopsListNew =
+       (IPV4_HOP *) XMALLOC (MTYPE_TE, sizeof (IPV4_HOP))) == NULL)
+    {
+      zlog_err ("Cannot allocate memory %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  memset (HopsListNew, 0, sizeof (IPV4_HOP));
+  HopsListNew->IpAddr = IpAddr;
+  HopsListNew->Loose = Loose;
+  HopsListPrev->next = HopsListNew;
+  HopsListNew->next = HopsList;
+  pStaticPath->HopCount++;
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_static_path_del_hop
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_static_path_del_hop (char *StaticPathName, IPV4_ADDR IpAddr)
+{
+  STATIC_PATH *pStaticPath;
+  IPV4_HOP *HopsList, *HopsListPrev = NULL;
+
+  if (rdb_get_static_path (StaticPathName, &pStaticPath) != E_OK)
+    {
+      zlog_err ("Cannot find a path %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  HopsList = pStaticPath->HopList;
+  while (HopsList != NULL)
+    {
+      if (HopsList->IpAddr == IpAddr)
+	break;
+      HopsListPrev = HopsList;
+      HopsList = HopsList->next;
+    }
+
+  if (HopsList == NULL)
+    {
+      zlog_err ("Hop %x is not found %s %d", IpAddr, __FILE__, __LINE__);
+      return E_ERR;
+    }
+
+  if (HopsListPrev == NULL)
+    {
+      pStaticPath->HopList = pStaticPath->HopList->next;
+    }
+  else
+    {
+      HopsListPrev->next = HopsList->next;
+    }
+  XFREE (MTYPE_TE, HopsList);
+  pStaticPath->HopCount--;
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_static_path_del_hop_by_index
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_static_path_del_hop_by_index (char *StaticPathName, int index)
+{
+  STATIC_PATH *pStaticPath;
+  IPV4_HOP *HopsList, *HopsListPrev = NULL;
+  int i = 0;
+
+  if (index == 0)
+    {
+      zlog_err ("invalid parameter (index == 0) %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  index--;
+  if (rdb_get_static_path (StaticPathName, &pStaticPath) != E_OK)
+    {
+      zlog_err ("Cannot find a path %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  zlog_info ("Index %d", index);
+  HopsList = pStaticPath->HopList;
+  while ((HopsList != NULL) && (i < index))
+    {
+      HopsListPrev = HopsList;
+      HopsList = HopsList->next;
+      i++;
+    }
+  if (i != index)
+    {
+      zlog_err ("There is no such index %d %s %d", index, __FILE__, __LINE__);
+      return E_ERR;
+    }
+  if (HopsListPrev == NULL)
+    {
+      pStaticPath->HopList = pStaticPath->HopList->next;
+    }
+  else
+    {
+      HopsListPrev->next = HopsList->next;
+    }
+  XFREE (MTYPE_TE, HopsList);
+  pStaticPath->HopCount--;
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_add_mod_path
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_add_mod_path (IPV4_ADDR dest_ip, PATH * pPath)
+{
+  RDB_PATH *path_entry;
+  PATH_L_LIST *pPathLList, *pPathLListPrev, *pErHopPathList;
+
+  PATH_L_LIST *pNewPath;
+  TE_HOP *pKxErHop;
+  ER_HOP_L_LIST *pKxErHopsLList;
+  TE_HOP *pErHops, *pErHops2Free;
+  link_key_t link_key;
+  int i, j;
+
+
+  if ((pPath->PathProperties.PathType <= EMPTY_PATH)
+      || (pPath->PathProperties.PathType >= MAX_PATH_TYPE))
+    {
+      zlog_err ("Invalid path type %d", pPath->PathProperties.PathType);
+      return E_ERR;
+    }
+
+  if ((pNewPath =
+       (PATH_L_LIST *) XMALLOC (MTYPE_TE, sizeof (PATH_L_LIST))) == NULL)
+    {
+      XFREE (MTYPE_TE, pPath->u.er_hops);
+      XFREE (MTYPE_TE, pPath);
+      zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+      return E_ERR;
+    }
+  pNewPath->pPath = pPath;
+  pNewPath->next = NULL;
+
+  if ((path_entry =
+       (RDB_PATH *) patricia_tree_get (&AreaBorderTree,
+				       (const uns8 *) &dest_ip)) == NULL)
+    {
+      if ((path_entry =
+	   (RDB_PATH *) XMALLOC (MTYPE_TE, sizeof (RDB_PATH))) == NULL)
+	{
+	  XFREE (MTYPE_TE, pNewPath);
+	  zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      /* Initialize new ABR */
+      path_entry->dest = dest_ip;
+      path_entry->Node.key_info = (uns8 *) & path_entry->dest;
+      path_entry->PathLList = pNewPath;
+
+      path_entry->LListItemsCount = 1;
+
+      if (patricia_tree_add (&AreaBorderTree, &path_entry->Node) != E_OK)
+	{
+	  XFREE (MTYPE_TE, path_entry);
+	  XFREE (MTYPE_TE, pNewPath);
+	  XFREE (MTYPE_TE, pPath->u.er_hops);
+	  XFREE (MTYPE_TE, pPath);
+	  zlog_err ("cannot add node to patricia %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+    }
+  /* There is no such ABR */
+  else
+    {
+      /* Initialize new Path to ABR */
+      if ((pPathLList = path_entry->PathLList) == NULL)
+	{
+	  patricia_tree_del (&AreaBorderTree, &path_entry->Node);
+	  XFREE (MTYPE_TE, path_entry);
+	  XFREE (MTYPE_TE, pNewPath);
+	  XFREE (MTYPE_TE, pPath->u.er_hops);
+	  XFREE (MTYPE_TE, pPath);
+	  zlog_err ("Fatal at %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      /* Lookup for the Path in Path's Linked List  */
+      pPathLListPrev = pPathLList;
+      while (pPathLList != NULL)
+	{
+	  /* if path vectors are equal */
+	  if ((pPathLList->pPath->PathProperties.PathType ==
+	       pPath->PathProperties.PathType)
+	      && (pPathLList->pPath->PathProperties.PathHopCount ==
+		  pPath->PathProperties.PathHopCount)
+	      &&
+	      (compare_er_hops
+	       (pPathLList->pPath->u.er_hops_l_list, pPath->u.er_hops,
+		pPath->PathProperties.PathHopCount) == TRUE))
+	    {
+	      /* if path properties are equal, nothing to do */
+	      memcpy (&pPathLList->pPath->PathProperties,
+		      &pPath->PathProperties, sizeof (PATH_PROPERTIES));
+
+	      pErHops = pPath->u.er_hops;
+
+	      for (i = 0; i < pPath->PathProperties.PathHopCount;
+		   i++, pErHops++)
+		{
+		  LINK_PROPERTIES link_prop;
+
+		  memset (&link_prop, 0, sizeof (link_prop));
+
+		  link_prop.LinkType = PSC_PATH;
+		  link_prop.LinkMaxLspBW = pErHops->MaxLspBW;
+		  link_prop.LinkMaxReservableBW = pErHops->MaxReservableBW;
+		  link_prop.LinkTeMetric = pErHops->te_metric;
+		  for (j = 0; j < 8; j++)
+		    {
+		      link_prop.LinkReservableBW[j] =
+			pErHops->ReservableBW[j];
+		    }
+		  link_prop.LinkColorMask = pErHops->ColorMask;
+		  rdb_link_state_update (pErHops->local_ip,
+					 pErHops->remote_ip, &link_prop);
+		}
+	      XFREE (MTYPE_TE, pPath->u.er_hops);
+	      XFREE (MTYPE_TE, pPath);
+	      XFREE (MTYPE_TE, pNewPath);
+	      zlog_info ("paths are equal %s %d", __FILE__, __LINE__);
+	      return E_OK;
+	    }			/* if er hops equal */
+	  pPathLListPrev = pPathLList;
+	  pPathLList = pPathLList->next;
+	}			/* while */
+
+      /* If this point is reached, path should be inserted to the path list */
+      /* insert to the head */
+      pNewPath->next = path_entry->PathLList;
+      path_entry->PathLList = pNewPath;
+      path_entry->LListItemsCount++;
+    }				/* ABR already exists */
+
+  /* now, check for existence of links to remote links and set if required */
+  pErHops2Free = pPath->u.er_hops;	/* to free after the loop */
+
+  pErHops = pPath->u.er_hops;
+
+  pNewPath->pPath->u.er_hops_l_list = pKxErHopsLList = NULL;
+
+  for (i = 0; i < pPath->PathProperties.PathHopCount; i++, pErHops++)
+    {
+      link_key.local_ip = pErHops->local_ip;
+      link_key.remote_ip = pErHops->remote_ip;
+
+      if ((pErHopPathList =
+	   (PATH_L_LIST *) XMALLOC (MTYPE_TE, sizeof (PATH_L_LIST))) == NULL)
+	{
+	  zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pErHopPathList->pPath = pPath;
+
+      if ((pKxErHop =
+	   (TE_HOP *)
+	   patricia_tree_get (&
+			      (RemoteLinkTree
+			       [pPath->PathProperties.PathType - 1]),
+			      (const uns8 *) &link_key)) == NULL)
+	{
+	  if ((pKxErHop =
+	       (TE_HOP *) XMALLOC (MTYPE_TE, sizeof (TE_HOP))) == NULL)
+	    {
+	      zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+
+	  pKxErHop->pPathList = pErHopPathList;
+	  pKxErHop->pPathList->next = NULL;
+	  pKxErHop->local_ip = link_key.local_ip;
+	  pKxErHop->remote_ip = link_key.remote_ip;
+	  pKxErHop->MaxLspBW = pErHops->MaxLspBW;
+	  pKxErHop->MaxReservableBW = pErHops->MaxReservableBW;
+	  for (j = 0; j < 8; j++)
+	    pKxErHop->ReservableBW[j] = pErHops->ReservableBW[j];
+	  pKxErHop->te_metric = pErHops->te_metric;
+	  pKxErHop->ColorMask = pErHops->ColorMask;
+
+	  pKxErHop->Node.key_info = (uns8 *) & pKxErHop->local_ip;
+	  zlog_info
+	    ("Creation of new remote link: local %x remote %x MaxBw %f MaxResBw %f %x",
+	     pKxErHop->local_ip, pKxErHop->remote_ip, pKxErHop->MaxLspBW,
+	     pKxErHop->MaxReservableBW, pKxErHop->te_metric);
+	  if (patricia_tree_add
+	      (&(RemoteLinkTree[pPath->PathProperties.PathType - 1]),
+	       &pKxErHop->Node) != E_OK)
+	    {
+	      zlog_err ("cannot add node to patricia %s %d", __FILE__,
+			__LINE__);
+	      return E_ERR;
+	    }
+	}
+      else
+	{
+	  pErHopPathList->next = pKxErHop->pPathList;
+	  pKxErHop->pPathList = pErHopPathList;
+	}
+
+      if (pNewPath->pPath->u.er_hops_l_list == NULL)
+	{
+	  if ((pKxErHopsLList =
+	       (ER_HOP_L_LIST *) XMALLOC (MTYPE_TE,
+					  sizeof (ER_HOP_L_LIST))) == NULL)
+	    {
+	      zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  pNewPath->pPath->u.er_hops_l_list = pKxErHopsLList;
+	}
+      else
+	{
+	  if ((pKxErHopsLList->next =
+	       (ER_HOP_L_LIST *) XMALLOC (MTYPE_TE,
+					  sizeof (ER_HOP_L_LIST))) == NULL)
+	    {
+	      zlog_err ("malloc failed %s %d", __FILE__, __LINE__);
+	      return E_ERR;
+	    }
+	  pKxErHopsLList = pKxErHopsLList->next;
+	}
+
+      pKxErHopsLList->next = NULL;
+
+      pKxErHopsLList->er_hop = pKxErHop;
+    }
+
+  XFREE (MTYPE_TE, pErHops2Free);
+
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_connectivity_broken
+
+  DESCRIPTION: When IGP receives a Link Advertisement (LSA or LSP), which says there is no
+  connectivity from the node from_node to the node to_node for path type path_type (packet switch,
+  lambda switch, fiber switch, TDM switch), such path is deleted.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              from_node - IP address of the node, from which connectivity is broken.
+                          to_node - IP address of the node, to which connectivity is broken.
+                          path_type - connectivity of which type is broken.
+                          
+  IMPORTANT NOTE: This API is not intended for indication of own link failures.
+
+*****************************************************************************/
+
+uns32
+rdb_connectivity_broken (IPV4_ADDR from_node, IPV4_ADDR to_node,
+			 PATH_TYPE path_type)
+{
+  RDB_PATH *path_entry;
+  TE_HOP *pKxErHop;
+  link_key_t link_key;
+  PATH *pPath, *pSavedPath;
+
+  if ((path_type <= EMPTY_PATH) || (path_type >= MAX_PATH_TYPE))
+    return E_ERR;
+  link_key.local_ip = from_node;
+  link_key.remote_ip = to_node;
+
+  /* first, find the remote link */
+  if ((pKxErHop =
+       (TE_HOP *) patricia_tree_get (&(RemoteLinkTree[path_type - 1]),
+				     (const uns8 *) &link_key)) != NULL)
+    {
+      PATH_L_LIST *pPathList, *pPathListNext, *pPathList2, *pPathListPrev2;
+      zlog_info ("connectivity broken event upon reception of TE LSA: %x %x",
+		 from_node, to_node);
+      pPathList = pKxErHop->pPathList;
+      /* for each path, passing through this remote link */
+      while (pPathList != NULL)
+	{
+	  pPathListNext = pPathList->next;
+	  pSavedPath = pPathList->pPath;
+	  /* find path's destination */
+	  zlog_info ("Path's destination %x", pPathList->pPath->destination);
+	  if ((path_entry = (RDB_PATH *) patricia_tree_get (&AreaBorderTree,
+							    (const uns8 *)
+							    &pPathList->
+							    pPath->
+							    destination)) !=
+	      NULL)
+	    {
+	      zlog_info
+		("Delete path from the list, hold by destination entry");
+	      pPathListPrev2 = pPathList2 = path_entry->PathLList;
+	      /* find the path in the path destination's path list */
+	      while (pPathList2 != NULL)
+		{
+		  /* path is found ? */
+		  if (pPathList2->pPath == pPathList->pPath)
+		    {
+		      zlog_info ("path found on the destination's list ...");
+		      /* extract the path from the path destination's path list
+		         without freing the memory */
+		      if (pPathList2 == pPathListPrev2)
+			path_entry->PathLList = path_entry->PathLList->next;
+		      else
+			pPathListPrev2->next = pPathList2->next;
+
+		      path_entry->LListItemsCount--;
+		      /* if ocausionally, path destination's path list became empty, 
+		         delete the destination from the patricia tree 
+		         and free the destination's memory */
+		      if (path_entry->PathLList == NULL)
+			{
+			  patricia_tree_del (&AreaBorderTree,
+					     &path_entry->Node);
+			  XFREE (MTYPE_TE, path_entry);
+			}
+		      /* free the destination's path list item memory */
+		      XFREE (MTYPE_TE, pPathList2);
+		      break;
+		    }		/* path found on the path's destination's path list */
+		  pPathListPrev2 = pPathList2;
+		  pPathList2 = pPathList2->next;
+		}		/* of while (through the path list of path's destination */
+	    }
+	  /* now, the memory of the remote link's path list item and 
+	     path's itself memory remain. Check if path references remote links,
+	     which are referenced by this path only. If such links are discovered,
+	     remove them. */
+	  zlog_info ("now, delete the path from the lists, hold by TE links");
+
+	  pPath = pPathList->pPath;
+	  while (pPath->u.er_hops_l_list != NULL)
+	    {
+	      ER_HOP_L_LIST *pTemp = pPath->u.er_hops_l_list->next;
+	      if (pPath->u.er_hops_l_list->er_hop != NULL)
+		{
+		  pPathListPrev2 = pPathList2 =
+		    pPath->u.er_hops_l_list->er_hop->pPathList;
+		  while (pPathList2 != NULL)
+		    {
+		      if (pPathList2->pPath == pPath)
+			{
+			  if (pPathListPrev2 == pPathList2)
+			    {
+			      pPath->u.er_hops_l_list->er_hop->pPathList =
+				pPath->u.er_hops_l_list->er_hop->pPathList->
+				next;
+			    }
+			  else
+			    {
+			      pPathListPrev2->next = pPathList2->next;
+			    }
+			  XFREE (MTYPE_TE, pPathList2);
+			  break;
+			}
+		      pPathListPrev2 = pPathList2;
+		      pPathList2 = pPathList2->next;
+		    }
+		}
+	      if (pPath->u.er_hops_l_list->er_hop->pPathList == NULL)
+		{
+		  zlog_info
+		    ("All paths, passed through the TE link are removed from the path list of this TE link %x %x",
+		     pPath->u.er_hops_l_list->er_hop->local_ip,
+		     pPath->u.er_hops_l_list->er_hop->remote_ip);
+		  patricia_tree_del (&(RemoteLinkTree[0]),
+				     &pPath->u.er_hops_l_list->er_hop->Node);
+		  XFREE (MTYPE_TE, pPath->u.er_hops_l_list->er_hop);
+		}
+	      XFREE (MTYPE_TE, pPath->u.er_hops_l_list);
+	      pPath->u.er_hops_l_list = pTemp;
+	    }
+
+
+	  zlog_info ("all er hop list items cleaned. delete the path");
+
+	  XFREE (MTYPE_TE, pSavedPath);
+
+	  pPathList = pPathListNext;
+	}
+    }
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_link_state_update
+
+  DESCRIPTION: When IGP receives a Link Advertisement (LSA or LSP), which says that TE link properties
+  are updated, this routine is called to update paths' properties for each path, pass the pair
+  from_node->to_node.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              from_node - Local IP address of the TE link.
+                          to_node - Remote IP address of the TE link.
+                          path_type - TE link type (there may be TE links of different packet switch capacity between
+                          the two nodes).
+                          
+  IMPORTANT NOTE: The IGP instance may aggregate the two or more TE links between the same nodes as well
+  as some node aggregates the component links into one TE link. The conditions are: same IGP and TE 
+  costs of the TE links.
+  This routine is for Link State Updates of remote links only.
+
+*****************************************************************************/
+
+uns32
+rdb_link_state_update (IPV4_ADDR from_node, IPV4_ADDR to_node,
+		       LINK_PROPERTIES * pLinkProperties)
+{
+  TE_HOP *pKxErHop;
+  link_key_t link_key;
+  int i, recalculate = 0;
+  float PathReservableBW[8], PathMaxLspBW, PathMaxReservableBW, delta;
+  int ColorMask, j;
+
+  if ((pLinkProperties->LinkType <= EMPTY_PATH)
+      || (pLinkProperties->LinkType >= MAX_PATH_TYPE))
+    return E_ERR;
+  link_key.local_ip = from_node;
+  link_key.remote_ip = to_node;
+
+  /* first, find the remote link */
+  if ((pKxErHop =
+       (TE_HOP *)
+       patricia_tree_get (&(RemoteLinkTree[pLinkProperties->LinkType - 1]),
+			  (const uns8 *) &link_key)) != NULL)
+    {
+      PATH_L_LIST *pPathList;
+
+      pPathList = pKxErHop->pPathList;
+      zlog_info ("Path Cash update upon updated TE LSA %x %x", from_node,
+		 to_node);
+      /* for each path, passes over this remote link */
+      while (pPathList != NULL)
+	{
+	  PATH *pPath;
+	  PATH_PROPERTIES *pProperties = &(pPathList->pPath->PathProperties);
+	  ER_HOP_L_LIST *pErHopLList;
+
+	  recalculate = 0;
+
+	  if (pLinkProperties->LinkMaxLspBW <= pProperties->PathMaxLspBW)
+	    pProperties->PathMaxLspBW = pLinkProperties->LinkMaxLspBW;
+	  else
+	    recalculate = 1;
+
+	  if (pLinkProperties->LinkMaxReservableBW <=
+	      pProperties->PathMaxReservableBW)
+	    pProperties->PathMaxReservableBW =
+	      pLinkProperties->LinkMaxReservableBW;
+	  else
+	    recalculate = 1;
+
+	  for (j = 0; j < 8; j++)
+	    {
+	      if (pLinkProperties->LinkReservableBW[j] <=
+		  pProperties->PathReservableBW[j])
+		pProperties->PathReservableBW[j] =
+		  pLinkProperties->LinkReservableBW[j];
+	      else
+		{
+		  recalculate = 1;
+		  break;
+		}
+	    }
+
+	  if (pKxErHop->ColorMask != pLinkProperties->LinkColorMask)
+	    recalculate = 1;
+
+	  delta = pKxErHop->te_metric - pLinkProperties->LinkTeMetric;
+	  pProperties->PathSumTeMetric -= delta;
+
+	  pPath = pPathList->pPath;
+	  pErHopLList = pPath->u.er_hops_l_list;
+
+	  if (recalculate)
+	    {
+	      for (j = 0; j < 8; j++)
+		PathReservableBW[j] = pLinkProperties->LinkReservableBW[j];
+	      PathMaxLspBW = pLinkProperties->LinkMaxLspBW;
+	      PathMaxReservableBW = pLinkProperties->LinkMaxReservableBW;
+	      ColorMask = pLinkProperties->LinkColorMask;
+	      for (i = 0; i < pPath->PathProperties.PathHopCount; i++)
+		{
+		  if (pErHopLList->er_hop != pKxErHop)
+		    {
+		      if (pErHopLList->er_hop->MaxLspBW < PathMaxLspBW)
+			PathMaxLspBW = pErHopLList->er_hop->MaxLspBW;
+		      if (pErHopLList->er_hop->MaxReservableBW <
+			  PathMaxReservableBW)
+			PathMaxReservableBW =
+			  pErHopLList->er_hop->MaxReservableBW;
+		      for (j = 0; j < 8; j++)
+			if (pErHopLList->er_hop->ReservableBW[j] <
+			    PathReservableBW[j])
+			  PathReservableBW[j] =
+			    pErHopLList->er_hop->ReservableBW[j];
+		      ColorMask |= pErHopLList->er_hop->ColorMask;
+		    }
+		  pErHopLList = pErHopLList->next;
+		}
+	      pProperties->PathColorMask = ColorMask;
+	      pProperties->PathMaxLspBW = PathMaxLspBW;
+	      pProperties->PathMaxReservableBW = PathMaxReservableBW;
+	      for (j = 0; j < 8; j++)
+		pProperties->PathReservableBW[j] = PathReservableBW[j];
+	    }
+
+	  pPathList = pPathList->next;
+	}
+
+      pKxErHop->ColorMask = pLinkProperties->LinkColorMask;
+      pKxErHop->MaxLspBW = pLinkProperties->LinkMaxLspBW;
+      pKxErHop->MaxReservableBW = pLinkProperties->LinkMaxReservableBW;
+      for (j = 0; j < 8; j++)
+	pKxErHop->ReservableBW[j] = pLinkProperties->LinkReservableBW[j];
+      pKxErHop->te_metric = pLinkProperties->LinkTeMetric;
+    }
+  else
+    {
+//        zlog_info("Link %x %x is not in the TE DB",from_node,to_node);
+    }
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_remote_link_bw_update
+
+  DESCRIPTION: When new RSVP LSP is created, if BW is expected to be allocated (according to rules - RSVP styles),
+  this routine must be called to maintain the path cash.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              from_node - Local IP address of the TE link.
+                          to_node - Remote IP address of the TE link.
+                          BW2Decrease - BW to be subtrackted from the remote link's reservable BW.
+              LinkSwitchCap - link's switching capability.
+              
+  IMPORTANT NOTE: This routine should be called on the case when BW is to be decreased only and
+   not in the case, when BW is to be increased - we wait for IGP's update.
+                          
+*****************************************************************************/
+
+uns32
+rdb_remote_link_bw_update (IPV4_ADDR from_node,
+			   IPV4_ADDR to_node,
+			   float BW2Decrease,
+			   uns8 Priority, PATH_TYPE LinkSwitchCap)
+{
+  TE_HOP *pKxErHop;
+  link_key_t link_key;
+  int i, recalculate = 0;
+  float PathMaxReservableBW, HopMaxReservableBW;
+
+  link_key.local_ip = from_node;
+  link_key.remote_ip = to_node;
+
+  /* first, find the remote link */
+  if ((pKxErHop =
+       (TE_HOP *) patricia_tree_get (&(RemoteLinkTree[LinkSwitchCap - 1]),
+				     (const uns8 *) &link_key)) != NULL)
+    {
+      PATH_L_LIST *pPathList;
+
+      pPathList = pKxErHop->pPathList;
+
+      if ((BW2Decrease > pKxErHop->ReservableBW[Priority]) ||
+	  (BW2Decrease > pKxErHop->MaxLspBW))
+	{
+	  zlog_err
+	    ("\nBW to decrease is larger than MaxLspBW or Reservable BW %s %d",
+	     __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      for (i = Priority; i < 8; i++)
+	{
+	  if (pKxErHop->ReservableBW[i] >= BW2Decrease)
+	    {
+	      /*zlog_info("\nDecreasing %x BW from %x %x with %x BW",BW2Decrease,pKxErHop->local_ip,pKxErHop->remote_ip,pKxErHop->ReservableBW[i]); */
+	      pKxErHop->ReservableBW[i] -= BW2Decrease;	/* what with MaxLspBW ? -:) */
+	    }
+	  else
+	    pKxErHop->ReservableBW[i] = 0;
+	}
+      HopMaxReservableBW = 0;
+      for (i = 0; i < 8; i++)
+	{
+	  if (pKxErHop->ReservableBW[i] > HopMaxReservableBW)
+	    HopMaxReservableBW = pKxErHop->ReservableBW[i];
+	}
+      pKxErHop->MaxReservableBW = HopMaxReservableBW;
+
+      {
+#if 0
+	REMOTE_BW_UPDATE_REQUEST *pRemoteBwUpdateReq;
+	struct zapi_te_remote_link link;
+	memset(&link, 0, sizeof(struct zapi_te_remote_link));
+
+	rdb_remote_link_router_id_get (pKxErHop->local_ip,
+				       &link.routerid.s_addr);
+	link.from_node.s_addr = pKxErHop->local_ip;
+	link.to_node.s_addr = pKxErHop->remote_ip;
+	for (i = 0; i < 8; i++)
+	  link.reservable_bw[i] = pKxErHop->ReservableBW[i];
+	zapi_te_remote_link_update(zclient, &link);
+#endif
+      }
+
+      /* for each path, passes over this remote link */
+      while (pPathList != NULL)
+	{
+	  PATH_PROPERTIES *pProperties = &(pPathList->pPath->PathProperties);
+	  recalculate = 0;
+
+	  if (BW2Decrease > pProperties->PathReservableBW[Priority])
+	    {
+	      zlog_info
+		("\nBW to decrease is larger than MaxLspBW or Reservable BW %s %d",
+		 __FILE__, __LINE__);
+	      pPathList = pPathList->next;
+	      continue;
+	    }
+	  for (i = Priority; i < 8; i++)
+	    {
+	      if (pKxErHop->ReservableBW[i] <
+		  pProperties->PathReservableBW[i])
+		{
+		  /*zlog_info("\nForcing path BW to %x (prev - %x BW) Path's dest %x",pKxErHop->ReservableBW[i],pProperties->PathReservableBW[i],pPathList->pPath->destination); */
+		  pProperties->PathReservableBW[i] =
+		    pKxErHop->ReservableBW[i];
+		}
+	    }
+	  PathMaxReservableBW = 0;
+	  for (i = 0; i < 8; i++)
+	    {
+	      if (pProperties->PathReservableBW[i] > PathMaxReservableBW)
+		PathMaxReservableBW = pProperties->PathReservableBW[i];
+	    }
+	  pProperties->PathMaxReservableBW = PathMaxReservableBW;
+	  pPathList = pPathList->next;
+	}
+    }
+  else
+    {
+      zlog_err
+	("\nSomething wrong - expected remote link %x %x is not found %s %d",
+	 from_node, to_node, __FILE__, __LINE__);
+    }
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_remote_link_2_router_id_mapping
+
+  DESCRIPTION: This function is called to map a link to the router ID.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              link_id - Local IP address of the TE link.
+              router_id - Router ID, to which this link belongs.
+                          
+*****************************************************************************/
+
+uns32
+rdb_remote_link_2_router_id_mapping (IPV4_ADDR link_id, IPV4_ADDR router_id)
+{
+  LINK_2_ROUTER_ID *pLink2RouterId;
+
+  if ((pLink2RouterId =
+       (LINK_2_ROUTER_ID *) patricia_tree_get (&Link2RouterIdTree,
+					       (const uns8 *) &link_id)) ==
+      NULL)
+    {
+      if ((pLink2RouterId =
+	   (LINK_2_ROUTER_ID *) XMALLOC (MTYPE_TE,
+					 sizeof (LINK_2_ROUTER_ID))) == NULL)
+	{
+	  zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  return E_ERR;
+	}
+      pLink2RouterId->link_id = link_id;
+      pLink2RouterId->router_id = router_id;
+      pLink2RouterId->Node.key_info = (uns8 *) & pLink2RouterId->link_id;
+      if (patricia_tree_add (&Link2RouterIdTree, &pLink2RouterId->Node) !=
+	  E_OK)
+	{
+	  zlog_err ("\ncannot add node to patricia %s %d...", __FILE__,
+		    __LINE__);
+	  return E_ERR;
+	}
+    }
+  else
+    {
+      pLink2RouterId->router_id = router_id;
+    }
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_remote_link_2_router_id_mapping_withdraw
+
+  DESCRIPTION: This function is called to remove a mapping of the link to the router ID.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              link_id - Local IP address of the TE link.
+              router_id - Router ID, to which this link belongs.
+                          
+*****************************************************************************/
+
+uns32
+rdb_remote_link_2_router_id_mapping_withdraw (IPV4_ADDR link_id)
+{
+  LINK_2_ROUTER_ID *pLink2RouterId;
+
+  if ((pLink2RouterId =
+       (LINK_2_ROUTER_ID *) patricia_tree_get (&Link2RouterIdTree,
+					       (const uns8 *) &link_id)) !=
+      NULL)
+    {
+      if (patricia_tree_del (&Link2RouterIdTree, &pLink2RouterId->Node) !=
+	  E_OK)
+	{
+	  zlog_err ("\ncannot add node to patricia %s %d...", __FILE__,
+		    __LINE__);
+	  return E_ERR;
+	}
+    }
+  return E_OK;
+}
+
+uns32
+rdb_set_router_id (IPV4_ADDR IpAddr)
+{
+  RouterID = IpAddr;
+  return E_OK;
+}
+
+IPV4_ADDR
+rdb_get_router_id ()
+{
+  return RouterID;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_remote_link_router_id_get
+
+  DESCRIPTION: This function is called to determine that link belongs to certain router.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              from_node - Local IP address of the TE link.
+              router_id - Router ID, to which this link belongs.
+                          
+*****************************************************************************/
+
+uns32
+rdb_remote_link_router_id_get (IPV4_ADDR from_node, IPV4_ADDR * router_id)
+{
+  LINK_2_ROUTER_ID *pLink2RouterId;
+
+  /* first, find the remote link */
+  if ((pLink2RouterId =
+       (LINK_2_ROUTER_ID *) patricia_tree_get (&Link2RouterIdTree,
+					       (const uns8 *) &from_node)) !=
+      NULL)
+    {
+      *router_id = pLink2RouterId->router_id;
+      return E_OK;
+    }
+  return E_ERR;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_igp_hello
+
+  DESCRIPTION: This function is called upon reception of Hello message from IGP in order to update it with already existing allocations.
+  
+  PARAMETERS: 
+                          
+*****************************************************************************/
+
+uns32
+rdb_igp_hello ()
+{
+  TE_LINK_L_LIST *pTeLinks;
+
+  pTeLinks = TeLinkLListHead;
+  while (pTeLinks != NULL)
+    {
+      BwUpdateRequest2Igp (pTeLinks->te_link);
+      /* component links are not processed yet */
+      pTeLinks = pTeLinks->next;
+    }
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_remote_link_router_id_get
+
+  DESCRIPTION: This function is called to determine that link belongs to certain router.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              from_node - Local IP address of the TE link.
+              router_id - Router ID, to which this link belongs.
+                          
+*****************************************************************************/
+
+uns32
+rdb_remote_link_router_id_mapping_dump (struct vty * vty)
+{
+  LINK_2_ROUTER_ID *pLink2RouterId;
+  IPV4_ADDR key = 0;
+
+  vty_out (vty, "%s", VTY_NEWLINE);
+
+  while ((pLink2RouterId =
+	  (LINK_2_ROUTER_ID *) patricia_tree_getnext (&Link2RouterIdTree,
+						      (const uns8 *) &key)) !=
+	 NULL)
+    {
+      vty_out (vty, "LinkID %x RouterID %x%s", pLink2RouterId->link_id,
+	       pLink2RouterId->router_id, VTY_NEWLINE);
+      key = pLink2RouterId->link_id;
+    }
+  vty_out (vty, "%s", VTY_NEWLINE);
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_te_links_dump
+
+  DESCRIPTION:           Displays TE links.
+
+
+*****************************************************************************/
+uns32
+rdb_te_links_dump (struct vty * vty)
+{
+  TE_LINK_L_LIST *pTeLinks;
+  COMPONENT_LINK *pComponentLink;
+  int j, i;
+
+  pTeLinks = TeLinkLListHead;
+  vty_out (vty, "%s", VTY_NEWLINE);
+  while (pTeLinks != NULL)
+    {
+      vty_out (vty,
+	       "TE LINK ID %x type %x MaxLspBW %f MaxReservableBW %f TE metric %x color mask %x%s",
+	       pTeLinks->te_link->te_link_id, pTeLinks->te_link->type,
+	       pTeLinks->te_link->te_link_properties.MaxLspBW,
+	       pTeLinks->te_link->te_link_properties.MaxReservableBW,
+	       pTeLinks->te_link->te_link_properties.TeMetric,
+	       pTeLinks->te_link->te_link_properties.color_mask, VTY_NEWLINE);
+      vty_out (vty, "ReservableBW (0-7):%s", VTY_NEWLINE);
+      for (j = 0; j < 8; j++)
+	vty_out (vty, "  %f",
+		 pTeLinks->te_link->te_link_properties.ReservableBW[j]);
+
+      vty_out (vty, "%s", VTY_NEWLINE);
+
+      pComponentLink = pTeLinks->te_link->component_links;
+      while (pComponentLink != NULL)
+	{
+	  vty_out (vty, "Out IF %x%s", pComponentLink->oifIndex, VTY_NEWLINE);
+	  vty_out (vty, "ConfiguredReservable BW (0 -7):%s", VTY_NEWLINE);
+	  for (j = 0; j < 8; j++)
+	    vty_out (vty, "  %f", pComponentLink->ConfiguredReservableBW[j]);
+	  vty_out (vty, "Reservable BW (0 -7):%s", VTY_NEWLINE);
+	  for (j = 0; j < 8; j++)
+	    vty_out (vty, "  %f", pComponentLink->ReservableBW[j]);
+	  vty_out (vty, "ALLOCATED:");
+	  for (j = 0; j < 8; j++)
+	    {
+	      vty_out (vty, "%s", VTY_NEWLINE);
+	      for (i = 0; i < 8; i++)
+		{
+		  vty_out (vty, "  %f", pComponentLink->AllocatedBW[j][i]);
+		}
+	    }
+	  vty_out (vty, "%s", VTY_NEWLINE);
+	  pComponentLink = pComponentLink->next;
+	}
+      pTeLinks = pTeLinks->next;
+    }
+  return E_OK;
+}
+
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_next_hop_dump
+
+  DESCRIPTION:           Displays Next Hops.
+
+
+*****************************************************************************/
+uns32
+rdb_next_hop_dump (struct vty * vty)
+{
+  RDB_NEXT_HOP *next_hop_entry;
+  IPV4_ADDR key_ip;
+  int j;
+
+  vty_out (vty, "%s", VTY_NEWLINE);
+
+  key_ip = 0;
+
+  while ((next_hop_entry =
+	  (RDB_NEXT_HOP *) patricia_tree_getnext (&NextHopTree,
+						  (const uns8 *) &key_ip)) !=
+	 NULL)
+    {
+      TE_LINK_L_LIST *pTeLink;
+      COMPONENT_LINK *pComponentLink;
+
+      pTeLink = next_hop_entry->TELinkLList;
+      vty_out (vty, "Next Hop %x%s", next_hop_entry->dest, VTY_NEWLINE);
+      while (pTeLink != NULL)
+	{
+	  switch (pTeLink->te_link->type)
+	    {
+	    case PSC_PATH:
+	      vty_out (vty, "TE LINK ID %x%s", pTeLink->te_link->te_link_id,
+		       VTY_NEWLINE);
+	      vty_out (vty,
+		       "MaxLspBW %f MaxReservableBW %f TE metric %x Color Mask %x%s",
+		       pTeLink->te_link->te_link_properties.MaxLspBW,
+		       pTeLink->te_link->te_link_properties.MaxReservableBW,
+		       pTeLink->te_link->te_link_properties.TeMetric,
+		       pTeLink->te_link->te_link_properties.color_mask,
+		       VTY_NEWLINE);
+	      vty_out (vty, "ReservableBW (0-7):%s", VTY_NEWLINE);
+	      for (j = 0; j < 8; j++)
+		vty_out (vty, "  %f",
+			 pTeLink->te_link->te_link_properties.
+			 ReservableBW[j]);
+	      break;
+	    default:
+	      zlog_info ("\nIS not supported %s %d", __FILE__, __LINE__);
+	    }
+	  pComponentLink = pTeLink->te_link->component_links;
+	  while (pComponentLink != NULL)
+	    {
+	      vty_out (vty, "Out IF %x%s", pComponentLink->oifIndex,
+		       VTY_NEWLINE);
+	      vty_out (vty, "ReservableBW (0-7):%s", VTY_NEWLINE);
+	      for (j = 0; j < 8; j++)
+		vty_out (vty, "  %f", pComponentLink->ReservableBW[j]);
+	      pComponentLink = pComponentLink->next;
+	    }
+	  pTeLink = pTeLink->next;
+	}
+      key_ip = next_hop_entry->dest;
+    }
+    /** Ok do the ifaddr list now.
+     **/
+  vty_out (vty, "%s", VTY_NEWLINE);
+  return E_OK;
+
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_summary_dump
+
+  DESCRIPTION:           Displays summary advertisements.
+
+
+*****************************************************************************/
+uns32
+rdb_summary_dump ()
+{
+  RDB_ABRS *abr_entry;
+  IPV4_ADDR key_ip;
+  int j;
+
+  zlog_debug ("\n\n");
+
+  key_ip = 0;
+
+  while ((abr_entry = (RDB_ABRS *) patricia_tree_getnext (&ASBorderTree,
+							  (const uns8 *)
+							  &key_ip)) != NULL)
+    {
+      ABRS_L_LIST *pAbrsList;
+      int i;
+
+      pAbrsList = abr_entry->AbrsLList;
+      zlog_debug ("\nASBR %x", abr_entry->dest);
+      while (pAbrsList != NULL)
+	{
+	  SUMMARY_PROPERTIES *pProperties = pAbrsList->Abr->SummaryProperties;
+	  zlog_debug ("\nABR %x", pAbrsList->Abr->AbrIpAddr);
+	  for (i = 0; i < pAbrsList->Abr->NumberOfSummaries; i++)
+	    {
+	      zlog_debug ("\nMaxLspBW %f", pProperties->SummaryMaxLspBW);
+	      zlog_debug ("\nMaxReservableBW %f",
+			  pProperties->SummaryMaxReservableBW);
+	      zlog_debug ("\nReservableBW (0-7):");
+	      for (j = 0; j < 8; j++)
+		zlog_debug ("  %f", pProperties->SummaryReservableBW[j]);
+	      pProperties++;
+	    }
+	  pAbrsList = pAbrsList->next;
+	}
+      key_ip = abr_entry->dest;
+    }
+
+    /** Ok do the ifaddr list now.
+     **/
+  zlog_debug ("\n\n");
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_path_dump
+
+  DESCRIPTION:       Displays the paths.
+
+
+*****************************************************************************/
+uns32
+rdb_path_dump (struct vty * vty)
+{
+  RDB_PATH *path_entry;
+  IPV4_ADDR key_ip;
+  int j;
+
+  key_ip = 0;
+  vty_out (vty, "%s", VTY_NEWLINE);
+  while ((path_entry = (RDB_PATH *) patricia_tree_getnext (&AreaBorderTree,
+							   (const uns8 *)
+							   &key_ip)) != NULL)
+    {
+      PATH_L_LIST *pPathList;
+      int i;
+
+      pPathList = path_entry->PathLList;
+      vty_out (vty, "Path to ABR %x%s", path_entry->dest, VTY_NEWLINE);
+      while (pPathList != NULL)
+	{
+	  ER_HOP_L_LIST *er_hop_l_list;
+	  er_hop_l_list = pPathList->pPath->u.er_hops_l_list;
+	  switch (pPathList->pPath->PathProperties.PathType)
+	    {
+	    case PSC_PATH:
+	    case LSC_PATH:
+	    case FSC_PATH:
+	    case TSC_PATH:
+	      for (i = 0;
+		   i < (pPathList->pPath->PathProperties.PathHopCount) &&
+		   (er_hop_l_list != NULL); i++)
+		{
+		  vty_out (vty, "%x %x -->", er_hop_l_list->er_hop->local_ip,
+			   er_hop_l_list->er_hop->remote_ip);
+		  er_hop_l_list = er_hop_l_list->next;
+		}
+	      break;
+
+	    default:
+	      zlog_info ("This path type %d is not supported",
+			 pPathList->pPath->PathProperties.PathType);
+	    }
+	  vty_out (vty,
+		   "MaxLspBW %f MaxReservableBW %f TE metric %x Hop count %x Color Mask %x%s",
+		   pPathList->pPath->PathProperties.PathMaxLspBW,
+		   pPathList->pPath->PathProperties.PathMaxReservableBW,
+		   pPathList->pPath->PathProperties.PathSumTeMetric,
+		   pPathList->pPath->PathProperties.PathHopCount,
+		   pPathList->pPath->PathProperties.PathColorMask,
+		   VTY_NEWLINE);
+	  vty_out (vty, "ReservableBW (0-7):%s", VTY_NEWLINE);
+	  for (j = 0; j < 8; j++)
+	    vty_out (vty, "  %f",
+		     pPathList->pPath->PathProperties.PathReservableBW[j]);
+
+	  pPathList = pPathList->next;
+	}
+      key_ip = path_entry->dest;
+    }
+  vty_out (vty, "%s", VTY_NEWLINE);
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_remote_link_dump
+
+  DESCRIPTION:       Displays the remote links.
+
+
+*****************************************************************************/
+
+uns32
+rdb_remote_link_dump (struct vty * vty)
+{
+  TE_HOP *pKxErHop;
+  link_key_t link_key;
+  int i, j;
+
+  vty_out (vty, "%s", VTY_NEWLINE);
+
+  link_key.local_ip = 0;
+  link_key.remote_ip = 0;
+
+  for (i = 0; i < (MAX_PATH_TYPE - 1); i++)
+    {
+      while ((pKxErHop =
+	      (TE_HOP *) patricia_tree_getnext (&(RemoteLinkTree[i - 1]),
+						(const uns8 *) &link_key)) !=
+	     NULL)
+	{
+	  vty_out (vty, "Link %x->%x%s", pKxErHop->local_ip,
+		   pKxErHop->remote_ip, VTY_NEWLINE);
+
+	  vty_out (vty,
+		   "MaxLspBW %f MaxReservableBW %f TE metric %x ColorMask %x %s",
+		   pKxErHop->MaxLspBW, pKxErHop->MaxReservableBW,
+		   pKxErHop->te_metric, pKxErHop->ColorMask, VTY_NEWLINE);
+	  vty_out (vty, "ReservableBW (0-7):%s", VTY_NEWLINE);
+	  for (j = 0; j < 8; j++)
+	    vty_out (vty, "  %f", pKxErHop->ReservableBW[j]);
+#if 0
+	  pPathList = pKxErHop->pPathList;
+	  while (pPathList != NULL)
+	    {
+	      ER_HOP_L_LIST *er_hop_l_list;
+	      er_hop_l_list = pPathList->pPath->u.er_hops_l_list;
+	      if ((i + 1) != pPathList->pPath->PathProperties.PathType)
+		{
+		  zlog_info ("expected path type %d, existing %d",
+			     (i + 1),
+			     pPathList->pPath->PathProperties.PathType);
+		}
+	      zlog_info ("");
+	      for (j = 0;
+		   j < (pPathList->pPath->PathProperties.PathHopCount) &&
+		   (er_hop_l_list != NULL); j++)
+		{
+		  zlog_info ("%x %x -->", er_hop_l_list->er_hop->local_ip,
+			     er_hop_l_list->er_hop->remote_ip);
+		  er_hop_l_list = er_hop_l_list->next;
+		}
+	      zlog_info
+		("MaxLspBW %f MaxReservableBW %f TE metric %x Hop count %x Color Mask %x",
+		 pPathList->pPath->PathProperties.PathMaxLspBW,
+		 pPathList->pPath->PathProperties.PathMaxReservableBW,
+		 pPathList->pPath->PathProperties.PathSumTeMetric,
+		 pPathList->pPath->PathProperties.PathHopCount,
+		 pPathList->pPath->PathProperties.PathColorMask);
+	      zlog_info ("ReservableBW (0-7):");
+	      for (j = 0; j < 8; j++)
+		zlog_info ("  %f",
+			   pPathList->pPath->PathProperties.
+			   PathReservableBW[j]);
+	      pPathList = pPathList->next;
+	    }
+#endif
+	  link_key.local_ip = pKxErHop->local_ip;
+	  link_key.remote_ip = pKxErHop->remote_ip;
+	}
+    }
+  vty_out (vty, "%s", VTY_NEWLINE);
+  return E_OK;
+}
+
+/*****************************************************************************
+
+  PROCEDURE NAME:    rdb_static_path_dump
+
+  DESCRIPTION: Adds a new path *pPath to destination dest_ip.
+  
+  PARAMETERS: rdb_handle - Routing Data Base handle.
+              dest_ip - Path destination's IP address.
+                          *pPath - pointer to the path description (path's summary propertieslist of hops
+                          and hops' properties).
+
+*****************************************************************************/
+uns32
+rdb_static_path_dump (char *pName, struct vty * vty)
+{
+  STATIC_PATH *pStaticPath;
+  IPV4_HOP *pHops;
+
+  vty_out (vty, "%s", VTY_NEWLINE);
+  pStaticPath = StaticPathHead;
+  while (pStaticPath != NULL)
+    {
+      if (pName)
+	{
+	  if (strcmp (pName, pStaticPath->PathName) != 0)
+	    {
+	      pStaticPath = pStaticPath->next;
+	      continue;
+	    }
+	}
+      vty_out (vty, "Path %s%s", pStaticPath->PathName, VTY_NEWLINE);
+      vty_out (vty, "Hops (%d): %s", pStaticPath->HopCount, VTY_NEWLINE);
+      for (pHops = pStaticPath->HopList; pHops; pHops = pHops->next)
+	{
+	  vty_out (vty, " Loose %x IP Address %x %s",
+		   pHops->Loose, pHops->IpAddr, VTY_NEWLINE);
+	}
+      if (pName)
+	{
+	  if (strcmp (pName, pStaticPath->PathName) == 0)
+	    {
+	      break;
+	    }
+	}
+      pStaticPath = pStaticPath->next;
+    }
+  vty_out (vty, "%s", VTY_NEWLINE);
+  return E_OK;
+}
diff -Naur quagga-0.99.10/rsvpd/te_rdb.h quagga-mpls/rsvpd/te_rdb.h
--- quagga-0.99.10/rsvpd/te_rdb.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_rdb.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,238 @@
+#ifndef RDB_H
+#define RDB_H
+
+typedef enum
+{
+  EMPTY_PATH,
+  PSC_PATH,
+  LSC_PATH,
+  FSC_PATH,
+  TSC_PATH,
+  PSC_LSP,
+  LSC_LSP,
+  FSC_LSP,
+  TSC_LSP,
+  MAX_PATH_TYPE
+} PATH_TYPE;
+
+typedef struct _link_properties_
+{
+  PATH_TYPE LinkType;
+  uns32 LinkCost;
+  float LinkMaxReservableBW;
+  float LinkReservableBW[8];
+  float LinkMaxLspBW;
+  uns32 LinkTeMetric;
+  uns32 LinkColorMask;
+} LINK_PROPERTIES;
+
+typedef struct _path_properties_
+{
+  PATH_TYPE PathType;
+  uns32 PathCost;
+  float PathMaxReservableBW;
+  float PathReservableBW[8];
+  float PathMaxLspBW;
+  uns32 PathSumTeMetric;
+  uns32 PathColorMask;
+  uns8 PathHopCount;
+} PATH_PROPERTIES;
+
+#if 0
+typedef struct
+{
+  IPV4_ADDR local_ip_addr;
+  IPV4_ADDR remote_ip_addr;
+  float MaxReservableBW;
+  float ReservableBW[8];
+  float MaxLspBW;
+  uns32 te_metric;
+  uns32 ColorMask;
+} TE_HOP;
+#else
+typedef struct _path_l_list_
+{
+  struct _path_ *pPath;
+  struct _path_l_list_ *next;
+} PATH_L_LIST;
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  IPV4_ADDR local_ip;
+  IPV4_ADDR remote_ip;
+  IPV4_ADDR adv_router_id;
+  float MaxReservableBW;
+  float ReservableBW[8];
+  float MaxLspBW;
+  uns32 te_metric;
+  uns32 ColorMask;
+  uns32 Cost;
+  PATH_L_LIST *pPathList;
+} TE_HOP;
+#endif
+
+typedef struct
+{
+  IPV4_ADDR local_ip;
+  IPV4_ADDR remote_ip;
+} link_key_t;
+
+typedef struct
+{
+  PATH_TYPE SummaryPathType;
+  float SummaryMaxLspBW;
+  float SummaryMaxReservableBW;
+  float SummaryReservableBW[8];
+  uns32 SummaryCost;
+} SUMMARY_PROPERTIES;
+
+typedef struct _abr_
+{
+  IPV4_ADDR AbrIpAddr;
+  uns8 NumberOfSummaries;
+  SUMMARY_PROPERTIES *SummaryProperties;
+} ABR;
+
+typedef struct _te_link_properties_
+{
+  float MaxReservableBW;
+  float ReservableBW[8];
+  float MaxLspBW;
+  uns32 TeMetric;
+  uns32 color_mask;
+} TE_LINK_PROPERTIES;
+
+typedef struct _component_link_
+{
+  uns32 oifIndex;
+  float ReservableBW[8];
+  float ConfiguredReservableBW[8];
+  float AllocatedBW[8][8];
+  PATRICIA_TREE ProtectionTree;
+  PATRICIA_TREE IngressProtectionTree;
+  struct _component_link_ *next;
+} COMPONENT_LINK;
+
+typedef struct _te_link_
+{
+  uns32 te_link_id;
+  uns8 Status;
+  PATH_TYPE type;
+  TE_LINK_PROPERTIES te_link_properties;
+  PATRICIA_TREE NeighborsTree;
+  COMPONENT_LINK *component_links;
+} TE_LINK;
+
+
+typedef struct
+{
+  PATRICIA_NODE Node;
+  IPV4_ADDR link_id;
+  IPV4_ADDR router_id;
+} LINK_2_ROUTER_ID;
+
+typedef struct _er_hop_l_list_
+{
+  TE_HOP *er_hop;
+  struct _er_hop_l_list_ *next;
+} ER_HOP_L_LIST;
+
+typedef struct _path_
+{
+  IPV4_ADDR destination;
+  PATH_PROPERTIES PathProperties;
+  union
+  {
+    ER_HOP_L_LIST *er_hops_l_list;
+    TE_HOP *er_hops;
+  } u;
+} PATH;
+
+typedef struct _abrs_l_list_
+{
+  ABR *Abr;
+  struct _abrs_l_list_ *next;
+} ABRS_L_LIST;
+
+typedef struct _te_link_l_list_
+{
+  TE_LINK *te_link;
+  struct _te_link_l_list_ *next;
+} TE_LINK_L_LIST;
+
+typedef struct _ipv4_hop_
+{
+  IPV4_ADDR IpAddr;
+  int Loose;
+  struct _ipv4_hop_ *next;
+} IPV4_HOP;
+
+typedef struct _static_path_l_list_
+{
+  char PathName[32];
+  int HopCount;
+  IPV4_HOP *HopList;
+  struct _static_path_l_list_ *next;
+} STATIC_PATH;
+
+uns32 AmIDestination (IPV4_ADDR dest, uns32 * pDestIf);
+uns32 IsDestinationNextHop (IPV4_ADDR dest, TE_LINK_L_LIST ** ppTeLinks);
+uns32 IsDestinationIntraArea (IPV4_ADDR dest, PATH_L_LIST ** ppPaths);
+uns32 GetPathNumber (IPV4_ADDR dest);
+uns32 IsDestinationASBorder (IPV4_ADDR dest, ABRS_L_LIST ** ppAbrs);
+E_RC rdb_create ();
+uns32 rdb_destroy ();
+uns32 rdb_add_component_link (uns32 TeLinkId,
+			      COMPONENT_LINK * pComponentLink);
+uns32 rdb_delete_component_link (uns32 TeLinkId, uns32 oIfIndex);
+uns32 rdb_get_component_link (uns32 TeLinkId, uns32 IfIndex,
+			      COMPONENT_LINK ** ppCompLink);
+uns32 rdb_add_mod_path (IPV4_ADDR dest_ip, PATH * pPath);
+uns32 rdb_connectivity_broken (IPV4_ADDR from_node, IPV4_ADDR to_node,
+			       PATH_TYPE path_type);
+uns32 rdb_link_state_update (IPV4_ADDR from_node, IPV4_ADDR to_node,
+			     LINK_PROPERTIES * pLinkProperties);
+uns32 rdb_remote_link_bw_update (IPV4_ADDR from_node, IPV4_ADDR to_node,
+				 float BW2Decrease, uns8 Priority,
+				 PATH_TYPE LinkSwitchCap);
+uns32 rdb_remote_link_2_router_id_mapping (IPV4_ADDR link_id,
+					   IPV4_ADDR router_id);
+uns32 rdb_remote_link_2_router_id_mapping_withdraw (IPV4_ADDR link_id);
+uns32 rdb_set_router_id (IPV4_ADDR IpAddr);
+IPV4_ADDR rdb_get_router_id ();
+uns32 rdb_remote_link_router_id_get (IPV4_ADDR from_node,
+				     IPV4_ADDR * router_id);
+uns32 rdb_static_path_del_hop_by_index (char *StaticPathName, int index);
+uns32 rdb_static_path_del_hop (char *StaticPathName, IPV4_ADDR IpAddr);
+uns32 rdb_static_path_add_hop_by_index (char *StaticPathName,
+					IPV4_ADDR IpAddr, int Loose,
+					int index);
+uns32 rdb_static_path_add_hop_after_index (char *StaticPathName,
+					   IPV4_ADDR IpAddr, int Loose,
+					   int index);
+uns32 rdb_static_path_add_hop (char *StaticPathName, IPV4_ADDR IpAddr,
+			       int Loose);
+uns32 rdb_get_static_path (char *pName, STATIC_PATH ** ppStaticPath);
+uns32 rdb_create_static_path (char *StaticPathName);
+uns32 rdb_delete_static_path (char *StaticPathName);
+uns32 rdb_delete_asbr (IPV4_ADDR asbr_ip, IPV4_ADDR abr_ip);
+uns32 rdb_add_mod_summary (IPV4_ADDR asbr_ip, ABR * pAbr);
+uns32 rdb_del_next_hop (IPV4_ADDR next_hop, uns32 te_link_id);
+uns32 rdb_local_link_status_change (uns32 TeLinkId, uns8 Status);
+uns32 rdb_add_next_hop (IPV4_ADDR next_hop, uns32 TeLinkId);
+uns32 rdb_del_te_link (uns32 te_link_id);
+uns32 rdb_add_te_link (TE_LINK * pTeLink);
+void rdb_te_link_max_lsp_bw_calc (TE_LINK * pTeLink);
+uns32 rdb_get_te_link (uns32 TeLinkId, TE_LINK ** ppTeLink);
+
+uns32 rdb_next_hop_dump (struct vty *vty);
+uns32 rdb_summary_dump ();
+uns32 rdb_path_dump (struct vty *vty);
+uns32 rdb_remote_link_dump (struct vty *vty);
+uns32 rdb_static_path_dump (char *, struct vty *vty);
+uns32 rdb_te_links_dump (struct vty *vty);
+uns32 rdb_remote_link_router_id_mapping_dump (struct vty *vty);
+uns32 rdb_igp_hello ();
+
+#endif
diff -Naur quagga-0.99.10/rsvpd/te_tr.c quagga-mpls/rsvpd/te_tr.c
--- quagga-0.99.10/rsvpd/te_tr.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_tr.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,430 @@
+/* Module:   transit_req_sm.c
+   Contains: TE application transit PATH message processing
+   Module creator: Vadim Suraev, vadim_suraev@hotmail.com
+   */
+#include "te.h"
+
+static SM_CALL_T *transit_req_sm_empty_handler (SM_T * pSm,
+						SM_EVENT_T * sm_data);
+static SM_CALL_T *transit_req_sm_init (SM_T * pSm, SM_EVENT_T * sm_data);
+static SM_CALL_T *transit_req_sm_constraint_route_resolution (SM_T * pSm,
+							      SM_EVENT_T *
+							      sm_data);
+static void TransitReqSmDestroy (SM_T * pSm);
+
+static SM_CALL_T *
+transit_req_sm_empty_handler (SM_T * pSm, SM_EVENT_T * sm_data)
+{
+  zlog_err ("new_transit_req_sm_empty_handler, state %d", pSm->state);
+  return NULL;
+}
+
+static SM_CALL_T *
+transit_req_sm_init (SM_T * pSm, SM_EVENT_T * sm_event)
+{
+  SM_CALL_T *pCall = NULL;
+  TRANSIT_REQ_SM_DATA *pTransitReqSmData = NULL;
+  CONSTRAINT_ROUTE_RESOLUTION_ARGS *pCrArgs;
+  PATH_NOTIFICATION *pTransitReqParams;
+
+  switch (sm_event->event)
+    {
+    case TRANSIT_REQ_EVENT:
+      sm_gen_event_trace (sm_event->event);
+
+      if ((pTransitReqSmData =
+	   (TRANSIT_REQ_SM_DATA *) XMALLOC (MTYPE_TE,
+					    sizeof (TRANSIT_REQ_SM_DATA))) ==
+	  NULL)
+	{
+	  zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  TransitReqSmDestroy (pSm);
+	  return NULL;
+	}
+
+      pTransitReqSmData->pTransitReqParams = sm_event->data;
+      pSm->data = pTransitReqSmData;
+      pTransitReqParams = pTransitReqSmData->pTransitReqParams;
+
+      if ((pCrArgs =
+	   (CONSTRAINT_ROUTE_RESOLUTION_ARGS *) XMALLOC (MTYPE_TE,
+							 sizeof
+							 (CONSTRAINT_ROUTE_RESOLUTION_ARGS)))
+	  == NULL)
+	{
+	  zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+	  TransitReqSmDestroy (pSm);
+	  return NULL;
+	}
+      pCrArgs->BW = pTransitReqParams->BW;
+      zlog_info ("\npCrArgs->BW %d", pCrArgs->BW);
+      if (pTransitReqParams->ErHopNumber != 0)
+	{
+	  zlog_info ("\ndestination %x", pTransitReqParams->ErHops[0]);
+	  pCrArgs->dest = pTransitReqParams->ErHops[0];
+	}
+      else
+	{
+	  pCrArgs->dest = ntohl (pTransitReqParams->PsbKey.Session.Dest);
+	  zlog_info ("\ndestination1 %x",
+		     pTransitReqParams->PsbKey.Session.Dest);
+	}
+
+      pCrArgs->PsbKey.Session = pTransitReqParams->PsbKey.Session;
+
+      if (pTransitReqParams->RA_Valid == TRUE)
+	{
+	  zlog_info
+	    ("\nSESSION ATTRIBUTES: SetPrio %x HoldPrio %x Shared %x FRR %x LabelRecording %x ExclAny %x InclAny %x InclAll %x",
+	     pTransitReqParams->SetupPrio, pTransitReqParams->HoldPrio,
+	     pTransitReqParams->SharedExplicit,
+	     pTransitReqParams->LocalProtection,
+	     pTransitReqParams->LabelRecordingDesired,
+	     pTransitReqParams->ExcludeAny, pTransitReqParams->IncludeAny,
+	     pTransitReqParams->IncludeAll);
+	  pCrArgs->SetupPriority = pTransitReqParams->SetupPrio;
+	  pCrArgs->HoldPriority = pTransitReqParams->HoldPrio;
+	  pCrArgs->ExclColorMask = pTransitReqParams->ExcludeAny;
+	  pCrArgs->InclColorMask = pTransitReqParams->IncludeAny;
+	}
+      else
+	{
+	  zlog_info ("\nSESSION ATTRIBUTES: %x %x %x %x %x",
+		     pTransitReqParams->SetupPrio,
+		     pTransitReqParams->HoldPrio,
+		     pTransitReqParams->SharedExplicit,
+		     pTransitReqParams->LocalProtection,
+		     pTransitReqParams->LocalProtection);
+	  pCrArgs->SetupPriority = pTransitReqParams->SetupPrio;
+	  pCrArgs->HoldPriority = pTransitReqParams->HoldPrio;
+	}
+
+      if ((pCall =
+	   (SM_CALL_T *) constraint_route_resolution_sm_invoke (pSm,
+								pCrArgs)) ==
+	  NULL)
+	{
+	  zlog_err ("\ncannot invoke constraint route resolution sm");
+	  XFREE (MTYPE_TE, pCrArgs);
+	  TransitReqSmDestroy (pSm);
+	}
+      pSm->state = TRANSIT_REQ_SM_CONSTRAINT_ROUTE_RESOLUTION_STATE;
+      break;
+    default:
+      zlog_err ("\nunexpected event %d %s %d",
+		sm_event->event, __FILE__, __LINE__);
+      TransitReqSmDestroy (pSm);
+    }
+  return pCall;
+}
+
+static SM_CALL_T *
+transit_req_sm_constraint_route_resolution (SM_T * pSm, SM_EVENT_T * sm_event)
+{
+  TRANSIT_REQ_SM_DATA *pTransitReqSmData = NULL;
+  CONSTRAINT_ROUTE_RESOLUTION_ARGS *pCrArgs;
+  PATH_NOTIFICATION *pTransitReqParams;
+  PSB_KEY PsbKey;
+  TE_API_MSG dmsg;
+  SM_CALL_T *pCall = NULL;
+  int i;
+  unsigned int label = 0;
+
+
+  pCrArgs = sm_event->data;
+
+  switch (sm_event->event)
+    {
+    case CONSTRAINT_ROUTE_RESOLVED_EVENT:
+      sm_gen_event_trace (sm_event->event);
+      pTransitReqSmData = pSm->data;
+      pTransitReqParams = pTransitReqSmData->pTransitReqParams;
+      pTransitReqParams->OutIfIndex = pCrArgs->OutIf;
+      pTransitReqParams->NextHop = ntohl (pCrArgs->OutNHop);
+
+
+      if (pCrArgs->rc == OUTPUT_CAC_FAILED)
+	{
+	  pTransitReqParams->rc = BW_UNAVAIL;
+	}
+      else if (pCrArgs->rc == OUTPUT_UNREACHABLE)
+	{
+	  pTransitReqParams->rc = NO_ROUTE;
+	}
+      else if (pCrArgs->rc == OUTPUT_NEXT_HOP)
+	{
+	  pTransitReqParams->rc = PATH_PROC_OK;
+	}
+      else if (pCrArgs->rc == OUTPUT_PATH)
+	{
+	  /* copy path here */
+	  pTransitReqParams->ErHopNumber = pCrArgs->data.path.ErHopNumber;
+	  for (i = 0; i < pTransitReqParams->ErHopNumber; i++)
+	    {
+	      pTransitReqParams->ErHops[i] = pCrArgs->data.path.pErHop[i];
+	    }
+	  pTransitReqParams->rc = PATH_PROC_OK;
+	}
+      else if (pCrArgs->rc == OUTPUT_LSP)
+	{
+	  zlog_info ("\nTunneled %x", pTransitReqParams->ErHopNumber);
+	  pTransitReqParams->ErHopNumber = 0;
+	  zlog_info ("\nLSP HIERARCHY is not supported currently");
+	  XFREE (MTYPE_TE, pCrArgs);
+	  TransitReqSmDestroy (pSm);
+	  return NULL;
+	}
+      else
+	{
+	  zlog_err ("\nunknown RC");
+	  XFREE (MTYPE_TE, pCrArgs);
+	  TransitReqSmDestroy (pSm);
+	  return NULL;
+	}
+
+      memset (&PsbKey, 0, sizeof (PSB_KEY));
+
+      PsbKey.Session = pTransitReqParams->PsbKey.Session;
+
+      if (LabelAllocate
+	  (&label, ALL_LABELS, &PsbKey,
+	   pTransitReqParams->OutIfIndex) != E_OK)
+	{
+	  zlog_err ("\ncannot allocate label %s %d", __FILE__, __LINE__);
+	  pTransitReqParams->Label = 0;
+	}
+      else
+	pTransitReqParams->Label = label;
+
+      dmsg.NotificationType = PATH_MSG_NOTIFICATION;
+      memcpy (&dmsg.u.PathNotification,
+	      pTransitReqParams, sizeof (PATH_NOTIFICATION));
+
+      te_send_msg (&dmsg, sizeof (TE_API_MSG));
+#ifdef FRR_SM_DEFINED
+      if (pTransitReqParams)
+	{
+	  if ((pCrArgs->rc == OUTPUT_PATH) &&
+	      (pTransitReqParams->ErHopNumber > 1))
+	    {
+	      FRR_SM_CALL frr_sm_call;
+	      int k;
+	      IPV4_ADDR protected_node_router_id = 0, merge_node_router_id =
+		0, after_merge_node_router_id = 0;
+
+	      memset (&frr_sm_call, 0, sizeof (FRR_SM_CALL));
+
+	      frr_sm_call.frr_key.OutIfIndex = pTransitReqParams->OutIfIndex;
+
+	      if (rdb_remote_link_router_id_get (pTransitReqParams->NextHop,
+						 &protected_node_router_id) !=
+		  E_OK)
+		{
+		  protected_node_router_id = pTransitReqParams->NextHop;
+		}
+	      frr_sm_call.frr_key.protected_node = protected_node_router_id;
+	      for (k = 1; k < pTransitReqParams->ErHopNumber; k++)
+		{
+		  rdb_remote_link_router_id_get (pTransitReqParams->ErHops[k],
+						 &merge_node_router_id);
+		  if ((merge_node_router_id != 0) &&
+		      (merge_node_router_id != protected_node_router_id))
+		    {
+		      frr_sm_call.frr_key.merge_node = merge_node_router_id;
+		      frr_sm_call.MergeNode = pTransitReqParams->ErHops[k];
+		      break;
+		    }
+		}
+	      if (frr_sm_call.frr_key.merge_node == 0)
+		{
+		  merge_node_router_id =
+		    frr_sm_call.frr_key.merge_node =
+		    pTransitReqParams->ErHops[1];
+		  frr_sm_call.MergeNode = pTransitReqParams->ErHops[1];
+		}
+	      for (; k < pTransitReqParams->ErHopNumber; k++)
+		{
+		  rdb_remote_link_router_id_get (pTransitReqParams->ErHops[k],
+						 &after_merge_node_router_id);
+		  if ((after_merge_node_router_id != 0) &&
+		      (after_merge_node_router_id != merge_node_router_id))
+		    {
+		      frr_sm_call.frr_key.prohibited_penultimate_node =
+			after_merge_node_router_id;
+		      break;
+		    }
+		}
+	      frr_sm_call.Label = label;
+
+	      PsbKey.SenderTemplate =
+		pTransitReqParams->PsbKey.SenderTemplate;
+	      frr_sm_call.PsbKey = PsbKey;
+
+	      if ((pCall =
+		   fast_reroute_sm_sync_invoke (&frr_sm_call,
+						BYPASS_SETUP_REQ_EVENT)) ==
+		  NULL)
+		{
+		  zlog_err ("\ncannot invoke FRR SM %s %d", __FILE__,
+			    __LINE__);
+		}
+	    }
+	  else if ((pCrArgs->rc == OUTPUT_NEXT_HOP) &&
+		   (pTransitReqParams->ErHopNumber > 1))
+	    {
+	      FRR_SM_CALL frr_sm_call;
+	      int k;
+	      IPV4_ADDR protected_node_router_id = 0, merge_node_router_id =
+		0, after_merge_node_router_id = 0;
+
+	      memset (&frr_sm_call, 0, sizeof (FRR_SM_CALL));
+
+	      frr_sm_call.frr_key.OutIfIndex = pTransitReqParams->OutIfIndex;
+
+	      if (rdb_remote_link_router_id_get (pTransitReqParams->NextHop,
+						 &protected_node_router_id) !=
+		  E_OK)
+		{
+		  protected_node_router_id = pTransitReqParams->NextHop;
+		}
+	      frr_sm_call.frr_key.protected_node = protected_node_router_id;
+	      for (k = 1; k < pTransitReqParams->ErHopNumber; k++)
+		{
+		  rdb_remote_link_router_id_get (pTransitReqParams->ErHops[k],
+						 &merge_node_router_id);
+		  if ((merge_node_router_id != 0) &&
+		      (merge_node_router_id != protected_node_router_id))
+		    {
+		      frr_sm_call.frr_key.merge_node = merge_node_router_id;
+		      frr_sm_call.MergeNode = pTransitReqParams->ErHops[k];
+		      break;
+		    }
+		}
+	      if (frr_sm_call.frr_key.merge_node == 0)
+		{
+		  merge_node_router_id =
+		    frr_sm_call.frr_key.merge_node =
+		    pTransitReqParams->ErHops[1];
+		  frr_sm_call.MergeNode = pTransitReqParams->ErHops[1];
+		}
+	      for (; k < pTransitReqParams->ErHopNumber; k++)
+		{
+		  rdb_remote_link_router_id_get (pTransitReqParams->ErHops[k],
+						 &after_merge_node_router_id);
+		  if ((after_merge_node_router_id != 0) &&
+		      (after_merge_node_router_id != merge_node_router_id))
+		    {
+		      frr_sm_call.frr_key.prohibited_penultimate_node =
+			after_merge_node_router_id;
+		      break;
+		    }
+		}
+	      frr_sm_call.Label = label;
+
+	      PsbKey.SenderTemplate =
+		pTransitReqParams->PsbKey.SenderTemplate;
+	      frr_sm_call.PsbKey = PsbKey;
+
+	      if ((pCall =
+		   fast_reroute_sm_sync_invoke (&frr_sm_call,
+						BYPASS_SETUP_REQ_EVENT)) ==
+		  NULL)
+		{
+		  zlog_err ("\ncannot invoke FRR SM %s %d", __FILE__,
+			    __LINE__);
+		}
+	    }
+	}
+#endif
+      break;
+    case CONSTRAINT_ROUTE_RESOLVE_FAILED_EVENT:
+      sm_gen_event_trace (sm_event->event);
+      pTransitReqSmData = pSm->data;
+      pTransitReqParams = pTransitReqSmData->pTransitReqParams;
+      pTransitReqParams->ErHopNumber = 0;
+      pTransitReqParams->OutIfIndex = 0;
+      pTransitReqParams->NextHop = 0;
+
+
+      pTransitReqParams->rc = NO_ROUTE;
+
+      memset (&PsbKey, 0, sizeof (PSB_KEY));
+
+      PsbKey.Session = pTransitReqParams->PsbKey.Session;
+
+      pTransitReqParams->Label = 0;
+
+      dmsg.NotificationType = PATH_MSG_NOTIFICATION;
+      memcpy (&dmsg.u.PathNotification,
+	      pTransitReqParams, sizeof (PATH_NOTIFICATION));
+
+      te_send_msg (&dmsg, sizeof (TE_API_MSG));
+      break;
+    default:
+      zlog_err ("\nunexpected event %d %s %d",
+		sm_event->event, __FILE__, __LINE__);
+    }
+  XFREE (MTYPE_TE, pCrArgs);
+  TransitReqSmDestroy (pSm);
+  zlog_info ("\nExiting SM %x...", pCall);
+  return pCall;
+}
+
+static SM_CALL_T
+  *(*transit_req_sm_event_handler[TRANSIT_REQ_SM_MAX_STATE]) (SM_T * pSm,
+							      SM_EVENT_T *
+							      sm_data) =
+{
+transit_req_sm_empty_handler,
+    transit_req_sm_init, transit_req_sm_constraint_route_resolution};
+
+SM_CALL_T *
+transit_req_sm_handler (SM_T * pSm, SM_EVENT_T * sm_data)
+{
+  if (sm_data == NULL)
+    {
+      zlog_err ("\nfatal: sm_data is NULL %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  zlog_info ("\ntransit_req_sm_event_handler. state %d\n", pSm->state);
+  if ((pSm->state < INIT_STATE) || (pSm->state >= TRANSIT_REQ_SM_MAX_STATE))
+    {
+      zlog_err ("\nstate is invalid");
+      TransitReqSmDestroy (pSm);
+      return NULL;
+    }
+  return transit_req_sm_event_handler[pSm->state] (pSm, sm_data);
+}
+
+SM_CALL_T *
+transit_req_sm_invoke (HANDLE caller, void *data)
+{
+  SM_T *pNewSm;
+  SM_CALL_T *pEvent;
+
+  pNewSm = sm_gen_alloc ((SM_T *) caller, TRANSIT_LSP_SM);
+  if (pNewSm == NULL)
+    {
+      zlog_err ("\nmalloc failed %s %d", __FILE__, __LINE__);
+      return NULL;
+    }
+  if ((pEvent = sm_gen_sync_event_send (pNewSm,
+					TRANSIT_REQ_EVENT, data)) == NULL)
+    {
+      zlog_err ("\ncan not invoke sm %s %d", __FILE__, __LINE__);
+    }
+  return pEvent;
+}
+
+static void
+TransitReqSmDestroy (SM_T * pSm)
+{
+  TRANSIT_REQ_SM_DATA *pTransitReqSmData = pSm->data;
+  PATH_NOTIFICATION *pTransitReqParams = pTransitReqSmData->pTransitReqParams;
+
+  if (pTransitReqParams != NULL)
+    XFREE (MTYPE_TE, pTransitReqParams);
+  if (pTransitReqSmData != NULL)
+    XFREE (MTYPE_TE, pTransitReqSmData);
+  sm_gen_free (pSm);
+}
diff -Naur quagga-0.99.10/rsvpd/te_tr.h quagga-mpls/rsvpd/te_tr.h
--- quagga-0.99.10/rsvpd/te_tr.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/rsvpd/te_tr.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,18 @@
+
+#ifndef __TRANSIT_REQ_SM_H__
+#define __TRANSIT_REQ_SM_H__
+
+typedef enum
+{
+  TRANSIT_REQ_SM_CONSTRAINT_ROUTE_RESOLUTION_STATE = INIT_STATE + 1,
+  TRANSIT_REQ_SM_MAX_STATE
+} TRANSIT_REQ_SM_STATE_E;
+
+typedef struct
+{
+  PATH_NOTIFICATION *pTransitReqParams;
+} TRANSIT_REQ_SM_DATA;
+
+SM_CALL_T *transit_req_sm_handler (SM_T * pSm, SM_EVENT_T * sm_data);
+
+#endif
diff -Naur quagga-0.99.10/vtysh/extract.pl.in quagga-mpls/vtysh/extract.pl.in
--- quagga-0.99.10/vtysh/extract.pl.in	2007-10-15 00:32:22.000000000 +0200
+++ quagga-mpls/vtysh/extract.pl.in	2008-11-25 12:30:18.000000000 +0100
@@ -31,6 +31,8 @@
 EOF
 
 $ignore{'"interface IFNAME"'} = "ignore";
+$ignore{'"create tunnel IFNAME"'} = "ignore";
+$ignore{'"tunnel mode mpls"'} = "ignore";
 $ignore{'"ip vrf NAME"'} = "ignore";
 $ignore{'"router rip"'} = "ignore";
 $ignore{'"router ripng"'} = "ignore";
@@ -41,6 +43,9 @@
 $ignore{'"router bgp CMD_AS_RANGE view WORD"'} = "ignore";
 $ignore{'"router isis WORD"'} = "ignore";
 $ignore{'"router zebra"'} = "ignore";
+$ignore{'"mpls ldp"'} = "ignore";
+$ignore{'"mpls ip"'} = "ignore";
+$ignore{'"mpls static <0-255>"'} = "ignore";
 $ignore{'"address-family ipv4"'} = "ignore";
 $ignore{'"address-family ipv4 (unicast|multicast)"'} = "ignore";
 $ignore{'"address-family ipv6"'} = "ignore";
diff -Naur quagga-0.99.10/vtysh/Makefile.am quagga-mpls/vtysh/Makefile.am
--- quagga-0.99.10/vtysh/Makefile.am	2005-08-25 14:00:58.000000000 +0200
+++ quagga-mpls/vtysh/Makefile.am	2008-11-25 12:30:18.000000000 +0100
@@ -21,14 +21,18 @@
 vtysh_cmd_FILES = $(top_srcdir)/bgpd/*.c $(top_srcdir)/isisd/*.c \
 		  $(top_srcdir)/ospfd/*.c $(top_srcdir)/ospf6d/*.c \
 		  $(top_srcdir)/ripd/*.c $(top_srcdir)/ripngd/*.c \
+		  $(top_srcdir)/ldpd/*.c \
 		  $(top_srcdir)/lib/keychain.c $(top_srcdir)/lib/routemap.c \
 		  $(top_srcdir)/lib/filter.c $(top_srcdir)/lib/plist.c \
 		  $(top_srcdir)/lib/distribute.c $(top_srcdir)/lib/if_rmap.c \
 		  $(top_srcdir)/lib/vty.c $(top_srcdir)/zebra/debug.c \
 		  $(top_srcdir)/zebra/interface.c \
+		  $(top_srcdir)/zebra/if_tunnel.c \
+		  $(top_srcdir)/zebra/if_vlan.c \
 		  $(top_srcdir)/zebra/irdp_interface.c \
 		  $(top_srcdir)/zebra/rtadv.c $(top_srcdir)/zebra/zebra_vty.c \
-		  $(top_srcdir)/zebra/zserv.c $(top_srcdir)/zebra/router-id.c
+		  $(top_srcdir)/zebra/zserv.c $(top_srcdir)/zebra/router-id.c \
+		  $(top_srcdir)/zebra/mpls_vty.c
 
 vtysh_cmd.c: $(vtysh_cmd_FILES)
 	./$(EXTRA_DIST) $(vtysh_cmd_FILES) > vtysh_cmd.c
diff -Naur quagga-0.99.10/vtysh/vtysh.c quagga-mpls/vtysh/vtysh.c
--- quagga-0.99.10/vtysh/vtysh.c	2007-10-15 00:32:22.000000000 +0200
+++ quagga-mpls/vtysh/vtysh.c	2008-11-25 12:30:18.000000000 +0100
@@ -57,6 +57,7 @@
   { .fd = -1, .name = "ospf6d", .flag = VTYSH_OSPF6D, .path = OSPF6_VTYSH_PATH},
   { .fd = -1, .name = "bgpd", .flag = VTYSH_BGPD, .path = BGP_VTYSH_PATH},
   { .fd = -1, .name = "isisd", .flag = VTYSH_ISISD, .path = ISIS_VTYSH_PATH},
+  { .fd = -1, .name = "ldpd", .flag = VTYSH_LDPD, .path = LDP_VTYSH_PATH},
 };
 
 #define VTYSH_INDEX_MAX (sizeof(vtysh_client)/sizeof(vtysh_client[0]))
@@ -728,12 +729,44 @@
   "%s(config-router)# ",
 };
 
+/* LDP node structure. */
+struct cmd_node mpls_ldp_node =
+{
+  LDP_NODE,
+  "%s(config-ldp)# ",
+};
+
+/* MPLS labelspace node structure. */
+struct cmd_node mpls_static_node =
+{
+  MPLS_LABELSPACE_NODE,
+  "%s(config-ls)# ",
+};
+
+struct cmd_node tunnel_node =
+{
+  TUNNEL_NODE,
+  "%s(config-tun)# ",
+};
+
+struct cmd_node mpls_tunnel_node =
+{
+  MPLS_TUNNEL_NODE,
+  "%s(config-tun)# ",
+};
+
 struct cmd_node interface_node =
 {
   INTERFACE_NODE,
   "%s(config-if)# ",
 };
 
+struct cmd_node ldp_if_node =
+{
+  LDP_IF_NODE,
+  "%s(config-if-ldp)# ",
+};
+
 struct cmd_node rmap_node =
 {
   RMAP_NODE,
@@ -952,6 +985,18 @@
   return CMD_SUCCESS;
 }
 
+DEFUNSH (VTYSH_ZEBRA,
+	 mpls_static,
+	 mpls_static_cmd,
+	 "mpls static <0-255>",
+	 "Multi-Protocol Label Switching configuration\n"
+	 "Static label information"
+	 "Labelspace number (0 = global)")
+{
+  vty->node = MPLS_LABELSPACE_NODE;
+  return CMD_SUCCESS;
+}
+
 DEFUNSH (VTYSH_RIPD,
 	 router_rip,
 	 router_rip_cmd,
@@ -1008,6 +1053,28 @@
   return CMD_SUCCESS;
 }
 
+DEFUNSH (VTYSH_LDPD,
+	 vtysh_mpls_ldp,
+	 vtysh_mpls_ldp_cmd,
+	 "mpls ldp",
+	 "Multi-Protocol Label Switching configuration\n"
+	 "Dynamic label distribution configuration")
+{
+  vty->node = LDP_NODE;
+  return CMD_SUCCESS;
+}
+
+DEFUNSH (VTYSH_LDPD,
+	 vtysh_mpls_ip,
+	 vtysh_mpls_ip_cmd,
+	 "mpls ip",
+	 "MPLS interface configuration\n"
+	 "Dynamic label distribution via LDP\n")
+{
+  vty->node = LDP_IF_NODE;
+  return CMD_SUCCESS;
+}
+
 DEFUNSH (VTYSH_RMAP,
 	 route_map,
 	 route_map_cmd,
@@ -1078,9 +1145,13 @@
       vty->node = ENABLE_NODE;
       break;
     case INTERFACE_NODE:
+    case TUNNEL_NODE:
+    case MPLS_TUNNEL_NODE:
     case ZEBRA_NODE:
     case BGP_NODE:
     case RIP_NODE:
+    case LDP_NODE:
+    case MPLS_LABELSPACE_NODE:
     case RIPNG_NODE:
     case OSPF_NODE:
     case OSPF6_NODE:
@@ -1103,6 +1174,9 @@
     case KEYCHAIN_KEY_NODE:
       vty->node = KEYCHAIN_NODE;
       break;
+    case LDP_IF_NODE:
+      vty->node = INTERFACE_NODE;
+      break;
     default:
       break;
     }
@@ -1152,6 +1226,21 @@
        "quit",
        "Exit current mode and down to previous mode\n")
 
+DEFUNSH (VTYSH_ZEBRA,
+	 vtysh_exit_mpls_ls,
+	 vtysh_exit_mpls_ls_cmd,
+	 "exit",
+	 "Exit current mode and down to previous mode\n")
+{
+  return vtysh_exit (vty);
+}
+
+ALIAS (vtysh_exit_mpls_ls,
+       vtysh_quit_mpls_ls_cmd,
+       "quit",
+       "Exit current mode and down to previous mode\n")
+
+
 DEFUNSH (VTYSH_RIPD,
 	 vtysh_exit_ripd,
 	 vtysh_exit_ripd_cmd,
@@ -1250,6 +1339,34 @@
        "quit",
        "Exit current mode and down to previous mode\n")
 
+DEFUNSH (VTYSH_LDPD,
+	 vtysh_exit_ldpd,
+	 vtysh_exit_ldpd_cmd,
+	 "exit",
+	 "Exit current mode and down to previous mode\n")
+{
+  return vtysh_exit (vty);
+}
+
+ALIAS (vtysh_exit_ldpd,
+       vtysh_quit_ldpd_cmd,
+       "quit",
+       "Exit current mode and down to previous mode\n")
+
+DEFUNSH (VTYSH_LDPD,
+	 vtysh_exit_ldp_if,
+	 vtysh_exit_ldp_if_cmd,
+	 "exit",
+	 "Exit current mode and down to previous mode\n")
+{
+  return vtysh_exit (vty);
+}
+
+ALIAS (vtysh_exit_ldp_if,
+       vtysh_quit_ldp_if_cmd,
+       "quit",
+       "Exit current mode and down to previous mode\n")
+
 DEFUNSH (VTYSH_ALL,
          vtysh_exit_line_vty,
          vtysh_exit_line_vty_cmd,
@@ -1264,6 +1381,52 @@
        "quit",
        "Exit current mode and down to previous mode\n")
 
+DEFUNSH (VTYSH_ZEBRA,
+	 vtysh_exit_tunnel,
+	 vtysh_exit_tunnel_cmd,
+	 "exit",
+	 "Exit current mode and down to previous mode\n")
+{
+  return vtysh_exit (vty);
+}
+
+ALIAS (vtysh_exit_tunnel,
+       vtysh_quit_tunnel_cmd,
+       "quit",
+       "Exit current mode and down to previous mode\n")
+
+DEFUNSH (VTYSH_ZEBRA,
+	 vtysh_tunnel,
+	 vtysh_tunnel_cmd,
+	 "create tunnel IFNAME",
+	 "Create virtual interfaces\n"
+	 "Create a tunnel interface\n"
+	 "Interface's name\n")
+{
+  vty->node = TUNNEL_NODE;
+  return CMD_SUCCESS;
+}
+
+DEFUNSH (VTYSH_ZEBRA,
+	 vtysh_tunnel_mode_mpls,
+	 vtysh_tunnel_mode_mpls_cmd,
+         "tunnel mode mpls",
+         "Tunnel configuration\n"
+         "Tunnel mode configuration\n"
+         "MPLS\n")
+{
+  vty->node = MPLS_TUNNEL_NODE;
+  return CMD_SUCCESS;
+}
+
+DEFSH (VTYSH_ZEBRA,
+       vtysh_no_tunnel_cmd,
+       "no create tunnel IFNAME",
+       NO_STR
+       "Delete a virtual interface\n"
+       "Delete a tunnel interface\n"
+       "Interface's name\n")
+
 DEFUNSH (VTYSH_INTERFACE,
 	 vtysh_interface,
 	 vtysh_interface_cmd,
@@ -2224,7 +2387,12 @@
   /* Install nodes. */
   install_node (&bgp_node, NULL);
   install_node (&rip_node, NULL);
+  install_node (&mpls_ldp_node, NULL);
+  install_node (&mpls_static_node, NULL);
+  install_node (&tunnel_node, NULL);
+  install_node (&mpls_tunnel_node, NULL);
   install_node (&interface_node, NULL);
+  install_node (&ldp_if_node, NULL);
   install_node (&rmap_node, NULL);
   install_node (&zebra_node, NULL);
   install_node (&bgp_vpnv4_node, NULL);
@@ -2249,6 +2417,11 @@
   vtysh_install_default (CONFIG_NODE);
   vtysh_install_default (BGP_NODE);
   vtysh_install_default (RIP_NODE);
+  vtysh_install_default (LDP_NODE);
+  vtysh_install_default (LDP_IF_NODE);
+  vtysh_install_default (MPLS_LABELSPACE_NODE);
+  vtysh_install_default (TUNNEL_NODE);
+  vtysh_install_default (MPLS_TUNNEL_NODE);
   vtysh_install_default (INTERFACE_NODE);
   vtysh_install_default (RMAP_NODE);
   vtysh_install_default (ZEBRA_NODE);
@@ -2276,6 +2449,16 @@
   /* install_element (CONFIG_NODE, &vtysh_quit_all_cmd); */
   install_element (ENABLE_NODE, &vtysh_exit_all_cmd);
   install_element (ENABLE_NODE, &vtysh_quit_all_cmd);
+  install_element (TUNNEL_NODE, &vtysh_exit_tunnel_cmd);
+  install_element (TUNNEL_NODE, &vtysh_quit_tunnel_cmd);
+  install_element (MPLS_TUNNEL_NODE, &vtysh_exit_tunnel_cmd);
+  install_element (MPLS_TUNNEL_NODE, &vtysh_quit_tunnel_cmd);
+  install_element (MPLS_LABELSPACE_NODE, &vtysh_exit_mpls_ls_cmd);
+  install_element (MPLS_LABELSPACE_NODE, &vtysh_quit_mpls_ls_cmd);
+  install_element (LDP_NODE, &vtysh_exit_ldpd_cmd);
+  install_element (LDP_NODE, &vtysh_quit_ldpd_cmd);
+  install_element (LDP_IF_NODE, &vtysh_exit_ldpd_cmd);
+  install_element (LDP_IF_NODE, &vtysh_quit_ldpd_cmd);
   install_element (RIP_NODE, &vtysh_exit_ripd_cmd);
   install_element (RIP_NODE, &vtysh_quit_ripd_cmd);
   install_element (RIPNG_NODE, &vtysh_exit_ripngd_cmd);
@@ -2310,6 +2493,9 @@
   /* "end" command. */
   install_element (CONFIG_NODE, &vtysh_end_all_cmd);
   install_element (ENABLE_NODE, &vtysh_end_all_cmd);
+  install_element (MPLS_LABELSPACE_NODE, &vtysh_end_all_cmd);
+  install_element (LDP_NODE, &vtysh_end_all_cmd);
+  install_element (LDP_IF_NODE, &vtysh_end_all_cmd);
   install_element (RIP_NODE, &vtysh_end_all_cmd);
   install_element (RIPNG_NODE, &vtysh_end_all_cmd);
   install_element (OSPF_NODE, &vtysh_end_all_cmd);
@@ -2325,12 +2511,17 @@
   install_element (KEYCHAIN_KEY_NODE, &vtysh_end_all_cmd);
   install_element (RMAP_NODE, &vtysh_end_all_cmd);
   install_element (VTY_NODE, &vtysh_end_all_cmd);
+  install_element (TUNNEL_NODE, &vtysh_end_all_cmd);
+  install_element (MPLS_TUNNEL_NODE, &vtysh_end_all_cmd);
 
   install_element (INTERFACE_NODE, &interface_desc_cmd);
   install_element (INTERFACE_NODE, &no_interface_desc_cmd);
   install_element (INTERFACE_NODE, &vtysh_end_all_cmd);
   install_element (INTERFACE_NODE, &vtysh_exit_interface_cmd);
   install_element (INTERFACE_NODE, &vtysh_quit_interface_cmd);
+  install_element (INTERFACE_NODE, &vtysh_mpls_ip_cmd);
+  install_element (CONFIG_NODE, &mpls_static_cmd);
+  install_element (CONFIG_NODE, &vtysh_mpls_ldp_cmd);
   install_element (CONFIG_NODE, &router_rip_cmd);
 #ifdef HAVE_IPV6
   install_element (CONFIG_NODE, &router_ripng_cmd);
@@ -2360,6 +2551,10 @@
   install_element (KEYCHAIN_NODE, &key_cmd);
   install_element (KEYCHAIN_NODE, &key_chain_cmd);
   install_element (KEYCHAIN_KEY_NODE, &key_chain_cmd);
+  install_element (CONFIG_NODE, &vtysh_tunnel_cmd);
+  install_element (TUNNEL_NODE, &vtysh_tunnel_mode_mpls_cmd);
+  install_element (MPLS_TUNNEL_NODE, &vtysh_tunnel_mode_mpls_cmd);
+  install_element (CONFIG_NODE, &vtysh_no_tunnel_cmd);
   install_element (CONFIG_NODE, &vtysh_interface_cmd);
   install_element (CONFIG_NODE, &vtysh_no_interface_cmd);
   install_element (ENABLE_NODE, &vtysh_show_running_config_cmd);
diff -Naur quagga-0.99.10/vtysh/vtysh_config.c quagga-mpls/vtysh/vtysh_config.c
--- quagga-0.99.10/vtysh/vtysh_config.c	2005-04-07 09:30:25.000000000 +0200
+++ quagga-mpls/vtysh/vtysh_config.c	2008-11-25 12:30:18.000000000 +0100
@@ -190,6 +190,8 @@
 	config = config_get (INTERFACE_NODE, line);
       else if (strncmp (line, "router-id", strlen ("router-id")) == 0)
 	config = config_get (ZEBRA_NODE, line);
+      else if (strncmp(line, "mpls static", strlen("mpls static")) == 0)
+	config = config_get (MPLS_LABELSPACE_NODE, line);
       else if (strncmp (line, "router rip", strlen ("router rip")) == 0)
 	config = config_get (RIP_NODE, line);
       else if (strncmp (line, "router ripng", strlen ("router ripng")) == 0)
@@ -204,6 +206,8 @@
   	config = config_get (ISIS_NODE, line);
       else if (strncmp (line, "router bgp", strlen ("router bgp")) == 0)
 	config = config_get (BGP_NODE, line);
+      else if (strncmp (line, "mpls ldp", strlen ("mpls ldp")) == 0)
+	config = config_get (LDP_NODE, line);
       else if (strncmp (line, "route-map", strlen ("route-map")) == 0)
 	config = config_get (RMAP_NODE, line);
       else if (strncmp (line, "access-list", strlen ("access-list")) == 0)
diff -Naur quagga-0.99.10/vtysh/vtysh.h quagga-mpls/vtysh/vtysh.h
--- quagga-0.99.10/vtysh/vtysh.h	2007-05-02 18:05:35.000000000 +0200
+++ quagga-mpls/vtysh/vtysh.h	2008-11-25 12:30:18.000000000 +0100
@@ -29,9 +29,10 @@
 #define VTYSH_OSPF6D 0x10
 #define VTYSH_BGPD   0x20
 #define VTYSH_ISISD  0x40
-#define VTYSH_ALL	  VTYSH_ZEBRA|VTYSH_RIPD|VTYSH_RIPNGD|VTYSH_OSPFD|VTYSH_OSPF6D|VTYSH_BGPD|VTYSH_ISISD
+#define VTYSH_LDPD   0x80
+#define VTYSH_ALL	  VTYSH_ZEBRA|VTYSH_RIPD|VTYSH_RIPNGD|VTYSH_OSPFD|VTYSH_OSPF6D|VTYSH_BGPD|VTYSH_ISISD|VTYSH_LDPD
 #define VTYSH_RMAP	  VTYSH_ZEBRA|VTYSH_RIPD|VTYSH_RIPNGD|VTYSH_OSPFD|VTYSH_OSPF6D|VTYSH_BGPD
-#define VTYSH_INTERFACE	  VTYSH_ZEBRA|VTYSH_RIPD|VTYSH_RIPNGD|VTYSH_OSPFD|VTYSH_OSPF6D|VTYSH_ISISD
+#define VTYSH_INTERFACE	  VTYSH_ZEBRA|VTYSH_RIPD|VTYSH_RIPNGD|VTYSH_OSPFD|VTYSH_OSPF6D|VTYSH_ISISD|VTYSH_LDPD
 
 /* vtysh local configuration file. */
 #define VTYSH_DEFAULT_CONFIG "vtysh.conf"
diff -Naur quagga-0.99.10/zebra/connected.c quagga-mpls/zebra/connected.c
--- quagga-0.99.10/zebra/connected.c	2008-06-07 22:25:16.000000000 +0200
+++ quagga-mpls/zebra/connected.c	2008-11-25 12:30:18.000000000 +0100
@@ -174,6 +174,7 @@
 connected_up_ipv4 (struct interface *ifp, struct connected *ifc)
 {
   struct prefix_ipv4 p;
+  struct zapi_nexthop nh;
 
   if (! CHECK_FLAG (ifc->conf, ZEBRA_IFC_REAL))
     return;
@@ -188,8 +189,12 @@
   if (prefix_ipv4_any (&p))
     return;
 
-  rib_add_ipv4 (ZEBRA_ROUTE_CONNECT, 0, &p, NULL, NULL, ifp->ifindex,
-	RT_TABLE_MAIN, ifp->metric, 0);
+  memset (&nh, 0, sizeof (struct zapi_nexthop));
+  SET_FLAG(nh.type, ZEBRA_NEXTHOP_IFINDEX);
+  nh.intf.index = ifp->ifindex;
+
+  rib_add_route (ZEBRA_ROUTE_CONNECT, 0, (struct prefix*)&p,
+                 &nh, RT_TABLE_MAIN, ifp->metric, 0);
 
   rib_update ();
 }
@@ -280,6 +285,7 @@
 connected_down_ipv4 (struct interface *ifp, struct connected *ifc)
 {
   struct prefix_ipv4 p;
+  struct zapi_nexthop nh;
 
   if (! CHECK_FLAG (ifc->conf, ZEBRA_IFC_REAL))
     return;
@@ -294,8 +300,11 @@
   if (prefix_ipv4_any (&p))
     return;
 
-  /* Same logic as for connected_up_ipv4(): push the changes into the head. */
-  rib_delete_ipv4 (ZEBRA_ROUTE_CONNECT, 0, &p, NULL, ifp->ifindex, 0);
+  memset (&nh, 0, sizeof (struct zapi_nexthop));
+  SET_FLAG (nh.type, ZEBRA_NEXTHOP_IFINDEX);
+  nh.intf.index = ifp->ifindex;
+
+  rib_delete_route (ZEBRA_ROUTE_CONNECT, 0, (struct prefix*)&p, &nh, 0);
 
   rib_update ();
 }
@@ -325,6 +334,7 @@
 connected_up_ipv6 (struct interface *ifp, struct connected *ifc)
 {
   struct prefix_ipv6 p;
+  struct zapi_nexthop nh;
 
   if (! CHECK_FLAG (ifc->conf, ZEBRA_IFC_REAL))
     return;
@@ -335,13 +345,17 @@
   apply_mask_ipv6 (&p);
 
 #if ! defined (MUSICA) && ! defined (LINUX)
-  /* XXX: It is already done by rib_bogus_ipv6 within rib_add_ipv6 */
+  /* XXX: It is already done by rib_bogus_ipv6 within rib_add_route */
   if (IN6_IS_ADDR_UNSPECIFIED (&p.prefix))
     return;
 #endif
 
-  rib_add_ipv6 (ZEBRA_ROUTE_CONNECT, 0, &p, NULL, ifp->ifindex, 0,
-                ifp->metric, 0);
+  memset (&nh, 0, sizeof (struct zapi_nexthop));
+  SET_FLAG (nh.type, ZEBRA_NEXTHOP_IFINDEX);
+  nh.intf.index = ifp->ifindex;
+
+  rib_add_route (ZEBRA_ROUTE_CONNECT, 0, (struct prefix*)&p,
+                 &nh, 0, ifp->metric, 0);
 
   rib_update ();
 }
@@ -404,6 +418,7 @@
 connected_down_ipv6 (struct interface *ifp, struct connected *ifc)
 {
   struct prefix_ipv6 p;
+  struct zapi_nexthop nh;
 
   if (! CHECK_FLAG (ifc->conf, ZEBRA_IFC_REAL))
     return;
@@ -415,7 +430,11 @@
   if (IN6_IS_ADDR_UNSPECIFIED (&p.prefix))
     return;
 
-  rib_delete_ipv6 (ZEBRA_ROUTE_CONNECT, 0, &p, NULL, ifp->ifindex, 0);
+  memset (&nh, 0, sizeof (struct zapi_nexthop));
+  SET_FLAG (nh.type, ZEBRA_NEXTHOP_IFINDEX);
+  nh.intf.index = ifp->ifindex;
+
+  rib_delete_route (ZEBRA_ROUTE_CONNECT, 0, (struct prefix*)&p, &nh, 0);
 
   rib_update ();
 }
diff -Naur quagga-0.99.10/zebra/if_netlink.c quagga-mpls/zebra/if_netlink.c
--- quagga-0.99.10/zebra/if_netlink.c	2002-12-13 21:15:30.000000000 +0100
+++ quagga-mpls/zebra/if_netlink.c	2008-11-25 12:30:18.000000000 +0100
@@ -22,8 +22,7 @@
 
 #include <zebra.h>
 
-/* Extern from rt_netlink.c */  
-void interface_lookup_netlink ();  
+#include "zebra/rt_netlink.h"
 
 /* Interface information read by netlink. */
 void
diff -Naur quagga-0.99.10/zebra/if_tunnel.c quagga-mpls/zebra/if_tunnel.c
--- quagga-0.99.10/zebra/if_tunnel.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/if_tunnel.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,862 @@
+/* Zebra Tunnel VTY functions
+ * Copyright (C) 2005 James R. Leu
+ *
+ * This file is part of GNU Zebra.
+ *
+ * GNU Zebra is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2, or (at your option) any
+ * later version.
+ *
+ * GNU Zebra is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU Zebra; see the file COPYING.  If not, write to the 
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330, 
+ * Boston, MA 02111-1307, USA.  
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <unistd.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+#include <sys/ioctl.h>
+#include <net/if.h>
+/* #include <linux/if.h>
+#include <arpa/inet.h>
+#include <linux/if_arp.h> */
+#include <netinet/ip.h>
+#include <linux/if_tunnel.h>
+#include <linux/sockios.h>
+
+#include <zebra.h>
+
+#include "if.h"
+#include "memory.h"
+#include "memory.h"
+#include "command.h"
+#include "vty.h"
+#include "prefix.h"
+#include "table.h"
+#include "interface.h"
+#ifdef HAVE_MPLS
+#include "mpls_vty.h"
+#endif
+#include "ioctl.h"
+
+enum tunnel_type
+{
+  TUNNEL_GRE = 1,
+  TUNNEL_IPIP,
+  TUNNEL_SIT,
+  TUNNEL_MPLS,
+  TUNNEL_MAX,
+};
+
+struct tunnel_info
+{
+  enum tunnel_type type;
+  struct prefix dest;
+  int configured;
+  int (*action)(int, struct interface*);
+  int (*check)(int, struct interface*);
+  void *data;
+};
+
+static const char*
+tunnel_mode_str (int type)
+{
+  const char *mode;
+  switch (type)
+  {
+    case TUNNEL_GRE:
+      mode = "gre";
+      break;
+    case TUNNEL_IPIP:
+      mode = "ipip";
+      break;
+    case TUNNEL_SIT:
+      mode = "sit";
+      break;
+#ifdef HAVE_MPLS
+    case TUNNEL_MPLS:
+      mode = "mpls";
+      break;
+#endif
+    default:
+      assert (0);
+      break;
+  }
+  return mode;
+}
+
+static void
+tunnel_config (struct vty *vty, struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  char buf[BUFSIZ];
+
+  vty_out (vty, "create tunnel %s%s", ifp->name, VTY_NEWLINE);
+  prefix2str (&tun_data->dest, buf, sizeof (buf));
+  vty_out (vty, " tunnel dest %s%s", buf, VTY_NEWLINE);
+  vty_out (vty, " tunnel mode %s%s", tunnel_mode_str (tun_data->type),
+    VTY_NEWLINE);
+}
+
+static void
+tunnel_show (struct vty *vty, struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  char buf[BUFSIZ];
+
+  prefix2str (&tun_data->dest, buf, sizeof (buf));
+
+  vty_out (vty, "  Tunnel mode: %s Destination: %s%s",
+    tunnel_mode_str (tun_data->type), buf, VTY_NEWLINE);
+}
+
+static void
+tunnel_free (struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  XFREE (MTYPE_TMP, if_data->ops);
+  if_data->ops = NULL;
+}
+
+static int
+do_tunnel (int cmd, struct interface *ifp)
+{
+  struct ip_tunnel_parm args;
+  struct ifreq ifr;
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+
+  memset(&args, 0, sizeof(args));
+  strncpy(args.name, ifp->name, IFNAMSIZ);
+  args.iph.version = 4;
+  args.iph.ihl = 5;
+  args.iph.frag_off = htons(IP_DF);
+  args.iph.daddr = tun_data->dest.u.prefix4.s_addr;
+
+  switch (tun_data->type)
+  {
+    case TUNNEL_GRE:
+      args.iph.protocol = IPPROTO_GRE;
+      strcpy(ifr.ifr_name, "gre0");
+      break;
+    case TUNNEL_IPIP:
+      args.iph.protocol = IPPROTO_IPIP;
+      strcpy(ifr.ifr_name, "tunl0");
+      break;
+    case TUNNEL_SIT:
+      args.iph.protocol = IPPROTO_IPV6;
+      strcpy(ifr.ifr_name, "sit0");
+      break;
+    default:
+      assert (0);
+  }
+
+  ifr.ifr_ifru.ifru_data = (void*)&args;
+  return if_ioctl(cmd, (caddr_t)&ifr);
+}
+
+static int
+do_tunnel_check (int cmd, struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+
+  if (cmd == SIOCADDTUNNEL)
+    {
+      if ((!tun_data->configured) && tun_data->type &&
+	tun_data->dest.family && tun_data->data)
+        return 1;
+    }
+  else
+    {
+      if (tun_data->configured)
+        return 1;
+    }
+  return 0;
+}
+
+#ifdef LINUX_MPLS
+static int
+do_mpls_tunnel (int cmd, struct interface *ifp)
+{
+  struct mpls_tunnel_req mtr;
+  struct ifreq ifr;
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  struct zmpls_out_segment *out = tun_data->data;
+
+  memset(&mtr, 0, sizeof(mtr));
+  strncpy(mtr.mt_ifname, ifp->name, IFNAMSIZ);
+  strcpy(ifr.ifr_name, "mpls0");
+  mtr.mt_nhlfe_key = out->out_key;
+
+  ifr.ifr_ifru.ifru_data = (void*)&mtr;
+  return if_ioctl(cmd, (caddr_t)&ifr);
+
+#if 0
+
+  ADD
+
+  struct interface *ifp;
+  struct connected *ifc;
+  struct prefix dest;
+  struct prefix *p;
+  int ret;
+
+  if (listcount (ifp->connected))
+  {
+    vty_out (vty, "%% Tunnel destination already configured %s", VTY_NEWLINE);
+    return CMD_WARNING;
+  }
+
+  ifc = connected_new ();
+  ifc->ifp = ifp;
+
+  /* source */
+  p = prefix_new ();
+  router_id_get (p);
+  ifc->address = (struct prefix *) p;
+
+  /* destination. */
+  p = prefix_new ();
+  *p = dest;
+  p->prefixlen = (p->family == AF_INET)?IPV4_MAX_BITLEN:IPV6_MAX_PREFIXLEN;
+  ifc->destination = (struct prefix *) p;
+
+  /* Add to linked list. */
+  listnode_add (ifp->connected, ifc);
+
+  SET_FLAG (ifc->conf, ZEBRA_IFC_CONFIGURED);
+
+  if_set_flags (ifp, IFF_UP | IFF_RUNNING);
+  if_refresh (ifp);
+
+  ret = if_set_prefix (ifp, ifc);
+  if (ret < 0)
+  {
+    vty_out (vty, "%% Can't set interface IP address: %s.%s",
+             strerror(errno), VTY_NEWLINE);
+    return CMD_WARNING;
+  }
+
+  /* IP address propery set. */
+  SET_FLAG (ifc->conf, ZEBRA_IFC_REAL);
+
+  /* Update interface address information to protocol daemon. */
+  zebra_interface_address_add_update (ifp, ifc);
+
+  /* If interface is up register connected route. */
+  if (if_is_operative(ifp))
+    connected_up_ipv4 (ifp, ifc);
+
+  mpls_ctrl_tunnel_register(ifp, 1);
+
+
+  DEL
+
+  struct interface *ifp;
+  struct connected *ifc;
+  int ret;
+
+  ifp = (struct interface *) vty->index;
+  ifc = listgetdata (listhead (ifp->connected));
+
+  /* This is real route. */
+  ret = if_unset_prefix (ifp, ifc);
+  if (ret < 0)
+  {
+    vty_out (vty, "%% Can't unset interface IP address: %s.%s",
+             strerror(errno), VTY_NEWLINE);
+    return CMD_WARNING;
+  }
+
+  /* Redistribute this information. */
+  zebra_interface_address_delete_update (ifp, ifc);
+
+  /* Remove connected route. */
+  connected_down_ipv4 (ifp, ifc);
+
+  /* Free address information. */
+  listnode_delete (ifp->connected, ifc);
+  connected_free (ifc);
+
+  mpls_ctrl_tunnel_unregister(ifp, 1);
+
+static void
+mpls_interface_config_write (struct vty *vty, struct interface *ifp)
+{
+  struct zebra_if *if_data;
+  if_data = ifp->info;
+
+  vty_out (vty, "create mpls-tunnel %s%s", ifp->name, VTY_NEWLINE);
+
+  if (if_data && if_data->ops && if_data->ops->info)
+  {
+    struct zmpls_out_segment *out;
+
+    out = mpls_out_segment_find_by_out_key((int)if_data->ops->info);
+    if (out)
+    {
+      vty_out (vty, " tunnel mode mpls static ");
+      mpls_out_segment_config_write (vty, out);
+      vty_out (vty, "%s", VTY_NEWLINE);
+    }
+  }
+}
+
+
+#endif
+}
+
+static int
+do_mpls_tunnel_check (int cmd, struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+
+  if (cmd == SIOCADDTUNNEL)
+    {
+      if ((!tun_data->configured) && tun_data->type && tun_data->dest.family)
+        return 1;
+    }
+  else
+    {
+      if (tun_data->configured)
+        return 1;
+    }
+  return 0;
+}
+#endif
+
+static int
+tunnel_create_check (struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  return tun_data->check(SIOCDELTUNNEL, ifp);
+}
+
+static int
+tunnel_delete_check (struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  return tun_data->check(SIOCDELTUNNEL, ifp);
+}
+
+static int
+tunnel_create (struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  int ret = tun_data->action (SIOCADDTUNNEL, ifp);
+  if (!ret)
+    tun_data->configured = 1;
+  return ret;
+}
+
+static int
+tunnel_delete (struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  int ret = tun_data->action (SIOCADDTUNNEL, ifp);
+  tun_data->configured = 0;
+  return ret;
+}
+
+static struct interface_ops*
+tunnel_create_ops ()
+{
+  struct tunnel_info *tun_data;
+  struct interface_ops *ops = XMALLOC (MTYPE_TMP,
+    sizeof(struct interface_ops) + sizeof (struct tunnel_info));
+
+  if (!ops)
+    return NULL;
+
+  memset (ops, 0, sizeof(struct interface_ops));
+  ops->type = INTERFACE_TYPE_TUNNEL;
+  ops->config = &tunnel_config;
+  ops->show = &tunnel_show;
+  ops->create_check = &tunnel_create_check;
+  ops->delete_check = &tunnel_delete_check;
+  ops->create = &tunnel_create;
+  ops->delete = &tunnel_delete;
+  ops->free = &tunnel_free;
+  ops->info = &ops[1];
+
+  tun_data = ops->info;
+  tun_data->action = &do_tunnel;
+  tun_data->check = &do_tunnel_check;
+
+  return ops;
+}
+
+DEFUN (create_tunnel,
+       create_tunnel_cmd,
+       "create tunnel IFNAME",
+       "Create virtual interface\n"
+       "Create tunnel interface\n"
+       "Tunnel interface name\n")
+{
+  struct zebra_if *if_data;
+  struct interface *ifp;
+
+  ifp = if_lookup_by_name(argv[0]);
+  if (!ifp)
+    {
+      ifp = if_create (argv[0], strlen (argv[0]));
+      if (!ifp)
+	{
+          vty_out (vty, "%% Unable to create tunnel%s", VTY_NEWLINE);
+          return CMD_WARNING;
+	}
+    }
+
+  if_data = ifp->info;
+  if (if_data->ops)
+    {
+      if (if_data->ops->type != INTERFACE_TYPE_TUNNEL)
+        {
+          vty_out (vty, "%% Interface is already owned by a protocol other then tunnel%s", VTY_NEWLINE);
+          return CMD_WARNING;
+        }
+    }
+   else
+    {
+      if_data->ops = tunnel_create_ops();
+      if (!if_data->ops)
+        {
+          vty_out (vty, "%% Unable to create tunnel%s", VTY_NEWLINE);
+          return CMD_WARNING;
+        }
+    }
+
+  vty->index = ifp;
+  vty->node = TUNNEL_NODE;
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_create_tunnel,
+       no_create_tunnel_cmd,
+       "no create tunnel IFNAME",
+       NO_STR
+       "Delete virtual interface\n"
+       "Delete tunnel interface\n"
+       "Tunnel interface name\n")
+{
+  struct zebra_if *if_data;
+  struct interface *ifp;
+
+  ifp = if_lookup_by_name (argv[0]);
+  if (!ifp)
+    {
+      vty_out (vty, "%% No such tunnel interface%s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+  if_data = ifp->info;
+  if (if_data && if_data->ops && if_data->ops->type == INTERFACE_TYPE_TUNNEL)
+    {
+      struct tunnel_info *tun_data = if_data->ops->info;
+
+      if (tun_data->configured)
+	if_data->ops->delete (ifp);
+
+      if_zebra_delete_ops (ifp);
+    }
+  else
+    {
+      vty_out (vty, "%% Interface is not a tunnel interface%s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (tunnel_destination,
+       tunnel_destination_cmd,
+       "tunnel destination IPADDR",
+       "Tunnel configuration\n"
+       "Destination of tunnel\n"
+       "IP Address of the destination of tunnel\n")
+{
+  struct interface *ifp = (struct interface *) vty->index;
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  int ret;
+
+  ret = str2prefix (argv[0], &tun_data->dest);
+  if (ret <= 0)
+    {
+      vty_out (vty, "%% Malformed destination address %s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+  if (if_data->ops->create_check (ifp))
+    if (if_data->ops->create (ifp) < 0)
+      {
+	vty_out (vty, "%% Unable to create tunnel%s", VTY_NEWLINE);
+	return CMD_WARNING;
+      }
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_tunnel_destination,
+       no_tunnel_destination_cmd,
+       "no tunnel destination",
+       NO_STR
+       "Tunnel configuration\n"
+       "Destination of tunnel\n")
+{
+  struct interface *ifp = (struct interface *) vty->index;
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+
+  if (if_data->ops->delete_check(ifp))
+    if_data->ops->delete (ifp);
+
+  memset(&tun_data->dest, 0, sizeof (struct prefix));
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (tunnel_mode,
+       tunnel_mode_cmd,
+       "tunnel mode (gre|sit|ipip)",
+       "Tunnel configuration\n"
+       "Tunnel mode configuration\n"
+       "Generic Routing Encapsulation\n"
+       "IPv6 in IPv4\n"
+       "IPv4 in IPv4\n")
+{
+  struct interface *ifp = (struct interface *) vty->index;
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  int new_type = 0;
+
+  if (strncmp(argv[0], "gre", 3) == 0) {
+    new_type = TUNNEL_GRE;
+  } else if (strncmp(argv[0], "sit", 3) == 0) {
+    new_type = TUNNEL_SIT;
+  } else if (strncmp(argv[0], "ipip", 4) == 0) {
+    new_type = TUNNEL_IPIP;
+  } else {
+    vty_out (vty, "%% Unknown tunnel mode%s\n", VTY_NEWLINE);
+    return CMD_WARNING;
+  }
+
+  if (tun_data->type != new_type)
+    {
+      if (if_data->ops->delete_check (ifp))
+        if_data->ops->delete (ifp);
+
+      tun_data->type = new_type;
+      vty->node = TUNNEL_NODE;
+
+      tun_data->action = &do_tunnel;
+      tun_data->check = &do_tunnel_check;
+    }
+
+  if (if_data->ops->create_check (ifp))
+    if (if_data->ops->create (ifp) < 0)
+      {
+	vty_out (vty, "%% Unable to create tunnel%s", VTY_NEWLINE);
+	return CMD_WARNING;
+      }
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_tunnel_mode,
+       no_tunnel_mode_cmd,
+       "no tunnel mode",
+       NO_STR
+       "Tunnel configuration\n"
+       "Tunnel mode configuration\n")
+{
+  struct interface *ifp = (struct interface *) vty->index;
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+
+  if (if_data->ops->delete_check(ifp))
+    if_data->ops->delete (ifp);
+
+  tun_data->type = 0;
+  tun_data->action = &do_tunnel;
+  tun_data->check = &do_tunnel_check;
+
+  return CMD_SUCCESS;
+}
+
+#ifdef LINUX_MPLS
+DEFUN (tunnel_mode_mpls,
+       tunnel_mode_mpls_cmd,
+       "tunnel mode mpls",
+       "Tunnel configuration\n"
+       "Tunnel mode configuration\n"
+       "MPLS\n")
+{
+  struct interface *ifp = (struct interface *) vty->index;
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+
+  if (tun_data->type != TUNNEL_MPLS)
+    {
+      if (if_data->ops->delete_check (ifp))
+        if_data->ops->delete (ifp);
+
+      tun_data->type = TUNNEL_MPLS;
+      vty->node = MPLS_TUNNEL_NODE;
+
+      tun_data->action = &do_mpls_tunnel;
+      tun_data->check = &do_mpls_tunnel_check;
+    }
+
+  if (if_data->ops->create_check (ifp))
+    if (if_data->ops->create (ifp) < 0)
+      {
+	vty_out (vty, "%% Unable to create tunnel%s", VTY_NEWLINE);
+	return CMD_WARNING;
+      }
+
+  return CMD_SUCCESS;
+}
+
+static int
+mpls_static(struct vty *vty, struct zmpls_out_segment *new, struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  struct zmpls_out_segment *out = NULL;
+  int index;
+
+  if (tun_data->data)
+    {
+      return CMD_WARNING;
+    }
+
+  if (mpls_out_segment_register(new))
+    {
+      return CMD_WARNING;
+    }
+
+  index = mpls_out_segment_find_index_by_nhlfe(new);
+  assert(index);
+  tun_data->data = mpls_out_segment_find(index);
+
+  if (if_data->ops->create_check (ifp))
+    if (if_data->ops->create (ifp) < 0)
+      {
+	vty_out (vty, "%% Unable to create tunnel%s", VTY_NEWLINE);
+	return CMD_WARNING;
+      }
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (tunnel_mpls_static_addr,
+       tunnel_mpls_static_addr_cmd,
+       "tunnel mpls static (gen|atm|fr) VALUE nexthop INTERFACE ADDR",
+       "Tunnel configuration\n"
+       "MPLS Tunnel configuration\n"
+       "Static Tunnel Configuration\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n")
+{
+  struct interface *ifp = (struct interface *) vty->index;
+  struct zmpls_out_segment new;
+  int result;
+
+  memset (&new, 0, sizeof (new));
+  new.owner = ZEBRA_ROUTE_STATIC;
+  result = nhlfe_parse (vty, &argv[0], &new, argv[3]);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  return mpls_static(vty, &new, ifp);
+}
+
+DEFUN (tunnel_mpls_static_intf,
+       tunnel_mpls_static_intf_cmd,
+       "tunnel mpls static (gen|atm|fr) VALUE nexthop INTERFACE",
+       "Tunnel configuration\n"
+       "MPLS Tunnel configuration\n"
+       "Static Tunnel Configuration\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n")
+{
+  struct interface *ifp = (struct interface *) vty->index;
+  struct zmpls_out_segment new;
+  int result;
+
+  memset (&new, 0, sizeof (new));
+  new.owner = ZEBRA_ROUTE_STATIC;
+  result = nhlfe_parse (vty, &argv[0], &new, NULL);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  return mpls_static(vty, &new, ifp);
+}
+
+static int
+no_mpls_static(struct vty *vty, struct zmpls_out_segment *old, struct interface *ifp)
+{
+  struct zebra_if *if_data = ifp->info;
+  struct tunnel_info *tun_data = if_data->ops->info;
+  struct zmpls_out_segment *out = tun_data->data;
+  struct zmpls_out_segment *tmp;
+  int index;
+
+  if (!out)
+    {
+      return CMD_WARNING;
+    }
+
+  index = mpls_out_segment_find_index_by_nhlfe(old);
+  if (!index)
+    {
+      return CMD_WARNING;
+    }
+
+  tmp = mpls_out_segment_find(index);
+  if (tmp->index != out->index)
+    {
+      return CMD_WARNING;
+    }
+
+  if (if_data->ops->delete_check(ifp))
+    if_data->ops->delete (ifp);
+
+  mpls_out_segment_unregister (out);
+  tun_data->data = NULL;
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_tunnel_mpls_static_addr,
+       no_tunnel_mpls_static_addr_cmd,
+       "no tunnel mpls static (gen|atm|fr) VALUE nexthop INTERFACE ADDR",
+       NO_STR
+       "Tunnel configuration\n"
+       "MPLS Tunnel configuration\n"
+       "Static Tunnel Configuration\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n")
+{
+  struct interface *ifp = (struct interface *) vty->index;
+  struct zmpls_out_segment old;
+  int result;
+
+  memset (&old, 0, sizeof (old));
+  old.owner = ZEBRA_ROUTE_STATIC;
+  result = nhlfe_parse (vty, &argv[0], &old, argv[3]);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  return no_mpls_static(vty, &old, ifp);
+}
+
+DEFUN (no_tunnel_mpls_static_intf,
+       no_tunnel_mpls_static_intf_cmd,
+       "no tunnel mpls static (gen|atm|fr) VALUE nexthop INTERFACE",
+       NO_STR
+       "Tunnel configuration\n"
+       "MPLS Tunnel configuration\n"
+       "Static Tunnel Configuration\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n")
+{
+  struct interface *ifp = (struct interface *) vty->index;
+  struct zmpls_out_segment old;
+  int result;
+
+  memset (&old, 0, sizeof (old));
+  old.owner = ZEBRA_ROUTE_STATIC;
+  result = nhlfe_parse (vty, &argv[0], &old, NULL);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  return no_mpls_static(vty, &old, ifp);
+}
+
+struct cmd_node mpls_tunnel_node =
+{
+  MPLS_TUNNEL_NODE,
+  "%s(config-tun-mpls)# ",
+  1
+};
+#endif
+
+struct cmd_node tunnel_node =
+{
+  TUNNEL_NODE,
+  "%s(config-tun)# ",
+  1
+};
+
+static int
+tunnel_config_write (struct vty *vty)
+{
+  return 0;
+}
+
+void
+if_tunnel_init ()
+{
+  install_element (CONFIG_NODE, &create_tunnel_cmd);
+  install_element (CONFIG_NODE, &no_create_tunnel_cmd);
+
+  install_node (&tunnel_node, tunnel_config_write);
+
+  install_element (TUNNEL_NODE, &tunnel_destination_cmd);
+  install_element (TUNNEL_NODE, &no_tunnel_destination_cmd);
+  install_element (TUNNEL_NODE, &tunnel_mode_cmd);
+  install_element (TUNNEL_NODE, &no_tunnel_mode_cmd);
+#ifdef LINUX_MPLS
+  install_element (TUNNEL_NODE, &tunnel_mode_mpls_cmd);
+  install_node (&mpls_tunnel_node, tunnel_config_write);
+  install_element (MPLS_TUNNEL_NODE, &tunnel_destination_cmd);
+  install_element (MPLS_TUNNEL_NODE, &no_tunnel_destination_cmd);
+  install_element (MPLS_TUNNEL_NODE, &tunnel_mode_cmd);
+  install_element (MPLS_TUNNEL_NODE, &tunnel_mode_mpls_cmd);
+  install_element (MPLS_TUNNEL_NODE, &no_tunnel_mode_cmd);
+  install_element (MPLS_TUNNEL_NODE, &tunnel_mpls_static_addr_cmd);
+  install_element (MPLS_TUNNEL_NODE, &tunnel_mpls_static_intf_cmd);
+  install_element (MPLS_TUNNEL_NODE, &no_tunnel_mpls_static_addr_cmd);
+  install_element (MPLS_TUNNEL_NODE, &no_tunnel_mpls_static_intf_cmd);
+#endif
+}
diff -Naur quagga-0.99.10/zebra/if_vlan.c quagga-mpls/zebra/if_vlan.c
--- quagga-0.99.10/zebra/if_vlan.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/if_vlan.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,199 @@
+/* Zebra VLAN VTY functions
+ * Copyright (C) 2005 James R. Leu
+ *
+ * This file is part of GNU Zebra.
+ *
+ * GNU Zebra is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2, or (at your option) any
+ * later version.
+ *
+ * GNU Zebra is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU Zebra; see the file COPYING.  If not, write to the 
+ * Free Software Foundation, Inc., 59 Temple Place - Suite 330, 
+ * Boston, MA 02111-1307, USA.  
+ */
+
+#include <zebra.h>
+
+#include "if.h"
+#include "memory.h"
+#include "command.h"
+#include "vty.h"
+#include "prefix.h"
+#include "table.h"
+#include "interface.h"
+
+#include <linux/if_vlan.h>
+#include <linux/sockios.h>
+#include "ioctl.h"
+
+static void
+vlan_config (struct vty *vty, struct interface *ifp)
+{
+  vty_out (vty, "create vlan %s%s", ifp->name, VTY_NEWLINE);
+}
+
+static void
+vlan_show (struct vty *vty, struct interface *ifp)
+{
+  struct zebra_if *if_data;
+  if_data = ifp->info;
+  vty_out (vty, "  802.1q VLAN Tag %d%s", (int)if_data->ops->info, VTY_NEWLINE);
+}
+
+static void
+vlan_free (struct interface *ifp)
+{
+  struct zebra_if *if_data;
+  if_data = ifp->info;
+  XFREE (MTYPE_TMP, if_data->ops);
+  if_data->ops = NULL;
+}
+
+static int
+vlan_name_check(const char *input, char *ifname, int *vlan)
+{
+  char iff_str[IFNAMSIZ];
+  char *vlan_str;
+  char *iff;
+
+  strncpy(iff_str, input, IFNAMSIZ);
+
+  iff = strtok(iff_str, ".");
+  vlan_str = strtok(NULL, ".");
+  *vlan = atoi(vlan_str);
+
+  if (!(iff && vlan_str && (vlan > 0)))
+    return 0;
+
+  strncpy(ifname, iff, IFNAMSIZ);
+  return 1;
+}
+
+static struct interface_ops*
+vlan_create_ops(int vlan)
+{
+  struct interface_ops *ops = XMALLOC (MTYPE_TMP, sizeof(struct interface_ops));
+  if (!ops)
+    return NULL;
+
+  memset (ops, 0, sizeof(struct interface_ops));
+  ops->type = INTERFACE_TYPE_VLAN;
+  ops->config = &vlan_config;
+  ops->show = &vlan_show;
+  ops->free = &vlan_free;
+  ops->info = (void*)vlan;
+  return ops;
+}
+
+static int
+do_vlan (int cmd, char *name, int vlan)
+{
+  struct vlan_ioctl_args args;
+
+  strncpy(args.device1, name, IFNAMSIZ);
+  args.cmd = cmd;
+  if (cmd == ADD_VLAN_CMD)
+    args.u.VID = vlan;
+
+  return if_ioctl(SIOCSIFVLAN, (caddr_t)&args);
+}
+
+DEFUN (create_vlan,
+       create_vlan_cmd,
+       "create vlan IFNAME",
+       "Create virtual interface\n"
+       "Create VLAN interface\n"
+       "VLAN interface name\n")
+{
+  struct zebra_if *if_data;
+  struct interface *ifp;
+  char iff[IFNAMSIZ];
+  int vlan;
+
+  if (!vlan_name_check(argv[0], iff, &vlan))
+    {
+      vty_out (vty, "%% Invalid VLAN name%s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+  ifp = if_lookup_by_name(argv[0]);
+  if (!ifp)
+    {
+      ifp = if_create (argv[0], strlen (argv[0]));
+      if (!ifp)
+	{
+          vty_out (vty, "%% Unable to create VLAN%s", VTY_NEWLINE);
+          return CMD_WARNING;
+	}
+    }
+
+  if_data = ifp->info;
+  if (if_data->ops)
+    {
+      vty_out (vty, "%% Interface is already owned by a protocol other then 802.1q%s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+  if_data->ops = vlan_create_ops(vlan);
+  if (!if_data->ops)
+    {
+      vty_out (vty, "%% Unable to create VLAN%s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+  if (do_vlan (ADD_VLAN_CMD, iff, vlan) < 0)
+    {
+      if_zebra_delete_ops (ifp);
+      vty_out (vty, "%% Unable creating VLAN%s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_create_vlan,
+       no_create_vlan_cmd,
+       "no create vlan IFNAME",
+       NO_STR
+       "Delete virtual interface\n"
+       "Delete VLAN interface\n"
+       "VLAN interface name\n")
+{
+  struct zebra_if *if_data;
+  struct interface *ifp;
+  char iff[IFNAMSIZ];
+  int vlan;
+
+  if (!vlan_name_check(argv[0], iff, &vlan))
+    {
+      vty_out (vty, "%% Invalid VLAN name%s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+  ifp = if_lookup_by_name (argv[0]);
+  if (!ifp)
+    return CMD_WARNING;
+
+  if_data = ifp->info;
+  if (if_data && if_data->ops && if_data->ops->type == INTERFACE_TYPE_VLAN)
+    {
+      if_zebra_delete_ops (ifp);
+      do_vlan (DEL_VLAN_CMD, ifp->name, 0);
+    }
+
+  return CMD_SUCCESS;
+}
+
+void
+if_vlan_init ()
+{
+  install_element (CONFIG_NODE, &create_vlan_cmd);
+  install_element (CONFIG_NODE, &no_create_vlan_cmd);
+}
diff -Naur quagga-0.99.10/zebra/interface.c quagga-mpls/zebra/interface.c
--- quagga-0.99.10/zebra/interface.c	2007-05-10 04:38:52.000000000 +0200
+++ quagga-mpls/zebra/interface.c	2008-11-25 12:30:18.000000000 +0100
@@ -88,6 +88,28 @@
   return 0;
 }
 
+void
+if_zebra_delete_ops (struct interface *ifp)
+{
+  struct zebra_if *zebra_if = ifp->info;
+
+  if (!zebra_if)
+    return;
+
+  if (zebra_if->ops)
+    {
+      if (zebra_if->ops->free)
+	{
+          zebra_if->ops->free(ifp);
+	}
+      else
+	{
+	  XFREE (MTYPE_TMP, zebra_if->ops);
+	  zebra_if->ops = NULL;
+	}
+    }
+}
+
 /* Called when interface is deleted. */
 static int
 if_zebra_delete_hook (struct interface *ifp)
@@ -98,6 +120,20 @@
     {
       zebra_if = ifp->info;
 
+      /* Free interface specific ops block. */
+      if (zebra_if->ops)
+	{
+ 	  if (zebra_if->ops->free)
+	    {
+              zebra_if->ops->free(ifp);
+	    }
+	  else
+	    {
+	      XFREE (MTYPE_TMP, zebra_if->ops);
+	      zebra_if->ops = NULL;
+	    }
+	}
+
       /* Free installed address chains tree. */
       if (zebra_if->ipv4_subnets)
 	route_table_finish (zebra_if->ipv4_subnets);
@@ -673,6 +709,10 @@
   if (ifp->desc)
     vty_out (vty, "  Description: %s%s", ifp->desc,
 	     VTY_NEWLINE);
+
+  if (zebra_if->ops && zebra_if->ops->show)
+    zebra_if->ops->show (vty, ifp);
+
   if (ifp->ifindex == IFINDEX_INTERNAL)
     {
       vty_out(vty, "  pseudo interface%s", VTY_NEWLINE);
@@ -727,6 +767,14 @@
       vty_out(vty, "%s", VTY_NEWLINE);
     }
 
+#ifdef HAVE_MPLS
+  /* MPLS labelspace */
+  if (ifp->mpls_labelspace != -1)
+    {
+      vty_out(vty, "  MPLS labelspace %u", ifp->mpls_labelspace);
+      vty_out(vty, "%s", VTY_NEWLINE);
+    }
+#endif
   for (rn = route_top (zebra_if->ipv4_subnets); rn; rn = route_next (rn))
     {
       if (! rn->info)
@@ -1519,6 +1567,18 @@
   for (ALL_LIST_ELEMENTS_RO (iflist, node, ifp))
     {
       struct zebra_if *if_data;
+
+      if_data = ifp->info;
+      
+      if (if_data->ops && if_data->ops->config)
+	if_data->ops->config (vty, ifp);
+
+      vty_out (vty, "!%s", VTY_NEWLINE);
+    }
+
+  for (ALL_LIST_ELEMENTS_RO (iflist, node, ifp))
+    {
+      struct zebra_if *if_data;
       struct listnode *addrnode;
       struct connected *ifc;
       struct prefix *p;
@@ -1536,7 +1596,10 @@
 	 while processing config script */
       if (ifp->bandwidth != 0)
 	vty_out(vty, " bandwidth %u%s", ifp->bandwidth, VTY_NEWLINE); 
-
+#ifdef HAVE_MPLS
+      if (ifp->mpls_labelspace != -1)
+	vty_out(vty, " mpls labelspace %u%s",ifp->mpls_labelspace,VTY_NEWLINE);
+#endif
       if (CHECK_FLAG(ifp->status, ZEBRA_INTERFACE_LINKDETECTION))
 	vty_out(vty, " link-detect%s", VTY_NEWLINE);
 
diff -Naur quagga-0.99.10/zebra/interface.h quagga-mpls/zebra/interface.h
--- quagga-0.99.10/zebra/interface.h	2006-08-06 17:57:59.000000000 +0200
+++ quagga-mpls/zebra/interface.h	2008-11-25 12:30:18.000000000 +0100
@@ -27,6 +27,7 @@
 #ifdef HAVE_IRDP
 #include "zebra/irdp.h"
 #endif
+#include "vty.h"
 
 /* For interface multicast configuration. */
 #define IF_ZEBRA_MULTICAST_UNSPEC 0
@@ -175,6 +176,26 @@
 
 #endif /* RTADV */
 
+enum interface_type
+{
+  INTERFACE_TYPE_VLAN = 1,
+  INTERFACE_TYPE_TUNNEL,
+  INTERFACE_TYPE_MAX
+};
+
+struct interface_ops
+{
+  enum interface_type type;
+  void (*config)(struct vty*, struct interface*);
+  void (*show)(struct vty*, struct interface*);
+  int (*create)(struct interface*);
+  int (*delete)(struct interface*);
+  int (*create_check)(struct interface*);
+  int (*delete_check)(struct interface*);
+  void (*free)(struct interface*);
+  void *info;
+};
+
 /* `zebra' daemon local interface structure. */
 struct zebra_if
 {
@@ -193,6 +214,9 @@
   /* Installed addresses chains tree. */
   struct route_table *ipv4_subnets;
 
+  /* Interface specific operations. */
+  struct interface_ops *ops;
+
 #ifdef RTADV
   struct rtadvconf rtadv;
 #endif /* RTADV */
@@ -217,6 +241,7 @@
 extern void if_down (struct interface *);
 extern void if_refresh (struct interface *);
 extern void if_flags_update (struct interface *, uint64_t);
+extern void if_zebra_delete_ops (struct interface *);
 extern int if_subnet_add (struct interface *, struct connected *);
 extern int if_subnet_delete (struct interface *, struct connected *);
 
@@ -238,4 +263,7 @@
 extern int if_kvm_get_mtu (struct interface *);
 #endif /* BSDI */
 
+extern void if_vlan_init();
+extern void if_tunnel_init();
+
 #endif /* _ZEBRA_INTERFACE_H */
diff -Naur quagga-0.99.10/zebra/ioctl.c quagga-mpls/zebra/ioctl.c
--- quagga-0.99.10/zebra/ioctl.c	2008-02-26 15:02:24.000000000 +0100
+++ quagga-mpls/zebra/ioctl.c	2008-11-25 12:30:18.000000000 +0100
@@ -52,7 +52,7 @@
 {
   int sock;
   int ret;
-  int err;
+  int err = 0;
 
   if (zserv_privs.change(ZPRIVS_RAISE))
     zlog (NULL, LOG_ERR, "Can't raise privileges");
@@ -85,7 +85,7 @@
 {
   int sock;
   int ret;
-  int err;
+  int err = 0;
 
   if (zserv_privs.change(ZPRIVS_RAISE))
     zlog (NULL, LOG_ERR, "Can't raise privileges");
diff -Naur quagga-0.99.10/zebra/kernel_socket.c quagga-mpls/zebra/kernel_socket.c
--- quagga-0.99.10/zebra/kernel_socket.c	2008-01-11 16:57:13.000000000 +0100
+++ quagga-mpls/zebra/kernel_socket.c	2008-11-25 12:30:18.000000000 +0100
@@ -761,11 +761,13 @@
 rtm_read (struct rt_msghdr *rtm)
 {
   int flags;
-  u_char zebra_flags;
+  u_short zebra_flags;
   union sockunion dest, mask, gate;
   char ifname[INTERFACE_NAMSIZ + 1];
   short ifnlen = 0;
+  struct zapi_nexthop nh;
 
+  memset(&nh, 0, sizeof(struct zapi_nexthop));
   zebra_flags = 0;
 
   /* Read destination and netmask and gateway from rtm message
@@ -802,13 +804,20 @@
 
   /* This is a reject or blackhole route */
   if (flags & RTF_REJECT)
-    SET_FLAG (zebra_flags, ZEBRA_FLAG_REJECT);
-  if (flags & RTF_BLACKHOLE)
-    SET_FLAG (zebra_flags, ZEBRA_FLAG_BLACKHOLE);
+    {
+      SET_FLAG (nh.type, ZEBRA_NEXTHOP_DROP);
+      nh.gw.drop = ZEBRA_DROP_REJECT;
+    }
+  else if (flags & RTF_BLACKHOLE)
+    {
+      SET_FLAG (nh.type, ZEBRA_NEXTHOP_DROP);
+      nh.gw.drop = ZEBRA_DROP_BLACKHOLE;
+    }
 
   if (dest.sa.sa_family == AF_INET)
     {
       struct prefix_ipv4 p;
+      struct zapi_nexthop znh;
 
       p.family = AF_INET;
       p.prefix = dest.sin.sin_addr;
@@ -816,6 +825,10 @@
 	p.prefixlen = IPV4_MAX_PREFIXLEN;
       else
 	p.prefixlen = ip_masklen (mask.sin.sin_addr);
+
+      memset (&znh, 0, sizeof (struct zapi_nexthop));
+      znh.type = ZEBRA_NEXTHOP_IPV4;
+      znh.gw.ipv4 = gate.sin;
       
       /* Catch self originated messages and match them against our current RIB.
        * At the same time, ignore unconfirmed messages, they should be tracked
@@ -827,7 +840,7 @@
         int ret;
         if (! IS_ZEBRA_DEBUG_RIB)
           return;
-        ret = rib_lookup_ipv4_route (&p, &gate); 
+        ret = rib_lookup_route_nexthop ((struct prefix*)&p, &znh); 
         inet_ntop (AF_INET, &p.prefix, buf, INET_ADDRSTRLEN);
         switch (rtm->rtm_type)
         {
@@ -891,17 +904,20 @@
        * to specify the route really
        */
       if (rtm->rtm_type == RTM_CHANGE)
-        rib_delete_ipv4 (ZEBRA_ROUTE_KERNEL, zebra_flags, &p,
-                         NULL, 0, 0);
+        rib_delete_route (ZEBRA_ROUTE_KERNEL, zebra_flags,
+                          (struct prefix*)&p, &nh, 0);
+
+      nh.gw.ipv4 = gate.sin.sin_addr;
+      SET_FLAG (nh.type, ZEBRA_NEXTHOP_IPV4);
       
       if (rtm->rtm_type == RTM_GET 
           || rtm->rtm_type == RTM_ADD
           || rtm->rtm_type == RTM_CHANGE)
-	rib_add_ipv4 (ZEBRA_ROUTE_KERNEL, zebra_flags, 
-		      &p, &gate.sin.sin_addr, NULL, 0, 0, 0, 0);
+	rib_add_route (ZEBRA_ROUTE_KERNEL, zebra_flags, (struct prefix*)&p,
+                       &nh, NULL, 0, 0, 0);
       else
-	rib_delete_ipv4 (ZEBRA_ROUTE_KERNEL, zebra_flags, 
-		      &p, &gate.sin.sin_addr, 0, 0);
+	rib_delete_route (ZEBRA_ROUTE_KERNEL, zebra_flags,
+                          (struct prefix*)&p, &nh, 0);
     }
 #ifdef HAVE_IPV6
   if (dest.sa.sa_family == AF_INET6)
@@ -933,17 +949,26 @@
        * to specify the route really
        */
       if (rtm->rtm_type == RTM_CHANGE)
-        rib_delete_ipv6 (ZEBRA_ROUTE_KERNEL, zebra_flags, &p,
+        rib_delete_route (ZEBRA_ROUTE_KERNEL, zebra_flags, (struct prefix*)&p,
                          NULL, 0, 0);
+
+      nh.gw.ipv6 = gate.sin6.sin_addr6;
+      SET_FLAG (nh.type, ZEBRA_NEXTHOP_IPV6);
+
+      if (ifindex)
+        {
+          nh.intf.index = ifindex;
+          SET_FLAG (nh.type, ZEBRA_NEXTHOP_IFINDEX);
+        }
       
       if (rtm->rtm_type == RTM_GET 
           || rtm->rtm_type == RTM_ADD
           || rtm->rtm_type == RTM_CHANGE)
-	rib_add_ipv6 (ZEBRA_ROUTE_KERNEL, zebra_flags,
-		      &p, &gate.sin6.sin6_addr, ifindex, 0, 0, 0);
+	rib_add_route (ZEBRA_ROUTE_KERNEL, zebra_flags, (struct prefix*)&p,
+                       &nh, 0, 0, 0);
       else
-	rib_delete_ipv6 (ZEBRA_ROUTE_KERNEL, zebra_flags,
-			 &p, &gate.sin6.sin6_addr, ifindex, 0);
+	rib_delete_route (ZEBRA_ROUTE_KERNEL, zebra_flags,
+                          (struct prefix*)&p, &nh, 0);
     }
 #endif /* HAVE_IPV6 */
 }
diff -Naur quagga-0.99.10/zebra/main.c quagga-mpls/zebra/main.c
--- quagga-0.99.10/zebra/main.c	2008-05-29 20:24:58.000000000 +0200
+++ quagga-mpls/zebra/main.c	2008-11-25 12:30:18.000000000 +0100
@@ -39,6 +39,7 @@
 #include "zebra/router-id.h"
 #include "zebra/irdp.h"
 #include "zebra/rtadv.h"
+#include "zebra/interface.h"
 
 /* Zebra instance */
 struct zebra_t zebrad =
@@ -169,6 +170,9 @@
 
   if (!retain_mode)
     rib_close ();
+#ifdef HAVE_MPLS
+  mpls_close ();
+#endif
 #ifdef HAVE_IRDP
   irdp_finish();
 #endif
@@ -320,16 +324,24 @@
   /* Zebra related initialize. */
   zebra_init ();
   rib_init ();
+#ifdef HAVE_MPLS
+  mpls_init ();
+#endif
   zebra_if_init ();
   zebra_debug_init ();
   router_id_init();
   zebra_vty_init ();
+#ifdef HAVE_MPLS
+  mpls_vty_init ();
+#endif
   access_list_init ();
   prefix_list_init ();
   rtadv_init ();
 #ifdef HAVE_IRDP
   irdp_init();
 #endif
+  if_vlan_init();
+  if_tunnel_init();
 
   /* For debug purpose. */
   /* SET_FLAG (zebra_debug_event, ZEBRA_DEBUG_EVENT); */
@@ -338,6 +350,10 @@
   kernel_init ();
   interface_list ();
   route_read ();
+#ifdef HAVE_MPLS
+  mpls_kernel_init ();
+  mpls_read ();
+#endif
 
   /* Sort VTY commands. */
   sort_node ();
diff -Naur quagga-0.99.10/zebra/Makefile.am quagga-mpls/zebra/Makefile.am
--- quagga-0.99.10/zebra/Makefile.am	2007-05-02 18:05:35.000000000 +0200
+++ quagga-mpls/zebra/Makefile.am	2008-11-25 12:30:18.000000000 +0100
@@ -15,39 +15,50 @@
 kernel_method = @KERNEL_METHOD@
 other_method = @OTHER_METHOD@
 ioctl_method = @IOCTL_METHOD@
+mpls_method = @MPLS_METHOD@
 
 otherobj = $(ioctl_method) $(ipforward) $(if_method) $(if_proc) \
-	$(rt_method) $(rtread_method) $(kernel_method) $(other_method)
+	$(rt_method) $(rtread_method) $(kernel_method) $(other_method) \
+	$(mpls_method)
 
 sbin_PROGRAMS = zebra
 
-noinst_PROGRAMS = testzebra
+#noinst_PROGRAMS = testzebra
+
+mpls_sources=
+mpls_headers=
+if MPLS_ENABLED
+mpls_sources+=mpls_vty.c mpls_lib.c
+mpls_headers+=mpls_vty.h mpls_lib.h
+endif
 
 zebra_SOURCES = \
 	zserv.c main.c interface.c connected.c zebra_rib.c zebra_routemap.c \
 	redistribute.c debug.c rtadv.c zebra_snmp.c zebra_vty.c \
-	irdp_main.c irdp_interface.c irdp_packet.c router-id.c
+	irdp_main.c irdp_interface.c irdp_packet.c router-id.c if_vlan.c \
+	if_tunnel.c $(mpls_sources)
 
-testzebra_SOURCES = test_main.c zebra_rib.c interface.c connected.c debug.c \
-	zebra_vty.c \
-	kernel_null.c  redistribute_null.c ioctl_null.c misc_null.c
+#testzebra_SOURCES = test_main.c zebra_rib.c interface.c connected.c debug.c \
+#	zebra_vty.c \
+#	kernel_null.c  redistribute_null.c ioctl_null.c misc_null.c
 
 noinst_HEADERS = \
 	connected.h ioctl.h rib.h rt.h zserv.h redistribute.h debug.h rtadv.h \
-	interface.h ipforward.h irdp.h router-id.h kernel_socket.h
+	interface.h ipforward.h irdp.h router-id.h kernel_socket.h netlink.h \
+	$(mpls_headers)
 
 zebra_LDADD = $(otherobj) $(LIBCAP) $(LIB_IPV6) ../lib/libzebra.la
 
-testzebra_LDADD = $(LIBCAP) $(LIB_IPV6) ../lib/libzebra.la
+#testzebra_LDADD = $(LIBCAP) $(LIB_IPV6) ../lib/libzebra.la
 
 zebra_DEPENDENCIES = $(otherobj)
 
 EXTRA_DIST = if_ioctl.c if_ioctl_solaris.c if_netlink.c if_proc.c \
         if_sysctl.c ipforward_aix.c ipforward_ews.c ipforward_proc.c \
-	ipforward_solaris.c ipforward_sysctl.c rt_ioctl.c rt_netlink.c \
+	ipforward_solaris.c ipforward_sysctl.c rt_ioctl.c netlink.c \
 	rt_socket.c rtread_netlink.c rtread_proc.c rtread_sysctl.c \
 	rtread_getmsg.c kernel_socket.c kernel_netlink.c mtu_kvm.c \
-	ioctl.c ioctl_solaris.c \
+	ioctl.c ioctl_solaris.c netlink.c\
 	GNOME-SMI GNOME-PRODUCT-ZEBRA-MIB
 
 #client : client_main.o ../lib/libzebra.la
diff -Naur quagga-0.99.10/zebra/mpls_ioctl.c quagga-mpls/zebra/mpls_ioctl.c
--- quagga-0.99.10/zebra/mpls_ioctl.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/mpls_ioctl.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,205 @@
+#include "zebra.h"
+#include "mpls_lib.h"
+
+static int mpls_linux_fd = 0;
+
+int
+mpls_ctrl_show_hardware(struct *vty)
+{
+  vty_out(vty, "MPLS-Linux: %d.%d%d%d%s ioctl control%s",
+    (MPLS_LINUX_VERSION >> 24) & 0xFF,
+    (MPLS_LINUX_VERSION >> 16) & 0xFF,
+    (MPLS_LINUX_VERSION >> 8) & 0xFF,
+    (MPLS_LINUX_VERSION) & 0xFF, VTY_NEWLINE);
+  return CMD_SUCCESS;
+}
+
+int
+mpls_kernel_init()
+{
+  mpls_linux_fd = socket(AF_INET,SOCK_DGRAM,0);
+#if 0
+  struct ifreq ifr;
+#endif
+
+  if(mpls_linux_fd < 0)
+  {
+    return -1;
+  }
+
+#if 0
+  ioctl(mpls_linux_fd,SIOCMPLSILMFLUSH,&ifr);
+  ioctl(mpls_linux_fd,SIOCMPLSNHLFEFLUSH,&ifr);
+#endif
+
+  return 0;
+}
+
+int
+mpls_ctrl_nhlfe_unregister(struct zmpls_out_segment *old)
+{
+  struct mpls_out_label_req mol_req;
+
+  mol_req.mol_label.ml_type = MPLS_LABEL_KEY;
+  mol_req.mol_label.u.ml_key = old->out_key;
+  return ioctl(mpls_linux_fd,SIOCMPLSNHLFEDEL,&mol_req);
+}
+
+int
+mpls_ctrl_nhlfe_register(struct zmpls_out_segment *new)
+{
+  struct mpls_out_label_req mol_req;
+  struct mpls_instr_req mir_req;
+  struct interface *ifp;
+  int result;
+
+  mol_req.mol_label.ml_type = MPLS_LABEL_KEY;
+  mol_req.mol_label.u.ml_key = 0;
+  
+  result = ioctl(mpls_linux_fd,SIOCMPLSNHLFEADD,&mol_req);
+  if (result < 0)
+  {
+    return -1;
+  }
+  new->out_key = mol_req.mol_label.u.ml_key;
+
+  mir_req.mir_direction = MPLS_OUT;
+  memcpy(&mir_req.mir_label,&mol_req.mol_label,sizeof(struct mpls_label));
+
+  mir_req.mir_instr[0].mir_opcode = MPLS_OP_PUSH;
+  mir_req.mir_instr[0].mir_data.push.ml_type = MPLS_LABEL_GEN;
+  mir_req.mir_instr[0].mir_data.push.u.ml_gen = new->push.u.gen;
+
+  mir_req.mir_instr[1].mir_opcode = MPLS_OP_SET;
+
+  if (new->nh.type & NEXTHOP_TYPE_IFNAME)
+  {
+      ifp = if_lookup_by_name (new->nh.ifname);
+      mir_req.mir_instr[1].mir_data.set.mni_if = ifp ? ifp->ifindex : 0;
+  }
+
+  if (new->nh.type & NEXTHOP_TYPE_IPV4)
+    {
+      struct sockaddr_in addr;
+      addr.sin_family = AF_INET;
+      addr.sin_addr = new->nh.gate.ipv4;
+      memcpy(&mir_req.mir_instr[1].mir_data.set.mni_addr, &addr, sizeof(addr));
+    }
+  else if (new->nh.type & NEXTHOP_TYPE_IPV6)
+    {
+      struct sockaddr_in6 addr;
+      addr.sin6_family = AF_INET6;
+      addr.sin6_addr = new->nh.gate.ipv6;
+      memcpy(&mir_req.mir_instr[1].mir_data.set.mni_addr, &addr, sizeof(addr));
+    }
+  else
+    {
+      assert (0);
+    }
+
+  mir_req.mir_instr_length = 2;
+
+  result = ioctl(mpls_linux_fd,SIOCSMPLSOUTINSTR,&mir_req);
+
+  return (result < 0) ? mpls_ctrl_nhlfe_unregister(new) : 0;
+}
+
+int
+mpls_ctrl_ilm_unregister(struct zmpls_in_segment *old)
+{
+  struct mpls_in_label_req mil_req;
+
+  mil_req.mil_label.ml_type = MPLS_LABEL_GEN;
+  mil_req.mil_label.u.ml_gen = old->label.u.gen;
+  mil_req.mil_label.ml_index = old->labelspace;
+
+  return ioctl(mpls_linux_fd,SIOCMPLSILMDEL,&mil_req);
+}
+
+int
+mpls_ctrl_ilm_register(struct zmpls_in_segment *new)
+{
+  struct mpls_in_label_req mil_req;
+  int result;
+
+  mil_req.mil_label.ml_type = MPLS_LABEL_GEN;
+  mil_req.mil_label.u.ml_gen = new->label.u.gen;
+  mil_req.mil_label.ml_index = new->labelspace;
+
+  result = ioctl(mpls_linux_fd,SIOCMPLSILMADD,&mil_req);
+
+  if (result < 0)
+  {
+    return -1;
+  }
+
+  return 0;
+}
+
+int mpls_ctrl_xc_register(struct zmpls_in_segment *in,
+  struct zmpls_out_segment *out)
+{
+  struct mpls_xconnect_req mx_req;
+  int result;
+
+  mx_req.mx_in.ml_type = MPLS_LABEL_GEN;
+  mx_req.mx_in.u.ml_gen = in->label.u.gen;
+  mx_req.mx_in.ml_index = in->labelspace;
+  mx_req.mx_out.ml_type = MPLS_LABEL_KEY;
+  mx_req.mx_out.u.ml_key = out->out_key;
+
+  result = ioctl(mpls_linux_fd,SIOCMPLSXCADD,&mx_req);
+  if (result < 0)
+  {
+    return -1;
+  }
+
+  return 0;
+}
+
+int mpls_ctrl_xc_unregister(struct zmpls_in_segment *in,
+  struct zmpls_out_segment *out)
+{
+  struct mpls_xconnect_req mx_req;
+  int result;
+
+  mx_req.mx_in.ml_type = MPLS_LABEL_GEN;
+  mx_req.mx_in.u.ml_gen = in->label.u.gen;
+  mx_req.mx_in.ml_index = in->labelspace;
+  mx_req.mx_out.ml_type = MPLS_LABEL_KEY;
+  mx_req.mx_out.u.ml_key = out->out_key;
+
+  result = ioctl(mpls_linux_fd,SIOCMPLSXCDEL,&mx_req);
+  if (result < 0)
+  {
+    return -1;
+  }
+
+  return 0;
+}
+
+int mpls_ctrl_ftn_register(struct zmpls_ftn *ftn)
+{
+  return 0;
+}
+
+int mpls_ctrl_ftn_unregister(struct zmpls_ftn *ftn)
+{
+  return 0;
+}
+
+int mpls_ctrl_set_interface_labelspace(struct interface *ifp)
+{
+  struct mpls_labelspace_req  mls_req;
+
+  mls_req.mls_ifindex    = ifp->ifindex;
+  mls_req.mls_labelspace = ifp->mpls_labelspace;
+  ioctl(mpls_linux_fd,SIOCSLABELSPACEMPLS,&mls_req);
+
+  return 0;
+}
+
+int
+mpls_read (void)
+{
+}
diff -Naur quagga-0.99.10/zebra/mpls_lib.c quagga-mpls/zebra/mpls_lib.c
--- quagga-0.99.10/zebra/mpls_lib.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/mpls_lib.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,768 @@
+/*
+ * MPLS Label Information Base for zebra daemon.
+ *
+ * Copyright (C) 2004 James R. Leu 
+ *
+ * This file is part of Quagga routing suite.
+ *
+ * Quagga is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2, or (at your option) any
+ * later version.
+ *
+ * Quagga is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU Zebra; see the file COPYING.  If not, write to the Free
+ * Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
+ * 02111-1307, USA.
+ */
+
+#include <zebra.h>
+
+#ifdef HAVE_MPLS
+
+#include "linklist.h"
+#include "memory.h"
+#include "if.h"
+#include "log.h"
+#include "mpls_lib.h"
+#include "redistribute.h"
+#include "zclient.h"
+
+extern struct zebra_t zebrad;
+extern void rib_queue_add (struct zebra_t *zebra, struct route_node *rn);
+void mpls_xc_unregister(struct zmpls_xc *old);
+
+/*************************** out segment *****************************/
+
+int
+mpls_nexthop_ready(struct zapi_nexthop *nh)
+{
+  struct interface *ifp = NULL;
+  int match = 0;
+  int try = 0;
+
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_IFINDEX))
+    {
+      ifp = if_lookup_by_index(nh->intf.index);
+      try++;
+      if (ifp && if_is_operative(ifp))
+        match++;
+    }
+  else if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_IFNAME))
+    {
+      ifp = if_lookup_by_name(nh->intf.name);
+      try++;
+      if (ifp && if_is_operative(ifp))
+        match++;
+    }
+
+  if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_IPV6))
+    {
+
+      try++;
+      if (ifp)
+        {
+          struct listnode *node;
+          struct connected *ifc;
+          struct prefix np;
+          memset (&np, 0, sizeof (struct prefix));
+
+          np.family = AF_INET6;
+          np.prefixlen = IPV6_MAX_PREFIXLEN;
+          np.u.prefix6 = nh->gw.ipv6;
+
+          for (ALL_LIST_ELEMENTS_RO(ifp->connected,node,ifc))
+            {
+              if (prefix_match(ifc->address, &np))
+                {
+                  match++;
+                  break;
+                }
+            }
+        }
+    }
+  else if (CHECK_FLAG (nh->type, ZEBRA_NEXTHOP_IPV4))
+    {
+      try++;
+      if (!ifp)
+        {
+          ifp = if_lookup_address(nh->gw.ipv4);
+          if (ifp && if_is_operative(ifp))
+            match++;
+        }
+      else
+        {
+          struct listnode *node;
+          struct connected *ifc;
+          struct prefix np;
+          memset (&np, 0, sizeof (struct prefix));
+
+          np.family = AF_INET;
+          np.prefixlen = IPV4_MAX_PREFIXLEN;
+          np.u.prefix4 = nh->gw.ipv4;
+
+          for (ALL_LIST_ELEMENTS_RO(ifp->connected,node,ifc))
+            {
+              if (prefix_match(ifc->address, &np))
+                {
+                  match++;
+                  break;
+                }
+            }
+        }
+    }
+
+  return (try && try == match) ? 1 : 0;
+}
+
+static
+int mpls_out_segment_cmp(void *val1, void *val2)
+{
+  struct zmpls_out_segment *v1 = val1;
+  struct zmpls_out_segment *v2 = val2;
+
+  if (v1->index > v2->index)
+  {
+    return 1;
+  }
+  else if (v1->index < v2->index)
+  {
+    return -1;
+  }
+  return 0;
+}
+
+static int mpls_out_segment_nextindex = 1;
+
+struct list mpls_out_segment_list = {
+  .head = NULL,
+  .tail = NULL, 
+  .count = 0,
+  .cmp = mpls_out_segment_cmp,
+  .del = NULL,
+};
+
+unsigned int
+mpls_out_segment_find_index_by_nexthop(struct zapi_nexthop *nh)
+{
+  struct listnode *node;
+  struct zmpls_out_segment *old;
+
+  for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list,node,old))
+  {
+    if (zapi_nexthop_match(&old->nh, nh, ZEBRA_NEXTHOP_ALL))
+      goto found;
+  }
+  return 0;
+found:
+  return old->index;
+}
+
+unsigned int
+mpls_out_segment_find_index_by_nhlfe(struct zmpls_out_segment *out)
+{
+  struct listnode *node;
+  struct zmpls_out_segment *old;
+
+  for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list,node,old))
+  {
+    if (old->owner == out->owner &&
+	zapi_nexthop_match(&old->nh, &out->nh, ZEBRA_NEXTHOP_ALL))
+      goto found;
+  }
+  return 0;
+found:
+  return old->index;
+}
+
+struct zmpls_out_segment*
+mpls_out_segment_find(unsigned int index)
+{
+  struct listnode *node;
+  struct zmpls_out_segment *old;
+
+  for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list,node,old))
+    if (index == old->index)
+      goto found;
+
+  return NULL;
+found:
+  return old;
+}
+
+struct zmpls_out_segment*
+mpls_out_segment_find_by_out_key(unsigned int key)
+{
+  struct listnode *node;
+  struct zmpls_out_segment *old;
+
+  for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list,node,old))
+    if (key == old->out_key)
+      goto found;
+
+  return NULL;
+found:
+  return old;
+}
+
+static int
+do_mpls_out_segment_unregister(struct zmpls_out_segment *old)
+{
+  int ret = 0;
+  if (old->owner != ZEBRA_ROUTE_KERNEL && old->installed)
+    ret = mpls_ctrl_nhlfe_unregister(old);
+
+  redistribute_delete_mpls_out_segment (old);
+  LISTNODE_DETACH(&mpls_out_segment_list, &old->global);
+  XFREE (MTYPE_TMP, old);
+  return ret;
+}
+
+int
+mpls_out_segment_unregister(struct zmpls_out_segment *out)
+{
+  struct zmpls_out_segment *old = mpls_out_segment_find (out->index);
+
+  if (!old)
+    return 1;
+
+  return do_mpls_out_segment_unregister (old);
+}
+
+int
+mpls_out_segment_unregister_by_index(unsigned int index)
+{
+  struct zmpls_out_segment *old = mpls_out_segment_find (index);
+
+  if (!old)
+    return 1;
+
+  return do_mpls_out_segment_unregister (old);
+}
+
+int
+mpls_out_segment_register(struct zmpls_out_segment *out)
+{
+  struct zmpls_out_segment *new;
+  int err;
+
+  if ((err = mpls_out_segment_find_index_by_nhlfe (out)))
+    return err;
+
+  new = XMALLOC (MTYPE_TMP, sizeof (struct zmpls_out_segment));
+  if (!new)
+    return -ENOMEM;
+
+  memcpy (new, out, sizeof (struct zmpls_out_segment));
+
+  new->global.data = new;
+  new->global.next = NULL;
+  new->global.prev = NULL;
+  out->index = new->index = mpls_out_segment_nextindex++;
+  new->installed = out->installed = 0;
+
+  if (new->owner != ZEBRA_ROUTE_KERNEL)
+  {
+    if (mpls_nexthop_ready(&new->nh))
+    {
+      if ((err = mpls_ctrl_nhlfe_register(new))) {
+	XFREE (MTYPE_TMP, new);
+	return err;
+      }
+      out->out_key = new->out_key;
+      new->installed = out->installed = 1;
+    } else {
+      /*
+       * in the future we should add this to a specific list, instead of
+       * relying on brute force search foreach interface/address event
+       */
+    }
+  } else {
+    new->installed = out->installed = 1;
+  }
+
+  LISTNODE_ATTACH(&mpls_out_segment_list, &new->global);
+
+  if (new->installed)
+    redistribute_add_mpls_out_segment (new);
+
+  return 0;
+}
+
+/*************************** in segment *****************************/
+
+struct list mpls_in_segment_list = {
+  .head = NULL,
+  .tail = NULL, 
+  .count = 0,
+  .cmp = NULL,
+  .del = NULL,
+};
+
+int
+mpls_in_segment_match(struct zmpls_in_segment *a, struct zmpls_in_segment *b)
+{
+
+  if (a->labelspace == b->labelspace)
+    return mpls_label_match(&a->label, &b->label);
+
+  return 0;
+}
+
+struct zmpls_in_segment*
+mpls_in_segment_find(struct zmpls_in_segment *in)
+{
+  struct listnode *node;
+  struct zmpls_in_segment *old;
+
+  for (ALL_LIST_ELEMENTS_RO(&mpls_in_segment_list,node,old))
+    if (mpls_in_segment_match(in, old))
+      return old;
+
+  return NULL;
+}
+
+static int
+do_mpls_in_segment_unregister(struct zmpls_in_segment *in, int flag)
+{
+  if (in->installed)
+    mpls_ctrl_ilm_unregister (in);
+
+  if (in->xc)
+  {
+    struct zmpls_xc *xc = mpls_xc_find(in->xc);
+    if (xc)
+      mpls_xc_unregister (xc);
+    else
+      zlog_warn("do_mpls_in_segment_unregister: xc %d does not exist", in->xc);
+
+    if (flag)
+       mpls_out_segment_unregister_by_index (xc->out_index);
+  }
+
+  redistribute_delete_mpls_in_segment (in);
+  LISTNODE_DETACH (&mpls_in_segment_list, &in->global);
+  XFREE (MTYPE_TMP, in);
+
+  return 0;
+}
+
+int
+mpls_in_segment_unregister(struct zmpls_in_segment *in, int flag)
+{
+  struct zmpls_in_segment *old = mpls_in_segment_find (in);
+
+  if (!old)
+    return 1;
+
+  return do_mpls_in_segment_unregister (old, flag);
+}
+
+int
+mpls_in_segment_register(struct zmpls_in_segment *in, int install)
+{
+  struct zmpls_in_segment *new;
+  int ret = 0;
+
+  if (mpls_in_segment_find (in))
+    return 1;
+
+  new = XMALLOC (MTYPE_TMP, sizeof (*new));
+  if (!new)
+    return 1;
+
+  memcpy (new, in, sizeof (*new));
+  new->global.data = new;
+  new->global.next = NULL;
+  new->global.prev = NULL;
+  new->xc = 0;
+
+  if (new->owner != ZEBRA_ROUTE_KERNEL && install)
+    ret = mpls_ctrl_ilm_register(new);
+
+  if (ret) {
+    XFREE (MTYPE_TMP, new);
+    return ret;
+  }
+
+  LISTNODE_ATTACH(&mpls_in_segment_list, &new->global);
+  redistribute_add_mpls_in_segment (new);
+  return 0;
+}
+
+/******************************* cross connect ******************************/
+
+static int mpls_xc_cmp(void *val1, void *val2)
+{
+  struct zmpls_xc *v1 = val1;
+  struct zmpls_xc *v2 = val2;
+
+  if (v1->index > v2->index)
+    return 1;
+  else if (v1->index < v2->index)
+    return -1;
+  return 0;
+}
+
+static int mpls_xc_nextindex = 1;
+
+struct list mpls_xc_list = {
+  .head = NULL,
+  .tail = NULL, 
+  .count = 0,
+  .cmp = mpls_xc_cmp,
+  .del = NULL,
+};
+
+struct zmpls_xc *mpls_xc_find(unsigned int index)
+{
+  struct listnode *node;
+  struct zmpls_xc *xc;
+
+  for (ALL_LIST_ELEMENTS_RO(&mpls_xc_list,node,xc))
+    if (index == xc->index)
+      return xc;
+
+  return NULL;
+}
+
+int
+mpls_xc_register(struct zmpls_xc *xc)
+{
+  struct zmpls_in_segment tmp;
+  struct zmpls_out_segment *out;
+  struct zmpls_in_segment *in;
+  struct zmpls_xc *new;
+
+  tmp.labelspace = xc->in_labelspace;
+  memcpy(&tmp.label, &xc->in_label, sizeof(struct zmpls_label));
+  in = mpls_in_segment_find (&tmp);
+  out = mpls_out_segment_find (xc->out_index);
+
+  if (in->xc)
+    return 1;
+
+  new = XMALLOC (MTYPE_TMP, sizeof (*new));
+  if (!new)
+    return 1;
+
+  new->global.data = new;
+  new->global.next = NULL;
+  new->global.prev = NULL;
+
+  new->in_labelspace = in->labelspace;
+  memcpy(&new->in_label, &in->label, sizeof(struct zmpls_label));
+  new->out_index = out->index;
+  new->index = mpls_xc_nextindex++;
+  in->xc = new->index;
+
+  LISTNODE_ATTACH(&mpls_xc_list, &new->global);
+
+  if (in->owner != ZEBRA_ROUTE_KERNEL)
+  {
+    if (in->installed && out->installed)
+    {
+      mpls_ctrl_xc_register(in, out);
+      new->installed = xc->installed = 1;
+    } else {
+      new->installed = xc->installed = 0;
+    }
+  } else {
+    new->installed = xc->installed = 1;
+  }
+
+  if (new->installed)
+    redistribute_add_mpls_xc (new);
+
+  return 0;
+}
+
+void
+mpls_xc_unregister(struct zmpls_xc *old)
+{
+  struct zmpls_out_segment *out;
+  struct zmpls_in_segment *in;
+  struct zmpls_in_segment tmp;
+
+  tmp.labelspace = old->in_labelspace;
+  memcpy(&tmp.label, &old->in_label, sizeof(struct zmpls_label));
+  in = mpls_in_segment_find(&tmp);
+  out = mpls_out_segment_find(old->out_index);
+
+  if (old->installed)
+    mpls_ctrl_xc_unregister(in, out);
+
+  in->xc = 0;
+
+  redistribute_delete_mpls_xc(old);
+  LISTNODE_DETACH(&mpls_xc_list, &old->global);
+  XFREE (MTYPE_TMP, old);
+}
+
+/*********************************** FTN **********************************/
+
+static int mpls_ftn_cmp(void *val1, void *val2)
+{
+  struct zmpls_xc *v1 = val1;
+  struct zmpls_xc *v2 = val2;
+
+  if (v1->index > v2->index)
+    return 1;
+  else if (v1->index < v2->index)
+    return -1;
+  return 0;
+}
+
+static int mpls_ftn_nextindex = 1;
+
+struct list mpls_ftn_list = {
+  .head = NULL,
+  .tail = NULL, 
+  .count = 0,
+  .cmp = mpls_ftn_cmp,
+  .del = NULL,
+};
+
+struct zmpls_ftn*
+mpls_ftn_find(unsigned int index)
+{
+  struct listnode *node;
+  struct zmpls_ftn *ftn;
+
+  for (ALL_LIST_ELEMENTS_RO(&mpls_ftn_list,node,ftn))
+    if (index == ftn->index)
+      return ftn;
+
+  return NULL;
+}
+
+struct zmpls_ftn*
+mpls_ftn_find_by_prefix(struct prefix* p)
+{
+  struct listnode *node;
+  struct zmpls_ftn *ftn;
+
+  for (ALL_LIST_ELEMENTS_RO(&mpls_ftn_list,node,ftn))
+    if ((ftn->fec.type == ZEBRA_MPLS_FEC_IPV4 ||
+	ftn->fec.type == ZEBRA_MPLS_FEC_IPV6) &&
+	prefix_match(&ftn->fec.u.p, p))
+      return ftn;
+
+  return NULL;
+}
+
+struct zmpls_ftn*
+mpls_ftn_find_by_fec(struct zmpls_fec* fec)
+{
+  struct listnode *node;
+  struct zmpls_ftn *ftn;
+
+  for (ALL_LIST_ELEMENTS_RO(&mpls_ftn_list,node,ftn))
+    if (mpls_fec_match(fec, &ftn->fec))
+      return ftn;
+
+  return NULL;
+}
+
+static struct zmpls_ftn*
+do_mpls_ftn_register(struct zmpls_ftn *ftn)
+{
+  struct zmpls_ftn *new;
+
+  new = XMALLOC (MTYPE_TMP, sizeof (*new));
+  if (!new)
+    return NULL;
+
+  memcpy (new, ftn, sizeof (*new));
+
+  new->global.data = new;
+  new->global.next = NULL;
+  new->global.prev = NULL;
+
+  new->index = mpls_ftn_nextindex++;
+  ftn->index = new->index;
+
+  LISTNODE_ATTACH(&mpls_ftn_list, &new->global);
+  mpls_ctrl_ftn_register(new);
+  redistribute_add_mpls_ftn (new);
+  return new;
+}
+
+void
+mpls_ftn_register_finish(struct zmpls_ftn *ftn, struct route_node *rn,
+  struct rib *rib, struct nexthop *nh)
+{
+  struct nexthop *newnh;
+  struct zmpls_out_segment *out;
+
+  if (CHECK_FLAG (rib->flags, ZEBRA_FLAG_SELECTED))
+    {
+      rib_uninstall_kernel (rn, rib);
+      UNSET_FLAG (rib->flags, ZEBRA_FLAG_SELECTED);
+    }
+
+  SET_FLAG (nh->flags, NEXTHOP_FLAG_IGNORE);
+  out = mpls_out_segment_find(ftn->out_index);
+  newnh = nexthop_zapi_nexthop_add(rib, &out->nh);
+  newnh->tied = nh;
+  nh->tied = newnh;
+
+  SET_FLAG (rib->flags, ZEBRA_FLAG_CHANGED_MPLS);
+  rib_queue_add (&zebrad, rn);
+}
+
+int
+mpls_ftn_register(struct zmpls_ftn *ftn, int modify)
+{
+  struct zmpls_out_segment *out;
+  struct zmpls_ftn *new;
+  if (!(out = mpls_out_segment_find(ftn->out_index)))
+    {
+      zlog_warn("mpls_ftn_register: unable to find outsegment with index %d",
+        ftn->out_index);
+      return 1;
+    }
+
+  if (!(new = do_mpls_ftn_register(ftn)))
+    return 1;
+  
+  switch (ftn->fec.type)
+  {
+    case ZEBRA_MPLS_FEC_IPV4:
+    case ZEBRA_MPLS_FEC_IPV6:
+    {  
+      struct route_node *rn = NULL;
+      struct nexthop *nh = NULL;
+      struct rib *rib = NULL;
+      struct nexthop nh_in;
+
+      zapi_nexthop2nexthop(&out->nh, &nh_in);
+
+      if (modify)
+      {
+        rib_find_nexthop(ftn->fec.owner, &ftn->fec.u.p, &nh_in,&rn,&rib,&nh);
+        if (rn)
+	{
+          mpls_ftn_register_finish(ftn, rn, rib, nh);
+          route_unlock_node(rn);
+	} else {
+	  char str[33];
+	  prefix2str(&ftn->fec.u.p, str, sizeof(str));
+          zlog_warn("mpls_ftn_register: unable to find FEC %s", str);
+        }
+      } else {
+        zlog_warn("mpls_ftn_register: modify flag not set");
+      }
+      break;
+    }
+    default:
+      assert(0);
+      break;
+  }
+  return 0;
+}
+
+static void
+do_mpls_ftn_unregister(struct zmpls_ftn *ftn)
+{
+  mpls_ctrl_ftn_unregister(ftn);
+
+  redistribute_delete_mpls_ftn(ftn);
+  LISTNODE_DETACH(&mpls_ftn_list, &ftn->global);
+  XFREE (MTYPE_TMP, ftn);
+}
+
+void
+mpls_ftn_unregister_finish(struct zmpls_ftn *ftn, struct route_node *rn,
+  struct rib *rib, struct nexthop *nh)
+{
+  if (CHECK_FLAG (rib->flags, ZEBRA_FLAG_SELECTED))
+    {
+      rib_uninstall_kernel (rn, rib);
+      UNSET_FLAG (rib->flags, ZEBRA_FLAG_SELECTED);
+    }
+
+  if (nh->tied)
+    {
+      if (CHECK_FLAG (nh->flags, NEXTHOP_FLAG_IGNORE))
+        {
+	  /* we've been handed the original non-mpls nexthop */
+          UNSET_FLAG (nh->flags, NEXTHOP_FLAG_IGNORE);
+          nexthop_delete (rib, nh->tied);
+          nexthop_free (nh->tied);
+          nh->tied = NULL;
+        }
+      else
+        {
+	  /* we've been handed the mpls nexthop */
+          UNSET_FLAG (nh->tied->flags, NEXTHOP_FLAG_IGNORE);
+          nh->tied->tied = NULL;
+          nexthop_delete (rib, nh);
+          nexthop_free (nh);
+        }
+  }
+
+  SET_FLAG (rib->flags, ZEBRA_FLAG_CHANGED_MPLS);
+  rib_queue_add (&zebrad, rn);
+}
+
+void
+mpls_ftn_unregister(struct zmpls_ftn *ftn, int modify)
+{
+  struct zmpls_out_segment *out;
+  if (!(out = mpls_out_segment_find(ftn->out_index)))
+    return;
+
+  switch (ftn->fec.type)
+  {
+    case ZEBRA_MPLS_FEC_IPV4:
+    case ZEBRA_MPLS_FEC_IPV6:
+    {
+      struct route_node *rn = NULL;
+      struct nexthop *nh = NULL;
+      struct rib *rib = NULL;
+      struct nexthop nh_in;
+
+      zapi_nexthop2nexthop(&out->nh, &nh_in);
+
+      if (modify)
+      {
+        rib_find_nexthop(ftn->fec.owner, &ftn->fec.u.p, &nh_in,&rn,&rib,&nh);
+	if (rn)
+	{
+	  mpls_ftn_unregister_finish(ftn, rn, rib, nh);
+	  route_unlock_node(rn);
+	}
+      }
+      break;
+    }
+    default:
+      assert(0);
+      break;
+  }
+  do_mpls_ftn_unregister(ftn);
+}
+
+void
+mpls_init (void)
+{
+}
+
+void
+mpls_close (void)
+{
+  struct listnode *node;
+
+  while ((node = listhead (&mpls_in_segment_list)))
+    do_mpls_in_segment_unregister ((struct zmpls_in_segment*)listgetdata (node), 0);
+
+  while ((node = listhead (&mpls_out_segment_list)))
+    do_mpls_out_segment_unregister ((struct zmpls_out_segment*)listgetdata (node));
+}
+
+#endif /* HAVE_MPLS */
diff -Naur quagga-0.99.10/zebra/mpls_lib.h quagga-mpls/zebra/mpls_lib.h
--- quagga-0.99.10/zebra/mpls_lib.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/mpls_lib.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,206 @@
+/*
+ * MPLS Label Information Base for zebra daemon.
+ *
+ * Copyright (C) 2004 James R. Leu 
+ *
+ * This file is part of Quagga routing suite.
+ *
+ * Quagga is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2, or (at your option) any
+ * later version.
+ *
+ * Quagga is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU Zebra; see the file COPYING.  If not, write to the Free
+ * Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
+ * 02111-1307, USA.
+ */
+
+#ifndef _ZEBRA_MPLS_LIB_H
+#define _ZEBRA_MPLS_LIB_H
+
+#ifdef LINUX_MPLS
+#include <linux/mpls.h>
+#endif
+
+#include "zclient.h"
+#include "table.h"
+#include "vty.h"
+#include "zebra/rib.h"
+
+struct zmpls_in_segment
+{
+  struct listnode global;
+  u_char installed;
+  u_char owner;
+  u_char labelspace;
+  u_short protocol;
+  u_int xc;
+  struct zmpls_label label;
+  u_char pop;
+};
+
+struct zmpls_out_segment
+{
+  struct listnode global;
+  u_char installed;
+  u_char owner;
+  struct zapi_nexthop nh;
+  u_int index;
+  u_int out_key;
+};
+
+struct zmpls_xc
+{
+  struct listnode global;
+  u_char installed;
+  u_char owner;
+  u_int index;
+  u_char in_labelspace;
+  struct zmpls_label in_label;
+  u_int out_index;
+};
+
+struct zmpls_ftn
+{
+  struct listnode global;
+  u_char installed;
+  u_char owner;
+  u_int index;
+  struct zmpls_fec fec;
+  u_int out_index;
+};
+
+extern struct list mpls_xc_list;
+extern struct list mpls_ftn_list;
+extern struct list mpls_in_segment_list;
+extern struct list mpls_out_segment_list;
+
+extern int
+mpls_nexthop_ready(struct zapi_nexthop *nh);
+
+extern int
+mpls_in_segment_match(struct zmpls_in_segment *a, struct zmpls_in_segment *b);
+
+extern struct zmpls_in_segment*
+mpls_in_segment_find(struct zmpls_in_segment *in);
+
+extern int
+mpls_in_segment_register(struct zmpls_in_segment *in, int install);
+
+extern int
+mpls_in_segment_unregister(struct zmpls_in_segment *in, int flag);
+
+extern int
+mpls_out_segment_register(struct zmpls_out_segment *out);
+
+extern int
+mpls_out_segment_unregister(struct zmpls_out_segment *out);
+
+extern int
+mpls_out_segment_unregister_by_index(unsigned int index);
+
+extern int
+mpls_labelspace_register(int labelspace);
+
+extern int
+mpls_labelspace_unregister(int labelspace);
+
+extern int
+mpls_labelspace_is_registered(int labelspace);
+
+extern struct zmpls_out_segment*
+mpls_out_segment_find(unsigned int index);
+
+struct zmpls_out_segment*
+mpls_out_segment_find_by_out_key(unsigned int key);
+
+extern unsigned int
+mpls_out_segment_find_index_by_nhlfe (struct zmpls_out_segment *out);
+
+extern unsigned int
+mpls_out_segment_find_index_by_nexthop(struct zapi_nexthop *nh);
+
+extern struct zmpls_xc* mpls_xc_find (unsigned int);
+
+extern int
+mpls_xc_register (struct zmpls_xc *xc);
+
+extern void
+mpls_xc_unregister (struct zmpls_xc *xc);
+
+extern struct zmpls_ftn* mpls_ftn_find (unsigned int);
+
+extern struct zmpls_ftn*
+mpls_ftn_find_by_fec(struct zmpls_fec* fec);
+
+extern int
+mpls_ftn_register (struct zmpls_ftn *ftn, int modify);
+
+extern void
+mpls_ftn_register_finish(struct zmpls_ftn *ftn, struct route_node *rn,
+  struct rib *rib, struct nexthop *nh);
+
+extern void
+mpls_ftn_unregister (struct zmpls_ftn *ftn, int modify);
+
+extern void
+mpls_ftn_unregister_finish(struct zmpls_ftn *ftn, struct route_node *rn,
+  struct rib *rib, struct nexthop *nh);
+
+extern int
+mpls_ctrl_init(void);
+
+extern int
+mpls_ctrl_show_hardware(struct vty *vty);
+
+extern int
+mpls_ctrl_nhlfe_unregister(struct zmpls_out_segment *old);
+
+extern int
+mpls_ctrl_nhlfe_register(struct zmpls_out_segment *new);
+
+extern int
+mpls_ctrl_ilm_unregister(struct zmpls_in_segment *old);
+
+extern int
+mpls_ctrl_ilm_register(struct zmpls_in_segment *new);
+
+extern int
+mpls_ctrl_xc_register(struct zmpls_in_segment *in,
+    struct zmpls_out_segment *out);
+
+extern int
+mpls_ctrl_xc_unregister(struct zmpls_in_segment *in,
+    struct zmpls_out_segment *out);
+
+extern int
+mpls_ctrl_ftn_register(struct zmpls_ftn *ftn);
+
+extern int
+mpls_ctrl_ftn_unregister(struct zmpls_ftn *ftn);
+
+extern int
+mpls_ctrl_set_interface_labelspace(struct interface *ifp, int labelspace);
+
+extern int
+mpls_ctrl_tunnel_register(struct interface *ifp, int update);
+
+extern int
+mpls_ctrl_tunnel_unregister(struct interface *ifp);
+
+extern int
+mpls_ctrl_read(void);
+
+extern void
+mpls_init(void);
+
+extern void
+mpls_close(void);
+
+#endif /* _ZEBRA_MPLS_VTY_H */
diff -Naur quagga-0.99.10/zebra/mpls_netlink.c quagga-mpls/zebra/mpls_netlink.c
--- quagga-0.99.10/zebra/mpls_netlink.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/mpls_netlink.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,601 @@
+#include <linux/mpls.h>
+#include <linux/if_ether.h>
+#include "zebra.h"
+#include "debug.h"
+#include "mpls_lib.h"
+#include "interface.h"
+#include "log.h"
+#include "command.h"
+#include "zebra/netlink.h"
+
+#ifndef AF_MPLS
+#define AF_MPLS 29
+#endif
+
+#ifndef NETLINK_GENERIC
+#define NETLINK_GENERIC 16
+#endif
+
+/* Socket interface to kernel */
+struct nlsock
+  mpls_netlink      = {-1,0,{0},"mpls-netlink-listen",0},/* kernel messages */
+  mpls_netlink_cmd  = {-1,0,{0},"mpls-netlink-cmd",1},   /* command channel */
+  mpls_netlink_nhlfe= {-1,0,{0},"mpls-netlink-nhlfe",1}; /* nhlfe adds */
+
+int
+mpls_ctrl_show_hardware(struct vty *vty)
+{
+  vty_out(vty, "MPLS-Linux: %d.%d%d%d netlink control%s",
+    (MPLS_LINUX_VERSION >> 24) & 0xFF,
+    (MPLS_LINUX_VERSION >> 16) & 0xFF,
+    (MPLS_LINUX_VERSION >> 8) & 0xFF,
+    (MPLS_LINUX_VERSION) & 0xFF, VTY_NEWLINE);
+  return CMD_SUCCESS;
+}
+
+int
+mpls_ctrl_nhlfe_unregister(struct zmpls_out_segment *old)
+{
+  struct genlmsghdr *ghdr;
+  struct
+  {
+    struct nlmsghdr n;
+    char buf[4096];
+  } req;
+  struct mpls_out_label_req mol;
+
+  memset (&req, 0, sizeof(req));
+  memset (&mol, 0, sizeof(mol));
+
+  req.n.nlmsg_len = NLMSG_LENGTH(GENL_HDRLEN);
+  req.n.nlmsg_flags = NLM_F_CREATE|NLM_F_REQUEST;
+  req.n.nlmsg_type = AF_MPLS;
+
+  ghdr = NLMSG_DATA(&req.n);
+  ghdr->cmd = MPLS_CMD_DELNHLFE;
+
+  mol.mol_label.ml_type = MPLS_LABEL_KEY;
+  mol.mol_label.u.ml_key = old->out_key;
+
+  addattr_l(&req.n, sizeof(req), MPLS_ATTR_NHLFE, &mol, sizeof(mol));
+
+  return netlink_talk (&req.n, &mpls_netlink_cmd, NULL, 0);
+}
+
+int
+mpls_ctrl_nhlfe_register(struct zmpls_out_segment *new)
+{
+  struct genlmsghdr *ghdr;
+  struct
+  {
+    struct nlmsghdr n;
+    char buf[4096];
+  } req, res;
+
+  struct mpls_out_label_req mol, *molp;
+  struct mpls_instr_req mir;
+  struct rtattr *tb[MPLS_ATTR_MAX + 1];
+  struct rtattr *attrs;
+  int result;
+
+  memset (&req, 0, sizeof(req));
+  memset (&res, 0, sizeof(res));
+  memset (&mol, 0, sizeof(mol));
+  memset (&mir, 0, sizeof(mir));
+
+  req.n.nlmsg_len = NLMSG_LENGTH(GENL_HDRLEN);
+  req.n.nlmsg_flags = NLM_F_CREATE|NLM_F_REQUEST;
+  req.n.nlmsg_type = AF_MPLS;
+
+  ghdr = NLMSG_DATA(&req.n);
+  ghdr->cmd = MPLS_CMD_NEWNHLFE;
+
+  mol.mol_label.ml_type = MPLS_LABEL_KEY;
+  mol.mol_label.u.ml_key = 0;
+  mol.mol_change_flag |= MPLS_CHANGE_INSTR;
+
+  mir.mir_direction = MPLS_OUT;
+  memcpy(&mir.mir_label,&mol.mol_label,sizeof(struct mpls_label));
+
+  mir.mir_instr[0].mir_opcode = MPLS_OP_PUSH;
+  mir.mir_instr[0].mir_data.push.ml_type = MPLS_LABEL_GEN;
+  mir.mir_instr[0].mir_data.push.u.ml_gen = new->nh.mpls.u.gen;
+
+  mir.mir_instr[1].mir_opcode = MPLS_OP_SET;
+
+  if (CHECK_FLAG (new->nh.type, ZEBRA_NEXTHOP_IFNAME))
+    {
+      struct interface *ifp = if_lookup_by_name (new->nh.intf.name);
+      mir.mir_instr[1].mir_data.set.mni_if = ifp ? ifp->ifindex : 0;
+    }
+
+  if (CHECK_FLAG (new->nh.type, ZEBRA_NEXTHOP_IPV4))
+    {
+      struct sockaddr_in addr;
+      addr.sin_family = AF_INET;
+      addr.sin_addr = new->nh.gw.ipv4;
+      memcpy(&mir.mir_instr[1].mir_data.set.mni_addr, &addr, sizeof(addr));
+    }
+  else if (CHECK_FLAG (new->nh.type, ZEBRA_NEXTHOP_IPV6))
+    {
+      struct sockaddr_in6 addr;
+      addr.sin6_family = AF_INET6;
+      addr.sin6_addr = new->nh.gw.ipv6;
+      memcpy(&mir.mir_instr[1].mir_data.set.mni_addr, &addr, sizeof(addr));
+    }
+  else
+    {
+      assert (0);
+    }
+
+  mir.mir_instr_length = 2;
+
+  addattr_l(&req.n, sizeof(req), MPLS_ATTR_NHLFE, &mol, sizeof(mol));
+  addattr_l(&req.n, sizeof(req), MPLS_ATTR_INSTR, &mir, sizeof(mir));
+
+  result = netlink_talk (&req.n, &mpls_netlink_nhlfe, (void*)&res, sizeof(res));
+
+  ghdr = NLMSG_DATA(&res.n);
+  attrs = (struct rtattr *) ((char *) ghdr + GENL_HDRLEN);
+  netlink_parse_rtattr(tb, MPLS_ATTR_MAX, attrs,
+    res.n.nlmsg_len - NLMSG_LENGTH(GENL_HDRLEN));
+  molp = RTA_DATA(tb[MPLS_ATTR_NHLFE]);
+
+  new->out_key = molp->mol_label.u.ml_key;
+  zlog(NULL, LOG_ERR, "mpls_ctrl_nhlfe_register(): "
+             "NHLFE 0x%08x", new->out_key);
+  return result;
+}
+
+static int do_ilm(int cmd, struct zmpls_in_segment *ilm)
+{
+  struct genlmsghdr *ghdr;
+  struct
+  {
+    struct nlmsghdr n;
+    char buf[4096];
+  } req;
+  struct mpls_in_label_req mil;
+
+  memset (&req, 0, sizeof(req));
+  memset (&mil, 0, sizeof(mil));
+
+  req.n.nlmsg_len = NLMSG_LENGTH(GENL_HDRLEN);
+  req.n.nlmsg_flags = NLM_F_CREATE|NLM_F_REQUEST;
+  req.n.nlmsg_type = AF_MPLS;
+
+  ghdr = NLMSG_DATA(&req.n);
+  ghdr->cmd = cmd;
+
+  mil.mil_proto = AF_INET;
+  mil.mil_label.ml_type = MPLS_LABEL_GEN;
+  mil.mil_label.u.ml_gen = ilm->label.u.gen;
+  mil.mil_label.ml_index = ilm->labelspace;
+
+  addattr_l(&req.n, sizeof(req), MPLS_ATTR_ILM, &mil, sizeof(mil));
+
+  return netlink_talk (&req.n, &mpls_netlink_cmd, NULL, 0);
+}
+
+int
+mpls_ctrl_ilm_unregister(struct zmpls_in_segment *old)
+{
+  return do_ilm(MPLS_CMD_DELILM, old);
+}
+
+int
+mpls_ctrl_ilm_register(struct zmpls_in_segment *new)
+{
+  return do_ilm(MPLS_CMD_NEWILM, new);
+}
+
+static int do_xc(int cmd, struct zmpls_in_segment *in,
+  struct zmpls_out_segment *out)
+{
+  struct genlmsghdr *ghdr;
+  struct
+  {
+    struct nlmsghdr n;
+    char buf[4096];
+  } req;
+  struct mpls_xconnect_req mx;
+
+  memset (&req, 0, sizeof(req));
+  memset (&mx, 0, sizeof(mx));
+
+  req.n.nlmsg_len = NLMSG_LENGTH(GENL_HDRLEN);
+  req.n.nlmsg_flags = NLM_F_CREATE|NLM_F_REQUEST;
+  req.n.nlmsg_type = AF_MPLS;
+
+  ghdr = NLMSG_DATA(&req.n);
+  ghdr->cmd = cmd;
+
+  mx.mx_in.ml_type = MPLS_LABEL_GEN;
+  mx.mx_in.u.ml_gen = in->label.u.gen;
+  mx.mx_in.ml_index = in->labelspace;
+  mx.mx_out.ml_type = MPLS_LABEL_KEY;
+  mx.mx_out.u.ml_key = out->out_key;
+
+  addattr_l(&req.n, sizeof(req), MPLS_ATTR_XC, &mx, sizeof(mx));
+
+  return netlink_talk (&req.n, &mpls_netlink_cmd, NULL, 0);
+}
+
+int mpls_ctrl_xc_register(struct zmpls_in_segment *in,
+  struct zmpls_out_segment *out)
+{
+  return do_xc(MPLS_CMD_NEWXC, in, out);
+}
+
+int mpls_ctrl_xc_unregister(struct zmpls_in_segment *in,
+  struct zmpls_out_segment *out)
+{
+  return do_xc(MPLS_CMD_DELXC, in, out);
+}
+
+int mpls_ctrl_ftn_register(struct zmpls_ftn *ftn)
+{
+  return 0;
+}
+
+int mpls_ctrl_ftn_unregister(struct zmpls_ftn *ftn)
+{
+  return 0;
+}
+
+int mpls_ctrl_tunnel_register(struct interface *ifp, int update)
+{
+#if 0
+  struct zebra_if *if_data = ifp->info;
+  struct
+  {
+    struct nlmsghdr n;
+    struct mpls_tunnel_req  mt;
+    char buf[1024];
+  } req;
+
+  memset (&req, 0, sizeof(req));
+  req.n.nlmsg_len = NLMSG_LENGTH (sizeof (struct mpls_tunnel_req));
+  req.n.nlmsg_flags = NLM_F_REQUEST;
+  if (update)
+  {
+    req.n.nlmsg_flags |= NLM_F_APPEND;
+    req.mt.mt_nhlfe_key = (int)if_data->ops->info;
+  }
+  else
+  {
+    req.n.nlmsg_flags |= NLM_F_CREATE;
+  }
+
+  req.n.nlmsg_type = MPLS_RTM_ADDTUNNEL;
+
+  strncpy(req.mt.mt_ifname, ifp->name, IFNAMSIZ);
+
+  return netlink_talk (&req.n, &netlink_cmd, NULL, 0);
+#else
+  return 0;
+#endif
+}
+
+int mpls_ctrl_tunnel_unregister(struct interface *ifp)
+{
+#if 0
+  struct genlmsghdr *ghdr;
+  struct
+  {
+    struct nlmsghdr n;
+    char buf[1024];
+  } req;
+  struct mpls_labelspace_req      ls;
+
+  memset (&req, 0, sizeof(req));
+  memset (&ls, 0, sizeof(ls));
+
+  req.n.nlmsg_len = NLMSG_LENGTH(GENL_HDRLEN);
+  req.n.nlmsg_flags = NLM_F_CREATE|NLM_F_REQUEST;
+  req.n.nlmsg_type = AF_MPLS;
+
+  ghdr = NLMSG_DATA(&req.n);
+  ghdr->cmd = MPLS_CMD_SETLABELSPACE;
+  struct
+  {
+    struct nlmsghdr n;
+    struct mpls_tunnel_req  mt;
+    char buf[1024];
+  } req;
+
+  memset (&req, 0, sizeof(req));
+  req.n.nlmsg_len = NLMSG_LENGTH (sizeof (struct mpls_tunnel_req));
+  req.n.nlmsg_flags = NLM_F_CREATE|NLM_F_REQUEST;
+  req.n.nlmsg_type = MPLS_RTM_DELTUNNEL;
+
+  req.mt.mt_nhlfe_key = 0;
+  strncpy(req.mt.mt_ifname, ifp->name, IFNAMSIZ);
+
+  return netlink_talk (&req.n, &netlink_cmd, NULL, 0);
+#else
+  return 0;
+#endif
+}
+
+int mpls_ctrl_set_interface_labelspace(struct interface *ifp, int labelspace)
+{
+  struct genlmsghdr *ghdr;
+  struct
+  {
+    struct nlmsghdr n;
+    char buf[1024];
+  } req;
+  struct mpls_labelspace_req      ls;
+
+  memset (&req, 0, sizeof(req));
+  memset (&ls, 0, sizeof(ls));
+
+  req.n.nlmsg_len = NLMSG_LENGTH(GENL_HDRLEN);
+  req.n.nlmsg_flags = NLM_F_CREATE|NLM_F_REQUEST;
+  req.n.nlmsg_type = AF_MPLS;
+
+  ghdr = NLMSG_DATA(&req.n);
+  ghdr->cmd = MPLS_CMD_SETLABELSPACE;
+
+  ls.mls_labelspace = (labelspace < 0) ? -1 : labelspace;
+  ls.mls_ifindex    = ifp->ifindex;
+
+  addattr_l(&req.n, sizeof(req), MPLS_ATTR_LABELSPACE, &ls, sizeof(ls));
+
+  return netlink_talk (&req.n, &mpls_netlink_cmd, NULL, 0);
+}
+
+static int
+mpls_netlink_information_fetch (struct nlsock *nl, struct sockaddr_nl *snl, struct nlmsghdr *h)
+{
+  struct rtattr *tb[MPLS_ATTR_MAX + 1];
+  struct genlmsghdr *ghdr = NLMSG_DATA(h);
+  int len = h->nlmsg_len;
+  struct rtattr *attrs;
+
+  /* skip unsolicited messages originating from command socket */
+  if (!nl->cmd)
+    {
+      struct nlsock *tmp = NULL;
+
+      if (h->nlmsg_pid == mpls_netlink_cmd.snl.nl_pid)
+        tmp = &mpls_netlink_cmd;
+      else if (h->nlmsg_pid == mpls_netlink_nhlfe.snl.nl_pid)
+        tmp = &mpls_netlink_nhlfe;
+
+      if (tmp)
+        {
+          if (IS_ZEBRA_DEBUG_KERNEL)
+            zlog_debug ("netlink_parse_info: %s packet comes from %s",
+                        tmp->name, nl->name);
+          return 0;
+        }
+    }
+
+  if (h->nlmsg_type != AF_MPLS) {
+      zlog_warn ("Invalid mpls-netlink nlmsg_type %d\n", h->nlmsg_type);
+      return 0;
+  }
+
+  len -= NLMSG_LENGTH(GENL_HDRLEN);
+  if (len < 0) {
+      zlog_warn ("Invalid mpls-netlink nlmsg length %d\n", len);
+      return 0;
+  }
+
+  attrs = (struct rtattr *) ((char *) ghdr + GENL_HDRLEN);
+  netlink_parse_rtattr(tb, MPLS_ATTR_MAX, attrs, len);
+
+  switch (ghdr->cmd)
+    {
+    case MPLS_CMD_NEWNHLFE:
+    case MPLS_CMD_DELNHLFE:
+      {
+        struct mpls_out_label_req *molr = RTA_DATA(tb[MPLS_ATTR_NHLFE]);
+        struct mpls_instr_req *mir = RTA_DATA(tb[MPLS_ATTR_INSTR]);
+        struct zmpls_out_segment out;
+        int i;
+
+        out.owner = ZEBRA_ROUTE_KERNEL;
+        out.out_key = molr->mol_label.u.ml_key;
+
+        for (i = 0;i < mir->mir_instr_length;i++)
+        {
+	  if (mir->mir_instr[i].mir_opcode == MPLS_OP_PUSH)
+	  {
+	    out.nh.mpls.u.gen = mir->mir_instr[i].mir_push.u.ml_gen;
+	    out.nh.mpls.type = ZEBRA_MPLS_LABEL_GEN;
+	  }
+
+	  if (mir->mir_instr[i].mir_opcode == MPLS_OP_SET)
+	  {
+	    struct interface *ifp;
+	    struct sockaddr_in *saddr;
+
+	    saddr = (struct sockaddr_in*)&mir->mir_instr[i].mir_set.mni_addr;
+	    ifp = if_lookup_by_index(mir->mir_instr[i].mir_set.mni_if);
+	    strncpy(out.nh.intf.name, ifp->name, IFNAMSIZ);
+	    out.nh.gw.ipv4.s_addr = saddr->sin_addr.s_addr;
+	    SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_IPV4);
+	    SET_FLAG (out.nh.type, ZEBRA_NEXTHOP_IFNAME);
+	  }
+        }
+        if (ghdr->cmd == MPLS_CMD_NEWNHLFE) {
+	   if (mpls_out_segment_find_by_out_key(out.out_key))
+	      return 0;
+	   if (mir->mir_instr_length == 2)
+              mpls_out_segment_register(&out);
+        } else {
+	   if (!mpls_out_segment_find_by_out_key(out.out_key))
+	      return 0;
+           mpls_out_segment_unregister(&out);
+        }
+        break;
+      }
+    case MPLS_CMD_NEWILM:
+    case MPLS_CMD_DELILM:
+      {
+        struct mpls_in_label_req *milr = RTA_DATA(tb[MPLS_ATTR_ILM]);
+        struct zmpls_in_segment in;
+
+        in.labelspace = milr->mil_label.ml_index;
+        in.label.type = ZEBRA_MPLS_LABEL_GEN;
+        in.label.u.gen = milr->mil_label.u.ml_gen;
+        in.protocol = milr->mil_proto;
+        in.owner = ZEBRA_ROUTE_KERNEL;
+        in.pop = 1;
+
+        if (ghdr->cmd == MPLS_CMD_NEWILM) {
+	  if (mpls_in_segment_find(&in))
+	    return 0;
+          mpls_in_segment_register(&in, 0);
+        } else {
+	  if (!mpls_in_segment_find(&in))
+	    return 0;
+          mpls_in_segment_unregister(&in, 0);
+        }
+        break;
+      }
+    case MPLS_CMD_NEWXC:
+    case MPLS_CMD_DELXC:
+      {
+        struct mpls_xconnect_req *mxr = RTA_DATA(tb[MPLS_ATTR_XC]);
+        struct zmpls_out_segment *out;
+        struct zmpls_in_segment tmp;
+        struct zmpls_in_segment *in;
+        struct zmpls_xc xc;
+
+        tmp.labelspace = mxr->mx_in.ml_index;
+        tmp.label.type = ZEBRA_MPLS_LABEL_GEN;
+        tmp.label.u.gen = mxr->mx_in.u.ml_gen;
+
+        out = mpls_out_segment_find_by_out_key(mxr->mx_out.u.ml_key);
+        in = mpls_in_segment_find (&tmp);
+
+        xc.in_labelspace = in->labelspace;
+        memcpy(&xc.in_label, &in->label, sizeof(struct zmpls_label));
+        xc.out_index = out->index;
+
+        if (ghdr->cmd == MPLS_CMD_NEWXC) {
+	  if (in->xc)
+	    return 0;
+          mpls_xc_register(&xc);
+        } else {
+	  if (!in->xc)
+	    return 0;
+          mpls_xc_unregister(&xc);
+        }
+        break;
+      }
+    case MPLS_CMD_SETLABELSPACE:
+      {
+        struct mpls_labelspace_req *mlr = RTA_DATA(tb[MPLS_ATTR_LABELSPACE]);
+        struct interface *ifp;
+
+        ifp = if_lookup_by_index(mlr->mls_ifindex);
+        if (ifp)
+	  ifp->mpls_labelspace = mlr->mls_labelspace;
+
+        break;
+      }
+    default:
+      zlog_warn ("Unknown mpls-netlink cmd %d\n", ghdr->cmd);
+      break;
+    }
+  return 0;
+}
+
+void
+mpls_read (void)
+{
+#if 0
+  int ret;
+  int flags;
+  int snb_ret;
+
+  /* 
+   * Change netlink socket flags to blocking to ensure we get 
+   * a reply via nelink_parse_info
+   */
+  snb_ret = set_netlink_blocking (&mpls_netlink_cmd, &flags);
+  if (snb_ret < 0)
+    zlog (NULL, LOG_WARNING,
+          "%s:%i Warning: Could not set netlink socket to blocking.",
+          __FUNCTION__, __LINE__);
+
+  /* Get NHLFE entries. */
+  ret = genetlink_request (AF_MPLS, MPLS_CMD_GETNHLFE, &mpls_netlink_cmd);
+  if (ret < 0)
+    return;
+  ret = netlink_parse_info (mpls_netlink_information_fetch,
+	&mpls_netlink_cmd, NULL, 0);
+  if (ret < 0)
+    return;
+
+  /* Get ILM entries */
+  ret = genetlink_request (AF_MPLS, MPLS_CMD_GETILM, &mpls_netlink_cmd);
+  if (ret < 0)
+    return;
+  ret = netlink_parse_info (mpls_netlink_information_fetch,
+	&mpls_netlink_cmd, NULL, 0);
+  if (ret < 0)
+    return;
+
+  /* Get LABELSPACE entries */
+  ret = netlink_request (AF_MPLS, MPLS_CMD_GETLABELSPACE, &mpls_netlink_cmd);
+  if (ret < 0)
+    return;
+  ret = netlink_parse_info (mpls_netlink_information_fetch,
+	&mpls_netlink_cmd, NULL, 0);
+  if (ret < 0)
+    return;
+
+  /* Get XC entries */
+  ret = netlink_request (AF_MPLS, MPLS_CMD_GETXC, &mpls_netlink_cmd);
+  if (ret < 0)
+    return;
+  ret = netlink_parse_info (mpls_netlink_information_fetch,
+	&mpls_netlink_cmd, NULL, 0);
+  if (ret < 0)
+    return;
+
+  /* restore flags */
+  if (snb_ret == 0)
+    set_netlink_nonblocking (&mpls_netlink_cmd, &flags);
+#endif
+}
+
+extern struct thread_master *master;
+
+/* Kernel route reflection. */
+static int
+mpls_kernel_read (struct thread *thread)
+{
+  int ret;
+  int sock;
+
+  sock = THREAD_FD (thread);
+  ret = netlink_parse_info (mpls_netlink_information_fetch,
+	&mpls_netlink, NULL, 0);
+  thread_add_read (zebrad.master, mpls_kernel_read, NULL, mpls_netlink.sock);
+
+  return 0;
+}
+
+/* Exported interface function.  This function simply calls
+   netlink_socket (). */
+void
+mpls_kernel_init ()
+{
+  unsigned long groups;
+
+  groups = MPLS_GRP_NHLFE | MPLS_GRP_ILM | MPLS_GRP_XC | MPLS_GRP_LABELSPACE;
+  netlink_socket (&mpls_netlink, NETLINK_GENERIC, groups);
+  netlink_socket (&mpls_netlink_cmd, NETLINK_GENERIC, 0);
+  netlink_socket (&mpls_netlink_nhlfe, NETLINK_GENERIC, MPLS_GRP_NHLFE);
+
+  /* Register kernel socket. */
+  if (mpls_netlink.sock > 0)
+    thread_add_read (zebrad.master, mpls_kernel_read, NULL, mpls_netlink.sock);
+}
diff -Naur quagga-0.99.10/zebra/mpls_null.c quagga-mpls/zebra/mpls_null.c
--- quagga-0.99.10/zebra/mpls_null.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/mpls_null.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,82 @@
+#include <zebra.h>
+#include "command.h"
+#include "mpls_lib.h"
+
+void
+mpls_kernel_init()
+{
+}
+
+int
+mpls_ctrl_show_hardware(struct vty *vty)
+{
+  vty_out(vty, "MPLS Null driver%s", VTY_NEWLINE);
+  return CMD_SUCCESS;
+}
+
+
+int
+mpls_ctrl_nhlfe_unregister(struct zmpls_out_segment *old)
+{
+  return 0;
+}
+
+int
+mpls_ctrl_nhlfe_register(struct zmpls_out_segment *new)
+{
+  return 0;
+}
+
+int
+mpls_ctrl_ilm_unregister(struct zmpls_in_segment *old)
+{
+  return 0;
+}
+
+int
+mpls_ctrl_ilm_register(struct zmpls_in_segment *new)
+{
+  return 0;
+}
+
+int mpls_ctrl_set_interface_labelspace(struct interface *ifp, int labelspace)
+{
+  return 0;
+}
+
+int mpls_ctrl_xc_register(struct zmpls_in_segment *in,
+  struct zmpls_out_segment *out)
+{
+  return 0;
+}
+
+int mpls_ctrl_xc_unregister(struct zmpls_in_segment *in,
+  struct zmpls_out_segment *out)
+{
+  return 0;
+}
+
+int mpls_ctrl_ftn_register(struct zmpls_ftn *ftn)
+{
+  return 0;
+}
+
+int mpls_ctrl_ftn_unregister(struct zmpls_ftn *ftn)
+{
+  return 0;
+}
+
+int mpls_ctrl_tunnel_register(struct interface *ifp, int update)
+{
+  return 0;
+}
+
+int mpls_ctrl_tunnel_unregister(struct interface *ifp)
+{
+  return 0;
+}
+
+int mpls_read(void)
+{
+  return 0;
+}
diff -Naur quagga-0.99.10/zebra/mpls_vty.c quagga-mpls/zebra/mpls_vty.c
--- quagga-0.99.10/zebra/mpls_vty.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/mpls_vty.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,738 @@
+/*
+ * MPLS CLI for zebra daemon.
+ *
+ * Copyright (C) 2004 James R. Leu 
+ *
+ * This file is part of Quagga routing suite.
+ *
+ * Quagga is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2, or (at your option) any
+ * later version.
+ *
+ * Quagga is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU Zebra; see the file COPYING.  If not, write to the Free
+ * Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
+ * 02111-1307, USA.
+ */
+
+#include <zebra.h>
+
+#ifdef HAVE_MPLS
+
+#include "zclient.h"
+#include "vty.h"
+#include "linklist.h"
+#include "memory.h"
+#include "command.h"
+#include "mpls_lib.h"
+#include "if.h"
+#include "connected.h"
+#include "interface.h"
+#include "ioctl.h"
+#include "zserv.h"
+#include "router-id.h"
+#include "mpls_vty.h"
+
+static
+int label_parse(struct vty *vty, const char **argv, struct zmpls_label *label)
+{
+  if (!strncmp(argv[0], "gen", 3))
+  {
+    label->type = ZEBRA_MPLS_LABEL_GEN;
+  }
+  else if (!strncmp(argv[0], "atm", 3))
+  {
+    label->type = ZEBRA_MPLS_LABEL_ATM;
+  }
+  else if (!strncmp(argv[0], "fr", 2))
+  {
+    label->type = ZEBRA_MPLS_LABEL_FR;
+  }
+  else
+  {
+    vty_out (vty, "'%s' is not a valid label type (gen|atm|fr)%s",
+      argv[0], VTY_NEWLINE);
+    return CMD_WARNING;
+  }
+
+  switch (label->type)
+  {
+    case ZEBRA_MPLS_LABEL_GEN:
+      if ((!sscanf(argv[1], "%u", &label->u.gen)))
+      {
+        vty_out (vty, "'%s' is not an valid gen label value (16 .. 2^20 - 1)%s",
+          argv[1], VTY_NEWLINE);
+        return CMD_WARNING;
+      }
+      break;
+    case ZEBRA_MPLS_LABEL_ATM:
+      if ((sscanf(argv[1], "%hu/%hu", &label->u.atm.vpi,
+	&label->u.atm.vci) != 2))
+      {
+        vty_out (vty, "'%s' is not an valid atm label value (vpi/vci)%s",
+          argv[1], VTY_NEWLINE);
+        return CMD_WARNING;
+      }
+      break;
+    case ZEBRA_MPLS_LABEL_FR:
+      if ((!sscanf(argv[1], "%u", &label->u.fr)))
+      {
+        vty_out (vty, "'%s' is not an valid fr label value (1 .. 2^17 - 1)%s",
+          argv[1], VTY_NEWLINE);
+        return CMD_WARNING;
+      }
+      break;
+  }
+  return CMD_SUCCESS;
+}
+
+int
+nhlfe_parse(struct vty *vty, const char **argv, struct zmpls_out_segment *out,
+  const char* addr)
+{
+  struct prefix p;
+  int result;
+
+  result = label_parse (vty, argv, &out->nh.mpls);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  strncpy(out->nh.intf.name, argv[2], IFNAMSIZ);
+  SET_FLAG (out->nh.type, ZEBRA_NEXTHOP_IFNAME);
+
+  if (addr)
+  {
+    str2prefix (addr, &p);
+    if ((p.family == AF_INET && p.prefixlen != IPV4_MAX_BITLEN) ||
+        (p.family == AF_INET6 && p.prefixlen != IPV6_MAX_BITLEN))
+    {
+      vty_out (vty, "Nexthop IP address must be a host address(%s)%s",
+	addr, VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+    switch (p.family)
+    {
+      case AF_INET:
+        if (p.prefixlen != IPV4_MAX_BITLEN)
+        {
+          vty_out (vty, "Nexthop IP address must be a host address(%s)%s",
+            addr, VTY_NEWLINE);
+          return CMD_WARNING;
+        }
+        out->nh.gw.ipv4 = p.u.prefix4;
+        SET_FLAG (out->nh.type, ZEBRA_NEXTHOP_IPV4);
+        break;
+      case AF_INET6:
+        if (p.prefixlen != IPV6_MAX_BITLEN)
+        {  
+          vty_out (vty, "Nexthop IP address must be a host address(%s)%s",
+            addr, VTY_NEWLINE);
+          return CMD_WARNING;
+        }
+        out->nh.gw.ipv6 = p.u.prefix6;
+        SET_FLAG (out->nh.type, ZEBRA_NEXTHOP_IPV6);
+        break;
+      default:
+        vty_out (vty, "Invalid nexthop(%s)%s", addr, VTY_NEWLINE);
+        return CMD_WARNING;
+        break;
+    }
+  }
+  return CMD_SUCCESS;
+}
+
+/******************************** vty commands ******************************/
+
+DEFUN (mpls_static_num,
+       mpls_static_num_cmd,
+       "mpls static <0-255>",
+       "Multi-protocol Label Switching\n"
+       "Static label information base\n"
+       "Labelspace number\n")
+{
+    int labelspace = -1;
+    if (!sscanf(argv[0], "%u", &labelspace)) {
+	vty_out (vty, "'%s' is not an valid labelspace (0 .. 255)%s",
+	    argv[0], VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+    vty->index = (void*)labelspace;
+    vty->node = MPLS_LABELSPACE_NODE;
+    return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_static_num,
+       no_mpls_static_num_cmd,
+       "no mpls static <0-255>",
+       NO_STR
+       "Multi-protocol Label Switching\n"
+       "Static labeling information\n"
+       "Labelspace number\n")
+{
+    struct listnode *node;
+    struct listnode *nnode;
+    struct zmpls_in_segment *in;
+    int labelspace = -1;
+
+    if (!sscanf(argv[0], "%u", &labelspace)) {
+	vty_out (vty, "'%s' is not an valid labelspace (0 .. 255)%s",
+	    argv[0], VTY_NEWLINE);
+	return CMD_WARNING;
+    }
+
+    for (ALL_LIST_ELEMENTS(&mpls_in_segment_list, node, nnode, in))
+	if (in->labelspace == labelspace)
+	    mpls_in_segment_unregister(in, 1);
+
+    return CMD_SUCCESS;
+}
+
+DEFUN (label_map_pop,
+       label_map_pop_cmd,
+       "label-map (gen|atm|fr) VALUE pop",
+       "Create a static incoming label-map (ILM)\n"
+       "In-coming Generic label\n"
+       "In-coming ATM VC\n"
+       "In-coming FR DLCI\n"
+       "Label value\n"
+       "Pop and lookup\n")
+{
+  struct zmpls_in_segment in;
+  int result;
+
+  in.owner = ZEBRA_ROUTE_STATIC;
+  in.labelspace = (int)vty->index;
+
+  result = label_parse(vty,argv,&in.label);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  in.pop = 1;
+
+  return mpls_in_segment_register(&in, 1) ? CMD_WARNING : CMD_SUCCESS;
+}
+
+static int
+create_ilm_xc_nhlfe(struct vty *vty, const char **ilm, const char **nhlfe,
+  const char *addr)
+{
+  struct zmpls_in_segment in;
+  struct zmpls_out_segment out;
+  struct zmpls_xc xc;
+  int result;
+
+  in.owner = ZEBRA_ROUTE_STATIC;
+
+  in.labelspace = (int)vty->index;
+
+  result = label_parse (vty, ilm, &in.label);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  memset (&out, 0, sizeof (out));
+  out.owner = ZEBRA_ROUTE_STATIC;
+  result = nhlfe_parse (vty, nhlfe, &out, addr);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  if (mpls_out_segment_find_index_by_nhlfe(&out))
+  {
+    vty_out(vty, "NHLFE already exists%s",VTY_NEWLINE);
+    goto error_out;
+  }
+
+  out.index = 0;
+  if (mpls_out_segment_register (&out))
+  {
+    vty_out(vty, "Unable to register NHLFE%s",VTY_NEWLINE);
+    goto error_out;
+  }
+
+  in.pop = 1;
+  if (mpls_in_segment_register (&in, (out.installed)))
+  {
+    goto error_in;
+  }
+
+  xc.in_labelspace = in.labelspace;
+  memcpy(&xc.in_label, &in.label, sizeof(struct zmpls_label));
+  xc.out_index = out.index;
+
+  if (mpls_xc_register (&xc))
+  {
+    goto error_xc;
+  }
+  return CMD_SUCCESS;
+
+error_xc:
+  mpls_in_segment_unregister (&in, 1);
+
+error_in:
+  mpls_out_segment_unregister (&out);
+
+error_out:
+  return CMD_WARNING;
+}
+
+DEFUN (label_map_swap_if,
+       label_map_swap_if_cmd,
+       "label-map (gen|atm|fr) VALUE swap (gen|atm|fr) VALUE nexthop INTERFACE",
+       "Create a static incoming label-map (ILM)\n"
+       "In-coming Generic label\n"
+       "In-coming ATM VC\n"
+       "In-coming FR DLCI\n"
+       "Label value\n"
+       "Forward\n"
+       "Out-going Generic label\n"
+       "Out-going ATM VC\n"
+       "Out-going FR DLCI\n"
+       "Label value\n"
+       "Nexthop\n"
+       "Out-going interface name\n")
+{
+  return create_ilm_xc_nhlfe(vty, argv, &argv[2], NULL);
+}
+
+DEFUN (label_map_swap_if_addr,
+       label_map_swap_if_addr_cmd,
+       "label-map (gen|atm|fr) VALUE swap (gen|atm|fr) VALUE nexthop INTERFACE IPADDR",
+       "Incoming label-map (ILM)\n"
+       "In-coming Generic label\n"
+       "In-coming ATM VC\n"
+       "In-coming FR DLCI\n"
+       "Label value\n"
+       "Forward\n"
+       "Out-going Generic label\n"
+       "Out-going ATM VC\n"
+       "Out-going FR DLCI\n"
+       "Label value\n"
+       "Nexthop\n"
+       "Out-going interface name\n"
+       "Nexthop IP address\n")
+{
+  return create_ilm_xc_nhlfe(vty, argv, &argv[2], argv[5]);
+}
+
+DEFUN (no_label_map,
+       no_label_map_cmd,
+       "no label-map (gen|atm|fr) VALUE",
+       NO_STR
+       "Incoming label-map (ILM)\n"
+       "In-coming Generic label\n"
+       "In-coming ATM VC\n"
+       "In-coming FR DLCI\n"
+       "Label value\n")
+{
+  struct zmpls_in_segment in;
+  int result;
+
+  in.labelspace = (int)vty->index;
+
+  result = label_parse(vty, argv, &in.label);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  return mpls_in_segment_unregister(&in, 1) ? CMD_WARNING : CMD_SUCCESS;
+}
+
+static void
+mpls_interface_show_write (struct vty *vty, struct interface *ifp)
+{
+  struct zebra_if *if_data;
+  if_data = ifp->info;
+
+  vty_out (vty, " Static MPLS tunnel out-segment: ");
+  if (if_data && if_data->ops && if_data->ops->info)
+  {
+    struct zmpls_out_segment *out;
+
+    out = mpls_out_segment_find_by_out_key((int)if_data->ops->info);
+    if (out)
+    {
+      mpls_out_segment_config_write (vty, out);
+      vty_out (vty, "%s", VTY_NEWLINE);
+    }
+    else
+    {
+      vty_out (vty, "  (invalid)%s", VTY_NEWLINE);
+    }
+  }
+  else
+  {
+    vty_out (vty, "  (not configured)%s", VTY_NEWLINE);
+  }
+}
+
+DEFUN (mpls_labelspace,
+       mpls_labelspace_cmd,
+       "mpls labelspace <0-255>",
+       "MPLS interface configuration\n"
+       "labelspace\n"
+       "labelspace number\n")
+{
+  struct interface *ifp;
+  int labelspace = atoi(argv[0]);
+
+  ifp = vty->index;
+  vty_out(vty, "Labelspace: %d%s",labelspace, VTY_NEWLINE);
+  if (labelspace < 0) {
+    vty_out(vty, "%% Invalid labelspace '%s'%s",argv[0], VTY_NEWLINE);
+    return CMD_WARNING;
+  }
+
+  mpls_ctrl_set_interface_labelspace(ifp, labelspace);
+  ifp->mpls_labelspace = labelspace;
+  redistribute_add_mpls_labelspace (ifp);
+
+  return CMD_SUCCESS;
+}
+
+DEFUN (no_mpls_labelspace,
+       no_mpls_labelspace_cmd,
+       "no mpls labelspace",
+       NO_STR
+       "MPLS interface configuration\n"
+       "labelspace\n")
+{
+  struct interface *ifp;
+  ifp = vty->index;
+
+  mpls_ctrl_set_interface_labelspace(ifp, -1);
+  redistribute_delete_mpls_labelspace (ifp);
+  ifp->mpls_labelspace = -1;
+
+  return CMD_SUCCESS;
+}
+
+void mpls_print_label(struct zmpls_label *label, char *buf)
+{
+  switch (label->type)
+  {
+    case ZEBRA_MPLS_LABEL_GEN:
+      sprintf(buf, "%u", label->u.gen);
+      break;
+    case ZEBRA_MPLS_LABEL_ATM:
+      sprintf(buf, "%hu/%hu", label->u.atm.vpi, label->u.atm.vci);
+      break;
+    case ZEBRA_MPLS_LABEL_FR:
+      sprintf(buf, "%u", label->u.fr);
+      break;
+  }
+}
+
+DEFUN (mpls_show_mpls_fwd,
+       mpls_show_mpls_fwd_cmd,
+       "show mpls forwarding",
+       SHOW_STR
+       "MPLS commands\n"
+       "forwarding table\n")
+{
+  struct zmpls_out_segment *out;
+  struct zmpls_in_segment *in;
+  struct zmpls_xc *xc;
+  struct listnode *node;
+  int count;
+
+  vty_out(vty, "Insegments:%s",VTY_NEWLINE);
+
+  count = 0;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_in_segment_list, node, in)) 
+  {
+    char buf[16];
+
+    mpls_print_label(&in->label, buf);
+
+    if (!count) {
+      vty_out(vty, "  Lbl Spc  Label Owner%s", VTY_NEWLINE);
+    }
+    vty_out(vty, "    %-3d  %7s %-6s", in->labelspace,
+      buf, zebra_route_string(in->owner));
+
+    if (!in->installed)
+      vty_out(vty, " (inactive)");
+
+    vty_out(vty, "%s", VTY_NEWLINE);
+    count++;
+  }
+  if (!count) {
+    vty_out(vty, "%s", VTY_NEWLINE);
+  }
+  vty_out(vty, "Total %d%s",count, VTY_NEWLINE);
+  vty_out(vty, "%s", VTY_NEWLINE);
+
+  vty_out(vty, "Outsegments:%s",VTY_NEWLINE);
+  count = 0;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list, node, out))
+  {
+    char buf2[16];
+    char buf[48];
+    char *ifname = NULL;
+
+    if (!count) {
+      vty_out (vty, "  Interface          Label Next Hop        Owner%s",
+        VTY_NEWLINE);
+    }
+
+    if (CHECK_FLAG (out->nh.type, ZEBRA_NEXTHOP_IFNAME))
+    {
+      ifname = out->nh.intf.name;
+    } else {
+      ifname = "(remote)";
+    }
+
+    if (CHECK_FLAG (out->nh.type, ZEBRA_NEXTHOP_IPV4))
+    {
+      inet_ntop (AF_INET, &out->nh.gw.ipv4, buf, sizeof(buf));
+    } else if (CHECK_FLAG (out->nh.type, ZEBRA_NEXTHOP_IPV6)) {
+      inet_ntop (AF_INET6, &out->nh.gw.ipv6, buf, sizeof(buf));
+    } else {
+      strcpy (buf, "0.0.0.0");
+    }
+
+    mpls_print_label(&out->nh.mpls, buf2);
+
+    vty_out(vty, "  %-16s %7s %-15s %-6s",  ifname, 
+      buf2, buf, zebra_route_string(out->owner));
+
+    if (!out->installed)
+      vty_out(vty, " (inactive)");
+
+    vty_out(vty, "%s", VTY_NEWLINE);
+    count++;
+  }
+  if (!count) {
+    vty_out(vty, "%s", VTY_NEWLINE);
+  }
+  vty_out(vty, "Total %d%s",count, VTY_NEWLINE);
+  vty_out(vty, "%s", VTY_NEWLINE);
+
+  vty_out(vty, "Cross Connects:%s",VTY_NEWLINE);
+  count = 0;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_xc_list, node, xc))
+  {
+    char buf[48];
+    char buf2[48];
+    char buf3[48];
+    char *ifname = NULL;
+    struct zmpls_in_segment tmp;
+    struct zmpls_in_segment *in;
+    struct zmpls_out_segment *out;
+
+    out = mpls_out_segment_find(xc->out_index);
+
+    tmp.labelspace = xc->in_labelspace;
+    memcpy(&tmp.label, &xc->in_label, sizeof(struct zmpls_label));
+    in = mpls_in_segment_find(&tmp);
+
+    if (!count) {
+      vty_out(vty, "  Lbl Spc  In Label Out Label Interface        "
+        "Next Hop        Owner%s", VTY_NEWLINE);
+    }
+
+    mpls_print_label(&in->label, buf);
+    mpls_print_label(&out->nh.mpls, buf2);
+
+    if (CHECK_FLAG (out->nh.type, ZEBRA_NEXTHOP_IFNAME))
+    {
+      ifname = out->nh.intf.name;
+    } else {
+      ifname = "(remote)";
+    }
+
+    if (CHECK_FLAG (out->nh.type, ZEBRA_NEXTHOP_IPV4))
+    {
+      inet_ntop (AF_INET, &out->nh.gw.ipv6, buf3, sizeof(buf3));
+    } else if (CHECK_FLAG (out->nh.type, ZEBRA_NEXTHOP_IPV6)) {
+      inet_ntop (AF_INET6, &out->nh.gw.ipv6, buf3, sizeof(buf3));
+    } else {
+      strcpy (buf3, "0.0.0.0");
+    }
+
+    vty_out(vty, "    %-3d     %7s   %7s %-16s %-15s %-6s",
+      xc->in_labelspace, buf, buf2, ifname, buf3,
+      zebra_route_string(in->owner));
+
+    if (!xc->installed)
+      vty_out(vty, " (inactive)");
+
+    vty_out(vty, "%s", VTY_NEWLINE);
+    count++;
+  }
+  if (!count) {
+      vty_out(vty, "%s", VTY_NEWLINE);
+  }
+  vty_out(vty, "Total %d%s",count, VTY_NEWLINE);
+  vty_out(vty, "%s", VTY_NEWLINE);
+
+  return CMD_SUCCESS;
+}
+
+#ifdef LINUX_MPLS
+DEFUN (mpls_show_mpls_version,
+       mpls_show_mpls_version_cmd,
+       "show mpls version",
+       SHOW_STR
+       "MPLS 'show' commands\n"
+       "Show MPLS version\n")
+{
+  vty_out(vty, "Version %d.%d%d%d%s", (MPLS_LINUX_VERSION >> 24) & 0xFF,
+    (MPLS_LINUX_VERSION >> 16) & 0xFF, (MPLS_LINUX_VERSION >> 8) & 0xFF,
+    (MPLS_LINUX_VERSION) & 0xFF, VTY_NEWLINE);
+  return CMD_SUCCESS;
+}
+#endif
+
+DEFUN (mpls_show_mpls_hardware,
+       mpls_show_mpls_hardware_cmd,
+       "show mpls hardware",
+       SHOW_STR
+       "MPLS 'show' commands\n"
+       "Show MPLS forwarder type\n")
+{
+  return mpls_ctrl_show_hardware(vty);
+}
+
+static void
+mpls_label_config_write (struct vty *vty, struct zmpls_label *label)
+{
+  switch (label->type)
+  {
+    case ZEBRA_MPLS_LABEL_GEN:
+      vty_out (vty, "gen %d", label->u.gen);
+      break;
+    case ZEBRA_MPLS_LABEL_ATM:
+      vty_out (vty, "atm %d/%d", label->u.atm.vpi, label->u.atm.vci);
+      break;
+    case ZEBRA_MPLS_LABEL_FR:
+      vty_out (vty, "fr %d", label->u.fr);
+      break;
+  }
+}
+
+void
+mpls_out_segment_config_write (struct vty *vty, struct zmpls_out_segment *out)
+{
+  char buf[128] = "";
+
+  mpls_label_config_write (vty, &out->nh.mpls);
+  vty_out (vty, " nexthop");
+
+  if (CHECK_FLAG (out->nh.type, ZEBRA_NEXTHOP_IFNAME))
+  {
+      vty_out (vty, " %s", out->nh.intf.name);
+  }
+
+  if (CHECK_FLAG (out->nh.type, ZEBRA_NEXTHOP_IPV6))
+  {
+      inet_ntop (AF_INET6, &out->nh.gw.ipv6, buf, sizeof (buf));
+  }
+  else if (CHECK_FLAG (out->nh.type, ZEBRA_NEXTHOP_IPV4))
+  {
+      inet_ntop (AF_INET, &out->nh.gw.ipv4, buf, sizeof (buf));
+  }
+  vty_out (vty, " %s", buf);
+}
+
+static void
+mpls_in_segment_config_write (struct vty *vty, struct zmpls_in_segment *in)
+{
+  mpls_label_config_write (vty, &in->label);
+
+  if (in->xc)
+  {
+    struct zmpls_out_segment *out;
+    struct zmpls_xc *xc;
+
+    vty_out (vty, " swap ");
+    xc = mpls_xc_find (in->xc);
+    out = mpls_out_segment_find (xc->out_index);
+    if (out)
+    {
+      mpls_out_segment_config_write (vty, out);
+    }
+    else
+    {
+      vty_out (vty, "(unable to find out-segment with index %d)", in->xc);
+    }
+  } else if (in->pop) {
+    vty_out (vty, " pop");
+  } else {
+    vty_out (vty, "(invalid ILM)");
+  }
+}
+
+static int
+mpls_static_config_write (struct vty *vty)
+{
+  struct listnode *node;
+  struct zmpls_in_segment *in;
+  int labelspace;
+  int first;
+
+  for (labelspace = 0;labelspace < 256;labelspace++)
+  {
+    first = 1;
+
+    for (ALL_LIST_ELEMENTS_RO (&mpls_in_segment_list, node, in))
+    {
+      if (in->owner != ZEBRA_ROUTE_STATIC &&
+	  in->owner != ZEBRA_ROUTE_KERNEL )
+        continue;
+
+      if (in->labelspace != labelspace)
+        continue;
+
+      if (first)
+        vty_out (vty, "mpls static %d%s", labelspace, VTY_NEWLINE);
+
+      vty_out (vty, " label-map ");
+      mpls_in_segment_config_write (vty, in);
+      vty_out (vty, "%s", VTY_NEWLINE);
+      first = 0;
+    }
+    vty_out (vty, "!%s", VTY_NEWLINE);
+  }
+  return 0;
+}
+
+static
+struct cmd_node mpls_static_node =
+{
+  MPLS_LABELSPACE_NODE,
+  "%s(config-ls)# ",
+  1
+};
+
+void
+mpls_vty_init ()
+{
+  install_element (CONFIG_NODE, &mpls_static_num_cmd);
+  install_element (CONFIG_NODE, &no_mpls_static_num_cmd);
+  install_element (INTERFACE_NODE, &mpls_labelspace_cmd);
+  install_element (INTERFACE_NODE, &no_mpls_labelspace_cmd);
+
+  install_node (&mpls_static_node, mpls_static_config_write);
+  install_default (MPLS_LABELSPACE_NODE);
+
+  install_element (MPLS_LABELSPACE_NODE, &label_map_pop_cmd);
+  install_element (MPLS_LABELSPACE_NODE, &label_map_swap_if_cmd);
+  install_element (MPLS_LABELSPACE_NODE, &label_map_swap_if_addr_cmd);
+  install_element (MPLS_LABELSPACE_NODE, &no_label_map_cmd);
+
+  install_element (VIEW_NODE, &mpls_show_mpls_fwd_cmd);
+  install_element (ENABLE_NODE, &mpls_show_mpls_fwd_cmd);
+#ifdef LINUX_MPLS
+  install_element (VIEW_NODE, &mpls_show_mpls_version_cmd);
+  install_element (ENABLE_NODE, &mpls_show_mpls_version_cmd);
+#endif
+  install_element (VIEW_NODE, &mpls_show_mpls_hardware_cmd);
+  install_element (ENABLE_NODE, &mpls_show_mpls_hardware_cmd);
+}
+
+#endif /* HAVE_MPLS */
diff -Naur quagga-0.99.10/zebra/mpls_vty.h quagga-mpls/zebra/mpls_vty.h
--- quagga-0.99.10/zebra/mpls_vty.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/mpls_vty.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,40 @@
+/*
+ * MPLS CLI for zebra daemon.
+ *
+ * Copyright (C) 2004 James R. Leu 
+ *
+ * This file is part of Quagga routing suite.
+ *
+ * Quagga is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2, or (at your option) any
+ * later version.
+ *
+ * Quagga is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU Zebra; see the file COPYING.  If not, write to the Free
+ * Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
+ * 02111-1307, USA.
+ */
+
+#ifndef _ZEBRA_MPLS_VTY_H
+#define _ZEBRA_MPLS_VTY_H
+
+#include "mpls_lib.h"
+#include "vty.h"
+
+extern void mpls_vty_init();
+extern void mpls_print_label(struct zmpls_label *label, char *buf);
+
+extern void
+mpls_out_segment_config_write (struct vty *vty, struct zmpls_out_segment *out);
+
+extern int
+nhlfe_parse(struct vty *vty, const char **argv, struct zmpls_out_segment *out,
+  const char* addr);
+
+#endif /* _ZEBRA_MPLS_VTY_H */
diff -Naur quagga-0.99.10/zebra/netlink.c quagga-mpls/zebra/netlink.c
--- quagga-0.99.10/zebra/netlink.c	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/netlink.c	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,623 @@
+/* Kernel routing table updates using netlink over GNU/Linux system.
+ * Copyright (C) 1997, 98, 99 Kunihiro Ishiguro
+ *
+ * This file is part of GNU Zebra.
+ *
+ * GNU Zebra is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 2, or (at your option) any
+ * later version.
+ *
+ * GNU Zebra is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with GNU Zebra; see the file COPYING.  If not, write to the Free
+ * Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA
+ * 02111-1307, USA.  
+ */
+
+#include <zebra.h>
+
+/* Hack for GNU libc version 2. */
+#ifndef MSG_TRUNC
+#define MSG_TRUNC      0x20
+#endif /* MSG_TRUNC */
+
+#include "linklist.h"
+#include "if.h"
+#include "log.h"
+#include "prefix.h"
+#include "connected.h"
+#include "table.h"
+#include "rib.h"
+#include "thread.h"
+#include "privs.h"
+
+#include "zebra/zserv.h"
+#include "zebra/redistribute.h"
+#include "zebra/interface.h"
+#include "zebra/debug.h"
+#include "zebra/netlink.h"
+
+extern struct zebra_t zebrad;
+extern struct zebra_privs_t zserv_privs;
+extern u_int32_t nl_rcvbufsize;
+
+struct message nlmsg_str[] = {
+  {RTM_NEWROUTE, "RTM_NEWROUTE"},
+  {RTM_DELROUTE, "RTM_DELROUTE"},
+  {RTM_GETROUTE, "RTM_GETROUTE"},
+  {RTM_NEWLINK,  "RTM_NEWLINK"},
+  {RTM_DELLINK,  "RTM_DELLINK"},
+  {RTM_GETLINK,  "RTM_GETLINK"},
+  {RTM_NEWADDR,  "RTM_NEWADDR"},
+  {RTM_DELADDR,  "RTM_DELADDR"},
+  {RTM_GETADDR,  "RTM_GETADDR"},
+  {0, NULL}
+};
+
+char *nexthop_types_desc(int x)
+{
+  static char buf[1024];
+  if (CHECK_FLAG (x, ZEBRA_NEXTHOP_IFINDEX)) {
+    sprintf(buf, "ifindex ");
+  }
+  if (CHECK_FLAG (x, ZEBRA_NEXTHOP_IFNAME)) {
+    sprintf(buf, "ifname ");
+  }
+  if (CHECK_FLAG (x, ZEBRA_NEXTHOP_IPV4)) {
+    sprintf(buf, "IPv4 ");
+  }
+  if (CHECK_FLAG (x, ZEBRA_NEXTHOP_IPV6)) {
+    sprintf(buf, "IPv6 ");
+  }
+  if (CHECK_FLAG (x, ZEBRA_NEXTHOP_DROP)) {
+    sprintf(buf, "Drop ");
+  }
+  return buf;
+}
+
+/* Make socket for Linux netlink interface. */
+int
+netlink_socket (struct nlsock *nl, int proto, unsigned long groups)
+{
+  int ret;
+  struct sockaddr_nl snl;
+  int sock;
+  int namelen;
+  int save_errno;
+
+  sock = socket (AF_NETLINK, SOCK_RAW, proto);
+  if (sock < 0)
+    {
+      zlog (NULL, LOG_ERR, "Can't open %s socket: %s", nl->name,
+            safe_strerror (errno));
+      return -1;
+    }
+
+  ret = fcntl (sock, F_SETFL, O_NONBLOCK);
+  if (ret < 0)
+    {
+      zlog (NULL, LOG_ERR, "Can't set %s socket flags: %s", nl->name,
+            safe_strerror (errno));
+      close (sock);
+      return -1;
+    }
+
+  /* Set receive buffer size if it's set from command line */
+  if (nl_rcvbufsize)
+    {
+      u_int32_t oldsize, oldlen;
+      u_int32_t newsize, newlen;
+
+      oldlen = sizeof(oldsize);
+      newlen = sizeof(newsize);
+
+      ret = getsockopt(sock, SOL_SOCKET, SO_RCVBUF, &oldsize, &oldlen);
+      if (ret < 0)
+	{
+	  zlog (NULL, LOG_ERR, "Can't get %s receive buffer size: %s", nl->name,
+		safe_strerror (errno));
+	  close (sock);
+	  return -1;
+	}
+
+      ret = setsockopt(sock, SOL_SOCKET, SO_RCVBUF, &nl_rcvbufsize,
+		       sizeof(nl_rcvbufsize));
+      if (ret < 0)
+	{
+	  zlog (NULL, LOG_ERR, "Can't set %s receive buffer size: %s", nl->name,
+		safe_strerror (errno));
+	  close (sock);
+	  return -1;
+	}
+
+      ret = getsockopt(sock, SOL_SOCKET, SO_RCVBUF, &newsize, &newlen);
+      if (ret < 0)
+	{
+	  zlog (NULL, LOG_ERR, "Can't get %s receive buffer size: %s", nl->name,
+		safe_strerror (errno));
+	  close (sock);
+	  return -1;
+	}
+
+      zlog (NULL, LOG_INFO,
+	    "Setting netlink socket receive buffer size: %u -> %u",
+	    oldsize, newsize);
+    }
+
+  memset (&snl, 0, sizeof snl);
+  snl.nl_family = AF_NETLINK;
+  snl.nl_groups = groups;
+
+  /* Bind the socket to the netlink structure for anything. */
+  if (zserv_privs.change (ZPRIVS_RAISE))
+    {
+      zlog (NULL, LOG_ERR, "Can't raise privileges");
+      return -1;
+    }
+
+  ret = bind (sock, (struct sockaddr *) &snl, sizeof snl);
+  save_errno = errno;
+  if (zserv_privs.change (ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  if (ret < 0)
+    {
+      zlog (NULL, LOG_ERR, "Can't bind %s socket to group 0x%x: %s",
+            nl->name, snl.nl_groups, safe_strerror (save_errno));
+      close (sock);
+      return -1;
+    }
+
+  /* multiple netlink sockets will have different nl_pid */
+  namelen = sizeof snl;
+  ret = getsockname (sock, (struct sockaddr *) &snl, (socklen_t *) &namelen);
+  if (ret < 0 || namelen != sizeof snl)
+    {
+      zlog (NULL, LOG_ERR, "Can't get %s socket name: %s", nl->name,
+            safe_strerror (errno));
+      close (sock);
+      return -1;
+    }
+
+  nl->snl = snl;
+  nl->sock = sock;
+  return ret;
+}
+
+int
+set_netlink_blocking (struct nlsock *nl, int *flags)
+{
+
+  /* Change socket flags for blocking I/O.  */
+  if ((*flags = fcntl (nl->sock, F_GETFL, 0)) < 0)
+    {
+      zlog (NULL, LOG_ERR, "%s:%i F_GETFL error: %s",
+            __FUNCTION__, __LINE__, safe_strerror (errno));
+      return -1;
+    }
+  *flags &= ~O_NONBLOCK;
+  if (fcntl (nl->sock, F_SETFL, *flags) < 0)
+    {
+      zlog (NULL, LOG_ERR, "%s:%i F_SETFL error: %s",
+            __FUNCTION__, __LINE__, safe_strerror (errno));
+      return -1;
+    }
+  return 0;
+}
+
+int
+set_netlink_nonblocking (struct nlsock *nl, int *flags)
+{
+  /* Restore socket flags for nonblocking I/O */
+  *flags |= O_NONBLOCK;
+  if (fcntl (nl->sock, F_SETFL, *flags) < 0)
+    {
+      zlog (NULL, LOG_ERR, "%s:%i F_SETFL error: %s",
+            __FUNCTION__, __LINE__, safe_strerror (errno));
+      return -1;
+    }
+  return 0;
+}
+
+static int
+do_netlink_request (struct nlsock *nl, void *buf, int size)
+{
+  int ret;
+  struct sockaddr_nl snl;
+  int save_errno;
+
+  memset (&snl, 0, sizeof snl);
+  snl.nl_family = AF_NETLINK;
+
+  /* Check netlink socket. */
+  if (nl->sock < 0)
+    {
+      zlog (NULL, LOG_ERR, "%s socket isn't active.", nl->name);
+      return -1;
+    }
+
+  /* linux appears to check capabilities on every message 
+   * have to raise caps for every message sent
+   */
+  if (zserv_privs.change (ZPRIVS_RAISE))
+    {
+      zlog (NULL, LOG_ERR, "Can't raise privileges");
+      return -1;
+    }
+
+  ret = sendto (nl->sock, buf, size, 0, (struct sockaddr *) &snl, sizeof snl);
+  save_errno = errno;
+
+  if (zserv_privs.change (ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  if (ret < 0)
+    {
+      zlog (NULL, LOG_ERR, "%s sendto failed: %s", nl->name,
+            safe_strerror (save_errno));
+      return -1;
+    }
+
+  return 0;
+}
+
+/* Get type specified information from netlink. */
+int
+netlink_request (int family, int type, struct nlsock *nl)
+{
+  struct
+  {
+    struct nlmsghdr nlh;
+    struct rtgenmsg g;
+  } req;
+
+  memset (&req, 0, sizeof req);
+  req.nlh.nlmsg_len = sizeof req;
+  req.nlh.nlmsg_type = type;
+  req.nlh.nlmsg_flags = NLM_F_ROOT | NLM_F_MATCH | NLM_F_REQUEST;
+  req.nlh.nlmsg_pid = 0;
+  req.nlh.nlmsg_seq = ++nl->seq;
+  req.g.rtgen_family = family;
+
+  return do_netlink_request(nl, (void*)&req, sizeof(req));
+}
+
+#if defined(HAVE_MPLS) && defined(LINUX_MPLS)
+int
+genetlink_request (int family, int type, struct nlsock *nl)
+{
+  struct genlmsghdr *ghdr;
+
+  struct {
+    struct nlmsghdr n;
+    char            buf[4096];
+  } req;
+
+  memset(&req, 0, sizeof(req));
+
+  req.n.nlmsg_len = NLMSG_LENGTH(GENL_HDRLEN);
+  req.n.nlmsg_flags = NLM_F_ROOT|NLM_F_MATCH|NLM_F_REQUEST;
+  req.n.nlmsg_type = family;
+  req.n.nlmsg_seq = ++nl->seq;
+
+  ghdr = NLMSG_DATA(&req.n);
+  ghdr->cmd = type;
+
+  return do_netlink_request(nl, (void*)&req, sizeof(req));
+}
+#endif
+
+/* Receive message from netlink interface and pass those information
+   to the given function. */
+int
+netlink_parse_info (int (*filter) (struct nlsock *nl, struct sockaddr_nl *, struct nlmsghdr *),
+                    struct nlsock *nl, void *a, unsigned int size)
+{
+  char buf[16384];
+  int status;
+  int ret = 0;
+  int error;
+
+  if (!a)
+    {
+      a = (void*)buf;
+      size = sizeof(buf);
+    }
+
+  while (1)
+    {
+      struct iovec iov = { a, size };
+      struct sockaddr_nl snl;
+      struct msghdr msg = { (void *) &snl, sizeof snl, &iov, 1, NULL, 0, 0 };
+      struct nlmsghdr *h;
+      int save_errno;
+
+      if (zserv_privs.change (ZPRIVS_RAISE))
+        zlog (NULL, LOG_ERR, "Can't raise privileges");
+
+      status = recvmsg (nl->sock, &msg, 0);
+      save_errno = errno;
+
+      if (zserv_privs.change (ZPRIVS_LOWER))
+        zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+      if (status < 0)
+        {
+          if (save_errno == EINTR)
+            continue;
+          if (save_errno == EWOULDBLOCK || save_errno == EAGAIN)
+            break;
+          zlog (NULL, LOG_ERR, "%s recvmsg overrun: %s",
+	  	nl->name, safe_strerror(save_errno));
+          continue;
+        }
+
+      if (status == 0)
+        {
+          zlog (NULL, LOG_ERR, "%s EOF", nl->name);
+          return -1;
+        }
+
+      if (msg.msg_namelen != sizeof snl)
+        {
+          zlog (NULL, LOG_ERR, "%s sender address length error: length %d",
+                nl->name, msg.msg_namelen);
+          return -1;
+        }
+      
+      /* JF: Ignore messages that aren't from the kernel */
+      if ( snl.nl_pid != 0 )
+        {
+          zlog ( NULL, LOG_ERR, "Ignoring message from pid %u", snl.nl_pid );
+          continue;
+        }
+
+      for (h = (struct nlmsghdr *) a; NLMSG_OK (h, (unsigned int) status);
+           h = NLMSG_NEXT (h, status))
+        {
+          /* Finish of reading. */
+          if (h->nlmsg_type == NLMSG_DONE)
+            return ret;
+
+          /* Error handling. */
+          if (h->nlmsg_type == NLMSG_ERROR)
+            {
+              struct nlmsgerr *err = (struct nlmsgerr *) NLMSG_DATA (h);
+
+              /* If the error field is zero, then this is an ACK */
+              if (err->error == 0)
+                {
+                  if (IS_ZEBRA_DEBUG_KERNEL)
+                    {
+                      zlog_debug ("%s: %s ACK: type=%s(%u), seq=%u, pid=%u",
+                                 __FUNCTION__, nl->name,
+                                 lookup (nlmsg_str, err->msg.nlmsg_type),
+                                 err->msg.nlmsg_type, err->msg.nlmsg_seq,
+                                 err->msg.nlmsg_pid);
+                    }
+
+                  /* return if not a multipart message, otherwise continue */
+                  if (!(h->nlmsg_flags & NLM_F_MULTI))
+                    {
+                      return 0;
+                    }
+                  continue;
+                }
+
+              if (h->nlmsg_len < NLMSG_LENGTH (sizeof (struct nlmsgerr)))
+                {
+                  zlog (NULL, LOG_ERR, "%s error: message truncated",
+                        nl->name);
+                  return -1;
+                }
+
+              /* Deal with Error Noise  - MAG */
+              {
+                int loglvl = LOG_ERR;
+                int errnum = err->error;
+                int msg_type = err->msg.nlmsg_type;
+
+		/* nl->cmd is defined only for the CMD sockets */
+                if (nl->cmd && (-errnum == ENODEV || -errnum == ESRCH))
+                  loglvl = LOG_DEBUG;
+
+                zlog (NULL, loglvl, "%s error: %s, type=%s(%u), "
+                      "seq=%u, pid=%u",
+                      nl->name, safe_strerror (-errnum),
+                      lookup (nlmsg_str, msg_type),
+                      msg_type, err->msg.nlmsg_seq, err->msg.nlmsg_pid);
+              }
+              /*
+                 ret = -1;
+                 continue;
+               */
+              return -1;
+            }
+
+          /* OK we got netlink message. */
+          if (IS_ZEBRA_DEBUG_KERNEL)
+            zlog_debug ("netlink_parse_info: %s type %s(%u), seq=%u, pid=%u",
+                       nl->name,
+                       lookup (nlmsg_str, h->nlmsg_type), h->nlmsg_type,
+                       h->nlmsg_seq, h->nlmsg_pid);
+
+          error = (*filter) (nl, &snl, h);
+          if (error < 0)
+            {
+              zlog (NULL, LOG_ERR, "%s filter function error", nl->name);
+              ret = error;
+            }
+        }
+
+      /* After error care. */
+      if (msg.msg_flags & MSG_TRUNC)
+        {
+          zlog (NULL, LOG_ERR, "%s error: message truncated", nl->name);
+          continue;
+        }
+      if (status)
+        {
+          zlog (NULL, LOG_ERR, "%s error: data remnant size %d", nl->name,
+                status);
+          return -1;
+        }
+    }
+  return ret;
+}
+
+/* Utility function for parse rtattr. */
+void
+netlink_parse_rtattr (struct rtattr **tb, int max, struct rtattr *rta,
+                      int len)
+{
+  while (RTA_OK (rta, len))
+    {
+      if (rta->rta_type <= max)
+        tb[rta->rta_type] = rta;
+      rta = RTA_NEXT (rta, len);
+    }
+}
+
+/* Utility function  comes from iproute2. 
+   Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru> */
+int
+addattr_l (struct nlmsghdr *n, unsigned int maxlen, int type,
+           void *data, int alen)
+{
+  int len;
+  struct rtattr *rta;
+
+  len = RTA_LENGTH (alen);
+
+  if (NLMSG_ALIGN (n->nlmsg_len) + len > maxlen)
+    return -1;
+
+  rta = (struct rtattr *) (((char *) n) + NLMSG_ALIGN (n->nlmsg_len));
+  rta->rta_type = type;
+  rta->rta_len = len;
+  memcpy (RTA_DATA (rta), data, alen);
+  n->nlmsg_len = NLMSG_ALIGN (n->nlmsg_len) + len;
+
+  return 0;
+}
+
+int
+rta_addattr_l (struct rtattr *rta, int maxlen, int type, void *data, int alen)
+{
+  int len;
+  struct rtattr *subrta;
+
+  len = RTA_LENGTH (alen);
+
+  if (RTA_ALIGN (rta->rta_len) + len > maxlen)
+    return -1;
+
+  subrta = (struct rtattr *) (((char *) rta) + RTA_ALIGN (rta->rta_len));
+  subrta->rta_type = type;
+  subrta->rta_len = len;
+  memcpy (RTA_DATA (subrta), data, alen);
+  rta->rta_len = NLMSG_ALIGN (rta->rta_len) + len;
+
+  return 0;
+}
+
+/* Utility function comes from iproute2. 
+   Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru> */
+int
+addattr32 (struct nlmsghdr *n, unsigned int maxlen, int type, int data)
+{
+  int len;
+  struct rtattr *rta;
+
+  len = RTA_LENGTH (4);
+
+  if (NLMSG_ALIGN (n->nlmsg_len) + len > maxlen)
+    return -1;
+
+  rta = (struct rtattr *) (((char *) n) + NLMSG_ALIGN (n->nlmsg_len));
+  rta->rta_type = type;
+  rta->rta_len = len;
+  memcpy (RTA_DATA (rta), &data, 4);
+  n->nlmsg_len = NLMSG_ALIGN (n->nlmsg_len) + len;
+
+  return 0;
+}
+
+int
+netlink_talk_filter (struct nlsock *nl, struct sockaddr_nl *snl, struct nlmsghdr *h)
+{
+  zlog_warn ("netlink_talk: ignoring message type 0x%04x", h->nlmsg_type);
+  return 0;
+}
+
+/* sendmsg() to netlink socket then recvmsg(). */
+int
+netlink_talk (struct nlmsghdr *n, struct nlsock *nl, void *a, unsigned int size)
+{
+  int status;
+  struct sockaddr_nl snl;
+  struct iovec iov = { (void *) n, n->nlmsg_len };
+  struct msghdr msg = { (void *) &snl, sizeof snl, &iov, 1, NULL, 0, 0 };
+  int flags = 0;
+  int snb_ret;
+  int save_errno;
+
+  memset (&snl, 0, sizeof snl);
+  snl.nl_family = AF_NETLINK;
+
+  n->nlmsg_seq = ++nl->seq;
+
+  /* Request an acknowledgement by setting NLM_F_ACK */
+  if (!a)
+    n->nlmsg_flags |= NLM_F_ACK;
+
+  if (IS_ZEBRA_DEBUG_KERNEL)
+    zlog_debug ("netlink_talk: %s type %s(%u), seq=%u", nl->name,
+               lookup (nlmsg_str, n->nlmsg_type), n->nlmsg_type,
+               n->nlmsg_seq);
+
+  /* Send message to netlink interface. */
+  if (zserv_privs.change (ZPRIVS_RAISE))
+    zlog (NULL, LOG_ERR, "Can't raise privileges");
+  status = sendmsg (nl->sock, &msg, 0);
+  save_errno = errno;
+  if (zserv_privs.change (ZPRIVS_LOWER))
+    zlog (NULL, LOG_ERR, "Can't lower privileges");
+
+  if (status < 0)
+    {
+      zlog (NULL, LOG_ERR, "netlink_talk sendmsg() error: %s",
+            safe_strerror (save_errno));
+      return -1;
+    }
+
+  if (!a)
+    {
+      /* 
+       * Change socket flags for blocking I/O. 
+       * This ensures we wait for a reply in netlink_parse_info().
+       */
+      snb_ret = set_netlink_blocking (nl, &flags);
+      if (snb_ret < 0)
+        zlog (NULL, LOG_WARNING,
+              "%s:%i Warning: Could not set netlink socket to blocking.",
+              __FUNCTION__, __LINE__);
+    }
+
+  /* 
+   * Get reply from netlink socket. 
+   * The reply should either be an acknowlegement or an error.
+   */
+  status = netlink_parse_info (netlink_talk_filter, nl, a, size);
+
+  /* Restore socket flags for nonblocking I/O */
+  if (snb_ret == 0 && !a)
+    set_netlink_nonblocking (nl, &flags);
+
+  return status;
+}
diff -Naur quagga-0.99.10/zebra/netlink.h quagga-mpls/zebra/netlink.h
--- quagga-0.99.10/zebra/netlink.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/netlink.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,41 @@
+#ifndef ZEBRA_NETLINK_H
+#define ZEBRA_NETLINK_H
+
+struct nlsock
+{
+  int sock;
+  int seq;
+  struct sockaddr_nl snl;
+  const char *name;
+  int cmd;
+};
+
+extern struct zebra_t zebrad;
+extern struct zebra_privs_t zserv_privs;
+extern u_int32_t nl_rcvbufsize;
+extern struct thread_master *master;
+
+extern struct message nlmsg_str[];
+
+extern int genetlink_request (int family, int type, struct nlsock *nl);
+extern int netlink_socket (struct nlsock *nl, int proto, unsigned long groups);
+extern int netlink_request (int family, int type, struct nlsock *nl);
+extern int set_netlink_blocking (struct nlsock *nl, int *flags);
+extern int set_netlink_nonblocking (struct nlsock *nl, int *flags);
+extern int netlink_parse_info (int (*filter) (struct nlsock *nl, struct sockaddr_nl *,
+                               struct nlmsghdr *), struct nlsock *nl,
+                               void *a, unsigned int size);
+extern void netlink_parse_rtattr (struct rtattr **tb, int max,
+                                  struct rtattr *rta, int len);
+extern int addattr32 (struct nlmsghdr *n, unsigned int maxlen, int type,
+                      int data);
+extern int addattr_l (struct nlmsghdr *n, unsigned int maxlen, int type,
+                      void *data, int alen);
+extern int rta_addattr_l (struct rtattr *rta, int maxlen, int type,
+                          void *data, int alen);
+extern int netlink_talk_filter (struct nlsock *nl, struct sockaddr_nl *snl, struct nlmsghdr *h);
+extern int netlink_talk (struct nlmsghdr *n, struct nlsock *nl,
+                         void *a, unsigned int size);
+extern char *nexthop_types_desc(int x);
+
+#endif
diff -Naur quagga-0.99.10/zebra/redistribute.c quagga-mpls/zebra/redistribute.c
--- quagga-0.99.10/zebra/redistribute.c	2007-04-10 21:24:45.000000000 +0200
+++ quagga-mpls/zebra/redistribute.c	2008-11-25 12:30:18.000000000 +0100
@@ -166,6 +166,38 @@
 	    && zebra_check_addr (&rn->p))
 	  zsend_route_multipath (ZEBRA_IPV6_ROUTE_ADD, client, &rn->p, newrib);
 #endif /* HAVE_IPV6 */
+
+#ifdef HAVE_MPLS
+  {
+    struct listnode *node;
+    struct zmpls_in_segment *in;
+    struct zmpls_out_segment *out;
+    struct zmpls_ftn *ftn;
+    struct zmpls_xc *xc;
+    struct interface *ifp;
+
+    for (ALL_LIST_ELEMENTS_RO(iflist, node, ifp))
+      if (type == ZEBRA_ROUTE_STATIC &&
+          ifp->mpls_labelspace > -1)
+          zsend_mpls_labelspace_add (client, ifp);
+
+    for (ALL_LIST_ELEMENTS_RO(&mpls_in_segment_list, node, in))
+      if (type == in->owner)
+        zsend_mpls_in_segment_add (client, in);
+
+    for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list, node, out))
+      if (type == out->owner)
+        zsend_mpls_out_segment_add (client, out);
+
+    for (ALL_LIST_ELEMENTS_RO(&mpls_xc_list, node, xc))
+      if (type == xc->owner)
+        zsend_mpls_xc_add (client, xc);
+
+    for (ALL_LIST_ELEMENTS_RO(&mpls_ftn_list, node, ftn))
+      if (type == ftn->owner)
+        zsend_mpls_ftn_add (client, ftn);
+  }
+#endif /* HAVE_MPLS */
 }
 
 void
@@ -174,6 +206,8 @@
   struct listnode *node, *nnode;
   struct zserv *client;
 
+  /* MPLS: check is there are any FTN waiting for this */
+
   for (ALL_LIST_ELEMENTS (zebrad.client_list, node, nnode, client))
     {
       if (is_default (p))
@@ -210,6 +244,8 @@
   if (rib->distance == DISTANCE_INFINITY)
     return;
 
+  /* MPLS: check is there are any FTN depending on this */
+
   for (ALL_LIST_ELEMENTS (zebrad.client_list, node, nnode, client))
     {
       if (is_default (p))
@@ -255,6 +291,7 @@
     case ZEBRA_ROUTE_OSPF:
     case ZEBRA_ROUTE_OSPF6:
     case ZEBRA_ROUTE_BGP:
+    case ZEBRA_ROUTE_LDP:
       if (! client->redist[type])
 	{
 	  client->redist[type] = 1;
@@ -283,6 +320,7 @@
     case ZEBRA_ROUTE_OSPF:
     case ZEBRA_ROUTE_OSPF6:
     case ZEBRA_ROUTE_BGP:
+    case ZEBRA_ROUTE_LDP:
       client->redist[type] = 0;
       break;
     default:
@@ -316,6 +354,29 @@
 
   for (ALL_LIST_ELEMENTS (zebrad.client_list, node, nnode, client))
     zsend_interface_update (ZEBRA_INTERFACE_UP, client, ifp);
+
+#ifdef HAVE_MPLS
+  if (ifp->mpls_labelspace >= 0)
+    mpls_ctrl_set_interface_labelspace(ifp, ifp->mpls_labelspace);
+
+  /* MPLS: check if there are any NHLFE waiting for this */
+  if (if_is_operative(ifp))
+  {
+    struct zmpls_out_segment *out;
+    for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list, node, out))
+    {
+      if ((out->installed) ||
+          !mpls_nexthop_ready(&out->nh))
+        continue;
+
+      out->installed = 1;
+      mpls_ctrl_nhlfe_register(out);
+      redistribute_add_mpls_out_segment (out);
+    }
+  } else {
+    assert(0);
+  }
+#endif /* HAVE_MPLS */
 }
 
 /* Interface down information. */
@@ -328,6 +389,21 @@
   if (IS_ZEBRA_DEBUG_EVENT)
     zlog_debug ("MESSAGE: ZEBRA_INTERFACE_DOWN %s", ifp->name);
 
+#ifdef HAVE_MPLS
+  /* MPLS: check if there are any NHLFE depending on this */
+  struct zmpls_out_segment *out;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list, node, out))
+  {
+    if ((!out->installed) ||
+        mpls_nexthop_ready(&out->nh))
+      continue;
+
+    redistribute_delete_mpls_out_segment (out);
+    mpls_ctrl_nhlfe_unregister(out);
+    out->installed = 0;
+  }
+#endif /* HAVE_MPLS */
+
   for (ALL_LIST_ELEMENTS (zebrad.client_list, node, nnode, client))
     zsend_interface_update (ZEBRA_INTERFACE_DOWN, client, ifp);
 }
@@ -345,6 +421,24 @@
   for (ALL_LIST_ELEMENTS (zebrad.client_list, node, nnode, client))
     if (client->ifinfo)
       zsend_interface_add (client, ifp);
+
+#ifdef HAVE_MPLS
+  /* MPLS: check if there are any NHLFE waiting for this */
+  if (if_is_operative(ifp))
+  {
+    struct zmpls_out_segment *out;
+    for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list, node, out))
+    {
+      if ((out->installed) ||
+          !mpls_nexthop_ready(&out->nh))
+        continue;
+
+      out->installed = 1;
+      mpls_ctrl_nhlfe_register(out);
+      redistribute_add_mpls_out_segment (out);
+    }
+  }
+#endif /* HAVE_MPLS */
 }
 
 void
@@ -356,6 +450,21 @@
   if (IS_ZEBRA_DEBUG_EVENT)
     zlog_debug ("MESSAGE: ZEBRA_INTERFACE_DELETE %s", ifp->name);
 
+#ifdef HAVE_MPLS
+  /* MPLS: check if there are any NHLFE depending on this */
+  struct zmpls_out_segment *out;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list, node, out))
+  {
+    if ((!out->installed) ||
+        mpls_nexthop_ready(&out->nh))
+      continue;
+
+    out->installed = 0;
+    redistribute_delete_mpls_out_segment (out);
+    mpls_ctrl_nhlfe_unregister(out);
+  }
+#endif /* HAVE_MPLS */
+
   for (ALL_LIST_ELEMENTS (zebrad.client_list, node, nnode, client))
     if (client->ifinfo)
       zsend_interface_delete (client, ifp);
@@ -379,11 +488,29 @@
 		  p->prefixlen, ifc->ifp->name);
     }
 
-  router_id_add_address(ifc);
-
   for (ALL_LIST_ELEMENTS (zebrad.client_list, node, nnode, client))
     if (client->ifinfo && CHECK_FLAG (ifc->conf, ZEBRA_IFC_REAL))
       zsend_interface_address (ZEBRA_INTERFACE_ADDRESS_ADD, client, ifp, ifc);
+
+  router_id_add_address(ifc);
+
+#ifdef HAVE_MPLS
+  /* MPLS: check if there are any NHLFE waiting for this */
+  if (if_is_operative(ifp))
+  {
+    struct zmpls_out_segment *out;
+    for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list, node, out))
+    {
+      if ((out->installed) ||
+          !mpls_nexthop_ready(&out->nh))
+        continue;
+
+      out->installed = 1;
+      mpls_ctrl_nhlfe_register(out);
+      redistribute_add_mpls_out_segment (out);
+    }
+  }
+#endif /* HAVE_MPLS */
 }
 
 /* Interface address deletion. */
@@ -404,9 +531,240 @@
 		 p->prefixlen, ifc->ifp->name);
     }
 
+#ifdef HAVE_MPLS
+  /* MPLS: check if there are any NHLFE depending on this */
+  struct zmpls_out_segment *out;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_out_segment_list, node, out))
+  {
+    if ((!out->installed) ||
+        mpls_nexthop_ready(&out->nh))
+      continue;
+
+    redistribute_delete_mpls_out_segment (out);
+    mpls_ctrl_nhlfe_unregister(out);
+    out->installed = 0;
+  }
+#endif /* HAVE_MPLS */
+
   router_id_del_address(ifc);
 
   for (ALL_LIST_ELEMENTS (zebrad.client_list, node, nnode, client))
     if (client->ifinfo && CHECK_FLAG (ifc->conf, ZEBRA_IFC_REAL))
       zsend_interface_address (ZEBRA_INTERFACE_ADDRESS_DELETE, client, ifp, ifc);
 }
+
+#ifdef HAVE_MPLS
+void
+redistribute_add_mpls_xc (struct zmpls_xc *xc)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  /* Check to see and and ILM are waiting for this xc */
+  struct zmpls_in_segment *in;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_in_segment_list, node, in))
+  {
+    if (in->installed || in->xc != xc->index)
+      continue;
+
+    in->installed = 1;
+    mpls_ctrl_ilm_register (in);
+    redistribute_add_mpls_in_segment (in);
+  }
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[xc->owner])
+	zsend_mpls_xc_add (client, xc);
+}
+
+void
+redistribute_delete_mpls_xc (struct zmpls_xc *xc)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[xc->owner])
+	zsend_mpls_xc_delete (client, xc);
+
+  /* Check to see and and ILM depend on this xc */
+  struct zmpls_in_segment *in;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_in_segment_list, node, in))
+  {
+    if ((!in->installed) || in->xc != xc->index)
+      continue;
+
+    in->installed = 0;
+    mpls_ctrl_ilm_unregister (in);
+    redistribute_delete_mpls_in_segment (in);
+  }
+}
+
+void
+redistribute_add_mpls_in_segment (struct zmpls_in_segment *in)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  /* MPLS: check is there are any XC waiting for this */
+  struct zmpls_xc *xc;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_xc_list, node, xc))
+  {
+    struct zmpls_out_segment *out;
+    struct zmpls_in_segment tmp;
+
+    tmp.labelspace = xc->in_labelspace;
+    memcpy(&tmp.label, &xc->in_label, sizeof(struct zmpls_label));
+
+    if (xc->installed || !mpls_in_segment_match(in, &tmp))
+      continue;
+
+    out = mpls_out_segment_find (xc->out_index);
+
+    xc->installed = 1;
+    mpls_ctrl_xc_register (in, out);
+    redistribute_add_mpls_xc (xc);
+  }
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[in->owner])
+	zsend_mpls_in_segment_add (client, in);
+}
+
+void
+redistribute_delete_mpls_in_segment (struct zmpls_in_segment *in)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[in->owner])
+	zsend_mpls_in_segment_delete (client, in);
+
+  /* MPLS: check is there are any XC depending on this */
+  struct zmpls_xc *xc;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_xc_list, node, xc))
+  {
+    struct zmpls_out_segment *out;
+    struct zmpls_in_segment tmp;
+
+    tmp.labelspace = xc->in_labelspace;
+    memcpy(&tmp.label, &xc->in_label, sizeof(struct zmpls_label));
+
+    if ((!xc->installed) || !mpls_in_segment_match(in, &tmp))
+      continue;
+
+    out = mpls_out_segment_find (xc->out_index);
+
+    xc->installed = 0;
+    mpls_ctrl_xc_unregister (in, out);
+    redistribute_delete_mpls_xc (xc);
+  }
+}
+
+void
+redistribute_add_mpls_out_segment (struct zmpls_out_segment *out)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  /* MPLS: check is there are any FTN waiting for this */
+  /* MPLS: check is there are any XC waiting for this */
+  struct zmpls_xc *xc;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_xc_list, node, xc))
+  {
+    struct zmpls_in_segment tmp;
+    struct zmpls_in_segment *in;
+
+    if (xc->installed || xc->out_index != out->index)
+      continue;
+
+    tmp.labelspace = xc->in_labelspace;
+    memcpy(&tmp.label, &xc->in_label, sizeof(struct zmpls_label));
+    in = mpls_in_segment_find (&tmp);
+
+    xc->installed = 1;
+    redistribute_add_mpls_xc (xc);
+    mpls_ctrl_xc_register (in, out);
+  }
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[out->owner])
+	zsend_mpls_out_segment_add (client, out);
+}
+
+void
+redistribute_delete_mpls_out_segment (struct zmpls_out_segment *out)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[out->owner])
+	zsend_mpls_out_segment_delete (client, out);
+
+  /* MPLS: check is there are any FTN depending on this */
+  /* MPLS: check is there are any XC depending on this */
+  struct zmpls_xc *xc;
+  for (ALL_LIST_ELEMENTS_RO(&mpls_xc_list, node, xc))
+  {
+    struct zmpls_in_segment tmp;
+    struct zmpls_in_segment *in;
+
+    if ((!xc->installed) || xc->out_index != out->index)
+      continue;
+
+    tmp.labelspace = xc->in_labelspace;
+    memcpy(&tmp.label, &xc->in_label, sizeof(struct zmpls_label));
+    in = mpls_in_segment_find (&tmp);
+
+    xc->installed = 0;
+    mpls_ctrl_xc_unregister (in, out);
+    redistribute_delete_mpls_xc (xc);
+  }
+}
+
+void
+redistribute_add_mpls_labelspace (struct interface *ifp)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[ZEBRA_ROUTE_STATIC])
+	zsend_mpls_labelspace_add (client, ifp);
+}
+
+void
+redistribute_delete_mpls_labelspace (struct interface *ifp)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[ZEBRA_ROUTE_STATIC])
+	zsend_mpls_labelspace_delete (client, ifp);
+}
+
+void
+redistribute_add_mpls_ftn (struct zmpls_ftn *ftn)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[ftn->owner])
+	zsend_mpls_ftn_add (client, ftn);
+}
+
+void
+redistribute_delete_mpls_ftn (struct zmpls_ftn *ftn)
+{
+  struct listnode *node;
+  struct zserv *client;
+
+  for (ALL_LIST_ELEMENTS_RO(zebrad.client_list, node, client))
+     if (client->redist[ftn->owner])
+	zsend_mpls_ftn_delete (client, ftn);
+}
+#endif /* HAVE_MPLS */
diff -Naur quagga-0.99.10/zebra/redistribute.h quagga-mpls/zebra/redistribute.h
--- quagga-0.99.10/zebra/redistribute.h	2007-04-10 21:24:45.000000000 +0200
+++ quagga-mpls/zebra/redistribute.h	2008-11-25 12:30:18.000000000 +0100
@@ -47,6 +47,17 @@
 						   struct connected *c);
 
 extern int zebra_check_addr (struct prefix *);
+#ifdef HAVE_MPLS
+void redistribute_add_mpls_xc (struct zmpls_xc *xc);
+void redistribute_delete_mpls_xc (struct zmpls_xc *xc);
+void redistribute_add_mpls_ftn (struct zmpls_ftn *ftn);
+void redistribute_delete_mpls_ftn (struct zmpls_ftn *ftn);
+void redistribute_add_mpls_in_segment (struct zmpls_in_segment *in);
+void redistribute_delete_mpls_in_segment (struct zmpls_in_segment *in);
+void redistribute_add_mpls_out_segment (struct zmpls_out_segment *out);
+void redistribute_delete_mpls_out_segment (struct zmpls_out_segment *out);
+void redistribute_add_mpls_labelspace (struct interface *ifp);
+void redistribute_delete_mpls_labelspace (struct interface *ifp);
+#endif
 
 #endif /* _ZEBRA_REDISTRIBUTE_H */
-
diff -Naur quagga-0.99.10/zebra/rib.h quagga-mpls/zebra/rib.h
--- quagga-0.99.10/zebra/rib.h	2008-06-07 22:25:16.000000000 +0200
+++ quagga-mpls/zebra/rib.h	2008-11-25 12:30:18.000000000 +0100
@@ -24,9 +24,12 @@
 #define _ZEBRA_RIB_H
 
 #include "prefix.h"
+#include "zclient.h"
 
 #define DISTANCE_INFINITY  255
 
+#include "table.h"
+
 /* Routing information base. */
 
 union g_addr {
@@ -71,7 +74,7 @@
    * This flag's definition is in lib/zebra.h ZEBRA_FLAG_* and is exposed
    * to clients via Zserv
    */
-  u_char flags;
+  u_short flags;
 
   /* RIB internal status */
   u_char status;
@@ -98,77 +101,15 @@
 };
 
 /* Static route information. */
-struct static_ipv4
-{
-  /* For linked list. */
-  struct static_ipv4 *prev;
-  struct static_ipv4 *next;
-
-  /* Administrative distance. */
-  u_char distance;
-
-  /* Flag for this static route's type. */
-  u_char type;
-#define STATIC_IPV4_GATEWAY     1
-#define STATIC_IPV4_IFNAME      2
-#define STATIC_IPV4_BLACKHOLE   3
-
-  /* Nexthop value. */
-  union 
-  {
-    struct in_addr ipv4;
-    char *ifname;
-  } gate;
-
-  /* bit flags */
-  u_char flags;
-/*
- see ZEBRA_FLAG_REJECT
-     ZEBRA_FLAG_BLACKHOLE
- */
-};
-
-#ifdef HAVE_IPV6
-/* Static route information. */
-struct static_ipv6
+struct static_route
 {
   /* For linked list. */
-  struct static_ipv6 *prev;
-  struct static_ipv6 *next;
+  struct static_route *prev;
+  struct static_route *next;
 
   /* Administrative distance. */
   u_char distance;
-
-  /* Flag for this static route's type. */
-  u_char type;
-#define STATIC_IPV6_GATEWAY          1
-#define STATIC_IPV6_GATEWAY_IFNAME   2
-#define STATIC_IPV6_IFNAME           3
-
-  /* Nexthop value. */
-  struct in6_addr ipv6;
-  char *ifname;
-
-  /* bit flags */
-  u_char flags;
-/*
- see ZEBRA_FLAG_REJECT
-     ZEBRA_FLAG_BLACKHOLE
- */
-};
-#endif /* HAVE_IPV6 */
-
-enum nexthop_types_t
-{
-  NEXTHOP_TYPE_IFINDEX = 1,      /* Directly connected.  */
-  NEXTHOP_TYPE_IFNAME,           /* Interface route.  */
-  NEXTHOP_TYPE_IPV4,             /* IPv4 nexthop.  */
-  NEXTHOP_TYPE_IPV4_IFINDEX,     /* IPv4 nexthop with ifindex.  */
-  NEXTHOP_TYPE_IPV4_IFNAME,      /* IPv4 nexthop with ifname.  */
-  NEXTHOP_TYPE_IPV6,             /* IPv6 nexthop.  */
-  NEXTHOP_TYPE_IPV6_IFINDEX,     /* IPv6 nexthop with ifindex.  */
-  NEXTHOP_TYPE_IPV6_IFNAME,      /* IPv6 nexthop with ifname.  */
-  NEXTHOP_TYPE_BLACKHOLE,        /* Null0 nexthop.  */
+  struct zapi_nexthop nh;
 };
 
 /* Nexthop structure. */
@@ -176,17 +117,24 @@
 {
   struct nexthop *next;
   struct nexthop *prev;
+  struct nexthop *tied;
 
   /* Interface index. */
   char *ifname;
   unsigned int ifindex;
   
-  enum nexthop_types_t type;
+  unsigned int mpls;
+  unsigned int type;
+  unsigned int advmss;
 
   u_char flags;
 #define NEXTHOP_FLAG_ACTIVE     (1 << 0) /* This nexthop is alive. */
 #define NEXTHOP_FLAG_FIB        (1 << 1) /* FIB nexthop. */
 #define NEXTHOP_FLAG_RECURSIVE  (1 << 2) /* Recursive nexthop. */
+#define NEXTHOP_FLAG_IGNORE     (1 << 3) /* Ignore this nexthop */
+
+  /* the type of drop (REJECT, BLACKHOLE, NULL) */
+  u_char drop;
 
   /* Nexthop address or interface name. */
   union g_addr gate;
@@ -196,6 +144,7 @@
   unsigned int rifindex;
   union g_addr rgate;
   union g_addr src;
+  unsigned int rmpls;
 };
 
 /* Routing table instance.  */
@@ -220,86 +169,72 @@
   struct route_table *stable[AFI_MAX][SAFI_MAX];
 };
 
-extern struct nexthop *nexthop_ifindex_add (struct rib *, unsigned int);
-extern struct nexthop *nexthop_ifname_add (struct rib *, char *);
-extern struct nexthop *nexthop_blackhole_add (struct rib *);
-extern struct nexthop *nexthop_ipv4_add (struct rib *, struct in_addr *,
-					 struct in_addr *);
+extern void
+nexthop_delete (struct rib *rib, struct nexthop *nexthop);
+
+extern void
+nexthop_free (struct nexthop *nexthop);
+
+extern struct nexthop *nexthop_zapi_nexthop_add(struct rib *rib,
+  struct zapi_nexthop* znh);
+extern void zapi_nexthop2nexthop(struct zapi_nexthop* znh, struct nexthop *nh);
+
 extern void rib_lookup_and_dump (struct prefix_ipv4 *);
 extern void rib_lookup_and_pushup (struct prefix_ipv4 *);
 extern void rib_dump (const char *, const struct prefix_ipv4 *, const struct rib *);
-extern int rib_lookup_ipv4_route (struct prefix_ipv4 *, union sockunion *);
+extern int rib_lookup_route_nexthop (struct prefix *, struct zapi_nexthop *);
 #define ZEBRA_RIB_LOOKUP_ERROR -1
 #define ZEBRA_RIB_FOUND_EXACT 0
 #define ZEBRA_RIB_FOUND_NOGATE 1
 #define ZEBRA_RIB_FOUND_CONNECTED 2
 #define ZEBRA_RIB_NOTFOUND 3
 
-#ifdef HAVE_IPV6
-extern struct nexthop *nexthop_ipv6_add (struct rib *, struct in6_addr *);
-#endif /* HAVE_IPV6 */
-
 extern struct vrf *vrf_lookup (u_int32_t);
 extern struct route_table *vrf_table (afi_t afi, safi_t safi, u_int32_t id);
 extern struct route_table *vrf_static_table (afi_t afi, safi_t safi, u_int32_t id);
 
 /* NOTE:
- * All rib_add_ipv[46]* functions will not just add prefix into RIB, but
+ * All rib_add_route function will not just add prefix into RIB, but
  * also implicitly withdraw equal prefix of same type. */
-extern int rib_add_ipv4 (int type, int flags, struct prefix_ipv4 *p, 
-			 struct in_addr *gate, struct in_addr *src,
-			 unsigned int ifindex, u_int32_t vrf_id,
-			 u_int32_t, u_char);
+extern int rib_add_route (int type, int flags, struct prefix *p, 
+			  struct zapi_nexthop *nh, u_int32_t vrf_id,
+			  u_int32_t, u_char);
 
-extern int rib_add_ipv4_multipath (struct prefix_ipv4 *, struct rib *);
+extern int rib_delete_route (int type, int flags, struct prefix *p,
+			     struct zapi_nexthop *nh, u_int32_t);
+extern int
+rib_find_nexthop2 (int owner, struct rib *rib_in, struct nexthop *nh_in,
+		   struct rib **rib_out, struct nexthop **nh_out);
+
+extern int
+rib_find_nexthop (int owner, struct prefix *p_in, struct nexthop *nh_in,
+		  struct route_node **rn_out, struct rib **rib_out,
+		  struct nexthop **nh_out);
 
-extern int rib_delete_ipv4 (int type, int flags, struct prefix_ipv4 *p,
-		            struct in_addr *gate, unsigned int ifindex, 
-		            u_int32_t);
+extern int rib_add_multipath (struct prefix *, struct rib *);
 
-extern struct rib *rib_match_ipv4 (struct in_addr);
+extern struct rib *rib_match_route (struct prefix *p);
 
-extern struct rib *rib_lookup_ipv4 (struct prefix_ipv4 *);
+extern struct rib *rib_lookup_route (struct prefix *);
 
+extern int rib_check_drop (struct rib *);
 extern void rib_update (void);
 extern void rib_weed_tables (void);
 extern void rib_sweep_route (void);
 extern void rib_close (void);
 extern void rib_init (void);
+extern int rib_uninstall_kernel (struct route_node *rn, struct rib *rib);
 
 extern int
-static_add_ipv4 (struct prefix *p, struct in_addr *gate, const char *ifname,
-       u_char flags, u_char distance, u_int32_t vrf_id);
+static_add_route (struct prefix *p, struct zapi_nexthop *nh,
+		  u_char distance, u_int32_t vrf_id);
 
 extern int
-static_delete_ipv4 (struct prefix *p, struct in_addr *gate, const char *ifname,
-		    u_char distance, u_int32_t vrf_id);
+static_delete_route (struct prefix *p, struct zapi_nexthop *nh,
+		     u_char distance, u_int32_t vrf_id);
 
 #ifdef HAVE_IPV6
-extern int
-rib_add_ipv6 (int type, int flags, struct prefix_ipv6 *p,
-	      struct in6_addr *gate, unsigned int ifindex, u_int32_t vrf_id,
-	      u_int32_t metric, u_char distance);
-
-extern int
-rib_delete_ipv6 (int type, int flags, struct prefix_ipv6 *p,
-		 struct in6_addr *gate, unsigned int ifindex, u_int32_t vrf_id);
-
-extern struct rib *rib_lookup_ipv6 (struct in6_addr *);
-
-extern struct rib *rib_match_ipv6 (struct in6_addr *);
-
 extern struct route_table *rib_table_ipv6;
-
-extern int
-static_add_ipv6 (struct prefix *p, u_char type, struct in6_addr *gate,
-		 const char *ifname, u_char flags, u_char distance,
-		 u_int32_t vrf_id);
-
-extern int
-static_delete_ipv6 (struct prefix *p, u_char type, struct in6_addr *gate,
-		    const char *ifname, u_char distance, u_int32_t vrf_id);
-
 #endif /* HAVE_IPV6 */
 
 #endif /*_ZEBRA_RIB_H */
diff -Naur quagga-0.99.10/zebra/rt_ioctl.c quagga-mpls/zebra/rt_ioctl.c
--- quagga-0.99.10/zebra/rt_ioctl.c	2007-05-10 04:38:52.000000000 +0200
+++ quagga-mpls/zebra/rt_ioctl.c	2008-11-25 12:30:18.000000000 +0100
@@ -206,8 +206,7 @@
 	{
 	  if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_RECURSIVE))
 	    {
-	      if (nexthop->rtype == NEXTHOP_TYPE_IPV4 ||
-		  nexthop->rtype == NEXTHOP_TYPE_IPV4_IFINDEX)
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
 		{
 		  sin_gate.sin_family = AF_INET;
 #ifdef HAVE_STRUCT_SOCKADDR_IN_SIN_LEN
@@ -216,8 +215,16 @@
 		  sin_gate.sin_addr = nexthop->rgate.ipv4;
 		  rtentry.rt_flags |= RTF_GATEWAY;
 		}
-	      if (nexthop->rtype == NEXTHOP_TYPE_IFINDEX
-		  || nexthop->rtype == NEXTHOP_TYPE_IFNAME)
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
+		{
+		  assert (0);
+		}
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_DROP))
+		{
+		  SET_FLAG (rtentry.rt_flags, RTF_REJECT);
+		}
+
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFINDEX))
 		{
 		  ifp = if_lookup_by_index (nexthop->rifindex);
 		  if (ifp)
@@ -225,11 +232,14 @@
 		  else
 		    return -1;
 		}
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFNAME))
+		{
+		  assert (0);
+		}
 	    }
 	  else
 	    {
-	      if (nexthop->type == NEXTHOP_TYPE_IPV4 ||
-		  nexthop->type == NEXTHOP_TYPE_IPV4_IFINDEX)
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
 		{
 		  sin_gate.sin_family = AF_INET;
 #ifdef HAVE_STRUCT_SOCKADDR_IN_SIN_LEN
@@ -238,8 +248,16 @@
 		  sin_gate.sin_addr = nexthop->gate.ipv4;
 		  rtentry.rt_flags |= RTF_GATEWAY;
 		}
-	      if (nexthop->type == NEXTHOP_TYPE_IFINDEX
-		  || nexthop->type == NEXTHOP_TYPE_IFNAME)
+	      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
+		{
+		  assert (0);
+		}
+	      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
+		{
+		  SET_FLAG (rtentry.rt_flags, RTF_REJECT);
+		}
+
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
 		{
 		  ifp = if_lookup_by_index (nexthop->ifindex);
 		  if (ifp)
@@ -247,6 +265,10 @@
 		  else
 		    return -1;
 		}
+	      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+		{
+		  assert (0);
+		}
 	    }
 
 	  if (cmd == SIOCADDRT)
@@ -465,17 +487,21 @@
 	{
 	  if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_RECURSIVE))
 	    {
-	      if (nexthop->rtype == NEXTHOP_TYPE_IPV6
-		  || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFNAME
-		  || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFINDEX)
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
 		{
 		  memcpy (&rtm.rtmsg_gateway, &nexthop->rgate.ipv6,
 			  sizeof (struct in6_addr));
 		}
-	      if (nexthop->rtype == NEXTHOP_TYPE_IFINDEX
-		  || nexthop->rtype == NEXTHOP_TYPE_IFNAME
-		  || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFNAME
-		  || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFINDEX)
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
+		{
+		  assert (0);
+		}
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_DROP))
+		{
+		  SET_FLAG (rtentry.rt_flags, RTF_REJECT);
+		}
+
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFINDEX))
 		rtm.rtmsg_ifindex = nexthop->rifindex;
 	      else
 		rtm.rtmsg_ifindex = 0;
@@ -483,17 +509,21 @@
 	    }
 	  else
 	    {
-	      if (nexthop->type == NEXTHOP_TYPE_IPV6
-		  || nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME
-		  || nexthop->type == NEXTHOP_TYPE_IPV6_IFINDEX)
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
 		{
 		  memcpy (&rtm.rtmsg_gateway, &nexthop->gate.ipv6,
 			  sizeof (struct in6_addr));
 		}
-	      if (nexthop->type == NEXTHOP_TYPE_IFINDEX
-		  || nexthop->type == NEXTHOP_TYPE_IFNAME
-		  || nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME
-		  || nexthop->type == NEXTHOP_TYPE_IPV6_IFINDEX)
+	      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
+		{
+		  assert (0);
+		}
+	      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
+		{
+		  SET_FLAG (rtentry.rt_flags, RTF_REJECT);
+		}
+
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
 		rtm.rtmsg_ifindex = nexthop->ifindex;
 	      else
 		rtm.rtmsg_ifindex = 0;
diff -Naur quagga-0.99.10/zebra/rt_netlink.c quagga-mpls/zebra/rt_netlink.c
--- quagga-0.99.10/zebra/rt_netlink.c	2008-05-29 20:20:34.000000000 +0200
+++ quagga-mpls/zebra/rt_netlink.c	2008-11-25 12:30:18.000000000 +0100
@@ -35,56 +35,26 @@
 #include "rib.h"
 #include "thread.h"
 #include "privs.h"
+#ifdef HAVE_MPLS
+#include "mpls_lib.h"
+#ifdef LINUX_MPLS
+#include <linux/shim.h>
+#endif
+#endif /* HAVE_MPLS */
 
+#include "zebra/rt.h"
 #include "zebra/zserv.h"
 #include "zebra/rt.h"
 #include "zebra/redistribute.h"
 #include "zebra/interface.h"
 #include "zebra/debug.h"
+#include "zebra/netlink.h"
+#include "zebra/rt_netlink.h"
 
 /* Socket interface to kernel */
-struct nlsock
-{
-  int sock;
-  int seq;
-  struct sockaddr_nl snl;
-  const char *name;
-} netlink      = { -1, 0, {0}, "netlink-listen"},     /* kernel messages */
-  netlink_cmd  = { -1, 0, {0}, "netlink-cmd"};        /* command channel */
-
-struct message nlmsg_str[] = {
-  {RTM_NEWROUTE, "RTM_NEWROUTE"},
-  {RTM_DELROUTE, "RTM_DELROUTE"},
-  {RTM_GETROUTE, "RTM_GETROUTE"},
-  {RTM_NEWLINK,  "RTM_NEWLINK"},
-  {RTM_DELLINK,  "RTM_DELLINK"},
-  {RTM_GETLINK,  "RTM_GETLINK"},
-  {RTM_NEWADDR,  "RTM_NEWADDR"},
-  {RTM_DELADDR,  "RTM_DELADDR"},
-  {RTM_GETADDR,  "RTM_GETADDR"},
-  {0, NULL}
-};
-
-const char *nexthop_types_desc[] =  
-{
-  "none",
-  "Directly connected",
-  "Interface route",
-  "IPv4 nexthop",
-  "IPv4 nexthop with ifindex",
-  "IPv4 nexthop with ifname",
-  "IPv6 nexthop",
-  "IPv6 nexthop with ifindex",
-  "IPv6 nexthop with ifname",
-  "Null0 nexthop",
-};
-
-
-extern struct zebra_t zebrad;
-
-extern struct zebra_privs_t zserv_privs;
-
-extern u_int32_t nl_rcvbufsize;
+static struct nlsock
+  netlink      = { -1, 0, {0}, "netlink-listen", 0},	/* kernel messages */
+  netlink_cmd  = { -1, 0, {0}, "netlink-cmd", 1};	/* command channel */
 
 /* Note: on netlink systems, there should be a 1-to-1 mapping between interface
    names and ifindex values. */
@@ -113,388 +83,10 @@
   ifp->ifindex = ifi_index;
 }
 
-/* Make socket for Linux netlink interface. */
-static int
-netlink_socket (struct nlsock *nl, unsigned long groups)
-{
-  int ret;
-  struct sockaddr_nl snl;
-  int sock;
-  int namelen;
-  int save_errno;
-
-  sock = socket (AF_NETLINK, SOCK_RAW, NETLINK_ROUTE);
-  if (sock < 0)
-    {
-      zlog (NULL, LOG_ERR, "Can't open %s socket: %s", nl->name,
-            safe_strerror (errno));
-      return -1;
-    }
-
-  ret = fcntl (sock, F_SETFL, O_NONBLOCK);
-  if (ret < 0)
-    {
-      zlog (NULL, LOG_ERR, "Can't set %s socket flags: %s", nl->name,
-            safe_strerror (errno));
-      close (sock);
-      return -1;
-    }
-
-  /* Set receive buffer size if it's set from command line */
-  if (nl_rcvbufsize)
-    {
-      u_int32_t oldsize, oldlen;
-      u_int32_t newsize, newlen;
-
-      oldlen = sizeof(oldsize);
-      newlen = sizeof(newsize);
-
-      ret = getsockopt(sock, SOL_SOCKET, SO_RCVBUF, &oldsize, &oldlen);
-      if (ret < 0)
-	{
-	  zlog (NULL, LOG_ERR, "Can't get %s receive buffer size: %s", nl->name,
-		safe_strerror (errno));
-	  close (sock);
-	  return -1;
-	}
-
-      ret = setsockopt(sock, SOL_SOCKET, SO_RCVBUF, &nl_rcvbufsize,
-		       sizeof(nl_rcvbufsize));
-      if (ret < 0)
-	{
-	  zlog (NULL, LOG_ERR, "Can't set %s receive buffer size: %s", nl->name,
-		safe_strerror (errno));
-	  close (sock);
-	  return -1;
-	}
-
-      ret = getsockopt(sock, SOL_SOCKET, SO_RCVBUF, &newsize, &newlen);
-      if (ret < 0)
-	{
-	  zlog (NULL, LOG_ERR, "Can't get %s receive buffer size: %s", nl->name,
-		safe_strerror (errno));
-	  close (sock);
-	  return -1;
-	}
-
-      zlog (NULL, LOG_INFO,
-	    "Setting netlink socket receive buffer size: %u -> %u",
-	    oldsize, newsize);
-    }
-
-  memset (&snl, 0, sizeof snl);
-  snl.nl_family = AF_NETLINK;
-  snl.nl_groups = groups;
-
-  /* Bind the socket to the netlink structure for anything. */
-  if (zserv_privs.change (ZPRIVS_RAISE))
-    {
-      zlog (NULL, LOG_ERR, "Can't raise privileges");
-      return -1;
-    }
-
-  ret = bind (sock, (struct sockaddr *) &snl, sizeof snl);
-  save_errno = errno;
-  if (zserv_privs.change (ZPRIVS_LOWER))
-    zlog (NULL, LOG_ERR, "Can't lower privileges");
-
-  if (ret < 0)
-    {
-      zlog (NULL, LOG_ERR, "Can't bind %s socket to group 0x%x: %s",
-            nl->name, snl.nl_groups, safe_strerror (save_errno));
-      close (sock);
-      return -1;
-    }
-
-  /* multiple netlink sockets will have different nl_pid */
-  namelen = sizeof snl;
-  ret = getsockname (sock, (struct sockaddr *) &snl, (socklen_t *) &namelen);
-  if (ret < 0 || namelen != sizeof snl)
-    {
-      zlog (NULL, LOG_ERR, "Can't get %s socket name: %s", nl->name,
-            safe_strerror (errno));
-      close (sock);
-      return -1;
-    }
-
-  nl->snl = snl;
-  nl->sock = sock;
-  return ret;
-}
-
-int
-set_netlink_blocking (struct nlsock *nl, int *flags)
-{
-
-  /* Change socket flags for blocking I/O.  */
-  if ((*flags = fcntl (nl->sock, F_GETFL, 0)) < 0)
-    {
-      zlog (NULL, LOG_ERR, "%s:%i F_GETFL error: %s",
-            __FUNCTION__, __LINE__, safe_strerror (errno));
-      return -1;
-    }
-  *flags &= ~O_NONBLOCK;
-  if (fcntl (nl->sock, F_SETFL, *flags) < 0)
-    {
-      zlog (NULL, LOG_ERR, "%s:%i F_SETFL error: %s",
-            __FUNCTION__, __LINE__, safe_strerror (errno));
-      return -1;
-    }
-  return 0;
-}
-
-int
-set_netlink_nonblocking (struct nlsock *nl, int *flags)
-{
-  /* Restore socket flags for nonblocking I/O */
-  *flags |= O_NONBLOCK;
-  if (fcntl (nl->sock, F_SETFL, *flags) < 0)
-    {
-      zlog (NULL, LOG_ERR, "%s:%i F_SETFL error: %s",
-            __FUNCTION__, __LINE__, safe_strerror (errno));
-      return -1;
-    }
-  return 0;
-}
-
-/* Get type specified information from netlink. */
-static int
-netlink_request (int family, int type, struct nlsock *nl)
-{
-  int ret;
-  struct sockaddr_nl snl;
-  int save_errno;
-
-  struct
-  {
-    struct nlmsghdr nlh;
-    struct rtgenmsg g;
-  } req;
-
-
-  /* Check netlink socket. */
-  if (nl->sock < 0)
-    {
-      zlog (NULL, LOG_ERR, "%s socket isn't active.", nl->name);
-      return -1;
-    }
-
-  memset (&snl, 0, sizeof snl);
-  snl.nl_family = AF_NETLINK;
-
-  memset (&req, 0, sizeof req);
-  req.nlh.nlmsg_len = sizeof req;
-  req.nlh.nlmsg_type = type;
-  req.nlh.nlmsg_flags = NLM_F_ROOT | NLM_F_MATCH | NLM_F_REQUEST;
-  req.nlh.nlmsg_pid = 0;
-  req.nlh.nlmsg_seq = ++nl->seq;
-  req.g.rtgen_family = family;
-
-  /* linux appears to check capabilities on every message 
-   * have to raise caps for every message sent
-   */
-  if (zserv_privs.change (ZPRIVS_RAISE))
-    {
-      zlog (NULL, LOG_ERR, "Can't raise privileges");
-      return -1;
-    }
-
-  ret = sendto (nl->sock, (void *) &req, sizeof req, 0,
-                (struct sockaddr *) &snl, sizeof snl);
-  save_errno = errno;
-
-  if (zserv_privs.change (ZPRIVS_LOWER))
-    zlog (NULL, LOG_ERR, "Can't lower privileges");
-
-  if (ret < 0)
-    {
-      zlog (NULL, LOG_ERR, "%s sendto failed: %s", nl->name,
-            safe_strerror (save_errno));
-      return -1;
-    }
-
-  return 0;
-}
-
-/* Receive message from netlink interface and pass those information
-   to the given function. */
-static int
-netlink_parse_info (int (*filter) (struct sockaddr_nl *, struct nlmsghdr *),
-                    struct nlsock *nl)
-{
-  int status;
-  int ret = 0;
-  int error;
-
-  while (1)
-    {
-      char buf[4096];
-      struct iovec iov = { buf, sizeof buf };
-      struct sockaddr_nl snl;
-      struct msghdr msg = { (void *) &snl, sizeof snl, &iov, 1, NULL, 0, 0 };
-      struct nlmsghdr *h;
-      int save_errno;
-
-      if (zserv_privs.change (ZPRIVS_RAISE))
-        zlog (NULL, LOG_ERR, "Can't raise privileges");
-
-      status = recvmsg (nl->sock, &msg, 0);
-      save_errno = errno;
-
-      if (zserv_privs.change (ZPRIVS_LOWER))
-        zlog (NULL, LOG_ERR, "Can't lower privileges");
-
-      if (status < 0)
-        {
-          if (save_errno == EINTR)
-            continue;
-          if (save_errno == EWOULDBLOCK || save_errno == EAGAIN)
-            break;
-          zlog (NULL, LOG_ERR, "%s recvmsg overrun: %s",
-	  	nl->name, safe_strerror(save_errno));
-          continue;
-        }
-
-      if (status == 0)
-        {
-          zlog (NULL, LOG_ERR, "%s EOF", nl->name);
-          return -1;
-        }
-
-      if (msg.msg_namelen != sizeof snl)
-        {
-          zlog (NULL, LOG_ERR, "%s sender address length error: length %d",
-                nl->name, msg.msg_namelen);
-          return -1;
-        }
-      
-      /* JF: Ignore messages that aren't from the kernel */
-      if ( snl.nl_pid != 0 )
-        {
-          zlog ( NULL, LOG_ERR, "Ignoring message from pid %u", snl.nl_pid );
-          continue;
-        }
-
-      for (h = (struct nlmsghdr *) buf; NLMSG_OK (h, (unsigned int) status);
-           h = NLMSG_NEXT (h, status))
-        {
-          /* Finish of reading. */
-          if (h->nlmsg_type == NLMSG_DONE)
-            return ret;
-
-          /* Error handling. */
-          if (h->nlmsg_type == NLMSG_ERROR)
-            {
-              struct nlmsgerr *err = (struct nlmsgerr *) NLMSG_DATA (h);
-
-              /* If the error field is zero, then this is an ACK */
-              if (err->error == 0)
-                {
-                  if (IS_ZEBRA_DEBUG_KERNEL)
-                    {
-                      zlog_debug ("%s: %s ACK: type=%s(%u), seq=%u, pid=%u",
-                                 __FUNCTION__, nl->name,
-                                 lookup (nlmsg_str, err->msg.nlmsg_type),
-                                 err->msg.nlmsg_type, err->msg.nlmsg_seq,
-                                 err->msg.nlmsg_pid);
-                    }
-
-                  /* return if not a multipart message, otherwise continue */
-                  if (!(h->nlmsg_flags & NLM_F_MULTI))
-                    {
-                      return 0;
-                    }
-                  continue;
-                }
-
-              if (h->nlmsg_len < NLMSG_LENGTH (sizeof (struct nlmsgerr)))
-                {
-                  zlog (NULL, LOG_ERR, "%s error: message truncated",
-                        nl->name);
-                  return -1;
-                }
-
-              /* Deal with Error Noise  - MAG */
-              {
-                int loglvl = LOG_ERR;
-                int errnum = err->error;
-                int msg_type = err->msg.nlmsg_type;
-
-                if (nl == &netlink_cmd
-                    && (-errnum == ENODEV || -errnum == ESRCH)
-                    && (msg_type == RTM_NEWROUTE || msg_type == RTM_DELROUTE))
-                  loglvl = LOG_DEBUG;
-
-                zlog (NULL, loglvl, "%s error: %s, type=%s(%u), "
-                      "seq=%u, pid=%u",
-                      nl->name, safe_strerror (-errnum),
-                      lookup (nlmsg_str, msg_type),
-                      msg_type, err->msg.nlmsg_seq, err->msg.nlmsg_pid);
-              }
-              /*
-                 ret = -1;
-                 continue;
-               */
-              return -1;
-            }
-
-          /* OK we got netlink message. */
-          if (IS_ZEBRA_DEBUG_KERNEL)
-            zlog_debug ("netlink_parse_info: %s type %s(%u), seq=%u, pid=%u",
-                       nl->name,
-                       lookup (nlmsg_str, h->nlmsg_type), h->nlmsg_type,
-                       h->nlmsg_seq, h->nlmsg_pid);
-
-          /* skip unsolicited messages originating from command socket */
-          if (nl != &netlink_cmd && h->nlmsg_pid == netlink_cmd.snl.nl_pid)
-            {
-              if (IS_ZEBRA_DEBUG_KERNEL)
-                zlog_debug ("netlink_parse_info: %s packet comes from %s",
-                            netlink_cmd.name, nl->name);
-              continue;
-            }
-
-          error = (*filter) (&snl, h);
-          if (error < 0)
-            {
-              zlog (NULL, LOG_ERR, "%s filter function error", nl->name);
-              ret = error;
-            }
-        }
-
-      /* After error care. */
-      if (msg.msg_flags & MSG_TRUNC)
-        {
-          zlog (NULL, LOG_ERR, "%s error: message truncated", nl->name);
-          continue;
-        }
-      if (status)
-        {
-          zlog (NULL, LOG_ERR, "%s error: data remnant size %d", nl->name,
-                status);
-          return -1;
-        }
-    }
-  return ret;
-}
-
-/* Utility function for parse rtattr. */
-static void
-netlink_parse_rtattr (struct rtattr **tb, int max, struct rtattr *rta,
-                      int len)
-{
-  while (RTA_OK (rta, len))
-    {
-      if (rta->rta_type <= max)
-        tb[rta->rta_type] = rta;
-      rta = RTA_NEXT (rta, len);
-    }
-}
-
 /* Called from interface_lookup_netlink().  This function is only used
    during bootstrap. */
-int
-netlink_interface (struct sockaddr_nl *snl, struct nlmsghdr *h)
+static int
+netlink_interface (struct nlsock *nl, struct sockaddr_nl *snl, struct nlmsghdr *h)
 {
   int len;
   struct ifinfomsg *ifi;
@@ -503,6 +95,15 @@
   char *name;
   int i;
 
+  /* skip unsolicited messages originating from command socket */
+  if ((!nl->cmd) && h->nlmsg_pid == netlink_cmd.snl.nl_pid)
+    {
+      if (IS_ZEBRA_DEBUG_KERNEL)
+        zlog_debug ("netlink_parse_info: %s packet comes from %s",
+                    netlink_cmd.name, nl->name);
+      return 0;
+    }
+
   ifi = NLMSG_DATA (h);
 
   if (h->nlmsg_type != RTM_NEWLINK)
@@ -570,8 +171,8 @@
 }
 
 /* Lookup interface IPv4/IPv6 address. */
-int
-netlink_interface_addr (struct sockaddr_nl *snl, struct nlmsghdr *h)
+static int
+netlink_interface_addr (struct nlsock *nl, struct sockaddr_nl *snl, struct nlmsghdr *h)
 {
   int len;
   struct ifaddrmsg *ifa;
@@ -582,6 +183,15 @@
   u_char flags = 0;
   char *label = NULL;
 
+  /* skip unsolicited messages originating from command socket */
+  if ((!nl->cmd) && h->nlmsg_pid == netlink_cmd.snl.nl_pid)
+    {
+      if (IS_ZEBRA_DEBUG_KERNEL)
+        zlog_debug ("netlink_parse_info: %s packet comes from %s",
+                    netlink_cmd.name, nl->name);
+      return 0;
+    }
+
   ifa = NLMSG_DATA (h);
 
   if (ifa->ifa_family != AF_INET
@@ -705,13 +315,14 @@
 }
 
 /* Looking up routing table by netlink interface. */
-int
-netlink_routing_table (struct sockaddr_nl *snl, struct nlmsghdr *h)
+static int
+netlink_routing_table (struct nlsock *nl, struct sockaddr_nl *snl, struct nlmsghdr *h)
 {
   int len;
   struct rtmsg *rtm;
   struct rtattr *tb[RTA_MAX + 1];
-  u_char flags = 0;
+  u_short zebra_flags = 0;
+  struct zapi_nexthop nh;
 
   char anyaddr[16] = { 0 };
 
@@ -723,6 +334,17 @@
   void *gate;
   void *src;
 
+  memset(&nh, 0, sizeof(struct zapi_nexthop));
+
+  /* skip unsolicited messages originating from command socket */
+  if ((!nl->cmd) && h->nlmsg_pid == netlink_cmd.snl.nl_pid)
+    {
+      if (IS_ZEBRA_DEBUG_KERNEL)
+        zlog_debug ("netlink_parse_info: %s packet comes from %s",
+                    netlink_cmd.name, nl->name);
+      return 0;
+    }
+
   rtm = NLMSG_DATA (h);
 
   if (h->nlmsg_type != RTM_NEWROUTE)
@@ -755,7 +377,7 @@
 
   /* Route which inserted by Zebra. */
   if (rtm->rtm_protocol == RTPROT_ZEBRA)
-    flags |= ZEBRA_FLAG_SELFROUTE;
+    zebra_flags |= ZEBRA_FLAG_SELFROUTE;
 
   index = 0;
   metric = 0;
@@ -764,7 +386,11 @@
   src = NULL;
 
   if (tb[RTA_OIF])
-    index = *(int *) RTA_DATA (tb[RTA_OIF]);
+    {
+      index = *(int *) RTA_DATA (tb[RTA_OIF]);
+      nh.intf.index = index;
+      SET_FLAG(nh.type, ZEBRA_NEXTHOP_IFINDEX);
+    }
 
   if (tb[RTA_DST])
     dest = RTA_DATA (tb[RTA_DST]);
@@ -776,7 +402,9 @@
 
   /* Multipath treatment is needed. */
   if (tb[RTA_GATEWAY])
-    gate = RTA_DATA (tb[RTA_GATEWAY]);
+    {
+      gate = RTA_DATA (tb[RTA_GATEWAY]);
+    }
 
   if (tb[RTA_PRIORITY])
     metric = *(int *) RTA_DATA(tb[RTA_PRIORITY]);
@@ -788,7 +416,20 @@
       memcpy (&p.prefix, dest, 4);
       p.prefixlen = rtm->rtm_dst_len;
 
-      rib_add_ipv4 (ZEBRA_ROUTE_KERNEL, flags, &p, gate, src, index, table, metric, 0);
+      if (gate)
+        {
+          memcpy(&nh.gw.ipv4, gate, sizeof(struct in_addr));
+          SET_FLAG(nh.type, ZEBRA_NEXTHOP_IPV4);
+        }
+
+      if (src)
+        {
+          memcpy(&nh.src.ipv4, src, sizeof(struct in_addr));
+          SET_FLAG(nh.type, ZEBRA_NEXTHOP_SRC_IPV4);
+        }
+
+      rib_add_route (ZEBRA_ROUTE_KERNEL, zebra_flags, (struct prefix*)&p,
+                     &nh, table, metric, 0);
     }
 #ifdef HAVE_IPV6
   if (rtm->rtm_family == AF_INET6)
@@ -798,8 +439,14 @@
       memcpy (&p.prefix, dest, 16);
       p.prefixlen = rtm->rtm_dst_len;
 
-      rib_add_ipv6 (ZEBRA_ROUTE_KERNEL, flags, &p, gate, index, table,
-		    metric, 0);
+      if (gate)
+        {
+          memcpy(&nh.gw.ipv6, gate, sizeof(struct in6_addr));
+          SET_FLAG(nh.type, ZEBRA_NEXTHOP_IPV6);
+        }
+
+      rib_add_route (ZEBRA_ROUTE_KERNEL, zebra_flags, (struct prefix*)&p,
+                     &nh, table, metric, 0);
     }
 #endif /* HAVE_IPV6 */
 
@@ -822,12 +469,13 @@
 };
 
 /* Routing information change from the kernel. */
-int
-netlink_route_change (struct sockaddr_nl *snl, struct nlmsghdr *h)
+static int
+netlink_route_change (struct nlsock *nl, struct sockaddr_nl *snl, struct nlmsghdr *h)
 {
   int len;
   struct rtmsg *rtm;
   struct rtattr *tb[RTA_MAX + 1];
+  struct zapi_nexthop nh;
 
   char anyaddr[16] = { 0 };
 
@@ -837,6 +485,17 @@
   void *gate;
   void *src;
 
+  memset(&nh, 0, sizeof(struct zapi_nexthop));
+
+  /* skip unsolicited messages originating from command socket */
+  if ((!nl->cmd) && h->nlmsg_pid == netlink_cmd.snl.nl_pid)
+    {
+      if (IS_ZEBRA_DEBUG_KERNEL)
+        zlog_debug ("netlink_parse_info: %s packet comes from %s",
+                    netlink_cmd.name, nl->name);
+      return 0;
+    }
+
   rtm = NLMSG_DATA (h);
 
   if (!(h->nlmsg_type == RTM_NEWROUTE || h->nlmsg_type == RTM_DELROUTE))
@@ -895,7 +554,11 @@
   src = NULL;
 
   if (tb[RTA_OIF])
-    index = *(int *) RTA_DATA (tb[RTA_OIF]);
+    {
+      index = *(int *) RTA_DATA (tb[RTA_OIF]);
+      nh.intf.index = index;
+      SET_FLAG(nh.type, ZEBRA_NEXTHOP_IFINDEX);
+    }
 
   if (tb[RTA_DST])
     dest = RTA_DATA (tb[RTA_DST]);
@@ -925,10 +588,24 @@
                        inet_ntoa (p.prefix), p.prefixlen);
         }
 
+      if (gate)
+        {
+          memcpy(&nh.gw.ipv4, gate, sizeof(struct in_addr));
+          SET_FLAG(nh.type, ZEBRA_NEXTHOP_IPV4);
+        }
+
+      if (src)
+        {
+          memcpy(&nh.src.ipv4, src, sizeof(struct in_addr));
+          SET_FLAG(nh.type, ZEBRA_NEXTHOP_SRC_IPV4);
+        }
+
       if (h->nlmsg_type == RTM_NEWROUTE)
-        rib_add_ipv4 (ZEBRA_ROUTE_KERNEL, 0, &p, gate, src, index, table, 0, 0);
+        rib_add_route (ZEBRA_ROUTE_KERNEL, 0, (struct prefix*)&p,
+                       &nh, table, 0, 0);
       else
-        rib_delete_ipv4 (ZEBRA_ROUTE_KERNEL, 0, &p, gate, index, table);
+        rib_delete_route (ZEBRA_ROUTE_KERNEL, 0, (struct prefix*)&p,
+                          &nh, table);
     }
 
 #ifdef HAVE_IPV6
@@ -953,18 +630,24 @@
                        p.prefixlen);
         }
 
+      if (gate)
+        {
+          memcpy(&nh.gw.ipv6, gate, sizeof(struct in6_addr));
+          SET_FLAG(nh.type, ZEBRA_NEXTHOP_IPV6);
+        }
+
       if (h->nlmsg_type == RTM_NEWROUTE)
-        rib_add_ipv6 (ZEBRA_ROUTE_KERNEL, 0, &p, gate, index, 0, 0, 0);
+        rib_add_route (ZEBRA_ROUTE_KERNEL, 0, (struct prefix*)&p, &nh, 0, 0, 0);
       else
-        rib_delete_ipv6 (ZEBRA_ROUTE_KERNEL, 0, &p, gate, index, 0);
+        rib_delete_route (ZEBRA_ROUTE_KERNEL, 0, (struct prefix*)&p, &nh, 0);
     }
 #endif /* HAVE_IPV6 */
 
   return 0;
 }
 
-int
-netlink_link_change (struct sockaddr_nl *snl, struct nlmsghdr *h)
+static int
+netlink_link_change (struct nlsock *nl, struct sockaddr_nl *snl, struct nlmsghdr *h)
 {
   int len;
   struct ifinfomsg *ifi;
@@ -974,6 +657,15 @@
 
   ifi = NLMSG_DATA (h);
 
+  /* skip unsolicited messages originating from command socket */
+  if ((!nl->cmd) && h->nlmsg_pid == netlink_cmd.snl.nl_pid)
+    {
+      if (IS_ZEBRA_DEBUG_KERNEL)
+        zlog_debug ("netlink_parse_info: %s packet comes from %s",
+                    netlink_cmd.name, nl->name);
+      return 0;
+    }
+
   if (!(h->nlmsg_type == RTM_NEWLINK || h->nlmsg_type == RTM_DELLINK))
     {
       /* If this is not link add/delete message so print warning. */
@@ -1064,28 +756,37 @@
   return 0;
 }
 
-int
-netlink_information_fetch (struct sockaddr_nl *snl, struct nlmsghdr *h)
+static int
+netlink_information_fetch (struct nlsock *nl, struct sockaddr_nl *snl, struct nlmsghdr *h)
 {
+  /* skip unsolicited messages originating from command socket */
+  if ((!nl->cmd) && h->nlmsg_pid == netlink_cmd.snl.nl_pid)
+    {
+      if (IS_ZEBRA_DEBUG_KERNEL)
+        zlog_debug ("netlink_parse_info: %s packet comes from %s",
+                    netlink_cmd.name, nl->name);
+      return 0;
+    }
+
   switch (h->nlmsg_type)
     {
     case RTM_NEWROUTE:
-      return netlink_route_change (snl, h);
+      return netlink_route_change (nl, snl, h);
       break;
     case RTM_DELROUTE:
-      return netlink_route_change (snl, h);
+      return netlink_route_change (nl, snl, h);
       break;
     case RTM_NEWLINK:
-      return netlink_link_change (snl, h);
+      return netlink_link_change (nl, snl, h);
       break;
     case RTM_DELLINK:
-      return netlink_link_change (snl, h);
+      return netlink_link_change (nl, snl, h);
       break;
     case RTM_NEWADDR:
-      return netlink_interface_addr (snl, h);
+      return netlink_interface_addr (nl, snl, h);
       break;
     case RTM_DELADDR:
-      return netlink_interface_addr (snl, h);
+      return netlink_interface_addr (nl, snl, h);
       break;
     default:
       zlog_warn ("Unknown netlink nlmsg_type %d\n", h->nlmsg_type);
@@ -1116,7 +817,7 @@
   ret = netlink_request (AF_PACKET, RTM_GETLINK, &netlink_cmd);
   if (ret < 0)
     return ret;
-  ret = netlink_parse_info (netlink_interface, &netlink_cmd);
+  ret = netlink_parse_info (netlink_interface, &netlink_cmd, NULL, 0);
   if (ret < 0)
     return ret;
 
@@ -1124,7 +825,7 @@
   ret = netlink_request (AF_INET, RTM_GETADDR, &netlink_cmd);
   if (ret < 0)
     return ret;
-  ret = netlink_parse_info (netlink_interface_addr, &netlink_cmd);
+  ret = netlink_parse_info (netlink_interface_addr, &netlink_cmd, NULL, 0);
   if (ret < 0)
     return ret;
 
@@ -1133,7 +834,7 @@
   ret = netlink_request (AF_INET6, RTM_GETADDR, &netlink_cmd);
   if (ret < 0)
     return ret;
-  ret = netlink_parse_info (netlink_interface_addr, &netlink_cmd);
+  ret = netlink_parse_info (netlink_interface_addr, &netlink_cmd, NULL, 0);
   if (ret < 0)
     return ret;
 #endif /* HAVE_IPV6 */
@@ -1167,7 +868,7 @@
   ret = netlink_request (AF_INET, RTM_GETROUTE, &netlink_cmd);
   if (ret < 0)
     return ret;
-  ret = netlink_parse_info (netlink_routing_table, &netlink_cmd);
+  ret = netlink_parse_info (netlink_routing_table, &netlink_cmd, NULL, 0);
   if (ret < 0)
     return ret;
 
@@ -1176,7 +877,7 @@
   ret = netlink_request (AF_INET6, RTM_GETROUTE, &netlink_cmd);
   if (ret < 0)
     return ret;
-  ret = netlink_parse_info (netlink_routing_table, &netlink_cmd);
+  ret = netlink_parse_info (netlink_routing_table, &netlink_cmd, NULL, 0);
   if (ret < 0)
     return ret;
 #endif /* HAVE_IPV6 */
@@ -1187,142 +888,8 @@
   return 0;
 }
 
-/* Utility function  comes from iproute2. 
-   Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru> */
-int
-addattr_l (struct nlmsghdr *n, int maxlen, int type, void *data, int alen)
-{
-  int len;
-  struct rtattr *rta;
-
-  len = RTA_LENGTH (alen);
-
-  if (NLMSG_ALIGN (n->nlmsg_len) + len > maxlen)
-    return -1;
-
-  rta = (struct rtattr *) (((char *) n) + NLMSG_ALIGN (n->nlmsg_len));
-  rta->rta_type = type;
-  rta->rta_len = len;
-  memcpy (RTA_DATA (rta), data, alen);
-  n->nlmsg_len = NLMSG_ALIGN (n->nlmsg_len) + len;
-
-  return 0;
-}
-
-int
-rta_addattr_l (struct rtattr *rta, int maxlen, int type, void *data, int alen)
-{
-  int len;
-  struct rtattr *subrta;
-
-  len = RTA_LENGTH (alen);
-
-  if (RTA_ALIGN (rta->rta_len) + len > maxlen)
-    return -1;
-
-  subrta = (struct rtattr *) (((char *) rta) + RTA_ALIGN (rta->rta_len));
-  subrta->rta_type = type;
-  subrta->rta_len = len;
-  memcpy (RTA_DATA (subrta), data, alen);
-  rta->rta_len = NLMSG_ALIGN (rta->rta_len) + len;
-
-  return 0;
-}
-
-/* Utility function comes from iproute2. 
-   Authors:	Alexey Kuznetsov, <kuznet@ms2.inr.ac.ru> */
-int
-addattr32 (struct nlmsghdr *n, int maxlen, int type, int data)
-{
-  int len;
-  struct rtattr *rta;
-
-  len = RTA_LENGTH (4);
-
-  if (NLMSG_ALIGN (n->nlmsg_len) + len > maxlen)
-    return -1;
-
-  rta = (struct rtattr *) (((char *) n) + NLMSG_ALIGN (n->nlmsg_len));
-  rta->rta_type = type;
-  rta->rta_len = len;
-  memcpy (RTA_DATA (rta), &data, 4);
-  n->nlmsg_len = NLMSG_ALIGN (n->nlmsg_len) + len;
-
-  return 0;
-}
-
-static int
-netlink_talk_filter (struct sockaddr_nl *snl, struct nlmsghdr *h)
-{
-  zlog_warn ("netlink_talk: ignoring message type 0x%04x", h->nlmsg_type);
-  return 0;
-}
-
-/* sendmsg() to netlink socket then recvmsg(). */
-int
-netlink_talk (struct nlmsghdr *n, struct nlsock *nl)
-{
-  int status;
-  struct sockaddr_nl snl;
-  struct iovec iov = { (void *) n, n->nlmsg_len };
-  struct msghdr msg = { (void *) &snl, sizeof snl, &iov, 1, NULL, 0, 0 };
-  int flags = 0;
-  int snb_ret;
-  int save_errno;
-
-  memset (&snl, 0, sizeof snl);
-  snl.nl_family = AF_NETLINK;
-
-  n->nlmsg_seq = ++nl->seq;
-
-  /* Request an acknowledgement by setting NLM_F_ACK */
-  n->nlmsg_flags |= NLM_F_ACK;
-
-  if (IS_ZEBRA_DEBUG_KERNEL)
-    zlog_debug ("netlink_talk: %s type %s(%u), seq=%u", nl->name,
-               lookup (nlmsg_str, n->nlmsg_type), n->nlmsg_type,
-               n->nlmsg_seq);
-
-  /* Send message to netlink interface. */
-  if (zserv_privs.change (ZPRIVS_RAISE))
-    zlog (NULL, LOG_ERR, "Can't raise privileges");
-  status = sendmsg (nl->sock, &msg, 0);
-  save_errno = errno;
-  if (zserv_privs.change (ZPRIVS_LOWER))
-    zlog (NULL, LOG_ERR, "Can't lower privileges");
-
-  if (status < 0)
-    {
-      zlog (NULL, LOG_ERR, "netlink_talk sendmsg() error: %s",
-            safe_strerror (save_errno));
-      return -1;
-    }
-
-  /* 
-   * Change socket flags for blocking I/O. 
-   * This ensures we wait for a reply in netlink_parse_info().
-   */
-  snb_ret = set_netlink_blocking (nl, &flags);
-  if (snb_ret < 0)
-    zlog (NULL, LOG_WARNING,
-          "%s:%i Warning: Could not set netlink socket to blocking.",
-          __FUNCTION__, __LINE__);
-
-  /* 
-   * Get reply from netlink socket. 
-   * The reply should either be an acknowlegement or an error.
-   */
-  status = netlink_parse_info (netlink_talk_filter, nl);
-
-  /* Restore socket flags for nonblocking I/O */
-  if (snb_ret == 0)
-    set_netlink_nonblocking (nl, &flags);
-
-  return status;
-}
-
 /* Routing table change via netlink interface. */
-int
+static int
 netlink_route (int cmd, int family, void *dest, int length, void *gate,
                int index, int zebra_flags, int table)
 {
@@ -1389,7 +956,7 @@
   snl.nl_family = AF_NETLINK;
 
   /* Talk to netlink socket. */
-  ret = netlink_talk (&req.n, &netlink_cmd);
+  ret = netlink_talk (&req.n, &netlink_cmd, NULL, 0);
   if (ret < 0)
     return -1;
 
@@ -1397,7 +964,7 @@
 }
 
 /* Routing table change via netlink interface. */
-int
+static int
 netlink_route_multipath (int cmd, struct prefix *p, struct rib *rib,
                          int family)
 {
@@ -1406,6 +973,7 @@
   struct nexthop *nexthop = NULL;
   int nexthop_num = 0;
   int discard;
+  int advmss = 0;
 
   struct
   {
@@ -1456,8 +1024,11 @@
   if (discard)
     {
       if (cmd == RTM_NEWROUTE)
-        for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
+        for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next) {
+          if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
+	      continue;
           SET_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB);
+        }
       goto skip;
     }
 
@@ -1466,8 +1037,11 @@
     {
       for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
         {
+	  if (nexthop->advmss && nexthop->advmss > advmss)
+	    advmss = nexthop->advmss;
 
           if ((cmd == RTM_NEWROUTE
+               && !CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE)
                && CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE))
               || (cmd == RTM_DELROUTE
                   && CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB)))
@@ -1487,17 +1061,18 @@
 			 inet_ntoa (p->u.prefix4),
 #endif /* HAVE_IPV6 */
 			 
-			 p->prefixlen, nexthop_types_desc[nexthop->rtype]);
+			 p->prefixlen, nexthop_types_desc(nexthop->rtype));
                     }
 
-                  if (nexthop->rtype == NEXTHOP_TYPE_IPV4
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV4_IFINDEX)
+                  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
 		    {
 		      addattr_l (&req.n, sizeof req, RTA_GATEWAY,
 				 &nexthop->rgate.ipv4, bytelen);
+
                       if (nexthop->src.ipv4.s_addr)
 		          addattr_l(&req.n, sizeof req, RTA_PREFSRC,
 				     &nexthop->src.ipv4, bytelen);
+
 		      if (IS_ZEBRA_DEBUG_KERNEL)
 			zlog_debug("netlink_route_multipath() (recursive, "
 				   "1 hop): nexthop via %s if %u",
@@ -1505,9 +1080,7 @@
 				   nexthop->rifindex);
 		    }
 #ifdef HAVE_IPV6
-                  if (nexthop->rtype == NEXTHOP_TYPE_IPV6
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFINDEX
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFNAME)
+                  else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
 		    {
 		      addattr_l (&req.n, sizeof req, RTA_GATEWAY,
 				 &nexthop->rgate.ipv6, bytelen);
@@ -1519,25 +1092,50 @@
 				   nexthop->rifindex);
 		    }
 #endif /* HAVE_IPV6 */
-                  if (nexthop->rtype == NEXTHOP_TYPE_IFINDEX
-                      || nexthop->rtype == NEXTHOP_TYPE_IFNAME
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV4_IFINDEX
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFINDEX
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFNAME)
+		  else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_DROP))
+		    {
+		      if (IS_ZEBRA_DEBUG_KERNEL)
+			zlog_debug("netlink_route_multipath() (recursive, "
+				   "1 hop): nexthop DROP(%d)", nexthop->drop);
+		    }
+
+                  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFINDEX) &&
+		      !(CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4) ||
+		        CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6)))
 		    {
 		      addattr32 (&req.n, sizeof req, RTA_OIF,
 				 nexthop->rifindex);
-                      if ((nexthop->rtype == NEXTHOP_TYPE_IPV4_IFINDEX
-                           || nexthop->rtype == NEXTHOP_TYPE_IFINDEX)
-                          && nexthop->src.ipv4.s_addr)
-                        addattr_l (&req.n, sizeof req, RTA_PREFSRC,
-				 &nexthop->src.ipv4, bytelen);
 
 		      if (IS_ZEBRA_DEBUG_KERNEL)
 			zlog_debug("netlink_route_multipath() (recursive, "
 				   "1 hop): nexthop via if %u",
 				   nexthop->rifindex);
 		    }
+
+#ifdef HAVE_MPLS
+                  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_MPLS))
+                    {
+#ifdef LINUX_MPLS
+		      struct zmpls_out_segment *out;
+		      char buf[sizeof(struct rtshim) + sizeof(unsigned int)];
+		      struct rtshim *shim = (struct rtshim*)buf;
+		      out = mpls_out_segment_find(nexthop->rmpls);
+		      if (out) {
+		        strcpy(shim->name, "mpls");
+		        shim->datalen = sizeof(unsigned int);
+		        *((unsigned int*)(shim->data)) = out->out_key;
+                        addattr_l(&req.n, sizeof(req), RTA_SHIM,
+			  shim, sizeof(buf));
+		        if (IS_ZEBRA_DEBUG_KERNEL)
+			  zlog_debug("netlink_route_multipath() (recursive, "
+				     "1 hop): MPLS info %08x", out->out_key);
+		      } else {
+		        zlog_debug("netlink_route_multipath() (multihop): "
+				   "unable to find NHLFE %d", nexthop->rmpls);
+		      }
+#endif
+                    }
+#endif /* HAVE_MPLS */
                 }
               else
                 {
@@ -1552,14 +1150,14 @@
 #else
 			 inet_ntoa (p->u.prefix4),
 #endif /* HAVE_IPV6 */
-			 p->prefixlen, nexthop_types_desc[nexthop->type]);
+			 p->prefixlen, nexthop_types_desc(nexthop->type));
                     }
 
-                  if (nexthop->type == NEXTHOP_TYPE_IPV4
-                      || nexthop->type == NEXTHOP_TYPE_IPV4_IFINDEX)
+                  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
 		    {
 		      addattr_l (&req.n, sizeof req, RTA_GATEWAY,
 				 &nexthop->gate.ipv4, bytelen);
+
 		      if (nexthop->src.ipv4.s_addr)
                         addattr_l (&req.n, sizeof req, RTA_PREFSRC,
 				 &nexthop->src.ipv4, bytelen);
@@ -1571,9 +1169,7 @@
 				   nexthop->ifindex);
 		    }
 #ifdef HAVE_IPV6
-                  if (nexthop->type == NEXTHOP_TYPE_IPV6
-                      || nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME
-                      || nexthop->type == NEXTHOP_TYPE_IPV6_IFINDEX)
+                  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
 		    {
 		      addattr_l (&req.n, sizeof req, RTA_GATEWAY,
 				 &nexthop->gate.ipv6, bytelen);
@@ -1585,22 +1181,16 @@
 				   nexthop->ifindex);
 		    }
 #endif /* HAVE_IPV6 */
-                  if (nexthop->type == NEXTHOP_TYPE_IFINDEX
-                      || nexthop->type == NEXTHOP_TYPE_IFNAME
-                      || nexthop->type == NEXTHOP_TYPE_IPV4_IFINDEX)
+                  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
 		    {
-		      addattr32 (&req.n, sizeof req, RTA_OIF, nexthop->ifindex);
-
-		      if (nexthop->src.ipv4.s_addr)
-                        addattr_l (&req.n, sizeof req, RTA_PREFSRC,
-				 &nexthop->src.ipv4, bytelen);
-
 		      if (IS_ZEBRA_DEBUG_KERNEL)
 			zlog_debug("netlink_route_multipath() (single hop): "
-				   "nexthop via if %u", nexthop->ifindex);
+				   "nexthop DROP(%d)", nexthop->drop);
 		    }
-                  else if (nexthop->type == NEXTHOP_TYPE_IPV6_IFINDEX
-                      || nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME)
+
+                  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX) &&
+		      !(CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4) ||
+		        CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6)))
 		    {
 		      addattr32 (&req.n, sizeof req, RTA_OIF, nexthop->ifindex);
 
@@ -1608,6 +1198,31 @@
 			zlog_debug("netlink_route_multipath() (single hop): "
 				   "nexthop via if %u", nexthop->ifindex);
 		    }
+
+#ifdef HAVE_MPLS
+                  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_MPLS))
+                    {
+#ifdef LINUX_MPLS
+		      struct zmpls_out_segment *out;
+		      char buf[sizeof(struct rtshim) + sizeof(unsigned int)];
+		      struct rtshim *shim = (struct rtshim*)buf;
+		      out = mpls_out_segment_find(nexthop->mpls);
+		      if (out) {
+		        strcpy(shim->name, "mpls");
+		        shim->datalen = sizeof(unsigned int);
+		        *((unsigned int*)(shim->data)) = out->out_key;
+                        addattr_l(&req.n, sizeof(req), RTA_SHIM,
+			  shim, sizeof(buf));
+		        if (IS_ZEBRA_DEBUG_KERNEL)
+			  zlog_debug("netlink_route_multipath() (single hop): "
+				     "MPLS info %08x", out->out_key);
+		      } else {
+		        zlog_debug("netlink_route_multipath() (single hop): "
+				   "unable to find NHLFE %d", nexthop->mpls);
+		      }
+#endif
+                    }
+#endif /* HAVE_MPLS */
                 }
 
               if (cmd == RTM_NEWROUTE)
@@ -1634,7 +1249,11 @@
            nexthop && (MULTIPATH_NUM == 0 || nexthop_num < MULTIPATH_NUM);
            nexthop = nexthop->next)
         {
+          if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
+	      continue;
+
           if ((cmd == RTM_NEWROUTE
+               && !CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE)
                && CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE))
               || (cmd == RTM_DELROUTE
                   && CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB)))
@@ -1659,10 +1278,9 @@
 #else
 			 inet_ntoa (p->u.prefix4),
 #endif /* HAVE_IPV6 */
-                         p->prefixlen, nexthop_types_desc[nexthop->rtype]);
+                         p->prefixlen, nexthop_types_desc(nexthop->type));
                     }
-                  if (nexthop->rtype == NEXTHOP_TYPE_IPV4
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV4_IFINDEX)
+                  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
                     {
                       rta_addattr_l (rta, 4096, RTA_GATEWAY,
                                      &nexthop->rgate.ipv4, bytelen);
@@ -1678,9 +1296,7 @@
 				   nexthop->rifindex);
                     }
 #ifdef HAVE_IPV6
-                  if (nexthop->rtype == NEXTHOP_TYPE_IPV6
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFNAME
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFINDEX)
+                  else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
 		    {
 		      rta_addattr_l (rta, 4096, RTA_GATEWAY,
 				     &nexthop->rgate.ipv6, bytelen);
@@ -1692,22 +1308,16 @@
 				   nexthop->rifindex);
 		    }
 #endif /* HAVE_IPV6 */
-                  /* ifindex */
-                  if (nexthop->rtype == NEXTHOP_TYPE_IPV4_IFINDEX
-		      || nexthop->rtype == NEXTHOP_TYPE_IFINDEX
-                      || nexthop->rtype == NEXTHOP_TYPE_IFNAME)
+		  else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_DROP))
 		    {
-		      rtnh->rtnh_ifindex = nexthop->rifindex;
-                      if (nexthop->src.ipv4.s_addr)
-                        src = &nexthop->src;
-
-		      if (IS_ZEBRA_DEBUG_KERNEL)
 			zlog_debug("netlink_route_multipath() (recursive, "
-				   "multihop): nexthop via if %u",
-				   nexthop->rifindex);
+				   "multihop): nexthop DROP %d", nexthop->drop);
 		    }
-		  else if (nexthop->rtype == NEXTHOP_TYPE_IPV6_IFINDEX
-                      || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFNAME)
+
+                  /* ifindex */
+                  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFINDEX) &&
+		      !(CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4) ||
+		        CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6)))
 		    {
 		      rtnh->rtnh_ifindex = nexthop->rifindex;
 
@@ -1720,6 +1330,32 @@
 		    {
 		      rtnh->rtnh_ifindex = 0;
 		    }
+
+#ifdef HAVE_MPLS
+                  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_MPLS))
+                    {
+#ifdef LINUX_MPLS
+		      struct zmpls_out_segment *out;
+		      char buf[sizeof(struct rtshim) + sizeof(unsigned int)];
+		      struct rtshim *shim = (struct rtshim*)buf;
+		      out = mpls_out_segment_find(nexthop->rmpls);
+		      if (out) {
+		        strcpy(shim->name, "mpls");
+		        shim->datalen = sizeof(unsigned int);
+		        *((unsigned int*)(shim->data)) = out->out_key;
+                        addattr_l(&req.n, sizeof(req), RTA_SHIM,
+			  shim, sizeof(buf));
+		        if (IS_ZEBRA_DEBUG_KERNEL)
+			  zlog_debug("netlink_route_multipath() (recursive "
+                                     "multihop): MPLS info %08x", out->out_key);
+		      } else {
+		        zlog_debug("netlink_route_multipath() (recursive "
+                                   "multihop): unable to find NHLFE %d",
+                                   nexthop->rmpls);
+		      }
+#endif
+                    }
+#endif /* HAVE_MPLS */
                 }
               else
                 {
@@ -1733,10 +1369,9 @@
 #else
 			 inet_ntoa (p->u.prefix4),
 #endif /* HAVE_IPV6 */
-			 p->prefixlen, nexthop_types_desc[nexthop->type]);
+			 p->prefixlen, nexthop_types_desc(nexthop->type));
                     }
-                  if (nexthop->type == NEXTHOP_TYPE_IPV4
-                      || nexthop->type == NEXTHOP_TYPE_IPV4_IFINDEX)
+                  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
                     {
 		      rta_addattr_l (rta, 4096, RTA_GATEWAY,
 				     &nexthop->gate.ipv4, bytelen);
@@ -1752,9 +1387,7 @@
 				   nexthop->ifindex);
                     }
 #ifdef HAVE_IPV6
-                  if (nexthop->type == NEXTHOP_TYPE_IPV6
-                      || nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME
-                      || nexthop->type == NEXTHOP_TYPE_IPV6_IFINDEX)
+                  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
 		    { 
 		      rta_addattr_l (rta, 4096, RTA_GATEWAY,
 				     &nexthop->gate.ipv6, bytelen);
@@ -1766,20 +1399,16 @@
 				   nexthop->ifindex);
 		    }
 #endif /* HAVE_IPV6 */
-                  /* ifindex */
-                  if (nexthop->type == NEXTHOP_TYPE_IPV4_IFINDEX
-		      || nexthop->type == NEXTHOP_TYPE_IFINDEX
-                      || nexthop->type == NEXTHOP_TYPE_IFNAME)
-                    {
-		      rtnh->rtnh_ifindex = nexthop->ifindex;
-		      if (nexthop->src.ipv4.s_addr)
-			src = &nexthop->src;
-		      if (IS_ZEBRA_DEBUG_KERNEL)
+		  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
+		    {
 			zlog_debug("netlink_route_multipath() (multihop): "
-				   "nexthop via if %u", nexthop->ifindex);
+				   "nexthop DROP %d", nexthop->drop);
 		    }
-                  else if (nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME
-                      || nexthop->type == NEXTHOP_TYPE_IPV6_IFINDEX)
+
+                  /* ifindex */
+                  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX) &&
+		      !(CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4) ||
+		        CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6)))
 		    {
 		      rtnh->rtnh_ifindex = nexthop->ifindex;
 
@@ -1791,6 +1420,31 @@
 		    {
 		      rtnh->rtnh_ifindex = 0;
 		    }
+
+#ifdef HAVE_MPLS
+                  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_MPLS))
+                    {
+#ifdef LINUX_MPLS
+		      struct zmpls_out_segment *out;
+		      char buf[sizeof(struct rtshim) + sizeof(unsigned int)];
+		      struct rtshim *shim = (struct rtshim*)buf;
+		      out = mpls_out_segment_find(nexthop->mpls);
+		      if (out) {
+		        strcpy(shim->name, "mpls");
+		        shim->datalen = sizeof(unsigned int);
+		        *((unsigned int*)(shim->data)) = out->out_key;
+                        addattr_l(&req.n, sizeof(req), RTA_SHIM,
+			  shim, sizeof(buf));
+		        if (IS_ZEBRA_DEBUG_KERNEL)
+			  zlog_debug("netlink_route_multipath() (multihop): "
+                                     "MPLS info %08x", out->out_key);
+		      } else {
+		        zlog_debug("netlink_route_multipath() (multihop): "
+				   "unable to find NHLFE %d", nexthop->mpls);
+		      }
+#endif
+                    }
+#endif /* HAVE_MPLS */
                 }
               rtnh = RTNH_NEXT (rtnh);
 
@@ -1806,6 +1460,20 @@
                    RTA_PAYLOAD (rta));
     }
 
+  if (advmss)
+    {
+      char buf[1024];
+      struct rtattr *rta = (void *) buf;
+      unsigned int mss = advmss;
+
+      rta->rta_type = RTA_METRICS;
+      rta->rta_len = RTA_LENGTH (0);
+
+      rta_addattr_l (rta, sizeof (buf), RTAX_ADVMSS, &mss, sizeof (mss));
+      addattr_l(&req.n, sizeof (buf), RTA_METRICS, RTA_DATA (rta),
+	        RTA_PAYLOAD (rta));
+   }
+
   /* If there is no useful nexthop then return. */
   if (nexthop_num == 0)
     {
@@ -1821,7 +1489,7 @@
   snl.nl_family = AF_NETLINK;
 
   /* Talk to netlink socket. */
-  return netlink_talk (&req.n, &netlink_cmd);
+  return netlink_talk (&req.n, &netlink_cmd, NULL, 0);
 }
 
 int
@@ -1860,7 +1528,7 @@
 #endif /* HAVE_IPV6 */
 
 /* Interface address modification. */
-int
+static int
 netlink_address (int cmd, int family, struct interface *ifp,
                  struct connected *ifc)
 {
@@ -1897,6 +1565,12 @@
           addattr_l (&req.n, sizeof req, IFA_BROADCAST, &p->u.prefix,
                      bytelen);
         }
+      else if (if_is_pointopoint (ifp) && ifc->destination)
+        {
+          p = ifc->destination;
+          addattr_l (&req.n, sizeof req, IFA_ADDRESS, &p->u.prefix,
+                     bytelen);
+        }
     }
 
   if (CHECK_FLAG (ifc->flags, ZEBRA_IFA_SECONDARY))
@@ -1906,7 +1580,7 @@
     addattr_l (&req.n, sizeof req, IFA_LABEL, ifc->label,
                strlen (ifc->label) + 1);
 
-  return netlink_talk (&req.n, &netlink_cmd);
+  return netlink_talk (&req.n, &netlink_cmd, NULL, 0);
 }
 
 int
@@ -1925,14 +1599,14 @@
 extern struct thread_master *master;
 
 /* Kernel route reflection. */
-int
+static int
 kernel_read (struct thread *thread)
 {
   int ret;
   int sock;
 
   sock = THREAD_FD (thread);
-  ret = netlink_parse_info (netlink_information_fetch, &netlink);
+  ret = netlink_parse_info (netlink_information_fetch, &netlink, NULL, 0);
   thread_add_read (zebrad.master, kernel_read, NULL, netlink.sock);
 
   return 0;
@@ -1999,8 +1673,8 @@
 #ifdef HAVE_IPV6
   groups |= RTMGRP_IPV6_ROUTE | RTMGRP_IPV6_IFADDR;
 #endif /* HAVE_IPV6 */
-  netlink_socket (&netlink, groups);
-  netlink_socket (&netlink_cmd, 0);
+  netlink_socket (&netlink, NETLINK_ROUTE, groups);
+  netlink_socket (&netlink_cmd, NETLINK_ROUTE, 0);
 
   /* Register kernel socket. */
   if (netlink.sock > 0)
diff -Naur quagga-0.99.10/zebra/rt_netlink.h quagga-mpls/zebra/rt_netlink.h
--- quagga-0.99.10/zebra/rt_netlink.h	1970-01-01 01:00:00.000000000 +0100
+++ quagga-mpls/zebra/rt_netlink.h	2008-11-25 12:30:18.000000000 +0100
@@ -0,0 +1,7 @@
+#ifndef ZEBRA_RT_NETLINK_H
+#define ZEBRA_RT_NETLINK_H
+
+extern int netlink_route_read ();
+extern int interface_lookup_netlink ();
+
+#endif
diff -Naur quagga-0.99.10/zebra/rtread_getmsg.c quagga-mpls/zebra/rtread_getmsg.c
--- quagga-0.99.10/zebra/rtread_getmsg.c	2007-05-02 18:05:35.000000000 +0200
+++ quagga-mpls/zebra/rtread_getmsg.c	2008-11-25 12:30:18.000000000 +0100
@@ -71,7 +71,8 @@
 {
 	struct prefix_ipv4	prefix;
  	struct in_addr		tmpaddr, gateway;
-	u_char			zebra_flags = 0;
+	u_short			zebra_flags = 0;
+	struct zapi_nexthop	nh;
 
 	if (routeEntry->ipRouteInfo.re_ire_type & IRE_CACHETABLE)
 		return;
@@ -79,6 +80,8 @@
 	if (routeEntry->ipRouteInfo.re_ire_type & IRE_HOST_REDIRECT)
 		zebra_flags |= ZEBRA_FLAG_SELFROUTE;
 
+	memset(&nh, 0, sizeof(struct zapi_nexthop));
+
 	prefix.family = AF_INET;
 
 	tmpaddr.s_addr = routeEntry->ipRouteDest;
@@ -88,9 +91,11 @@
 	prefix.prefixlen = ip_masklen (tmpaddr);
 
 	gateway.s_addr = routeEntry->ipRouteNextHop;
+	nh.gw.ipv4 = gateway;
+	SET_FLAG(nh.type, ZEBRA_NEXTHOP_IPV4);
 
-	rib_add_ipv4 (ZEBRA_ROUTE_KERNEL, zebra_flags, &prefix,
-		      &gateway, NULL, 0, 0, 0, 0);
+	rib_add_route (ZEBRA_ROUTE_KERNEL, zebra_flags,
+                       (struct prefix*)&prefix, &nh, 0, 0, 0);
 }
 
 void
diff -Naur quagga-0.99.10/zebra/rtread_netlink.c quagga-mpls/zebra/rtread_netlink.c
--- quagga-0.99.10/zebra/rtread_netlink.c	2002-12-13 21:15:30.000000000 +0100
+++ quagga-mpls/zebra/rtread_netlink.c	2008-11-25 12:30:18.000000000 +0100
@@ -22,8 +22,12 @@
 
 #include <zebra.h>
 
-/* Extern from rt_netlink.c */
-void netlink_route_read ();
+#include "if.h"
+#include "prefix.h"
+#include "rib.h"
+
+#include "zebra/zserv.h"
+#include "zebra/rt_netlink.h"
 
 void route_read ()
 {
diff -Naur quagga-0.99.10/zebra/rtread_proc.c quagga-mpls/zebra/rtread_proc.c
--- quagga-0.99.10/zebra/rtread_proc.c	2007-05-02 18:05:35.000000000 +0200
+++ quagga-mpls/zebra/rtread_proc.c	2008-11-25 12:30:18.000000000 +0100
@@ -72,7 +72,8 @@
       struct prefix_ipv4 p;
       struct in_addr tmpmask;
       struct in_addr gateway;
-      u_char zebra_flags = 0;
+      struct zapi_nexthop nh;
+      u_short zebra_flags = 0;
 
       n = sscanf (buf, "%s %s %s %x %d %d %d %s %d %d %d",
 		  iface, dest, gate, &flags, &refcnt, &use, &metric, 
@@ -87,6 +88,8 @@
       if (! (flags & RTF_GATEWAY))
 	continue;
 
+      memset(&nh, 0, sizeof(struct zapi_nexthop));
+
       if (flags & RTF_DYNAMIC)
 	zebra_flags |= ZEBRA_FLAG_SELFROUTE;
 
@@ -96,7 +99,11 @@
       p.prefixlen = ip_masklen (tmpmask);
       sscanf (gate, "%lX", (unsigned long *)&gateway);
 
-      rib_add_ipv4 (ZEBRA_ROUTE_KERNEL, zebra_flags, &p, &gateway, NULL, 0, 0, 0, 0);
+      SET_FLAG(nh.type, ZEBRA_NEXTHOP_IPV4);
+      nh.gw.ipv4 = gateway;
+
+      rib_add_route (ZEBRA_ROUTE_KERNEL, zebra_flags, (struct prefix*)&p,
+                     &nh, 0, 0, 0);
     }
 
   fclose (fp);
@@ -129,7 +136,8 @@
       int metric, use, refcnt, flags;
       struct prefix_ipv6 p;
       struct in6_addr gateway;
-      u_char zebra_flags = 0;
+      u_short zebra_flags = 0;
+      struct zapi_nexthop nh;
 
       /* Linux 2.1.x write this information at net/ipv6/route.c
          rt6_info_node () */
@@ -148,6 +156,8 @@
       if (! (flags & RTF_GATEWAY))
 	continue;
 
+      memset(&nh, 0, sizeof(struct zapi_nexthop));
+
       if (flags & RTF_DYNAMIC)
 	zebra_flags |= ZEBRA_FLAG_SELFROUTE;
 
@@ -156,8 +166,11 @@
       str2in6_addr (gate, &gateway);
       p.prefixlen = dest_plen;
 
-      rib_add_ipv6 (ZEBRA_ROUTE_KERNEL, zebra_flags, &p, &gateway, 0, 0,
-		    metric, 0);
+      SET_FLAG(nh.type, ZEBRA_NEXTHOP_IPV4);
+      nh.gw.ipv4 = gateway;
+
+      rib_add_route (ZEBRA_ROUTE_KERNEL, zebra_flags, (struct prefix*)&p,
+                     &nh, 0, metric, 0);
     }
 
   fclose (fp);
diff -Naur quagga-0.99.10/zebra/rt_socket.c quagga-mpls/zebra/rt_socket.c
--- quagga-0.99.10/zebra/rt_socket.c	2007-09-14 13:31:55.000000000 +0200
+++ quagga-mpls/zebra/rt_socket.c	2008-11-25 12:30:18.000000000 +0100
@@ -114,37 +114,46 @@
 	{
 	  if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_RECURSIVE))
 	    {
-	      if (nexthop->rtype == NEXTHOP_TYPE_IPV4 ||
-		  nexthop->rtype == NEXTHOP_TYPE_IPV4_IFINDEX)
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
 		{
 		  sin_gate.sin_addr = nexthop->rgate.ipv4;
 		  gate = 1;
 		}
-	      if (nexthop->rtype == NEXTHOP_TYPE_IFINDEX
-		  || nexthop->rtype == NEXTHOP_TYPE_IFNAME
-		  || nexthop->rtype == NEXTHOP_TYPE_IPV4_IFINDEX)
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
+		assert (0);
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_DROP))
+	        {
+	          struct in_addr loopback;
+	          loopback.s_addr = htonl (INADDR_LOOPBACK);
+	          sin_gate.sin_addr = loopback;
+	          gate = 1;
+	        }
+
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFINDEX))
 		ifindex = nexthop->rifindex;
 	    }
 	  else
 	    {
-	      if (nexthop->type == NEXTHOP_TYPE_IPV4 ||
-		  nexthop->type == NEXTHOP_TYPE_IPV4_IFINDEX)
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
 		{
 		  sin_gate.sin_addr = nexthop->gate.ipv4;
 		  gate = 1;
 		}
-	      if (nexthop->type == NEXTHOP_TYPE_IFINDEX
-		  || nexthop->type == NEXTHOP_TYPE_IFNAME
-		  || nexthop->type == NEXTHOP_TYPE_IPV4_IFINDEX)
+	      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
+		assert (0);
+	      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
+	        {
+	          struct in_addr loopback;
+	          loopback.s_addr = htonl (INADDR_LOOPBACK);
+	          sin_gate.sin_addr = loopback;
+	          gate = 1;
+	        }
+
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
 		ifindex = nexthop->ifindex;
-	      if (nexthop->type == NEXTHOP_TYPE_BLACKHOLE)
-		{
-		  struct in_addr loopback;
-		  loopback.s_addr = htonl (INADDR_LOOPBACK);
-		  sin_gate.sin_addr = loopback;
-		  gate = 1;
-		}
-	    }
+
+	  if (cmd == RTM_ADD)
+	    SET_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB);
 
 	  if (gate && p->prefixlen == 32)
 	    mask = NULL;
@@ -390,32 +399,28 @@
 	{
 	  if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_RECURSIVE))
 	    {
-	      if (nexthop->rtype == NEXTHOP_TYPE_IPV6
-		  || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFNAME
-		  || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFINDEX)
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
 		{
 		  sin_gate.sin6_addr = nexthop->rgate.ipv6;
 		  gate = 1;
 		}
-	      if (nexthop->rtype == NEXTHOP_TYPE_IFINDEX
-		  || nexthop->rtype == NEXTHOP_TYPE_IFNAME
-		  || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFNAME
-		  || nexthop->rtype == NEXTHOP_TYPE_IPV6_IFINDEX)
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
+		assert (0);
+
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFINDEX))
 		ifindex = nexthop->rifindex;
 	    }
 	  else
 	    {
-	      if (nexthop->type == NEXTHOP_TYPE_IPV6
-		  || nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME
-		  || nexthop->type == NEXTHOP_TYPE_IPV6_IFINDEX)
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
 		{
 		  sin_gate.sin6_addr = nexthop->gate.ipv6;
 		  gate = 1;
 		}
-	      if (nexthop->type == NEXTHOP_TYPE_IFINDEX
-		  || nexthop->type == NEXTHOP_TYPE_IFNAME
-		  || nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME
-		  || nexthop->type == NEXTHOP_TYPE_IPV6_IFINDEX)
+	      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
+		assert (0);
+
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
 		ifindex = nexthop->ifindex;
 	    }
 
diff -Naur quagga-0.99.10/zebra/zebra_rib.c quagga-mpls/zebra/zebra_rib.c
--- quagga-0.99.10/zebra/zebra_rib.c	2008-06-07 22:25:16.000000000 +0200
+++ quagga-mpls/zebra/zebra_rib.c	2008-11-25 12:30:18.000000000 +0100
@@ -72,6 +72,11 @@
 /* Vector for routing table.  */
 vector vrf_vector;
 
+#ifdef HAVE_IPV6
+static int
+rib_bogus_ipv6 (int, struct prefix_ipv6*, struct in6_addr*, unsigned int, int);
+#endif
+
 /* Allocate new VRF.  */
 static struct vrf *
 vrf_alloc (const char *name)
@@ -165,173 +170,432 @@
   return vrf->stable[afi][safi];
 }
 
-/* Add nexthop to the end of the list.  */
-static void
-nexthop_add (struct rib *rib, struct nexthop *nexthop)
+static int
+zapi_nexthop_str(struct zapi_nexthop *nh, char *buf, int size)
 {
-  struct nexthop *last;
+  struct interface *ifp = NULL;
+  char buf1[BUFSIZ];
+  char *ptr = buf;
+  int len = 0;
 
-  for (last = rib->nexthop; last && last->next; last = last->next)
-    ;
-  if (last)
-    last->next = nexthop;
-  else
-    rib->nexthop = nexthop;
-  nexthop->prev = last;
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_DROP))
+    {
+      switch (nh->gw.drop)
+        {
+	  case ZEBRA_DROP_NULL:
+	    len = snprintf(buf, size, " Null0");
+	    break;
+	  case ZEBRA_DROP_REJECT:
+	    len = snprintf(buf, size, " reject");
+	    break;
+	  case ZEBRA_DROP_BLACKHOLE:
+	    len = snprintf(buf, size, " blackhole");
+	    break;
+	  default:
+	    assert(0);
+        }
+    }
 
-  rib->nexthop_num++;
-}
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IPV4))
+    {
+      inet_ntop (AF_INET, &nh->gw.ipv4, buf1, BUFSIZ),
+      len += snprintf(ptr, size, " via %s", buf1);
+      ptr = &buf[len];
+    }
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IPV6))
+    {
+      inet_ntop (AF_INET6, &nh->gw.ipv6, buf1, BUFSIZ),
+      len += snprintf(ptr, size, " via %s", buf1);
+      ptr = &buf[len];
+    }
+#endif
 
-/* Delete specified nexthop from the list. */
-static void
-nexthop_delete (struct rib *rib, struct nexthop *nexthop)
-{
-  if (nexthop->next)
-    nexthop->next->prev = nexthop->prev;
-  if (nexthop->prev)
-    nexthop->prev->next = nexthop->next;
-  else
-    rib->nexthop = nexthop->next;
-  rib->nexthop_num--;
-}
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IFINDEX))
+    {
+      ifp = if_lookup_by_index (nh->intf.index);
+    }
+  else if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IFNAME))
+    {
+      ifp = if_lookup_by_name (nh->intf.name);
+    }
 
-/* Free nexthop. */
-static void
-nexthop_free (struct nexthop *nexthop)
-{
-  if (nexthop->ifname)
-    XFREE (0, nexthop->ifname);
-  XFREE (MTYPE_NEXTHOP, nexthop);
+  if (ifp)
+    {
+      len += snprintf(ptr, size - len, " intf %s(%d)", ifp->name, ifp->ifindex);
+      ptr = &buf[len];
+    }
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_MPLS))
+    {
+      struct zmpls_out_segment *out;
+      out = mpls_out_segment_find(&nh->mpls);
+      if (out)
+	{
+	  len += snprintf(ptr, size - len, " mpls 0x%08x", nh->mpls);
+	  ptr = &buf[len];
+	}
+    }
+#endif
+  return len;  
 }
 
-struct nexthop *
-nexthop_ifindex_add (struct rib *rib, unsigned int ifindex)
+static int
+nexthop_str(struct nexthop *nh, char *buf, int size)
 {
-  struct nexthop *nexthop;
+  struct interface *ifp = NULL;
+  char buf1[BUFSIZ];
+  char *ptr = buf;
+  int len = 0;
 
-  nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
-  memset (nexthop, 0, sizeof (struct nexthop));
-  nexthop->type = NEXTHOP_TYPE_IFINDEX;
-  nexthop->ifindex = ifindex;
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_DROP))
+    {
+      switch (nh->drop)
+        {
+	  case ZEBRA_DROP_NULL:
+	    len = snprintf(buf, size, " Null0");
+	    break;
+	  case ZEBRA_DROP_REJECT:
+	    len = snprintf(buf, size, " reject");
+	    break;
+	  case ZEBRA_DROP_BLACKHOLE:
+	    len = snprintf(buf, size, " blackhole");
+	    break;
+	  default:
+	    assert(0);
+        }
+    }
 
-  nexthop_add (rib, nexthop);
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IPV4))
+    {
+      inet_ntop (AF_INET, &nh->gate.ipv4, buf1, BUFSIZ),
+      len += snprintf(ptr, size, " via %s", buf1);
+      ptr = &buf[len];
+    }
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IPV6))
+    {
+      inet_ntop (AF_INET6, &nh->gate.ipv6, buf1, BUFSIZ),
+      len += snprintf(ptr, size, " via %s", buf1);
+      ptr = &buf[len];
+    }
+#endif
 
-  return nexthop;
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IFINDEX))
+    {
+      ifp = if_lookup_by_index (nh->ifindex);
+    }
+  else if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IFNAME))
+    {
+      ifp = if_lookup_by_name (nh->ifname);
+    }
+
+  if (ifp)
+    {
+      len += snprintf(ptr, size - len, " intf %s(%d)", ifp->name, ifp->ifindex);
+      ptr = &buf[len];
+    }
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_MPLS))
+    {
+      struct zmpls_out_segment *out;
+      out = mpls_out_segment_find(&nh->mpls);
+      if (out)
+	{
+	  len += snprintf(ptr, size - len, " mpls 0x%08x", nh->mpls);
+	  ptr = &buf[len];
+	}
+    }
+#endif
+  return len;  
 }
 
-struct nexthop *
-nexthop_ifname_add (struct rib *rib, char *ifname)
+static int
+zapi_nexthop_match_nexthop(struct zapi_nexthop *znh, struct nexthop *nh, int mask)
 {
-  struct nexthop *nexthop;
-
-  nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
-  memset (nexthop, 0, sizeof (struct nexthop));
-  nexthop->type = NEXTHOP_TYPE_IFNAME;
-  nexthop->ifname = XSTRDUP (0, ifname);
+  int either = (nh->type | znh->type) & mask;
+  int both = (nh->type & znh->type) & mask;
+  int try = 0;
+  int match = 0;
+  int v4_gate_match = 0;
+
+  try++;
+  if (nh->advmss == znh->advmss)
+    match++;
+
+  if (CHECK_FLAG(either, ZEBRA_NEXTHOP_DROP))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_DROP) &&
+	  nh->drop == znh->gw.drop)
+        match++;
+    }
+  else if (CHECK_FLAG(either, ZEBRA_NEXTHOP_IPV4))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_IPV4) &&
+         (IPV4_ADDR_SAME (&nh->gate.ipv4, &znh->gw.ipv4) ||
+          IPV4_ADDR_SAME (&nh->rgate.ipv4, &znh->gw.ipv4)))
+	{
+	  match++;
+	  v4_gate_match = 1;
+	}
+    }
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG(either, ZEBRA_NEXTHOP_IPV6))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_IPV6) &&
+         (IPV6_ADDR_SAME (&nh->gate.ipv6, &znh->gw.ipv6) ||
+          IPV6_ADDR_SAME (&nh->rgate.ipv6, &znh->gw.ipv6)))
+        match++;
+    }
+#endif
 
-  nexthop_add (rib, nexthop);
+  if (CHECK_FLAG(either, ZEBRA_NEXTHOP_IFINDEX))
+    {
+      if (!v4_gate_match)
+        {
+          try++;
+          if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IFINDEX) &&
+            (nh->ifindex == znh->intf.index))
+            match++;
+        }
+      else if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IFINDEX))
+        {
+            try++;
+            if (nh->ifindex == znh->intf.index)
+              match++;
+        }
+    }
+  else if (CHECK_FLAG(either, ZEBRA_NEXTHOP_IFNAME))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_IFNAME) &&
+         (!strncmp(nh->ifname, znh->intf.name, IFNAMSIZ)))
+        match++;
+    }
 
-  return nexthop;
+  if (CHECK_FLAG(either, ZEBRA_NEXTHOP_SRC_IPV4))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_SRC_IPV4) &&
+          IPV4_ADDR_SAME (&nh->src.ipv4, &znh->src.ipv4))
+        match++;
+    }
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG(either, ZEBRA_NEXTHOP_SRC_IPV6))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_SRC_IPV6) &&
+          IPV6_ADDR_SAME (&nh->src.ipv6, &znh->src.ipv6))
+        match++;
+    }
+#endif
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG(either, ZEBRA_NEXTHOP_MPLS))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_MPLS) &&
+          nh->mpls == mpls_out_segment_find_index_by_nexthop(znh))
+        match++;
+    }
+#endif
+  return (try && try == match) ? 1 : 0;
 }
 
-struct nexthop *
-nexthop_ipv4_add (struct rib *rib, struct in_addr *ipv4, struct in_addr *src)
+static int
+zapi_nexthop_match_static_route(u_char distance, struct zapi_nexthop *znh,
+                                struct static_route *si)
 {
-  struct nexthop *nexthop;
+  int try = 0;
+  int match = 0;
 
-  nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
-  memset (nexthop, 0, sizeof (struct nexthop));
-  nexthop->type = NEXTHOP_TYPE_IPV4;
-  nexthop->gate.ipv4 = *ipv4;
-  if (src)
-    nexthop->src.ipv4 = *src;
+  try++;
+  if (distance == si->distance)
+    match++;
 
-  nexthop_add (rib, nexthop);
+  try++;
+  if (zapi_nexthop_match(znh, &si->nh, ZEBRA_NEXTHOP_ALL))
+    match++;
 
-  return nexthop;
+  return (try && try == match) ? 1 : 0;
 }
 
-static struct nexthop *
-nexthop_ipv4_ifindex_add (struct rib *rib, struct in_addr *ipv4, 
-                          struct in_addr *src, unsigned int ifindex)
+void
+zapi_nexthop2nexthop(struct zapi_nexthop* znh, struct nexthop *nh)
 {
-  struct nexthop *nexthop;
-
-  nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
-  memset (nexthop, 0, sizeof (struct nexthop));
-  nexthop->type = NEXTHOP_TYPE_IPV4_IFINDEX;
-  nexthop->gate.ipv4 = *ipv4;
-  if (src)
-    nexthop->src.ipv4 = *src;
-  nexthop->ifindex = ifindex;
+  nh->type = znh->type;
+  nh->advmss = znh->advmss;
 
-  nexthop_add (rib, nexthop);
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_DROP))
+    nh->drop = znh->gw.drop;
+  else if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_SRC_IPV4))
+    nh->src.ipv4 = znh->src.ipv4;
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_SRC_IPV6))
+    nh->src.ipv6 = znh->src.ipv6;
+#endif
 
-  return nexthop;
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IPV4))
+    nh->gate.ipv4 = znh->gw.ipv4;
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IPV6))
+    nh->gate.ipv6 = znh->gw.ipv6;
+#endif
+
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IFINDEX))
+    nh->ifindex = znh->intf.index;
+  else if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_IFNAME))
+    nh->ifname = XSTRDUP (0, znh->intf.name);
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG(nh->type, ZEBRA_NEXTHOP_MPLS))
+    nh->mpls = mpls_out_segment_find_index_by_nexthop(znh);
+#endif
 }
 
-#ifdef HAVE_IPV6
-struct nexthop *
-nexthop_ipv6_add (struct rib *rib, struct in6_addr *ipv6)
+static int
+nexthop_match(struct nexthop *znh, struct nexthop *nh, int mask)
 {
-  struct nexthop *nexthop;
-
-  nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
-  memset (nexthop, 0, sizeof (struct nexthop));
-  nexthop->type = NEXTHOP_TYPE_IPV6;
-  nexthop->gate.ipv6 = *ipv6;
+  int either = (nh->type | znh->type) & mask;
+  int both = (nh->type & znh->type) & mask;
+  int try = 0;
+  int match = 0;
+  int v4_gate_match = 0;
+
+  try++;
+  if (nh->advmss == znh->advmss)
+    match++;
+
+  if (CHECK_FLAG(either, ZEBRA_NEXTHOP_DROP))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_DROP) &&
+	  nh->drop == znh->drop)
+        match++;
+    }
+  else if (CHECK_FLAG(either, ZEBRA_NEXTHOP_IPV4))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_IPV4) &&
+         (IPV4_ADDR_SAME (&nh->gate.ipv4, &znh->gate.ipv4) ||
+          IPV4_ADDR_SAME (&nh->rgate.ipv4, &znh->rgate.ipv4)))
+	{
+	  match++;
+	  v4_gate_match = 1;
+	}
+    }
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG(either, ZEBRA_NEXTHOP_IPV6))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_IPV6) &&
+         (IPV6_ADDR_SAME (&nh->gate.ipv6, &znh->gate.ipv6) ||
+          IPV6_ADDR_SAME (&nh->rgate.ipv6, &znh->rgate.ipv6)))
+        match++;
+    }
+#endif
 
-  nexthop_add (rib, nexthop);
+  if (CHECK_FLAG(either, ZEBRA_NEXTHOP_IFINDEX))
+    {
+      if (!v4_gate_match)
+        {
+          try++;
+          if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IFINDEX) &&
+            (nh->ifindex == znh->ifindex))
+            match++;
+        }
+      else if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IFINDEX))
+        {
+            try++;
+            if (nh->ifindex == znh->ifindex)
+              match++;
+        }
+    }
+  else if (CHECK_FLAG(either, ZEBRA_NEXTHOP_IFNAME))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_IFNAME) &&
+         (!strncmp(nh->ifname, znh->ifname, IFNAMSIZ)))
+        match++;
+    }
 
-  return nexthop;
+  if (CHECK_FLAG(either, ZEBRA_NEXTHOP_SRC_IPV4))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_SRC_IPV4) &&
+          IPV4_ADDR_SAME (&nh->src.ipv4, &znh->src.ipv4))
+        match++;
+    }
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG(either, ZEBRA_NEXTHOP_SRC_IPV6))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_SRC_IPV6) &&
+          IPV6_ADDR_SAME (&nh->src.ipv6, &znh->src.ipv6))
+        match++;
+    }
+#endif
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG(either, ZEBRA_NEXTHOP_MPLS))
+    {
+      try++;
+      if (CHECK_FLAG(both, ZEBRA_NEXTHOP_MPLS) &&
+          nh->mpls == znh->mpls)
+        match++;
+    }
+#endif
+  return (try && try == match) ? 1 : 0;
 }
-
-static struct nexthop *
-nexthop_ipv6_ifname_add (struct rib *rib, struct in6_addr *ipv6,
-			 char *ifname)
+/* Add nexthop to the end of the list.  */
+static void
+nexthop_add (struct rib *rib, struct nexthop *nexthop)
 {
-  struct nexthop *nexthop;
-
-  nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
-  memset (nexthop, 0, sizeof (struct nexthop));
-  nexthop->type = NEXTHOP_TYPE_IPV6_IFNAME;
-  nexthop->gate.ipv6 = *ipv6;
-  nexthop->ifname = XSTRDUP (0, ifname);
+  struct nexthop *last;
 
-  nexthop_add (rib, nexthop);
+  for (last = rib->nexthop; last && last->next; last = last->next)
+    ;
+  if (last)
+    last->next = nexthop;
+  else
+    rib->nexthop = nexthop;
+  nexthop->prev = last;
 
-  return nexthop;
+  rib->nexthop_num++;
 }
 
-static struct nexthop *
-nexthop_ipv6_ifindex_add (struct rib *rib, struct in6_addr *ipv6,
-			  unsigned int ifindex)
+/* Delete specified nexthop from the list. */
+void
+nexthop_delete (struct rib *rib, struct nexthop *nexthop)
 {
-  struct nexthop *nexthop;
-
-  nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
-  memset (nexthop, 0, sizeof (struct nexthop));
-  nexthop->type = NEXTHOP_TYPE_IPV6_IFINDEX;
-  nexthop->gate.ipv6 = *ipv6;
-  nexthop->ifindex = ifindex;
-
-  nexthop_add (rib, nexthop);
+  if (nexthop->next)
+    nexthop->next->prev = nexthop->prev;
+  if (nexthop->prev)
+    nexthop->prev->next = nexthop->next;
+  else
+    rib->nexthop = nexthop->next;
+  rib->nexthop_num--;
+}
 
-  return nexthop;
+/* Free nexthop. */
+void
+nexthop_free (struct nexthop *nexthop)
+{
+  if (nexthop->ifname)
+    XFREE (0, nexthop->ifname);
+  XFREE (MTYPE_NEXTHOP, nexthop);
 }
-#endif /* HAVE_IPV6 */
 
 struct nexthop *
-nexthop_blackhole_add (struct rib *rib)
+nexthop_zapi_nexthop_add(struct rib *rib, struct zapi_nexthop* znh)
 {
   struct nexthop *nexthop;
 
   nexthop = XMALLOC (MTYPE_NEXTHOP, sizeof (struct nexthop));
   memset (nexthop, 0, sizeof (struct nexthop));
-  nexthop->type = NEXTHOP_TYPE_BLACKHOLE;
-  SET_FLAG (rib->flags, ZEBRA_FLAG_BLACKHOLE);
 
-  nexthop_add (rib, nexthop);
+  zapi_nexthop2nexthop(znh, nexthop);
+  nexthop_add(rib, nexthop);
 
   return nexthop;
 }
@@ -339,33 +603,54 @@
 /* If force flag is not set, do not modify falgs at all for uninstall
    the route from FIB. */
 static int
-nexthop_active_ipv4 (struct rib *rib, struct nexthop *nexthop, int set,
-		     struct route_node *top)
+nexthop_active_route (struct rib *rib, struct nexthop *nexthop, int set,
+		      struct route_node *top)
 {
-  struct prefix_ipv4 p;
+  struct prefix p;
   struct route_table *table;
   struct route_node *rn;
   struct rib *match;
   struct nexthop *newhop;
+  int afi;
+
+  memset (&p, 0, sizeof (struct prefix));
 
-  if (nexthop->type == NEXTHOP_TYPE_IPV4)
-    nexthop->ifindex = 0;
+  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
+    {
+      nexthop->ifindex = 0;
+      UNSET_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX);
+
+      /* Make lookup prefix. */
+      p.family = AF_INET;
+      p.prefixlen = IPV4_MAX_PREFIXLEN;
+      p.u.prefix4 = nexthop->gate.ipv4;
+      afi = AFI_IP;
+    }
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
+    {
+      nexthop->ifindex = 0;
+      UNSET_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX);
+
+      /* Make lookup prefix. */
+      p.family = AF_INET6;
+      p.prefixlen = IPV6_MAX_PREFIXLEN;
+      p.u.prefix6 = nexthop->gate.ipv6;
+      afi = AFI_IP6;
+    }
+#endif
+  else
+    return 0;
 
   if (set)
     UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_RECURSIVE);
 
-  /* Make lookup prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv4));
-  p.family = AF_INET;
-  p.prefixlen = IPV4_MAX_PREFIXLEN;
-  p.prefix = nexthop->gate.ipv4;
-
   /* Lookup table.  */
-  table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
+  table = vrf_table (afi, SAFI_UNICAST, 0);
   if (! table)
     return 0;
 
-  rn = route_node_match (table, (struct prefix *) &p);
+  rn = route_node_match (table, &p);
   while (rn)
     {
       route_unlock_node (rn);
@@ -396,8 +681,11 @@
 	    {
 	      /* Directly point connected route. */
 	      newhop = match->nexthop;
-	      if (newhop && nexthop->type == NEXTHOP_TYPE_IPV4)
-		nexthop->ifindex = newhop->ifindex;
+	      if (newhop)
+		{
+		  SET_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX);
+		  nexthop->ifindex = newhop->ifindex;
+		}
 	      
 	      return 1;
 	    }
@@ -405,19 +693,29 @@
 	    {
 	      for (newhop = match->nexthop; newhop; newhop = newhop->next)
 		if (CHECK_FLAG (newhop->flags, NEXTHOP_FLAG_FIB)
+		    && ! CHECK_FLAG (newhop->flags, NEXTHOP_FLAG_IGNORE)
 		    && ! CHECK_FLAG (newhop->flags, NEXTHOP_FLAG_RECURSIVE))
 		  {
 		    if (set)
 		      {
 			SET_FLAG (nexthop->flags, NEXTHOP_FLAG_RECURSIVE);
 			nexthop->rtype = newhop->type;
-			if (newhop->type == NEXTHOP_TYPE_IPV4 ||
-			    newhop->type == NEXTHOP_TYPE_IPV4_IFINDEX)
+
+			if (CHECK_FLAG (newhop->type, ZEBRA_NEXTHOP_IPV4))
 			  nexthop->rgate.ipv4 = newhop->gate.ipv4;
-			if (newhop->type == NEXTHOP_TYPE_IFINDEX
-			    || newhop->type == NEXTHOP_TYPE_IFNAME
-			    || newhop->type == NEXTHOP_TYPE_IPV4_IFINDEX)
+#ifdef HAVE_IPV6
+			else if (CHECK_FLAG (newhop->type, ZEBRA_NEXTHOP_IPV6))
+			  nexthop->rgate.ipv6 = newhop->gate.ipv6;
+#endif
+			else
+			  assert (0);
+
+			if (CHECK_FLAG (newhop->type, ZEBRA_NEXTHOP_IFINDEX))
 			  nexthop->rifindex = newhop->ifindex;
+#ifdef HAVE_MPLS
+			if (CHECK_FLAG (newhop->type, ZEBRA_NEXTHOP_MPLS))
+			    nexthop->rmpls = newhop->mpls;
+#endif
 		      }
 		    return 1;
 		  }
@@ -432,45 +730,78 @@
   return 0;
 }
 
-#ifdef HAVE_IPV6
-/* If force flag is not set, do not modify falgs at all for uninstall
-   the route from FIB. */
-static int
-nexthop_active_ipv6 (struct rib *rib, struct nexthop *nexthop, int set,
-		     struct route_node *top)
+int
+rib_check_drop (struct rib *rib)
+{
+  struct nexthop *nexthop;
+  int flags = 0;
+  int drop = 0;
+
+  for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
+    {
+      if ((CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE) ||
+           CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB)) &&
+           ((CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_RECURSIVE) &&
+	     CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_DROP)) ||
+	     CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP)))
+	{
+	  drop = nexthop->drop;
+	  break;
+	}
+    }
+
+  switch (drop)
+    {
+      case 0:
+	break;
+      case ZEBRA_DROP_NULL:
+      case ZEBRA_DROP_BLACKHOLE:
+        flags = ZEBRA_FLAG_BLACKHOLE;
+        break;
+      case ZEBRA_DROP_REJECT:
+        flags = ZEBRA_FLAG_REJECT;
+        break;
+      default:
+        assert(0);
+    }
+
+  return flags;
+}
+
+struct rib *
+rib_match_route (struct prefix *p)
 {
-  struct prefix_ipv6 p;
   struct route_table *table;
   struct route_node *rn;
   struct rib *match;
   struct nexthop *newhop;
+  int afi;
 
-  if (nexthop->type == NEXTHOP_TYPE_IPV6)
-    nexthop->ifindex = 0;
-
-  if (set)
-    UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_RECURSIVE);
-
-  /* Make lookup prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv6));
-  p.family = AF_INET6;
-  p.prefixlen = IPV6_MAX_PREFIXLEN;
-  p.prefix = nexthop->gate.ipv6;
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+	p->prefixlen = IPV4_MAX_PREFIXLEN;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+	p->prefixlen = IPV6_MAX_PREFIXLEN;
+        break;
+      default:
+        assert(0);
+    }
 
   /* Lookup table.  */
-  table = vrf_table (AFI_IP6, SAFI_UNICAST, 0);
+  table = vrf_table (afi, SAFI_UNICAST, 0);
   if (! table)
     return 0;
 
-  rn = route_node_match (table, (struct prefix *) &p);
+  rn = route_node_match (table, p);
+
   while (rn)
     {
       route_unlock_node (rn);
       
-      /* If lookup self prefix return immidiately. */
-      if (rn == top)
-	return 0;
-
       /* Pick up selected route. */
       for (match = rn->info; match; match = match->next)
 	if (CHECK_FLAG (match->flags, ZEBRA_FLAG_SELECTED))
@@ -478,94 +809,7 @@
 
       /* If there is no selected route or matched route is EGP, go up
          tree. */
-      if (! match
-	  || match->type == ZEBRA_ROUTE_BGP)
-	{
-	  do {
-	    rn = rn->parent;
-	  } while (rn && rn->info == NULL);
-	  if (rn)
-	    route_lock_node (rn);
-	}
-      else
-	{
-	  if (match->type == ZEBRA_ROUTE_CONNECT)
-	    {
-	      /* Directly point connected route. */
-	      newhop = match->nexthop;
-
-	      if (newhop && nexthop->type == NEXTHOP_TYPE_IPV6)
-		nexthop->ifindex = newhop->ifindex;
-	      
-	      return 1;
-	    }
-	  else if (CHECK_FLAG (rib->flags, ZEBRA_FLAG_INTERNAL))
-	    {
-	      for (newhop = match->nexthop; newhop; newhop = newhop->next)
-		if (CHECK_FLAG (newhop->flags, NEXTHOP_FLAG_FIB)
-		    && ! CHECK_FLAG (newhop->flags, NEXTHOP_FLAG_RECURSIVE))
-		  {
-		    if (set)
-		      {
-			SET_FLAG (nexthop->flags, NEXTHOP_FLAG_RECURSIVE);
-			nexthop->rtype = newhop->type;
-			if (newhop->type == NEXTHOP_TYPE_IPV6
-			    || newhop->type == NEXTHOP_TYPE_IPV6_IFINDEX
-			    || newhop->type == NEXTHOP_TYPE_IPV6_IFNAME)
-			  nexthop->rgate.ipv6 = newhop->gate.ipv6;
-			if (newhop->type == NEXTHOP_TYPE_IFINDEX
-			    || newhop->type == NEXTHOP_TYPE_IFNAME
-			    || newhop->type == NEXTHOP_TYPE_IPV6_IFINDEX
-			    || newhop->type == NEXTHOP_TYPE_IPV6_IFNAME)
-			  nexthop->rifindex = newhop->ifindex;
-		      }
-		    return 1;
-		  }
-	      return 0;
-	    }
-	  else
-	    {
-	      return 0;
-	    }
-	}
-    }
-  return 0;
-}
-#endif /* HAVE_IPV6 */
-
-struct rib *
-rib_match_ipv4 (struct in_addr addr)
-{
-  struct prefix_ipv4 p;
-  struct route_table *table;
-  struct route_node *rn;
-  struct rib *match;
-  struct nexthop *newhop;
-
-  /* Lookup table.  */
-  table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
-  if (! table)
-    return 0;
-
-  memset (&p, 0, sizeof (struct prefix_ipv4));
-  p.family = AF_INET;
-  p.prefixlen = IPV4_MAX_PREFIXLEN;
-  p.prefix = addr;
-
-  rn = route_node_match (table, (struct prefix *) &p);
-
-  while (rn)
-    {
-      route_unlock_node (rn);
-      
-      /* Pick up selected route. */
-      for (match = rn->info; match; match = match->next)
-	if (CHECK_FLAG (match->flags, ZEBRA_FLAG_SELECTED))
-	  break;
-
-      /* If there is no selected route or matched route is EGP, go up
-         tree. */
-      if (! match 
+      if (! match 
 	  || match->type == ZEBRA_ROUTE_BGP)
 	{
 	  do {
@@ -582,7 +826,8 @@
 	  else
 	    {
 	      for (newhop = match->nexthop; newhop; newhop = newhop->next)
-		if (CHECK_FLAG (newhop->flags, NEXTHOP_FLAG_FIB))
+		if (CHECK_FLAG (newhop->flags, NEXTHOP_FLAG_FIB)
+		    && ! CHECK_FLAG (newhop->flags, NEXTHOP_FLAG_IGNORE))
 		  return match;
 	      return NULL;
 	    }
@@ -592,19 +837,32 @@
 }
 
 struct rib *
-rib_lookup_ipv4 (struct prefix_ipv4 *p)
+rib_lookup_route (struct prefix *p)
 {
   struct route_table *table;
   struct route_node *rn;
   struct rib *match;
   struct nexthop *nexthop;
+  int afi;
+
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+        break;
+      default:
+        assert(0);
+    }
 
   /* Lookup table.  */
-  table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
+  table = vrf_table (afi, SAFI_UNICAST, 0);
   if (! table)
     return 0;
 
-  rn = route_node_lookup (table, (struct prefix *) p);
+  rn = route_node_lookup (table, p);
 
   /* No route for this prefix. */
   if (! rn)
@@ -625,15 +883,16 @@
     return match;
   
   for (nexthop = match->nexthop; nexthop; nexthop = nexthop->next)
-    if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB))
+    if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB)
+	&& ! CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
       return match;
 
   return NULL;
 }
 
 /*
- * This clone function, unlike its original rib_lookup_ipv4(), checks
- * if specified IPv4 route record (prefix/mask -> gate) exists in
+ * This clone function, unlike its original rib_lookup_route(), checks
+ * if specified route record (prefix/mask -> gate) exists in
  * the whole RIB and has ZEBRA_FLAG_SELECTED set.
  *
  * Return values:
@@ -644,20 +903,33 @@
  * 3: no matches found
  */
 int
-rib_lookup_ipv4_route (struct prefix_ipv4 *p, union sockunion * qgate)
+rib_lookup_route_nexthop (struct prefix *p, struct zapi_nexthop *znh)
 {
   struct route_table *table;
   struct route_node *rn;
   struct rib *match;
   struct nexthop *nexthop;
+  int afi;
+
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+        break;
+      default:
+	assert(0);
+    }
 
   /* Lookup table.  */
-  table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
+  table = vrf_table (afi, SAFI_UNICAST, 0);
   if (! table)
     return ZEBRA_RIB_LOOKUP_ERROR;
 
   /* Scan the RIB table for exactly matching RIB entry. */
-  rn = route_node_lookup (table, (struct prefix *) p);
+  rn = route_node_lookup (table, p);
 
   /* No route for this prefix. */
   if (! rn)
@@ -687,17 +959,17 @@
     if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB))
     {
       /* We are happy with either direct or recursive hexthop */
-      if (nexthop->gate.ipv4.s_addr == qgate->sin.sin_addr.s_addr ||
-          nexthop->rgate.ipv4.s_addr == qgate->sin.sin_addr.s_addr)
+      if (zapi_nexthop_match_nexthop(znh, nexthop,
+	ZEBRA_NEXTHOP_IPV4|ZEBRA_NEXTHOP_IPV6))
         return ZEBRA_RIB_FOUND_EXACT;
       else
       {
         if (IS_ZEBRA_DEBUG_RIB)
         {
           char gate_buf[INET_ADDRSTRLEN], rgate_buf[INET_ADDRSTRLEN], qgate_buf[INET_ADDRSTRLEN];
-          inet_ntop (AF_INET, &nexthop->gate.ipv4.s_addr, gate_buf, INET_ADDRSTRLEN);
-          inet_ntop (AF_INET, &nexthop->rgate.ipv4.s_addr, rgate_buf, INET_ADDRSTRLEN);
-          inet_ntop (AF_INET, &qgate->sin.sin_addr.s_addr, qgate_buf, INET_ADDRSTRLEN);
+          inet_ntop (p->family, &nexthop->gate, gate_buf, INET_ADDRSTRLEN);
+          inet_ntop (p->family, &nexthop->rgate, rgate_buf, INET_ADDRSTRLEN);
+          inet_ntop (p->family, &znh->gw, qgate_buf, INET_ADDRSTRLEN);
           zlog_debug ("%s: qgate == %s, gate == %s, rgate == %s", __func__, qgate_buf, gate_buf, rgate_buf);
         }
         return ZEBRA_RIB_FOUND_NOGATE;
@@ -707,66 +979,6 @@
   return ZEBRA_RIB_NOTFOUND;
 }
 
-#ifdef HAVE_IPV6
-struct rib *
-rib_match_ipv6 (struct in6_addr *addr)
-{
-  struct prefix_ipv6 p;
-  struct route_table *table;
-  struct route_node *rn;
-  struct rib *match;
-  struct nexthop *newhop;
-
-  /* Lookup table.  */
-  table = vrf_table (AFI_IP6, SAFI_UNICAST, 0);
-  if (! table)
-    return 0;
-
-  memset (&p, 0, sizeof (struct prefix_ipv6));
-  p.family = AF_INET6;
-  p.prefixlen = IPV6_MAX_PREFIXLEN;
-  IPV6_ADDR_COPY (&p.prefix, addr);
-
-  rn = route_node_match (table, (struct prefix *) &p);
-
-  while (rn)
-    {
-      route_unlock_node (rn);
-      
-      /* Pick up selected route. */
-      for (match = rn->info; match; match = match->next)
-	if (CHECK_FLAG (match->flags, ZEBRA_FLAG_SELECTED))
-	  break;
-
-      /* If there is no selected route or matched route is EGP, go up
-         tree. */
-      if (! match 
-	  || match->type == ZEBRA_ROUTE_BGP)
-	{
-	  do {
-	    rn = rn->parent;
-	  } while (rn && rn->info == NULL);
-	  if (rn)
-	    route_lock_node (rn);
-	}
-      else
-	{
-	  if (match->type == ZEBRA_ROUTE_CONNECT)
-	    /* Directly point connected route. */
-	    return match;
-	  else
-	    {
-	      for (newhop = match->nexthop; newhop; newhop = newhop->next)
-		if (CHECK_FLAG (newhop->flags, NEXTHOP_FLAG_FIB))
-		  return match;
-	      return NULL;
-	    }
-	}
-    }
-  return NULL;
-}
-#endif /* HAVE_IPV6 */
-
 #define RIB_SYSTEM_ROUTE(R) \
         ((R)->type == ZEBRA_ROUTE_KERNEL || (R)->type == ZEBRA_ROUTE_CONNECT)
 
@@ -789,76 +1001,105 @@
   extern char *proto_rm[AFI_MAX][ZEBRA_ROUTE_MAX+1];
   struct route_map *rmap;
   int family;
+  int try = 0;
+  int match = 0;
 
   family = 0;
-  switch (nexthop->type)
+  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
     {
-    case NEXTHOP_TYPE_IFINDEX:
-      ifp = if_lookup_by_index (nexthop->ifindex);
-      if (ifp && if_is_operative(ifp))
-	SET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-      else
-	UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-      break;
-    case NEXTHOP_TYPE_IPV6_IFNAME:
-      family = AFI_IP6;
-    case NEXTHOP_TYPE_IFNAME:
+      try++;
       ifp = if_lookup_by_name (nexthop->ifname);
       if (ifp && if_is_operative(ifp))
 	{
 	  if (set)
-	    nexthop->ifindex = ifp->ifindex;
-	  SET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
+	    {
+	      nexthop->ifindex = ifp->ifindex;
+	      SET_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX);
+	      UNSET_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME);
+	    }
+          match++;
 	}
       else
 	{
 	  if (set)
-	    nexthop->ifindex = 0;
-	  UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
+	    {
+	      nexthop->ifindex = 0;
+	      UNSET_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX);
+	      SET_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME);
+	    }
 	}
-      break;
-    case NEXTHOP_TYPE_IPV4:
-    case NEXTHOP_TYPE_IPV4_IFINDEX:
+    }
+  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+    {
+      try++;
+      ifp = if_lookup_by_index (nexthop->ifindex);
+      if (ifp && if_is_up (ifp)) {
+        match++;
+      }
+    }
+
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_MPLS))
+    {
+      try++;
+      if (mpls_out_segment_find(nexthop->mpls))
+	match++;
+    }
+#endif
+
+  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
+    {
       family = AFI_IP;
-      if (nexthop_active_ipv4 (rib, nexthop, set, rn))
-	SET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-      else
-	UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-      break;
+      try++;
+      if (nexthop_active_route (rib, nexthop, set, rn)) {
+        match++;
+      }
+    }
 #ifdef HAVE_IPV6
-    case NEXTHOP_TYPE_IPV6:
-      family = AFI_IP6;
-      if (nexthop_active_ipv6 (rib, nexthop, set, rn))
-	SET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-      else
-	UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-      break;
-    case NEXTHOP_TYPE_IPV6_IFINDEX:
+  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
+    {
       family = AFI_IP6;
-      if (IN6_IS_ADDR_LINKLOCAL (&nexthop->gate.ipv6))
-	{
-	  ifp = if_lookup_by_index (nexthop->ifindex);
-	  if (ifp && if_is_operative(ifp))
-	    SET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-	  else
-	    UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-	}
+      try++;
+      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+        {
+          if (IN6_IS_ADDR_LINKLOCAL (&nexthop->gate.ipv6))
+            {
+              ifp = if_lookup_by_index (nexthop->ifindex);
+              if (ifp && if_is_operative(ifp)) {
+                match++;
+              }
+            }
+          else
+            {
+              if (nexthop_active_route (rib, nexthop, set, rn)) {
+                match++;
+              }
+            }
+        }
       else
-	{
-	  if (nexthop_active_ipv6 (rib, nexthop, set, rn))
-	    SET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-	  else
-	    UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-	}
-      break;
+        {
+          if (nexthop_active_route (rib, nexthop, set, rn)) {
+            match++;
+          }
+        }
+    }
 #endif /* HAVE_IPV6 */
-    case NEXTHOP_TYPE_BLACKHOLE:
-      SET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
-      break;
-    default:
-      break;
+  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
+    {
+      try++;
+      match++;
     }
-  if (! CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE))
+
+  try++;
+  if (!CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
+    match++;
+
+  if (try && (try == match))
+    SET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
+  else
+    UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
+
+  if (!CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE))
     return 0;
 
   if (RIB_SYSTEM_ROUTE(rib) ||
@@ -898,15 +1139,27 @@
 
   rib->nexthop_active_num = 0;
   UNSET_FLAG (rib->flags, ZEBRA_FLAG_CHANGED);
+  UNSET_FLAG (rib->flags, ZEBRA_FLAG_BLACKHOLE|ZEBRA_FLAG_REJECT);
 
   for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
   {
+    /*
+     * we want to process all nexthops even IGNORED ones incase
+     * a newly ignored nexthop was active, that should trigger
+     * a route change.  So nexthop_active_check is responsible
+     * for checking IGNORED and handling accordingly
+     */
     prev_active = CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE);
     if ((new_active = nexthop_active_check (rn, rib, nexthop, set)))
       rib->nexthop_active_num++;
     if (prev_active != new_active)
       SET_FLAG (rib->flags, ZEBRA_FLAG_CHANGED);
   }
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG (rib->flags, ZEBRA_FLAG_CHANGED_MPLS))
+    SET_FLAG (rib->flags, ZEBRA_FLAG_CHANGED);
+#endif
+  SET_FLAG (rib->flags, rib_check_drop(rib));
   return rib->nexthop_active_num;
 }
 
@@ -939,7 +1192,7 @@
 }
 
 /* Uninstall the route from kernel. */
-static int
+int
 rib_uninstall_kernel (struct route_node *rn, struct rib *rib)
 {
   int ret = 0;
@@ -1096,7 +1349,11 @@
                      __func__, buf, rn->p.prefixlen, select, fib);
       if (CHECK_FLAG (select->flags, ZEBRA_FLAG_CHANGED))
         {
-          redistribute_delete (&rn->p, select);
+#ifdef HAVE_MPLS
+	  if (!CHECK_FLAG (select->flags, ZEBRA_FLAG_CHANGED_MPLS))
+#endif
+	    redistribute_delete (&rn->p, select);
+
           if (! RIB_SYSTEM_ROUTE (select))
             rib_uninstall_kernel (rn, select);
 
@@ -1105,7 +1362,11 @@
   
           if (! RIB_SYSTEM_ROUTE (select))
             rib_install_kernel (rn, select);
-          redistribute_add (&rn->p, select);
+
+#ifdef HAVE_MPLS
+	  if (!CHECK_FLAG (select->flags, ZEBRA_FLAG_CHANGED_MPLS))
+#endif
+	    redistribute_add (&rn->p, select);
         }
       else if (! RIB_SYSTEM_ROUTE (select))
         {
@@ -1125,6 +1386,9 @@
           if (! installed) 
             rib_install_kernel (rn, select);
         }
+#ifdef HAVE_MPLS
+      UNSET_FLAG (select->flags, ZEBRA_FLAG_CHANGED_MPLS);
+#endif
       goto end;
     }
 
@@ -1161,7 +1425,13 @@
       if (! RIB_SYSTEM_ROUTE (select))
         rib_install_kernel (rn, select);
       SET_FLAG (select->flags, ZEBRA_FLAG_SELECTED);
-      redistribute_add (&rn->p, select);
+#ifdef HAVE_MPLS
+      if (!CHECK_FLAG (select->flags, ZEBRA_FLAG_CHANGED_MPLS))
+#endif
+        redistribute_add (&rn->p, select);
+#ifdef HAVE_MPLS
+      UNSET_FLAG (select->flags, ZEBRA_FLAG_CHANGED_MPLS);
+#endif
     }
 
   /* FIB route was removed, should be deleted */
@@ -1268,7 +1538,7 @@
 }
 
 /* Add route_node to work queue and schedule processing */
-static void
+void
 rib_queue_add (struct zebra_t *zebra, struct route_node *rn)
 {
   char buf[INET_ADDRSTRLEN];
@@ -1519,24 +1789,97 @@
 }
 
 int
-rib_add_ipv4 (int type, int flags, struct prefix_ipv4 *p, 
-	      struct in_addr *gate, struct in_addr *src,
-	      unsigned int ifindex, u_int32_t vrf_id,
-	      u_int32_t metric, u_char distance)
+rib_find_nexthop2 (int owner, struct rib *rib_in, struct nexthop *nh_in,
+  struct rib **rib_out, struct nexthop **nh_out)
+{
+  struct nexthop *nh = NULL;
+  struct rib *rib = NULL;
+
+  for (rib = rib_in; rib; rib = rib->next)
+    {
+      if ((owner >= 0) && (rib->type != owner))
+        continue;
+
+      for (nh = rib->nexthop; nh; nh = nh->next)
+        {
+          if (nexthop_match(nh_in, nh,
+	      (ZEBRA_NEXTHOP_ALL & (~ZEBRA_NEXTHOP_MPLS))))
+            {
+	      *rib_out = rib;
+	      *nh_out = nh;
+	      return 0;
+            }
+        }
+    }
+  return 1;
+}
+
+int
+rib_find_nexthop (int owner, struct prefix *p_in, struct nexthop *nh_in,
+  struct route_node **rn_out, struct rib **rib_out, struct nexthop **nh_out)
+{
+  struct route_table *table = NULL;
+  struct route_node *rn = NULL;
+
+  *rn_out = NULL;
+  *rib_out = NULL;
+  *nh_out = NULL;
+
+  switch (p_in->family)
+    {
+      case AF_INET:
+        table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
+        break;
+      case AF_INET6:
+        table = vrf_table (AFI_IP6, SAFI_UNICAST, 0);
+        break;
+      default:
+        assert(0);
+    }
+
+  if ((!table) || (!(rn = route_node_lookup (table, p_in))))
+    return 1;
+ 
+  if (!rib_find_nexthop2(owner, rn->info, nh_in, rib_out, nh_out))
+    {
+      *rn_out = rn;
+      return 0;
+    }
+  route_unlock_node (rn);
+  return 1;
+}
+
+int
+rib_add_route (int type, int flags, struct prefix *p, 
+	       struct zapi_nexthop *nh, u_int32_t vrf_id,
+	       u_int32_t metric, u_char distance)
 {
   struct rib *rib;
   struct rib *same = NULL;
   struct route_table *table;
   struct route_node *rn;
   struct nexthop *nexthop;
+  int afi;
+
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+        break;
+      default:
+        assert(0);
+    }
 
   /* Lookup table.  */
-  table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
+  table = vrf_table (afi, SAFI_UNICAST, 0);
   if (! table)
     return 0;
 
   /* Make it sure prefixlen is applied to the prefix. */
-  apply_mask_ipv4 (p);
+  apply_mask (p);
 
   /* Set default distance by route type. */
   if (distance == 0)
@@ -1548,8 +1891,16 @@
 	distance = 200;
     }
 
+#ifdef HAVE_IPV6
+  /* Filter bogus route. */
+  if (afi == AFI_IP6 &&
+      rib_bogus_ipv6 (type, (struct prefix_ipv6*)p, &nh->gw.ipv6,
+                      nh->intf.index, 0))
+    return 0;
+#endif
+
   /* Lookup route node.*/
-  rn = route_node_get (table, (struct prefix *) p);
+  rn = route_node_get (table, p);
 
   /* If same type of route are installed, treat it as a implicit
      withdraw. */
@@ -1567,8 +1918,8 @@
         }
       /* Duplicate connected route comes in. */
       else if ((nexthop = rib->nexthop) &&
-	       nexthop->type == NEXTHOP_TYPE_IFINDEX &&
-	       nexthop->ifindex == ifindex &&
+	       zapi_nexthop_match_nexthop(nh, nexthop,
+               ZEBRA_NEXTHOP_IPV4|ZEBRA_NEXTHOP_IPV6) &&
 	       !CHECK_FLAG (rib->status, RIB_ENTRY_REMOVED))
 	{
 	  rib->refcnt++;
@@ -1587,20 +1938,16 @@
   rib->uptime = time (NULL);
 
   /* Nexthop settings. */
-  if (gate)
-    {
-      if (ifindex)
-	nexthop_ipv4_ifindex_add (rib, gate, src, ifindex);
-      else
-	nexthop_ipv4_add (rib, gate, src);
-    }
-  else
-    nexthop_ifindex_add (rib, ifindex);
+  nexthop_zapi_nexthop_add(rib, nh);
 
   /* If this route is kernel route, set FIB flag to the route. */
   if (type == ZEBRA_ROUTE_KERNEL || type == ZEBRA_ROUTE_CONNECT)
     for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
-      SET_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB);
+      {
+        if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
+	  continue;
+        SET_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB);
+      }
 
   /* Link new rib to node.*/
   if (IS_ZEBRA_DEBUG_RIB)
@@ -1676,7 +2023,7 @@
 }
 
 /* This is an exported helper to rtm_read() to dump the strange
- * RIB entry found by rib_lookup_ipv4_route()
+ * RIB entry found by rib_lookup_route_nexthop()
  */
 
 void rib_lookup_and_dump (struct prefix_ipv4 * p)
@@ -1777,19 +2124,33 @@
 }
 
 int
-rib_add_ipv4_multipath (struct prefix_ipv4 *p, struct rib *rib)
+rib_add_multipath (struct prefix *p, struct rib *rib)
 {
   struct route_table *table;
   struct route_node *rn;
   struct rib *same;
   struct nexthop *nexthop;
-  
-  /* Lookup table.  */
-  table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
+  int afi;
+
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+        break;
+      default:
+        assert(0);
+    }
+
+  
+  /* Lookup table.  */
+  table = vrf_table (afi, SAFI_UNICAST, 0);
   if (! table)
     return 0;
   /* Make it sure prefixlen is applied to the prefix. */
-  apply_mask_ipv4 (p);
+  apply_mask (p);
 
   /* Set default distance by route type. */
   if (rib->distance == 0)
@@ -1803,7 +2164,7 @@
     }
 
   /* Lookup route node.*/
-  rn = route_node_get (table, (struct prefix *) p);
+  rn = route_node_get (table, p);
 
   /* If same type of route are installed, treat it as a implicit
      withdraw. */
@@ -1820,7 +2181,11 @@
   /* If this route is kernel route, set FIB flag to the route. */
   if (rib->type == ZEBRA_ROUTE_KERNEL || rib->type == ZEBRA_ROUTE_CONNECT)
     for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
-      SET_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB);
+      {
+        if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
+	  continue;
+        SET_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB);
+      }
 
   /* Link new rib to node.*/
   rib_addnode (rn, rib);
@@ -1847,53 +2212,55 @@
   return 0;
 }
 
-/* XXX factor with rib_delete_ipv6 */
 int
-rib_delete_ipv4 (int type, int flags, struct prefix_ipv4 *p,
-		 struct in_addr *gate, unsigned int ifindex, u_int32_t vrf_id)
+rib_delete_route (int type, int flags, struct prefix *p,
+                  struct zapi_nexthop *nh, u_int32_t vrf_id)
 {
   struct route_table *table;
   struct route_node *rn;
   struct rib *rib;
   struct rib *fib = NULL;
   struct rib *same = NULL;
-  struct nexthop *nexthop;
-  char buf1[BUFSIZ];
-  char buf2[BUFSIZ];
+  char prefix_str[BUFSIZ];
+  int afi;
+
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+        break;
+      default:
+        assert(0);
+    }
 
   /* Lookup table.  */
-  table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
+  table = vrf_table (afi, SAFI_UNICAST, 0);
   if (! table)
     return 0;
 
   /* Apply mask. */
-  apply_mask_ipv4 (p);
+  apply_mask (p);
+
+  if (IS_ZEBRA_DEBUG_KERNEL)
+    {
+      inet_ntop (p->family, &p->u.prefix, prefix_str, BUFSIZ),
+      snprintf(&prefix_str[strlen(prefix_str)], BUFSIZ - strlen(prefix_str),
+               "/%d", p->prefixlen);
+      zapi_nexthop_str(nh, &prefix_str[strlen(prefix_str)],
+                         BUFSIZ - strlen(prefix_str));
 
-  if (IS_ZEBRA_DEBUG_KERNEL && gate)
-    zlog_debug ("rib_delete_ipv4(): route delete %s/%d via %s ifindex %d",
-		       inet_ntop (AF_INET, &p->prefix, buf1, BUFSIZ),
-		       p->prefixlen, 
-		       inet_ntoa (*gate), 
-		       ifindex);
+      zlog_debug ("rib_delete_route(): route delete %s", prefix_str);
+    }
 
   /* Lookup route node. */
-  rn = route_node_lookup (table, (struct prefix *) p);
+  rn = route_node_lookup (table, p);
   if (! rn)
     {
       if (IS_ZEBRA_DEBUG_KERNEL)
-	{
-	  if (gate)
-	    zlog_debug ("route %s/%d via %s ifindex %d doesn't exist in rib",
-		       inet_ntop (AF_INET, &p->prefix, buf1, BUFSIZ),
-		       p->prefixlen,
-		       inet_ntop (AF_INET, gate, buf2, BUFSIZ),
-		       ifindex);
-	  else
-	    zlog_debug ("route %s/%d ifindex %d doesn't exist in rib",
-		       inet_ntop (AF_INET, &p->prefix, buf1, BUFSIZ),
-		       p->prefixlen,
-		       ifindex);
-	}
+        zlog_debug ("route %s doesn't exist in rib", prefix_str);
       return ZEBRA_ERR_RTNOEXIST;
     }
 
@@ -1908,36 +2275,36 @@
 
       if (rib->type != type)
 	continue;
-      if (rib->type == ZEBRA_ROUTE_CONNECT && (nexthop = rib->nexthop) &&
-	  nexthop->type == NEXTHOP_TYPE_IFINDEX && nexthop->ifindex == ifindex)
-	{
-	  if (rib->refcnt)
+
+      /* Make sure that the route found matched */
+      if (zapi_nexthop_match_nexthop(nh, rib->nexthop, ZEBRA_NEXTHOP_ALL))
+        {
+          if (rib->type == ZEBRA_ROUTE_CONNECT)
 	    {
-	      rib->refcnt--;
-	      route_unlock_node (rn);
-	      route_unlock_node (rn);
-	      return 0;
+	      if (rib->refcnt)
+	        {
+	          rib->refcnt--;
+	          route_unlock_node (rn);
+	          route_unlock_node (rn);
+	          return 0;
+	        }
+	      same = rib;
+	      break;
 	    }
-	  same = rib;
-	  break;
-	}
-      /* Make sure that the route found has the same gateway. */
-      else if (gate == NULL ||
-	       ((nexthop = rib->nexthop) &&
-	        (IPV4_ADDR_SAME (&nexthop->gate.ipv4, gate) ||
-		 IPV4_ADDR_SAME (&nexthop->rgate.ipv4, gate)))) 
-        {
-	  same = rib;
-	  break;
-	}
+          else
+            {
+	      same = rib;
+	      break;
+	    }
+        }
     }
 
-  /* If same type of route can't be found and this message is from
-     kernel. */
+  /* If same type of route can't be found and this message is from kernel. */
   if (! same)
     {
       if (fib && type == ZEBRA_ROUTE_KERNEL)
 	{
+          struct nexthop *nexthop = NULL;
 	  /* Unset flags. */
 	  for (nexthop = fib->nexthop; nexthop; nexthop = nexthop->next)
 	    UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB);
@@ -1947,21 +2314,8 @@
       else
 	{
 	  if (IS_ZEBRA_DEBUG_KERNEL)
-	    {
-	      if (gate)
-		zlog_debug ("route %s/%d via %s ifindex %d type %d doesn't exist in rib",
-			   inet_ntop (AF_INET, &p->prefix, buf1, BUFSIZ),
-			   p->prefixlen,
-			   inet_ntop (AF_INET, gate, buf2, BUFSIZ),
-			   ifindex,
-			   type);
-	      else
-		zlog_debug ("route %s/%d ifindex %d type %d doesn't exist in rib",
-			   inet_ntop (AF_INET, &p->prefix, buf1, BUFSIZ),
-			   p->prefixlen,
-			   ifindex,
-			   type);
-	    }
+	    zlog_debug ("route %s type %d doesn't exist in rib",
+                        prefix_str, type);
 	  route_unlock_node (rn);
 	  return ZEBRA_ERR_RTNOEXIST;
 	}
@@ -1973,17 +2327,84 @@
   route_unlock_node (rn);
   return 0;
 }
+
+static int
+static_route_compare(struct static_route *a, struct static_route *b, int mask)
+{
+  int both = (a->nh.type & b->nh.type) & mask;
+  int ret = 0;
+
+  if (a->distance < b->distance)
+    return -1;
+
+  if (a->distance > b->distance)
+    return 1;
+
+  if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IPV4))
+    {
+      ret = IPV4_ADDR_CMP(&a->nh.gw.ipv4, &b->nh.gw.ipv4);
+      if (ret)
+	return ret;
+    }
+  else if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IPV6))
+    {
+      ret = IPV6_ADDR_CMP(&a->nh.gw.ipv6, &b->nh.gw.ipv6);
+      if (ret)
+	return ret;
+    }
+
+  if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IFNAME))
+    {
+      ret = strncmp(a->nh.intf.name, b->nh.intf.name, IFNAMSIZ);
+      if (ret)
+	return ret;
+    }
+  else if (CHECK_FLAG (both, ZEBRA_NEXTHOP_IFINDEX))
+    {
+      if (a->nh.intf.index < b->nh.intf.index)
+        return -1;
+      if (a->nh.intf.index > b->nh.intf.index)
+        return 1;
+    }
+#ifdef HAVE_MPLS
+  if (CHECK_FLAG (both, ZEBRA_NEXTHOP_MPLS))
+    {
+      int aos = mpls_out_segment_find_index_by_nexthop(&a->nh);
+      int bos = mpls_out_segment_find_index_by_nexthop(&b->nh);
+      if (aos < bos)
+        return -1;
+      if (aos > bos)
+        return 1;
+    }
+#endif
+
+  return 0;
+}
 
 /* Install static route into rib. */
 static void
-static_install_ipv4 (struct prefix *p, struct static_ipv4 *si)
+static_install_route (struct prefix *p, struct zapi_nexthop *nexthop, int distance)
 {
   struct rib *rib;
   struct route_node *rn;
   struct route_table *table;
+  int new = 0;
+  int afi;
 
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+        break;
+      default:
+        assert(0);
+    }
+    
   /* Lookup table.  */
-  table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
+  table = vrf_table (afi, SAFI_UNICAST, 0);
   if (! table)
     return;
 
@@ -1994,88 +2415,66 @@
        if (CHECK_FLAG (rib->status, RIB_ENTRY_REMOVED))
          continue;
         
-       if (rib->type == ZEBRA_ROUTE_STATIC && rib->distance == si->distance)
+       if (rib->type == ZEBRA_ROUTE_STATIC && rib->distance == distance)
          break;
     }
 
-  if (rib)
-    {
-      /* Same distance static route is there.  Update it with new
-         nexthop. */
-      route_unlock_node (rn);
-      switch (si->type)
-        {
-          case STATIC_IPV4_GATEWAY:
-            nexthop_ipv4_add (rib, &si->gate.ipv4, NULL);
-            break;
-          case STATIC_IPV4_IFNAME:
-            nexthop_ifname_add (rib, si->gate.ifname);
-            break;
-          case STATIC_IPV4_BLACKHOLE:
-            nexthop_blackhole_add (rib);
-            break;
-        }
-      rib_queue_add (&zebrad, rn);
-    }
-  else
+  if (!rib)
     {
+      new = 1;
+
       /* This is new static route. */
       rib = XCALLOC (MTYPE_RIB, sizeof (struct rib));
       
       rib->type = ZEBRA_ROUTE_STATIC;
-      rib->distance = si->distance;
+      rib->distance = distance;
       rib->metric = 0;
       rib->nexthop_num = 0;
+    }
+  else
+    {
+      /* Same distance static route is there.  Update it with new
+         nexthop. */
+      route_unlock_node (rn);
+    }
 
-      switch (si->type)
-        {
-          case STATIC_IPV4_GATEWAY:
-            nexthop_ipv4_add (rib, &si->gate.ipv4, NULL);
-            break;
-          case STATIC_IPV4_IFNAME:
-            nexthop_ifname_add (rib, si->gate.ifname);
-            break;
-          case STATIC_IPV4_BLACKHOLE:
-            nexthop_blackhole_add (rib);
-            break;
-        }
-
-      /* Save the flags of this static routes (reject, blackhole) */
-      rib->flags = si->flags;
+  nexthop_zapi_nexthop_add(rib, nexthop);
 
+  if (new)
+    {
       /* Link this rib to the tree. */
       rib_addnode (rn, rib);
     }
-}
-
-static int
-static_ipv4_nexthop_same (struct nexthop *nexthop, struct static_ipv4 *si)
-{
-  if (nexthop->type == NEXTHOP_TYPE_IPV4
-      && si->type == STATIC_IPV4_GATEWAY
-      && IPV4_ADDR_SAME (&nexthop->gate.ipv4, &si->gate.ipv4))
-    return 1;
-  if (nexthop->type == NEXTHOP_TYPE_IFNAME
-      && si->type == STATIC_IPV4_IFNAME
-      && strcmp (nexthop->ifname, si->gate.ifname) == 0)
-    return 1;
-  if (nexthop->type == NEXTHOP_TYPE_BLACKHOLE
-      && si->type == STATIC_IPV4_BLACKHOLE)
-    return 1;
-  return 0;
+  else
+    {
+      rib_queue_add (&zebrad, rn);
+    }
 }
 
 /* Uninstall static route from RIB. */
 static void
-static_uninstall_ipv4 (struct prefix *p, struct static_ipv4 *si)
+static_uninstall_route (struct prefix *p, struct zapi_nexthop *znexthop, int distance)
 {
   struct route_node *rn;
   struct rib *rib;
   struct nexthop *nexthop;
   struct route_table *table;
+  int afi;
+
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+        break;
+      default:
+        assert(0);
+    }
 
   /* Lookup table.  */
-  table = vrf_table (AFI_IP, SAFI_UNICAST, 0);
+  table = vrf_table (afi, SAFI_UNICAST, 0);
   if (! table)
     return;
   
@@ -2089,7 +2488,7 @@
       if (CHECK_FLAG (rib->status, RIB_ENTRY_REMOVED))
         continue;
 
-      if (rib->type == ZEBRA_ROUTE_STATIC && rib->distance == si->distance)
+      if (rib->type == ZEBRA_ROUTE_STATIC && rib->distance == distance)
         break;
     }
 
@@ -2101,7 +2500,7 @@
 
   /* Lookup nexthop. */
   for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
-    if (static_ipv4_nexthop_same (nexthop, si))
+    if (zapi_nexthop_match_nexthop (znexthop, nexthop, ZEBRA_NEXTHOP_ALL))
       break;
 
   /* Can't find nexthop. */
@@ -2128,82 +2527,67 @@
 
 /* Add static route into static route configuration. */
 int
-static_add_ipv4 (struct prefix *p, struct in_addr *gate, const char *ifname,
-		 u_char flags, u_char distance, u_int32_t vrf_id)
+static_add_route (struct prefix *p, struct zapi_nexthop *nexthop,
+		  u_char distance, u_int32_t vrf_id)
 {
-  u_char type = 0;
   struct route_node *rn;
-  struct static_ipv4 *si;
-  struct static_ipv4 *pp;
-  struct static_ipv4 *cp;
-  struct static_ipv4 *update = NULL;
+  struct static_route *si;
+  struct static_route *pp;
+  struct static_route *cp;
+  struct static_route *update = NULL;
   struct route_table *stable;
+  int afi;
+
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+        break;
+      default:
+        assert(0);
+    }
 
   /* Lookup table.  */
-  stable = vrf_static_table (AFI_IP, SAFI_UNICAST, vrf_id);
+  stable = vrf_static_table (afi, SAFI_UNICAST, vrf_id);
   if (! stable)
     return -1;
   
   /* Lookup static route prefix. */
   rn = route_node_get (stable, p);
 
-  /* Make flags. */
-  if (gate)
-    type = STATIC_IPV4_GATEWAY;
-  else if (ifname)
-    type = STATIC_IPV4_IFNAME;
-  else
-    type = STATIC_IPV4_BLACKHOLE;
-
   /* Do nothing if there is a same static route.  */
   for (si = rn->info; si; si = si->next)
-    {
-      if (type == si->type
-	  && (! gate || IPV4_ADDR_SAME (gate, &si->gate.ipv4))
-	  && (! ifname || strcmp (ifname, si->gate.ifname) == 0))
-	{
-	  if (distance == si->distance)
-	    {
-	      route_unlock_node (rn);
-	      return 0;
-	    }
-	  else
-	    update = si;
-	}
-    }
+    if (zapi_nexthop_match_static_route(distance, nexthop, si))
+      {
+	route_unlock_node (rn);
+	return 0;
+      }
+    else if (afi == AFI_IP)
+      update = si;
 
-  /* Distance changed.  */
+  /* Distance or nexthop changed.  */
   if (update)
-    static_delete_ipv4 (p, gate, ifname, update->distance, vrf_id);
+    static_delete_route (p, nexthop, update->distance, vrf_id);
 
   /* Make new static route structure. */
-  si = XMALLOC (MTYPE_STATIC_IPV4, sizeof (struct static_ipv4));
-  memset (si, 0, sizeof (struct static_ipv4));
+  si = XMALLOC (MTYPE_STATIC_ROUTE, sizeof (struct static_route));
+  memset (si, 0, sizeof (struct static_route));
 
-  si->type = type;
   si->distance = distance;
-  si->flags = flags;
-
-  if (gate)
-    si->gate.ipv4 = *gate;
-  if (ifname)
-    si->gate.ifname = XSTRDUP (0, ifname);
+  memcpy(&si->nh, nexthop, sizeof(struct zapi_nexthop));
 
   /* Add new static route information to the tree with sort by
      distance value and gateway address. */
   for (pp = NULL, cp = rn->info; cp; pp = cp, cp = cp->next)
     {
-      if (si->distance < cp->distance)
+      int cmp = static_route_compare(si, cp, ZEBRA_NEXTHOP_ALL);
+      if (cmp < 0)
 	break;
-      if (si->distance > cp->distance)
+      if (cmp > 0)
 	continue;
-      if (si->type == STATIC_IPV4_GATEWAY && cp->type == STATIC_IPV4_GATEWAY)
-	{
-	  if (ntohl (si->gate.ipv4.s_addr) < ntohl (cp->gate.ipv4.s_addr))
-	    break;
-	  if (ntohl (si->gate.ipv4.s_addr) > ntohl (cp->gate.ipv4.s_addr))
-	    continue;
-	}
     }
 
   /* Make linked list. */
@@ -2217,23 +2601,35 @@
   si->next = cp;
 
   /* Install into rib. */
-  static_install_ipv4 (p, si);
+  static_install_route (p, nexthop, distance);
 
   return 1;
 }
 
 /* Delete static route from static route configuration. */
 int
-static_delete_ipv4 (struct prefix *p, struct in_addr *gate, const char *ifname,
-		    u_char distance, u_int32_t vrf_id)
+static_delete_route (struct prefix *p, struct zapi_nexthop *nexthop,
+		     u_char distance, u_int32_t vrf_id)
 {
-  u_char type = 0;
   struct route_node *rn;
-  struct static_ipv4 *si;
+  struct static_route *si;
   struct route_table *stable;
+  int afi;
+
+  switch (p->family)
+    {
+      case AF_INET:
+        afi = AFI_IP;
+        break;
+      case AF_INET6:
+        afi = AFI_IP6;
+        break;
+      default:
+        assert(0);
+    }
 
   /* Lookup table.  */
-  stable = vrf_static_table (AFI_IP, SAFI_UNICAST, vrf_id);
+  stable = vrf_static_table (afi, SAFI_UNICAST, vrf_id);
   if (! stable)
     return -1;
 
@@ -2242,19 +2638,9 @@
   if (! rn)
     return 0;
 
-  /* Make flags. */
-  if (gate)
-    type = STATIC_IPV4_GATEWAY;
-  else if (ifname)
-    type = STATIC_IPV4_IFNAME;
-  else
-    type = STATIC_IPV4_BLACKHOLE;
-
   /* Find same static route is the tree */
   for (si = rn->info; si; si = si->next)
-    if (type == si->type
-	&& (! gate || IPV4_ADDR_SAME (gate, &si->gate.ipv4))
-	&& (! ifname || strcmp (ifname, si->gate.ifname) == 0))
+    if (zapi_nexthop_match_static_route(distance, nexthop, si))
       break;
 
   /* Can't find static route. */
@@ -2265,7 +2651,7 @@
     }
 
   /* Install into rib. */
-  static_uninstall_ipv4 (p, si);
+  static_uninstall_route (p, nexthop, distance);
 
   /* Unlink static route from linked list. */
   if (si->prev)
@@ -2277,15 +2663,12 @@
   route_unlock_node (rn);
   
   /* Free static route configuration. */
-  if (ifname)
-    XFREE (0, si->gate.ifname);
-  XFREE (MTYPE_STATIC_IPV4, si);
+  XFREE (MTYPE_STATIC_ROUTE, si);
 
   route_unlock_node (rn);
 
   return 1;
 }
-
 
 #ifdef HAVE_IPV6
 static int
@@ -2308,518 +2691,6 @@
     }
   return 0;
 }
-
-int
-rib_add_ipv6 (int type, int flags, struct prefix_ipv6 *p,
-	      struct in6_addr *gate, unsigned int ifindex, u_int32_t vrf_id,
-	      u_int32_t metric, u_char distance)
-{
-  struct rib *rib;
-  struct rib *same = NULL;
-  struct route_table *table;
-  struct route_node *rn;
-  struct nexthop *nexthop;
-
-  /* Lookup table.  */
-  table = vrf_table (AFI_IP6, SAFI_UNICAST, 0);
-  if (! table)
-    return 0;
-
-  /* Make sure mask is applied. */
-  apply_mask_ipv6 (p);
-
-  /* Set default distance by route type. */
-  if (!distance)
-    distance = route_info[type].distance;
-  
-  if (type == ZEBRA_ROUTE_BGP && CHECK_FLAG (flags, ZEBRA_FLAG_IBGP))
-    distance = 200;
-
-  /* Filter bogus route. */
-  if (rib_bogus_ipv6 (type, p, gate, ifindex, 0))
-    return 0;
-
-  /* Lookup route node.*/
-  rn = route_node_get (table, (struct prefix *) p);
-
-  /* If same type of route are installed, treat it as a implicit
-     withdraw. */
-  for (rib = rn->info; rib; rib = rib->next)
-    {
-      if (CHECK_FLAG (rib->status, RIB_ENTRY_REMOVED))
-        continue;
-
-      if (rib->type != type)
-	continue;
-      if (rib->type != ZEBRA_ROUTE_CONNECT)
-	{
-	  same = rib;
-	  break;
-	}
-      else if ((nexthop = rib->nexthop) &&
-	       nexthop->type == NEXTHOP_TYPE_IFINDEX &&
-	       nexthop->ifindex == ifindex)
-	{
-	  rib->refcnt++;
-	  return 0;
-	}
-    }
-
-  /* Allocate new rib structure. */
-  rib = XCALLOC (MTYPE_RIB, sizeof (struct rib));
-  
-  rib->type = type;
-  rib->distance = distance;
-  rib->flags = flags;
-  rib->metric = metric;
-  rib->table = vrf_id;
-  rib->nexthop_num = 0;
-  rib->uptime = time (NULL);
-
-  /* Nexthop settings. */
-  if (gate)
-    {
-      if (ifindex)
-	nexthop_ipv6_ifindex_add (rib, gate, ifindex);
-      else
-	nexthop_ipv6_add (rib, gate);
-    }
-  else
-    nexthop_ifindex_add (rib, ifindex);
-
-  /* If this route is kernel route, set FIB flag to the route. */
-  if (type == ZEBRA_ROUTE_KERNEL || type == ZEBRA_ROUTE_CONNECT)
-    for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
-      SET_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB);
-
-  /* Link new rib to node.*/
-  rib_addnode (rn, rib);
-
-  /* Free implicit route.*/
-  if (same)
-    rib_delnode (rn, same);
-  
-  route_unlock_node (rn);
-  return 0;
-}
-
-/* XXX factor with rib_delete_ipv6 */
-int
-rib_delete_ipv6 (int type, int flags, struct prefix_ipv6 *p,
-		 struct in6_addr *gate, unsigned int ifindex, u_int32_t vrf_id)
-{
-  struct route_table *table;
-  struct route_node *rn;
-  struct rib *rib;
-  struct rib *fib = NULL;
-  struct rib *same = NULL;
-  struct nexthop *nexthop;
-  char buf1[BUFSIZ];
-  char buf2[BUFSIZ];
-
-  /* Apply mask. */
-  apply_mask_ipv6 (p);
-
-  /* Lookup table.  */
-  table = vrf_table (AFI_IP6, SAFI_UNICAST, 0);
-  if (! table)
-    return 0;
-  
-  /* Lookup route node. */
-  rn = route_node_lookup (table, (struct prefix *) p);
-  if (! rn)
-    {
-      if (IS_ZEBRA_DEBUG_KERNEL)
-	{
-	  if (gate)
-	    zlog_debug ("route %s/%d via %s ifindex %d doesn't exist in rib",
-		       inet_ntop (AF_INET6, &p->prefix, buf1, BUFSIZ),
-		       p->prefixlen,
-		       inet_ntop (AF_INET6, gate, buf2, BUFSIZ),
-		       ifindex);
-	  else
-	    zlog_debug ("route %s/%d ifindex %d doesn't exist in rib",
-		       inet_ntop (AF_INET6, &p->prefix, buf1, BUFSIZ),
-		       p->prefixlen,
-		       ifindex);
-	}
-      return ZEBRA_ERR_RTNOEXIST;
-    }
-
-  /* Lookup same type route. */
-  for (rib = rn->info; rib; rib = rib->next)
-    {
-      if (CHECK_FLAG(rib->status, RIB_ENTRY_REMOVED))
-        continue;
-
-      if (CHECK_FLAG (rib->flags, ZEBRA_FLAG_SELECTED))
-	fib = rib;
-
-      if (rib->type != type)
-        continue;
-      if (rib->type == ZEBRA_ROUTE_CONNECT && (nexthop = rib->nexthop) &&
-	  nexthop->type == NEXTHOP_TYPE_IFINDEX && nexthop->ifindex == ifindex)
-	{
-	  if (rib->refcnt)
-	    {
-	      rib->refcnt--;
-	      route_unlock_node (rn);
-	      route_unlock_node (rn);
-	      return 0;
-	    }
-	  same = rib;
-	  break;
-	}
-      /* Make sure that the route found has the same gateway. */
-      else if (gate == NULL ||
-	       ((nexthop = rib->nexthop) &&
-	        (IPV6_ADDR_SAME (&nexthop->gate.ipv6, gate) ||
-		 IPV6_ADDR_SAME (&nexthop->rgate.ipv6, gate))))
-	{
-	  same = rib;
-	  break;
-	}
-    }
-
-  /* If same type of route can't be found and this message is from
-     kernel. */
-  if (! same)
-    {
-      if (fib && type == ZEBRA_ROUTE_KERNEL)
-	{
-	  /* Unset flags. */
-	  for (nexthop = fib->nexthop; nexthop; nexthop = nexthop->next)
-	    UNSET_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB);
-
-	  UNSET_FLAG (fib->flags, ZEBRA_FLAG_SELECTED);
-	}
-      else
-	{
-	  if (IS_ZEBRA_DEBUG_KERNEL)
-	    {
-	      if (gate)
-		zlog_debug ("route %s/%d via %s ifindex %d type %d doesn't exist in rib",
-			   inet_ntop (AF_INET6, &p->prefix, buf1, BUFSIZ),
-			   p->prefixlen,
-			   inet_ntop (AF_INET6, gate, buf2, BUFSIZ),
-			   ifindex,
-			   type);
-	      else
-		zlog_debug ("route %s/%d ifindex %d type %d doesn't exist in rib",
-			   inet_ntop (AF_INET6, &p->prefix, buf1, BUFSIZ),
-			   p->prefixlen,
-			   ifindex,
-			   type);
-	    }
-	  route_unlock_node (rn);
-	  return ZEBRA_ERR_RTNOEXIST;
-	}
-    }
-
-  if (same)
-    rib_delnode (rn, same);
-  
-  route_unlock_node (rn);
-  return 0;
-}
-
-/* Install static route into rib. */
-static void
-static_install_ipv6 (struct prefix *p, struct static_ipv6 *si)
-{
-  struct rib *rib;
-  struct route_table *table;
-  struct route_node *rn;
-
-  /* Lookup table.  */
-  table = vrf_table (AFI_IP6, SAFI_UNICAST, 0);
-  if (! table)
-    return;
-
-  /* Lookup existing route */
-  rn = route_node_get (table, p);
-  for (rib = rn->info; rib; rib = rib->next)
-    {
-      if (CHECK_FLAG(rib->status, RIB_ENTRY_REMOVED))
-        continue;
-
-      if (rib->type == ZEBRA_ROUTE_STATIC && rib->distance == si->distance)
-        break;
-    }
-
-  if (rib)
-    {
-      /* Same distance static route is there.  Update it with new
-         nexthop. */
-      route_unlock_node (rn);
-
-      switch (si->type)
-	{
-	case STATIC_IPV6_GATEWAY:
-	  nexthop_ipv6_add (rib, &si->ipv6);
-	  break;
-	case STATIC_IPV6_IFNAME:
-	  nexthop_ifname_add (rib, si->ifname);
-	  break;
-	case STATIC_IPV6_GATEWAY_IFNAME:
-	  nexthop_ipv6_ifname_add (rib, &si->ipv6, si->ifname);
-	  break;
-	}
-      rib_queue_add (&zebrad, rn);
-    }
-  else
-    {
-      /* This is new static route. */
-      rib = XCALLOC (MTYPE_RIB, sizeof (struct rib));
-      
-      rib->type = ZEBRA_ROUTE_STATIC;
-      rib->distance = si->distance;
-      rib->metric = 0;
-      rib->nexthop_num = 0;
-
-      switch (si->type)
-	{
-	case STATIC_IPV6_GATEWAY:
-	  nexthop_ipv6_add (rib, &si->ipv6);
-	  break;
-	case STATIC_IPV6_IFNAME:
-	  nexthop_ifname_add (rib, si->ifname);
-	  break;
-	case STATIC_IPV6_GATEWAY_IFNAME:
-	  nexthop_ipv6_ifname_add (rib, &si->ipv6, si->ifname);
-	  break;
-	}
-
-      /* Save the flags of this static routes (reject, blackhole) */
-      rib->flags = si->flags;
-
-      /* Link this rib to the tree. */
-      rib_addnode (rn, rib);
-    }
-}
-
-static int
-static_ipv6_nexthop_same (struct nexthop *nexthop, struct static_ipv6 *si)
-{
-  if (nexthop->type == NEXTHOP_TYPE_IPV6
-      && si->type == STATIC_IPV6_GATEWAY
-      && IPV6_ADDR_SAME (&nexthop->gate.ipv6, &si->ipv6))
-    return 1;
-  if (nexthop->type == NEXTHOP_TYPE_IFNAME
-      && si->type == STATIC_IPV6_IFNAME
-      && strcmp (nexthop->ifname, si->ifname) == 0)
-    return 1;
-  if (nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME
-      && si->type == STATIC_IPV6_GATEWAY_IFNAME
-      && IPV6_ADDR_SAME (&nexthop->gate.ipv6, &si->ipv6)
-      && strcmp (nexthop->ifname, si->ifname) == 0)
-    return 1;
-  return 0;
-}
-
-static void
-static_uninstall_ipv6 (struct prefix *p, struct static_ipv6 *si)
-{
-  struct route_table *table;
-  struct route_node *rn;
-  struct rib *rib;
-  struct nexthop *nexthop;
-
-  /* Lookup table.  */
-  table = vrf_table (AFI_IP6, SAFI_UNICAST, 0);
-  if (! table)
-    return;
-
-  /* Lookup existing route with type and distance. */
-  rn = route_node_lookup (table, (struct prefix *) p);
-  if (! rn)
-    return;
-
-  for (rib = rn->info; rib; rib = rib->next)
-    {
-      if (CHECK_FLAG (rib->status, RIB_ENTRY_REMOVED))
-        continue;
-    
-      if (rib->type == ZEBRA_ROUTE_STATIC && rib->distance == si->distance)
-        break;
-    }
-
-  if (! rib)
-    {
-      route_unlock_node (rn);
-      return;
-    }
-
-  /* Lookup nexthop. */
-  for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
-    if (static_ipv6_nexthop_same (nexthop, si))
-      break;
-
-  /* Can't find nexthop. */
-  if (! nexthop)
-    {
-      route_unlock_node (rn);
-      return;
-    }
-  
-  /* Check nexthop. */
-  if (rib->nexthop_num == 1)
-    {
-      rib_delnode (rn, rib);
-    }
-  else
-    {
-      if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB))
-        rib_uninstall (rn, rib);
-      nexthop_delete (rib, nexthop);
-      nexthop_free (nexthop);
-      rib_queue_add (&zebrad, rn);
-    }
-  /* Unlock node. */
-  route_unlock_node (rn);
-}
-
-/* Add static route into static route configuration. */
-int
-static_add_ipv6 (struct prefix *p, u_char type, struct in6_addr *gate,
-		 const char *ifname, u_char flags, u_char distance,
-		 u_int32_t vrf_id)
-{
-  struct route_node *rn;
-  struct static_ipv6 *si;
-  struct static_ipv6 *pp;
-  struct static_ipv6 *cp;
-  struct route_table *stable;
-
-  /* Lookup table.  */
-  stable = vrf_static_table (AFI_IP6, SAFI_UNICAST, vrf_id);
-  if (! stable)
-    return -1;
-    
-  if (!gate &&
-      (type == STATIC_IPV6_GATEWAY || type == STATIC_IPV6_GATEWAY_IFNAME))
-    return -1;
-  
-  if (!ifname && 
-      (type == STATIC_IPV6_GATEWAY_IFNAME || type == STATIC_IPV6_IFNAME))
-    return -1;
-
-  /* Lookup static route prefix. */
-  rn = route_node_get (stable, p);
-
-  /* Do nothing if there is a same static route.  */
-  for (si = rn->info; si; si = si->next)
-    {
-      if (distance == si->distance 
-	  && type == si->type
-	  && (! gate || IPV6_ADDR_SAME (gate, &si->ipv6))
-	  && (! ifname || strcmp (ifname, si->ifname) == 0))
-	{
-	  route_unlock_node (rn);
-	  return 0;
-	}
-    }
-
-  /* Make new static route structure. */
-  si = XMALLOC (MTYPE_STATIC_IPV6, sizeof (struct static_ipv6));
-  memset (si, 0, sizeof (struct static_ipv6));
-
-  si->type = type;
-  si->distance = distance;
-  si->flags = flags;
-
-  switch (type)
-    {
-    case STATIC_IPV6_GATEWAY:
-      si->ipv6 = *gate;
-      break;
-    case STATIC_IPV6_IFNAME:
-      si->ifname = XSTRDUP (0, ifname);
-      break;
-    case STATIC_IPV6_GATEWAY_IFNAME:
-      si->ipv6 = *gate;
-      si->ifname = XSTRDUP (0, ifname);
-      break;
-    }
-
-  /* Add new static route information to the tree with sort by
-     distance value and gateway address. */
-  for (pp = NULL, cp = rn->info; cp; pp = cp, cp = cp->next)
-    {
-      if (si->distance < cp->distance)
-	break;
-      if (si->distance > cp->distance)
-	continue;
-    }
-
-  /* Make linked list. */
-  if (pp)
-    pp->next = si;
-  else
-    rn->info = si;
-  if (cp)
-    cp->prev = si;
-  si->prev = pp;
-  si->next = cp;
-
-  /* Install into rib. */
-  static_install_ipv6 (p, si);
-
-  return 1;
-}
-
-/* Delete static route from static route configuration. */
-int
-static_delete_ipv6 (struct prefix *p, u_char type, struct in6_addr *gate,
-		    const char *ifname, u_char distance, u_int32_t vrf_id)
-{
-  struct route_node *rn;
-  struct static_ipv6 *si;
-  struct route_table *stable;
-
-  /* Lookup table.  */
-  stable = vrf_static_table (AFI_IP6, SAFI_UNICAST, vrf_id);
-  if (! stable)
-    return -1;
-
-  /* Lookup static route prefix. */
-  rn = route_node_lookup (stable, p);
-  if (! rn)
-    return 0;
-
-  /* Find same static route is the tree */
-  for (si = rn->info; si; si = si->next)
-    if (distance == si->distance 
-	&& type == si->type
-	&& (! gate || IPV6_ADDR_SAME (gate, &si->ipv6))
-	&& (! ifname || strcmp (ifname, si->ifname) == 0))
-      break;
-
-  /* Can't find static route. */
-  if (! si)
-    {
-      route_unlock_node (rn);
-      return 0;
-    }
-
-  /* Install into rib. */
-  static_uninstall_ipv6 (p, si);
-
-  /* Unlink static route from linked list. */
-  if (si->prev)
-    si->prev->next = si->next;
-  else
-    rn->info = si->next;
-  if (si->next)
-    si->next->prev = si->prev;
-  
-  /* Free static route configuration. */
-  if (ifname)
-    XFREE (0, si->ifname);
-  XFREE (MTYPE_STATIC_IPV6, si);
-
-  return 1;
-}
 #endif /* HAVE_IPV6 */
 
 /* RIB update function. */
diff -Naur quagga-0.99.10/zebra/zebra_routemap.c quagga-mpls/zebra/zebra_routemap.c
--- quagga-0.99.10/zebra/zebra_routemap.c	2007-05-30 22:10:34.000000000 +0200
+++ quagga-mpls/zebra/zebra_routemap.c	2008-11-25 12:30:18.000000000 +0100
@@ -419,25 +419,24 @@
   if (type == RMAP_ZEBRA)
     {
       nexthop = object;
-      switch (nexthop->type) {
-      case NEXTHOP_TYPE_IFINDEX:
-      case NEXTHOP_TYPE_IFNAME:
-      case NEXTHOP_TYPE_IPV4_IFINDEX:
-      case NEXTHOP_TYPE_IPV4_IFNAME:
-        if (nexthop->rtype != NEXTHOP_TYPE_IPV4)
-		return RMAP_NOMATCH;
-        p.family = AF_INET;
-        p.prefix = nexthop->rgate.ipv4;
-        p.prefixlen = IPV4_MAX_BITLEN;
-        break;
-      case NEXTHOP_TYPE_IPV4:
-        p.family = AF_INET;
-        p.prefix = nexthop->gate.ipv4;
-        p.prefixlen = IPV4_MAX_BITLEN;
-        break;
-      default:
+      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
+	{
+	  p.family = AF_INET;
+	  p.prefix = nexthop->gate.ipv4;
+	  p.prefixlen = IPV4_MAX_BITLEN;
+	}
+      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX) ||
+	       CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+	{
+	  if (!CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
+	    return RMAP_NOMATCH;
+	  p.family = AF_INET;
+	  p.prefix = nexthop->rgate.ipv4;
+	  p.prefixlen = IPV4_MAX_BITLEN;
+	}
+      else
         return RMAP_NOMATCH;
-      }
+
       alist = access_list_lookup (AFI_IP, (char *) rule);
       if (alist == NULL)
 	return RMAP_NOMATCH;
@@ -485,25 +484,24 @@
   if (type == RMAP_ZEBRA)
     {
       nexthop = object;
-      switch (nexthop->type) {
-      case NEXTHOP_TYPE_IFINDEX:
-      case NEXTHOP_TYPE_IFNAME:
-      case NEXTHOP_TYPE_IPV4_IFINDEX:
-      case NEXTHOP_TYPE_IPV4_IFNAME:
-        if (nexthop->rtype != NEXTHOP_TYPE_IPV4)
-		return RMAP_NOMATCH;
-        p.family = AF_INET;
-        p.prefix = nexthop->rgate.ipv4;
-        p.prefixlen = IPV4_MAX_BITLEN;
-        break;
-      case NEXTHOP_TYPE_IPV4:
-        p.family = AF_INET;
-        p.prefix = nexthop->gate.ipv4;
-        p.prefixlen = IPV4_MAX_BITLEN;
-        break;
-      default:
+      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
+	{
+	  p.family = AF_INET;
+	  p.prefix = nexthop->gate.ipv4;
+	  p.prefixlen = IPV4_MAX_BITLEN;
+	}
+      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX) ||
+	       CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+	{
+	  if (!CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
+	    return RMAP_NOMATCH;
+	  p.family = AF_INET;
+	  p.prefix = nexthop->rgate.ipv4;
+	  p.prefixlen = IPV4_MAX_BITLEN;
+	}
+      else
         return RMAP_NOMATCH;
-      }
+
       plist = prefix_list_lookup (AFI_IP, (char *) rule);
       if (plist == NULL)
         return RMAP_NOMATCH;
diff -Naur quagga-0.99.10/zebra/zebra_snmp.c quagga-mpls/zebra/zebra_snmp.c
--- quagga-0.99.10/zebra/zebra_snmp.c	2004-10-13 12:33:27.000000000 +0200
+++ quagga-mpls/zebra/zebra_snmp.c	2008-11-25 12:30:18.000000000 +0100
@@ -483,8 +483,7 @@
       return (u_char *)&nexthop->ifindex;
       break;
     case IPFORWARDTYPE:
-      if (nexthop->type == NEXTHOP_TYPE_IFINDEX
-	  || nexthop->type == NEXTHOP_TYPE_IFNAME)
+      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
         result = 3;
       else
         result = 4;
diff -Naur quagga-0.99.10/zebra/zebra_vty.c quagga-mpls/zebra/zebra_vty.c
--- quagga-0.99.10/zebra/zebra_vty.c	2007-05-30 22:10:34.000000000 +0200
+++ quagga-mpls/zebra/zebra_vty.c	2008-11-25 12:30:18.000000000 +0100
@@ -29,20 +29,25 @@
 #include "rib.h"
 
 #include "zebra/zserv.h"
+#ifdef HAVE_MPLS
+#include "mpls_vty.h"
+#endif
 
 /* General fucntion for static route. */
 static int
-zebra_static_ipv4 (struct vty *vty, int add_cmd, const char *dest_str,
-		   const char *mask_str, const char *gate_str,
-		   const char *flag_str, const char *distance_str)
+do_zebra_static_ipv4 (struct vty *vty, int add_cmd, const char *dest_str,
+		     const char *mask_str, const char *gate_str,
+		     const char *flag_str, const char *distance_str,
+		     const char *advmss_str, u_int mpls)
 {
   int ret;
   u_char distance;
   struct prefix p;
+  struct zapi_nexthop nexthop;
   struct in_addr gate;
   struct in_addr mask;
-  const char *ifname;
-  u_char flag = 0;
+
+  memset(&nexthop, 0, sizeof (struct zapi_nexthop));
   
   ret = str2prefix (dest_str, &p);
   if (ret <= 0)
@@ -72,6 +77,33 @@
   else
     distance = ZEBRA_STATIC_DISTANCE_DEFAULT;
 
+  if (advmss_str)
+    nexthop.advmss = atoi (advmss_str);
+
+#ifdef HAVE_MPLS
+  if (mpls)
+  {
+    struct zmpls_out_segment* out = mpls_out_segment_find(mpls);
+    if (out)
+    {
+      /* there needs to be a better way to do this, this is frought with
+       * possible inconsistency issues.  By the time we get here we've
+       * created a out segment which has a full next hop specification,
+       * and we've started to build a whole new next hop in this
+       * function, are we sure they even match?  Maybe static needs to
+       * creating the out segment and pass around a label struct
+       * and then we build a single nexthop which can be used to
+       * build the out segment and the static route entry.
+       *
+       * for now I punt, just copy the label from the out segment, we'll
+       * magically hook this back together someplace down the line ...
+       */
+      SET_FLAG (nexthop.type, ZEBRA_NEXTHOP_MPLS);
+      nexthop.mpls = out->nh.mpls;
+    }
+  }
+#endif
+
   /* Null0 static route.  */
   if ((gate_str != NULL) && (strncasecmp (gate_str, "Null0", strlen (gate_str)) == 0))
     {
@@ -80,10 +112,13 @@
           vty_out (vty, "%% can not have flag %s with Null0%s", flag_str, VTY_NEWLINE);
           return CMD_WARNING;
         }
+      SET_FLAG (nexthop.type, ZEBRA_NEXTHOP_DROP);
+      nexthop.gw.drop = ZEBRA_DROP_NULL;
+
       if (add_cmd)
-        static_add_ipv4 (&p, NULL, NULL, ZEBRA_FLAG_BLACKHOLE, distance, 0);
+        static_add_route (&p, &nexthop, distance, 0);
       else
-        static_delete_ipv4 (&p, NULL, NULL, distance, 0);
+        static_delete_route (&p, &nexthop, distance, 0);
       return CMD_SUCCESS;
     }
 
@@ -92,11 +127,13 @@
     switch(flag_str[0]) {
       case 'r':
       case 'R': /* XXX */
-        SET_FLAG (flag, ZEBRA_FLAG_REJECT);
+        SET_FLAG (nexthop.type, ZEBRA_NEXTHOP_DROP);
+	nexthop.gw.drop = ZEBRA_DROP_REJECT;
         break;
       case 'b':
       case 'B': /* XXX */
-        SET_FLAG (flag, ZEBRA_FLAG_BLACKHOLE);
+        SET_FLAG (nexthop.type, ZEBRA_NEXTHOP_DROP);
+	nexthop.gw.drop = ZEBRA_DROP_BLACKHOLE;
         break;
       default:
         vty_out (vty, "%% Malformed flag %s %s", flag_str, VTY_NEWLINE);
@@ -107,9 +144,9 @@
   if (gate_str == NULL)
   {
     if (add_cmd)
-      static_add_ipv4 (&p, NULL, NULL, flag, distance, 0);
+      static_add_route (&p, &nexthop, distance, 0);
     else
-      static_delete_ipv4 (&p, NULL, NULL, distance, 0);
+      static_delete_route (&p, &nexthop, distance, 0);
 
     return CMD_SUCCESS;
   }
@@ -118,18 +155,34 @@
      address other case gate is treated as interface name. */
   ret = inet_aton (gate_str, &gate);
   if (ret)
-    ifname = NULL;
+    {
+      nexthop.gw.ipv4 = gate;
+      SET_FLAG (nexthop.type, ZEBRA_NEXTHOP_IPV4);
+    }
   else
-    ifname = gate_str;
+    {
+      strncpy(nexthop.intf.name, gate_str, IFNAMSIZ);
+      SET_FLAG (nexthop.type, ZEBRA_NEXTHOP_IFNAME);
+    }
 
   if (add_cmd)
-    static_add_ipv4 (&p, ifname ? NULL : &gate, ifname, flag, distance, 0);
+    static_add_route (&p, &nexthop, distance, 0);
   else
-    static_delete_ipv4 (&p, ifname ? NULL : &gate, ifname, distance, 0);
+    static_delete_route (&p, &nexthop, distance, 0);
 
   return CMD_SUCCESS;
 }
 
+int
+zebra_static_ipv4 (struct vty *vty, int add_cmd, const char *dest_str,
+                  const char *mask_str, const char *gate_str,
+                  const char *flag_str, const char *distance_str,
+                  const char *advmss_str)
+{
+  return do_zebra_static_ipv4(vty, add_cmd, dest_str, mask_str, gate_str,
+    flag_str, distance_str, advmss_str, 0);
+}
+
 /* Static route configuration.  */
 DEFUN (ip_route, 
        ip_route_cmd,
@@ -141,7 +194,22 @@
        "IP gateway interface name\n"
        "Null interface\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], NULL, NULL);
+  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], NULL, NULL, NULL);
+}
+
+DEFUN (ip_route_advmss, 
+       ip_route_advmss_cmd,
+       "ip route A.B.C.D/M (A.B.C.D|INTERFACE|null0) advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "IP gateway address\n"
+       "IP gateway interface name\n"
+       "Null interface\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], NULL, NULL, argv[2]);
 }
 
 DEFUN (ip_route_flags,
@@ -155,7 +223,7 @@
        "Emit an ICMP unreachable when matched\n"
        "Silently discard pkts when matched\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], argv[2], NULL);
+  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], argv[2], NULL, NULL);
 }
 
 DEFUN (ip_route_flags2,
@@ -167,7 +235,7 @@
        "Emit an ICMP unreachable when matched\n"
        "Silently discard pkts when matched\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], NULL, NULL, argv[1], NULL);
+  return zebra_static_ipv4 (vty, 1, argv[0], NULL, NULL, argv[1], NULL, NULL);
 }
 
 /* Mask as A.B.C.D format.  */
@@ -182,7 +250,23 @@
        "IP gateway interface name\n"
        "Null interface\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], NULL, NULL);
+  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], NULL, NULL, NULL);
+}
+
+DEFUN (ip_route_mask_advmss,
+       ip_route_mask_advmss_cmd,
+       "ip route A.B.C.D A.B.C.D (A.B.C.D|INTERFACE|null0) advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "IP gateway address\n"
+       "IP gateway interface name\n"
+       "Null interface\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], NULL, NULL, argv[3]);
 }
 
 DEFUN (ip_route_mask_flags,
@@ -197,7 +281,7 @@
        "Emit an ICMP unreachable when matched\n"
        "Silently discard pkts when matched\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], argv[3], NULL);
+  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], argv[3], NULL, NULL);
 }
 
 DEFUN (ip_route_mask_flags2,
@@ -210,7 +294,7 @@
        "Emit an ICMP unreachable when matched\n"
        "Silently discard pkts when matched\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], NULL, argv[2], NULL);
+  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], NULL, argv[2], NULL, NULL);
 }
 
 /* Distance option value.  */
@@ -225,7 +309,23 @@
        "Null interface\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], NULL, argv[2]);
+  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], NULL, argv[2], NULL);
+}
+
+DEFUN (ip_route_distance_advmss,
+       ip_route_distance_advmss_cmd,
+       "ip route A.B.C.D/M (A.B.C.D|INTERFACE|null0) <1-255> advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "IP gateway address\n"
+       "IP gateway interface name\n"
+       "Null interface\n"
+       "Distance value for this route\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], NULL, argv[2], argv[3]);
 }
 
 DEFUN (ip_route_flags_distance,
@@ -240,7 +340,7 @@
        "Silently discard pkts when matched\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], argv[2], argv[3]);
+  return zebra_static_ipv4 (vty, 1, argv[0], NULL, argv[1], argv[2], argv[3], NULL);
 }
 
 DEFUN (ip_route_flags_distance2,
@@ -253,7 +353,7 @@
        "Silently discard pkts when matched\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], NULL, NULL, argv[1], argv[2]);
+  return zebra_static_ipv4 (vty, 1, argv[0], NULL, NULL, argv[1], argv[2], NULL);
 }
 
 DEFUN (ip_route_mask_distance,
@@ -268,7 +368,24 @@
        "Null interface\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], NULL, argv[3]);
+  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], NULL, argv[3], NULL);
+}
+
+DEFUN (ip_route_mask_distance_advmss,
+       ip_route_mask_distance_advmss_cmd,
+       "ip route A.B.C.D A.B.C.D (A.B.C.D|INTERFACE|null0) <1-255> advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "IP gateway address\n"
+       "IP gateway interface name\n"
+       "Null interface\n"
+       "Distance value for this route\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], NULL, argv[3], argv[4]);
 }
 
 DEFUN (ip_route_mask_flags_distance,
@@ -284,7 +401,7 @@
        "Emit an ICMP unreachable when matched\n"
        "Silently discard pkts when matched\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], argv[3], argv[4]);
+  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], argv[2], argv[3], argv[4], NULL);
 }
 
 DEFUN (ip_route_mask_flags_distance2,
@@ -298,7 +415,7 @@
        "Emit an ICMP unreachable when matched\n"
        "Silently discard pkts when matched\n")
 {
-  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], NULL, argv[2], argv[3]);
+  return zebra_static_ipv4 (vty, 1, argv[0], argv[1], NULL, argv[2], argv[3], NULL);
 }
 
 DEFUN (no_ip_route, 
@@ -312,7 +429,23 @@
        "IP gateway interface name\n"
        "Null interface\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], NULL, argv[1], NULL, NULL);
+  return zebra_static_ipv4 (vty, 0, argv[0], NULL, argv[1], NULL, NULL, NULL);
+}
+
+DEFUN (no_ip_route_advmss, 
+       no_ip_route_advmss_cmd,
+       "no ip route A.B.C.D/M (A.B.C.D|INTERFACE|null0) advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "IP gateway address\n"
+       "IP gateway interface name\n"
+       "Null interface\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4 (vty, 0, argv[0], NULL, argv[1], NULL, NULL, argv[2]);
 }
 
 ALIAS (no_ip_route,
@@ -337,7 +470,7 @@
        "Emit an ICMP unreachable when matched\n"
        "Silently discard pkts when matched\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], NULL, NULL, NULL, NULL);
+  return zebra_static_ipv4 (vty, 0, argv[0], NULL, NULL, NULL, NULL, NULL);
 }
 
 DEFUN (no_ip_route_mask,
@@ -352,7 +485,24 @@
        "IP gateway interface name\n"
        "Null interface\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], argv[2], NULL, NULL);
+  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], argv[2], NULL, NULL, NULL);
+}
+
+DEFUN (no_ip_route_mask_advmss,
+       no_ip_route_mask_advmss_cmd,
+       "no ip route A.B.C.D A.B.C.D (A.B.C.D|INTERFACE|null0) advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "IP gateway address\n"
+       "IP gateway interface name\n"
+       "Null interface\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], argv[2], NULL, NULL, argv[3]);
 }
 
 ALIAS (no_ip_route_mask,
@@ -379,7 +529,7 @@
        "Emit an ICMP unreachable when matched\n"
        "Silently discard pkts when matched\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], NULL, NULL, NULL);
+  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], NULL, NULL, NULL, NULL);
 }
 
 DEFUN (no_ip_route_distance,
@@ -394,7 +544,24 @@
        "Null interface\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], NULL, argv[1], NULL, argv[2]);
+  return zebra_static_ipv4 (vty, 0, argv[0], NULL, argv[1], NULL, argv[2], NULL);
+}
+
+DEFUN (no_ip_route_distance_advmss,
+       no_ip_route_distance_advmss_cmd,
+       "no ip route A.B.C.D/M (A.B.C.D|INTERFACE|null0) <1-255> advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "IP gateway address\n"
+       "IP gateway interface name\n"
+       "Null interface\n"
+       "Distance value for this route\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4 (vty, 0, argv[0], NULL, argv[1], NULL, argv[2], argv[3]);
 }
 
 DEFUN (no_ip_route_flags_distance,
@@ -410,7 +577,7 @@
        "Silently discard pkts when matched\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], NULL, argv[1], argv[2], argv[3]);
+  return zebra_static_ipv4 (vty, 0, argv[0], NULL, argv[1], argv[2], argv[3], NULL);
 }
 
 DEFUN (no_ip_route_flags_distance2,
@@ -424,7 +591,7 @@
        "Silently discard pkts when matched\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], NULL, NULL, argv[1], argv[2]);
+  return zebra_static_ipv4 (vty, 0, argv[0], NULL, NULL, argv[1], argv[2], NULL);
 }
 
 DEFUN (no_ip_route_mask_distance,
@@ -440,7 +607,25 @@
        "Null interface\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], argv[2], NULL, argv[3]);
+  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], argv[2], NULL, argv[3], NULL);
+}
+
+DEFUN (no_ip_route_mask_distance_advmss,
+       no_ip_route_mask_distance_advmss_cmd,
+       "no ip route A.B.C.D A.B.C.D (A.B.C.D|INTERFACE|null0) <1-255> advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "IP gateway address\n"
+       "IP gateway interface name\n"
+       "Null interface\n"
+       "Distance value for this route\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], argv[2], NULL, argv[3], argv[4]);
 }
 
 DEFUN (no_ip_route_mask_flags_distance,
@@ -457,7 +642,7 @@
        "Silently discard pkts when matched\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], argv[2], argv[3], argv[4]);
+  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], argv[2], argv[3], argv[4], NULL);
 }
 
 DEFUN (no_ip_route_mask_flags_distance2,
@@ -472,7 +657,7 @@
        "Silently discard pkts when matched\n"
        "Distance value for this route\n")
 {
-  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], NULL, argv[2], argv[3]);
+  return zebra_static_ipv4 (vty, 0, argv[0], argv[1], NULL, argv[2], argv[3], NULL);
 }
 
 char *proto_rm[AFI_MAX][ZEBRA_ROUTE_MAX+1];	/* "any" == ZEBRA_ROUTE_MAX */
@@ -527,6 +712,474 @@
   proto_rm[AFI_IP][i] = NULL;
   return CMD_SUCCESS;
 }
+#ifdef HAVE_MPLS
+/* Static route + MPLS configuration.  */
+static int
+zebra_static_ipv4_mpls (struct vty *vty, int add_cmd, const char *dest_str,
+  const char *addr, const char *mask_str, const char *distance,
+  const char *advmss, const char **argv)
+{
+  struct zmpls_out_segment out;
+  struct zmpls_ftn *old;
+  struct zmpls_ftn ftn;
+  struct prefix p;
+  int result;
+
+  if (str2prefix (dest_str, &p) <= 0)
+    {
+      vty_out (vty, "%% Malformed address%s", VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+  /* Cisco like mask notation. */
+  if (mask_str)
+    {
+      struct in_addr mask;
+      if (inet_aton (mask_str, &mask) == 0)
+        {
+          vty_out (vty, "%% Malformed address%s", VTY_NEWLINE);
+          return CMD_WARNING;
+        }
+      p.prefixlen = ip_masklen (mask);
+    }
+
+  /* Apply mask for given prefix. */
+  apply_mask (&p);
+
+  memcpy(&ftn.fec.u.p, &p, sizeof(p));
+  ftn.fec.type = ZEBRA_MPLS_FEC_IPV4;
+  ftn.fec.owner = ZEBRA_ROUTE_STATIC;
+  old = mpls_ftn_find_by_fec(&ftn.fec);
+
+  memset (&out, 0, sizeof (out));
+  out.owner = ZEBRA_ROUTE_STATIC;
+  result = nhlfe_parse (vty, argv, &out, addr);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  out.index = mpls_out_segment_find_index_by_nhlfe(&out);
+
+  if (add_cmd)
+  {
+    if (old)
+    {
+      vty_out(vty, "FTN already exists%s",VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+    if (out.index)
+    {
+      vty_out(vty, "NHLFE already exists%s",VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+    if ((result = mpls_out_segment_register (&out)))
+    {
+      vty_out(vty, "Unable to register NHLFE(%d)%s", result, VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+    ftn.out_index = out.index;
+
+  } else {
+    if (!out.index)
+    {
+      vty_out(vty, "No such NHLFE%s",VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+    if (!old)
+    {
+      vty_out(vty, "No such FEC%s",VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+    mpls_ftn_unregister(old, 0);
+  }
+
+  result = do_zebra_static_ipv4 (vty, add_cmd, dest_str, mask_str, addr, NULL,
+    distance, advmss, out.index);
+
+  if (add_cmd)
+  {
+    if (result != CMD_SUCCESS)
+    {
+      mpls_out_segment_unregister_by_index (out.index);
+      return CMD_WARNING;
+    }
+    mpls_ftn_register(&ftn, 0);
+  }
+  else
+  {
+    mpls_out_segment_unregister_by_index (out.index);
+  }
+  return CMD_SUCCESS;
+}
+
+DEFUN (ip_route_mpls, 
+       ip_route_mpls_cmd,
+       "ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], NULL, NULL, NULL, NULL, &argv[1]);
+}
+
+DEFUN (ip_route_mpls_advmss, 
+       ip_route_mpls_advmss_cmd,
+       "ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], NULL, NULL, NULL, argv[4], &argv[1]);
+}
+
+DEFUN (ip_route_mpls_addr,
+       ip_route_mpls_addr_cmd,
+       "ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], argv[4], NULL, NULL, NULL, &argv[1]);
+}
+
+DEFUN (ip_route_mpls_addr_advmss,
+       ip_route_mpls_addr_advmss_cmd,
+       "ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], argv[4], NULL, NULL, argv[5], &argv[1]);
+}
+
+/* Mask as A.B.C.D format.  */
+DEFUN (ip_route_mpls_mask,
+       ip_route_mpls_mask_cmd,
+       "ip route A.B.C.D A.B.C.D (gen|atm|fr) VALUE nexthop INTERFACE",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], argv[1], NULL, NULL, NULL, &argv[2]);
+}
+
+DEFUN (ip_route_mpls_mask_addr,
+       ip_route_mpls_mask_addr_cmd,
+       "ip route A.B.C.D A.B.C.D (gen|atm|fr) VALUE nexthop INTERFACE ADDR",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], argv[1], argv[5], NULL, NULL, &argv[2]);
+}
+
+/* Distance option value.  */
+DEFUN (ip_route_mpls_distance,
+       ip_route_mpls_distance_cmd,
+       "ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE <1-255>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "Distance value for this route\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], NULL, NULL, argv[4], NULL, &argv[1]);
+}
+
+DEFUN (ip_route_mpls_distance_addr,
+       ip_route_mpls_distance_addr_cmd,
+       "ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR <1-255>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n"
+       "Distance value for this route\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], NULL, argv[4], argv[5], NULL, &argv[1]);
+}
+
+DEFUN (ip_route_mpls_mask_distance,
+       ip_route_mpls_mask_distance_cmd,
+       "ip route A.B.C.D A.B.C.D (gen|atm|fr) VALUE nexthop INTERFACE <1-255>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "Distance value for this route\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], argv[1], NULL, argv[5], NULL, &argv[2]);
+}
+
+DEFUN (ip_route_mpls_mask_distance_addr,
+       ip_route_mpls_mask_distance_addr_cmd,
+       "ip route A.B.C.D A.B.C.D (gen|atm|fr) VALUE nexthop INTERFACE ADDR <1-255>",
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n"
+       "Distance value for this route\n")
+{
+  return zebra_static_ipv4_mpls (vty, 1, argv[0], argv[1], argv[5], argv[6], NULL, &argv[2]);
+}
+
+DEFUN (no_ip_route_mpls,
+       no_ip_route_mpls_cmd,
+       "no ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], NULL, NULL, NULL, NULL, &argv[1]);
+}
+
+DEFUN (no_ip_route_mpls_advmss,
+       no_ip_route_mpls_advmss_cmd,
+       "no ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], NULL, NULL, NULL, argv[4], &argv[1]);
+}
+DEFUN (no_ip_route_mpls_addr,
+       no_ip_route_mpls_addr_cmd,
+       "no ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], argv[4], NULL, NULL, NULL, &argv[1]);
+}
+
+DEFUN (no_ip_route_mpls_addr_advmss,
+       no_ip_route_mpls_addr_advmss_cmd,
+       "no ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], argv[4], NULL, NULL, argv[5], &argv[1]);
+}
+
+DEFUN (no_ip_route_mpls_mask,
+       no_ip_route_mpls_mask_cmd,
+       "no ip route A.B.C.D A.B.C.D (gen|atm|fr) VALUE nexthop INTERFACE",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], argv[1], NULL, NULL, NULL, &argv[2]);
+}
+
+DEFUN (no_ip_route_mpls_mask_addr,
+       no_ip_route_mpls_mask_addr_cmd,
+       "no ip route A.B.C.D A.B.C.D (gen|atm|fr) VALUE nexthop INTERFACE ADDR",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], argv[1], argv[5], NULL, NULL, &argv[2]);
+}
+
+DEFUN (no_ip_route_mpls_distance,
+       no_ip_route_mpls_distance_cmd,
+       "no ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE <1-255>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "Distance value for this route\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], NULL, NULL, argv[4], NULL, &argv[1]);
+}
+
+DEFUN (no_ip_route_mpls_distance_addr,
+       no_ip_route_mpls_distance_addr_cmd,
+       "no ip route A.B.C.D/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR <1-255>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix (e.g. 10.0.0.0/8)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n"
+       "Distance value for this route\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], NULL, argv[4], argv[5], NULL, &argv[1]);
+}
+
+DEFUN (no_ip_route_mpls_mask_distance,
+       no_ip_route_mpls_mask_distance_cmd,
+       "no ip route A.B.C.D A.B.C.D (gen|atm|fr) VALUE nexthop INTERFACE <1-255>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "Distance value for this route\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], argv[1], NULL, argv[5], NULL, &argv[2]);
+}
+
+DEFUN (no_ip_route_mpls_mask_distance_addr,
+       no_ip_route_mpls_mask_distance_addr_cmd,
+       "no ip route A.B.C.D A.B.C.D (gen|atm|fr) VALUE nexthop INTERFACE ADDR <1-255>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IP destination prefix\n"
+       "IP destination prefix mask\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IP gateway interface name\n"
+       "IP gateway address\n"
+       "Distance value for this route\n")
+{
+  return zebra_static_ipv4_mpls (vty, 0, argv[0], argv[1], argv[5], argv[6], NULL, &argv[2]);
+}
+#endif /* HAVE_MPLS */
 
 /* New RIB.  Detailed information for IPv4 route. */
 static void
@@ -584,31 +1237,83 @@
       for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
 	{
           char addrstr[32];
+	  if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
+	    continue;
+
+          if (nexthop->advmss)
+            vty_out (vty, " advmss %d", nexthop->advmss);
 
 	  vty_out (vty, "  %c",
 		   CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB) ? '*' : ' ');
 
-	  switch (nexthop->type)
+#ifdef HAVE_IPV6
+	  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
+            {
+              if (!IPV6_ADDR_SAME(&nexthop->src.ipv6, &in6addr_any))
+                {
+		  if (inet_ntop(AF_INET6, &nexthop->src.ipv6, addrstr,
+		      sizeof addrstr))
+                    vty_out (vty, ", src %s", addrstr);
+                }
+            }
+	  else
+#endif /* HAVE_IPV6 */
+          if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
 	    {
-	    case NEXTHOP_TYPE_IPV4:
-	    case NEXTHOP_TYPE_IPV4_IFINDEX:
 	      vty_out (vty, " %s", inet_ntoa (nexthop->gate.ipv4));
-	      if (nexthop->ifindex)
-		vty_out (vty, ", via %s", ifindex2ifname (nexthop->ifindex));
-	      break;
-	    case NEXTHOP_TYPE_IFINDEX:
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+		vty_out (vty, ", via %s", nexthop->ifname);
+	      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+	        if (if_lookup_by_index(nexthop->ifindex))
+		  vty_out (vty, ", via %s", ifindex2ifname(nexthop->ifindex));
+
+              if (nexthop->src.ipv4.s_addr)
+                {
+		  if (inet_ntop(AF_INET, &nexthop->src.ipv4, addrstr,
+		      sizeof addrstr))
+                    vty_out (vty, ", src %s", addrstr);
+                }
+	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+	    {
+	      vty_out (vty, " directly connected, %s", nexthop->ifname);
+	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+	    {
 	      vty_out (vty, " directly connected, %s",
 		       ifindex2ifname (nexthop->ifindex));
-	      break;
-	    case NEXTHOP_TYPE_IFNAME:
-	      vty_out (vty, " directly connected, %s", nexthop->ifname);
-	      break;
-      case NEXTHOP_TYPE_BLACKHOLE:
-        vty_out (vty, " directly connected, Null0");
-        break;
-      default:
-	      break;
 	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
+	    {
+	      switch (nexthop->drop)
+		{
+		  case ZEBRA_DROP_NULL:
+		    vty_out (vty, " directly connected, Null0");
+		    break;
+		  case ZEBRA_DROP_REJECT:
+		    vty_out (vty, ", reject");
+		    break;
+		  case ZEBRA_DROP_BLACKHOLE:
+		    vty_out (vty, ", blackhole");
+		    break;
+		  default:
+		    assert(0);
+		}
+	    }
+#ifdef HAVE_MPLS
+	  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_MPLS))
+	    {
+	      struct zmpls_out_segment *out;
+	      char buf[16];
+
+	      out = mpls_out_segment_find(nexthop->mpls);
+	      if (out)
+		mpls_print_label(&out->nh.mpls, buf);
+	      else
+		strcpy(buf, "not found");
+	      vty_out (vty, " (label %s)", buf);
+	    }
+#endif
 	  if (! CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE))
 	    vty_out (vty, " inactive");
 
@@ -616,48 +1321,48 @@
 	    {
 	      vty_out (vty, " (recursive");
 		
-	      switch (nexthop->rtype)
+#ifdef HAVE_IPV6
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
+                {
+                  if (!IPV6_ADDR_SAME(&nexthop->src.ipv6, &in6addr_any))
+                    {
+		      if (inet_ntop(AF_INET6, &nexthop->src.ipv6, addrstr,
+		          sizeof addrstr))
+                        vty_out (vty, ", src %s", addrstr);
+                    }
+                }
+	      else
+#endif /* HAVE_IPV6 */
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
 		{
-		case NEXTHOP_TYPE_IPV4:
-		case NEXTHOP_TYPE_IPV4_IFINDEX:
 		  vty_out (vty, " via %s)", inet_ntoa (nexthop->rgate.ipv4));
-		  break;
-		case NEXTHOP_TYPE_IFINDEX:
-		case NEXTHOP_TYPE_IFNAME:
+                  if (nexthop->src.ipv4.s_addr)
+                    {
+		      if (inet_ntop(AF_INET, &nexthop->src.ipv4, addrstr,
+		          sizeof addrstr))
+                        vty_out (vty, ", src %s", addrstr);
+                    }
+		}
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFINDEX))
+		{
 		  vty_out (vty, " is directly connected, %s)",
 			   ifindex2ifname (nexthop->rifindex));
-		  break;
-		default:
-		  break;
 		}
+#ifdef HAVE_MPLS
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_MPLS))
+		{
+		  struct zmpls_out_segment *out;
+		  char buf[16];
+
+		  out = mpls_out_segment_find(nexthop->rmpls);
+		  if (out)
+		    mpls_print_label(&out->nh.mpls, buf);
+		  else
+		    strcpy(buf, "not found");
+		  vty_out (vty, " (label %s)", buf);
+		}
+#endif
 	    }
-	  switch (nexthop->type)
-            {
-            case NEXTHOP_TYPE_IPV4:
-            case NEXTHOP_TYPE_IPV4_IFINDEX:
-            case NEXTHOP_TYPE_IPV4_IFNAME:
-              if (nexthop->src.ipv4.s_addr)
-                {
-		  if (inet_ntop(AF_INET, &nexthop->src.ipv4, addrstr,
-		      sizeof addrstr))
-                    vty_out (vty, ", src %s", addrstr);
-                }
-              break;
-#ifdef HAVE_IPV6
-            case NEXTHOP_TYPE_IPV6:
-            case NEXTHOP_TYPE_IPV6_IFINDEX:
-            case NEXTHOP_TYPE_IPV6_IFNAME:
-              if (!IPV6_ADDR_SAME(&nexthop->src.ipv6, &in6addr_any))
-                {
-		  if (inet_ntop(AF_INET6, &nexthop->src.ipv6, addrstr,
-		      sizeof addrstr))
-                    vty_out (vty, ", src %s", addrstr);
-                }
-              break;
-#endif /* HAVE_IPV6 */
-            default:
-	       break;
-            }
 	  vty_out (vty, "%s", VTY_NEWLINE);
 	}
       vty_out (vty, "%s", VTY_NEWLINE);
@@ -674,6 +1379,9 @@
   /* Nexthop information. */
   for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
     {
+      if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
+         continue;
+
       if (nexthop == rib->nexthop)
 	{
 	  /* Prefix information. */
@@ -698,27 +1406,72 @@
 		 ? '*' : ' ',
 		 len - 3, ' ');
 
-      switch (nexthop->type)
+#ifdef HAVE_IPV6
+      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
+        {
+          if (!IPV6_ADDR_SAME(&nexthop->src.ipv6, &in6addr_any))
+            {
+	      if (inet_ntop(AF_INET6, &nexthop->src.ipv6, buf, sizeof buf))
+                vty_out (vty, ", src %s", buf);
+            }
+        }
+      else
+#endif /* HAVE_IPV6 */
+      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
 	{
-	case NEXTHOP_TYPE_IPV4:
-	case NEXTHOP_TYPE_IPV4_IFINDEX:
 	  vty_out (vty, " via %s", inet_ntoa (nexthop->gate.ipv4));
-	  if (nexthop->ifindex)
-	    vty_out (vty, ", %s", ifindex2ifname (nexthop->ifindex));
-	  break;
-	case NEXTHOP_TYPE_IFINDEX:
+          if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+	    vty_out (vty, ", %s", nexthop->ifname);
+          else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+	    if (if_lookup_by_index(nexthop->ifindex))
+	      vty_out (vty, ", %s", ifindex2ifname (nexthop->ifindex));
+
+          if (nexthop->src.ipv4.s_addr)
+            {
+	      if (inet_ntop(AF_INET, &nexthop->src.ipv4, buf, sizeof buf))
+                vty_out (vty, ", src %s", buf);
+            }
+	}
+      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+	{
+	  vty_out (vty, " is directly connected, %s", nexthop->ifname);
+	}
+      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+	{
 	  vty_out (vty, " is directly connected, %s",
 		   ifindex2ifname (nexthop->ifindex));
-	  break;
-	case NEXTHOP_TYPE_IFNAME:
-	  vty_out (vty, " is directly connected, %s", nexthop->ifname);
-	  break;
-  case NEXTHOP_TYPE_BLACKHOLE:
-    vty_out (vty, " is directly connected, Null0");
-    break;
-  default:
-	  break;
 	}
+      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
+	{
+	  switch (nexthop->drop)
+	    {
+	      case ZEBRA_DROP_NULL:
+		vty_out (vty, " directly connected, Null0");
+		break;
+	      case ZEBRA_DROP_REJECT:
+		vty_out (vty, ", reject");
+		break;
+	      case ZEBRA_DROP_BLACKHOLE:
+		vty_out (vty, ", blackhole");
+		break;
+	      default:
+		assert(0);
+	    }
+	}
+#ifdef HAVE_MPLS
+      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_MPLS))
+	{
+	  struct zmpls_out_segment *out;
+	  char buf[16];
+
+	  out = mpls_out_segment_find(nexthop->mpls);
+	  if (out)
+	    mpls_print_label(&out->nh.mpls, buf);
+	  else
+	    strcpy(buf, "not found");
+	  vty_out (vty, " (label %s)", buf);
+	}
+#endif
       if (! CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE))
 	vty_out (vty, " inactive");
 
@@ -726,46 +1479,53 @@
 	{
 	  vty_out (vty, " (recursive");
 		
-	  switch (nexthop->rtype)
+#ifdef HAVE_IPV6
+	  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
+            {
+              if (!IPV6_ADDR_SAME(&nexthop->src.ipv6, &in6addr_any))
+                {
+		  if (inet_ntop(AF_INET6, &nexthop->src.ipv6, buf, sizeof buf))
+                    vty_out (vty, ", src %s", buf);
+                }
+            }
+          else
+#endif /* HAVE_IPV6 */
+	  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV4))
+	    {
+	      vty_out (vty, " via %s", inet_ntoa (nexthop->rgate.ipv4));
+	      if (nexthop->rifindex)
+		vty_out (vty, ", %s", ifindex2ifname (nexthop->rifindex));
+	      vty_out (vty, ")");
+
+              if (nexthop->src.ipv4.s_addr)
+                {
+	          if (inet_ntop(AF_INET, &nexthop->src.ipv4, buf, sizeof buf))
+                    vty_out (vty, ", src %s", buf);
+                }
+	    }
+	  else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFINDEX))
 	    {
-	    case NEXTHOP_TYPE_IPV4:
-	    case NEXTHOP_TYPE_IPV4_IFINDEX:
-	      vty_out (vty, " via %s)", inet_ntoa (nexthop->rgate.ipv4));
-	      break;
-	    case NEXTHOP_TYPE_IFINDEX:
-	    case NEXTHOP_TYPE_IFNAME:
 	      vty_out (vty, " is directly connected, %s)",
 		       ifindex2ifname (nexthop->rifindex));
-	      break;
-	    default:
-	      break;
 	    }
+#ifdef HAVE_MPLS
+	  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_MPLS))
+	    {
+	      struct zmpls_out_segment *out;
+	      char buf[16];
+
+	      out = mpls_out_segment_find(nexthop->rmpls);
+	      if (out)
+		mpls_print_label(&out->nh.mpls, buf);
+	      else
+		strcpy(buf, "not found");
+	      vty_out (vty, " (label %s)", buf);
+	    }
+#endif
 	}
-      switch (nexthop->type)
-        {
-          case NEXTHOP_TYPE_IPV4:
-          case NEXTHOP_TYPE_IPV4_IFINDEX:
-          case NEXTHOP_TYPE_IPV4_IFNAME:
-            if (nexthop->src.ipv4.s_addr)
-              {
-		if (inet_ntop(AF_INET, &nexthop->src.ipv4, buf, sizeof buf))
-                  vty_out (vty, ", src %s", buf);
-              }
-            break;
-#ifdef HAVE_IPV6
-          case NEXTHOP_TYPE_IPV6:
-          case NEXTHOP_TYPE_IPV6_IFINDEX:
-          case NEXTHOP_TYPE_IPV6_IFNAME:
-            if (!IPV6_ADDR_SAME(&nexthop->src.ipv6, &in6addr_any))
-              {
-		if (inet_ntop(AF_INET6, &nexthop->src.ipv6, buf, sizeof buf))
-                  vty_out (vty, ", src %s", buf);
-              }
-            break;
-#endif /* HAVE_IPV6 */
-          default:
-	    break;
-        }
+
+      if (nexthop->advmss)
+        vty_out (vty, " advmss %d", nexthop->advmss);
 
       if (CHECK_FLAG (rib->flags, ZEBRA_FLAG_BLACKHOLE))
                vty_out (vty, ", bh");
@@ -954,6 +1714,8 @@
     type = ZEBRA_ROUTE_RIP;
   else if (strncmp (argv[0], "s", 1) == 0)
     type = ZEBRA_ROUTE_STATIC;
+  else if (strncmp (argv[0], "l", 1) == 0)
+    type = ZEBRA_ROUTE_LDP;
   else 
     {
       vty_out (vty, "Unknown route type%s", VTY_NEWLINE);
@@ -1111,7 +1873,7 @@
 static_config_ipv4 (struct vty *vty)
 {
   struct route_node *rn;
-  struct static_ipv4 *si;  
+  struct static_route *si;  
   struct route_table *stable;
   int write;
 
@@ -1128,32 +1890,51 @@
         vty_out (vty, "ip route %s/%d", inet_ntoa (rn->p.u.prefix4),
                  rn->p.prefixlen);
 
-        switch (si->type)
-          {
-            case STATIC_IPV4_GATEWAY:
-              vty_out (vty, " %s", inet_ntoa (si->gate.ipv4));
-              break;
-            case STATIC_IPV4_IFNAME:
-              vty_out (vty, " %s", si->gate.ifname);
-              break;
-            case STATIC_IPV4_BLACKHOLE:
-              vty_out (vty, " Null0");
-              break;
-          }
+        if (CHECK_FLAG(si->nh.type, ZEBRA_NEXTHOP_DROP))
+	  switch(si->nh.gw.drop)
+	    {
+	      case ZEBRA_DROP_NULL:
+		vty_out (vty, " Null0");
+		break;
+	      case ZEBRA_DROP_REJECT:
+		vty_out (vty, " %s", "reject");
+		break;
+	      case ZEBRA_DROP_BLACKHOLE:
+		vty_out (vty, " %s", "blackhole");
+		break;
+	      default:
+		assert(0);
+	    }
+	else
+	  {
+	    if (CHECK_FLAG(si->nh.type, ZEBRA_NEXTHOP_IPV4))
+	      vty_out (vty, " %s", inet_ntoa (si->nh.gw.ipv4));
+	    if (CHECK_FLAG(si->nh.type, ZEBRA_NEXTHOP_IFNAME))
+	      vty_out (vty, " %s", si->nh.intf.name);
+#ifdef HAVE_MPLS
+	    if (CHECK_FLAG(si->nh.type, ZEBRA_NEXTHOP_MPLS))
+	      {
+		int index = mpls_out_segment_find_index_by_nexthop(&si->nh);
+		vty_out (vty, " ");
+		if (index)
+		  {
+		    mpls_out_segment_config_write (vty,
+		      mpls_out_segment_find(index));
+		  }
+		else
+		  {
+		    vty_out (vty, "(unknown)");
+		  }
+	      }
+#endif
+	  }
         
-        /* flags are incompatible with STATIC_IPV4_BLACKHOLE */
-        if (si->type != STATIC_IPV4_BLACKHOLE)
-          {
-            if (CHECK_FLAG(si->flags, ZEBRA_FLAG_REJECT))
-              vty_out (vty, " %s", "reject");
-
-            if (CHECK_FLAG(si->flags, ZEBRA_FLAG_BLACKHOLE))
-              vty_out (vty, " %s", "blackhole");
-          }
-
         if (si->distance != ZEBRA_STATIC_DISTANCE_DEFAULT)
           vty_out (vty, " %d", si->distance);
 
+        if (si->nh.advmss)
+	  vty_out (vty, " advmss %d", si->nh.advmss);
+
         vty_out (vty, "%s", VTY_NEWLINE);
 
         write = 1;
@@ -1201,11 +1982,11 @@
   int ret;
   u_char distance;
   struct prefix p;
-  struct in6_addr *gate = NULL;
   struct in6_addr gate_addr;
-  u_char type = 0;
+  struct zapi_nexthop nh;
   int table = 0;
-  u_char flag = 0;
+
+  memset(&nh, 0, sizeof(struct zapi_nexthop));
   
   ret = str2prefix (dest_str, &p);
   if (ret <= 0)
@@ -1222,11 +2003,13 @@
     switch(flag_str[0]) {
       case 'r':
       case 'R': /* XXX */
-        SET_FLAG (flag, ZEBRA_FLAG_REJECT);
+        SET_FLAG (nh.type, ZEBRA_NEXTHOP_DROP);
+	nh.gw.drop = ZEBRA_DROP_REJECT;
         break;
       case 'b':
       case 'B': /* XXX */
-        SET_FLAG (flag, ZEBRA_FLAG_BLACKHOLE);
+        SET_FLAG (nh.type, ZEBRA_NEXTHOP_DROP);
+	nh.gw.drop = ZEBRA_DROP_BLACKHOLE;
         break;
       default:
         vty_out (vty, "%% Malformed flag %s %s", flag_str, VTY_NEWLINE);
@@ -1253,27 +2036,30 @@
 	  vty_out (vty, "%% Malformed address%s", VTY_NEWLINE);
 	  return CMD_WARNING;
 	}
-      type = STATIC_IPV6_GATEWAY_IFNAME;
-      gate = &gate_addr;
+
+      SET_FLAG (nh.type, ZEBRA_NEXTHOP_IPV6);
+      SET_FLAG (nh.type, ZEBRA_NEXTHOP_IFNAME);
+      nh.gw.ipv6 = gate_addr;
+      strncpy(nh.intf.name, ifname, IFNAMSIZ);
     }
   else
     {
       if (ret == 1)
 	{
-	  type = STATIC_IPV6_GATEWAY;
-	  gate = &gate_addr;
+	  SET_FLAG (nh.type, ZEBRA_NEXTHOP_IPV6);
+	  nh.gw.ipv6 = gate_addr;
 	}
       else
 	{
-	  type = STATIC_IPV6_IFNAME;
-	  ifname = gate_str;
+	  SET_FLAG (nh.type, ZEBRA_NEXTHOP_IFNAME);
+	  strncpy(nh.intf.name, gate_str, IFNAMSIZ);
 	}
     }
 
   if (add_cmd)
-    static_add_ipv6 (&p, type, gate, ifname, flag, distance, table);
+    static_add_route (&p, &nh, distance, table);
   else
-    static_delete_ipv6 (&p, type, gate, ifname, distance, table);
+    static_delete_route (&p, &nh, distance, table);
 
   return CMD_SUCCESS;
 }
@@ -1290,6 +2076,20 @@
   return static_ipv6_func (vty, 1, argv[0], argv[1], NULL, NULL, NULL);
 }
 
+DEFUN (ipv6_route_advmss,
+       ipv6_route_advmss_cmd,
+       "ipv6 route X:X::X:X/M (X:X::X:X|INTERFACE) advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "IPv6 gateway address\n"
+       "IPv6 gateway interface name\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return static_ipv6_func (vty, 1, argv[0], argv[1], NULL, NULL, NULL);
+}
+
 DEFUN (ipv6_route_flags,
        ipv6_route_flags_cmd,
        "ipv6 route X:X::X:X/M (X:X::X:X|INTERFACE) (reject|blackhole)",
@@ -1316,6 +2116,20 @@
   return static_ipv6_func (vty, 1, argv[0], argv[1], argv[2], NULL, NULL);
 }
 
+DEFUN (ipv6_route_ifname_advmss,
+       ipv6_route_ifname_advmss_cmd,
+       "ipv6 route X:X::X:X/M X:X::X:X INTERFACE advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "IPv6 gateway address\n"
+       "IPv6 gateway interface name\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return static_ipv6_func (vty, 1, argv[0], argv[1], argv[2], NULL, NULL);
+}
+
 DEFUN (ipv6_route_ifname_flags,
        ipv6_route_ifname_flags_cmd,
        "ipv6 route X:X::X:X/M X:X::X:X INTERFACE (reject|blackhole)",
@@ -1343,6 +2157,21 @@
   return static_ipv6_func (vty, 1, argv[0], argv[1], NULL, NULL, argv[2]);
 }
 
+DEFUN (ipv6_route_pref_advmss,
+       ipv6_route_pref_advmss_cmd,
+       "ipv6 route X:X::X:X/M (X:X::X:X|INTERFACE) <1-255> advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "IPv6 gateway address\n"
+       "IPv6 gateway interface name\n"
+       "Distance value for this prefix\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return static_ipv6_func (vty, 1, argv[0], argv[1], NULL, NULL, argv[2]);
+}
+
 DEFUN (ipv6_route_flags_pref,
        ipv6_route_flags_pref_cmd,
        "ipv6 route X:X::X:X/M (X:X::X:X|INTERFACE) (reject|blackhole) <1-255>",
@@ -1371,6 +2200,21 @@
   return static_ipv6_func (vty, 1, argv[0], argv[1], argv[2], NULL, argv[3]);
 }
 
+DEFUN (ipv6_route_ifname_pref_advmss,
+       ipv6_route_ifname_pref_advmss_cmd,
+       "ipv6 route X:X::X:X/M X:X::X:X INTERFACE <1-255> advmss <0-65495>",
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "IPv6 gateway address\n"
+       "IPv6 gateway interface name\n"
+       "Distance value for this prefix\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return static_ipv6_func (vty, 1, argv[0], argv[1], argv[2], NULL, argv[3]);
+}
+
 DEFUN (ipv6_route_ifname_flags_pref,
        ipv6_route_ifname_flags_pref_cmd,
        "ipv6 route X:X::X:X/M X:X::X:X INTERFACE (reject|blackhole) <1-255>",
@@ -1399,6 +2243,21 @@
   return static_ipv6_func (vty, 0, argv[0], argv[1], NULL, NULL, NULL);
 }
 
+DEFUN (no_ipv6_route_advmss,
+       no_ipv6_route_advmss_cmd,
+       "no ipv6 route X:X::X:X/M (X:X::X:X|INTERFACE) advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "IPv6 gateway address\n"
+       "IPv6 gateway interface name\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return static_ipv6_func (vty, 0, argv[0], argv[1], NULL, NULL, NULL);
+}
+
 ALIAS (no_ipv6_route,
        no_ipv6_route_flags_cmd,
        "no ipv6 route X:X::X:X/M (X:X::X:X|INTERFACE) (reject|blackhole)",
@@ -1424,6 +2283,21 @@
   return static_ipv6_func (vty, 0, argv[0], argv[1], argv[2], NULL, NULL);
 }
 
+DEFUN (no_ipv6_route_ifname_advmss,
+       no_ipv6_route_ifname_advmss_cmd,
+       "no ipv6 route X:X::X:X/M X:X::X:X INTERFACE advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "IPv6 gateway address\n"
+       "IPv6 gateway interface name\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return static_ipv6_func (vty, 0, argv[0], argv[1], argv[2], NULL, NULL);
+}
+
 ALIAS (no_ipv6_route_ifname,
        no_ipv6_route_ifname_flags_cmd,
        "no ipv6 route X:X::X:X/M X:X::X:X INTERFACE (reject|blackhole)",
@@ -1450,6 +2324,22 @@
   return static_ipv6_func (vty, 0, argv[0], argv[1], NULL, NULL, argv[2]);
 }
 
+DEFUN (no_ipv6_route_pref_advmss,
+       no_ipv6_route_pref_advmss_cmd,
+       "no ipv6 route X:X::X:X/M (X:X::X:X|INTERFACE) <1-255> advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "IPv6 gateway address\n"
+       "IPv6 gateway interface name\n"
+       "Distance value for this prefix\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return static_ipv6_func (vty, 0, argv[0], argv[1], NULL, NULL, argv[2]);
+}
+
 DEFUN (no_ipv6_route_flags_pref,
        no_ipv6_route_flags_pref_cmd,
        "no ipv6 route X:X::X:X/M (X:X::X:X|INTERFACE) (reject|blackhole) <1-255>",
@@ -1481,6 +2371,22 @@
   return static_ipv6_func (vty, 0, argv[0], argv[1], argv[2], NULL, argv[3]);
 }
 
+DEFUN (no_ipv6_route_ifname_pref_advmss,
+       no_ipv6_route_ifname_pref_advmss_cmd,
+       "no ipv6 route X:X::X:X/M X:X::X:X INTERFACE <1-255> advmss <0-65495>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "IPv6 gateway address\n"
+       "IPv6 gateway interface name\n"
+       "Distance value for this prefix\n"
+       "Advertised MSS\n"
+       "Maximum TCP Segment Size\n")
+{
+  return static_ipv6_func (vty, 0, argv[0], argv[1], argv[2], NULL, argv[3]);
+}
+
 DEFUN (no_ipv6_route_ifname_flags_pref,
        no_ipv6_route_ifname_flags_pref_cmd,
        "no ipv6 route X:X::X:X/M X:X::X:X INTERFACE (reject|blackhole) <1-255>",
@@ -1497,6 +2403,195 @@
   return static_ipv6_func (vty, 0, argv[0], argv[1], argv[2], argv[3], argv[4]);
 }
 
+#ifdef HAVE_MPLS
+static int
+static_ipv6_func_mpls (struct vty *vty, int add_cmd, const char *dest,
+  const char *addr, const char *distance, const char **argv)
+{
+  struct zmpls_out_segment out;
+  int result;
+
+  memset (&out, 0, sizeof (out));
+  out.owner = ZEBRA_ROUTE_STATIC;
+  result = nhlfe_parse (vty, argv, &out, addr);
+  if (result != CMD_SUCCESS)
+    return result;
+
+  out.index = mpls_out_segment_find_index_by_nhlfe(&out);
+
+  if (add_cmd)
+  {
+    if (out.index)
+    {
+      vty_out(vty, "NHLFE already exists%s",VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+
+    if ((result = mpls_out_segment_register (&out)))
+    {
+      vty_out(vty, "Unable to register NHLFE(%d)%s",result, VTY_NEWLINE);
+      return CMD_WARNING;
+    }
+  }
+
+  result = static_ipv6_func (vty, add_cmd, dest, NULL, NULL, NULL, distance);
+
+  if (add_cmd)
+  {
+    if (result != CMD_SUCCESS)
+    {
+      mpls_out_segment_unregister_by_index (out.index);
+      return CMD_WARNING;
+    }
+  }
+  else
+  {
+    mpls_out_segment_unregister_by_index (out.index);
+  }
+  return CMD_SUCCESS;
+}
+
+DEFUN (ipv6_route_mpls,
+       ipv6_route_mpls_cmd,
+       "ipv6 route X:X::X:X/M (gen|atm|fr) VALUE nexthop INTERFACE",
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IPv6 gateway interface name\n")
+{
+  return static_ipv6_func_mpls (vty, 1, argv[0], NULL, NULL, &argv[1]);
+}
+
+DEFUN (ipv6_route_mpls_addr,
+       ipv6_route_mpls_addr_cmd,
+       "ipv6 route X:X::X:X/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR",
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IPv6 gateway interface name\n"
+       "IPv6 gateway address\n")
+{
+  return static_ipv6_func_mpls (vty, 1, argv[0], argv[4], NULL, &argv[1]);
+}
+
+DEFUN (ipv6_route_mpls_pref,
+       ipv6_route_mpls_pref_cmd,
+       "ipv6 route X:X::X:X/M (gen|atm|fr) VALUE nexthop INTERFACE <1-255>",
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IPv6 gateway interface name\n"
+       "Distance value for this prefix\n")
+{
+  return static_ipv6_func_mpls (vty, 1, argv[0], NULL, argv[4], &argv[1]);
+}
+
+DEFUN (ipv6_route_mpls_pref_addr,
+       ipv6_route_mpls_pref_addr_cmd,
+       "ipv6 route X:X::X:X/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR <1-255>",
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IPv6 gateway interface name\n"
+       "IPv6 gateway address\n"
+       "Distance value for this prefix\n")
+{
+  return static_ipv6_func_mpls (vty, 1, argv[0], argv[4], argv[5], &argv[1]);
+}
+
+DEFUN (no_ipv6_route_mpls,
+       no_ipv6_route_mpls_cmd,
+       "no ipv6 route X:X::X:X/M (gen|atm|fr) VALUE nexthop INTERFACE",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IPv6 gateway interface name\n")
+{
+  return static_ipv6_func_mpls (vty, 0, argv[0], NULL, NULL, &argv[1]);
+}
+
+DEFUN (no_ipv6_route_mpls_addr,
+       no_ipv6_route_mpls_addr_cmd,
+       "no ipv6 route X:X::X:X/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IPv6 gateway interface name\n"
+       "IPv6 gateway address\n")
+{
+  return static_ipv6_func_mpls (vty, 0, argv[0], argv[4], NULL, &argv[1]);
+}
+
+DEFUN (no_ipv6_route_mpls_pref,
+       no_ipv6_route_mpls_pref_cmd,
+       "no ipv6 route X:X::X:X/M (gen|atm|fr) VALUE nexthop INTERFACE <1-255>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IPv6 gateway interface name\n"
+       "Distance value for this prefix\n")
+{
+  return static_ipv6_func_mpls (vty, 0, argv[0], NULL, argv[4], &argv[1]);
+}
+
+DEFUN (no_ipv6_route_mpls_pref_addr,
+       no_ipv6_route_mpls_pref_addr_cmd,
+       "no ipv6 route X:X::X:X/M (gen|atm|fr) VALUE nexthop INTERFACE ADDR <1-255>",
+       NO_STR
+       IP_STR
+       "Establish static routes\n"
+       "IPv6 destination prefix (e.g. 3ffe:506::/32)\n"
+       "Out-going generic MPLS label (16 - 2^20-1)\n"
+       "Out-going ATM MPLS label (VPI/VCI)\n"
+       "Out-going Frame Relay MPLS label (16 - 2^17-1)\n"
+       "Out-going label value\n"
+       "Nexthop\n"
+       "IPv6 gateway interface name\n"
+       "IPv6 gateway address\n"
+       "Distance value for this prefix\n")
+{
+  return static_ipv6_func_mpls (vty, 0, argv[0], argv[4], argv[5], &argv[1]);
+}
+#endif /* HAVE_MPLS */
+
 /* New RIB.  Detailed information for IPv6 route. */
 static void
 vty_show_ipv6_route_detail (struct vty *vty, struct route_node *rn)
@@ -1554,32 +2649,63 @@
 
       for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
 	{
+           if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
+              continue;
+
 	  vty_out (vty, "  %c",
 		   CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB) ? '*' : ' ');
 
-	  switch (nexthop->type)
+	  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
 	    {
-	    case NEXTHOP_TYPE_IPV6:
-	    case NEXTHOP_TYPE_IPV6_IFINDEX:
-	    case NEXTHOP_TYPE_IPV6_IFNAME:
 	      vty_out (vty, " %s",
 		       inet_ntop (AF_INET6, &nexthop->gate.ipv6, buf, BUFSIZ));
-	      if (nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME)
+	      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
 		vty_out (vty, ", %s", nexthop->ifname);
 	      else if (nexthop->ifindex)
 		vty_out (vty, ", via %s", ifindex2ifname (nexthop->ifindex));
-	      break;
-	    case NEXTHOP_TYPE_IFINDEX:
+	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+	    {
 	      vty_out (vty, " directly connected, %s",
 		       ifindex2ifname (nexthop->ifindex));
-	      break;
-	    case NEXTHOP_TYPE_IFNAME:
+	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+	    {
 	      vty_out (vty, " directly connected, %s",
 		       nexthop->ifname);
-	      break;
-	    default:
-	      break;
 	    }
+	  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
+	    {
+	      switch (nexthop->drop)
+		{
+		  case ZEBRA_DROP_NULL:
+		    vty_out (vty, " directly connected, Null0");
+		    break;
+		  case ZEBRA_DROP_REJECT:
+		    vty_out (vty, ", reject");
+		    break;
+		  case ZEBRA_DROP_BLACKHOLE:
+		    vty_out (vty, ", blackhole");
+		    break;
+		  default:
+		    assert(0);
+		}
+	    }
+#ifdef HAVE_MPLS
+          if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_MPLS))
+            {
+              struct zmpls_out_segment *out;
+              char buf[16];
+
+              out = mpls_out_segment_find(nexthop->mpls);
+              if (out)
+                mpls_print_label(&out->nh.mpls, buf);
+              else
+                strcpy(buf, "not found");
+              vty_out (vty, " (label %s)", buf);
+           }
+#endif
+
 	  if (! CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE))
 	    vty_out (vty, " inactive");
 
@@ -1587,26 +2713,38 @@
 	    {
 	      vty_out (vty, " (recursive");
 		
-	      switch (nexthop->rtype)
+	      if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
 		{
-		case NEXTHOP_TYPE_IPV6:
-		case NEXTHOP_TYPE_IPV6_IFINDEX:
-		case NEXTHOP_TYPE_IPV6_IFNAME:
-		  vty_out (vty, " via %s)",
+		  vty_out (vty, " via %s",
 			   inet_ntop (AF_INET6, &nexthop->rgate.ipv6,
 				      buf, BUFSIZ));
 		  if (nexthop->rifindex)
 		    vty_out (vty, ", %s", ifindex2ifname (nexthop->rifindex));
-		  break;
-		case NEXTHOP_TYPE_IFINDEX:
-		case NEXTHOP_TYPE_IFNAME:
+		  vty_out (vty, ")");
+		}
+	      else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
+		{
 		  vty_out (vty, " is directly connected, %s)",
 			   ifindex2ifname (nexthop->rifindex));
-		  break;
-		default:
-		  break;
 		}
+#ifdef HAVE_MPLS
+              if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_MPLS))
+                {
+                  struct zmpls_out_segment *out;
+                  char buf[16];
+
+                  out = mpls_out_segment_find(nexthop->rmpls);
+                  if (out)
+                    mpls_print_label(&out->nh.mpls, buf);
+                  else
+                    strcpy(buf, "not found");
+                  vty_out (vty, " (label %s)", buf);
+                }
+#endif
 	    }
+          if (nexthop->advmss)
+            vty_out (vty, " advmss %d", nexthop->advmss);
+
 	  vty_out (vty, "%s", VTY_NEWLINE);
 	}
       vty_out (vty, "%s", VTY_NEWLINE);
@@ -1624,8 +2762,12 @@
   /* Nexthop information. */
   for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
     {
+      if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_IGNORE))
+         continue;
+
       if (nexthop == rib->nexthop)
 	{
+
 	  /* Prefix information. */
 	  len = vty_out (vty, "%c%c%c %s/%d",
 			 zebra_route_char (rib->type),
@@ -1648,29 +2790,40 @@
 		 ? '*' : ' ',
 		 len - 3, ' ');
 
-      switch (nexthop->type)
+      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
 	{
-	case NEXTHOP_TYPE_IPV6:
-	case NEXTHOP_TYPE_IPV6_IFINDEX:
-	case NEXTHOP_TYPE_IPV6_IFNAME:
 	  vty_out (vty, " via %s",
 		   inet_ntop (AF_INET6, &nexthop->gate.ipv6, buf, BUFSIZ));
-	  if (nexthop->type == NEXTHOP_TYPE_IPV6_IFNAME)
+	  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
 	    vty_out (vty, ", %s", nexthop->ifname);
 	  else if (nexthop->ifindex)
 	    vty_out (vty, ", %s", ifindex2ifname (nexthop->ifindex));
-	  break;
-	case NEXTHOP_TYPE_IFINDEX:
+	}
+      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+	{
 	  vty_out (vty, " is directly connected, %s",
 		   ifindex2ifname (nexthop->ifindex));
-	  break;
-	case NEXTHOP_TYPE_IFNAME:
+	}
+      else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+	{
 	  vty_out (vty, " is directly connected, %s",
 		   nexthop->ifname);
-	  break;
-	default:
-	  break;
 	}
+#ifdef HAVE_MPLS
+      if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_MPLS))
+        {
+          struct zmpls_out_segment *out;
+          char buf[16];
+
+          out = mpls_out_segment_find(nexthop->mpls);
+          if (out)
+            mpls_print_label(&out->nh.mpls, buf);
+          else
+            strcpy(buf, "not found");
+          vty_out (vty, " (label %s)", buf);
+       }
+#endif
+
       if (! CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_ACTIVE))
 	vty_out (vty, " inactive");
 
@@ -1678,32 +2831,57 @@
 	{
 	  vty_out (vty, " (recursive");
 		
-	  switch (nexthop->rtype)
+	  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IPV6))
 	    {
-	    case NEXTHOP_TYPE_IPV6:
-	    case NEXTHOP_TYPE_IPV6_IFINDEX:
-	    case NEXTHOP_TYPE_IPV6_IFNAME:
-	      vty_out (vty, " via %s)",
+	      vty_out (vty, " via %s",
 		       inet_ntop (AF_INET6, &nexthop->rgate.ipv6,
 				  buf, BUFSIZ));
 	      if (nexthop->rifindex)
 		vty_out (vty, ", %s", ifindex2ifname (nexthop->rifindex));
-	      break;
-	    case NEXTHOP_TYPE_IFINDEX:
-	    case NEXTHOP_TYPE_IFNAME:
+	      vty_out (vty, ")");
+	    }
+	  else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_IFINDEX))
+	    {
 	      vty_out (vty, " is directly connected, %s)",
 		       ifindex2ifname (nexthop->rifindex));
-	      break;
-	    default:
-	      break;
 	    }
+	  else if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_DROP))
+	    {
+	      switch (nexthop->drop)
+		{
+		  case ZEBRA_DROP_NULL:
+		    vty_out (vty, " directly connected, Null0");
+		    break;
+		  case ZEBRA_DROP_REJECT:
+		    vty_out (vty, ", reject");
+		    break;
+		  case ZEBRA_DROP_BLACKHOLE:
+		    vty_out (vty, ", blackhole");
+		    break;
+		  default:
+		    assert(0);
+		}
+	    }
+#ifdef HAVE_MPLS
+	  if (CHECK_FLAG (nexthop->rtype, ZEBRA_NEXTHOP_MPLS))
+            {
+              struct zmpls_out_segment *out;
+              char buf[16];
+
+              out = mpls_out_segment_find(nexthop->rmpls);
+              if (out)
+                mpls_print_label(&out->nh.mpls, buf);
+              else
+                strcpy(buf, "not found");
+              vty_out (vty, " (label %s)", buf);
+           }
+#endif
 	}
 
-      if (CHECK_FLAG (rib->flags, ZEBRA_FLAG_BLACKHOLE))
-       vty_out (vty, ", bh");
-      if (CHECK_FLAG (rib->flags, ZEBRA_FLAG_REJECT))
-       vty_out (vty, ", rej");
-      
+
+      if (nexthop->advmss)
+	vty_out (vty, " advmss %d", nexthop->advmss);
+
       if (rib->type == ZEBRA_ROUTE_RIPNG
 	  || rib->type == ZEBRA_ROUTE_OSPF6
 	  || rib->type == ZEBRA_ROUTE_ISIS
@@ -1730,6 +2908,7 @@
 		     tm->tm_yday/7,
 		     tm->tm_yday - ((tm->tm_yday/7) * 7), tm->tm_hour);
 	}
+
       vty_out (vty, "%s", VTY_NEWLINE);
     }
 }
@@ -1842,6 +3021,8 @@
     type = ZEBRA_ROUTE_RIPNG;
   else if (strncmp (argv[0], "s", 1) == 0)
     type = ZEBRA_ROUTE_STATIC;
+  else if (strncmp (argv[0], "l", 1) == 0)
+    type = ZEBRA_ROUTE_LDP;
   else 
     {
       vty_out (vty, "Unknown route type%s", VTY_NEWLINE);
@@ -1948,7 +3129,7 @@
 static_config_ipv6 (struct vty *vty)
 {
   struct route_node *rn;
-  struct static_ipv6 *si;  
+  struct static_route *si;  
   int write;
   char buf[BUFSIZ];
   struct route_table *stable;
@@ -1967,28 +3148,39 @@
 		 inet_ntop (AF_INET6, &rn->p.u.prefix6, buf, BUFSIZ),
 		 rn->p.prefixlen);
 
-	switch (si->type)
+        if (CHECK_FLAG(si->nh.type, ZEBRA_NEXTHOP_DROP))
+	  switch(si->nh.gw.drop)
+	    {
+	      case ZEBRA_DROP_NULL:
+		vty_out (vty, " Null0");
+		break;
+	      case ZEBRA_DROP_REJECT:
+		vty_out (vty, " %s", "reject");
+		break;
+	      case ZEBRA_DROP_BLACKHOLE:
+		vty_out (vty, " %s", "blackhole");
+		break;
+	      default:
+		assert(0);
+	    }
+	else
 	  {
-	  case STATIC_IPV6_GATEWAY:
-	    vty_out (vty, " %s", inet_ntop (AF_INET6, &si->ipv6, buf, BUFSIZ));
-	    break;
-	  case STATIC_IPV6_IFNAME:
-	    vty_out (vty, " %s", si->ifname);
-	    break;
-	  case STATIC_IPV6_GATEWAY_IFNAME:
-	    vty_out (vty, " %s %s",
-		     inet_ntop (AF_INET6, &si->ipv6, buf, BUFSIZ), si->ifname);
-	    break;
+	    if (CHECK_FLAG(si->nh.type, ZEBRA_NEXTHOP_IPV6))
+	      vty_out (vty, " %s", inet_ntop (AF_INET6, &si->nh.gw.ipv6,buf,BUFSIZ));
+	    if (CHECK_FLAG(si->nh.type, ZEBRA_NEXTHOP_IFNAME))
+	      vty_out (vty, " %s", si->nh.intf.name);
+#ifdef HAVE_MPLS
+	    if (CHECK_FLAG(si->nh.type, ZEBRA_NEXTHOP_MPLS))
+	      vty_out (vty, " 0x%08x", si->nh.mpls);
+#endif
 	  }
 
-       if (CHECK_FLAG(si->flags, ZEBRA_FLAG_REJECT))
-               vty_out (vty, " %s", "reject");
-
-       if (CHECK_FLAG(si->flags, ZEBRA_FLAG_BLACKHOLE))
-               vty_out (vty, " %s", "blackhole");
-
 	if (si->distance != ZEBRA_STATIC_DISTANCE_DEFAULT)
 	  vty_out (vty, " %d", si->distance);
+
+        if (si->nh.advmss)
+	  vty_out (vty, " advmss %d", si->nh.advmss);
+
 	vty_out (vty, "%s", VTY_NEWLINE);
 
 	write = 1;
@@ -2070,6 +3262,37 @@
   install_element (CONFIG_NODE, &no_ip_route_mask_flags_distance_cmd);
   install_element (CONFIG_NODE, &no_ip_route_mask_flags_distance2_cmd);
 
+  install_element (CONFIG_NODE, &ip_route_advmss_cmd);
+  install_element (CONFIG_NODE, &ip_route_mask_advmss_cmd);
+  install_element (CONFIG_NODE, &ip_route_distance_advmss_cmd);
+  install_element (CONFIG_NODE, &ip_route_mask_distance_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mask_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_distance_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mask_distance_advmss_cmd);
+#ifdef HAVE_MPLS
+  install_element (CONFIG_NODE, &ip_route_mpls_cmd);
+  install_element (CONFIG_NODE, &ip_route_mpls_addr_cmd);
+  install_element (CONFIG_NODE, &ip_route_mpls_mask_cmd);
+  install_element (CONFIG_NODE, &ip_route_mpls_mask_addr_cmd);
+  install_element (CONFIG_NODE, &ip_route_mpls_distance_cmd);
+  install_element (CONFIG_NODE, &ip_route_mpls_distance_addr_cmd);
+  install_element (CONFIG_NODE, &ip_route_mpls_mask_distance_cmd);
+  install_element (CONFIG_NODE, &ip_route_mpls_mask_distance_addr_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_addr_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_mask_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_mask_addr_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_distance_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_distance_addr_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_mask_distance_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_mask_distance_addr_cmd);
+
+  install_element (CONFIG_NODE, &ip_route_mpls_advmss_cmd);
+  install_element (CONFIG_NODE, &ip_route_mpls_addr_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ip_route_mpls_addr_advmss_cmd);
+#endif /* HAVE_MPLS */
   install_element (VIEW_NODE, &show_ip_route_cmd);
   install_element (VIEW_NODE, &show_ip_route_addr_cmd);
   install_element (VIEW_NODE, &show_ip_route_prefix_cmd);
@@ -2105,11 +3328,29 @@
   install_element (CONFIG_NODE, &no_ipv6_route_flags_pref_cmd);
   install_element (CONFIG_NODE, &no_ipv6_route_ifname_pref_cmd);
   install_element (CONFIG_NODE, &no_ipv6_route_ifname_flags_pref_cmd);
+  install_element (CONFIG_NODE, &ipv6_route_advmss_cmd);
+  install_element (CONFIG_NODE, &ipv6_route_ifname_advmss_cmd);
+  install_element (CONFIG_NODE, &ipv6_route_pref_advmss_cmd);
+  install_element (CONFIG_NODE, &ipv6_route_ifname_pref_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ipv6_route_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ipv6_route_ifname_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ipv6_route_pref_advmss_cmd);
+  install_element (CONFIG_NODE, &no_ipv6_route_ifname_pref_advmss_cmd);
   install_element (VIEW_NODE, &show_ipv6_route_cmd);
   install_element (VIEW_NODE, &show_ipv6_route_protocol_cmd);
   install_element (VIEW_NODE, &show_ipv6_route_addr_cmd);
   install_element (VIEW_NODE, &show_ipv6_route_prefix_cmd);
   install_element (VIEW_NODE, &show_ipv6_route_prefix_longer_cmd);
+#ifdef HAVE_MPLS
+  install_element (CONFIG_NODE, &ipv6_route_mpls_cmd);
+  install_element (CONFIG_NODE, &ipv6_route_mpls_addr_cmd);
+  install_element (CONFIG_NODE, &ipv6_route_mpls_pref_cmd);
+  install_element (CONFIG_NODE, &ipv6_route_mpls_pref_addr_cmd);
+  install_element (CONFIG_NODE, &no_ipv6_route_mpls_cmd);
+  install_element (CONFIG_NODE, &no_ipv6_route_mpls_addr_cmd);
+  install_element (CONFIG_NODE, &no_ipv6_route_mpls_pref_cmd);
+  install_element (CONFIG_NODE, &no_ipv6_route_mpls_pref_addr_cmd);
+#endif /* HAVE_MPLS */
   install_element (ENABLE_NODE, &show_ipv6_route_cmd);
   install_element (ENABLE_NODE, &show_ipv6_route_protocol_cmd);
   install_element (ENABLE_NODE, &show_ipv6_route_addr_cmd);
diff -Naur quagga-0.99.10/zebra/zserv.c quagga-mpls/zebra/zserv.c
--- quagga-0.99.10/zebra/zserv.c	2007-05-10 04:38:52.000000000 +0200
+++ quagga-mpls/zebra/zserv.c	2008-11-25 12:30:18.000000000 +0100
@@ -336,6 +336,25 @@
   return zebra_server_send_message(client);
 }
 
+static void
+zsend_nexthop (struct zapi_nexthop *nh, struct nexthop *nexthop)
+{
+  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_DROP))
+    nh->gw.drop = nexthop->drop;
+  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV4))
+    nh->gw.ipv4 = nexthop->gate.ipv4;
+#ifdef HAVE_IPV6
+  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IPV6))
+    memcpy (&nh->gw.ipv6, &nexthop->gate.ipv6, 16);
+#endif
+  if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFINDEX))
+    nh->intf.index = nexthop->ifindex;
+  else if (CHECK_FLAG (nexthop->type, ZEBRA_NEXTHOP_IFNAME))
+    strncpy (nh->intf.name, nexthop->ifname, IFNAMSIZ);
+
+  nh->type = nexthop->type;
+}
+
 /*
  * The zebra server sends the clients  a ZEBRA_IPV4_ROUTE_ADD or a
  * ZEBRA_IPV6_ROUTE_ADD via zsend_route_multipath in the following
@@ -363,113 +382,103 @@
 zsend_route_multipath (int cmd, struct zserv *client, struct prefix *p,
                        struct rib *rib)
 {
-  int psize;
   struct stream *s;
+  int nhnum;
   struct nexthop *nexthop;
-  unsigned long nhnummark = 0, messmark = 0;
-  int nhnum = 0;
   u_char zapi_flags = 0;
-  
   s = client->obuf;
-  stream_reset (s);
-  
-  zserv_create_header (s, cmd);
-  
-  /* Put type and nexthop. */
-  stream_putc (s, rib->type);
-  stream_putc (s, rib->flags);
-  
-  /* marker for message flags field */
-  messmark = stream_get_endp (s);
-  stream_putc (s, 0);
-
-  /* Prefix. */
-  psize = PSIZE (p->prefixlen);
-  stream_putc (s, p->prefixlen);
-  stream_write (s, (u_char *) & p->u.prefix, psize);
 
-  /* 
-   * XXX The message format sent by zebra below does not match the format
-   * of the corresponding message expected by the zebra server
-   * itself (e.g., see zread_ipv4_add). The nexthop_num is not set correctly,
-   * (is there a bug on the client side if more than one segment is sent?)
-   * nexthop ZEBRA_NEXTHOP_IPV4 is never set, ZEBRA_NEXTHOP_IFINDEX 
-   * is hard-coded.
-   */
-  /* Nexthop */
-  
-  for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
+  if (p->family == AF_INET)
     {
-      if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB))
+      struct zapi_ipv4 api;
+  
+      memset (&api, 0, sizeof(api));
+      api.type = rib->type;
+      api.flags = rib->flags;
+      nhnum = 0;
+
+      /* Nexthop */
+      for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
         {
-          SET_FLAG (zapi_flags, ZAPI_MESSAGE_NEXTHOP);
-          SET_FLAG (zapi_flags, ZAPI_MESSAGE_IFINDEX);
-          
-          if (nhnummark == 0)
+          if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB))
             {
-              nhnummark = stream_get_endp (s);
-              stream_putc (s, 1); /* placeholder */
+              SET_FLAG (zapi_flags, ZAPI_MESSAGE_NEXTHOP);
+              zsend_nexthop(&api.nexthop[nhnum], nexthop);
+              nhnum++;
             }
-          
-          nhnum++;
+        }
+      api.nexthop_num = nhnum;
 
-          switch(nexthop->type) 
-            {
-              case NEXTHOP_TYPE_IPV4:
-              case NEXTHOP_TYPE_IPV4_IFINDEX:
-                stream_put_in_addr (s, &nexthop->gate.ipv4);
-                break;
-#ifdef HAVE_IPV6
-              case NEXTHOP_TYPE_IPV6:
-              case NEXTHOP_TYPE_IPV6_IFINDEX:
-              case NEXTHOP_TYPE_IPV6_IFNAME:
-                stream_write (s, (u_char *) &nexthop->gate.ipv6, 16);
-                break;
-#endif
-              default:
-                if (cmd == ZEBRA_IPV4_ROUTE_ADD 
-                    || cmd == ZEBRA_IPV4_ROUTE_DELETE)
-                  {
-                    struct in_addr empty;
-                    memset (&empty, 0, sizeof (struct in_addr));
-                    stream_write (s, (u_char *) &empty, IPV4_MAX_BYTELEN);
-                  }
-                else
-                  {
-                    struct in6_addr empty;
-                    memset (&empty, 0, sizeof (struct in6_addr));
-                    stream_write (s, (u_char *) &empty, IPV6_MAX_BYTELEN);
-                  }
-              }
-
-          /* Interface index. */
-          stream_putc (s, 1);
-          stream_putl (s, nexthop->ifindex);
+      /* Distance */
+      if (CHECK_FLAG (zapi_flags, ZAPI_MESSAGE_DISTANCE))
+        api.distance = rib->distance;
 
-          break;
+      /* Metric */
+      if (cmd == ZEBRA_IPV4_ROUTE_ADD)
+        {
+          SET_FLAG (zapi_flags, ZAPI_MESSAGE_DISTANCE);
+          api.distance = rib->distance;
+          SET_FLAG (zapi_flags, ZAPI_MESSAGE_METRIC);
+          api.metric = rib->metric;
         }
-    }
+  
+      /* write real message flags value */
+      api.message = zapi_flags;
 
-  /* Metric */
-  if (cmd == ZEBRA_IPV4_ROUTE_ADD || ZEBRA_IPV6_ROUTE_ADD)
-    {
-      SET_FLAG (zapi_flags, ZAPI_MESSAGE_DISTANCE);
-      stream_putc (s, rib->distance);
-      SET_FLAG (zapi_flags, ZAPI_MESSAGE_METRIC);
-      stream_putl (s, rib->metric);
+      zapi_ipv4_write (cmd, s, (struct prefix_ipv4*)p, &api);
+
+      /* Write packet length. */
+      stream_putw_at (s, 0, stream_get_endp (s));
+
+      return zebra_server_send_message (client);
     }
+#ifdef HAVE_IPV6
+  else if (p->family == AF_INET6)
+    {
+      struct zapi_ipv6 api;
   
-  /* write real message flags value */
-  stream_putc_at (s, messmark, zapi_flags);
-  
-  /* Write next-hop number */
-  if (nhnummark)
-    stream_putc_at (s, nhnummark, nhnum);
+      memset (&api, 0, sizeof(api));
+      api.type = rib->type;
+      api.flags = rib->flags;
+      nhnum = 0;
+
+      /* Nexthop */
+      for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
+        {
+          if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB))
+            {
+              SET_FLAG (zapi_flags, ZAPI_MESSAGE_NEXTHOP);
+              zsend_nexthop(&api.nexthop[nhnum], nexthop);
+              nhnum++;
+            }
+        }
+      api.nexthop_num = nhnum;
+
+      /* Distance */
+      if (CHECK_FLAG (zapi_flags, ZAPI_MESSAGE_DISTANCE))
+        api.distance = rib->distance;
+
+      /* Metric */
+      if (cmd == ZEBRA_IPV6_ROUTE_ADD)
+        {
+          SET_FLAG (zapi_flags, ZAPI_MESSAGE_DISTANCE);
+          api.distance = rib->distance;
+          SET_FLAG (zapi_flags, ZAPI_MESSAGE_METRIC);
+          api.metric = rib->metric;
+        }
   
-  /* Write packet size. */
-  stream_putw_at (s, 0, stream_get_endp (s));
+      /* write real message flags value */
+      api.message = zapi_flags;
 
-  return zebra_server_send_message(client);
+      zapi_ipv6_write (cmd, s, (struct prefix_ipv6*)p, &api);
+
+      /* Write packet length. */
+      stream_putw_at (s, 0, stream_get_endp (s));
+
+      return zebra_server_send_message (client);
+    }
+#endif
+   return 0;
 }
 
 #ifdef HAVE_IPV6
@@ -481,9 +490,16 @@
   unsigned long nump;
   u_char num;
   struct nexthop *nexthop;
+  struct zapi_nexthop znh;
+  struct prefix p;
+
+  memset(&p, 0, sizeof(struct prefix));
+  p.family = AF_INET6;
+  p.prefixlen = IPV6_MAX_PREFIXLEN;
+  IPV6_ADDR_COPY (&p.u.prefix6, addr);
 
   /* Lookup nexthop. */
-  rib = rib_match_ipv6 (addr);
+  rib = rib_match_route (&p);
 
   /* Get output stream. */
   s = client->obuf;
@@ -502,25 +518,8 @@
       for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
 	if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB))
 	  {
-	    stream_putc (s, nexthop->type);
-	    switch (nexthop->type)
-	      {
-	      case ZEBRA_NEXTHOP_IPV6:
-		stream_put (s, &nexthop->gate.ipv6, 16);
-		break;
-	      case ZEBRA_NEXTHOP_IPV6_IFINDEX:
-	      case ZEBRA_NEXTHOP_IPV6_IFNAME:
-		stream_put (s, &nexthop->gate.ipv6, 16);
-		stream_putl (s, nexthop->ifindex);
-		break;
-	      case ZEBRA_NEXTHOP_IFINDEX:
-	      case ZEBRA_NEXTHOP_IFNAME:
-		stream_putl (s, nexthop->ifindex);
-		break;
-	      default:
-                /* do nothing */
-		break;
-	      }
+	    zsend_nexthop(&znh, nexthop);
+	    zapi_nexthop_write(s, &znh);
 	    num++;
 	  }
       stream_putc_at (s, nump, num);
@@ -545,9 +544,16 @@
   unsigned long nump;
   u_char num;
   struct nexthop *nexthop;
+  struct zapi_nexthop znh;
+  struct prefix p;
+
+  memset(&p, 0, sizeof(struct prefix));
+  p.family = AF_INET;
+  p.prefixlen = IPV4_MAX_PREFIXLEN;
+  IPV4_ADDR_COPY (&p.u.prefix4, &addr);
 
   /* Lookup nexthop. */
-  rib = rib_match_ipv4 (addr);
+  rib = rib_match_route (&p);
 
   /* Get output stream. */
   s = client->obuf;
@@ -566,20 +572,8 @@
       for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
 	if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB))
 	  {
-	    stream_putc (s, nexthop->type);
-	    switch (nexthop->type)
-	      {
-	      case ZEBRA_NEXTHOP_IPV4:
-		stream_put_in_addr (s, &nexthop->gate.ipv4);
-		break;
-	      case ZEBRA_NEXTHOP_IFINDEX:
-	      case ZEBRA_NEXTHOP_IFNAME:
-		stream_putl (s, nexthop->ifindex);
-		break;
-	      default:
-                /* do nothing */
-		break;
-	      }
+	    zsend_nexthop(&znh, nexthop);
+	    zapi_nexthop_write(s, &znh);
 	    num++;
 	  }
       stream_putc_at (s, nump, num);
@@ -603,9 +597,10 @@
   unsigned long nump;
   u_char num;
   struct nexthop *nexthop;
+  struct zapi_nexthop znh;
 
   /* Lookup nexthop. */
-  rib = rib_lookup_ipv4 (p);
+  rib = rib_lookup_route ((struct prefix*)p);
 
   /* Get output stream. */
   s = client->obuf;
@@ -624,20 +619,8 @@
       for (nexthop = rib->nexthop; nexthop; nexthop = nexthop->next)
 	if (CHECK_FLAG (nexthop->flags, NEXTHOP_FLAG_FIB))
 	  {
-	    stream_putc (s, nexthop->type);
-	    switch (nexthop->type)
-	      {
-	      case ZEBRA_NEXTHOP_IPV4:
-		stream_put_in_addr (s, &nexthop->gate.ipv4);
-		break;
-	      case ZEBRA_NEXTHOP_IFINDEX:
-	      case ZEBRA_NEXTHOP_IFNAME:
-		stream_putl (s, nexthop->ifindex);
-		break;
-	      default:
-                /* do nothing */
-		break;
-	      }
+	    zsend_nexthop(&znh, nexthop);
+	    zapi_nexthop_write(s, &znh);
 	    num++;
 	  }
       stream_putc_at (s, nump, num);
@@ -734,76 +717,41 @@
   int i;
   struct rib *rib;
   struct prefix_ipv4 p;
-  u_char message;
-  struct in_addr nexthop;
-  u_char nexthop_num;
-  u_char nexthop_type;
   struct stream *s;
-  unsigned int ifindex;
-  u_char ifname_len;
+  struct zapi_ipv4 api;
 
   /* Get input stream.  */
   s = client->ibuf;
+  memset (&api, 0, sizeof (api));
+  memset (&p, 0, sizeof (p));
+  zapi_ipv4_read (s, length, &api, &p);
 
   /* Allocate new rib. */
   rib = XCALLOC (MTYPE_RIB, sizeof (struct rib));
   
   /* Type, flags, message. */
-  rib->type = stream_getc (s);
-  rib->flags = stream_getc (s);
-  message = stream_getc (s); 
+  rib->type = api.type;
+  rib->flags = api.flags;
   rib->uptime = time (NULL);
 
-  /* IPv4 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv4));
-  p.family = AF_INET;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
-
   /* Nexthop parse. */
-  if (CHECK_FLAG (message, ZAPI_MESSAGE_NEXTHOP))
+  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
     {
-      nexthop_num = stream_getc (s);
-
-      for (i = 0; i < nexthop_num; i++)
-	{
-	  nexthop_type = stream_getc (s);
-
-	  switch (nexthop_type)
-	    {
-	    case ZEBRA_NEXTHOP_IFINDEX:
-	      ifindex = stream_getl (s);
-	      nexthop_ifindex_add (rib, ifindex);
-	      break;
-	    case ZEBRA_NEXTHOP_IFNAME:
-	      ifname_len = stream_getc (s);
-	      stream_forward_getp (s, ifname_len);
-	      break;
-	    case ZEBRA_NEXTHOP_IPV4:
-	      nexthop.s_addr = stream_get_ipv4 (s);
-	      nexthop_ipv4_add (rib, &nexthop, NULL);
-	      break;
-	    case ZEBRA_NEXTHOP_IPV6:
-	      stream_forward_getp (s, IPV6_MAX_BYTELEN);
-	      break;
-      case ZEBRA_NEXTHOP_BLACKHOLE:
-        nexthop_blackhole_add (rib);
-        break;
-	    }
-	}
+      for (i = 0; i < api.nexthop_num; i++)
+        nexthop_zapi_nexthop_add(rib, &api.nexthop[i]);
     }
 
   /* Distance. */
-  if (CHECK_FLAG (message, ZAPI_MESSAGE_DISTANCE))
-    rib->distance = stream_getc (s);
+  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
+    rib->distance = api.distance;
 
   /* Metric. */
-  if (CHECK_FLAG (message, ZAPI_MESSAGE_METRIC))
-    rib->metric = stream_getl (s);
+  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
+    rib->metric = api.metric;
     
   /* Table */
   rib->table=zebrad.rtm_table_default;
-  rib_add_ipv4_multipath (&p, rib);
+  rib_add_multipath ((struct prefix*)&p, rib);
   return 0;
 }
 
@@ -812,72 +760,22 @@
 zread_ipv4_delete (struct zserv *client, u_short length)
 {
   int i;
+  struct prefix_ipv4 p;
   struct stream *s;
   struct zapi_ipv4 api;
-  struct in_addr nexthop;
-  unsigned long ifindex;
-  struct prefix_ipv4 p;
-  u_char nexthop_num;
-  u_char nexthop_type;
-  u_char ifname_len;
-  
-  s = client->ibuf;
-  ifindex = 0;
-  nexthop.s_addr = 0;
 
-  /* Type, flags, message. */
-  api.type = stream_getc (s);
-  api.flags = stream_getc (s);
-  api.message = stream_getc (s);
-
-  /* IPv4 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv4));
-  p.family = AF_INET;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
+  /* Get input stream.  */
+  s = client->ibuf;
+  memset (&api, 0, sizeof (api));
+  memset (&p, 0, sizeof (p));
+  zapi_ipv4_read (s, length, &api, &p);
 
   /* Nexthop, ifindex, distance, metric. */
   if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
-    {
-      nexthop_num = stream_getc (s);
-
-      for (i = 0; i < nexthop_num; i++)
-	{
-	  nexthop_type = stream_getc (s);
-
-	  switch (nexthop_type)
-	    {
-	    case ZEBRA_NEXTHOP_IFINDEX:
-	      ifindex = stream_getl (s);
-	      break;
-	    case ZEBRA_NEXTHOP_IFNAME:
-	      ifname_len = stream_getc (s);
-	      stream_forward_getp (s, ifname_len);
-	      break;
-	    case ZEBRA_NEXTHOP_IPV4:
-	      nexthop.s_addr = stream_get_ipv4 (s);
-	      break;
-	    case ZEBRA_NEXTHOP_IPV6:
-	      stream_forward_getp (s, IPV6_MAX_BYTELEN);
-	      break;
-	    }
-	}
-    }
-
-  /* Distance. */
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (s);
-  else
-    api.distance = 0;
+    for (i = 0; i < api.nexthop_num; i++)
+      rib_delete_route (api.type, api.flags, (struct prefix*)&p,
+                        &api.nexthop[i], client->rtm_table);
 
-  /* Metric. */
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (s);
-  else
-    api.metric = 0;
-    
-  rib_delete_ipv4 (api.type, api.flags, &p, &nexthop, ifindex,
-		   client->rtm_table);
   return 0;
 }
 
@@ -910,65 +808,24 @@
 zread_ipv6_add (struct zserv *client, u_short length)
 {
   int i;
+  struct prefix_ipv6 p;
   struct stream *s;
   struct zapi_ipv6 api;
-  struct in6_addr nexthop;
-  unsigned long ifindex;
-  struct prefix_ipv6 p;
-  
-  s = client->ibuf;
-  ifindex = 0;
-  memset (&nexthop, 0, sizeof (struct in6_addr));
 
-  /* Type, flags, message. */
-  api.type = stream_getc (s);
-  api.flags = stream_getc (s);
-  api.message = stream_getc (s);
-
-  /* IPv4 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv6));
-  p.family = AF_INET6;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
+  /* Get input stream.  */
+  s = client->ibuf;
+  memset (&api, 0, sizeof (api));
+  memset (&p, 0, sizeof (p));
+  zapi_ipv6_read (s, length, &api, &p);
 
   /* Nexthop, ifindex, distance, metric. */
   if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
     {
-      u_char nexthop_type;
-
-      api.nexthop_num = stream_getc (s);
       for (i = 0; i < api.nexthop_num; i++)
-	{
-	  nexthop_type = stream_getc (s);
-
-	  switch (nexthop_type)
-	    {
-	    case ZEBRA_NEXTHOP_IPV6:
-	      stream_get (&nexthop, s, 16);
-	      break;
-	    case ZEBRA_NEXTHOP_IFINDEX:
-	      ifindex = stream_getl (s);
-	      break;
-	    }
-	}
+        rib_add_route (api.type, api.flags, (struct prefix*)&p,
+                       &api.nexthop[i], 0, api.metric, api.distance);
     }
 
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (s);
-  else
-    api.distance = 0;
-
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (s);
-  else
-    api.metric = 0;
-    
-  if (IN6_IS_ADDR_UNSPECIFIED (&nexthop))
-    rib_add_ipv6 (api.type, api.flags, &p, NULL, ifindex, 0, api.metric,
-		  api.distance);
-  else
-    rib_add_ipv6 (api.type, api.flags, &p, &nexthop, ifindex, 0, api.metric,
-		  api.distance);
   return 0;
 }
 
@@ -977,62 +834,24 @@
 zread_ipv6_delete (struct zserv *client, u_short length)
 {
   int i;
+  struct prefix_ipv6 p;
   struct stream *s;
   struct zapi_ipv6 api;
-  struct in6_addr nexthop;
-  unsigned long ifindex;
-  struct prefix_ipv6 p;
-  
-  s = client->ibuf;
-  ifindex = 0;
-  memset (&nexthop, 0, sizeof (struct in6_addr));
-
-  /* Type, flags, message. */
-  api.type = stream_getc (s);
-  api.flags = stream_getc (s);
-  api.message = stream_getc (s);
 
-  /* IPv4 prefix. */
-  memset (&p, 0, sizeof (struct prefix_ipv6));
-  p.family = AF_INET6;
-  p.prefixlen = stream_getc (s);
-  stream_get (&p.prefix, s, PSIZE (p.prefixlen));
+  /* Get input stream.  */
+  s = client->ibuf;
+  memset (&api, 0, sizeof (api));
+  memset (&p, 0, sizeof (p));
+  zapi_ipv6_read (s, length, &api, &p);
 
   /* Nexthop, ifindex, distance, metric. */
   if (CHECK_FLAG (api.message, ZAPI_MESSAGE_NEXTHOP))
     {
-      u_char nexthop_type;
-
-      api.nexthop_num = stream_getc (s);
       for (i = 0; i < api.nexthop_num; i++)
-	{
-	  nexthop_type = stream_getc (s);
-
-	  switch (nexthop_type)
-	    {
-	    case ZEBRA_NEXTHOP_IPV6:
-	      stream_get (&nexthop, s, 16);
-	      break;
-	    case ZEBRA_NEXTHOP_IFINDEX:
-	      ifindex = stream_getl (s);
-	      break;
-	    }
-	}
+        rib_delete_route (api.type, api.flags, (struct prefix*)&p,
+                          &api.nexthop[i], 0);
     }
 
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_DISTANCE))
-    api.distance = stream_getc (s);
-  else
-    api.distance = 0;
-  if (CHECK_FLAG (api.message, ZAPI_MESSAGE_METRIC))
-    api.metric = stream_getl (s);
-  else
-    api.metric = 0;
-    
-  if (IN6_IS_ADDR_UNSPECIFIED (&nexthop))
-    rib_delete_ipv6 (api.type, api.flags, &p, NULL, ifindex, 0);
-  else
-    rib_delete_ipv6 (api.type, api.flags, &p, &nexthop, ifindex, 0);
   return 0;
 }
 
@@ -1049,6 +868,416 @@
 }
 #endif /* HAVE_IPV6 */
 
+#ifdef HAVE_MPLS
+int
+zsend_mpls_xc_add (struct zserv *client, struct zmpls_xc *p)
+{
+  struct zapi_mpls_xc api;
+  struct stream *s;
+
+  s = client->obuf;
+  stream_reset (s);
+
+  api.owner = p->owner;
+  api.index = p->index;
+  api.in_labelspace = p->in_labelspace;
+  memcpy(&api.in_label,&p->in_label, sizeof(struct zmpls_label));
+  api.out_index = p->out_index;
+
+  zserv_create_header (s, ZEBRA_MPLS_XC_ADD);
+  mpls_xc_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+int
+zsend_mpls_xc_delete (struct zserv *client, struct zmpls_xc *p)
+{
+  struct zapi_mpls_xc api;
+  struct stream *s;
+
+  s = client->obuf;
+  stream_reset (s);
+
+  api.owner = p->owner;
+  api.index = p->index;
+  api.in_labelspace = p->in_labelspace;
+  memcpy(&api.in_label,&p->in_label, sizeof(struct zmpls_label));
+  api.out_index = p->out_index;
+
+  zserv_create_header (s, ZEBRA_MPLS_XC_DELETE);
+  mpls_xc_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+int
+zsend_mpls_in_segment_add (struct zserv *client, struct zmpls_in_segment *in)
+{
+  struct zapi_mpls_in_segment api;
+  struct stream *s;
+
+  s = client->obuf;
+  stream_reset (s);
+
+  zserv_create_header (s, ZEBRA_MPLS_IN_SEGMENT_ADD);
+
+  api.owner = in->owner;
+  api.labelspace = in->labelspace;
+  api.protocol = in->protocol;
+  api.pop = in->pop;
+  memcpy (&api.label, &in->label, sizeof (api.label));
+  
+  mpls_in_segment_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+int
+zsend_mpls_in_segment_delete (struct zserv *client, struct zmpls_in_segment *in)
+{
+  struct zapi_mpls_in_segment api;
+  struct stream *s;
+
+  s = client->obuf;
+  stream_reset (s);
+
+  zserv_create_header (s, ZEBRA_MPLS_IN_SEGMENT_DELETE);
+
+  api.owner = in->owner;
+  api.labelspace = in->labelspace;
+  api.protocol = in->protocol;
+  api.pop = in->pop;
+  memcpy (&api.label, &in->label, sizeof (api.label));
+  
+  mpls_in_segment_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+int
+zsend_mpls_out_segment_add (struct zserv *client, struct zmpls_out_segment *out)
+{
+  struct zapi_mpls_out_segment api;
+  struct stream *s;
+
+  api.owner = out->owner;
+
+  memcpy(&api.nh, &out->nh, sizeof(struct zapi_nexthop));
+
+  s = client->obuf;
+  stream_reset (s);
+
+  zserv_create_header (s, ZEBRA_MPLS_OUT_SEGMENT_ADD);
+  mpls_out_segment_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+int
+zsend_mpls_out_segment_delete (struct zserv *client, struct zmpls_out_segment *out)
+{
+  struct zapi_mpls_out_segment api;
+  struct stream *s;
+
+  api.owner = out->owner;
+
+  memcpy(&api.nh, &out->nh, sizeof(struct zapi_nexthop));
+
+  s = client->obuf;
+  stream_reset (s);
+
+  zserv_create_header (s, ZEBRA_MPLS_OUT_SEGMENT_DELETE);
+  mpls_out_segment_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+int
+zsend_mpls_labelspace_add (struct zserv *client, struct interface *ifp)
+{
+  struct zapi_mpls_labelspace api;
+  struct stream *s;
+
+  s = client->obuf;
+  stream_reset (s);
+
+  zserv_create_header (s, ZEBRA_MPLS_LABELSPACE_ADD);
+
+  api.owner = ZEBRA_ROUTE_KERNEL;
+  api.labelspace = ifp->mpls_labelspace;
+  strncpy(api.ifname, ifp->name, INTERFACE_NAMSIZ);
+  mpls_labelspace_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+int
+zsend_mpls_labelspace_delete (struct zserv *client, struct interface *ifp)
+{
+  struct zapi_mpls_labelspace api;
+  struct stream *s;
+
+  s = client->obuf;
+  stream_reset (s);
+
+  zserv_create_header (s, ZEBRA_MPLS_LABELSPACE_DELETE);
+
+  api.owner = ZEBRA_ROUTE_KERNEL;
+  api.labelspace = ifp->mpls_labelspace;
+  strncpy(api.ifname, ifp->name, INTERFACE_NAMSIZ);
+  mpls_labelspace_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+int
+zsend_mpls_ftn_add (struct zserv *client, struct zmpls_ftn *ftn)
+{
+  struct zapi_mpls_ftn api;
+  struct stream *s;
+
+  s = client->obuf;
+  stream_reset (s);
+
+  zserv_create_header (s, ZEBRA_MPLS_FTN_ADD);
+
+  api.owner = ftn->owner;
+  api.out_index = ftn->out_index;
+  memcpy(&api.fec.u.p, &ftn->fec.u.p, sizeof (struct prefix));
+  if (ftn->fec.u.p.family == AF_INET) {
+    api.fec.type = ZEBRA_MPLS_FEC_IPV4;
+  } else if (ftn->fec.u.p.family == AF_INET6) {
+    api.fec.type = ZEBRA_MPLS_FEC_IPV6;
+  } else {
+    assert (0);
+  }
+  mpls_ftn_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+int
+zsend_mpls_ftn_delete (struct zserv *client, struct zmpls_ftn *ftn)
+{
+  struct zapi_mpls_ftn api;
+  struct stream *s;
+
+  s = client->obuf;
+  stream_reset (s);
+
+  zserv_create_header (s, ZEBRA_MPLS_FTN_DELETE);
+
+  api.owner = ftn->owner;
+  api.out_index = ftn->out_index;
+  memcpy(&api.fec.u.p, &ftn->fec.u.p, sizeof (struct prefix));
+  if (ftn->fec.u.p.family == AF_INET) {
+    api.fec.type = ZEBRA_MPLS_FEC_IPV4;
+  } else if (ftn->fec.u.p.family == AF_INET6) {
+    api.fec.type = ZEBRA_MPLS_FEC_IPV6;
+  } else {
+    assert (0);
+  }
+  mpls_ftn_stream_write (s, &api);
+
+  stream_putw_at (s, 0, stream_get_endp (s));
+  return zebra_server_send_message(client);
+}
+
+static void
+zread_mpls_xc_add (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_xc api;
+  struct zmpls_out_segment *out;
+  struct zmpls_in_segment tmp;
+  struct zmpls_in_segment *in;
+  struct zmpls_xc xc;
+
+  memset(&api, 0, sizeof(api));
+  memset(&xc, 0, sizeof(xc));
+  mpls_xc_stream_read (client->ibuf, &api);
+
+  tmp.labelspace = api.in_labelspace;
+  memcpy(&tmp.label, &api.in_label, sizeof(struct zmpls_label));
+
+  out = mpls_out_segment_find (api.out_index);
+  in = mpls_in_segment_find (&tmp);
+
+  xc.in_labelspace = in->labelspace;
+  memcpy(&xc.in_label, &in->label, sizeof(struct zmpls_label));
+  xc.out_index = out->index;
+  xc.owner = api.owner;
+
+  mpls_xc_register (&xc);
+}
+
+static void
+zread_mpls_xc_delete (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_xc api;
+  struct zmpls_in_segment tmp;
+  struct zmpls_in_segment *in;
+  struct zmpls_xc *xc;
+
+  memset(&api, 0, sizeof(api));
+  memset(&tmp, 0, sizeof(tmp));
+  mpls_xc_stream_read (client->ibuf, &api);
+
+  memcpy(&tmp.label, &api.in_label, sizeof(struct zmpls_label));
+  tmp.labelspace = api.in_labelspace;
+  in = mpls_in_segment_find (&tmp);
+  xc = mpls_xc_find (in->xc);
+
+  if (xc)
+    mpls_xc_unregister (xc);
+  else
+    zlog_warn("zread_mpls_xc_delete: xc %d does not exist", in->xc);
+}
+
+static void
+zread_mpls_in_segment_add (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_in_segment api;
+  struct zmpls_in_segment in;
+
+  memset(&api, 0, sizeof(api));
+  memset(&in, 0, sizeof(in));
+  mpls_in_segment_stream_read (client->ibuf, &api);
+
+  in.owner = api.owner;
+  in.labelspace = api.labelspace;
+  in.protocol = api.protocol;
+  in.pop = api.pop;
+  memcpy (&in.label, &api.label, sizeof (api.label));
+
+  mpls_in_segment_register (&in, 1);
+}
+
+static void
+zread_mpls_in_segment_delete (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_in_segment api;
+  struct zmpls_in_segment in;
+
+  memset(&api, 0, sizeof(api));
+  memset(&in, 0, sizeof(in));
+  mpls_in_segment_stream_read (client->ibuf, &api);
+  in.owner = api.owner;
+  in.labelspace = api.labelspace;
+  in.protocol = api.protocol;
+  in.pop = api.pop;
+  memcpy (&in.label, &api.label, sizeof (api.label));
+
+  mpls_in_segment_unregister (&in, 0);
+}
+
+static void
+zread_mpls_out_segment_add (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_out_segment api;
+  struct zmpls_out_segment out;
+  struct stream *s;
+
+  memset(&api, 0, sizeof(api));
+  memset(&out, 0, sizeof(out));
+  mpls_out_segment_stream_read (client->ibuf, &api);
+
+  out.owner = api.owner;
+  memcpy(&out.nh, &api.nh, sizeof(struct zapi_nexthop));
+
+  mpls_out_segment_register (&out);
+  api.index = out.index;
+
+  /* Reset stream. */
+  s = client->obuf;
+  stream_reset (s);
+
+  zserv_create_header (s, ZEBRA_MPLS_OUT_SEGMENT_ADD);
+  mpls_out_segment_stream_write(s, &api);
+
+  /* Put length at the first point of the stream. */
+  stream_putw_at (s, 0, stream_get_endp (s));
+
+  zebra_server_send_message(client);
+}
+
+static void
+zread_mpls_out_segment_delete (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_out_segment api;
+  struct zmpls_out_segment out;
+
+  memset(&api, 0, sizeof(api));
+  memset(&out, 0, sizeof(out));
+  mpls_out_segment_stream_read (client->ibuf, &api);
+
+  out.owner = api.owner;
+  memcpy(&out.nh, &api.nh, sizeof(struct zapi_nexthop));
+
+  mpls_out_segment_unregister (&out);
+}
+
+static void
+zread_mpls_ftn_add (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_ftn api;
+  struct zmpls_ftn ftn;
+
+  memset(&api, 0, sizeof(api));
+  memset(&ftn, 0, sizeof(ftn));
+  mpls_ftn_stream_read (client->ibuf, &api);
+
+  memcpy(&ftn.fec, &api.fec, sizeof(struct zmpls_fec));
+  ftn.owner = api.owner;
+  ftn.out_index = api.out_index;
+  mpls_ftn_register (&ftn, 1);
+}
+
+static void
+zread_mpls_ftn_delete (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_ftn api;
+  struct zmpls_ftn *ftn;
+
+  memset(&api, 0, sizeof(api));
+  mpls_ftn_stream_read (client->ibuf, &api);
+
+  ftn = mpls_ftn_find_by_fec(&api.fec);
+  if (ftn) {
+    mpls_ftn_unregister (ftn, 1);
+  }
+}
+
+static void
+zread_mpls_labelspace_add (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_labelspace api;
+
+  memset(&api, 0, sizeof(api));
+  mpls_labelspace_stream_read (client->ibuf, &api);
+  assert(0);
+}
+
+static void
+zread_mpls_labelspace_delete (struct zserv *client, u_short length)
+{
+  struct zapi_mpls_labelspace api;
+
+  memset(&api, 0, sizeof(api));
+  mpls_labelspace_stream_read (client->ibuf, &api);
+  assert(0);
+}
+#endif /* HAVE_MPLS */
+
 /* Register zebra server router-id information.  Send current router-id */
 static int
 zread_router_id_add (struct zserv *client, u_short length)
@@ -1283,6 +1512,38 @@
     case ZEBRA_IPV4_IMPORT_LOOKUP:
       zread_ipv4_import_lookup (client, length);
       break;
+#ifdef HAVE_MPLS
+    case ZEBRA_MPLS_XC_ADD:
+      zread_mpls_xc_add (client, length);
+      break;
+    case ZEBRA_MPLS_XC_DELETE:
+      zread_mpls_xc_delete (client, length);
+      break;
+    case ZEBRA_MPLS_IN_SEGMENT_ADD:
+      zread_mpls_in_segment_add (client, length);
+      break;
+    case ZEBRA_MPLS_IN_SEGMENT_DELETE:
+      zread_mpls_in_segment_delete (client, length);
+      break;
+    case ZEBRA_MPLS_OUT_SEGMENT_ADD:
+      zread_mpls_out_segment_add (client, length);
+      break;
+    case ZEBRA_MPLS_OUT_SEGMENT_DELETE:
+      zread_mpls_out_segment_delete (client, length);
+      break;
+    case ZEBRA_MPLS_LABELSPACE_ADD:
+      zread_mpls_labelspace_add (client, length);
+      break;
+    case ZEBRA_MPLS_LABELSPACE_DELETE:
+      zread_mpls_labelspace_delete (client, length);
+      break;
+    case ZEBRA_MPLS_FTN_ADD:
+      zread_mpls_ftn_add (client, length);
+      break;
+    case ZEBRA_MPLS_FTN_DELETE:
+      zread_mpls_ftn_delete (client, length);
+      break;
+#endif /* HAVE_MPLS */
     default:
       zlog_info ("Zebra received unknown command %d", command);
       break;
diff -Naur quagga-0.99.10/zebra/zserv.h quagga-mpls/zebra/zserv.h
--- quagga-0.99.10/zebra/zserv.h	2008-06-07 22:25:16.000000000 +0200
+++ quagga-mpls/zebra/zserv.h	2008-11-25 12:30:18.000000000 +0100
@@ -25,6 +25,9 @@
 #include "rib.h"
 #include "if.h"
 #include "workqueue.h"
+#ifdef HAVE_MPLS
+#include "mpls_lib.h"
+#endif
 
 /* Default port information. */
 #define ZEBRA_VTY_PORT                2601
@@ -95,6 +98,10 @@
 extern void kernel_init (void);
 extern void route_read (void);
 extern void zebra_route_map_init (void);
+#ifdef HAVE_MPLS
+extern void mpls_kernel_init (void);
+extern void mpls_read (void);
+#endif
 extern void zebra_snmp_init (void);
 extern void zebra_vty_init (void);
 
@@ -107,6 +114,38 @@
                                   struct rib *);
 extern int zsend_router_id_update(struct zserv *, struct prefix *);
 
+#ifdef HAVE_MPLS
+int
+zsend_mpls_xc_add (struct zserv *client, struct zmpls_xc *p);
+
+int
+zsend_mpls_xc_delete (struct zserv *client, struct zmpls_xc *p);
+
+int
+zsend_mpls_in_segment_add (struct zserv *client, struct zmpls_in_segment *p);
+
+int
+zsend_mpls_in_segment_delete (struct zserv *client, struct zmpls_in_segment *p);
+
+int
+zsend_mpls_out_segment_add (struct zserv *client, struct zmpls_out_segment *p);
+
+int
+zsend_mpls_out_segment_delete (struct zserv *client, struct zmpls_out_segment *p);
+
+int
+zsend_mpls_labelspace_add (struct zserv *client, struct interface *ifp);
+
+int
+zsend_mpls_labelspace_delete (struct zserv *client, struct interface *ifp);
+
+int
+zsend_mpls_ftn_add (struct zserv *client, struct zmpls_ftn *ftn);
+
+int
+zsend_mpls_ftn_delete (struct zserv *client, struct zmpls_ftn *ftn);
+#endif
+
 extern pid_t pid;
 
 #endif /* _ZEBRA_ZEBRA_H */
